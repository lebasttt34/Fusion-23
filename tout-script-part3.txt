    with contextlib.redirect_stdout(old_stdout), contextlib.redirect_stderr(old_stderr):
        try:
            # Ex√©cute dans un environnement tr√®s limit√© pour la s√©curit√©
            exec(code, {'__builtins__': {}})
            output = old_stdout.getvalue()
            error = old_stderr.getvalue()
            if error:
                return f"üêç Erreur Python:\n{error}\nSortie:\n{output}"
            return f"‚úÖ Sortie Python:\n{output}"
        except Exception as e:
            return f"‚ùå Erreur d'ex√©cution Python: {e}\nSortie standard:\n{old_stdout.getvalue()}\nErreur standard:\n{old_stderr.getvalue()}"

def _run_shell_sync(command: str) -> str:
    """Ex√©cute une commande shell de mani√®re synchrone et capture la sortie."""
    try:
        # Utilisation de subprocess.run pour une ex√©cution plus contr√¥l√©e
        result = subprocess.run(
            command,
            shell=True,
            capture_output=True,
            text=True,
            check=True,
            timeout=10 # Ajoute un timeout pour √©viter les boucles infinies
        )
        output = result.stdout
        error = result.stderr
        if error:
            return f"üêö Erreur Shell:\n{error}\nSortie:\n{output}"
        return f"‚úÖ Sortie Shell:\n{output}"
    except subprocess.CalledProcessError as e:
        return f"‚ùå Erreur d'ex√©cution Shell (Code: {e.returncode}):\n{e.stderr}\nSortie:\n{e.stdout}"
    except subprocess.TimeoutExpired:
        return "‚ùå Erreur Shell: La commande a d√©pass√© le temps d'ex√©cution imparti."
    except Exception as e:
        return f"‚ùå Erreur inattendue lors de l'ex√©cution Shell: {e}"

async def analyze_python_code(code: str) -> str:
    """Analyse le code Python avec Pyflakes et formate avec Black (simul√©)."""
    # Simulation de Pyflakes (analyse syntaxique basique)
    try:
        ast.parse(code)
    except SyntaxError as e:
        return f"‚ùå Erreur de syntaxe Python: {e}"

    # Simulation de Black (retourne le code tel quel pour l'instant)
    formatted_code = code # Dans un environnement r√©el, on appellerait Black

    # Simulation de Pyflakes (pour des erreurs plus sp√©cifiques)
    # Dans un environnement r√©el, on utiliserait un wrapper pour pyflakes
    pyflakes_output = []
    if "import os" in code and "os.remove" in code: # Exemple de r√®gle simple
        pyflakes_output.append("AVERTISSEMENT: Utilisation potentielle de os.remove d√©tect√©e.")

    if pyflakes_output:
        return f"Code format√© (Black):\n```python\n{formatted_code}\n```\n\nAnalyses Pyflakes (simul√©):\n" + "\n".join(pyflakes_output)
    return f"Code format√© (Black):\n```python\n{formatted_code}\n```\n\nAnalyse Pyflakes: Aucun probl√®me majeur d√©tect√© (simulation)."

# --- OCR Tool (using external API like Cloudmersive if configured) ---
import base64 # Import n√©cessaire pour l'OCR

async def perform_ocr(image_url: str, api_key: str, endpoint: str) -> str:
    """
    Effectue l'OCR sur une URL d'image en utilisant une API sp√©cifi√©e.
    Suppose qu'une API comme Cloudmersive ou similaire est utilis√©e.
    """
    try:
        # T√©l√©charge d'abord l'image
        async with httpx.AsyncClient(timeout=10) as client:
            img_response = await client.get(image_url)
            img_response.raise_for_status() # L√®ve une exception pour les erreurs HTTP (4xx ou 5xx)

        # Encode l'image en base64 pour l'API (pratique courante)
        img_data = base64.b64encode(img_response.content).decode('utf-8')

        headers = {
            "Content-Type": "application/json",
            "Apikey": api_key # Supposant un header de cl√© API de style Cloudmersive
        }
        # Supposant que l'API prend l'image encod√©e en base64 en JSON
        payload = {"base64_image": img_data}

        # Cet endpoint peut varier consid√©rablement selon l'API OCR r√©elle.
        # Ceci est un placeholder pour 'Image_RecognizeAndExtractText' de Cloudmersive par exemple
        ocr_endpoint = f"{endpoint}/image/recognize/extractText" if "cloudmersive" in endpoint.lower() else endpoint

        async with httpx.AsyncClient(timeout=30) as client:
            response = await client.post(ocr_endpoint, json=payload, headers=headers)
            response.raise_for_status()
            result = response.json()

        # Adapte le parsing bas√© sur la structure de la r√©ponse API r√©elle
        if "TextExtracted" in result: # Exemple pour Cloudmersive
            return f"‚úÖ Texte extrait par OCR:\n{result['TextExtracted']}"
        elif "extractedText" in result: # Autre cl√© commune
            return f"‚úÖ Texte extrait par OCR:\n{result['extractedText']}"
        else:
            return f"‚ùå OCR: Format de r√©ponse API inconnu. R√©ponse brute: {result}"

    except httpx.HTTPStatusError as e:
        log_message(f"Erreur HTTP/r√©seau lors de l'OCR: {e.response.status_code} - {e.response.text}", level="error")
        return f"‚ùå Erreur lors de l'OCR (r√©seau/API): {e}"
    except httpx.RequestError as e:
        log_message(f"Erreur de requ√™te lors de l'OCR: {e}", level="error")
        return f"‚ùå Erreur lors de l'OCR (requ√™te): {e}"
    except json.JSONDecodeError:
        return "‚ùå OCR: R√©ponse non JSON de l'API."
    except Exception as e:
        log_message(f"Erreur inattendue lors de l'OCR: {e}", level="error")
        return f"‚ùå Erreur inattendue lors de l'OCR: {e}"


# --- FIN DU BLOC OUTILS DE DEVELOPPEMENT ---

# --- DEBUT DU BLOC CLIENT API (BASE) ---

class APIClient:
    """Classe de base pour tous les clients API."""
    def __init__(self, name: str, key_info: Union["Dict", "List"]):
        self.name = name
        self.key_info = key_info # Peut √™tre un dict pour une cl√© unique, ou une liste de dicts pour plusieurs
        self.available_keys = []
        self._load_keys()

    def _load_keys(self):
        """Charge et pr√©pare les cl√©s API, g√®re les cl√©s multiples si pr√©sentes."""
        if isinstance(self.key_info, list):
            self.available_keys = self.key_info
        else:
            self.available_keys = [self.key_info] # Enveloppe la cl√© unique dans une liste
        log_message(f"Client API {self.name} initialis√© avec {len(self.available_keys)} cl√©(s).")

    async def _make_request(self, method: str, url: str, headers: "Dict" = None, json_data: "Dict" = None, params: "Dict" = None, timeout: int = 30) -> Optional["Dict"]:
        """M√©thode interne pour effectuer les requ√™tes HTTP."""
        try:
            async with httpx.AsyncClient(timeout=timeout) as client:
                response = await client.request(method, url, headers=headers, json=json_data, params=params)
                response.raise_for_status() # L√®ve une exception pour les r√©ponses 4xx/5xx
                return response.json()
        except httpx.HTTPStatusError as e:
            log_message(f"API {self.name} erreur HTTP: {e.response.status_code} - {e.response.text}", level="error")
            return {"error": True, "status_code": e.response.status_code, "message": e.response.text}
        except httpx.RequestError as e:
            log_message(f"API {self.name} erreur de requ√™te: {e}", level="error")
            return {"error": True, "message": str(e)}
        except json.JSONDecodeError:
            log_message(f"API {self.name} erreur de d√©codage JSON: {response.text}", level="error")
            return {"error": True, "message": "R√©ponse JSON invalide de l'API"}
        except Exception as e:
            log_message(f"API {self.name} erreur inattendue: {e}", level="error")
            return {"error": True, "message": str(e)}

    async def query(self, *args, **kwargs) -> Any:
        """M√©thode abstraite pour interroger l'API."""
        raise NotImplementedError("La m√©thode query doit √™tre impl√©ment√©e par les sous-classes.")

# --- FIN DU BLOC CLIENT API (BASE) ---

# --- DEBUT DU BLOC CLIENTS API SPECIFIQUES ---

class DeepSeekClient(APIClient):
    def __init__(self):
        super().__init__("DeepSeek", API_KEYS["DEEPSEEK"])
        self.api_key = self.available_keys[0]["key"]
        self.endpoint = self.available_keys[0]["endpoint"]

    async def query(self, prompt: str, model: str = "deepseek-chat") -> str:
        headers = {
            "Content-Type": "application/json",
            "Authorization": f"Bearer {self.api_key}"
        }
        payload = {
            "model": model,
            "messages": [{"role": "user", "content": prompt}],
            "stream": False
        }
        response = await self._make_request("POST", self.endpoint, headers=headers, json_data=payload)
        if response and not response.get("error"):
            return response.get("choices", [{}])[0].get("message", {}).get("content", "Pas de r√©ponse de DeepSeek.")
        return f"Erreur DeepSeek: {response.get('message', 'Inconnu')}" if response else "DeepSeek: R√©ponse vide."

class SerperClient(APIClient):
    def __init__(self):
        super().__init__("Serper", API_KEYS["SERPER"])
        self.api_key = self.available_keys[0]["key"]
        self.endpoint = self.available_keys[0]["endpoint"]

    async def query(self, query_text: str) -> str:
        headers = {
            "X-API-KEY": self.api_key,
            "Content-Type": "application/json"
        }
        payload = {"q": query_text}
        response = await self._make_request("POST", self.endpoint, headers=headers, json_data=payload)
        if response and not response.get("error"):
            organic_results = response.get("organic", [])
            if organic_results:
                snippet = organic_results[0].get("snippet", "Pas de snippet.")
                link = organic_results[0].get("link", "")
                return f"Serper (recherche web):\n{snippet} {neutralize_urls(link)}"
            return "Serper: Aucune information trouv√©e."
        return f"Erreur Serper: {response.get('message', 'Inconnu')}" if response else "Serper: R√©ponse vide."

class WolframAlphaClient(APIClient):
    def __init__(self):
        super().__init__("WolframAlpha", API_KEYS["WOLFRAMALPHA"])
        self.api_key = self.available_keys[0]["key"]
        self.endpoint = self.available_keys[0]["endpoint"]

    async def query(self, input_text: str) -> str:
        params = {
            "appid": self.api_key,
            "input": input_text,
            "format": "plaintext",
            "output": "json" # Request JSON output for easier parsing
        }
        response = await self._make_request("GET", self.endpoint, params=params)
        if response and not response.get("error"):
            pods = response.get("queryresult", {}).get("pods", [])
            if pods:
                for pod in pods:
                    if pod.get("title") in ["Result", "Input interpretation", "Decimal approximation"]:
                        subpods = pod.get("subpods", [])
                        if subpods and subpods[0].get("plaintext"):
                            return f"WolframAlpha:\n{subpods[0]['plaintext']}"
                if pods[0].get("subpods") and pods[0]["subpods"][0].get("plaintext"):
                    return f"WolframAlpha:\n{pods[0]['subpods'][0]['plaintext']}"
            return "WolframAlpha: Pas de r√©sultat clair."
        return f"Erreur WolframAlpha: {response.get('message', 'Inconnu')}" if response else "WolframAlpha: R√©ponse vide."

class TavilyClient(APIClient):
    def __init__(self):
        super().__init__("Tavily", API_KEYS["TAVILY"])
        self.api_key = self.available_keys[0]["key"]
        self.endpoint = self.available_keys[0]["endpoint"]

    async def query(self, query_text: str, max_results: int = 3) -> str:
        headers = {
            "Content-Type": "application/json",
            "Authorization": f"Bearer {self.api_key}"
        }
        payload = {
            "query": query_text,
            "search_depth": "advanced", # or "basic"
            "max_results": max_results,
            "include_answer": True
        }
        response = await self._make_request("POST", self.endpoint, headers=headers, json_data=payload)
        if response and not response.get("error"):
            results = response.get("results", [])
            answer = response.get("answer", "Aucune r√©ponse directe trouv√©e.")

            output = f"Tavily (recherche web):\nR√©ponse directe: {answer}\n"
            if results:
                output += "Extraits pertinents:\n"
                for i, res in enumerate(results[:max_results]):
                    output += f"- {res.get('title', 'N/A')}: {res.get('content', 'N/A')} {neutralize_urls(res.get('url', ''))}\n"
            return output
        return f"Erreur Tavily: {response.get('message', 'Inconnu')}" if response else "Tavily: R√©ponse vide."

class ApiFlashClient(APIClient):
    def __init__(self):
        super().__init__("ApiFlash", API_KEYS["APIFLASH"])
        self.api_key = self.available_keys[0]["key"]
        self.endpoint = self.available_keys[0]["endpoint"]

    async def query(self, url: str) -> str:
        params = {
            "access_key": self.api_key,
            "url": url,
            "format": "jpeg",
            "full_page": "true"
        }
        capture_url = f"{self.endpoint}?access_key={self.api_key}&url={url}"
        return f"ApiFlash (capture d'√©cran): {neutralize_urls(capture_url)} (V√©rifiez le lien pour l'image)"

class CrawlbaseClient(APIClient):
    def __init__(self):
        super().__init__("Crawlbase", API_KEYS["CRAWLBASE"])
        self.api_key = self.available_keys[0]["key"]
        self.endpoint = self.available_keys[0]["endpoint"]

    async def query(self, url: str, use_js: bool = False) -> str:
        params = {
            "token": self.api_key,
            "url": url,
            "format": "json"
        }
        if use_js:
            params["js"] = 1

        response = await self._make_request("GET", self.endpoint, params=params)
        if response and not response.get("error"):
            body = response.get("body")
            if body:
                try:
                    decoded_body = base64.b64decode(body).decode('utf-8', errors='ignore')
                    return f"Crawlbase (contenu web):\n{decoded_body[:1000]}..." # Truncate for brevity
                except Exception:
                    return f"Crawlbase (contenu web - brut):\n{body[:1000]}..."
            return "Crawlbase: Contenu non trouv√©."
        return f"Erreur Crawlbase: {response.get('message', 'Inconnu')}" if response else "Crawlbase: R√©ponse vide."

class DetectLanguageClient(APIClient):
    def __init__(self):
        super().__init__("DetectLanguage", API_KEYS["DETECTLANGUAGE"])
        self.api_key = self.available_keys[0]["key"]
        self.endpoint = self.available_keys[0]["endpoint"]

    async def query(self, text: str) -> str:
        payload = {"q": text}
        headers = {"Authorization": f"Bearer {self.api_key}"} # Check if this is the correct header
        response = await self._make_request("POST", self.endpoint, headers=headers, json_data=payload)
        if response and not response.get("error"):
            detections = response.get("data", {}).get("detections", [])
            if detections:
                first_detection = detections[0]
                lang = first_detection.get("language")
                confidence = first_detection.get("confidence")
                return f"Langue d√©tect√©e: {lang} (confiance: {confidence})"
            return "DetectLanguage: Aucune langue d√©tect√©e."
        return f"Erreur DetectLanguage: {response.get('message', 'Inconnu')}" if response else "DetectLanguage: R√©ponse vide."

class GuardianClient(APIClient):
    def __init__(self):
        super().__init__("Guardian", API_KEYS["GUARDIAN"])
        self.api_key = self.available_keys[0]["key"]
        self.endpoint = self.available_keys[0]["endpoint"]

    async def query(self, query_text: str) -> str:
        params = {
            "api-key": self.api_key,
            "q": query_text,
            "show-fields": "headline,trailText"
        }
        response = await self._make_request("GET", self.endpoint, params=params)
        if response and not response.get("error"):
            results = response.get("response", {}).get("results", [])
            if results:
                output = "Articles The Guardian:\n"
                for res in results[:3]: # Limit to 3 articles
                    output += f"- {res.get('webTitle', 'N/A')}: {res.get('fields', {}).get('trailText', 'N/A')} {neutralize_urls(res.get('webUrl', ''))}\n"
                return output
            return "Guardian: Aucun article trouv√©."
        return f"Erreur Guardian: {response.get('message', 'Inconnu')}" if response else "Guardian: R√©ponse vide."

class IP2LocationClient(APIClient):
    def __init__(self):
        super().__init__("IP2Location", API_KEYS["IP2LOCATION"])
        self.api_key = self.available_keys[0]["key"]
        self.endpoint = self.available_keys[0]["endpoint"]

    async def query(self, ip_address: str) -> str:
        params = {
            "key": self.api_key,
            "ip": ip_address
        }
        response = await self._make_request("GET", self.endpoint, params=params)
        if response and not response.get("error"):
            if "country_name" in response:
                return f"IP2Location (G√©olocalisation IP {ip_address}): Pays: {response['country_name']}, Ville: {response.get('city_name', 'N/A')}"
            return "IP2Location: Informations non trouv√©es."
        return f"Erreur IP2Location: {response.get('message', 'Inconnu')}" if response else "IP2Location: R√©ponse vide."

class ShodanClient(APIClient):
    def __init__(self):
        super().__init__("Shodan", API_KEYS["SHODAN"])
        self.api_key = self.available_keys[0]["key"]
        self.endpoint = self.available_keys[0]["endpoint"]

    async def query(self, query_text: str) -> str:
        # Shodan API has various endpoints. This example uses /api-info.
        # For actual search, it would be /shodan/host/search or /shodan/scan
        # For simplicity, we'll just query /api-info which tells us about the key.
        params = {"key": self.api_key}
        response = await self._make_request("GET", self.endpoint, params=params)
        if response and not response.get("error"):
            return f"Shodan (info cl√©): Requ√™tes restantes: {response.get('usage_limits', {}).get('query_credits', 'N/A')}, Scan cr√©dits: {response.get('usage_limits', {}).get('scan_credits', 'N/A')}"
        return f"Erreur Shodan: {response.get('message', 'Inconnu')}" if response else "Shodan: R√©ponse vide."

class WeatherAPIClient(APIClient):
    def __init__(self):
        super().__init__("WeatherAPI", API_KEYS["WEATHERAPI"])
        self.api_key = self.available_keys[0]["key"]
        self.endpoint = self.available_keys[0]["endpoint"]

    async def query(self, location: str) -> str:
        params = {
            "key": self.api_key,
            "q": location
        }
        response = await self._make_request("GET", self.endpoint, params=params)
        if response and not response.get("error"):
            current = response.get("current", {})
            location_info = response.get("location", {})
            if current and location_info:
                return (
                    f"M√©t√©o √† {location_info.get('name', 'N/A')}, {location_info.get('country', 'N/A')}:\n"
                    f"Temp√©rature: {current.get('temp_c', 'N/A')}¬∞C, "
                    f"Conditions: {current.get('condition', {}).get('text', 'N/A')}, "
                    f"Vent: {current.get('wind_kph', 'N/A')} km/h"
                )
            return "WeatherAPI: Donn√©es m√©t√©o non trouv√©es."
        return f"Erreur WeatherAPI: {response.get('message', 'Inconnu')}" if response else "WeatherAPI: R√©ponse vide."

class CloudmersiveClient(APIClient):
    def __init__(self):
        super().__init__("Cloudmersive", API_KEYS["CLOUDMERSIVE"])
        self.api_key = self.available_keys[0]["key"]
        self.endpoint = self.available_keys[0]["endpoint"]

    async def query(self, domain: str) -> str:
        headers = {"Apikey": self.api_key}
        payload = {"domain": domain}
        response = await self._make_request("POST", self.endpoint, headers=headers, json_data=payload)
        if response and not response.get("error"):
            return f"Cloudmersive (v√©rification de domaine {domain}): Valide: {response.get('ValidDomain', 'N/A')}, Type: {response.get('DomainType', 'N/A')}"
        return f"Erreur Cloudmersive: {response.get('message', 'Inconnu')}" if response else "Cloudmersive: R√©ponse vide."

class GreyNoiseClient(APIClient):
    def __init__(self):
        super().__init__("GreyNoise", API_KEYS["GREYNOISE"])
        self.api_key = self.available_keys[0]["key"]
        self.endpoint = self.available_keys[0]["endpoint"]

    async def query(self, ip_address: str) -> str:
        headers = {"key": self.api_key}
        endpoint = f"{self.endpoint}{ip_address}"
        response = await self._make_request("GET", endpoint, headers=headers)
        if response and not response.get("error"):
            if response.get("noise"):
                return f"GreyNoise (IP {ip_address}): C'est une IP 'bruit' (malveillante). Classification: {response.get('classification', 'N/A')}, Nom d'acteur: {response.get('actor', 'N/A')}"
            return f"GreyNoise (IP {ip_address}): Pas de 'bruit' d√©tect√©. Statut: {response.get('status', 'N/A')}"
        return f"Erreur GreyNoise: {response.get('message', 'Inconnu')}" if response else "GreyNoise: R√©ponse vide."

class PulsediveClient(APIClient):
    def __init__(self):
        super().__init__("Pulsedive", API_KEYS["PULSEDIVE"])
        self.api_key = self.available_keys[0]["key"]
        self.endpoint = self.available_keys[0]["endpoint"]

    async def query(self, indicator: str, type: str = "auto") -> str:
        params = {
            "key": self.api_key,
            "indicator": indicator,
            "type": type
        }
        response = await self._make_request("GET", self.endpoint, params=params)
        if response and not response.get("error"):
            if response.get("results"):
                result = response["results"][0]
                return (
                    f"Pulsedive (Analyse {indicator}): Type: {result.get('type', 'N/A')}, "
                    f"Risk: {result.get('risk', 'N/A')}, "
                    f"Description: {result.get('description', 'N/A')[:200]}..."
                )
            return "Pulsedive: Aucun r√©sultat d'analyse trouv√©."
        return f"Erreur Pulsedive: {response.get('message', 'Inconnu')}" if response else "Pulsedive: R√©ponse vide."

class StormGlassClient(APIClient):
    def __init__(self):
        super().__init__("StormGlass", API_KEYS["STORMGLASS"])
        self.api_key = self.available_keys[0]["key"]
        self.endpoint = self.available_keys[0]["endpoint"]

    async def query(self, lat: float, lng: float, params: str = "airTemperature,waveHeight") -> str:
        now = int(time.time())
        headers = {"Authorization": self.api_key}
        params_dict = {
            "lat": lat,
            "lng": lng,
            "params": params,
            "start": now,
            "end": now + 3600 # One hour from now
        }
        response = await self._make_request("GET", self.endpoint, headers=headers, params=params_dict)
        if response and not response.get("error"):
            data = response.get("hours", [])
            if data:
                first_hour = data[0]
                temp = first_hour.get('airTemperature', [{}])[0].get('value', 'N/A')
                wave_height = first_hour.get('waveHeight', [{}])[0].get('value', 'N/A')
                return f"StormGlass (M√©t√©o maritime √† {lat},{lng}): Temp√©rature air: {temp}¬∞C, Hauteur vagues: {wave_height}m"
            return "StormGlass: Donn√©es non trouv√©es."
        return f"Erreur StormGlass: {response.get('message', 'Inconnu')}" if response else "StormGlass: R√©ponse vide."

class LoginRadiusClient(APIClient):
    def __init__(self):
        super().__init__("LoginRadius", API_KEYS["LOGINRADIUS"])
        self.api_key = self.available_keys[0]["key"]
        self.endpoint = self.available_keys[0]["endpoint"]

    async def query(self) -> str:
        headers = {"Authorization": f"Bearer {self.api_key}"}
        response = await self._make_request("GET", self.endpoint, headers=headers)
        if response and not response.get("error"):
            return f"LoginRadius (Ping API): Statut: {response.get('Status', 'N/A')}, Message: {response.get('Message', 'N/A')}"
        return f"Erreur LoginRadius: {response.get('message', 'Inconnu')}" if response else "LoginRadius: R√©ponse vide."

class JsonbinClient(APIClient):
    def __init__(self):
        super().__init__("Jsonbin", API_KEYS["JSONBIN"])
        self.api_key = self.available_keys[0]["key"]
        self.endpoint = self.available_keys[0]["endpoint"]

    async def query(self, data: Dict[str, Any], private: bool = True) -> str:
        headers = {
            "X-Master-Key": self.api_key,
            "Content-Type": "application/json"
        }
        payload = {
            "record": data,
            "private": private
        }
        response = await self._make_request("POST", self.endpoint, headers=headers, json_data=payload)
        if response and not response.get("error"):
            return f"Jsonbin (Cr√©ation de bin): ID: {response.get('metadata', {}).get('id', 'N/A')}, URL: {neutralize_urls(response.get('metadata', {}).get('url', 'N/A'))}"
        return f"Erreur Jsonbin: {response.get('message', 'Inconnu')}" if response else "Jsonbin: R√©ponse vide."

class HuggingFaceClient(APIClient):
    def __init__(self):
        super().__init__("HuggingFace", API_KEYS["HUGGINGFACE"])
        self.current_key_index = 0

    def _get_current_key_info(self):
        return self.available_keys[self.current_key_index % len(self.available_keys)]

    async def query(self, model_name: str = "distilbert-base-uncased-finetuned-sst-2-english", input_text: str = "Hello world") -> str:
        key_info = self._get_current_key_info()
        api_key = key_info["key"]
        endpoint = f"https://api-inference.huggingface.co/models/{model_name}"

        headers = {
            "Authorization": f"Bearer {api_key}",
            "Content-Type": "application/json"
        }
        payload = {"inputs": input_text}
        response = await self._make_request("POST", endpoint, headers=headers, json_data=payload)
        self.current_key_index += 1

        if response and not response.get("error"):
            if isinstance(response, list) and response:
                first_result = response[0]
                if isinstance(first_result, list) and first_result:
                    return f"HuggingFace ({model_name} - {first_result[0].get('label')}): Score {first_result[0].get('score', 'N/A'):.2f}"
                elif isinstance(first_result, dict):
                     return f"HuggingFace ({model_name}): {first_result.get('generated_text', str(response))}"
            return f"HuggingFace ({model_name}): R√©ponse non pars√©e. {response}"
        return f"Erreur HuggingFace: {response.get('message', 'Inconnu')}" if response else "HuggingFace: R√©ponse vide."

class TwilioClient(APIClient):
    def __init__(self):
        super().__init__("Twilio", API_KEYS["TWILIO"])
        self.sid = self.available_keys[0]["sid"]
        self.secret = self.available_keys[0]["secret"]
        self.endpoint_base = self.available_keys[0]["endpoint"]

    async def query(self) -> str:
        endpoint = f"{self.endpoint_base}{self.sid}/Balance.json"
        headers = httpx.BasicAuth(self.sid, self.secret).auth_header

        response = await self._make_request("GET", endpoint, headers={"Authorization": headers})
        if response and not response.get("error"):
            return f"Twilio (Balance): {response.get('balance', 'N/A')} {response.get('currency', 'N/A')}"
        return f"Erreur Twilio: {response.get('message', 'Inconnu')}" if response else "Twilio: R√©ponse vide."


class AbstractAPIClient(APIClient):
    def __init__(self):
        super().__init__("AbstractAPI", API_KEYS["ABSTRACTAPI"])
        self.current_key_index = 0

    def _get_current_key_info(self, api_type: str):
        """Retourne la cl√© et l'endpoint pour le type d'API AbstractAPI sp√©cifi√©."""
        # Recherche la cl√© correspondant au type d'API demand√©
        for key_info in self.available_keys:
            if key_info.get("type") == api_type:
                return key_info
        return None

    async def query(self, input_value: str, api_type: str = "PHONE_VALIDATION") -> str:
        key_info = self._get_current_key_info(api_type)
        if not key_info:
            return f"AbstractAPI: Type d'API '{api_type}' non configur√©."

        api_key = key_info["key"]
        endpoint = key_info["endpoint"]

        params = {"api_key": api_key}

        if api_type == "PHONE_VALIDATION":
            params["phone"] = input_value
        elif api_type == "IP_GEOLOCATION":
            params["ip_address"] = input_value
        else:
            return f"AbstractAPI: Type d'API '{api_type}' non support√© pour la requ√™te."

        response = await self._make_request("GET", endpoint, params=params)

        if response and not response.get("error"):
            if api_type == "PHONE_VALIDATION":
                return (
                    f"AbstractAPI (Validation T√©l): Num√©ro: {response.get('phone', 'N/A')}, "
                    f"Valide: {response.get('valid', 'N/A')}, "
                    f"Pays: {response.get('country', {}).get('name', 'N/A')}"
                )
            elif api_type == "IP_GEOLOCATION":
                return (
                    f"AbstractAPI (G√©olocalisation IP): IP: {response.get('ip_address', 'N/A')}, "
                    f"Pays: {response.get('country', 'N/A')}, "
                    f"Ville: {response.get('city', 'N/A')}"
                )
            return f"AbstractAPI ({api_type}): R√©ponse brute: {response}"
        return f"Erreur AbstractAPI ({api_type}): {response.get('message', 'Inconnu')}" if response else "AbstractAPI: R√©ponse vide."


# --- Instancier tous les clients API ---
# Ceci sera la liste de tous tes guerriers API, pr√™ts √† √™tre utilis√©s par le cerveau mixte
ALL_API_CLIENTS = [
    DeepSeekClient(),
    SerperClient(),
    WolframAlphaClient(),
    TavilyClient(),
    ApiFlashClient(),
    CrawlbaseClient(),
    DetectLanguageClient(),
    GuardianClient(),
    IP2LocationClient(),
    ShodanClient(),
    WeatherAPIClient(),
    CloudmersiveClient(),
    GreyNoiseClient(),
    PulsediveClient(),
    StormGlassClient(),
    LoginRadiusClient(),
    JsonbinClient(),
    HuggingFaceClient(),
    TwilioClient(),
    AbstractAPIClient(),
]

# --- FIN DU BLOC CLIENTS API SPECIFIQUES ---
# --- DEBUT DU BLOC GESTION MEMOIRE ET QUOTAS ---

class MemoryManager:
    def __init__(self):
        self.chat_history = load_json(HISTORY_FILE, [])
        self.long_term_memory = load_json(LONG_MEMORY_FILE, {})
        self.ia_status = load_json(IA_STATUS_FILE, {}) # Statut/sant√© des IA
        self._initialize_ia_status()

    def _initialize_ia_status(self):
        """Initialise le statut des IA si elles ne sont pas d√©j√† pr√©sentes ou si leur statut est obsol√®te."""
        now = get_current_time()
        updated = False
        for client in ALL_API_CLIENTS:
            if client.name not in self.ia_status:
                self.ia_status[client.name] = {
                    "last_used": None,
                    "last_error": None,
                    "error_count": 0,
                    "cooldown_until": None,
                    "success_count": 0, # Nouveau : Compteur de succ√®s
                    "current_score": 1.0, # Nouveau : Score dynamique de l'IA, commence √† 1.0
                    "last_rotation_check": format_datetime(now)
                }
                updated = True
            else:
                # S'assurer que les nouvelles cl√©s existent pour les IA existantes
                if "success_count" not in self.ia_status[client.name]:
                    self.ia_status[client.name]["success_count"] = 0
                    updated = True
                if "current_score" not in self.ia_status[client.name]:
                    self.ia_status[client.name]["current_score"] = 1.0
                    updated = True
                if "last_rotation_check" not in self.ia_status[client.name]:
                    self.ia_status[client.name]["last_rotation_check"] = format_datetime(now)
                    updated = True

        if updated:
            save_json(IA_STATUS_FILE, self.ia_status)
            log_message("Statut des IA initialis√©/mis √† jour.")

    def add_message_to_history(self, role, content):
        """Ajoute un message √† l'historique de la conversation."""
        self.chat_history.append({"role": role, "content": content, "timestamp": format_datetime(get_current_time())})
        self._prune_history() # Pour √©viter que l'historique ne devienne trop long
        save_json(HISTORY_FILE, self.chat_history)
        log_message(f"Message ajout√© √† l'historique par {role}.")

    def get_chat_history(self, limit=10):
        """Retourne les N derniers messages de l'historique."""
        return self.chat_history[-limit:]

    def add_to_long_term_memory(self, key, value):
        """Ajoute une information √† la m√©moire √† long terme."""
        self.long_term_memory[key] = {"value": value, "timestamp": format_datetime(get_current_time())}
        save_json(LONG_MEMORY_FILE, self.long_term_memory)
        log_message(f"Information ajout√©e √† la m√©moire √† long terme: {key}")

    def get_from_long_term_memory(self, key):
        """R√©cup√®re une information de la m√©moire √† long terme."""
        return self.long_term_memory.get(key)

    def update_ia_status(self, ia_name: str, success: bool, error_message: Optional[str] = None):
        """Met √† jour le statut et le score d'une IA apr√®s une utilisation."""
        status = self.ia_status.get(ia_name)
        if not status:
            log_message(f"Tentative de mise √† jour d'un statut d'IA inconnu: {ia_name}", level="warning")
            return

        now = get_current_time()
        status["last_used"] = format_datetime(now)

        if success:
            status["success_count"] += 1
            status["error_count"] = 0 # Reset error count on success
            status["cooldown_until"] = None
            status["last_error"] = None
            status["current_score"] = min(1.0, status["current_score"] + 0.1) # Augmente le score, max 1.0
            log_message(f"IA {ia_name} : Succ√®s enregistr√©. Nouveau score: {status['current_score']:.2f}")
        else:
            status["error_count"] += 1
            status["last_error"] = error_message
            # Applique un cooldown si trop d'erreurs cons√©cutives
            if status["error_count"] >= 3: # Exemple: 3 erreurs cons√©cutives
                status["cooldown_until"] = format_datetime(now + timedelta(seconds=API_COOLDOWN_DURATION_SECONDS))
                status["current_score"] = max(0.1, status["current_score"] - 0.2) # Diminue le score, min 0.1
                log_message(f"IA {ia_name} : Trop d'erreurs ({status['error_count']}). Cooldown jusqu'√† {status['cooldown_until']}. Nouveau score: {status['current_score']:.2f}", level="warning")
            else:
                 status["current_score"] = max(0.1, status["current_score"] - 0.05) # Petite diminution sur erreur non critique
                 log_message(f"IA {ia_name} : Erreur enregistr√©e. Nouveau score: {status['current_score']:.2f}", level="warning")

        save_json(IA_STATUS_FILE, self.ia_status)

    def get_ia_status(self, ia_name: str) -> Optional[Dict]:
        """R√©cup√®re le statut d'une IA."""
        return self.ia_status.get(ia_name)

    def get_available_ias(self) -> List[str]:
        """Retourne les noms des IA actuellement non en cooldown."""
        available = []
        now = get_current_time()
        for name, status in self.ia_status.items():
            cooldown_until_str = status.get("cooldown_until")
            if cooldown_until_str:
                cooldown_until = datetime.strptime(cooldown_until_str, "%Y-%m-%d %H:%M:%S UTC")
                if now < cooldown_until:
                    # log_message(f"IA {name} est en cooldown jusqu'√† {cooldown_until_str}.")
                    continue # Toujours en cooldown
            available.append(name)
        return available

    def _prune_history(self, max_entries=50):
        """Supprime les anciennes entr√©es de l'historique si trop nombreuses."""
        if len(self.chat_history) > max_entries:
            self.chat_history = self.chat_history[-max_entries:]
            log_message(f"Historique de chat purg√©, {len(self.chat_history)} entr√©es restantes.")

class QuotaManager:
    def __init__(self):
        self.quotas = load_json(QUOTAS_FILE, {})
        self._initialize_quotas()

    def _initialize_quotas(self):
        """Initialise les quotas pour toutes les APIs bas√©es sur config.API_QUOTAS."""
        updated = False
        now = get_current_time()
        for api_name, quota_info in API_QUOTAS.items():
            if api_name not in self.quotas:
                self.quotas[api_name] = {
                    "monthly_usage": 0,
                    "daily_usage": 0,
                    "last_reset_month": now.month,
                    "last_reset_day": now.day,
                    "last_usage": None,
                    "total_calls": 0,
                    "last_hourly_reset": format_datetime(now) # Pour les quotas horaires
                }
                updated = True
            else:
                # Assure que les nouvelles cl√©s sont ajout√©es aux quotas existants
                if "last_hourly_reset" not in self.quotas[api_name]:
                    self.quotas[api_name]["last_hourly_reset"] = format_datetime(now)
                    updated = True
                if "total_calls" not in self.quotas[api_name]:
                    self.quotas[api_name]["total_calls"] = 0
                    updated = True

        if updated:
            save_json(QUOTAS_FILE, self.quotas)
            log_message("Quotas API initialis√©s/mis √† jour.")

    def _reset_quotas_if_needed(self):
        """R√©initialise les quotas journaliers, mensuels et horaires si n√©cessaire."""
        now = get_current_time()
        for api_name, data in self.quotas.items():
            # Reset mensuel
            if now.month != data["last_reset_month"]:
                data["monthly_usage"] = 0
                data["last_reset_month"] = now.month
                log_message(f"Quota mensuel pour {api_name} r√©initialis√©.")
            # Reset journalier
            if now.day != data["last_reset_day"]:
                data["daily_usage"] = 0
                data["last_reset_day"] = now.day
                log_message(f"Quota journalier pour {api_name} r√©initialis√©.")
            # Reset horaire
            last_hourly_reset = datetime.strptime(data["last_hourly_reset"], "%Y-%m-%d %H:%M:%S UTC")
            if (now - last_hourly_reset) >= timedelta(hours=1):
                # R√©initialiser seulement si le quota_info a une cl√© "hourly"
                if API_QUOTAS.get(api_name, {}).get("hourly") is not None:
                    # Ici, il faudrait une logique pour stocker l'usage horaire et le r√©initialiser.
                    # Pour l'instant, on se contente de r√©initialiser la marque de temps.
                    # L'usage horaire r√©el devrait √™tre suivi s√©par√©ment si n√©cessaire.
                    # Pour ce syst√®me, on va dire que 'hourly_usage' est implicite et juste r√©initialis√©.
                    log_message(f"Quota horaire pour {api_name} r√©initialis√© (marque de temps).")
                data["last_hourly_reset"] = format_datetime(now)

        save_json(QUOTAS_FILE, self.quotas)

    def check_and_update_quota(self, api_name: str, cost: int = 1) -> bool:
        """V√©rifie si une API a du quota et le d√©cr√©mente. Retourne True si ok, False sinon."""
        self._reset_quotas_if_needed()
        if api_name not in self.quotas:
            log_message(f"API {api_name} non trouv√©e dans les quotas d√©finis. Autorisation.", level="warning")
            return True # Si non d√©finie, on suppose pas de limite

        quota_data = self.quotas[api_name]
        api_limits = API_QUOTAS.get(api_name, {})

        # V√©rification mensuelle
        monthly_limit = api_limits.get("monthly")
        if monthly_limit is not None and (quota_data["monthly_usage"] + cost) > monthly_limit:
            log_message(f"Quota mensuel d√©pass√© pour {api_name}", level="warning")
            return False

        # V√©rification journali√®re
        daily_limit = api_limits.get("daily")
        if daily_limit is not None and (quota_data["daily_usage"] + cost) > daily_limit:
            log_message(f"Quota journalier d√©pass√© pour {api_name}", level="warning")
            return False

        # V√©rification horaire (si impl√©ment√©e plus tard, n√©cessite un suivi plus granulaire)
        hourly_limit = api_limits.get("hourly")
        # Pour l'instant, pas de suivi horaire d√©taill√©, seulement le reset de la marque de temps.
        # Si un quota horaire est d√©fini, il faudrait une logique pour 'hourly_usage'.
        # Par exemple, une liste de timestamps d'appels sur la derni√®re heure.

        # V√©rification du taux de requ√™tes (rate_limit_per_sec)
        rate_limit_per_sec = api_limits.get("rate_limit_per_sec")
        if rate_limit_per_sec:
            last_usage_str = quota_data.get("last_usage")
            if last_usage_str:
                last_usage = datetime.strptime(last_usage_str, "%Y-%m-%d %H:%M:%S UTC")
                time_since_last_call = (get_current_time() - last_usage).total_seconds()
                if time_since_last_call < (1 / rate_limit_per_sec):
                    log_message(f"Taux de requ√™tes d√©pass√© pour {api_name}. Attendre {1/rate_limit_per_sec - time_since_last_call:.2f}s", level="warning")
                    return False

        # Si toutes les v√©rifications passent, met √† jour l'usage
        quota_data["monthly_usage"] += cost
        quota_data["daily_usage"] += cost
        quota_data["total_calls"] += cost
        quota_data["last_usage"] = format_datetime(get_current_time())
        save_json(QUOTAS_FILE, self.quotas)
        log_message(f"Quota pour {api_name} mis √† jour. Usage mensuel: {quota_data['monthly_usage']}/{monthly_limit if monthly_limit else 'Illimit√©'}, Journalier: {quota_data['daily_usage']}/{daily_limit if daily_limit else 'Illimit√©'}")
        return True

    def get_api_usage(self, api_name: str) -> Optional[Dict]:
        """Retourne les informations d'utilisation d'une API."""
        return self.quotas.get(api_name)

    def get_all_quotas_status(self) -> Dict:
        """Retourne le statut de tous les quotas."""
        self._reset_quotas_if_needed() # S'assurer que les donn√©es sont √† jour
        status = {}
        for api_name, quota_data in self.quotas.items():
            api_limits = API_QUOTAS.get(api_name, {})
            monthly_limit = api_limits.get("monthly", "Illimit√©")
            daily_limit = api_limits.get("daily", "Illimit√©")
            hourly_limit = api_limits.get("hourly", "Illimit√©") # Affiche m√™me si pas de suivi granulaire
            status[api_name] = {
                "monthly_usage": quota_data["monthly_usage"],
                "monthly_limit": monthly_limit,
                "daily_usage": quota_data["daily_usage"],
                "daily_limit": daily_limit,
                "hourly_limit": hourly_limit, # Info de la config
                "total_calls": quota_data["total_calls"],
                "last_usage": quota_data["last_usage"],
                "last_reset_month": quota_data["last_reset_month"],
                "last_reset_day": quota_data["last_reset_day"],
                "last_hourly_reset": quota_data["last_hourly_reset"]
            }
        return status

    def get_burn_window_apis(self) -> List[str]:
        """
        Identifie les APIs dont les quotas sont sur le point d'√™tre r√©initialis√©s
        et o√π il est opportun de "br√ªler" le quota restant.
        """
        burn_apis = []
        now = get_current_time()
        for api_name, data in self.quotas.items():
            api_limits = API_QUOTAS.get(api_name, {})

            # V√©rification pour les quotas mensuels
            if api_limits.get("monthly") is not None:
                last_reset_month = data["last_reset_month"]
                # Calcule le premier jour du mois suivant pour le reset mensuel
                next_month_reset = datetime(now.year + (1 if now.month == 12 else 0), (now.month % 12) + 1, 1)
                
                # V√©rifie si on est dans la fen√™tre de br√ªlage avant le reset mensuel
                if is_within_time_window(next_month_reset, QUOTA_BURN_WINDOW_HOURS * 60, 0):
                    if data["monthly_usage"] < api_limits["monthly"]: # S'il reste du quota
                        burn_apis.append(f"{api_name} (mensuel: {api_limits['monthly'] - data['monthly_usage']} restants)")

            # V√©rification pour les quotas journaliers
            if api_limits.get("daily") is not None:
                last_reset_day = data["last_reset_day"]
                # Calcule le prochain jour pour le reset journalier
                next_day_reset = datetime(now.year, now.month, now.day) + timedelta(days=1)
                
                # V√©rifie si on est dans la fen√™tre de br√ªlage avant le reset journalier
                if is_within_time_window(next_day_reset, QUOTA_BURN_WINDOW_HOURS * 60, 0):
                    if data["daily_usage"] < api_limits["daily"]: # S'il reste du quota
                        burn_apis.append(f"{api_name} (journalier: {api_limits['daily'] - data['daily_usage']} restants)")
            
            # Note: Les quotas horaires n√©cessiteraient une logique plus complexe si 'hourly_usage' est r√©ellement suivi.
            # Pour l'instant, ils sont g√©r√©s par le 'last_hourly_reset' et ne d√©clenchent pas de "burn window" automatique.

        return burn_apis


# Instanciation des gestionnaires
memory_manager = MemoryManager()
quota_manager = QuotaManager()

# --- FIN DU BLOC GESTION MEMOIRE ET QUOTAS ---

# --- DEBUT DU BLOC BOT TELEGRAM PRINCIPAL ---

import time
from telegram import Update, ForceReply
from telegram.ext import Application, CommandHandler, MessageHandler, filters, ContextTypes

# Assurez-vous que tous les imports n√©cessaires sont pr√©sents en haut du fichier
# (asyncio, httpx, logging, re, random, io, contextlib, ast, subprocess, datetime, timedelta, ThreadPoolExecutor, typing)
# Ils devraient d√©j√† y √™tre gr√¢ce aux blocs pr√©c√©dents.

# --- Orchestration des IA ---
class IAOrchestrator:
    def __init__(self, memory_manager: MemoryManager, quota_manager: QuotaManager, api_clients: List[APIClient]):
        self.memory_manager = memory_manager
        self.quota_manager = quota_manager
        self.api_clients = {client.name: client for client in api_clients}
        self.last_rotation_time = get_current_time()
        self.current_ia_strategy = self._determine_initial_strategy()

    def _determine_initial_strategy(self) -> str:
        """D√©termine la strat√©gie initiale ou la strat√©gie par d√©faut."""
        # Pour l'instant, une strat√©gie simple, peut √™tre √©tendue
        return "balanced" # Ou "performance", "cost_effective", etc.

    async def _select_ia(self, query: str) -> Optional[APIClient]:
        """
        S√©lectionne la meilleure IA/API bas√©e sur la requ√™te, le statut, le score et les quotas.
        Impl√©mente une logique de "Cerveau Mixte" dynamique.
        """
        self._rotate_strategy_if_needed()

        available_ias = self.memory_manager.get_available_ias()
        if not available_ias:
            log_message("Aucune IA disponible (toutes en cooldown).", level="error")
            return None

        # Filtrer les IA qui sont pertinents pour la requ√™te (bas√© sur des mots-cl√©s simples pour l'exemple)
        # Ceci est une simplification. Une vraie impl√©mentation utiliserait un mod√®le NLP.
        relevant_ias = []
        query_lower = query.lower()

        # Mappage des mots-cl√©s aux APIs
        keyword_to_api = {
            "recherche web": ["Serper", "Tavily"],
            "calcul": ["WolframAlpha"],
            "m√©t√©o": ["WeatherAPI", "StormGlass"],
            "screenshot": ["ApiFlash"],
            "contenu web": ["Crawlbase"],
            "langue": ["DetectLanguage"],
            "actualit√©": ["Guardian"],
            "ip": ["IP2Location", "GreyNoise", "AbstractAPI"],
            "s√©curit√©": ["Shodan", "GreyNoise", "Pulsedive"],
            "domaine": ["Cloudmersive"],
            "analyse": ["Pulsedive"],
            "maritime": ["StormGlass"],
            "authentification": ["LoginRadius"],
            "json": ["Jsonbin"],
            "ia": ["DeepSeek", "HuggingFace"], # DeepSeek comme IA g√©n√©rique
            "t√©l√©phone": ["AbstractAPI"],
            "twilio": ["Twilio"],
            "huggingface": ["HuggingFace"],
            "code": ["DeepSeek"], # DeepSeek peut aussi aider avec le code
            "python": ["DeepSeek"],
            "shell": ["DeepSeek"]
        }

        potential_ias = set()
        for keyword, apis in keyword_to_api.items():
            if keyword in query_lower:
                potential_ias.update(apis)
        
        # Si aucun mot-cl√© sp√©cifique, consid√©rer toutes les IA g√©n√©riques ou de recherche
        if not potential_ias:
            potential_ias.update(["DeepSeek", "Serper", "Tavily"]) # IA par d√©faut pour les requ√™tes g√©n√©rales

        for ia_name in available_ias:
            if ia_name in potential_ias and ia_name in self.api_clients:
                relevant_ias.append(ia_name)

        if not relevant_ias:
            log_message("Aucune IA pertinente trouv√©e pour la requ√™te.", level="warning")
            # Fallback si aucune IA pertinente n'est trouv√©e, essaie DeepSeek ou Serper
            if "DeepSeek" in available_ias:
                return self.api_clients["DeepSeek"]
            elif "Serper" in available_ias:
                return self.api_clients["Serper"]
            return None

        # Appliquer la strat√©gie de s√©lection
        selected_ia_name = None
        if self.current_ia_strategy == "balanced":
            # Choisir l'IA avec le meilleur score actuel parmi les pertinentes
            best_score = -1
            for ia_name in relevant_ias:
                status = self.memory_manager.get_ia_status(ia_name)
                if status and status["current_score"] > best_score:
                    if self.quota_manager.check_and_update_quota(ia_name, cost=0): # V√©rifie sans consommer
                        best_score = status["current_score"]
                        selected_ia_name = ia_name
            if not selected_ia_name: # Si toutes les IA pertinentes sont sans quota, r√©essaie avec moins de contraintes
                for ia_name in relevant_ias:
                    if self.quota_manager.check_and_update_quota(ia_name, cost=0):
                        selected_ia_name = ia_name
                        break # Prend la premi√®re disponible
        elif self.current_ia_strategy == "cost_effective":
            # Prioriser les APIs avec des quotas √©lev√©s ou illimit√©s
            # Pour l'exemple, on prendra la premi√®re disponible qui n'a pas de limite mensuelle/journali√®re
            for ia_name in relevant_ias:
                api_limits = API_QUOTAS.get(ia_name, {})
                if api_limits.get("monthly") is None and api_limits.get("daily") is None:
                    if self.quota_manager.check_and_update_quota(ia_name, cost=0):
                        selected_ia_name = ia_name
                        break
            if not selected_ia_name: # Fallback au mode √©quilibr√© si pas de "pas cher" dispo
                return await self._select_ia_balanced(relevant_ias) # Appel r√©cursif avec strat√©gie balanc√©e
        elif self.current_ia_strategy == "performance":
            # Prioriser les APIs avec les temps de r√©ponse les plus rapides (n√©cessiterait de stocker les latences)
            # Pour l'exemple, on prendra l'IA avec le plus grand nombre de succ√®s r√©cents comme proxy de performance
            best_success_count = -1
            for ia_name in relevant_ias:
                status = self.memory_manager.get_ia_status(ia_name)
                if status and status["success_count"] > best_success_count:
                    if self.quota_manager.check_and_update_quota(ia_name, cost=0):
                        best_success_count = status["success_count"]
                        selected_ia_name = ia_name
            if not selected_ia_name: # Fallback au mode √©quilibr√©
                return await self._select_ia_balanced(relevant_ias)

        if selected_ia_name and self.quota_manager.check_and_update_quota(selected_ia_name):
            log_message(f"IA s√©lectionn√©e: {selected_ia_name} (Strat√©gie: {self.current_ia_strategy})")
            return self.api_clients[selected_ia_name]
        else:
            log_message("Aucune IA s√©lectionn√©e apr√®s application de la strat√©gie et v√©rification des quotas.", level="warning")
            return None

    async def _select_ia_balanced(self, relevant_ias: List[str]) -> Optional[APIClient]:
        """Helper pour la s√©lection balanc√©e, utilis√©e en fallback."""
        best_score = -1
        selected_ia_name = None
        for ia_name in relevant_ias:
            status = self.memory_manager.get_ia_status(ia_name)
            if status and status["current_score"] > best_score:
                if self.quota_manager.check_and_update_quota(ia_name, cost=0):
                    best_score = status["current_score"]
                    selected_ia_name = ia_name
        if selected_ia_name:
            return self.api_clients[selected_ia_name]
        return None


    def _rotate_strategy_if_needed(self):
        """Change la strat√©gie d'IA si l'intervalle de rotation est pass√©."""
        now = get_current_time()
        if (now - self.last_rotation_time).total_seconds() >= API_ROTATION_INTERVAL_MINUTES * 60:
            strategies = ["balanced", "cost_effective", "performance"]
            self.current_ia_strategy = random.choice(strategies)
            self.last_rotation_time = now
            log_message(f"Strat√©gie d'IA chang√©e pour: {self.current_ia_strategy}")
            # Mettre √† jour le last_rotation_check pour toutes les IA
            for ia_name in self.memory_manager.ia_status:
                self.memory_manager.ia_status[ia_name]["last_rotation_check"] = format_datetime(now)
            save_json(IA_STATUS_FILE, self.memory_manager.ia_status)


    async def process_query(self, query: str) -> str:
        """Traite une requ√™te en s√©lectionnant une IA et en obtenant une r√©ponse."""
        selected_ia = await self._select_ia(query)
        if not selected_ia:
            return "D√©sol√©, toutes mes IA sont occup√©es ou en maintenance pour le moment. Veuillez r√©essayer plus tard."

        ia_name = selected_ia.name
        response_content = ""
        try:
            log_message(f"Appel de l'IA {ia_name} avec la requ√™te: '{query}'")
            if ia_name == "DeepSeek":
                response_content = await selected_ia.query(query)
            elif ia_name == "Serper":
                response_content = await selected_ia.query(query)
            elif ia_name == "WolframAlpha":
                response_content = await selected_ia.query(query)
            elif ia_name == "Tavily":
                response_content = await selected_ia.query(query)
            elif ia_name == "ApiFlash":
                # N√©cessite une URL. Si la query n'est pas une URL, on ne peut pas l'utiliser directement.
                # Ici, on ferait une d√©tection d'URL ou on demanderait √† l'utilisateur.
                # Pour l'exemple, on suppose que la query est une URL si ApiFlash est choisie.
                if re.match(r'https?://[^\s]+', query):
                    response_content = await selected_ia.query(query)
                else:
                    response_content = "Veuillez fournir une URL valide pour la capture d'√©cran."
                    self.memory_manager.update_ia_status(ia_name, False, "URL invalide pour ApiFlash")
                    return response_content
            elif ia_name == "Crawlbase":
                if re.match(r'https?://[^\s]+', query):
                    response_content = await selected_ia.query(query)
                else:
                    response_content = "Veuillez fournir une URL valide pour l'extraction de contenu."
                    self.memory_manager.update_ia_status(ia_name, False, "URL invalide pour Crawlbase")
                    return response_content
            elif ia_name == "DetectLanguage":
                response_content = await selected_ia.query(query)
            elif ia_name == "Guardian":
                response_content = await selected_ia.query(query)
            elif ia_name == "IP2Location":
                # Simple regex pour une IP, peut √™tre am√©lior√©
                if re.match(r'^\d{1,3}\.\d{1,3}\.\d{1,3}\.\d{1,3}$', query):
                    response_content = await selected_ia.query(query)
                else:
                    response_content = "Veuillez fournir une adresse IP valide pour la g√©olocalisation."
                    self.memory_manager.update_ia_status(ia_name, False, "IP invalide pour IP2Location")
                    return response_content
            elif ia_name == "Shodan":
                response_content = await selected_ia.query(query) # Shodan query est plus complexe en r√©alit√©
            elif ia_name == "WeatherAPI":
                response_content = await selected_ia.query(query)
            elif ia_name == "Cloudmersive":
                # Supposons que la query est un domaine
                response_content = await selected_ia.query(query)
            elif ia_name == "GreyNoise":
                if re.match(r'^\d{1,3}\.\d{1,3}\.\d{1,3}\.\d{1,3}$', query):
                    response_content = await selected_ia.query(query)
                else:
                    response_content = "Veuillez fournir une adresse IP valide pour GreyNoise."
                    self.memory_manager.update_ia_status(ia_name, False, "IP invalide pour GreyNoise")
                    return response_content
            elif ia_name == "Pulsedive":
                response_content = await selected_ia.query(query) # L'indicateur est la query
            elif ia_name == "StormGlass":
                # N√©cessite lat/lng et params. On va faire une d√©tection simple ou demander.
                # Pour l'exemple, on peut chercher des chiffres qui ressemblent √† lat/lng dans la query.
                coords = re.findall(r"[-+]?\d*\.\d+|\d+", query)
                if len(coords) >= 2:
                    try:
                        lat, lng = float(coords[0]), float(coords[1])
                        response_content = await selected_ia.query(lat, lng)
                    except ValueError:
                        response_content = "Coordonn√©es lat/lng invalides pour StormGlass."
                        self.memory_manager.update_ia_status(ia_name, False, "Coordonn√©es invalides")
                        return response_content
                else:
                    response_content = "Veuillez fournir des coordonn√©es (latitude, longitude) pour StormGlass."
                    self.memory_manager.update_ia_status(ia_name, False, "Coordonn√©es manquantes pour StormGlass")
                    return response_content
            elif ia_name == "LoginRadius":
                response_content = await selected_ia.query() # Pas d'argument pour la query de ping
            elif ia_name == "Jsonbin":
                # N√©cessite des donn√©es JSON. On va simuler une cr√©ation de bin simple.
                try:
                    # Tente de parser la query comme JSON
                    data_to_save = json.loads(query)
                    response_content = await selected_ia.query(data_to_save)
                except json.JSONDecodeError:
                    response_content = "Veuillez fournir des donn√©es JSON valides pour Jsonbin."
                    self.memory_manager.update_ia_status(ia_name, False, "Donn√©es JSON invalides pour Jsonbin")
                    return response_content
            elif ia_name == "HuggingFace":
                # HuggingFace est plus complexe, n√©cessite un mod√®le et un input.
                # Pour l'exemple, on utilise un mod√®le par d√©faut et la query comme input.
                response_content = await selected_ia.query(input_text=query)
            elif ia_name == "Twilio":
                response_content = await selected_ia.query() # Pas d'argument pour la query de balance
            elif ia_name == "AbstractAPI":
                # D√©tecter le type d'API AbstractAPI √† utiliser (t√©l√©phone ou IP)
                if re.match(r'^\+?\d{7,15}$', query.replace(" ", "")): # Simple regex pour num√©ro de tel
                    response_content = await selected_ia.query(query, api_type="PHONE_VALIDATION")
                elif re.match(r'^\d{1,3}\.\d{1,3}\.\d{1,3}\.\d{1,3}$', query):
                    response_content = await selected_ia.query(query, api_type="IP_GEOLOCATION")
                else:
                    response_content = "Veuillez sp√©cifier un num√©ro de t√©l√©phone ou une adresse IP pour AbstractAPI."
                    self.memory_manager.update_ia_status(ia_name, False, "Input invalide pour AbstractAPI")
                    return response_content
            else:
                response_content = f"L'IA {ia_name} n'a pas de m√©thode de requ√™te d√©finie pour cette interaction."
                self.memory_manager.update_ia_status(ia_name, False, "M√©thode de requ√™te non d√©finie")
                return response_content

            self.memory_manager.update_ia_status(ia_name, True)
            return response_content
        except Exception as e:
            log_message(f"Erreur lors de l'appel de l'IA {ia_name}: {e}", level="error")
            self.memory_manager.update_ia_status(ia_name, False, str(e))
            return f"D√©sol√©, l'IA {ia_name} a rencontr√© une erreur: {e}. J'essaierai de trouver une alternative la prochaine fois."

    async def synthesize_response(self, question: str, responses: List[str]) -> str:
        """
        Synth√©tise les r√©ponses de plusieurs IA en utilisant DeepSeek.
        """
        if not responses:
            return "Je n'ai re√ßu aucune r√©ponse des IA pour le moment."

        combined_responses = "\n\n".join([f"R√©ponse {i+1}:\n{r}" for i, r in enumerate(responses)])
        synthesis_prompt = SYNTHESIS_PROMPT_TEMPLATE.format(question=question, responses=combined_responses)

        deepseek_client = self.api_clients.get("DeepSeek")
        if not deepseek_client:
            log_message("DeepSeek n'est pas disponible pour la synth√®se.", level="warning")
            return "J'ai plusieurs r√©ponses, mais je ne peux pas les synth√©tiser pour le moment. Voici les r√©ponses brutes:\n\n" + combined_responses

        try:
            synthesis = await deepseek_client.query(synthesis_prompt)
            self.memory_manager.update_ia_status("DeepSeek", True)
            return detect_and_correct_toxicity(synthesis)
        except Exception as e:
            log_message(f"Erreur lors de la synth√®se avec DeepSeek: {e}", level="error")
            self.memory_manager.update_ia_status("DeepSeek", False, str(e))
            return "J'ai rencontr√© un probl√®me lors de la synth√®se des informations. Voici les r√©ponses brutes:\n\n" + combined_responses


# Instancier l'orchestrateur
orchestrator = IAOrchestrator(memory_manager, quota_manager, ALL_API_CLIENTS)


# --- Handlers de commandes Telegram ---

async def start(update: Update, context: ContextTypes.DEFAULT_TYPE) -> None:
    """Envoie un message lorsque la commande /start est √©mise."""
    user = update.effective_user
    await update.message.reply_html(
        f"Salut {user.mention_html()} ! Je suis ton assistant IA de 2025. "
        "Pose-moi une question, demande-moi d'√©crire du code, ou de chercher des infos. "
        "Utilise /help pour voir ce que je peux faire.",
        reply_markup=ForceReply(selective=True),
    )
    log_message(f"Commande /start re√ßue de {user.id}")

async def help_command(update: Update, context: ContextTypes.DEFAULT_TYPE) -> None:
    """Envoie un message lorsque la commande /help est √©mise."""
    help_text = """
    Voici ce que je peux faire :
    - Pose-moi n'importe quelle question factuelle.
    - Demande-moi d'√©crire ou d'am√©liorer du code (Python, Shell).
    - Cherche des informations sur le web (actualit√©s, m√©t√©o, g√©olocalisation IP, etc.).
    - Demande-moi de faire une capture d'√©cran d'un site web (donne l'URL).
    - Demande-moi d'analyser le contenu d'une page web (donne l'URL).
    - Demande-moi de d√©tecter la langue d'un texte.
    - Demande-moi de valider un num√©ro de t√©l√©phone ou de g√©olocaliser une IP.
    - G√®re tes rappels et alarmes (Ex: "Rappelle-moi d'acheter du lait √† 18h", "Mets une alarme √† 7h du matin").
    - V√©rifie le statut de mes APIs avec /status.
    - Affiche mon historique de conversation avec /history.
    - Affiche le statut des quotas API avec /quotas.
    - Affiche les APIs o√π il est opportun de "br√ªler" le quota avec /burn_quota.

    Exemples :
    - "Quelle est la capitale de la France ?"
    - "√âcris un script Python pour trier une liste."
    - "M√©t√©o √† Paris"
    - "Capture d'√©cran de https://google.com"
    - "Analyse de https://openai.com"
    - "D√©tecte la langue de 'Hello world'"
    - "Valide le num√©ro +33612345678"
    - "G√©olocalise l'IP 8.8.8.8"
    - "Rappelle-moi de faire les courses demain √† 10h"
    - "Mets une alarme pour 7h du matin"
    """
    await update.message.reply_text(help_text)
    log_message(f"Commande /help re√ßue de {update.effective_user.id}")

async def status_command(update: Update, context: ContextTypes.DEFAULT_TYPE) -> None:
    """Affiche le statut et les scores des IA."""
    status_message = "üìä **Statut des IA**:\n"
    now = get_current_time()
    for ia_name, status in memory_manager.ia_status.items():
        cooldown_until_str = status.get("cooldown_until")
        cooldown_status = "Pr√™te"
        if cooldown_until_str:
            cooldown_until = datetime.strptime(cooldown_until_str, "%Y-%m-%d %H:%M:%S UTC")
            if now < cooldown_until:
                remaining = cooldown_until - now
                cooldown_status = f"Cooldown ({remaining.seconds:.0f}s restantes)"
        
        last_used_str = status.get("last_used", "Jamais")
        if last_used_str != "Jamais":
            last_used_dt = datetime.strptime(last_used_str, "%Y-%m-%d %H:%M:%S UTC")
            time_since_last_used = (now - last_used_dt).total_seconds()
            if time_since_last_used < 60:
                last_used_display = f"{time_since_last_used:.0f}s ago"
            elif time_since_last_used < 3600:
                last_used_display = f"{time_since_last_used / 60:.0f}m ago"
            else:
                last_used_display = f"{time_since_last_used / 3600:.1f}h ago"
        else:
            last_used_display = "Jamais"

        status_message += (
            f"- **{ia_name}**: Score: `{status['current_score']:.2f}`, "
            f"Succ√®s: `{status['success_count']}`, Erreurs: `{status['error_count']}`, "
            f"Statut: `{cooldown_status}`, Derni√®re utilisation: `{last_used_display}`\n"
        )
    status_message += f"\nStrat√©gie actuelle: `{orchestrator.current_ia_strategy}`"
    await update.message.reply_markdown(status_message)
    log_message(f"Commande /status re√ßue de {update.effective_user.id}")

async def history_command(update: Update, context: ContextTypes.DEFAULT_TYPE) -> None:
    """Affiche les 10 derniers messages de l'historique."""
    history = memory_manager.get_chat_history()
    if not history:
        await update.message.reply_text("L'historique de conversation est vide.")
        return

    history_text = "üìú **Historique des 10 derni√®res interactions**:\n\n"
    for entry in history:
        history_text += f"**{entry['role'].capitalize()}** ({entry['timestamp']}):\n{entry['content'][:150]}...\n\n" # Limite la longueur
    await update.message.reply_markdown(history_text)
    log_message(f"Commande /history re√ßue de {update.effective_user.id}")

async def quotas_command(update: Update, context: ContextTypes.DEFAULT_TYPE) -> None:
    """Affiche le statut actuel des quotas API."""
    quotas_status = quota_manager.get_all_quotas_status()
    message = "üìà **Statut des Quotas API**:\n\n"
    for api_name, data in quotas_status.items():
        message += (
            f"**{api_name}**:\n"
            f"  - Mensuel: `{data['monthly_usage']}` / `{data['monthly_limit']}`\n"
            f"  - Journalier: `{data['daily_usage']}` / `{data['daily_limit']}`\n"
            f"  - Horaire: `{data['hourly_limit']}` (limite config)\n"
            f"  - Total appels: `{data['total_calls']}`\n"
            f"  - Derni√®re utilisation: `{data['last_usage'] if data['last_usage'] else 'N/A'}`\n"
            f"  - Reset Mensuel: `{data['last_reset_month']}`\n"
            f"  - Reset Journalier: `{data['last_reset_day']}`\n"
            f"  - Reset Horaire: `{data['last_hourly_reset']}`\n\n"
        )
    await update.message.reply_markdown(message)
    log_message(f"Commande /quotas re√ßue de {update.effective_user.id}")

async def burn_quota_command(update: Update, context: ContextTypes.DEFAULT_TYPE) -> None:
    """Affiche les APIs o√π il est opportun de "br√ªler" le quota."""
    burn_apis = quota_manager.get_burn_window_apis()
    if burn_apis:
        message = "üî• **APIs o√π il est opportun de 'br√ªler' le quota avant r√©initialisation**:\n\n"
        for api_info in burn_apis:
            message += f"- {api_info}\n"
        message += f"\nFen√™tre de br√ªlage: {QUOTA_BURN_WINDOW_HOURS} heures avant le reset."
    else:
        message = "üéâ Aucune API n'est actuellement dans une fen√™tre de 'br√ªlage' de quota. Tout est optimis√© !"
    await update.message.reply_markdown(message)
    log_message(f"Commande /burn_quota re√ßue de {update.effective_user.id}")


# --- Gestionnaire de messages (le c≈ìur du bot) ---

async def handle_message(update: Update, context: ContextTypes.DEFAULT_TYPE) -> None:
    """Traite les messages texte de l'utilisateur."""
    user_message = update.message.text
    user_id = update.effective_user.id
    log_message(f"Message re√ßu de {user_id}: {user_message}")

    # Ajouter le message de l'utilisateur √† l'historique
    memory_manager.add_message_to_history("user", user_message)

    # --- D√©tection des intentions sp√©cifiques (alarmes/rappels, code, OCR) ---
    response_text = ""

    # 1. D√©tection d'intentions pour les outils Clock/Reminders
    if any(keyword in user_message.lower() for keyword in ["alarme", "r√©veil", "timer", "minuteur", "rappelle-moi", "rappel", "reminder"]):
        log_message("Intention d√©tect√©e: Alarme/Rappel.")
        try:
            # Tente d'appeler l'outil Clock ou GenericReminders
            # Note: L'int√©gration directe des outils Clock/Reminders est complexe
            # et n√©cessiterait une logique de parsing NLP avanc√©e pour mapper
            # la requ√™te utilisateur aux arguments exacts des fonctions.
            # Pour l'instant, on va simuler un appel ou demander plus de d√©tails.

            # Exemple simplifi√© (non fonctionnel sans NLP avanc√© pour les args):
            # if "alarme" in user_message.lower() or "r√©veil" in user_message.lower():
            #     # Ici, il faudrait extraire le temps, la date, la r√©currence, etc.
            #     # Exemple: clock.create_alarm(time="07:00", label="r√©veil")
            #     response_text = "Je peux cr√©er des alarmes, mais il me faut plus de d√©tails. Par exemple: 'Mets une alarme √† 7h du matin'."
            # elif "timer" in user_message.lower() or "minuteur" in user_message.lower():
            #     # Exemple: clock.create_timer(duration="10m", label="cuisine")
            #     response_text = "Je peux g√©rer des minuteurs. Dis-moi la dur√©e, par exemple: 'Mets un minuteur de 10 minutes'."
            # elif "rappel" in user_message.lower() or "rappelle-moi" in user_message.lower() or "reminder" in user_message.lower():
            #     # Exemple: generic_reminders.create_reminder(title="acheter du lait", time_of_day="18:00:00")
            #     response_text = "Je peux cr√©er des rappels. Dis-moi ce que je dois te rappeler et quand. Par exemple: 'Rappelle-moi d'appeler Maman demain √† 14h'."
            
            # Pour cette version, on va juste informer l'utilisateur de la capacit√©
            response_text = "Je peux t'aider avec les alarmes, minuteurs et rappels ! Dis-moi par exemple : 'Mets une alarme √† 7h du matin' ou 'Rappelle-moi d'acheter du lait √† 18h'."

        except Exception as e:
            log_message(f"Erreur lors de l'appel de l'outil Clock/Reminders: {e}", level="error")
            response_text = f"D√©sol√©, j'ai eu un probl√®me avec les alarmes/rappels: {e}"

    # 2. D√©tection d'intention pour l'ex√©cution de code
    elif "```python" in user_message or "```shell" in user_message or "ex√©cute ce code" in user_message.lower() or "teste ce script" in user_message.lower():
        log_message("Intention d√©tect√©e: Ex√©cution de code.")
        lang_match = re.search(r"```(python|shell)\n(.*?)```", user_message, re.DOTALL)
        if lang_match:
            language = lang_match.group(1)
            code = lang_match.group(2)
            response_text = await run_in_sandbox(code, language)
        else:
            response_text = "Veuillez formater votre code avec des triple backticks et sp√©cifier le langage (ex: ```python\\nprint('Hello')``` ou ```shell\\nls -l```)."
    
    # 3. D√©tection d'intention pour l'analyse de code
    elif "analyse ce code python" in user_message.lower() or "v√©rifie ce script python" in user_message.lower():
        log_message("Intention d√©tect√©e: Analyse de code Python.")
        code_match = re.search(r"```python\n(.*?)```", user_message, re.DOTALL)
        if code_match:
            code = code_match.group(1)
            response_text = await analyze_python_code(code)
        else:
            response_text = "Veuillez fournir le code Python √† analyser format√© avec ```python\\n...```."

    # 4. D√©tection d'intention pour l'OCR
    elif "extraire texte image" in user_message.lower() or "ocr" in user_message.lower() or "lis cette image" in user_message.lower():
        log_message("Intention d√©tect√©e: OCR.")
        url_match = re.search(r'https?://[^\s]+(?:\.jpg|\.jpeg|\.png|\.gif|\.bmp|\.tiff)', user_message, re.IGNORECASE)
        if url_match:
            image_url = url_match.group(0)
            abstract_api_key_info = None
            for key_info in API_KEYS["ABSTRACTAPI"]:
                if key_info.get("type") == "OCR": # Supposons que tu as une cl√© AbstractAPI pour l'OCR
                    abstract_api_key_info = key_info
                    break
            
            if abstract_api_key_info:
                # Utilise le client AbstractAPI pour l'OCR si la cl√© est configur√©e
                # Note: AbstractAPI n'a pas d'API OCR directe dans la configuration fournie.
                # Ceci est un placeholder. Si tu as une vraie API OCR, remplace ceci.
                response_text = "D√©sol√©, je n'ai pas d'API OCR configur√©e directement pour le moment. " \
                                "Si vous avez une cl√© pour AbstractAPI OCR ou une autre API OCR, veuillez l'ajouter."
                # response_text = await perform_ocr(image_url, abstract_api_key_info["key"], abstract_api_key_info["endpoint"])
            else:
                response_text = "Je n'ai pas d'API OCR configur√©e. Veuillez ajouter une cl√© API OCR (ex: Cloudmersive OCR, ou une cl√© AbstractAPI pour OCR si disponible)."
        else:
            response_text = "Veuillez fournir une URL d'image valide (jpg, png, etc.) pour l'extraction de texte."

    # 5. Si aucune intention sp√©cifique, utiliser l'orchestrateur d'IA g√©n√©ral
    else:
        log_message("Intention g√©n√©rale, utilisation de l'orchestrateur d'IA.")
        # L'orchestrateur s√©lectionne la meilleure IA et obtient une r√©ponse
        response_from_ia = await orchestrator.process_query(user_message)
        
        # Si la r√©ponse vient d'une API sp√©cifique, on la retourne directement.
        # Sinon, on la synth√©tise si n√©cessaire (par exemple, si plusieurs sources sont consult√©es).
        # Pour l'instant, on suppose que process_query retourne d√©j√† la meilleure r√©ponse.
        response_text = response_from_ia

    # Nettoyer et corriger la r√©ponse avant de l'envoyer
    final_response = clean_html_tags(response_text)
    final_response = neutralize_urls(final_response)
    final_response = detect_and_correct_toxicity(final_response)

    await update.message.reply_text(final_response)
    memory_manager.add_message_to_history("assistant", final_response)
    log_message(f"R√©ponse envoy√©e √† {user_id}.")


# --- Fonction principale pour d√©marrer le bot ---

async def main() -> None:
    """D√©marre le bot."""
    log_message("D√©marrage du bot Telegram...")
    # Cr√©e l'Application et passe le token de ton bot.
    application = Application.builder().token(TELEGRAM_BOT_TOKEN).build()

    # Ajoute les gestionnaires de commandes
    application.add_handler(CommandHandler("start", start))
    application.add_handler(CommandHandler("help", help_command))
    application.add_handler(CommandHandler("status", status_command))
    application.add_handler(CommandHandler("history", history_command))
    application.add_handler(CommandHandler("quotas", quotas_command))
    application.add_handler(CommandHandler("burn_quota", burn_quota_command))


    # Ajoute le gestionnaire de messages (pour tous les messages texte)
    application.add_handler(MessageHandler(filters.TEXT & ~filters.COMMAND, handle_message))

    # D√©marre le bot
    log_message("Bot pr√™t √† recevoir des messages.")
    await application.run_polling(allowed_updates=Update.ALL_TYPES)

if __name__ == "__main__":
    # Ex√©cute la fonction main() de mani√®re asynchrone
    # Cela permet de lancer le bot et de g√©rer les t√¢ches asynchrones.
    try:
        asyncio.run(main())
    except Exception as e:
        log_message(f"Erreur fatale lors du d√©marrage du bot: {e}", level="error")
        print(f"Une erreur est survenue au d√©marrage du bot: {e}")

# --- FIN DU BLOC BOT TELEGRAM PRINCIPAL ---


#!/usr/bin/env python3
import os,sys,json,time,logging,asyncio,re,signal,traceback,httpx,gzip,random,gc,hashlib
from datetime import datetime,timezone,date
from functools import wraps
from pathlib import Path
from collections import OrderedDict
from apscheduler.schedulers.asyncio import AsyncIOScheduler
from telegram import Bot,Update
from telegram.constants import ParseMode
from telegram.ext import ApplicationBuilder,MessageHandler,filters,CommandHandler
try: import fitz
except: fitz=None
os.environ["TZ"]="UTC"
semaphore=asyncio.Semaphore(2)
UPDATE_URL="https://tonlien.com/levraibot.py"
LOCAL_SCRIPT_PATH=Path(__file__)
MAX_FILE_SIZE=510241024
BASE_DIR=Path("sauvegardes");BASE_DIR.mkdir(exist_ok=True)
ERROR_LOG_PATH=BASE_DIR/"erreurs.log"
DAILY_CHALLENGE_PATH=Path("defis_code");DAILY_CHALLENGE_PATH.mkdir(exist_ok=True)
BOT_TOKEN="7902342551:AAG6r1QA2GTMXcmcsWHi36Ivd_PVeMXULOs"
PRIVATE_GROUP_ID=-1002845235344
GOOGLE_API_KEYS=["AIzaSyAk6Ph25xuIY3b5o-JgdL652MvK4usp8Ms","AIzaSyDuccmfiPSk4042NeJCYIjA8EOXPo1YKXU","AIzaSyAQq6o9voefaDxkAEORf7W-IB3QbotIkwY","AIzaSyDYaYrQQ7cwYFm8TBpyGM3dJweOGOYl7qw"]
GOOGLE_CX_LIST=["3368510e864b74936","e745c9ca0ffb94659"]
OCR_API_KEYS=["K82679097388957","K81079143888957","K84281517488957"]
TAVILY_KEYS=["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","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","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","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"]
HUGGINGFACE_KEYS=["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","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","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"]
OPENROUTER_KEYS=["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","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","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"]
WOLFRAM_APP_IDS=["96LX77-G8PGKJ3T7V","96LX77-PYHRRET363","96LX77-P9HPAYWRGL"]
SERPER_KEYS=["047b30db1df999aaa9c293f2048037d40c651439"]
OPENWEATHER_API_KEYS=["c80075b7332716a418e47033463085ef"]
RAPIDAPI_KEYS=["d4d1f58d8emsh58d888c711b7400p1bcebejsn2cc04dce6efe"]
DAILY_LIMIT=150;MONTHLY_LIMIT=3000
prompt_cache=OrderedDict();MAX_CACHE_SIZE=1500;AUTHORIZED_TO_LEARN=True
bot_instance=Bot(BOT_TOKEN)
api_response_cache=OrderedDict();api_global_lock={};API_CACHE_EXPIRATION=600
def H(t):return hashlib.sha256(t.encode()).hexdigest()
def K(n,p):return f"{n}:{H(p)}"
def G(n,p):v=api_response_cache.get(K(n,p));return v["r"] if v and time.time()-v["t"]<API_CACHE_EXPIRATION else None
def S(n,p,r):api_response_cache[K(n,p)]={"r":r,"t":time.time()};len(api_response_cache)>MAX_CACHE_SIZE and api_response_cache.popitem(last=False)
async def C(f,n,p,*a,**k):k_=K(n,p);api_global_lock.setdefault(k_,asyncio.Lock());async with api_global_lock[k_]:c=G(n,p);return c if c is not None else (lambda r:S(n,p,r),r)[1] if (r:=await f(p,*a,**k)) else None
def NU(x):return re.sub(r"https?://",lambda m:m.group(0).replace("t","x",1),re.sub(r"\.org","[.]org",re.sub(r"\.net","[.]net",re.sub(r"\.com","[.]com",re.sub(r"www\.","wxx.",x)))))
def RL(p):p.exists() and p.stat().st_size>MAX_FILE_SIZE and p.replace(p.with_suffix(f".old_{int(time.time())}.json"))
def LG():RL(ERROR_LOG_PATH);logging.basicConfig(level=logging.INFO,format="%(asctime)s [%(levelname)s] %(message)s",datefmt="%Y-%m-%d %H:%M:%S");el=logging.getLogger("erreurs_api");eh=logging.FileHandler(ERROR_LOG_PATH,encoding="utf-8");eh.setFormatter(logging.Formatter("%(asctime)s [%(levelname)s] %(message)s",datefmt="%Y-%m-%d %H:%M:%S"));el.addHandler(eh);el.setLevel(logging.ERROR);return el
error_logger=LG()
signal.signal(signal.SIGINT,lambda s,f:(logging.info("Arr√™t demand√©, fermeture propre..."),sys.exit(0)))
def LE(m):RL(ERROR_LOG_PATH);error_logger.error(m);asyncio.create_task(bot_instance.send_message(chat_id=PRIVATE_GROUP_ID,text=f"‚ö†Ô∏è ERREUR CRITIQUE :\n{m}"))
def SJA(p,d):RL(p);tp=p.with_suffix(".tmp");p.exists() and p.replace(p.with_suffix(p.suffix+".fullbackup"));json.dump(d,tp.open("w",encoding="utf-8"),indent=2,ensure_ascii=False);tp.replace(p)
def SLJ(p,d): 
 try:return json.load(open(p,"r",encoding="utf-8")) if p.exists() else d
 except: 
  try:p.unlink()
  except:pass
  return d
def CL(p): 
 try:
  if p.exists() and p.stat().st_size>1e6:
   import shutil
   gz=p.with_suffix(p.suffix+".gz")
   with open(p,"rb") as f_in,gzip.open(gz,"wb") as f_out:shutil.copyfileobj(f_in,f_out)
   p.unlink();gz.rename(p)
 except Exception as e:LE(f"[Compression auto] {e}\n{traceback.format_exc()}")
quotas_path=BASE_DIR/"quotas.json"
def LQ():q=SLJ(quotas_path,{"daily":0,"monthly":0,"last_reset":datetime.now().isoformat(),"tavily_idx":0});q.setdefault("daily",0);q.setdefault("monthly",0);q.setdefault("last_reset",datetime.now().isoformat());q.setdefault("tavily_idx",0);return q
quotas=LQ()
def SQ():SJA(quotas_path,quotas)
def RQ():n=datetime.now();last=datetime.fromisoformat(quotas.get("last_reset",n.isoformat())) if quotas.get("last_reset") else n;c=False;if (n-last).days>=1:quotas["daily"]=0;c=True;if n.month!=last.month:quotas["monthly"]=0;if c:quotas["last_reset"]=n.isoformat();SQ()
def IQ(b=1):quotas["daily"]+=b;quotas["monthly"]+=b;SQ()
def CQ():return quotas["daily"]<DAILY_LIMIT and quotas["monthly"]<MONTHLY_LIMIT
def AQ(b=None): 
 if quotas["daily"]>=DAILY_LIMIT:LE("üö® Quota journalier IA atteint !");b and asyncio.create_task(b.send_message(chat_id=PRIVATE_GROUP_ID,text="üö® Quota journalier IA atteint !"))
 if quotas["monthly"]>=MONTHLY_LIMIT:LE("üö® Quota mensuel IA atteint !");b and asyncio.create_task(b.send_message(chat_id=PRIVATE_GROUP_ID,text="üö® Quota mensuel IA atteint !"))
def STK():idx=quotas.get("tavily_idx",0);key=TAVILY_KEYS[idx%len(TAVILY_KEYS)];quotas["tavily_idx"]=(idx+1)%len(TAVILY_KEYS);SQ();return key
def GUD(u):p=BASE_DIR/str(u);p.mkdir(exist_ok=True);return p
def SJ(u,f,d):SJA(GUD(u)/f,d)
def EK(t):w=re.findall(r"\b[a-zA-Z√©√®√™√¥√†√π√ß√Æ√Ø≈ì]{4,}\b",t.lower());f={};[f.setdefault(x,0) or f.update({x:f[x]+1}) for x in w];return ", ".join(x for x,_ in sorted(f.items(),key=lambda x:x[1],reverse=True)[:5])
def TC(t):return "#tags : "+EK(t)
def AL(u,r,t,m=100):t=NU(t);u!=PRIVATE_GROUP_ID and SJ(u,"log.json",SLJ(GUD(u)/"log.json",[])+[{"time":datetime.now().isoformat(),"role":r,"text":t[:500],"tags":TC(t)}][-m:])
def ACH(u,r,t):t=NU(t);u!=PRIVATE_GROUP_ID and SJ(u,"chat_history.json",SLJ(GUD(u)/"chat_history.json",[])+[{"time":datetime.now().isoformat(),"role":r,"text":t}][-1000:])
def SGM(g,r,t,m=1000):SJ(g,"group_chat_history.json",SLJ(GUD(g)/"group_chat_history.json",[])+[{"time":datetime.now().isoformat(),"role":r,"text":t}][-m:])
def UPO(s):z=set();r=[];[r.append(x) for x in s if x not in z and not z.add(x)];return r
def ALM(u,t):SJ(u,"long_memory.json",UPO(SLJ(GUD(u)/"long_memory.json",[]) if isinstance(SLJ(GUD(u)/"long_memory.json",[]),list) else [])+[t.strip()])[-100:]
def GLM(u):return "\n".join(SLJ(GUD(u)/"long_memory.json",[])[-20:])
def GRM(u,l=5):return "\n".join(f"{x['role']} : {x['text']}" for x in SLJ(GUD(u)/"log.json",[])[-l:] if x.get("role")!="bot")
def NPM(p):return re.sub(r"\s+"," ",p.strip().replace("‚Ä¶","...").strip("¬´¬ª'\""))
def SRI(t):s=100;if "je ne sais pas" in t.lower():s-=30;if "d√©sol√©" in t.lower():s-=20;if len(t)<50:s-=30;if len(t)>1500:s-=10;if t.count("...")>3:s-=10;return max(0,min(100,s))
def ISR(t):return (not t or len(t.strip())<10 or t.lower().strip() in ["...","aucune id√©e","je ne sais pas"])
def SRV2(t,q=""):tc=t.lower();ql=len(q);rl=len(tc);e=["je ne peux pas","je suis d√©sol√©","impossible","je ne sais pas","je ne suis pas capable","en tant que mod√®le","je n'ai pas acc√®s","je ne suis pas en mesure","i'm sorry"];found=sum(tc.count(x) for x in e);p=["solution","r√©ponse","voici","peut","possible","certainement"];return False if any(x in tc for x in p) else rl<15 or found>1 or (ql>100 and rl<ql/4)
BROKEN_IA={}
def IAB(m):i=BROKEN_IA.get(m,{"fail_count":0,"last_fail":0});return i["fail_count"]>=3 and (time.time()-i["last_fail"]<600)
def MIF(m):i=BROKEN_IA.get(m,{"fail_count":0,"last_fail":0});i["fail_count"]+=1;i["last_fail"]=time.time();BROKEN_IA[m]=i
def MIS(m):m in BROKEN_IA and BROKEN_IA.pop(m)
async def with_timeout(func,*args,timeout=25): 
 try:return await asyncio.wait_for(func(*args),timeout)
 except asyncio.TimeoutError:LE(f"[Timeout] {func.__name__} >{timeout}s.");return None
async def retry_async(func,*args,retries=3,delay=2,**kwargs):
 for attempt in range(retries):
  try:return await func(*args,**kwargs)
  except:await asyncio.sleep(delay*(2**attempt)+random.uniform(0,1))
def get_any_key(keys):return random.choice(keys)
async def call_ia_gratuite(prompt): 
 prompt=NPM(prompt)
 models=["openai/gpt-4o-mini","mistralai/mistral-7b-instruct","mistralai/mixtral-8x7b-instruct"]
 async def single_model_call(m):
  async with httpx.AsyncClient(timeout=30) as c:
   try:
    r=await c.post("https://openrouter.ai/api/v1/chat/completions",headers={"Authorization":f"Bearer {get_any_key(OPENROUTER_KEYS)}","Content-Type":"application/json"},json={"model":m,"messages":[{"role":"user","content":prompt}],"max_tokens":600,"temperature":0.7})
    if r.status_code==200:
     j=r.json();cont=j.get("choices",[{}])[0].get("message",{}).get("content","")
     if cont and not SRV2(cont,prompt):return NU(cont)
     elif SRV2(cont,prompt):MIF(m);return None
   except Exception as e:MIF(m);LE(f"[OpenRouter] {m} erreur : {e}\n{traceback.format_exc()}");return None
 async def safe_model_call(m):
  async with semaphore:
   if IAB(m):return None
   try:result=await with_timeout(single_model_call,m);return result if result else None
   except Exception:MIF(m);return None
 tasks=[safe_model_call(m) for m in models]
 for fut in asyncio.as_completed(tasks):
  r=await fut
  if r:return r
 return "‚ùå Toutes les IA gratuites ont √©chou√© (r√©seau ou quota ?)."
async def fallback_api_calls(prompt):
 apis=[CGC,CW,CTA,CHF]
 for api in apis:
  res=await api(prompt)
  if res and "pas de" not in res.lower():return res
 return None
async def deliberation_interne(prompt):
 r=[await call_ia_gratuite(prompt)]
 filtres=[x for x in r if x and not SRV2(x,prompt)]
 if not filtres:return "‚ùå Toutes les IA ont √©chou√© √† r√©pondre correctement."
 debat="\n".join(f"R√©ponse {i+1} : {txt}" for i,txt in enumerate(filtres))
 juge_prompt=f"""Tu es une IA experte. Voici les r√©ponses propos√©es √† une m√™me question par d'autres IA :
{debat}
Analyse et synth√©tise la meilleure r√©ponse √† fournir √† l'utilisateur. Corrige si besoin, garde seulement les faits utiles. Ignore les excuses ou formulations inutiles."""
 s=await call_ia_gratuite(juge_prompt)
 return NU(s) or "‚ö†Ô∏è D√©lib√©ration impossible."
def get_recent_messages(uid,limit=5):return "\n".join(f"{l['role']} : {l['text']}" for l in SLJ(GUD(uid)/"log.json",[])[-limit:] if l.get("role")!="bot")
async def envoyer_texte_long_dans_groupe(txt):chunk_size=1998;[await bot_instance.send_message(chat_id=PRIVATE_GROUP_ID,text=NU(txt[i:i+chunk_size])) for i in range(0,len(txt),chunk_size)]
async def envoyer_fichier_dans_groupe(fichier:Path):
 try:async with fichier.open("rb") as f:await bot_instance.send_document(chat_id=PRIVATE_GROUP_ID,document=f,filename=fichier.name)
 except Exception as e:LE(f"Erreur envoi fichier dans groupe : {e}\n{traceback.format_exc()}")
def get_daily_python_challenge():
 today=date.today().isoformat();fp=DAILY_CHALLENGE_PATH/f"{today}_defi.py"
 if fp.exists():return fp.read_text(encoding="utf-8")
 ct="""üéØ D√©fi IA du {today}
üß© Objectif : Lire un fichier texte 'exemple.txt', remplacer 'chat' par 'chien', sauvegarder le nouveau texte dans 'resultat.txt'.
def remplacer_mot():
    with open("exemple.txt", "r", encoding="utf-8") as f:
        contenu = f.read()
    contenu = contenu.replace("chat", "chien")
    with open("resultat.txt", "w", encoding="utf-8") as f:
        f.write(contenu)
remplacer_mot()"""
 fp.write_text(ct,encoding="utf-8");return ct
async def defi_coding_force():
 defi=get_daily_python_challenge()
 if defi:await envoyer_texte_long_dans_groupe("‚öôÔ∏è <b>D√©fi IA forc√© (toutes les 45 min)</b> :\n"+defi)
async def process_prompt(update,prompt,is_group=False):
 response=await call_ia_gratuite(prompt)
 if not response or "pas de" in response.lower():
  api_response=await fallback_api_calls(prompt)
  if api_response:
   resume=await call_ia_gratuite("R√©sume cette r√©ponse :\n"+api_response)
   response=resume or api_response
   chemin=BASE_DIR/f"web_learning_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json"
   SJA(chemin,{"question":prompt,"r√©sultat_api":api_response,"r√©sum√©":response})
   await envoyer_fichier_dans_groupe(chemin)
   await envoyer_texte_long_dans_groupe(f"üåê [API] R√©ponse externe pour: {prompt}\n{response}")
 if is_group:await bot_instance.send_message(chat_id=PRIVATE_GROUP_ID,text=response)
 else:await update.message.reply_text(response)
async def handle_message(update,context):
 try:
  user_msg=update.message.text.strip()
  await envoyer_texte_long_dans_groupe(f"üìù [handle_message] Message utilisateur re√ßu int√©gralement :\n{user_msg}")
  if "je vous autorise" in user_msg.lower() or "tu peux utiliser" in user_msg.lower():
   global AUTHORIZED_TO_LEARN
   AUTHORIZED_TO_LEARN=True
   await update.message.reply_text("‚úÖ Autorisation enregistr√©e. J'utiliserai les APIs et j'enverrai mes trouvailles dans le groupe.")
   return
  if user_msg.strip().lower()=="stats ia":
   s=SLJ(BASE_DIR/"stats.json",{});moyenne="inconnue"
   if s.get("durations"):moyenne=round(sum(s["durations"])/len(s["durations"]),2)
   await update.message.reply_text(f"üìä Appels IA : {s.get('calls',0)}\n‚è±Ô∏è Moyenne r√©ponse : {moyenne}s\nDernier appel : {s.get('last','inconnu')}")
   return
  if not CQ():await update.message.reply_text("üö® Quota IA atteint pour aujourd'hui, r√©essaie demain.");return
  recent=get_recent_messages(update.effective_user.id)
  prompt=NPM(user_msg)
  if prompt in prompt_cache:response=prompt_cache[prompt]
  else:
   response=await call_ia_gratuite(prompt)
   if ISR(response) and AUTHORIZED_TO_LEARN:
    webresult=await CGC(prompt)
    if "Pas de r√©ponse Google" in webresult or "aucune information" in webresult.lower():response="‚ö†Ô∏è Aucune information pertinente trouv√©e sur Google."
    else:
     resume=await call_ia_gratuite("R√©sume cette r√©ponse Google :\n"+webresult)
     response=resume or "‚ö†Ô∏è R√©sum√© introuvable."
     await envoyer_texte_long_dans_groupe(f"üåê [Google API] Contenu brut r√©cup√©r√© :\n{webresult}")
     chemin=BASE_DIR/f"web_learning_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json"
     SJA(chemin,{"question":prompt,"r√©sultat_google":webresult,"r√©sum√©":response})
     await envoyer_fichier_dans_groupe(chemin)
    ALM(update.effective_user.id,response)
    prompt_cache[prompt]=response
   if len(prompt_cache)>MAX_CACHE_SIZE:prompt_cache.popitem(last=False)
  IQ()
  AL(update.effective_user.id,"user",user_msg)
  AL(update.effective_user.id,"bot",response)
  ACH(update.effective_user.id,"user",user_msg)
  ACH(update.effective_user.id,"bot",response)
  confiance=SRI(response)
  AL(update.effective_user.id,"score",f"{confiance}/100")
  if ISR(response):
   correction=await call_ia_gratuite("Ta r√©ponse pr√©c√©dente √©tait vide ou inutile. Corrige-la :\n"+prompt)
   if correction and len(correction)>10:response=correction
  await envoyer_texte_long_dans_groupe(f"ü§ñ [R√©ponse IA] :\n{response}")
  await update.message.reply_text(NU(response))
 except Exception as e:LE(f"Erreur dans handle_message : {e}\n{traceback.format_exc()}")
async def handle_group_message(update,context):
 try:
  msg=update.message.text.strip()
  await envoyer_texte_long_dans_groupe(f"üìù [handle_group_message] Message de groupe re√ßu int√©gralement :\n{msg}")
  if update.effective_chat.id!=PRIVATE_GROUP_ID:return
  if not msg or not CQ():return
  prompt=NPM(msg)
  if prompt in prompt_cache:response=prompt_cache[prompt]
  else:
   response=await deliberation_interne(prompt)
   if ISR(response) and AUTHORIZED_TO_LEARN:
    webresult=await CGC(prompt)
    if "Pas de r√©ponse Google" in webresult or "aucune information" in webresult.lower():response="‚ö†Ô∏è Aucune information pertinente trouv√©e sur Google."
    else:
     resume=await call_ia_gratuite("R√©sume cette r√©ponse Google :\n"+webresult)
     response=resume or "‚ö†Ô∏è R√©sum√© introuvable."
     await envoyer_texte_long_dans_groupe(f"üåê [Google API] Contenu brut r√©cup√©r√© :\n{webresult}")
     chemin=BASE_DIR/f"web_learning_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json"
     SJA(chemin,{"question":prompt,"r√©sultat_google":webresult,"r√©sum√©":response})
     await envoyer_fichier_dans_groupe(chemin)
    ALM(update.effective_user.id,response)
   prompt_cache[prompt]=response
   if len(prompt_cache)>MAX_CACHE_SIZE:prompt_cache.popitem(last=False)
  IQ()
  AL(PRIVATE_GROUP_ID,"user",msg)
  AL(PRIVATE_GROUP_ID,"bot",response)
  ACH(update.effective_user.id,"user",msg)
  ACH(update.effective_user.id,"bot",response)
  SGM(PRIVATE_GROUP_ID,"user",msg)
  SGM(PRIVATE_GROUP_ID,"bot",response)
  confiance=SRI(response)
  AL(PRIVATE_GROUP_ID,"score",f"{confiance}/100")
  if ISR(response):
   correction=await call_ia_gratuite("Ta r√©ponse pr√©c√©dente √©tait vide ou inutile. Corrige-la :\n"+prompt)
   if correction and len(correction)>10:response=correction
  await envoyer_texte_long_dans_groupe(f"ü§ñ [R√©ponse IA] :\n{response}")
  await update.message.reply_text(NU(response))
 except Exception as e:LE(f"Erreur dans handle_group_message : {e}\n{traceback.format_exc()}")
async def cmd_quota(update,context):
 await quota_ia()
 stats_file=BASE_DIR/"stats.json";stats=SLJ(stats_file,{}) if stats_file.exists() else {}
 calls=stats.get("calls",0)
 durations=stats.get("durations",[])
 avg_duration=round(sum(durations)/len(durations),2) if durations else "inconnue"
 last_call=stats.get("last","jamais")
 texte=(f"üìä Statistiques IA :\n‚Ä¢ Appels API : {calls}\n‚Ä¢ Dur√©e moyenne : {avg_duration}s\n‚Ä¢ Dernier appel : {last_call}\n")
 await update.message.reply_text(texte)
async def cmd_defi(update,context):await update.message.reply_text(get_daily_python_challenge())
async def cmd_update(update,context):
 await update.message.reply_text("üîÑ V√©rification et mise √† jour du script en cours...")
 try:
  await mise_a_jour_script()
  await update.message.reply_text("‚úÖ Mise √† jour termin√©e (voir logs).")
 except Exception as e:
  await update.message.reply_text(f"‚ùå Erreur mise √† jour : {e}")
def register_commands(app):
 app.add_handler(CommandHandler("quota",cmd_quota))
 app.add_handler(CommandHandler("defi",cmd_defi))
 app.add_handler(CommandHandler("update",cmd_update))
async def coding_challenge_task():
 while True:
  if not CQ():await asyncio.sleep(900);continue
  prompt=get_daily_python_challenge()
  await envoyer_texte_long_dans_groupe("‚öôÔ∏è <b>D√©fi IA forc√© (toutes les 45 min)</b> :\n"+prompt)
  await asyncio.sleep(2700)
async def start_background_tasks(app):asyncio.create_task(coding_challenge_task())
async def quota_ia():
 from datetime import datetime
 results=[]
 async def test_openrouter():
  messages=[]
  for i,key in enumerate(OPENROUTER_KEYS):
   try:
    async with httpx.AsyncClient(timeout=5) as c:
     r=await c.get("https://openrouter.ai/api/v1/models",headers={"Authorization":f"Bearer {key}"})
     if r.status_code==200:messages.append(f"‚úÖ OpenRouter key #{i+1}: OK")
     else:messages.append(f"‚ùå OpenRouter key #{i+1}: {r.status_code} {r.text[:100]}")
   except Exception as e:messages.append(f"‚ùå OpenRouter key #{i+1} erreur : {e}")
  return "\n".join(messages)
 async def test_tavily():
  messages=[]
  for i,key in enumerate(TAVILY_KEYS):
   try:
    async with httpx.AsyncClient(timeout=5) as c:
     r=await c.get("https://api.tavily.com/ping",headers={"Authorization":key})
     if r.status_code==200:messages.append(f"‚úÖ Tavily key #{i+1}: OK")
     else:messages.append(f"‚ùå Tavily key #{i+1}: {r.status_code} {r.text[:100]}")
   except Exception as e:messages.append(f"‚ùå Tavily key #{i+1} erreur : {e}")
  return "\n".join(messages)
 async def test_serper():
  messages=[]
  for i,key in enumerate(SERPER_KEYS):
   try:
    async with httpx.AsyncClient(timeout=5) as c:
     r=await c.get("https://serpapi.com/search",params={"q":"test","api_key":key,"engine":"google"})
     if r.status_code==200:messages.append(f"‚úÖ Serper key #{i+1}: OK")
     else:messages.append(f"‚ùå Serper key #{i+1}: {r.status_code} {r.text[:100]}")
   except Exception as e:messages.append(f"‚ùå Serper key #{i+1} erreur : {e}")
  return "\n".join(messages)
 async def test_hf():
  messages=[]
  for i,key in enumerate(HUGGINGFACE_KEYS):
   try:
    async with httpx.AsyncClient(timeout=5) as c:
     r=await c.get("https://api-inference.huggingface.co/models/gpt2",headers={"Authorization":f"Bearer {key}"})
     if r.status_code==200:messages.append(f"‚úÖ HuggingFace key #{i+1}: OK")
     else:messages.append(f"‚ùå HuggingFace key #{i+1}: {r.status_code} {r.text[:100]}")
   except Exception as e:messages.append(f"‚ùå HuggingFace key #{i+1} erreur : {e}")
  return "\n".join(messages)
 async def test_wolfram():
  messages=[]
  for i,key in enumerate(WOLFRAM_APP_IDS):
   try:
    async with httpx.AsyncClient(timeout=5) as c:
     r=await c.get("http://api.wolframalpha.com/v2/query",params={"input":"pi","appid":key})
     if r.status_code==200:messages.append(f"‚úÖ Wolfram key #{i+1}: OK")
     else:messages.append(f"‚ùå Wolfram key #{i+1}: {r.status_code} {r.text[:100]}")
   except Exception as e:messages.append(f"‚ùå Wolfram key #{i+1} erreur : {e}")
  return "\n".join(messages)
 async def test_google_apis():
  messages=[]
  for i,key in enumerate(GOOGLE_API_KEYS):
   for j,cx in enumerate(GOOGLE_CX_LIST):
    try:
     async with httpx.AsyncClient(timeout=5) as c:
      r=await c.get("https://www.googleapis.com/customsearch/v1",params={"q":"test","key":key,"cx":cx})
      if r.status_code==200:messages.append(f"‚úÖ Google Custom Search key #{i+1} CX #{j+1}: OK")
      else:messages.append(f"‚ùå Google Custom Search key #{i+1} CX #{j+1}: {r.status_code} {r.text[:100]}")
    except Exception as e:messages.append(f"‚ùå Google Custom Search key #{i+1} CX #{j+1} erreur : {e}")
  return "\n".join(messages)
 async def test_ocr():
  messages=[]
  for i,key in enumerate(OCR_API_KEYS):
   try:
    async with httpx.AsyncClient(timeout=5) as c:
     messages.append(f"üîé OCR key #{i+1}: (pas de ping, cl√© charg√©e)")
   except Exception as e:messages.append(f"‚ùå OCR key #{i+1} erreur : {e}")
  return "\n".join(messages)
 async def test_openweather():
  messages=[]
  for i,key in enumerate(OPENWEATHER_API_KEYS):
   try:
    async with httpx.AsyncClient(timeout=5) as c:
     r=await c.get("https://api.openweathermap.org/data/2.5/weather",params={"q":"Paris","appid":key})
     if r.status_code==200:messages.append(f"‚úÖ OpenWeather key #{i+1}: OK")
     else:messages.append(f"‚ùå OpenWeather key #{i+1}: {r.status_code} {r.text[:100]}")
   except Exception as e:messages.append(f"‚ùå OpenWeather key #{i+1} erreur : {e}")
  return "\n".join(messages)
 async def test_rapidapi():
  messages=[]
  for i,key in enumerate(RAPIDAPI_KEYS):
   try:
    async with httpx.AsyncClient(timeout=5) as c:
     messages.append(f"üîé RapidAPI key #{i+1}: (pas de ping, cl√© charg√©e)")
   except Exception as e:messages.append(f"‚ùå RapidAPI key #{i+1} erreur : {e}")
  return "\n".join(messages)
 results.append(await test_openrouter())
 results.append(await test_tavily())
 results.append(await test_serper())
 results.append(await test_hf())
 results.append(await test_wolfram())
 results.append(await test_google_apis())
 results.append(await test_ocr())
 results.append(await test_openweather())
 results.append(await test_rapidapi())
 status_message="üìä <b>√âtat et quota IA / API :</b>\n"+"\n\n".join(results)+f"\n\nDernier test : {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}"
 try:await bot_instance.send_message(chat_id=PRIVATE_GROUP_ID,text=status_message,parse_mode="HTML")
 except Exception as e:print(f"Erreur envoi message quota ia : {e}")
async def mise_a_jour_script():
 try:
  async with httpx.AsyncClient(timeout=20) as c:
   r=await c.get(UPDATE_URL)
   if r.status_code==200:
    nc=r.text
    ac=LOCAL_SCRIPT_PATH.read_text(encoding="utf-8")
    if H(nc)!=H(ac):
     b=LOCAL_SCRIPT_PATH.with_suffix(".backup.py")
     LOCAL_SCRIPT_PATH.rename(b)
     LOCAL_SCRIPT_PATH.write_text(nc,encoding="utf-8")
     logging.info("‚úÖ Script MAJ auto.")
     await bot_instance.send_message(chat_id=PRIVATE_GROUP_ID,text="üîÑ Script MAJ auto. Red√©marrage recommand√©.")
    else:logging.info("‚ÑπÔ∏è Script √† jour.")
 except Exception as e:LE(f"[AutoUpdate] MAJ auto : {e}")
async def main():
 try:import nest_asyncio;nest_asyncio.apply()
 except:pass
 await bot_instance.send_message(chat_id=PRIVATE_GROUP_ID,text="‚úÖ Bot red√©marr√© "+datetime.now().strftime("%H:%M:%S"))
 scheduler=AsyncIOScheduler(timezone=timezone.utc)
 if not scheduler.running:scheduler.start();scheduler.add_job(lambda: prompt_cache.clear() or api_response_cache.clear() or gc.collect(),'interval',hours=6);scheduler.add_job(mise_a_jour_script,'interval',hours=8);scheduler.add_job(defi_coding_force,'interval',minutes=45)
 app=ApplicationBuilder().token(BOT_TOKEN).build()
 register_commands(app)
 app.add_handler(MessageHandler(filters.TEXT&(~filters.Chat(PRIVATE_GROUP_ID)),handle_message))
 app.add_handler(MessageHandler(filters.Chat(PRIVATE_GROUP_ID)&filters.TEXT,handle_group_message))
 await start_background_tasks(app)
 await app.run_polling()
if __name__=="__main__":asyncio.run(main())



#!/usr/bin/env python3
import os, sys, json, time, logging, asyncio, re, signal, traceback, httpx, gzip, random, gc, hashlib
from datetime import datetime, timezone, date
from functools import wraps
from pathlib import Path
from collections import OrderedDict
from apscheduler.schedulers.asyncio import AsyncIOScheduler
from telegram import Bot, Update
from telegram.constants import ParseMode
from telegram.ext import ApplicationBuilder, MessageHandler, filters, CommandHandler, ContextTypes
try: import fitz
except: fitz = None

os.environ["TZ"] = "UTC"
semaphore = asyncio.Semaphore(2)
UPDATE_URL = "https://tonlien.com/levraibot.py"
LOCAL_SCRIPT_PATH = Path(__file__)
MAX_FILE_SIZE = 510241024
BASE_DIR = Path("sauvegardes"); BASE_DIR.mkdir(exist_ok=True)
ERROR_LOG_PATH = BASE_DIR / "erreurs.log"
DAILY_CHALLENGE_PATH = Path("defis_code"); DAILY_CHALLENGE_PATH.mkdir(exist_ok=True)

# ===================== CL√âS API EN DUR =====================
BOT_TOKEN = "7902342551:AAG6r1QA2GTMXcmcsWHi36Ivd_PVeMXULOs"
PRIVATE_GROUP_ID = -1002845235344  # <-- V√©rifi√©, bien entier, pas cha√Æne

GOOGLE_API_KEYS = [
    "AIzaSyAk6Ph25xuIY3b5o-JgdL652MvK4usp8Ms",
    "AIzaSyDuccmfiPSk4042NeJCYIjA8EOXPo1YKXU",
    "AIzaSyAQq6o9voefaDxkAEORf7W-IB3QbotIkwY",
    "AIzaSyDYaYrQQ7cwYFm8TBpyGM3dJweOGOYl7qw",
]
GOOGLE_CX_LIST = [
    "3368510e864b74936",
    "e745c9ca0ffb94659"
]

OCR_API_KEYS = [
    "K82679097388957",
    "K81079143888957",
    "K84281517488957",
]

TAVILY_KEYS = [
    "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",
    "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",
    "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",
    "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",
]

HUGGINGFACE_KEYS = [
    "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",
    "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",
    "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",
]

OPENROUTER_KEYS = [
    "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",
    "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",
    "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",
]

WOLFRAM_APP_IDS = [
    "96LX77-G8PGKJ3T7V",
    "96LX77-PYHRRET363",
    "96LX77-P9HPAYWRGL",
]

SERPER_KEYS = [
    "047b30db1df999aaa9c293f2048037d40c651439"
]

OPENWEATHER_API_KEYS = [
    "c80075b7332716a418e47033463085ef"
]

RAPIDAPI_KEYS = [
    "d4d1f58d8emsh58d888c711b7400p1bcebejsn2cc04dce6efe"
]

# Liste unique de toutes les cl√©s API (pour v√©rification/rotation globale si besoin)
ALL_API_KEYS = list(set(
    GOOGLE_API_KEYS
    + OCR_API_KEYS
    + TAVILY_KEYS
    + HUGGINGFACE_KEYS
    + OPENROUTER_KEYS
    + WOLFRAM_APP_IDS
    + SERPER_KEYS
    + OPENWEATHER_API_KEYS
    + RAPIDAPI_KEYS
))
# ===========================================================

DAILY_LIMIT = 150
MONTHLY_LIMIT = 3000
prompt_cache = OrderedDict()
MAX_CACHE_SIZE = 1500
AUTHORIZED_TO_LEARN = True

bot_instance = Bot(BOT_TOKEN)
api_response_cache = OrderedDict()
api_global_lock = {}
API_CACHE_EXPIRATION = 600

def H(t): return hashlib.sha256(t.encode()).hexdigest()
def K(n, p): return f"{n}:{H(p)}"
def G(n, p): v = api_response_cache.get(K(n, p)); return v["r"] if v and time.time() - v["t"] < API_CACHE_EXPIRATION else None
def S(n, p, r): api_response_cache[K(n, p)] = {"r": r, "t": time.time()}; len(api_response_cache) > MAX_CACHE_SIZE and api_response_cache.popitem(last=False)

async def C(f, n, p, *a, **k):
    k_ = K(n, p)
    if k_ not in api_global_lock:
        api_global_lock[k_] = asyncio.Lock()
    async with api_global_lock[k_]:
        c = G(n, p)
        if c is not None: return c
        r = await f(p, *a, **k)
        S(n, p, r)
        return r

def NU(x): return re.sub(r"https?://", lambda m: m.group(0).replace("t", "x", 1), re.sub(r"\.org", "[.]org", re.sub(r"\.net", "[.]net", re.sub(r"\.com", "[.]com", re.sub(r"www\.", "wxx.", x)))))
def RL(p): p.exists() and p.stat().st_size > MAX_FILE_SIZE and p.replace(p.with_suffix(f".old_{int(time.time())}.json"))
def LG():
    RL(ERROR_LOG_PATH)
    logging.basicConfig(level=logging.INFO, format="%(asctime)s [%(levelname)s] %(message)s", datefmt="%Y-%m-%d %H:%M:%S")
    el = logging.getLogger("erreurs_api")
    eh = logging.FileHandler(ERROR_LOG_PATH, encoding="utf-8")
    eh.setFormatter(logging.Formatter("%(asctime)s [%(levelname)s] %(message)s", datefmt="%Y-%m-%d %H:%M:%S"))
    el.addHandler(eh)
    el.setLevel(logging.ERROR)
    return el
error_logger = LG()
signal.signal(signal.SIGINT, lambda s, f: (logging.info("Arr√™t demand√©, fermeture propre..."), sys.exit(0)))
def LE(m): RL(ERROR_LOG_PATH); error_logger.error(m); asyncio.create_task(bot_instance.send_message(chat_id=PRIVATE_GROUP_ID, text=f"‚ö†Ô∏è ERREUR CRITIQUE :\n{m}"))

def SJA(p, d):
    RL(p)
    tp = p.with_suffix(".tmp")
    if p.exists():
        p.replace(p.with_suffix(p.suffix + ".fullbackup"))
    json.dump(d, tp.open("w", encoding="utf-8"), indent=2, ensure_ascii=False)
    tp.replace(p)
def SLJ(p, d):
    try:
        if not p.exists(): return d
        return json.load(open(p, "r", encoding="utf-8"))
    except Exception:
        try: p.unlink()
        except Exception: pass
        return d
def CL(p):
    try:
        if p.exists() and p.stat().st_size > 1e6:
            import shutil
            gz = p.with_suffix(p.suffix + ".gz")
            with open(p, "rb") as f_in, gzip.open(gz, "wb") as f_out:
                shutil.copyfileobj(f_in, f_out)
            p.unlink()
            gz.rename(p)
    except Exception as e:
        LE(f"[Compression auto] {e}\n{traceback.format_exc()}")

quotas_path = BASE_DIR / "quotas.json"
def LQ():
    q = SLJ(quotas_path, {"daily": 0, "monthly": 0, "last_reset": datetime.now().isoformat(), "tavily_idx": 0})
    q.setdefault("daily", 0)
    q.setdefault("monthly", 0)
    q.setdefault("last_reset", datetime.now().isoformat())
    q.setdefault("tavily_idx", 0)
    return q
quotas = LQ()
def SQ(): SJA(quotas_path, quotas)
def RQ():
    n = datetime.now()
    last = datetime.fromisoformat(quotas.get("last_reset", n.isoformat())) if quotas.get("last_reset") else n
    c = False
    if (n - last).days >= 1:
        quotas["daily"] = 0
        c = True
    if n.month != last.month:
        quotas["monthly"] = 0
    if c:
        quotas["last_reset"] = n.isoformat()
        SQ()
def IQ(b=1):
    quotas["daily"] += b
    quotas["monthly"] += b
    SQ()
def CQ():
    return quotas["daily"] < DAILY_LIMIT and quotas["monthly"] < MONTHLY_LIMIT
def AQ(b=None):
    if quotas["daily"] >= DAILY_LIMIT:
        LE("üö® Quota journalier IA atteint !")
        if b: asyncio.create_task(b.send_message(chat_id=PRIVATE_GROUP_ID, text="üö® Quota journalier IA atteint !"))
    if quotas["monthly"] >= MONTHLY_LIMIT:
        LE("üö® Quota mensuel IA atteint !")
        if b: asyncio.create_task(b.send_message(chat_id=PRIVATE_GROUP_ID, text="üö® Quota mensuel IA atteint !"))

def STK():
    idx = quotas.get("tavily_idx", 0)
    key = TAVILY_KEYS[idx % len(TAVILY_KEYS)]
    quotas["tavily_idx"] = (idx + 1) % len(TAVILY_KEYS)
    SQ()
    return key

def GUD(u): p = BASE_DIR / str(u); p.mkdir(exist_ok=True); return p
def SJ(u, f, d): SJA(GUD(u) / f, d)
def EK(t): w = re.findall(r"\b[a-zA-Z√©√®√™√¥√†√π√ß√Æ√Ø≈ì]{4,}\b", t.lower()); f = {}; [f.setdefault(x, 0) or f.update({x: f[x] + 1}) for x in w]; return ", ".join(x for x, _ in sorted(f.items(), key=lambda x: x[1], reverse=True)[:5])
def TC(t): return "#tags : " + EK(t)
def AL(u, r, t, m=100): t = NU(t); u != PRIVATE_GROUP_ID and SJ(u, "log.json", SLJ(GUD(u) / "log.json", []) + [{"time": datetime.now().isoformat(), "role": r, "text": t[:500], "tags": TC(t)}][-m:])
def ACH(u, r, t): t = NU(t); u != PRIVATE_GROUP_ID and SJ(u, "chat_history.json", SLJ(GUD(u) / "chat_history.json", []) + [{"time": datetime.now().isoformat(), "role": r, "text": t}][-1000:])
def SGM(g, r, t, m=1000): SJ(g, "group_chat_history.json", SLJ(GUD(g) / "group_chat_history.json", []) + [{"time": datetime.now().isoformat(), "role": r, "text": t}][-m:])
def UPO(s): z = set(); r = []; [r.append(x) for x in s if x not in z and not z.add(x)]; return r
def ALM(u, t): SJ(u, "long_memory.json", UPO(SLJ(GUD(u) / "long_memory.json", []) if isinstance(SLJ(GUD(u) / "long_memory.json", []), list) else []) + [t.strip()])[-100:]
def GLM(u): return "\n".join(SLJ(GUD(u) / "long_memory.json", [])[-20:])
def GRM(u, l=5): return "\n".join(f"{x['role']} : {x['text']}" for x in SLJ(GUD(u) / "log.json", [])[-l:] if x.get("role") != "bot")
def NPM(p): return re.sub(r"\s+", " ", p.strip().replace("‚Ä¶", "...").strip("¬´¬ª'\""))
def SRI(t): 
    s = 100
    if "je ne sais pas" in t.lower(): s -= 30
    if "d√©sol√©" in t.lower(): s -= 20
    if len(t) < 50: s -= 30
    if len(t) > 1500: s -= 10
    if t.count("...") > 3: s -= 10
    return max(0, min(100, s))
def ISR(t): return (not t or len(t.strip()) < 10 or t.lower().strip() in ["...", "aucune id√©e", "je ne sais pas"])
def SRV2(t, q=""):
    tc = t.lower(); ql = len(q); rl = len(tc)
    e = ["je ne peux pas", "je suis d√©sol√©", "impossible", "je ne sais pas", "je ne suis pas capable", "en tant que mod√®le", "je n'ai pas acc√®s", "je ne suis pas en mesure", "i'm sorry"]; found = sum(tc.count(x) for x in e)
    p = ["solution", "r√©ponse", "voici", "peut", "possible", "certainement"]
    return False if any(x in tc for x in p) else rl < 15 or found > 1 or (ql > 100 and rl < ql / 4)
BROKEN_IA = {}
def IAB(m): i = BROKEN_IA.get(m, {"fail_count": 0, "last_fail": 0}); return i["fail_count"] >= 3 and (time.time() - i["last_fail"] < 600)
def MIF(m): i = BROKEN_IA.get(m, {"fail_count": 0, "last_fail": 0}); i["fail_count"] += 1; i["last_fail"] = time.time(); BROKEN_IA[m] = i
def MIS(m): m in BROKEN_IA and BROKEN_IA.pop(m)
running_jobs = {}
def UJ(n):
    def d(f):
        async def w(*a, **k):
            if not running_jobs.get(n):
                running_jobs[n] = True
                await f(*a, **k)
                running_jobs.pop(n)
        return w
    return d
async def WT(f, *a, timeout=25):
    try: return await asyncio.wait_for(f(*a), timeout)
    except: LE(f"[Timeout] {f.__name__} >{timeout}s."); return None
async def RA(f, *a, retries=3, delay=2, **k):
    for i in range(retries):
        try: return await f(*a, **k)
        except: await asyncio.sleep(delay * (2 ** i) + random.uniform(0, 1))
def AC(f):
    @wraps(f)
    async def w(*a, **k):
        try: r = await f(*a, **k)
        except Exception as e: LE(f"API {f.__name__}:{e}\n{traceback.format_exc()}"); return f"Erreur API {f.__name__} : {e}"
        if not r: LE(f"[API] Vide {f.__name__}"); return "R√©ponse vide"
        return r
    return w

# ===================== Ajout gestion messages HM / HGM =====================
async def HM(update, context):
    print(f"[HM] Message re√ßu hors groupe : {update.message.text}")
    await update.message.reply_text("R√©ponse hors groupe OK")

async def HGM(update, context):
    print(f"[HGM] Message re√ßu dans groupe priv√© : {update.message.text}")
    await update.message.reply_text("R√©ponse groupe priv√© OK")

# ===================== Commandes Telegram =====================

# Commande /quota : affiche l‚Äô√©tat des quotas et appels API
async def cmd_quota(update, context):
    await quota_ia()
    stats_file = BASE_DIR / "stats.json"
    stats = {}
    if stats_file.exists():
        stats = SLJ(stats_file, {})
    calls = stats.get("calls", 0)
    durations = stats.get("durations", [])
    avg_duration = round(sum(durations) / len(durations), 2) if durations else "inconnue"
    last_call = stats.get("last", "jamais")
    texte = (
        f"üìä Statistiques IA :\n"
        f"‚Ä¢ Appels API : {calls}\n"
        f"‚Ä¢ Dur√©e moyenne : {avg_duration}s\n"
        f"‚Ä¢ Dernier appel : {last_call}\n"
    )
    await update.message.reply_text(texte)

# Commande /defi : affiche ou lance ton d√©fi IA automatique (exemple)
async def cmd_defi(update, context):
    texte = (
        "üéØ D√©fi IA du jour :\n"
        "üß© Lire un fichier 'exemple.txt', remplacer 'chat' par 'chien', "
        "et sauvegarder dans 'resultat.txt'.\n\n"
        "Code Python exemple :\n"
        "def remplacer_mot():\n"
        "    with open('exemple.txt', 'r', encoding='utf-8') as f:\n"
        "        contenu = f.read()\n"
        "    contenu = contenu.replace('chat', 'chien')\n"
        "    with open('resultat.txt', 'w', encoding='utf-8') as f:\n"
        "        f.write(contenu)\n"
        "remplacer_mot()"
    )
    await update.message.reply_text(texte)

# Commande /update : lance une mise √† jour automatique du script (exemple)
async def cmd_update(update, context):
    await update.message.reply_text("üîÑ V√©rification et mise √† jour du script en cours...")
    try:
        await mise_a_jour_script()
        await update.message.reply_text("‚úÖ Mise √† jour termin√©e (voir logs).")
    except Exception as e:
        await update.message.reply_text(f"‚ùå Erreur mise √† jour : {e}")

def register_commands(app):
    app.add_handler(CommandHandler("quota", cmd_quota))
    app.add_handler(CommandHandler("defi", cmd_defi))
    app.add_handler(CommandHandler("update", cmd_update))

# ===================== APPELS API AVEC CL√âS EN DUR =====================
def get_any_key(keys):
    # Renvoie une cl√© au hasard pour le service (rotation simple)
    return random.choice(keys)

async def CHF(p):
    url = "https://api-inference.huggingface.co/models/gpt2"
    h = {"Authorization": f"Bearer {get_any_key(HUGGINGFACE_KEYS)}"}
    pl = {"inputs": p, "options": {"wait_for_model": True}}
    async with httpx.AsyncClient(timeout=30) as c:
        r = await c.post(url, headers=h, json=pl)
        return r.json()[0]["generated_text"] if r.status_code == 200 and isinstance(r.json(), list) and "generated_text" in r.json()[0] else (str(r.json()) if r.status_code == 200 else None)

async def CW(q):
    url = "http://api.wolframalpha.com/v2/query"
    pa = {"appid": get_any_key(WOLFRAM_APP_IDS), "input": q, "output": "JSON"}
    async with httpx.AsyncClient(timeout=20) as c:
        r = await c.get(url, params=pa)
        d = r.json(); pods = d.get("queryresult", {}).get("pods", [])
        return next((x["subpods"][0].get("plaintext", "") for x in pods if x.get("title", "").lower() in ["result", "definition"]), None) if r.status_code == 200 else None

async def CGC(q):
    cx = GOOGLE_CX_LIST[0]
    url = "https://www.googleapis.com/customsearch/v1"
    pa = {"key": get_any_key(GOOGLE_API_KEYS), "cx": cx, "q": q, "num": 1}
    async with httpx.AsyncClient(timeout=20) as c:
        r = await c.get(url, params=pa)
        j = r.json(); i = j.get("items", [])
        return i[0].get("snippet", "Pas de contenu trouv√©.") if r.status_code == 200 and i else "Pas de r√©sultat trouv√© via Google Custom Search."

async def CTA(q):
    url = "https://api.tavily.com/v1/ask"
    h = {"Authorization": f"Bearer {get_any_key(TAVILY_KEYS)}"}
    pl = {"question": q}
    async with httpx.AsyncClient(timeout=20) as c:
        r = await c.post(url, headers=h, json=pl)
        return r.json().get("answer") or "Pas de r√©ponse de Tavily." if r.status_code == 200 else None

async def CO(image_url):
    url = "https://api.ocrservice.com/parse/image"
    h = {"apikey": get_any_key(OCR_API_KEYS)}
    pl = {"url": image_url}
    async with httpx.AsyncClient(timeout=20) as c:
        r = await c.post(url, headers=h, json=pl)
        return r.json().get("ParsedText", "Pas de texte d√©tect√©.") if r.status_code == 200 else None

async def COW(city):
    url = "https://api.openweathermap.org/data/2.5/weather"
    pa = {"q": city, "appid": get_any_key(OPENWEATHER_API_KEYS), "units": "metric", "lang": "fr"}
    async with httpx.AsyncClient(timeout=20) as c:
        r = await c.get(url, params=pa)
        d = r.json()
        return f"M√©t√©o √† {city} : {d['weather'][0]['description']}, {d['main']['temp']}¬∞C" if r.status_code == 200 else None

async def CRA(q):
    url = "https://example-rapidapi.p.rapidapi.com/endpoint"
    h = {"X-RapidAPI-Key": get_any_key(RAPIDAPI_KEYS), "X-RapidAPI-Host": "example-rapidapi.p.rapidapi.com"}
    pa = {"query": q}
    async with httpx.AsyncClient(timeout=20) as c:
        r = await c.get(url, headers=h, params=pa)
        return r.json().get("result", "Pas de r√©sultat.") if r.status_code == 200 else None

# Nouvelle fonction CIG multi-IA/cl√©
async def CIG(prompt, api_key=None, model_name=None):
    prompt = NPM(prompt)
    # OpenRouter
    if model_name == "OpenRouter" or (not model_name and not api_key):
        models = ["openai/gpt-4o-mini", "mistralai/mistral-7b-instruct", "mistralai/mixtral-8x7b-instruct"]
        async def SMC(m):
            async with httpx.AsyncClient(timeout=30) as c:
                try:
                    st = time.time()
                    r = await c.post("https://openrouter.ai/api/v1/chat/completions", headers={"Authorization": f"Bearer {get_any_key(OPENROUTER_KEYS)}", "Content-Type": "application/json"}, json={"model": m, "messages": [{"role": "user", "content": prompt}], "max_tokens": 600, "temperature": 0.7})
                    du = round(time.time() - st, 2)
                    if r.status_code == 200:
                        j = r.json(); cont = j.get("choices", [{}])[0].get("message", {}).get("content", "")
                        if cont and not SRV2(cont, prompt):
                            f = BASE_DIR / f"ia_reply_{datetime.now().strftime('%Y%m%d_%H%M%S')}.txt"
                            f.write_text(cont, encoding="utf-8")
                            return NU(cont)
                        elif SRV2(cont, prompt):
                            MIF(m)
                            return None
                    else:
                        LE(f"[OpenRouter] {m}: {r.status_code} ‚Üí {r.text}")
                except Exception as e:
                    LE(f"[OpenRouter] {m} erreur:{e}\n{traceback.format_exc()}")
                    MIF(m)
                    return None
        async def SFC(m):
            async with semaphore:
                if IAB(m): return None
                r = await WT(SMC, m)
                if r: MIS(m); return r
                return None
        ts = [SFC(m) for m in models]
        for f in asyncio.as_completed(ts):
            r = await f
            if r: return r
        return "‚ùå Toutes les IA gratuites ont √©chou√© (r√©seau ou quota ?)."

    # Tavily
    if model_name and model_name.startswith("Tavily"):
        url = "https://api.tavily.com/v1/ask"
        headers = {"Authorization": f"Bearer {api_key or get_any_key(TAVILY_KEYS)}"}
        payload = {"question": prompt}
        async with httpx.AsyncClient(timeout=20) as c:
            try:
                r = await c.post(url, headers=headers, json=payload)
                if r.status_code == 200:
                    rep = r.json().get("answer")
                    return rep if rep else "Pas de r√©ponse de Tavily."
                else:
                    return f"[Tavily] Erreur {r.status_code}: {r.text}"
            except Exception as e:
                return f"[Tavily] Exception: {e}"

    # Serper
    if model_name == "Serper":
        url = "https://serpapi.com/search"
        params = {"q": prompt, "api_key": api_key or get_any_key(SERPER_KEYS), "engine": "google"}
        async with httpx.AsyncClient(timeout=10) as c:
            try:
                r = await c.get(url, params=params)
                if r.status_code == 200:
                    j = r.json()
                    return j.get("organic_results", [{}])[0].get("snippet", "Pas de r√©sultat Serper.")
                return f"[Serper] Erreur {r.status_code}: {r.text}"
            except Exception as e:
                return f"[Serper] Exception: {e}"

    # HuggingFace
    if model_name == "HuggingFace":
        url = "https://api-inference.huggingface.co/models/gpt2"
        headers = {"Authorization": f"Bearer {api_key or get_any_key(HUGGINGFACE_KEYS)}"}
        payload = {"inputs": prompt, "options": {"wait_for_model": True}}
        async with httpx.AsyncClient(timeout=30) as c:
            try:
                r = await c.post(url, headers=headers, json=payload)
                if r.status_code == 200 and isinstance(r.json(), list) and "generated_text" in r.json()[0]:
                    return r.json()[0]["generated_text"]
                return f"[HF] Erreur {r.status_code}: {r.text}"
            except Exception as e:
                return f"[HF] Exception: {e}"

    # Wolfram
    if model_name == "Wolfram":
        url = "http://api.wolframalpha.com/v2/query"
        params = {"input": prompt, "appid": api_key or get_any_key(WOLFRAM_APP_IDS)}
        async with httpx.AsyncClient(timeout=20) as c:
            try:
                r = await c.get(url, params=params)
                if r.status_code == 200:
                    d = r.json(); pods = d.get("queryresult", {}).get("pods", [])
                    return next((x["subpods"][0].get("plaintext", "") for x in pods if x.get("title", "").lower() in ["result", "definition"]), None) or "Pas de r√©sultat Wolfram."
                return f"[Wolfram] Erreur {r.status_code}: {r.text}"
            except Exception as e:
                return f"[Wolfram] Exception: {e}"

    # Google API
    if model_name and model_name.startswith("GoogleCX"):
        idx = int(model_name.split("-")[1]) - 1
        cx = GOOGLE_CX_LIST[idx]
        url = "https://www.googleapis.com/customsearch/v1"
        params = {"q": prompt, "key": api_key or get_any_key(GOOGLE_API_KEYS), "cx": cx}
        async with httpx.AsyncClient(timeout=10) as c:
            try:
                r = await c.get(url, params=params)
                if r.status_code == 200:
                    j = r.json(); i = j.get("items", [])
                    return i[0].get("snippet", "Pas de r√©sultat Google CustomSearch.") if i else "Pas de r√©sultat Google."
                return f"[GoogleCX] Erreur {r.status_code}: {r.text}"
            except Exception as e:
                return f"[GoogleCX] Exception: {e}"

    return "‚ùå Aucune IA/cl√© valide pour ce CIG"

# -------------------------------------------------------------------------
# ----------------- CODING CHALLENGE TOUTES IA EN PARALL√àLE --------------
# -------------------------------------------------------------------------
CODING_CHALLENGE_ENABLED = True
LAST_CHALLENGE_FILE = DAILY_CHALLENGE_PATH / "last_challenge.py"
HISTORY_DIR = DAILY_CHALLENGE_PATH / "history"
HISTORY_DIR.mkdir(exist_ok=True)

def diff_text(old_text, new_text):
    import difflib
    diff = difflib.unified_diff(
        old_text.splitlines(), new_text.splitlines(), lineterm=""
    )
    return "\n".join(diff)

async def coding_challenge_task():
    while True:
        if not CODING_CHALLENGE_ENABLED:
            await asyncio.sleep(900)
            continue

        prompt = """
Tu es une IA experte en programmation Python. G√©n√®re un script clair, correct et optimis√©, 100% en fran√ßais.
Ne dis pas que tu ne sais pas, ne t'excuse pas, ne formule pas de r√©ponses vagues.
Chaque version doit √™tre une am√©lioration nette de la pr√©c√©dente.
Commence par un commentaire indiquant ce qui a √©t√© am√©lior√©.
Le code doit √™tre direct, lisible, et pr√™t √† √™tre utilis√©.
"""

        # Liste des IA / cl√©s √† utiliser
        ia_list = (
            [("OpenRouter", k) for k in OPENROUTER_KEYS] +
            [("Tavily", k) for k in TAVILY_KEYS] +
            [("Serper", k) for k in SERPER_KEYS] +
            [("HuggingFace", k) for k in HUGGINGFACE_KEYS] +
            [("Wolfram", k) for k in WOLFRAM_APP_IDS] +
            [("GoogleCX-1", k) for k in GOOGLE_API_KEYS] +
            [("GoogleCX-2", k) for k in GOOGLE_API_KEYS]
        )

        async def call_ia(nom, cle):
            try:
                r = await CIG(prompt, api_key=cle, model_name=nom)
                if r and len(r.strip()) > 20:
                    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
                    fpath = DAILY_CHALLENGE_PATH / f"challenge_{nom}_{timestamp}.py"
                    fpath.write_text(r, encoding="utf-8")
                    await bot_instance.send_message(
                        chat_id=PRIVATE_GROUP_ID,
                        text=f"üíª <b>Code g√©n√©r√© par {nom}</b> :\n<pre>{r[:600]}</pre>",
                        parse_mode="HTML"
                    )
                    return r
                else:
                    await bot_instance.send_message(
                        chat_id=PRIVATE_GROUP_ID,
                        text=f"‚ö†Ô∏è <b>{nom}</b> n'a pas g√©n√©r√© de code valable cette fois.",
                        parse_mode="HTML"
                    )
                    return None
            except Exception as e:
                await bot_instance.send_message(
                    chat_id=PRIVATE_GROUP_ID,
                    text=f"‚ùå <b>{nom}</b> erreur lors de l'appel IA : {e}",
                    parse_mode="HTML"
                )
                return None

        # Appels en parall√®le
        results = await asyncio.gather(*[call_ia(n, k) for n, k in ia_list])

        await asyncio.sleep(900)  # Pause 15 min

async def start_background_tasks(app):
    asyncio.create_task(coding_challenge_task())

# -------------------------------------------------------------------------
# ------------- COMMANDE /QUOTA POUR TOUTES LES IA (v√©rif statuts) --------
# -------------------------------------------------------------------------
async def quota_ia():
    from datetime import datetime
    results = []

    # Test OpenRouter
    async def test_openrouter():
        messages = []
        for i, key in enumerate(OPENROUTER_KEYS):
            try:
                async with httpx.AsyncClient(timeout=5) as c:
                    r = await c.get("https://openrouter.ai/api/v1/models", headers={"Authorization": f"Bearer {key}"})
                    if r.status_code == 200:
                        messages.append(f"‚úÖ OpenRouter key #{i+1}: OK")
                    else:
                        messages.append(f"‚ùå OpenRouter key #{i+1}: {r.status_code} {r.text[:100]}")
            except Exception as e:
                messages.append(f"‚ùå OpenRouter key #{i+1} erreur : {e}")
        return "\n".join(messages)

    # Test Tavily keys
    async def test_tavily():
        messages = []
        for i, key in enumerate(TAVILY_KEYS):
            try:
                async with httpx.AsyncClient(timeout=5) as c:
                    r = await c.get("https://api.tavily.com/ping", headers={"Authorization": key})
                    if r.status_code == 200:
                        messages.append(f"‚úÖ Tavily key #{i+1}: OK")
                    else:
                        messages.append(f"‚ùå Tavily key #{i+1}: {r.status_code} {r.text[:100]}")
            except Exception as e:
                messages.append(f"‚ùå Tavily key #{i+1} erreur : {e}")
        return "\n".join(messages)

    # Test Serper
    async def test_serper():
        messages = []
        for i, key in enumerate(SERPER_KEYS):
            try:
                async with httpx.AsyncClient(timeout=5) as c:
                    r = await c.get("https://serpapi.com/search", params={"q": "test", "api_key": key, "engine": "google"})
                    if r.status_code == 200:
                        messages.append(f"‚úÖ Serper key #{i+1}: OK")
                    else:
                        messages.append(f"‚ùå Serper key #{i+1}: {r.status_code} {r.text[:100]}")
            except Exception as e:
                messages.append(f"‚ùå Serper key #{i+1} erreur : {e}")
        return "\n".join(messages)

    # Test HuggingFace
    async def test_hf():
        messages = []
        for i, key in enumerate(HUGGINGFACE_KEYS):
            try:
                async with httpx.AsyncClient(timeout=5) as c:
                    r = await c.get("https://api-inference.huggingface.co/models/gpt2", headers={"Authorization": f"Bearer {key}"})
                    if r.status_code == 200:
                        messages.append(f"‚úÖ HuggingFace key #{i+1}: OK")
                    else:
                        messages.append(f"‚ùå HuggingFace key #{i+1}: {r.status_code} {r.text[:100]}")
            except Exception as e:
                messages.append(f"‚ùå HuggingFace key #{i+1} erreur : {e}")
        return "\n".join(messages)

    # Test Wolfram App IDs
    async def test_wolfram():
        messages = []
        for i, key in enumerate(WOLFRAM_APP_IDS):
            try:
                async with httpx.AsyncClient(timeout=5) as c:
                    r = await c.get("http://api.wolframalpha.com/v2/query", params={"input": "pi", "appid": key})
                    if r.status_code == 200:
                        messages.append(f"‚úÖ Wolfram key #{i+1}: OK")
                    else:
                        messages.append(f"‚ùå Wolfram key #{i+1}: {r.status_code} {r.text[:100]}")
            except Exception as e:
                messages.append(f"‚ùå Wolfram key #{i+1} erreur : {e}")
        return "\n".join(messages)

    # Tests Google API Keys (multiple)
    async def test_google_apis():
        messages = []
        for i, key in enumerate(GOOGLE_API_KEYS):
            for j, cx in enumerate(GOOGLE_CX_LIST):
                try:
                    async with httpx.AsyncClient(timeout=5) as c:
                        r = await c.get("https://www.googleapis.com/customsearch/v1",
                                       params={"q": "test", "key": key, "cx": cx})
                        if r.status_code == 200:
                            messages.append(f"‚úÖ Google Custom Search key #{i+1} CX #{j+1}: OK")
                        else:
                            messages.append(f"‚ùå Google Custom Search key #{i+1} CX #{j+1}: {r.status_code} {r.text[:100]}")
                except Exception as e:
                    messages.append(f"‚ùå Google Custom Search key #{i+1} CX #{j+1} erreur : {e}")
        return "\n".join(messages)

    # Test OCR
    async def test_ocr():
        messages = []
        for i, key in enumerate(OCR_API_KEYS):
            try:
                async with httpx.AsyncClient(timeout=5) as c:
                    # OCR.space ne fournit pas d'endpoint ping, on simule
                    messages.append(f"üîé OCR key #{i+1}: (pas de ping, cl√© charg√©e)")
            except Exception as e:
                messages.append(f"‚ùå OCR key #{i+1} erreur : {e}")
        return "\n".join(messages)

    # Test OpenWeather
    async def test_openweather():
        messages = []
        for i, key in enumerate(OPENWEATHER_API_KEYS):
            try:
                async with httpx.AsyncClient(timeout=5) as c:
                    r = await c.get("https://api.openweathermap.org/data/2.5/weather", params={"q": "Paris", "appid": key})
                    if r.status_code == 200:
                        messages.append(f"‚úÖ OpenWeather key #{i+1}: OK")
                    else:
                        messages.append(f"‚ùå OpenWeather key #{i+1}: {r.status_code} {r.text[:100]}")
            except Exception as e:
                messages.append(f"‚ùå OpenWeather key #{i+1} erreur : {e}")
        return "\n".join(messages)

    # Test RapidAPI
    async def test_rapidapi():
        messages = []
        for i, key in enumerate(RAPIDAPI_KEYS):
            try:
                async with httpx.AsyncClient(timeout=5) as c:
                    # RapidAPI ne fournit pas d'endpoint ping, on simule
                    messages.append(f"üîé RapidAPI key #{i+1}: (pas de ping, cl√© charg√©e)")
            except Exception as e:
                messages.append(f"‚ùå RapidAPI key #{i+1} erreur : {e}")
        return "\n".join(messages)

    results.append(await test_openrouter())
    results.append(await test_tavily())
    results.append(await test_serper())
    results.append(await test_hf())
    results.append(await test_wolfram())
    results.append(await test_google_apis())
    results.append(await test_ocr())
    results.append(await test_openweather())
    results.append(await test_rapidapi())

    status_message = "üìä <b>√âtat et quota IA / API :</b>\n" + "\n\n".join(results) + f"\n\nDernier test : {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}"
    try:
        await bot_instance.send_message(chat_id=PRIVATE_GROUP_ID, text=status_message, parse_mode="HTML")
    except Exception as e:
        print(f"Erreur envoi message quota ia : {e}")

# -------------------------------------------------------------------------
# -------------------------- FONCTIONS BOT PRINCIPALES --------------------
# -------------------------------------------------------------------------

async def MA():
    try: import nest_asyncio; nest_asyncio.apply()
    except: pass
    sm = "‚úÖ Bot red√©marr√© " + datetime.now().strftime("%H:%M:%S")
    await bot_instance.send_message(chat_id=PRIVATE_GROUP_ID, text=sm)
    if not AsyncIOScheduler(timezone=timezone.utc).running:
        scheduler = AsyncIOScheduler(timezone=timezone.utc); scheduler.start()
        scheduler.add_job(lambda: prompt_cache.clear() or api_response_cache.clear() or gc.collect(), 'interval', hours=6)
        scheduler.add_job(mise_a_jour_script, 'interval', hours=8)
        scheduler.add_job(lambda: None, 'interval', minutes=60) # Placeholders, tu peux remettre DCF et SIIA ici
    app = ApplicationBuilder().token(BOT_TOKEN).build()
    register_commands(app)
    app.add_handler(MessageHandler(filters.TEXT & (~filters.Chat(PRIVATE_GROUP_ID)), HM))
    app.add_handler(MessageHandler(filters.Chat(PRIVATE_GROUP_ID) & filters.TEXT, HGM))
    await start_background_tasks(app)
    print(f"Bot actif : Levraibootbot (ID {BOT_TOKEN.split(':')[0]})\nüîß Gestionnaire API optimis√© activ√©")
    await app.run_polling()

async def mise_a_jour_script():
    try:
        async with httpx.AsyncClient(timeout=20) as c:
            r = await c.get(UPDATE_URL)
            if r.status_code == 200:
                nc = r.text
                ac = LOCAL_SCRIPT_PATH.read_text(encoding="utf-8")
                if H(nc) != H(ac):
                    b = LOCAL_SCRIPT_PATH.with_suffix(".backup.py")
                    LOCAL_SCRIPT_PATH.rename(b)
                    LOCAL_SCRIPT_PATH.write_text(nc, encoding="utf-8")
                    logging.info("‚úÖ Script MAJ auto.")
                    await bot_instance.send_message(chat_id=PRIVATE_GROUP_ID, text="üîÑ Script MAJ auto. Red√©marrage recommand√©.")
                else:
                    logging.info("‚ÑπÔ∏è Script √† jour.")
    except Exception as e: LE(f"[AutoUpdate] MAJ auto : {e}")

if __name__ == "__main__":
    asyncio.run(MA())



#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Bot IA Multi-API/Dev ultra-fusionn√©, version Swiss Army Knife.

- Multiplexage intelligent sur toutes les IA/API (OpenRouter, Google, Serper, Tavily, Wolfram, Huggingface, etc.)
- Archivage exhaustif de tout ce qui est consult√© par tous les utilisateurs (pages, logs, conversations‚Ä¶)
- Gestion m√©moire locale avant toute sortie externe (anti-doublon, anti-r√©p√©tition)
- D√©fi codage toutes les 15min (toutes les IA participent, anti-doublon)
- Synth√®se crois√©e des r√©ponses IA (pas de concat brute)
- Outils dev Python accessibles via commandes et d√©clenchement auto (pyflakes, black, pygments, ast, exec, OCR, shell‚Ä¶)
- Aucune restriction d‚Äôutilisateur : tout le monde profite de tout
"""
import os, sys, json, time, logging, asyncio, re, signal, traceback, httpx, gzip, random, difflib, gc, hashlib, subprocess, ast, io
from datetime import datetime, timezone, date, timedelta
from functools import wraps
from pathlib import Path
from apscheduler.schedulers.asyncio import AsyncIOScheduler
from telegram import Bot, Update
from telegram.constants import ParseMode
from telegram.ext import ApplicationBuilder, MessageHandler, filters, CommandHandler, ContextTypes
from pygments import highlight
from pygments.lexers import PythonLexer
from pygments.formatters import TerminalFormatter
from pyflakes.api import check
from pyflakes.reporter import Reporter
import black
import pytesseract
from PIL import Image
try: import fitz
except: fitz = None

# ----------------------------
# CONFIGURATION & CONSTANTES
# ----------------------------
os.environ["TZ"] = "UTC"
BASE_DIR = Path("sauvegardes"); BASE_DIR.mkdir(exist_ok=True)
ERROR_LOG_PATH = BASE_DIR / "erreurs.log"
DAILY_CHALLENGE_PATH = Path("defis_code"); DAILY_CHALLENGE_PATH.mkdir(exist_ok=True)
HISTORY_DIR = DAILY_CHALLENGE_PATH / "history"; HISTORY_DIR.mkdir(exist_ok=True)
MAX_FILE_SIZE = 5*1024*1024
MAX_CACHE_SIZE = 1200
AUTHORIZED_TO_LEARN = True
DEBUG = True

# ==== TOKENS & KEYS ====
BOT_TOKEN = "7902342551:AAG6r1QA2GTMXcmcsWHi36Ivd_PVeMXULOs"
PRIVATE_GROUP_ID = -1002845235344 # utilis√© uniquement pour logs, pas pour restreindre
GOOGLE_API_KEYS = [
    "AIzaSyAk6Ph25xuIY3b5o-JgdL652MvK4usp8Ms",
    "AIzaSyDuccmfiPSk4042NeJCYIjA8EOXPo1YKXU",
    "AIzaSyAQq6o9voefaDxkAEORf7W-IB3QbotIkwY",
    "AIzaSyDYaYrQQ7cwYFm8TBpyGM3dJweOGOYl7qw",
]
GOOGLE_CX_LIST = ["3368510e864b74936", "e745c9ca0ffb94659"]
OCR_API_KEYS = ["K82679097388957", "K81079143888957", "K84281517488957"]
TAVILY_KEYS = [
    "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",
    "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",
    "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",
    "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",
]
HUGGINGFACE_KEYS = [
    "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",
    "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",
    "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",
]
OPENROUTER_KEYS = [
    "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",
    "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",
    "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",
]
WOLFRAM_APP_IDS = [
    "96LX77-G8PGKJ3T7V",
    "96LX77-PYHRRET363",
    "96LX77-P9HPAYWRGL",
]
SERPER_KEYS = ["047b30db1df999aaa9c293f2048037d40c651439"]
OPENWEATHER_API_KEYS = ["c80075b7332716a418e47033463085ef"]
RAPIDAPI_KEYS = ["d4d1f58d8emsh58d888c711b7400p1bcebejsn2cc04dce6efe"]

ALL_API_KEYS = list(set(
    GOOGLE_API_KEYS + OCR_API_KEYS + TAVILY_KEYS + HUGGINGFACE_KEYS + OPENROUTER_KEYS +
    WOLFRAM_APP_IDS + SERPER_KEYS + OPENWEATHER_API_KEYS + RAPIDAPI_KEYS
))

# ==== QUOTA LOGIQUE ====
DAILY_LIMIT = 150
MONTHLY_LIMIT = 3000

prompt_cache = {}
api_response_cache = {}
api_global_lock = {}
API_CACHE_EXPIRATION = 600

bot_instance = Bot(BOT_TOKEN)
semaphore = asyncio.Semaphore(4) # Limite 4 appels IA simultan√©s max

# ----------------------------
# LOGGING & SIGNALS
# ----------------------------
def rotate_log_if_needed(path: Path):
    if path.exists() and path.stat().st_size > MAX_FILE_SIZE:
        path.replace(path.with_suffix(f".old_{int(time.time())}.json"))

def setup_logging():
    rotate_log_if_needed(ERROR_LOG_PATH)
    logging.basicConfig(level=logging.INFO, format="%(asctime)s [%(levelname)s] %(message)s", datefmt="%Y-%m-%d %H:%M:%S")
    el = logging.getLogger("erreurs_api")
    eh = logging.FileHandler(ERROR_LOG_PATH, encoding="utf-8")
    eh.setFormatter(logging.Formatter("%(asctime)s [%(levelname)s] %(message)s", datefmt="%Y-%m-%d %H:%M:%S"))
    el.addHandler(eh)
    el.setLevel(logging.ERROR)
    return el
error_logger = setup_logging()
signal.signal(signal.SIGINT, lambda s, f: (logging.info("Arr√™t demand√©, fermeture propre..."), sys.exit(0)))

def log_api_error(message: str):
    rotate_log_if_needed(ERROR_LOG_PATH)
    error_logger.error(message)
    try:
        asyncio.create_task(bot_instance.send_message(chat_id=PRIVATE_GROUP_ID, text=f"‚ö†Ô∏è ERREUR CRITIQUE :\n{message}"))
    except: pass

# ----------------------------
# UTILS : JSON, LOGS, MEMOIRE
# ----------------------------
def hash_text(t: str) -> str:
    return hashlib.sha256(t.encode('utf-8')).hexdigest()

def save_json_atomic(path: Path, data):
    rotate_log_if_needed(path)
    tmp_path = path.with_suffix(".tmp")
    if path.exists():
        path.replace(path.with_suffix(path.suffix + ".fullbackup"))
    with tmp_path.open("w", encoding="utf-8") as f:
        json.dump(data, f, indent=2, ensure_ascii=False)
    tmp_path.replace(path)

def safe_load_json(path: Path, default):
    try:
        if not path.exists():
            return default
        with open(path, "r", encoding="utf-8") as f:
            return json.load(f)
    except Exception as e:
        log_api_error(f"[safe_load_json] Erreur de lecture : {e}")
        try: path.unlink()
        except: pass
        return default

def compress_if_large(path: Path):
    try:
        if path.exists() and path.stat().st_size > 1_000_000:
            import shutil
            gz_path = path.with_suffix(path.suffix + ".gz")
            with open(path, "rb") as f_in, gzip.open(gz_path, "wb") as f_out:
                shutil.copyfileobj(f_in, f_out)
            path.unlink(); gz_path.rename(path)
    except Exception as e:
        log_api_error(f"[Compression auto] Erreur : {e}\n{traceback.format_exc()}")

def neutraliser_urls(txt: str) -> str:
    txt = re.sub(r"https?://", lambda m: m.group(0).replace("t", "x", 1), txt)
    txt = re.sub(r"www\.", "wxx.", txt)
    txt = re.sub(r"\.com", "[.]com", txt)
    txt = re.sub(r"\.net", "[.]net", txt)
    txt = re.sub(r"\.org", "[.]org", txt)
    return txt

def extract_keywords(text: str) -> str:
    words = re.findall(r'\b[a-zA-Z√©√®√™√¥√†√π√ß√Æ√Ø≈ì]{4,}\b', text.lower())
    freq = {}
    for w in words: freq[w] = freq.get(w, 0) + 1
    keywords = sorted(freq.items(), key=lambda x: x[1], reverse=True)
    return ", ".join(w for w,_ in keywords[:5])

def tag_conversation(text: str):
    words = extract_keywords(text)
    return f"#tags : {words}"

def unique_preserve_order(seq):
    seen = set(); result = []
    for item in seq:
        if item not in seen:
            seen.add(item); result.append(item)
    return result

def get_user_dir(uid):
    p = BASE_DIR / str(uid); p.mkdir(exist_ok=True)
    return p

def save_json(uid, fname, data):
    save_json_atomic(get_user_dir(uid) / fname, data)

def append_log(uid, role, text, max_log=100):
    text = neutraliser_urls(text)
    path = get_user_dir(uid) / "log.json"
    logs = safe_load_json(path, [])
    logs.append({"time": datetime.now().isoformat(), "role": role, "text": text[:500]})
    logs = logs[-max_log:]
    if logs:
        last_text = logs[-1]["text"]
        tag = tag_conversation(last_text)
        logs[-1]["tags"] = tag
    save_json(uid, "log.json", logs)

def append_chat_history(uid, role, text):
    text = neutraliser_urls(text)
    path = get_user_dir(uid) / "chat_history.json"
    hist = safe_load_json(path, [])
    hist.append({"time": datetime.now().isoformat(), "role": role, "text": text})
    save_json(uid, "chat_history.json", hist[-1000:])

def save_group_memory(group_id: int, role: str, text: str, max_items=1000):
    path = get_user_dir(group_id) / "group_chat_history.json"
    hist = safe_load_json(path, [])
    hist.append({"time": datetime.now().isoformat(), "role": role, "text": text})
    save_json(group_id, "group_chat_history.json", hist[-max_items:])

def append_long_memory(uid, text):
    path = get_user_dir(uid) / "long_memory.json"
    logs = safe_load_json(path, [])
    logs = logs if isinstance(logs, list) else []
    logs.append(text.strip())
    logs = unique_preserve_order(logs)[-100:]
    save_json(uid, "long_memory.json", logs)

def get_long_memory(uid):
    return "\n".join(safe_load_json(get_user_dir(uid) / "long_memory.json", [])[-20:])

def get_recent_messages(uid, limit=5):
    logs = safe_load_json(get_user_dir(uid) / "log.json", [])
    return "\n".join(f"{l['role']} : {l['text']}" for l in logs[-limit:] if l.get("role") != "bot")

def load_chat_history(uid):
    path = get_user_dir(uid) / "chat_history.json"
    return safe_load_json(path, [])

# ----------------------------
# QUOTA SYSTEM
# ----------------------------
quotas_path = BASE_DIR / "quotas.json"
def load_quotas():
    q = safe_load_json(quotas_path, {"daily": 0, "monthly": 0, "last_reset": datetime.now().isoformat(), "tavily_idx": 0})
    q.setdefault("daily", 0)
    q.setdefault("monthly", 0)
    q.setdefault("last_reset", datetime.now().isoformat())
    q.setdefault("tavily_idx", 0)
    return q
quotas = load_quotas()
def save_quotas():
    save_json_atomic(quotas_path, quotas)
def reset_quotas_if_needed():
    now = datetime.now()
    try:
        last = datetime.fromisoformat(quotas.get("last_reset", now.isoformat()))
    except: last = now
    c = False
    if (now - last).days >= 1:
        quotas["daily"] = 0
        c = True
    if now.month != last.month:
        quotas["monthly"] = 0
    if c:
        quotas["last_reset"] = now.isoformat()
        save_quotas()
def increment_quota(by=1):
    quotas["daily"] += by
    quotas["monthly"] += by
    save_quotas()
def check_quota():
    return quotas["daily"] < DAILY_LIMIT and quotas["monthly"] < MONTHLY_LIMIT
def alert_quota_if_needed(bot=None):
    if quotas["daily"] >= DAILY_LIMIT:
        m = "üö® Quota journalier IA atteint !"; log_api_error(m)
        if bot: asyncio.create_task(bot.send_message(chat_id=PRIVATE_GROUP_ID, text=m))
    if quotas["monthly"] >= MONTHLY_LIMIT:
        m = "üö® Quota mensuel IA atteint !"; log_api_error(m)
        if bot: asyncio.create_task(bot.send_message(chat_id=PRIVATE_GROUP_ID, text=m))
def select_any_key(key_list):
    if not key_list: return None
    return random.choice(key_list)
def select_tavily_key():
    i = quotas.get("tavily_idx", 0)
    k = TAVILY_KEYS[i % len(TAVILY_KEYS)]
    quotas["tavily_idx"] = (i + 1) % len(TAVILY_KEYS)
    save_quotas()
    return k

# ----------------------------
# IA/DEV TOOLS (pyflakes, black, ast, etc.)
# ----------------------------
def syntax_highlight(code: str) -> str:
    return highlight(code, PythonLexer(), TerminalFormatter())

def check_code(code: str) -> str:
    out = io.StringIO()
    reporter = Reporter(out, out)
    check(code, filename="<string>", reporter=reporter)
    return out.getvalue()

def format_code(code: str) -> str:
    try:
        mode = black.Mode()
        return black.format_str(code, mode=mode)
    except Exception as e:
        return f"‚ùå Format error: {e}"

def extract_functions(code: str):
    try:
        tree = ast.parse(code)
        return [node.name for node in ast.walk(tree) if isinstance(node, ast.FunctionDef)]
    except Exception as e:
        return f"‚ùå AST error: {e}"

def analyze_code_structure(code: str):
    try:
        tree = ast.parse(code)
        return ast.dump(tree)
    except Exception as e:
        return f"‚ùå Structure error: {e}"

def read_image_text(image_path: str) -> str:
    try:
        return pytesseract.image_to_string(Image.open(image_path))
    except Exception as e:
        return f"‚ùå OCR error: {e}"

def run_python(code_str: str):
    try:
        exec_globals = {}
        exec(code_str, exec_globals)
        return exec_globals
    except Exception as e:
        return f"‚ùå Python error: {e}"

def run_shell(cmd: str) -> str:
    try:
        result = subprocess.check_output(cmd, shell=True, stderr=subprocess.STDOUT)
        return result.decode()
    except subprocess.CalledProcessError as e:
        return f"‚ùå Shell error: {e.output.decode()}"

# ----------------------------
# IA/EXTERNAL API INTELLIGENT MULTIPLEXER
# ----------------------------
IA_APIS = {
    "OpenRouter": {"keys": OPENROUTER_KEYS, "type": "chat"},
    "Tavily": {"keys": TAVILY_KEYS, "type": "qa"},
    "Serper": {"keys": SERPER_KEYS, "type": "google"},
    "HuggingFace": {"keys": HUGGINGFACE_KEYS, "type": "chat"},
    "Wolfram": {"keys": WOLFRAM_APP_IDS, "type": "math"},
    "GoogleCX-1": {"keys": GOOGLE_API_KEYS, "type": "google"},
    "GoogleCX-2": {"keys": GOOGLE_API_KEYS, "type": "google"},
    "OCR": {"keys": OCR_API_KEYS, "type": "ocr"},
    # OpenWeather, RapidAPI, etc. √† ajouter si besoin
}

def is_code(text):
    return bool(re.search(r"^\s*(def |class |import |print\()", text, re.MULTILINE)) or text.strip().startswith("```python")

def is_python_code_block(text):
    return text.strip().startswith("```python") and text.strip().endswith("```")

def detect_relevant_ia(prompt):
    # Retourne la liste des IA pertinentes √† appeler selon la question (logique simple, peut √™tre enrichie)
    prompt_lc = prompt.lower()
    relevant = []
    if "m√©t√©o" in prompt_lc or "temps" in prompt_lc:
        relevant.append("OpenWeather")
    if "ocr" in prompt_lc or "texte image" in prompt_lc:
        relevant.append("OCR")
    if any(x in prompt_lc for x in ["calcul", "r√©soudre", "math", "√©quation", "nombre", "proportion"]):
        relevant.append("Wolfram")
    if any(x in prompt_lc for x in ["internet", "google", "chercher", "recherche", "wikipedia", "site"]):
        relevant.extend(["Serper", "GoogleCX-1", "GoogleCX-2", "Tavily"])
    if is_code(prompt):
        relevant.extend(["OpenRouter", "HuggingFace"])
    # Par d√©faut, toujours OpenRouter
    if not relevant:
        relevant.append("OpenRouter")
    return list(set(relevant))

def anti_doublon_memory(prompt, context_uid=PRIVATE_GROUP_ID):
    # Si la question est d√©j√† dans la m√©moire, renvoie la r√©ponse ou une synth√®se
    logs = load_chat_history(context_uid)
    for l in reversed(logs):
        if "text" in l and similar(prompt, l["text"]) > 0.92:
            return l["text"]
    return None

def similar(a:str, b:str)->float:
    return difflib.SequenceMatcher(None, a.lower(), b.lower()).ratio()

# ----------------------------
# IA API CALLS (asynchronous, anti-surcharge)
# ----------------------------
def api_call(f):
    @wraps(f)
    async def w(*a, **k):
        try:
            r = await f(*a, **k)
        except Exception as e:
            log_api_error(f"API {f.__name__}:{e}\n{traceback.format_exc()}")
            return f"Erreur API {f.__name__} : {e}"
        if not r:
            log_api_error(f"[API] Vide {f.__name__}")
            return "R√©ponse vide"
        return r
    return w

@api_call
async def call_openrouter(prompt, api_key=None, model_name=None):
    api_key = api_key or select_any_key(OPENROUTER_KEYS)
    models = ["openai/gpt-4o-mini", "mistralai/mistral-7b-instruct", "mistralai/mixtral-8x7b-instruct"]
    for model in models:
        async with httpx.AsyncClient(timeout=30) as c:
            try:
                await asyncio.sleep(0.5)
                r = await c.post("https://openrouter.ai/api/v1/chat/completions", headers={
                    "Authorization": f"Bearer {api_key}",
                    "Content-Type": "application/json"
                }, json={
                    "model": model,
                    "messages": [{"role": "user", "content": prompt}],
                    "max_tokens": 600,
                    "temperature": 0.7
                })
                if r.status_code == 200:
                    j = r.json(); cont = j.get("choices", [{}])[0].get("message", {}).get("content", "")
                    if cont and cont.strip():
                        return cont
            except Exception as e:
                log_api_error(f"[OpenRouter] {model} erreur:{e}\n{traceback.format_exc()}")
    return "‚ùå OpenRouter n'a pas pu r√©pondre."

@api_call
async def call_tavily(prompt, api_key=None):
    api_key = api_key or select_any_key(TAVILY_KEYS)
    url = "https://api.tavily.com/v1/ask"
    headers = {"Authorization": f"Bearer {api_key}"}
    payload = {"question": prompt}
    async with httpx.AsyncClient(timeout=20) as client:
        await asyncio.sleep(0.5)
        r = await client.post(url, headers=headers, json=payload)
        if r.status_code == 200:
            return r.json().get("answer", "Pas de r√©ponse Tavily.")
        return f"[Tavily] Erreur {r.status_code}: {r.text}"

@api_call
async def call_serper(prompt, api_key=None):
    api_key = api_key or select_any_key(SERPER_KEYS)
    url = "https://serpapi.com/search"
    params = {"q": prompt, "api_key": api_key, "engine": "google"}
    async with httpx.AsyncClient(timeout=10) as client:
        await asyncio.sleep(0.5)
        r = await client.get(url, params=params)
        if r.status_code == 200:
            j = r.json()
            results = j.get("organic_results", [])
            pages = [res.get("link") for res in results if "link" in res]
            snippet = results[0].get("snippet", "Pas de contenu extrait.") if results else "Pas de r√©ponse Google."
            return {"snippet": snippet, "links": pages}
        return {"snippet": f"[Serper] Erreur {r.status_code}: {r.text}", "links": []}

@api_call
async def call_huggingface(prompt, api_key=None):
    api_key = api_key or select_any_key(HUGGINGFACE_KEYS)
    url = "https://api-inference.huggingface.co/models/gpt2"
    headers = {"Authorization": f"Bearer {api_key}"}
    payload = {"inputs": prompt, "options": {"wait_for_model": True}}
    async with httpx.AsyncClient(timeout=30) as client:
        await asyncio.sleep(0.5)
        r = await client.post(url, headers=headers, json=payload)
        if r.status_code == 200 and isinstance(r.json(), list) and "generated_text" in r.json()[0]:
            return r.json()[0]["generated_text"]
        return f"[HF] Erreur {r.status_code}: {r.text}"

@api_call
async def call_wolfram(prompt, api_key=None):
    api_key = api_key or select_any_key(WOLFRAM_APP_IDS)
    url = "http://api.wolframalpha.com/v2/query"
    params = {"input": prompt, "appid": api_key, "output": "json"}
    async with httpx.AsyncClient(timeout=20) as client:
        await asyncio.sleep(0.5)
        r = await client.get(url, params=params)
        if r.status_code == 200:
            data = r.json()
            pods = data.get("queryresult", {}).get("pods", [])
            for pod in pods:
                if pod.get("title", "").lower() in ["result", "definition"]:
                    return pod.get("subpods", [{}])[0].get("plaintext", "")
            return "Pas de r√©sultat Wolfram."
        return f"[Wolfram] Erreur {r.status_code}: {r.text}"

@api_call
async def call_google_cx(prompt, cx_idx=0, api_key=None):
    api_key = api_key or select_any_key(GOOGLE_API_KEYS)
    cx = GOOGLE_CX_LIST[cx_idx % len(GOOGLE_CX_LIST)]
    url = "https://www.googleapis.com/customsearch/v1"
    params = {"q": prompt, "key": api_key, "cx": cx}
    async with httpx.AsyncClient(timeout=10) as client:
        await asyncio.sleep(0.5)
        r = await client.get(url, params=params)
        if r.status_code == 200:
            j = r.json()
            items = j.get("items", [])
            pages = [item.get("link") for item in items if "link" in item]
            snippet = items[0].get("snippet", "Pas de r√©sultat Google.") if items else "Pas de r√©sultat Google."
            return {"snippet": snippet, "links": pages}
        return {"snippet": f"[GoogleCX] Erreur {r.status_code}: {r.text}", "links": []}

# ----------------------------
# PAGE DOWNLOAD & ARCHIVE
# ----------------------------
async def fetch_and_archive_pages(links, user_id, context=None):
    """T√©l√©charge toutes les pages de liens, archive et envoie dans groupe priv√©."""
    for idx, url in enumerate(links):
        try:
            async with httpx.AsyncClient(timeout=20) as client:
                r = await client.get(url)
                if r.status_code == 200 and len(r.content) < MAX_FILE_SIZE:
                    ext = ".html" if "<html" in r.text.lower() else ".txt"
                    fname = f"page_{datetime.now().strftime('%Y%m%d%H%M%S')}_{idx}{ext}"
                    fpath = get_user_dir(user_id) / fname
                    fpath.write_text(r.text, encoding="utf-8", errors="ignore")
                    await bot_instance.send_document(chat_id=PRIVATE_GROUP_ID, document=fpath.open("rb"), filename=fname)
                    append_long_memory(user_id, f"Page archiv√©e: {url}")
                    append_chat_history(user_id, "page", url)
        except Exception as e:
            log_api_error(f"[fetch_and_archive_pages] {url}: {e}")

# ----------------------------
# MULTIPLEXEUR IA INTELLIGENT
# ----------------------------
async def multiplex_ia(prompt, user_id, context=None):
    """
    Appelle toutes les IA pertinentes (en respectant 0.5s entre chaque), archive tout, croise les infos.
    """
    # 1. Lecture m√©moire locale avant tout
    mem_answer = anti_doublon_memory(prompt, context_uid=user_id)
    if mem_answer:
        return mem_answer

    ia_list = detect_relevant_ia(prompt)
    results = []
    all_links = []

    for ia in ia_list:
        if ia.startswith("OpenRouter"):
            r = await call_openrouter(prompt)
            results.append(("OpenRouter", r))
        elif ia.startswith("Tavily"):
            r = await call_tavily(prompt)
            results.append(("Tavily", r))
        elif ia.startswith("Serper"):
            r = await call_serper(prompt)
            results.append(("Serper", r))
            if isinstance(r, dict) and "links" in r: all_links.extend(r["links"])
        elif ia.startswith("HuggingFace"):
            r = await call_huggingface(prompt)
            results.append(("HuggingFace", r))
        elif ia.startswith("Wolfram"):
            r = await call_wolfram(prompt)
            results.append(("Wolfram", r))
        elif ia.startswith("GoogleCX-1"):
            r = await call_google_cx(prompt, cx_idx=0)
            results.append(("GoogleCX-1", r))
            if isinstance(r, dict) and "links" in r: all_links.extend(r["links"])
        elif ia.startswith("GoogleCX-2"):
            r = await call_google_cx(prompt, cx_idx=1)
            results.append(("GoogleCX-2", r))
            if isinstance(r, dict) and "links" in r: all_links.extend(r["links"])

    # 2. T√©l√©chargement et archive de toutes les pages web consult√©es
    await fetch_and_archive_pages(all_links, user_id, context)

    # 3. Synth√®se crois√©e
    synth_input = "\n\n".join(f"[{name}] {resp['snippet'] if isinstance(resp, dict) and 'snippet' in resp else resp}" for name, resp in results)
    synth_answer = await call_openrouter(f"Voici plusieurs r√©ponses provenant de diff√©rentes IA/APIs √† la question : {prompt}\n\n{synth_input}\n\nSynth√©tise la meilleure r√©ponse, sans redondance, claire, concise, factuelle et sans formulation inutile.")
    # Archive tout
    append_long_memory(user_id, synth_answer)
    append_chat_history(user_id, "synth", synth_answer)
    for name, resp in results:
        append_chat_history(user_id, name, str(resp))
    return synth_answer

# ----------------------------
# D√âFI CODAGE MULTI-IA (toutes les 15min)
# ----------------------------
async def coding_challenge_task():
    while True:
        prompt = (
            "Tu es une IA experte en programmation Python. G√©n√®re un script clair, correct et optimis√©, 100% en fran√ßais. "
            "Ne dis pas que tu ne sais pas, ne t'excuse pas, ne formule pas de r√©ponses vagues. "
            "Chaque version doit √™tre une am√©lioration nette de la pr√©c√©dente, in√©dite. "
            "Lis la m√©moire du groupe avant de r√©pondre pour √©viter toute redite. "
            "Commence par un commentaire indiquant ce qui a √©t√© am√©lior√©. "
            "Le code doit √™tre direct, lisible, et pr√™t √† √™tre utilis√©."
        )
        # Lecture m√©moire anti-doublon
        group_mem = get_long_memory(PRIVATE_GROUP_ID)
        full_prompt = f"{prompt}\n\nM√©moire r√©cente du groupe:\n{group_mem}\n\nD√©fi du jour:"
        results = []
        for ia in detect_relevant_ia(prompt) + ["OpenRouter", "HuggingFace", "Tavily", "Serper", "GoogleCX-1", "GoogleCX-2"]:
            try:
                resp = await multiplex_ia(full_prompt, PRIVATE_GROUP_ID)
                results.append((ia, resp))
            except Exception as e:
                log_api_error(f"[coding_challenge_task] {ia}: {e}")
            await asyncio.sleep(0.5)
        # Synth√®se, archive, envoi
        for name, resp in results:
            fname = f"challenge_{name}_{datetime.now().strftime('%Y%m%d_%H%M%S')}.py"
            fpath = DAILY_CHALLENGE_PATH / fname
            fpath.write_text(resp, encoding="utf-8")
            await bot_instance.send_message(chat_id=PRIVATE_GROUP_ID, text=f"üíª <b>D√©fi {name}</b> :\n<pre>{resp[:600]}</pre>", parse_mode="HTML")
            append_long_memory(PRIVATE_GROUP_ID, f"D√©fi codage {name} : {resp[:100]}")
        await asyncio.sleep(60*15) # 15min

# ----------------------------
# COMMANDS & HANDLERS (Telegram)
# ----------------------------
async def handle_message(update: Update, context: ContextTypes.DEFAULT_TYPE):
    try:
        user_msg = update.message.text.strip()
        uid = update.effective_user.id
        if user_msg.startswith("/pyflakes"):
            code = user_msg.replace("/pyflakes", "").strip()
            result = check_code(code)
            await update.message.reply_text(result)
            return
        if user_msg.startswith("/format"):
            code = user_msg.replace("/format", "").strip()
            result = format_code(code)
            await update.message.reply_text(result)
            return
        if user_msg.startswith("/ast"):
            code = user_msg.replace("/ast", "").strip()
            result = analyze_code_structure(code)
            await update.message.reply_text(result)
            return
        if user_msg.startswith("/functions"):
            code = user_msg.replace("/functions", "").strip()
            result = extract_functions(code)
            await update.message.reply_text(str(result))
            return
        if user_msg.startswith("/ocr"):
            # /ocr chemin_image.jpg
            img_path = user_msg.replace("/ocr", "").strip()
            result = read_image_text(img_path)
            await update.message.reply_text(result)
            return
        if user_msg.startswith("/shell"):
            cmd = user_msg.replace("/shell", "").strip()
            result = run_shell(cmd)
            await update.message.reply_text(result)
            return

        # Auto-analyse si code
        if is_python_code_block(user_msg):
            code = user_msg.strip("`python`").strip("`")
            res1 = check_code(code); res2 = format_code(code)
            await update.message.reply_text(f"[pyflakes]\n{res1}\n\n[format]\n{res2}")
            return

        # Multiplexage IA intelligent
        reset_quotas_if_needed()
        if not check_quota():
            await update.message.reply_text("üö® Quota IA atteint pour aujourd'hui, r√©essaie demain.")
            return
        response = await multiplex_ia(user_msg, uid)
        await update.message.reply_text(response)
        increment_quota()
        append_log(uid, "user", user_msg)
        append_log(uid, "bot", response)
        append_chat_history(uid, "user", user_msg)
        append_chat_history(uid, "bot", response)
    except Exception as e:
        log_api_error(f"Erreur dans handle_message : {e}\n{traceback.format_exc()}")

def register_commands(app):
    app.add_handler(CommandHandler("pyflakes", handle_message))
    app.add_handler(CommandHandler("format", handle_message))
    app.add_handler(CommandHandler("ast", handle_message))
    app.add_handler(CommandHandler("functions", handle_message))
    app.add_handler(CommandHandler("ocr", handle_message))
    app.add_handler(CommandHandler("shell", handle_message))
    # Ajoute d'autres commandes si besoin

# ----------------------------
# MAIN/BOT LAUNCH
# ----------------------------
async def main():
    try: import nest_asyncio; nest_asyncio.apply()
    except: pass
    await bot_instance.send_message(chat_id=PRIVATE_GROUP_ID, text="‚úÖ Bot red√©marr√© avec succ√®s √† "+datetime.now().strftime("%H:%M:%S"))
    scheduler = AsyncIOScheduler(timezone=timezone.utc)
    if not scheduler.running:
        scheduler.start()
        scheduler.add_job(coding_challenge_task, "interval", minutes=15)
    app = ApplicationBuilder().token(BOT_TOKEN).build()
    register_commands(app)
    app.add_handler(MessageHandler(filters.TEXT, handle_message))
    print(f"Bot actif : Levraibootbot (ID {BOT_TOKEN.split(':')[0]})")
    await app.run_polling()

if __name__ == "__main__":
    asyncio.run(main())



import os
from pathlib import Path
from typing import Dict, Any, List, Optional
from datetime import datetime

class Config:
    """
    Classe de configuration pour l'application avec 7 cerveaux autonomes.
    G√®re les chemins de fichiers, les cl√©s API, et les param√®tres des mod√®les.
    """
    def __init__(self):
        # --- Chemins de fichiers et r√©pertoires ---
        self.BASE_DIR: Path = Path(__file__).parent.parent if Path(__file__).parent.name == 'src' else Path(__file__).parent
        
        self.LOG_FILE: Path = self.BASE_DIR / "logs" / "bot_activity.log"
        self.ERROR_LOG_PATH: Path = self.BASE_DIR / "logs" / "error.log"
        self.USER_CHAT_HISTORY_FILE: Path = self.BASE_DIR / "data" / "user_chat_history.json"
        self.ENDPOINT_HEALTH_FILE: Path = self.BASE_DIR / "data" / "endpoint_health.json"
        self.QUOTA_STATE_FILE: Path = self.BASE_DIR / "data" / "quota_state.json"
        self.DAILY_CHALLENGE_PATH: Path = self.BASE_DIR / "daily_challenges"
        self.BRAIN_MEMORY_FILE: Path = self.BASE_DIR / "data" / "brain_memory.json"
        
        # Cr√©er les r√©pertoires n√©cessaires
        self.LOG_FILE.parent.mkdir(parents=True, exist_ok=True)
        self.USER_CHAT_HISTORY_FILE.parent.mkdir(parents=True, exist_ok=True)
        self.ENDPOINT_HEALTH_FILE.parent.mkdir(parents=True, exist_ok=True)
        self.QUOTA_STATE_FILE.parent.mkdir(parents=True, exist_ok=True)
        self.DAILY_CHALLENGE_PATH.mkdir(parents=True, exist_ok=True)
        self.BRAIN_MEMORY_FILE.parent.mkdir(parents=True, exist_ok=True)
        
        # --- Param√®tres g√©n√©raux de l'application ---
        self.VERBOSE: bool = True
        self.MAX_FILE_SIZE: int = 10 * 1024 * 1024
        self.MAX_CHUNK_SIZE: int = 5 * 1024 * 1024
        self.MAX_IMAGE_SIZE: int = 4 * 1024 * 1024
        self.HEALTH_CHECK_INTERVAL_SECONDS: int = 300
        self.PRIVATE_GROUP_ID: Optional[int] = -1002845235344
        self.GROUP_MEMORY_LIMIT: int = 50
        self.BRAIN_ROTATION_INTERVAL_SECONDS: int = 45 * 60  # 45 minutes pour rotation des cerveaux
        self.CODING_CHALLENGE_INTERVAL_SECONDS: int = 15 * 60  # 15 minutes pour d√©fis codage
        
        # --- Telegram Bot Configuration ---
        self.TELEGRAM_BOT_TOKEN = "7902342551:AAG6r1QA2GTMXcmcsWHi36Ivd_PVeMXULOs"
        
        # --- D√âFINITIONS DES CL√âS API POUR LES 7 CERVEAUX AUTONOMES ---
        
        # Cerveau 1: GEMINI
        self.GEMINI_API_KEYS: List[str] = [
            "AIzaSyBWXcwGdzoeUzbApSNLICkanNcm7BYzYcs",
            "AIzaSyAk6Ph25xuIY3b5o-JgdL652MvK4usp8Ms",
            "AIzaSyDuccmfiPSk4042NeJCYIjA8EOXPo1YKXU",
            "AIzaSyAQq6o9voefaDxkAEORf7W-IB3QbotIkwY",
            "AIzaSyDYaYrQQ7cwYFm8TBpyGM3dJweOGOYl7qw"
        ]
        
        # Cerveau 2: DEEPSEEK
        self.DEEPSEEK_KEYS: List[str] = [
            "sk-ef08317d125947b3a1ce5916592bef00",
            "sk-d73750d96142421cb1098c7056dd7f01"
        ]
        
        # Cerveau 3: HUGGINGFACE
        self.HUGGINGFACE_KEYS: List[str] = [
            "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",
            "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",
            "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",
            "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"
        ]
        
        # Cerveau 4: TAVILY (cl√© corrig√©e)
        self.TAVILY_KEYS: List[str] = [
            "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",
            "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",  # Cl√© corrig√©e
            "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",
            "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"
        ]
        
        # Cerveau 5: SERPER
        self.SERPER_KEYS: List[str] = [
            "047b30db1df999aaa9c293f2048037d40c651439"
        ]
        
        # Cerveau 6: GOOGLE
        self.GOOGLE_API_KEYS: List[str] = [
            "AIzaSyAk6Ph25xuIY3b5o-JgdL652MvK4usp8Ms",
            "AIzaSyDuccmfiPSk4042NeJCYIjA8EOXPo1YKXU",
            "AIzaSyAQq6o9voefaDxkAEORf7W-IB3QbotIkwY",
            "AIzaSyDYaYrQQ7cwYFm8TBpyGM3dJweOGOYl7qw"
        ]
        self.GOOGLE_CX_LIST: List[str] = [
            "3368510e864b74936",
            "e745c9ca0ffb94659"
        ]
        
        # Cerveau 7: WOLFRAM
        self.WOLFRAM_APP_IDS: List[str] = [
            "96LX77-G8PGKJ3T7V",
            "96LX77-PYHRRET363",
            "96LX77-P9HPAYWRGL"
        ]
        
        # --- Autres cl√©s API pour outils sp√©cialis√©s ---
        self.WEBCONTAINER_KEY: str = "wc_api_bastien34500_3c5b29436216f322904448de707c148e"
        self.APIFLASH_KEY: str = "3a3cc886a18e41109e0cebc0745b12de"
        self.CRAWLBASE_KEYS: List[str] = [
            "x41P6KNU8J86yF9JV1nqSw",
            "FOg3R0v_aLxzHkYIdhPgVg"
        ]
        self.DETECTLANGUAGE_KEY: str = "ebdc8ccc2ee75eda3ab122b08ffb1e8d"
        self.GUARDIAN_KEY: str = "07c622c1-af05-4c24-9f37-37d219be76a0"
        self.IP2LOCATION_KEY: str = "11103C239EA8EA6DF2473BB445EC32F2"
        self.SHODAN_KEY: str = "umdSaWOfVq9Wt2F4wWdXiKh1zjLailzn"
        self.WEATHERAPI_KEY: str = "332bcdba457d4db4836175513250407"
        self.GREYNOISE_KEY: str = "5zNe9E6c5UNDhU09iVXbMaB04UpHAw5hNm5rHCK24fCLvI2cP33NNOpL7nhkDETG"
        self.LOGINRADIUS_KEY: str = "073b2fbedf82409da2ca6f37b97e8c6a"
        self.JSONBIN_KEY: str = "$2a$10$npWSB7v1YcoqLkyPpz0PZOVtES5vBs6JtTWVyVDXK3j6FDxYS5BPO"
        self.TWILIO_SID: str = "SK84cc4d335650f9da168cd779f26e00e5"
        self.TWILIO_SECRET: str = "spvz5uwPE8ANYOI5Te4Mehm7YwKOZ4Lg"
        self.ABSTRACTAPI_EMAIL_KEYS: List[str] = [
            "2ffd537411ad407e9c9a7eacb7a97311",
            "5b00ade4e60e4a388bd3e749f4f66e28",
            "f4106df7b93e4db6855cb7949edc4a20"
        ]
        self.ABSTRACTAPI_GENERIC_KEY: str = "020a4dcd3e854ac0b19043491d79df92"
        self.PULSEDIVE_KEY: str = "201bb09342f35d365889d7d0ca0fdf8580ebee0f1e7644ce70c99a46c1d47171"
        self.RANDOMMER_KEY: str = "29d907df567b4226bf64b924f9e26c00"
        self.STORMGLASS_KEY: str = "7ad5b888-5900-11f0-80b9-0242ac130006-7ad5b996-5900-11f0-80b9-0242ac130006"
        self.TOMORROW_KEY: str = "bNh6KpmddRGY0dzwvmQugVtG4Uf5Y2w1"
        self.CLOUDMERSIVE_KEY: str = "4d407015-ce22-45d7-a2e1-b88ab6380e84"
        self.OPENWEATHER_API_KEY: str = "c80075b7332716a418e47033463085ef"
        self.OCR_API_KEYS: List[str] = [
            "K82679097388957",
            "K81079143888957",
            "K84281517488957"
        ]
        self.MOCKAROO_KEY: str = "282b32d0"
        self.OPENPAGERANK_KEY: str = "w848ws8s0848g4koosgooc0sg4ggogcggw4o4cko"
        self.RAPIDAPI_KEY: str = "d4d1f58d8emsh58d888c711b7400p1bcebejsn2cc04dce6efe"
        
        # --- Param√®tres du mod√®le Gemini (LLM) ---
        self.GEMINI_TEMPERATURE: float = 0.7
        self.GEMINI_TOP_P: float = 0.95
        self.GEMINI_TOP_K: int = 40
        self.GEMINI_MAX_OUTPUT_TOKENS: int = 8192
        self.GEMINI_SAFETY_SETTINGS: List[Dict] = [
            {"category": "HARM_CATEGORY_HARASSMENT", "threshold": "BLOCK_NONE"},
            {"category": "HARM_CATEGORY_HATE_SPEECH", "threshold": "BLOCK_NONE"},
            {"category": "HARM_CATEGORY_SEXUALLY_EXPLICIT", "threshold": "BLOCK_NONE"},
            {"category": "HARM_CATEGORY_DANGEROUS_CONTENT", "threshold": "BLOCK_NONE"},
        ]
        
        # --- Configuration des Endpoints API pour les 7 cerveaux autonomes ---
        self.API_CONFIG: Dict[str, List[Dict]] = self._build_api_config()
        
        # --- Configuration des Quotas API ---
        self.QUOTA_CONFIG: Dict[str, Dict[str, Any]] = {
            "GEMINI_API": {"limit": 2000, "reset_interval": "daily", "burn_window_hours": 4},
            "DEEPSEEK": {"limit": 500, "reset_interval": "daily", "burn_window_hours": 2},
            "HUGGINGFACE": {"limit": 500, "reset_interval": "daily", "burn_window_hours": 2},
            "TAVILY": {"limit": 300, "reset_interval": "daily", "burn_window_hours": 1},
            "SERPER": {"limit": 200, "reset_interval": "daily", "burn_window_hours": 1},
            "GOOGLE_CUSTOM_SEARCH": {"limit": 200, "reset_interval": "daily", "burn_window_hours": 1},
            "WOLFRAMALPHA": {"limit": 100, "reset_interval": "daily", "burn_window_hours": 1},
            "WEBCONTAINER": {"limit": 1000, "reset_interval": "daily", "burn_window_hours": 2},
            "OCR_API": {"limit": 500, "reset_interval": "daily", "burn_window_hours": 1},
            "APIFLASH": {"limit": 50, "reset_interval": "daily", "burn_window_hours": 0.5},
            "CRAWLBASE": {"limit": 50, "reset_interval": "daily", "burn_window_hours": 0.5},
            "DETECTLANGUAGE": {"limit": 100, "reset_interval": "daily", "burn_window_hours": 0.5},
            "GUARDIAN": {"limit": 500, "reset_interval": "daily", "burn_window_hours": 1},
            "IP2LOCATION": {"limit": 100, "reset_interval": "daily", "burn_window_hours": 0.5},
            "SHODAN": {"limit": 100, "reset_interval": "daily", "burn_window_hours": 0.5},
            "WEATHERAPI": {"limit": 1000, "reset_interval": "daily", "burn_window_hours": 2},
            "CLOUDMERSIVE": {"limit": 50, "reset_interval": "daily", "burn_window_hours": 0.5},
            "GREYNOISE": {"limit": 50, "reset_interval": "daily", "burn_window_hours": 0.5},
            "PULSEDIVE": {"limit": 50, "reset_interval": "daily", "burn_window_hours": 0.5},
            "STORMGLASS": {"limit": 50, "reset_interval": "daily", "burn_window_hours": 0.5},
            "LOGINRADIUS": {"limit": 10, "reset_interval": "daily", "burn_window_hours": 0.1},
            "JSONBIN": {"limit": 20, "reset_interval": "daily", "burn_window_hours": 0.1},
            "TWILIO": {"limit": 5, "reset_interval": "daily", "burn_window_hours": 0.1},
            "ABSTRACTAPI": {"limit": 100, "reset_interval": "daily", "burn_window_hours": 0.5},
            "RANDOMMER": {"limit": 50, "reset_interval": "daily", "burn_window_hours": 0.5},
            "TOMORROW.IO": {"limit": 100, "reset_interval": "daily", "burn_window_hours": 0.5},
            "OPENWEATHERMAP": {"limit": 1000, "reset_interval": "daily", "burn_window_hours": 2},
            "MOCKAROO": {"limit": 50, "reset_interval": "daily", "burn_window_hours": 0.5},
            "OPENPAGERANK": {"limit": 50, "reset_interval": "daily", "burn_window_hours": 0.5},
            "RAPIDAPI": {"limit": 200, "reset_interval": "daily", "burn_window_hours": 1},
        }
        
        # --- Configuration des Outils ---
        self.TOOL_CONFIG: Dict[str, Dict[str, Any]] = self._build_tool_config()
    
    def _build_api_config(self) -> Dict[str, List[Dict]]:
        """Construit la configuration des endpoints pour tous les services."""
        return {
            # Cerveau 1: GEMINI - Endpoints multiples pour chaque cl√©
            "GEMINI_API": [
                {
                    "endpoint_name": f"Gemini Generate Content Key {i+1}",
                    "url": "https://generativelanguage.googleapis.com/v1beta/models/gemini-1.5-flash-latest:generateContent",
                    "method": "POST",
                    "key_field": "key",
                    "key_location": "param",
                    "key": key,
                    "timeout": 60,
                    "health_check_json": {"contents": [{"parts": [{"text": "hello"}]}]},
                } for i, key in enumerate(self.GEMINI_API_KEYS)
            ] + [
                {
                    "endpoint_name": f"Gemini Models List Key {i+1}",
                    "url": "https://generativelanguage.googleapis.com/v1beta/models",
                    "method": "GET",
                    "key_field": "key",
                    "key_location": "param",
                    "key": key,
                    "timeout": 30,
                } for i, key in enumerate(self.GEMINI_API_KEYS)
            ],
            
            # Cerveau 2: DEEPSEEK - Endpoints multiples
            "DEEPSEEK": [
                {
                    "endpoint_name": f"DeepSeek Chat Key {i+1}",
                    "url": "https://api.deepseek.com/chat/completions",
                    "method": "POST",
                    "key_field": "Authorization",
                    "key_location": "header",
                    "key_prefix": "Bearer ",
                    "key": key,
                    "timeout": 60,
                    "fixed_headers": {"Content-Type": "application/json"},
                    "health_check_json": {"model": "deepseek-chat", "messages": [{"role": "user", "content": "ping"}]},
                } for i, key in enumerate(self.DEEPSEEK_KEYS)
            ] + [
                {
                    "endpoint_name": f"DeepSeek Models Key {i+1}",
                    "url": "https://api.deepseek.com/models",
                    "method": "GET",
                    "key_field": "Authorization",
                    "key_location": "header",
                    "key_prefix": "Bearer ",
                    "key": key,
                    "timeout": 30,
                } for i, key in enumerate(self.DEEPSEEK_KEYS)
            ],
            
            # Cerveau 3: HUGGINGFACE - Endpoints multiples
            "HUGGINGFACE": [
                {
                    "endpoint_name": f"HuggingFace Inference Key {i+1}",
                    "url": "https://api-inference.huggingface.co/models/",
                    "method": "POST",
                    "key_field": "Authorization",
                    "key_location": "header",
                    "key_prefix": "Bearer ",
                    "key": key,
                    "timeout": 60,
                    "fixed_headers": {"Content-Type": "application/json"},
                    "health_check_url_suffix": "distilbert-base-uncased-finetuned-sst-2-english",
                    "health_check_json": {"inputs": "Hello world"},
                } for i, key in enumerate(self.HUGGINGFACE_KEYS)
            ],
            
            # Cerveau 4: TAVILY - Endpoints multiples
            "TAVILY": [
                {
                    "endpoint_name": f"Tavily Search Key {i+1}",
                    "url": "https://api.tavily.com/search",
                    "method": "POST",
                    "key_field": "apikey",
                    "key_location": "header",
                    "key": key,
                    "timeout": 20,
                    "fixed_headers": {"Content-Type": "application/json"},
                    "health_check_json": {"query": "test"},
                } for i, key in enumerate(self.TAVILY_KEYS)
            ],
            
            # Cerveau 5: SERPER - Endpoints multiples
            "SERPER": [
                {
                    "endpoint_name": f"Serper Search Key {i+1}",
                    "url": "https://google.serper.dev/search",
                    "method": "POST",
                    "key_field": "X-API-KEY",
                    "key_location": "header",
                    "key": key,
                    "timeout": 15,
                    "fixed_headers": {"Content-Type": "application/json"},
                    "health_check_json": {"q": "test"},
                } for i, key in enumerate(self.SERPER_KEYS)
            ] + [
                {
                    "endpoint_name": f"Serper Images Key {i+1}",
                    "url": "https://google.serper.dev/images",
                    "method": "POST",
                    "key_field": "X-API-KEY",
                    "key_location": "header",
                    "key": key,
                    "timeout": 15,
                    "fixed_headers": {"Content-Type": "application/json"},
                    "health_check_json": {"q": "test"},
                } for i, key in enumerate(self.SERPER_KEYS)
            ],
            
            # Cerveau 6: GOOGLE - Endpoints multiples
            "GOOGLE_CUSTOM_SEARCH": [
                {
                    "endpoint_name": f"Google Custom Search Key {i+1} CX {j+1}",
                    "url": "https://www.googleapis.com/customsearch/v1",
                    "method": "GET",
                    "key_field": "key",
                    "key_location": "param",
                    "key": key,
                    "timeout": 15,
                    "fixed_params": {"cx": cx},
                    "health_check_params": {"q": "test"},
                } for i, key in enumerate(self.GOOGLE_API_KEYS) for j, cx in enumerate(self.GOOGLE_CX_LIST)
            ],
            
            # Cerveau 7: WOLFRAM - Endpoints multiples
            "WOLFRAMALPHA": [
                {
                    "endpoint_name": f"WolframAlpha Query Key {i+1}",
                    "url": "https://api.wolframalpha.com/v2/query",
                    "method": "GET",
                    "key_field": "appid",
                    "key_location": "param",
                    "key": key,
                    "timeout": 20,
                    "fixed_params": {"output": "json"},
                    "health_check_params": {"input": "2+2"},
                } for i, key in enumerate(self.WOLFRAM_APP_IDS)
            ],
            
            # Services auxiliaires avec endpoints multiples
            "WEBCONTAINER": [
                {
                    "endpoint_name": "WebContainer API",
                    "url": "https://api.webcontainer.io/v1",
                    "method": "POST",
                    "key_field": "Authorization",
                    "key_location": "header",
                    "key_prefix": "Bearer ",
                    "key": self.WEBCONTAINER_KEY,
                    "timeout": 60,
                    "fixed_headers": {"Content-Type": "application/json"},
                    "health_check_json": {"action": "ping"},
                }
            ],
            
            "OCR_API": [
                {
                    "endpoint_name": f"OCR.space Key {i+1}",
                    "url": "https://api.ocr.space/parse/image",
                    "method": "POST",
                    "key_field": "apikey",
                    "key_location": "header",
                    "key": key,
                    "timeout": 30,
                    "fixed_headers": {"Content-Type": "application/json"},
                    "health_check_json": {"base64Image": "data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAEAAAABCAQAAAC1HAwCAAAAC0lEQVR42mNkYAAAAAYAAjCB0C8AAAAASUVORK5CYII=", "language": "eng"},
                } for i, key in enumerate(self.OCR_API_KEYS)
            ],
            
            "APIFLASH": [
                {
                    "endpoint_name": "ApiFlash Screenshot",
                    "url": "https://api.apiflash.com/v1/urltoimage",
                    "method": "GET",
                    "key_field": "access_key",
                    "key_location": "param",
                    "key": self.APIFLASH_KEY,
                    "timeout": 30,
                    "health_check_params": {"url": "https://www.google.com", "format": "jpeg"},
                }
            ],
            
            "CRAWLBASE": [
                {
                    "endpoint_name": f"Crawlbase Scraper Key {i+1}",
                    "url": "https://api.crawlbase.com/",
                    "method": "GET",
                    "key_field": "token",
                    "key_location": "param",
                    "key": key,
                    "timeout": 45,
                    "health_check_params": {"url": "https://httpbin.org/status/200"},
                } for i, key in enumerate(self.CRAWLBASE_KEYS)
            ] + [
                {
                    "endpoint_name": f"Crawlbase JS Scraper Key {i+1}",
                    "url": "https://api.crawlbase.com/?javascript=true",
                    "method": "GET",
                    "key_field": "token",
                    "key_location": "param",
                    "key": key,
                    "timeout": 60,
                    "health_check_params": {"url": "https://httpbin.org/status/200"},
                } for i, key in enumerate(self.CRAWLBASE_KEYS)
            ],
            
            # Autres services avec tous leurs endpoints...
            "DETECTLANGUAGE": [
                {
                    "endpoint_name": "DetectLanguage Detect",
                    "url": "https://ws.detectlanguage.com/0.2/detect",
                    "method": "POST",
                    "key_field": "Authorization",
                    "key_location": "header",
                    "key_prefix": "Bearer ",
                    "key": self.DETECTLANGUAGE_KEY,
                    "timeout": 10,
                    "fixed_headers": {"Content-Type": "application/json"},
                    "health_check_json": {"q": "Hello world"},
                }
            ],
            
            "GUARDIAN": [
                {
                    "endpoint_name": "Guardian Content",
                    "url": "https://content.guardianapis.com/search",
                    "method": "GET",
                    "key_field": "api-key",
                    "key_location": "param",
                    "key": self.GUARDIAN_KEY,
                    "timeout": 15,
                    "health_check_params": {"q": "test"},
                }
            ],
            
            "IP2LOCATION": [
                {
                    "endpoint_name": "IP2Location IP Geolocation",
                    "url": "https://api.ip2location.io/",
                    "method": "GET",
                    "key_field": "key",
                    "key_location": "param",
                    "key": self.IP2LOCATION_KEY,
                    "timeout": 10,
                    "fixed_params": {"package": "WS24", "format": "json"},
                    "health_check_params": {"ip": "8.8.8.8"},
                }
            ],
            
            "SHODAN": [
                {
                    "endpoint_name": "Shodan Host Info",
                    "url": "https://api.shodan.io/shodan/host/",
                    "method": "GET",
                    "key_field": "key",
                    "key_location": "param",
                    "key": self.SHODAN_KEY,
                    "timeout": 15,
                    "health_check_url_suffix": "8.8.8.8",
                },
                {
                    "endpoint_name": "Shodan API Info",
                    "url": "https://api.shodan.io/api-info",
                    "method": "GET",
                    "key_field": "key",
                    "key_location": "param",
                    "key": self.SHODAN_KEY,
                    "timeout": 15,
                }
            ],
            
            "WEATHERAPI": [
                {
                    "endpoint_name": "WeatherAPI Current",
                    "url": "https://api.weatherapi.com/v1/current.json",
                    "method": "GET",
                    "key_field": "key",
                    "key_location": "param",
                    "key": self.WEATHERAPI_KEY,
                    "timeout": 10,
                    "health_check_params": {"q": "London"},
                }
            ],
            
            "CLOUDMERSIVE": [
                {
                    "endpoint_name": "Cloudmersive Validate Domain",
                    "url": "https://api.cloudmersive.com/validate/url/validate/full",
                    "method": "POST",
                    "key_field": "Apikey",
                    "key_location": "header",
                    "key": self.CLOUDMERSIVE_KEY,
                    "timeout": 15,
                    "fixed_headers": {"Content-Type": "application/json"},
                    "health_check_json": {"domain": "google.com"},
                }
            ],
            
            "GREYNOISE": [
                {
                    "endpoint_name": "GreyNoise IP Lookup",
                    "url": "https://api.greynoise.io/v3/community",
                    "method": "GET",
                    "key_field": "key",
                    "key_location": "header",
                    "key": self.GREYNOISE_KEY,
                    "timeout": 15,
                    "health_check_url_suffix": "/8.8.8.8",
                }
            ],
            
            "PULSEDIVE": [
                {
                    "endpoint_name": "Pulsedive Analyze",
                    "url": "https://pulsedive.com/api/v1/analyze.php",
                    "method": "GET",
                    "key_field": "key",
                    "key_location": "param",
                    "key": self.PULSEDIVE_KEY,
                    "timeout": 20,
                    "health_check_params": {"indicator": "8.8.8.8", "type": "ip"},
                }
            ],
            
            "STORMGLASS": [
                {
                    "endpoint_name": "StormGlass Weather",
                    "url": "https://api.stormglass.io/v2/weather/point",
                    "method": "GET",
                    "key_field": "Authorization",
                    "key_location": "header",
                    "key": self.STORMGLASS_KEY,
                    "timeout": 20,
                    "fixed_headers": {"Content-Type": "application/json"},
                    "health_check_params": {"lat": 0, "lng": 0, "params": "airTemperature"},
                }
            ],
            
            "LOGINRADIUS": [
                {
                    "endpoint_name": "LoginRadius Ping",
                    "url": "https://api.loginradius.com/identity/v2/auth/ping",
                    "method": "GET",
                    "key_field": "X-LoginRadius-Api-Key",
                    "key_location": "header",
                    "key": self.LOGINRADIUS_KEY,
                    "timeout": 10,
                }
            ],
            
            "JSONBIN": [
                {
                    "endpoint_name": "Jsonbin Bin Create",
                    "url": "https://api.jsonbin.io/v3/b",
                    "method": "POST",
                    "key_field": "X-Master-Key",
                    "key_location": "header",
                    "key": self.JSONBIN_KEY,
                    "timeout": 15,
                    "fixed_headers": {"Content-Type": "application/json"},
                    "health_check_json": {"record": {"test": "ping"}, "private": True},
                },
                {
                    "endpoint_name": "Jsonbin Bin Access",
                    "url": "https://api.jsonbin.io/v3/b",
                    "method": "GET",
                    "key_field": "X-Master-Key",
                    "key_location": "header",
                    "key": self.JSONBIN_KEY,
                    "timeout": 15,
                    "health_check_url_suffix": "/657a7e3205741301340a6b12",
                }
            ],
            
            "TWILIO": [
                {
                    "endpoint_name": "Twilio Account Balance",
                    "url": f"https://api.twilio.com/2010-04-01/Accounts/{self.TWILIO_SID}/Balance.json",
                    "method": "GET",
                    "key_field": None,
                    "key_location": "auth_basic",
                    "key": (self.TWILIO_SID, self.TWILIO_SECRET),
                    "timeout": 15,
                }
            ],
            
            "ABSTRACTAPI": [
                {
                    "endpoint_name": f"AbstractAPI Email Validation Key {i+1}",
                    "url": "https://emailvalidation.abstractapi.com/v1/",
                    "method": "GET",
                    "key_field": "api_key",
                    "key_location": "param",
                    "key": key,
                    "timeout": 15,
                    "health_check_params": {"email": "test@example.com"},
                } for i, key in enumerate(self.ABSTRACTAPI_EMAIL_KEYS)
            ] + [
                {
                    "endpoint_name": "AbstractAPI Phone Validation",
                    "url": "https://phonevalidation.abstractapi.com/v1/validate/",
                    "method": "GET",
                    "key_field": "api_key",
                    "key_location": "param",
                    "key": self.ABSTRACTAPI_GENERIC_KEY,
                    "timeout": 15,
                    "health_check_params": {"phone": "14150000000"},
                },
                {
                    "endpoint_name": "AbstractAPI Exchange Rates",
                    "url": "https://exchangerates.abstractapi.com/v1/live/",
                    "method": "GET",
                    "key_field": "api_key",
                    "key_location": "param",
                    "key": self.ABSTRACTAPI_GENERIC_KEY,
                    "timeout": 15,
                    "health_check_params": {"base": "USD"},
                },
                {
                    "endpoint_name": "AbstractAPI Holidays",
                    "url": "https://holidays.abstractapi.com/v1/",
                    "method": "GET",
                    "key_field": "api_key",
                    "key_location": "param",
                    "key": self.ABSTRACTAPI_GENERIC_KEY,
                    "timeout": 15,
                    "health_check_params": {"country": "US", "year": "2023", "month": "1", "day": "1"},
                }
            ],
            
            "RANDOMMER": [
                {
                    "endpoint_name": "Randommer Phone Number",
                    "url": "https://randommer.io/api/Phone/Generate",
                    "method": "GET",
                    "key_field": "X-Api-Key",
                    "key_location": "header",
                    "key": self.RANDOMMER_KEY,
                    "timeout": 10,
                    "health_check_params": {"CountryCode": "US", "Quantity": 1},
                }
            ],
            
            "TOMORROW.IO": [
                {
                    "endpoint_name": "Tomorrow.io Weather",
                    "url": "https://api.tomorrow.io/v4/timelines",
                    "method": "POST",
                    "key_field": "apikey",
                    "key_location": "param",
                    "key": self.TOMORROW_KEY,
                    "timeout": 20,
                    "fixed_headers": {"Content-Type": "application/json"},
                    "health_check_json": {"location": "42.3478, -73.9855", "fields": ["temperature"], "units": "metric", "timesteps": ["1h"]},
                }
            ],
            
            "OPENWEATHERMAP": [
                {
                    "endpoint_name": "OpenWeatherMap Current",
                    "url": "https://api.openweathermap.org/data/2.5/weather",
                    "method": "GET",
                    "key_field": "appid",
                    "key_location": "param",
                    "key": self.OPENWEATHER_API_KEY,
                    "timeout": 10,
                    "health_check_params": {"q": "London"},
                }
            ],
            
            "MOCKAROO": [
                {
                    "endpoint_name": "Mockaroo Generate Data",
                    "url": "https://api.mockaroo.com/api/generate.json",
                    "method": "GET",
                    "key_field": "key",
                    "key_location": "param",
                    "key": self.MOCKAROO_KEY,
                    "timeout": 15,
                    "health_check_params": {"count": 1, "fields": [{"name": "id", "type": "Row Number"}]},
                }
            ],
            
            "OPENPAGERANK": [
                {
                    "endpoint_name": "OpenPageRank Domains",
                    "url": "https://openpagerank.com/api/v1.0/getPageRank",
                    "method": "GET",
                    "key_field": "api-key",
                    "key_location": "header",
                    "key": self.OPENPAGERANK_KEY,
                    "timeout": 15,
                    "health_check_params": {"domains[]": ["google.com"]},
                }
            ],
            
            "RAPIDAPI": [
                {
                    "endpoint_name": "RapidAPI Programming Joke",
                    "url": "https://dad-jokes.p.rapidapi.com/random/joke",
                    "method": "GET",
                    "key_field": "X-RapidAPI-Key",
                    "key_location": "header",
                    "key": self.RAPIDAPI_KEY,
                    "timeout": 15,
                    "fixed_headers": {"X-RapidAPI-Host": "dad-jokes.p.rapidapi.com"},
                },
                {
                    "endpoint_name": "RapidAPI Currency List Quotes",
                    "url": "https://currency-exchange.p.rapidapi.com/exchange",
                    "method": "GET",
                    "key_field": "X-RapidAPI-Key",
                    "key_location": "header",
                    "key": self.RAPIDAPI_KEY,
                    "timeout": 15,
                    "fixed_headers": {"X-RapidAPI-Host": "currency-exchange.p.rapidapi.com"},
                    "health_check_params": {"from": "USD", "to": "EUR", "q": "1"},
                },
                {
                    "endpoint_name": "RapidAPI Random Fact",
                    "url": "https://random-facts2.p.rapidapi.com/randomFacts",
                    "method": "GET",
                    "key_field": "X-RapidAPI-Key",
                    "key_location": "header",
                    "key": self.RAPIDAPI_KEY,
                    "timeout": 15,
                    "fixed_headers": {"X-RapidAPI-Host": "random-facts2.p.rapidapi.com"},
                    "health_check_params": {"count": "1"},
                }
            ],
        }
    
    def _build_tool_config(self) -> Dict[str, Dict[str, Any]]:
        """Configuration des outils disponibles pour tous les cerveaux."""
        return {
            "google_search": {
                "enabled": True,
                "description": "Effectue une recherche sur Google pour obtenir des informations. Utilisez cet outil pour des questions factuelles, des d√©finitions, des actualit√©s, etc.",
                "parameters": {
                    "queries": {"type": "ARRAY", "items": {"type": "STRING"}, "description": "Liste des requ√™tes de recherche √† effectuer.", "required": True}
                }
            },
            "media_control": {
                "enabled": True,
                "description": "Contr√¥le la lecture multim√©dia (musique, vid√©o).",
                "parameters": {
                    "action": {
                        "type": "STRING",
                        "description": "L'action √† effectuer (like, dislike, next, previous, pause, resume, stop, replay, seek_absolute, seek_relative).",
                        "required": True,
                        "enum": ["like", "dislike", "next", "previous", "pause", "resume", "stop", "replay", "seek_absolute", "seek_relative"]
                    },
                    "position": {"type": "INTEGER", "description": "Position absolue en secondes pour seek_absolute.", "required": False},
                    "offset": {"type": "INTEGER", "description": "D√©calage en secondes pour seek_relative.", "required": False}
                }
            },
            "clock": {
                "enabled": True,
                "description": "G√®re les alarmes et les minuteurs.",
                "parameters": {
                    "action": {
                        "type": "STRING",
                        "description": "L'action √† effectuer (create_alarm, create_timer, show_matching_alarms, show_matching_timers, modify_alarm_v2, modify_timer_v2, snooze).",
                        "required": True,
                        "enum": ["create_alarm", "create_timer", "show_matching_alarms", "show_matching_timers", "modify_alarm_v2", "modify_timer_v2", "snooze"]
                    },
                    "duration": {"type": "STRING", "description": "Dur√©e pour le minuteur ou l'alarme (ex: '30 minutes', '1h 30m').", "required": False},
                    "time": {"type": "STRING", "description": "Heure sp√©cifique pour l'alarme (ex: '07:00 AM', '14:30').", "required": False},
                    "date": {"type": "STRING", "description": "Date sp√©cifique pour l'alarme (ex: '2023-12-25', 'demain').", "required": False},
                    "label": {"type": "STRING", "description": "√âtiquette ou description pour l'alarme/minuteur.", "required": False},
                    "recurrence": {"type": "ARRAY", "items": {"type": "STRING"}, "description": "Jours de la semaine pour la r√©currence de l'alarme (ex: ['MONDAY', 'WEDNESDAY']).", "required": False},
                    "query": {"type": "STRING", "description": "Requ√™te de recherche pour les alarmes/minuteurs.", "required": False},
                    "alarm_type": {"type": "STRING", "description": "Type d'alarme √† afficher (ex: 'active', 'snoozed').", "required": False},
                    "alarm_ids": {"type": "ARRAY", "items": {"type": "STRING"}, "description": "Liste des IDs d'alarmes √† afficher ou modifier.", "required": False},
                    "timer_type": {"type": "STRING", "description": "Type de minuteur √† afficher (ex: 'running', 'paused').", "required": False},
                    "timer_ids": {"type": "ARRAY", "items": {"type": "STRING"}, "description": "Liste des IDs de minuteurs √† afficher ou modifier.", "required": False},
                    "alarm_filters": {"type": "OBJECT", "description": "Filtres pour s√©lectionner les alarmes √† modifier.", "required": False},
                    "alarm_modifications": {"type": "OBJECT", "description": "Modifications √† appliquer aux alarmes s√©lectionn√©es.", "required": False},
                    "timer_filters": {"type": "OBJECT", "description": "Filtres pour s√©lectionner les minuteurs √† modifier.", "required": False},
                    "timer_modifications": {"type": "OBJECT", "description": "Modifications √† appliquer aux minuteurs s√©lectionn√©es.", "required": False}
                }
            },
            "ocr_space": {
                "enabled": True,
                "description": "Extrait le texte d'une image en utilisant la reconnaissance optique de caract√®res (OCR). L'image doit √™tre fournie sous forme de cha√Æne Base64 (data:image/png;base64,...).",
                "parameters": {
                    "image_base64": {"type": "STRING", "description": "L'image encod√©e en Base64, incluant le pr√©fixe MIME (ex: data:image/png;base64,iVB...).", "required": True}
                }
            },
            "deepseek_chat": {
                "enabled": True,
                "description": "Interagit avec le mod√®le de chat DeepSeek pour des conversations g√©n√©rales ou des t√¢ches de g√©n√©ration de texte. Utile pour des r√©ponses cr√©atives ou des discussions.",
                "parameters": {
                    "prompt": {"type": "STRING", "description": "Le prompt ou la liste de messages pour le mod√®le de chat.", "required": True},
                    "model": {"type": "STRING", "description": "Le nom du mod√®le DeepSeek √† utiliser (ex: 'deepseek-chat', 'deepseek-coder').", "required": False, "default": "deepseek-chat"}
                }
            },
            "serper_dev": {
                "enabled": True,
                "description": "Effectue une recherche web via l'API Serper. Utile pour obtenir des snippets et des liens pertinents pour une requ√™te.",
                "parameters": {
                    "query_text": {"type": "STRING", "description": "La requ√™te de recherche.", "required": True}
                }
            },
            "wolfram_alpha": {
                "enabled": True,
                "description": "Interroge WolframAlpha pour des calculs, des faits scientifiques, des conversions d'unit√©s, des informations math√©matiques, etc.",
                "parameters": {
                    "input_text": {"type": "STRING", "description": "La requ√™te √† soumettre √† WolframAlpha (ex: 'derivative of x^2', 'population of France').", "required": True}
                }
            },
            "tavily_search": {
                "enabled": True,
                "description": "Effectue une recherche web avanc√©e via l'API Tavily, fournissant des r√©ponses directes et des extraits pertinents.",
                "parameters": {
                    "query_text": {"type": "STRING", "description": "La requ√™te de recherche.", "required": True},
                    "max_results": {"type": "INTEGER", "description": "Nombre maximum de r√©sultats √† retourner.", "required": False, "default": 3}
                }
            },
            "apiflash_screenshot": {
                "enabled": True,
                "description": "Capture une capture d'√©cran d'une page web √† partir d'une URL donn√©e. Retourne une URL vers l'image captur√©e.",
                "parameters": {
                    "url": {"type": "STRING", "description": "L'URL de la page web √† capturer.", "required": True}
                }
            },
            "crawlbase_scraper": {
                "enabled": True,
                "description": "Scrape le contenu HTML ou JavaScript d'une URL. Peut √™tre utilis√© pour obtenir le contenu brut d'une page web.",
                "parameters": {
                    "url": {"type": "STRING", "description": "L'URL de la page web √† scraper.", "required": True},
                    "use_js": {"type": "BOOLEAN", "description": "Indique si le scraping doit ex√©cuter JavaScript sur la page.", "required": False, "default": False}
                }
            },
            "detect_language": {
                "enabled": True,
                "description": "D√©tecte la langue d'un texte donn√©.",
                "parameters": {
                    "text": {"type": "STRING", "description": "Le texte dont la langue doit √™tre d√©tect√©e.", "required": True}
                }
            },
            "guardian_news": {
                "enabled": True,
                "description": "Recherche des articles de presse sur The Guardian. Utile pour des actualit√©s ou des informations sp√©cifiques.",
                "parameters": {
                    "query_text": {"type": "STRING", "description": "La requ√™te de recherche pour les articles.", "required": True}
                }
            },
            "ip2location": {
                "enabled": True,
                "description": "G√©olocalise une adresse IP pour obtenir des informations sur le pays, la ville, etc.",
                "parameters": {
                    "ip_address": {"type": "STRING", "description": "L'adresse IP √† g√©olocaliser.", "required": True}
                }
            },
            "shodan": {
                "enabled": True,
                "description": "Interroge Shodan pour des informations sur un h√¥te IP ou des informations sur la cl√© API. Si une IP est fournie, retourne les infos de l'h√¥te, sinon les infos de la cl√© API.",
                "parameters": {
                    "query_text": {"type": "STRING", "description": "L'adresse IP √† rechercher ou vide pour les infos de la cl√© API.", "required": False, "default": ""}
                }
            },
            "weather_api": {
                "enabled": True,
                "description": "R√©cup√®re les conditions m√©t√©orologiques actuelles pour une localisation donn√©e.",
                "parameters": {
                    "location": {"type": "STRING", "description": "La ville ou le code postal pour la m√©t√©o.", "required": True}
                }
            },
            "cloudmersive_domain": {
                "enabled": True,
                "description": "V√©rifie la validit√© et le type d'un nom de domaine via Cloudmersive API.",
                "parameters": {
                    "domain": {"type": "STRING", "description": "Le nom de domaine √† v√©rifier.", "required": True}
                }
            },
            "greynoise": {
                "enabled": True,
                "description": "Analyse une adresse IP pour d√©tecter si elle est associ√©e √† des activit√©s 'bruit' (scans, attaques, etc.) via GreyNoise.",
                "parameters": {
                    "ip_address": {"type": "STRING", "description": "L'adresse IP √† analyser.", "required": True}
                }
            },
            "pulsedive": {
                "enabled": True,
                "description": "Analyse un indicateur de menace (IP, domaine, URL) via Pulsedive pour obtenir des informations sur les risques.",
                "parameters": {
                    "indicator": {"type": "STRING", "description": "L'indicateur de menace √† analyser (ex: '8.8.8.8', 'example.com').", "required": True},
                    "type": {"type": "STRING", "description": "Le type d'indicateur ('auto', 'ip', 'domain', 'url').", "required": False, "default": "auto", "enum": ["auto", "ip", "domain", "url"]}
                }
            },
            "stormglass": {
                "enabled": True,
                "description": "R√©cup√®re les donn√©es m√©t√©orologiques maritimes (temp√©rature de l'air, hauteur des vagues, etc.) pour une coordonn√©e g√©ographique.",
                "parameters": {
                    "lat": {"type": "NUMBER", "description": "Latitude.", "required": True},
                    "lng": {"type": "NUMBER", "description": "Longitude.", "required": True},
                    "params": {"type": "STRING", "description": "Param√®tres m√©t√©o √† r√©cup√©rer (comma-separated, ex: 'airTemperature,waveHeight').", "required": False, "default": "airTemperature,waveHeight"}
                }
            },
            "loginradius_ping": {
                "enabled": True,
                "description": "Effectue un simple ping √† l'API LoginRadius pour v√©rifier sa disponibilit√©. Ne n√©cessite aucun param√®tre.",
                "parameters": {}
            },
            "jsonbin_io": {
                "enabled": True,
                "description": "Cr√©e un nouveau 'bin' JSON pour stocker des donn√©es ou acc√®de √† un bin existant. Utile pour stocker temporairement des donn√©es structur√©es.",
                "parameters": {
                    "data": {"type": "OBJECT", "description": "Les donn√©es JSON √† stocker lors de la cr√©ation d'un bin.", "required": False},
                    "private": {"type": "BOOLEAN", "description": "Indique si le bin doit √™tre priv√©.", "required": False, "default": True},
                    "bin_id": {"type": "STRING", "description": "L'ID du bin existant √† acc√©der.", "required": False}
                }
            },
            "huggingface_inference": {
                "enabled": True,
                "description": "Effectue une inf√©rence sur un mod√®le HuggingFace (ex: classification de texte, g√©n√©ration de texte).",
                "parameters": {
                    "model_name": {"type": "STRING", "description": "Le nom du mod√®le HuggingFace √† utiliser (ex: 'distilbert-base-uncased-finetuned-sst-2-english').", "required": False, "default": "distilbert-base-uncased-finetuned-sst-2-english"},
                    "input_text": {"type": "STRING", "description": "Le texte d'entr√©e pour l'inf√©rence.", "required": True}
                }
            },
            "twilio_balance": {
                "enabled": True,
                "description": "R√©cup√®re le solde du compte Twilio. Utile pour v√©rifier les cr√©dits restants pour l'envoi de SMS/appels.",
                "parameters": {}
            },
            "abstractapi": {
                "enabled": True,
                "description": "Interroge diverses APIs d'AbstractAPI pour la validation d'emails/t√©l√©phones, les taux de change ou les jours f√©ri√©s.",
                "parameters": {
                    "input_value": {"type": "STRING", "description": "La valeur d'entr√©e (email, num√©ro de t√©l√©phone, devise de base, code pays) selon le type d'API.", "required": True},
                    "api_type": {"type": "STRING", "description": "Le type d'API AbstractAPI √† utiliser ('PHONE_VALIDATION', 'EMAIL_VALIDATION', 'EXCHANGE_RATES', 'HOLIDAYS').", "required": True, "enum": ["PHONE_VALIDATION", "EMAIL_VALIDATION", "EXCHANGE_RATES", "HOLIDAYS"]}
                }
            },
            "google_custom_search": {
                "enabled": True,
                "description": "Effectue une recherche personnalis√©e Google en utilisant l'API Custom Search. N√©cessite un ID de moteur de recherche personnalis√© (CSE ID).",
                "parameters": {
                    "query_text": {"type": "STRING", "description": "La requ√™te de recherche.", "required": True}
                }
            },
            "randommer_phone": {
                "enabled": True,
                "description": "G√©n√®re des num√©ros de t√©l√©phone al√©atoires pour un pays donn√©. Utile pour des donn√©es de test ou des exemples.",
                "parameters": {
                    "country_code": {"type": "STRING", "description": "Le code ISO du pays (ex: 'US', 'FR').", "required": False, "default": "US"},
                    "quantity": {"type": "INTEGER", "description": "Le nombre de num√©ros de t√©l√©phone √† g√©n√©rer.", "required": False, "default": 1}
                }
            },
            "tomorrow_io_weather": {
                "enabled": True,
                "description": "R√©cup√®re les pr√©visions m√©t√©orologiques d√©taill√©es via Tomorrow.io pour une localisation et des champs sp√©cifiques.",
                "parameters": {
                    "location": {"type": "STRING", "description": "La localisation (nom de ville, code postal, coordonn√©es lat/lng).", "required": True},
                    "fields": {"type": "ARRAY", "items": {"type": "STRING"}, "description": "Liste des champs m√©t√©o √† r√©cup√©rer (ex: ['temperature', 'humidity']).", "required": False, "default": ["temperature", "humidity", "windSpeed"]}
                }
            },
            "openweathermap_weather": {
                "enabled": True,
                "description": "R√©cup√®re les conditions m√©t√©orologiques actuelles via OpenWeatherMap pour une localisation donn√©e.",
                "parameters": {
                    "location": {"type": "STRING", "description": "La ville ou le code postal pour la m√©t√©o.", "required": True}
                }
            },
            "mockaroo_data": {
                "enabled": True,
                "description": "G√©n√®re des donn√©es de test al√©atoires via Mockaroo en fonction d'un sch√©ma JSON.",
                "parameters": {
                    "count": {"type": "INTEGER", "description": "Le nombre d'enregistrements √† g√©n√©rer.", "required": False, "default": 1},
                    "fields_json": {"type": "STRING", "description": "Un tableau JSON de d√©finitions de champs (ex: '[{\"name\":\"id\",\"type\":\"Row Number\"}]').", "required": False}
                }
            },
            "openpagerank": {
                "enabled": True,
                "description": "R√©cup√®re le PageRank de domaines via OpenPageRank. Utile pour √©valuer l'autorit√© d'un site web.",
                "parameters": {
                    "domains": {"type": "ARRAY", "items": {"type": "STRING"}, "description": "Liste des noms de domaine √† v√©rifier (ex: ['google.com', 'openai.com']).", "required": True}
                }
            },
            "rapidapi": {
                "enabled": True,
                "description": "Interroge diverses APIs disponibles via RapidAPI (blagues, taux de change, faits al√©atoires).",
                "parameters": {
                    "api_name": {"type": "STRING", "description": "Le nom de l'API RapidAPI √† utiliser (ex: 'Programming Joke', 'Currency List Quotes', 'Random Fact').", "required": True, "enum": ["Programming Joke", "Currency List Quotes", "Random Fact"]},
                    "api_kwargs": {"type": "OBJECT", "description": "Arguments sp√©cifiques √† l'API RapidAPI appel√©e.", "required": False}
                }
            },
            "run_in_sandbox": {
                "enabled": True,
                "description": "Ex√©cute du code Python ou Shell dans une sandbox s√©curis√©e. Utilisez cet outil pour tester ou ex√©cuter des extraits de code.",
                "parameters": {
                    "code": {"type": "STRING", "description": "Le code √† ex√©cuter.", "required": True},
                    "language": {"type": "STRING", "description": "Le langage du code ('python' ou 'shell').", "required": False, "default": "python", "enum": ["python", "shell"]}
                }
            },
            "webcontainer_sandbox": {
                "enabled": True,
                "description": "Ex√©cute du code dans un environnement WebContainer pour JavaScript/HTML/CSS.",
                "parameters": {
                    "code": {"type": "STRING", "description": "Le code √† ex√©cuter.", "required": True},
                    "language": {"type": "STRING", "description": "Le langage du code ('javascript', 'html', 'css').", "required": False, "default": "javascript"}
                }
            },
            "fetch_and_archive_pages": {
                "enabled": True,
                "description": "T√©l√©charge, s√©curise et archive des pages web avec protection contre les trackers.",
                "parameters": {
                    "links": {"type": "ARRAY", "items": {"type": "STRING"}, "description": "Liste des URLs √† archiver.", "required": True},
                    "user_id": {"type": "STRING", "description": "Identifiant de l'utilisateur pour l'archivage.", "required": True}
                }
            }
        }

# Instance globale de configuration
config = Config()

import requests
import json
import asyncio
import httpx
from typing import Dict, Any, List, Optional, Tuple, Union
import logging
from datetime import datetime
import random

from config import config
from app_singletons import endpoint_health_manager, quota_manager
from utils import log_message

class ApiClient:
    """
    Classe de base pour tous les clients API des 7 cerveaux autonomes.
    G√®re les requ√™tes HTTP, la rotation des cl√©s et le basculement automatique.
    """
    def __init__(self, service_name: str, config_manager: Any,
                 health_manager: Any, quota_manager: Any):
        self.service_name = service_name
        self.config = config_manager
        self.health_manager = health_manager
        self.quota_manager = quota_manager
        self.endpoints = self.config.API_CONFIG.get(service_name, [])
        self.current_endpoint_index = 0
        self.last_rotation_time = datetime.now()

        if not self.endpoints:
            log_message(f"Aucun endpoint configur√© pour le service {service_name}", level="warning")

    async def _make_request(self, endpoint_config: Dict[str, Any],
                          url_suffix: str = "", params: Optional[Dict] = None,
                          json_data: Optional[Dict] = None,
                          files: Optional[Dict] = None) -> Union[Dict, str]:
        """Effectue une requ√™te HTTP vers un endpoint sp√©cifique."""
        full_url = endpoint_config["url"] + url_suffix
        method = endpoint_config["method"]
        timeout = endpoint_config.get("timeout", 30)
        headers = endpoint_config.get("fixed_headers", {}).copy()
        req_params = endpoint_config.get("fixed_params", {}).copy()

        if params:
            req_params.update(params)

        key_field = endpoint_config.get("key_field")
        key_location = endpoint_config.get("key_location")
        key = endpoint_config.get("key")
        key_prefix = endpoint_config.get("key_prefix", "")

        if key:
            if key_location == "header":
                headers[key_field] = f"{key_prefix}{key}"
            elif key_location == "param":
                req_params[key_field] = key
            elif key_location == "auth_basic" and isinstance(key, tuple) and len(key) == 2:
                pass  # L'authentification sera g√©r√©e par httpx.AsyncClient

        async with httpx.AsyncClient() as client:
            try:
                log_message(f"Requ√™te {self.service_name} vers {full_url}")
                start_time = asyncio.get_event_loop().time()

                request_kwargs = {
                    "params": req_params,
                    "headers": headers,
                    "timeout": timeout
                }

                if json_data:
                    request_kwargs["json"] = json_data
                if files:
                    request_kwargs["files"] = files
                if key_location == "auth_basic" and isinstance(key, tuple) and len(key) == 2:
                    request_kwargs["auth"] = key

                if method == "POST":
                    response = await client.post(full_url, **request_kwargs)
                elif method == "GET":
                    response = await client.get(full_url, **request_kwargs)
                else:
                    raise ValueError(f"M√©thode HTTP non support√©e: {method}")

                response.raise_for_status()
                latency = asyncio.get_event_loop().time() - start_time
                log_message(f"R√©ponse {self.service_name}: {response.status_code} en {latency:.2f}s")

                try:
                    return response.json()
                except:
                    return {"status": "success", "content": response.text}

            except httpx.HTTPStatusError as e:
                log_message(f"API {self.service_name} erreur HTTP: {e.response.status_code} - {e.response.text}", level="warning")
                if 400 <= e.response.status_code < 500 and e.response.status_code not in [429]:
                    await self.health_manager.mark_unhealthy(endpoint_config["endpoint_name"], self.service_name, "API_CLIENT_ERROR")
                elif e.response.status_code >= 500:
                    await self.health_manager.mark_unhealthy(endpoint_config["endpoint_name"], self.service_name, "API_SERVER_ERROR")
                return f"‚ùå Erreur API {self.service_name}: {e.response.status_code} - {e.response.text}"

            except httpx.RequestError as e:
                log_message(f"API {self.service_name} erreur r√©seau: {e}", level="warning")
                await self.health_manager.mark_unhealthy(endpoint_config["endpoint_name"], self.service_name, "NETWORK_ERROR")
                return f"‚ùå Erreur r√©seau pour {self.service_name}: {e}"

            except Exception as e:
                log_message(f"API {self.service_name} erreur inattendue: {e}", level="error")
                await self.health_manager.mark_unhealthy(endpoint_config["endpoint_name"], self.service_name, "UNKNOWN_ERROR")
                return f"‚ùå Erreur inattendue pour {self.service_name}: {e}"

    async def _get_available_endpoint(self) -> Optional[Dict[str, Any]]:
        """S√©lectionne un endpoint sain et avec quota disponible."""
        num_endpoints = len(self.endpoints)
        if num_endpoints == 0:
            log_message(f"Aucun endpoint configur√© pour le service {self.service_name}.", level="warning")
            return None

        # Rotation pour les services LLM
        if self.service_name in ["GEMINI_API", "DEEPSEEK", "HUGGINGFACE"]:
            current_time = datetime.now()
            if (current_time - self.last_rotation_time).total_seconds() >= config.BRAIN_ROTATION_INTERVAL_SECONDS:
                self.current_endpoint_index = (self.current_endpoint_index + 1) % num_endpoints
                self.last_rotation_time = current_time
                log_message(f"Rotation d'endpoint pour {self.service_name}. Nouvel index: {self.current_endpoint_index}")

        # Essayer tous les endpoints
        initial_index = self.current_endpoint_index
        for _ in range(num_endpoints):
            endpoint_config = self.endpoints[self.current_endpoint_index]
            endpoint_name = endpoint_config["endpoint_name"]

            is_healthy = await self.health_manager.is_healthy(endpoint_name, self.service_name)
            has_quota = await self.quota_manager.check_quota(self.service_name)

            log_message(f"V√©rification endpoint {endpoint_name} pour {self.service_name}: Sain={is_healthy}, Quota={has_quota}")

            if is_healthy and has_quota:
                log_message(f"Endpoint s√©lectionn√© pour {self.service_name}: {endpoint_name}")
                return endpoint_config
            else:
                self.current_endpoint_index = (self.current_endpoint_index + 1) % num_endpoints
                log_message(f"Endpoint {endpoint_name} non disponible. Passage au suivant.")
                if self.current_endpoint_index == initial_index:
                    break

        log_message(f"Aucun endpoint sain ou disponible pour {self.service_name}.", level="warning")
        return None

    async def _increment_quota(self):
        """Incr√©mente le quota pour le service."""
        await self.quota_manager.increment_quota(self.service_name)

class LLMApiClient(ApiClient):
    """Classe de base pour les clients d'API de mod√®les de langage."""
    def __init__(self, service_name: str, config_manager: Any,
                 health_manager: Any, quota_manager: Any):
        super().__init__(service_name, config_manager, health_manager, quota_manager)
        self.default_model: str = ""

    async def generate_content(self, prompt: Union[str, List[Dict[str, Any]]],
                              chat_history: List[Dict[str, Any]],
                              image_data: Optional[str] = None,
                              tools: Optional[List[Dict]] = None,
                              model_name: Optional[str] = None) -> Union[Dict, str]:
        """M√©thode abstraite pour g√©n√©rer du contenu."""
        raise NotImplementedError("La m√©thode 'generate_content' doit √™tre impl√©ment√©e par les sous-classes.")

class GeminiApiClient(LLMApiClient):
    """Client API pour Gemini avec support complet des 7 cerveaux autonomes."""
    def __init__(self, health_manager: Any, quota_manager: Any):
        super().__init__("GEMINI_API", config, health_manager, quota_manager)
        self.default_model = "gemini-1.5-flash-latest"
        log_message(f"GeminiApiClient initialis√© avec le mod√®le par d√©faut: {self.default_model}")

    async def generate_content(self, prompt: Union[str, List[Dict[str, Any]]],
                              chat_history: List[Dict[str, Any]],
                              image_data: Optional[str] = None,
                              tools: Optional[List[Dict]] = None,
                              model_name: Optional[str] = None) -> Union[Dict, str]:
        """G√©n√®re du contenu textuel en utilisant le mod√®le Gemini."""
        import google.generativeai as genai

        log_message(f"Appel √† Gemini API pour le mod√®le {model_name or self.default_model}")

        endpoint_config = await self._get_available_endpoint()
        if not endpoint_config:
            return f"‚ùå Erreur Gemini: Aucun endpoint sain ou disponible pour {self.service_name}."

        genai.configure(api_key=endpoint_config["key"])
        log_message(f"Configuration de genai avec la cl√© de l'endpoint: {endpoint_config['endpoint_name']}")

        await self._increment_quota()

        # Pr√©paration du contenu
        contents = []
        for msg in chat_history:
            formatted_parts = []
            for part in msg.get("parts", []):
                if "text" in part:
                    formatted_parts.append(part["text"])
                elif "function_response" in part:
                    formatted_parts.append(genai.types.FunctionResponse(
                        name=part["function_response"]["name"],
                        response=part["function_response"]["response"]
                    ))
                elif "function_call" in part:
                    formatted_parts.append(genai.types.FunctionCall(
                        name=part["function_call"]["name"],
                        args=part["function_call"]["args"]
                    ))
                elif "inlineData" in part:
                    formatted_parts.append(genai.types.Blob(
                        mime_type=part["inlineData"]["mimeType"],
                        data=part["inlineData"]["data"]
                    ))
            contents.append({"role": msg["role"], "parts": formatted_parts})

        # Ajout du prompt actuel
        user_parts = []
        if isinstance(prompt, str):
            user_parts.append(prompt)
        elif isinstance(prompt, list):
            user_parts.extend(prompt)

        if image_data:
            mime_type = image_data.split(';')[0].split(':')[1]
            base64_string = image_data.split(',')[1]
            user_parts.append(genai.types.Blob(mime_type=mime_type, data=base64_string))

        contents.append({"role": "user", "parts": user_parts})

        # Pr√©paration des outils
        genai_tools = None
        if tools:
            genai_tools = [genai.types.FunctionDeclaration(**tool["function_declarations"][0]) 
                          for tool in tools if "function_declarations" in tool and tool["function_declarations"]]

        try:
            model_to_use = model_name if model_name else self.default_model
            model_instance = genai.GenerativeModel(model_to_use, tools=genai_tools)

            response = await model_instance.generate_content_async(
                contents=contents,
                generation_config=genai.types.GenerationConfig(
                    temperature=config.GEMINI_TEMPERATURE,
                    top_p=config.GEMINI_TOP_P,
                    top_k=config.GEMINI_TOP_K,
                    max_output_tokens=config.GEMINI_MAX_OUTPUT_TOKENS,
                ),
                safety_settings=config.GEMINI_SAFETY_SETTINGS,
            )

            response_dict = response.to_dict()
            return response_dict

        except Exception as e:
            log_message(f"API GEMINI_API erreur sur l'endpoint {endpoint_config['endpoint_name']}: {e}", level="error")
            if "PERMISSION_DENIED" in str(e) or "RESOURCE_EXHAUSTED" in str(e):
                await self.health_manager.mark_unhealthy(endpoint_config["endpoint_name"], self.service_name, "PERMISSION_DENIED_OR_QUOTA_EXCEEDED")
                return f"‚ùå Erreur Gemini (√† r√©essayer): {e}"
            else:
                await self.health_manager.mark_unhealthy(endpoint_config["endpoint_name"], self.service_name, "API_ERROR")
                return f"‚ùå Erreur Gemini: {e}"

class TelegramBotClient(ApiClient):
    """Client API pour l'API Bot de Telegram."""
    def __init__(self, health_manager: Any, quota_manager: Any):
        super().__init__("TELEGRAM_BOT", config, health_manager, quota_manager)
        
        if not self.endpoints:
            self.endpoints.append({
                "endpoint_name": "Telegram Bot API",
                "url": f"https://api.telegram.org/bot{config.TELEGRAM_BOT_TOKEN}",
                "method": "POST",
                "key_field": None,
                "key_location": None,
                "key": config.TELEGRAM_BOT_TOKEN,
                "timeout": 10,
                "fixed_headers": {"Content-Type": "application/json"},
                "health_check_url_suffix": "/getMe",
                "health_check_json": {}
            })
        log_message("TelegramBotClient initialis√©.")

    async def send_message(self, chat_id: Union[int, str], text: str, parse_mode: Optional[str] = None) -> Union[Dict, str]:
        """Envoie un message texte √† un chat Telegram sp√©cifi√©."""
        endpoint_config = await self._get_available_endpoint()
        if not endpoint_config:
            return f"‚ùå Erreur Telegram: Aucun endpoint sain ou disponible."

        await self._increment_quota()

        json_data = {
            "chat_id": chat_id,
            "text": text,
        }
        if parse_mode:
            json_data["parse_mode"] = parse_mode

        send_message_url_suffix = "/sendMessage"
        return await self._make_request(endpoint_config, url_suffix=send_message_url_suffix, json_data=json_data)

# Clients API sp√©cialis√©s pour chaque service

class WebContainerClient(ApiClient):
    def __init__(self, health_manager: Any, quota_manager: Any):
        super().__init__("WEBCONTAINER", config, health_manager, quota_manager)

    async def run_code(self, code: str, language: str = "javascript") -> Union[Dict, str]:
        endpoint_config = await self._get_available_endpoint()
        if not endpoint_config:
            return f"‚ùå Erreur WebContainer: Aucun endpoint sain ou disponible."

        await self._increment_quota()
        json_data = {
            "action": "execute",
            "language": language,
            "code": code
        }
        return await self._make_request(endpoint_config, json_data=json_data)

class OCRApiClient(ApiClient):
    def __init__(self, health_manager: Any, quota_manager: Any):
        super().__init__("OCR_API", config, health_manager, quota_manager)

    async def parse_image(self, image_base64: str, language: str = "eng") -> Union[Dict, str]:
        endpoint_config = await self._get_available_endpoint()
        if not endpoint_config:
            return f"‚ùå Erreur OCR: Aucun endpoint sain ou disponible."

        await self._increment_quota()
        json_data = {
            "base64Image": image_base64,
            "language": language,
            "isOverlayRequired": False
        }
        return await self._make_request(endpoint_config, json_data=json_data)

class DeepSeekClient(ApiClient):
    def __init__(self, health_manager: Any, quota_manager: Any):
        super().__init__("DEEPSEEK", config, health_manager, quota_manager)

    async def chat_completion(self, messages: List[Dict[str, str]], model: str = "deepseek-chat") -> Union[Dict, str]:
        endpoint_config = await self._get_available_endpoint()
        if not endpoint_config:
            return f"‚ùå Erreur DeepSeek: Aucun endpoint sain ou disponible."

        await self._increment_quota()
        json_data = {
            "model": model,
            "messages": messages
        }
        return await self._make_request(endpoint_config, json_data=json_data)

class SerperClient(ApiClient):
    def __init__(self, health_manager: Any, quota_manager: Any):
        super().__init__("SERPER", config, health_manager, quota_manager)

    async def search(self, query: str) -> Union[Dict, str]:
        endpoint_config = await self._get_available_endpoint()
        if not endpoint_config:
            return f"‚ùå Erreur Serper: Aucun endpoint sain ou disponible."

        await self._increment_quota()
        json_data = {"q": query}
        return await self._make_request(endpoint_config, json_data=json_data)

class WolframAlphaClient(ApiClient):
    def __init__(self, health_manager: Any, quota_manager: Any):
        super().__init__("WOLFRAMALPHA", config, health_manager, quota_manager)

    async def query(self, input_text: str) -> Union[Dict, str]:
        endpoint_config = await self._get_available_endpoint()
        if not endpoint_config:
            return f"‚ùå Erreur WolframAlpha: Aucun endpoint sain ou disponible."

        await self._increment_quota()
        params = {"input": input_text, "output": "json"}
        return await self._make_request(endpoint_config, params=params)

class TavilyClient(ApiClient):
    def __init__(self, health_manager: Any, quota_manager: Any):
        super().__init__("TAVILY", config, health_manager, quota_manager)

    async def search(self, query: str, max_results: int = 3) -> Union[Dict, str]:
        endpoint_config = await self._get_available_endpoint()
        if not endpoint_config:
            return f"‚ùå Erreur Tavily: Aucun endpoint sain ou disponible."

        await self._increment_quota()
        json_data = {"query": query, "max_results": max_results}
        return await self._make_request(endpoint_config, json_data=json_data)

class ApiFlashClient(ApiClient):
    def __init__(self, health_manager: Any, quota_manager: Any):
        super().__init__("APIFLASH", config, health_manager, quota_manager)

    async def screenshot(self, url: str) -> Union[Dict, str]:
        endpoint_config = await self._get_available_endpoint()
        if not endpoint_config:
            return f"‚ùå Erreur ApiFlash: Aucun endpoint sain ou disponible."

        await self._increment_quota()
        params = {"url": url, "format": "jpeg"}
        return await self._make_request(endpoint_config, params=params)

class CrawlbaseClient(ApiClient):
    def __init__(self, health_manager: Any, quota_manager: Any):
        super().__init__("CRAWLBASE", config, health_manager, quota_manager)

    async def scrape(self, url: str, use_js: bool = False) -> Union[Dict, str]:
        endpoint_config = await self._get_available_endpoint()
        if not endpoint_config:
            return f"‚ùå Erreur Crawlbase: Aucun endpoint sain ou disponible."

        await self._increment_quota()
        params = {"url": url}
        if use_js:
            params["javascript"] = "true"
        return await self._make_request(endpoint_config, params=params)

class DetectLanguageClient(ApiClient):
    def __init__(self, health_manager: Any, quota_manager: Any):
        super().__init__("DETECTLANGUAGE", config, health_manager, quota_manager)

    async def detect(self, text: str) -> Union[Dict, str]:
        endpoint_config = await self._get_available_endpoint()
        if not endpoint_config:
            return f"‚ùå Erreur DetectLanguage: Aucun endpoint sain ou disponible."

        await self._increment_quota()
        json_data = {"q": text}
        return await self._make_request(endpoint_config, json_data=json_data)

class GuardianClient(ApiClient):
    def __init__(self, health_manager: Any, quota_manager: Any):
        super().__init__("GUARDIAN", config, health_manager, quota_manager)

    async def search_news(self, query: str) -> Union[Dict, str]:
        endpoint_config = await self._get_available_endpoint()
        if not endpoint_config:
            return f"‚ùå Erreur Guardian: Aucun endpoint sain ou disponible."

        await self._increment_quota()
        params = {"q": query}
        return await self._make_request(endpoint_config, params=params)

class IP2LocationClient(ApiClient):
    def __init__(self, health_manager: Any, quota_manager: Any):
        super().__init__("IP2LOCATION", config, health_manager, quota_manager)

    async def geolocate_ip(self, ip_address: str) -> Union[Dict, str]:
        endpoint_config = await self._get_available_endpoint()
        if not endpoint_config:
            return f"‚ùå Erreur IP2Location: Aucun endpoint sain ou disponible."

        await self._increment_quota()
        params = {"ip": ip_address, "package": "WS24", "format": "json"}
        return await self._make_request(endpoint_config, params=params)

class ShodanClient(ApiClient):
    def __init__(self, health_manager: Any, quota_manager: Any):
        super().__init__("SHODAN", config, health_manager, quota_manager)

    async def get_info(self, query_text: str = "") -> Union[Dict, str]:
        endpoint_config = await self._get_available_endpoint()
        if not endpoint_config:
            return f"‚ùå Erreur Shodan: Aucun endpoint sain ou disponible."

        await self._increment_quota()

        if query_text:
            url_suffix = f"/{query_text}"
            return await self._make_request(endpoint_config, url_suffix=url_suffix)
        else:
            api_info_endpoint = next((ep for ep in self.endpoints if "API Info" in ep.get("endpoint_name", "")), None)
            if api_info_endpoint:
                return await self._make_request(api_info_endpoint)
            else:
                return "‚ùå Erreur Shodan: Endpoint 'API Info' non trouv√© dans la configuration."

class WeatherAPIClient(ApiClient):
    def __init__(self, health_manager: Any, quota_manager: Any):
        super().__init__("WEATHERAPI", config, health_manager, quota_manager)

    async def get_current_weather(self, location: str) -> Union[Dict, str]:
        endpoint_config = await self._get_available_endpoint()
        if not endpoint_config:
            return f"‚ùå Erreur WeatherAPI: Aucun endpoint sain ou disponible."

        await self._increment_quota()
        params = {"q": location}
        return await self._make_request(endpoint_config, params=params)

class CloudmersiveClient(ApiClient):
    def __init__(self, health_manager: Any, quota_manager: Any):
        super().__init__("CLOUDMERSIVE", config, health_manager, quota_manager)

    async def validate_domain(self, domain: str) -> Union[Dict, str]:
        endpoint_config = await self._get_available_endpoint()
        if not endpoint_config:
            return f"‚ùå Erreur Cloudmersive: Aucun endpoint sain ou disponible."

        await self._increment_quota()
        json_data = {"domain": domain}
        return await self._make_request(endpoint_config, json_data=json_data)

class GreyNoiseClient(ApiClient):
    def __init__(self, health_manager: Any, quota_manager: Any):
        super().__init__("GREYNOISE", config, health_manager, quota_manager)

    async def ip_lookup(self, ip_address: str) -> Union[Dict, str]:
        endpoint_config = await self._get_available_endpoint()
        if not endpoint_config:
            return f"‚ùå Erreur GreyNoise: Aucun endpoint sain ou disponible."

        await self._increment_quota()
        url_suffix = f"/{ip_address}"
        return await self._make_request(endpoint_config, url_suffix=url_suffix)

class PulsediveClient(ApiClient):
    def __init__(self, health_manager: Any, quota_manager: Any):
        super().__init__("PULSEDIVE", config, health_manager, quota_manager)

    async def analyze_indicator(self, indicator: str, type: str = "auto") -> Union[Dict, str]:
        endpoint_config = await self._get_available_endpoint()
        if not endpoint_config:
            return f"‚ùå Erreur Pulsedive: Aucun endpoint sain ou disponible."

        await self._increment_quota()
        params = {"indicator": indicator, "type": type}
        return await self._make_request(endpoint_config, params=params)

class StormGlassClient(ApiClient):
    def __init__(self, health_manager: Any, quota_manager: Any):
        super().__init__("STORMGLASS", config, health_manager, quota_manager)

    async def get_weather_point(self, lat: float, lng: float, params: str = "airTemperature,waveHeight") -> Union[Dict, str]:
        endpoint_config = await self._get_available_endpoint()
        if not endpoint_config:
            return f"‚ùå Erreur StormGlass: Aucun endpoint sain ou disponible."

        await self._increment_quota()
        req_params = {"lat": lat, "lng": lng, "params": params}
        return await self._make_request(endpoint_config, params=req_params)

class LoginRadiusClient(ApiClient):
    def __init__(self, health_manager: Any, quota_manager: Any):
        super().__init__("LOGINRADIUS", config, health_manager, quota_manager)

    async def ping(self) -> Union[Dict, str]:
        endpoint_config = await self._get_available_endpoint()
        if not endpoint_config:
            return f"‚ùå Erreur LoginRadius: Aucun endpoint sain ou disponible."

        await self._increment_quota()
        return await self._make_request(endpoint_config)

class JsonbinClient(ApiClient):
    def __init__(self, health_manager: Any, quota_manager: Any):
        super().__init__("JSONBIN", config, health_manager, quota_manager)

    async def handle_bin(self, data: Optional[Dict] = None, private: bool = True, bin_id: Optional[str] = None) -> Union[Dict, str]:
        endpoint_config = await self._get_available_endpoint()
        if not endpoint_config:
            return f"‚ùå Erreur Jsonbin: Aucun endpoint sain ou disponible."

        await self._increment_quota()

        if bin_id:
            access_endpoint = next((ep for ep in self.endpoints if "Bin Access" in ep.get("endpoint_name", "")), None)
            if not access_endpoint:
                return "‚ùå Erreur Jsonbin: Endpoint 'Bin Access' non trouv√© dans la configuration."
            return await self._make_request(access_endpoint, url_suffix=f"/{bin_id}")
        elif data:
            create_endpoint = next((ep for ep in self.endpoints if "Bin Create" in ep.get("endpoint_name", "")), None)
            if not create_endpoint:
                return "‚ùå Erreur Jsonbin: Endpoint 'Bin Create' non trouv√© dans la configuration."
            json_data = {"record": data, "private": private}
            return await self._make_request(create_endpoint, json_data=json_data)
        else:
            return "‚ùå Erreur Jsonbin: Veuillez fournir des donn√©es pour cr√©er un bin ou un ID de bin pour y acc√©der."

class HuggingFaceClient(ApiClient):
    def __init__(self, health_manager: Any, quota_manager: Any):
        super().__init__("HUGGINGFACE", config, health_manager, quota_manager)

    async def inference(self, model_name: str, input_text: str) -> Union[Dict, str]:
        endpoint_config = await self._get_available_endpoint()
        if not endpoint_config:
            return f"‚ùå Erreur HuggingFace: Aucun endpoint sain ou disponible."

        await self._increment_quota()
        url_suffix = model_name
        json_data = {"inputs": input_text}
        return await self._make_request(endpoint_config, url_suffix=url_suffix, json_data=json_data)

class TwilioClient(ApiClient):
    def __init__(self, health_manager: Any, quota_manager: Any):
        super().__init__("TWILIO", config, health_manager, quota_manager)

    async def get_account_balance(self) -> Union[Dict, str]:
        endpoint_config = await self._get_available_endpoint()
        if not endpoint_config:
            return f"‚ùå Erreur Twilio: Aucun endpoint sain ou disponible."

        await self._increment_quota()
        return await self._make_request(endpoint_config)

class AbstractAPIClient(ApiClient):
    def __init__(self, health_manager: Any, quota_manager: Any):
        super().__init__("ABSTRACTAPI", config, health_manager, quota_manager)

    async def call_api(self, input_value: str, api_type: str) -> Union[Dict, str]:
        endpoint_config = await self._get_available_endpoint()
        if not endpoint_config:
            return f"‚ùå Erreur AbstractAPI: Aucun endpoint sain ou disponible."

        await self._increment_quota()

        params = {}
        url_suffix = ""

        if api_type == "EMAIL_VALIDATION":
            email_endpoint = next((ep for ep in self.endpoints if "Email Validation" in ep.get("endpoint_name", "")), None)
            if not email_endpoint:
                return "‚ùå Erreur AbstractAPI: Endpoint de validation d'email non configur√©."
            params["email"] = input_value
            endpoint_config = email_endpoint
        elif api_type == "PHONE_VALIDATION":
            phone_endpoint = next((ep for ep in self.endpoints if "Phone Validation" in ep.get("endpoint_name", "")), None)
            if not phone_endpoint:
                return "‚ùå Erreur AbstractAPI: Endpoint de validation de t√©l√©phone non configur√©."
            params["phone"] = input_value
            endpoint_config = phone_endpoint
        elif api_type == "EXCHANGE_RATES":
            exchange_endpoint = next((ep for ep in self.endpoints if "Exchange Rates" in ep.get("endpoint_name", "")), None)
            if not exchange_endpoint:
                return "‚ùå Erreur AbstractAPI: Endpoint de taux de change non configur√©."
            params["base"] = input_value
            endpoint_config = exchange_endpoint
        elif api_type == "HOLIDAYS":
            holidays_endpoint = next((ep for ep in self.endpoints if "Holidays" in ep.get("endpoint_name", "")), None)
            if not holidays_endpoint:
                return "‚ùå Erreur AbstractAPI: Endpoint de jours f√©ri√©s non configur√©."
            params["country"] = input_value
            params["year"] = datetime.now().year
            endpoint_config = holidays_endpoint
        else:
            return f"‚ùå Type d'API AbstractAPI non support√©: {api_type}"

        return await self._make_request(endpoint_config, params=params, url_suffix=url_suffix)

class GoogleCustomSearchClient(ApiClient):
    def __init__(self, health_manager: Any, quota_manager: Any):
        super().__init__("GOOGLE_CUSTOM_SEARCH", config, health_manager, quota_manager)

    async def search(self, query: str) -> Union[Dict, str]:
        endpoint_config = await self._get_available_endpoint()
        if not endpoint_config:
            return f"‚ùå Erreur Google Custom Search: Aucun endpoint sain ou disponible."

        await self._increment_quota()
        params = {"q": query}
        return await self._make_request(endpoint_config, params=params)

class RandommerClient(ApiClient):
    def __init__(self, health_manager: Any, quota_manager: Any):
        super().__init__("RANDOMMER", config, health_manager, quota_manager)

    async def generate_phone_number(self, country_code: str = "US", quantity: int = 1) -> Union[Dict, str]:
        endpoint_config = await self._get_available_endpoint()
        if not endpoint_config:
            return f"‚ùå Erreur Randommer: Aucun endpoint sain ou disponible."

        await self._increment_quota()
        params = {"CountryCode": country_code, "Quantity": quantity}
        return await self._make_request(endpoint_config, params=params)

class TomorrowIOClient(ApiClient):
    def __init__(self, health_manager: Any, quota_manager: Any):
        super().__init__("TOMORROW.IO", config, health_manager, quota_manager)

    async def get_weather_timelines(self, location: str, fields: List[str]) -> Union[Dict, str]:
        endpoint_config = await self._get_available_endpoint()
        if not endpoint_config:
            return f"‚ùå Erreur Tomorrow.io: Aucun endpoint sain ou disponible."

        await self._increment_quota()
        json_data = {
            "location": location,
            "fields": fields,
            "units": "metric",
            "timesteps": ["1h"]
        }
        return await self._make_request(endpoint_config, json_data=json_data)

class OpenWeatherMapClient(ApiClient):
    def __init__(self, health_manager: Any, quota_manager: Any):
        super().__init__("OPENWEATHERMAP", config, health_manager, quota_manager)

    async def get_current_weather(self, location: str) -> Union[Dict, str]:
        endpoint_config = await self._get_available_endpoint()
        if not endpoint_config:
            return f"‚ùå Erreur OpenWeatherMap: Aucun endpoint sain ou disponible."

        await self._increment_quota()
        params = {"q": location}
        return await self._make_request(endpoint_config, params=params)

class MockarooClient(ApiClient):
    def __init__(self, health_manager: Any, quota_manager: Any):
        super().__init__("MOCKAROO", config, health_manager, quota_manager)

    async def generate_data(self, count: int = 1, fields_json: Optional[str] = None) -> Union[Dict, str]:
        endpoint_config = await self._get_available_endpoint()
        if not endpoint_config:
            return f"‚ùå Erreur Mockaroo: Aucun endpoint sain ou disponible."

        await self._increment_quota()
        params = {"count": count}
        if fields_json:
            params["fields"] = fields_json
        return await self._make_request(endpoint_config, params=params)

class OpenPageRankClient(ApiClient):
    def __init__(self, health_manager: Any, quota_manager: Any):
        super().__init__("OPENPAGERANK", config, health_manager, quota_manager)

    async def get_page_rank(self, domains: List[str]) -> Union[Dict, str]:
        endpoint_config = await self._get_available_endpoint()
        if not endpoint_config:
            return f"‚ùå Erreur OpenPageRank: Aucun endpoint sain ou disponible."

        await self._increment_quota()
        params = {"domains[]": domains}
        return await self._make_request(endpoint_config, params=params)

class RapidAPIClient(ApiClient):
    def __init__(self, health_manager: Any, quota_manager: Any):
        super().__init__("RAPIDAPI", config, health_manager, quota_manager)

    async def call_rapidapi_endpoint(self, api_name: str, api_kwargs: Optional[Dict] = None) -> Union[Dict, str]:
        endpoint_config = None
        if api_name == "Programming Joke":
            endpoint_config = next((ep for ep in self.endpoints if "Programming Joke" in ep.get("endpoint_name", "")), None)
        elif api_name == "Currency List Quotes":
            endpoint_config = next((ep for ep in self.endpoints if "Currency List Quotes" in ep.get("endpoint_name", "")), None)
        elif api_name == "Random Fact":
            endpoint_config = next((ep for ep in self.endpoints if "Random Fact" in ep.get("endpoint_name", "")), None)

        if not endpoint_config:
            return f"‚ùå Erreur RapidAPI: Endpoint '{api_name}' non trouv√© ou non configur√©."

        is_healthy = await self.health_manager.is_healthy(endpoint_config["endpoint_name"], self.service_name)
        has_quota = await self.quota_manager.check_quota(self.service_name)

        if not is_healthy or not has_quota:
            return f"‚ùå Erreur RapidAPI: Endpoint '{api_name}' non sain ou quota d√©pass√©."

        await self._increment_quota()
        params = api_kwargs if api_kwargs else {}
        return await self._make_request(endpoint_config, params=params)
        
        import google.generativeai as genai
from google.generativeai import types
import asyncio
from typing import Dict, Any, List, Optional, Union

from config import config
from app_singletons import endpoint_health_manager, quota_manager
from api_clients import (
    ApiClient, WebContainerClient, OCRApiClient, DeepSeekClient, SerperClient,
    WolframAlphaClient, TavilyClient, ApiFlashClient, CrawlbaseClient,
    DetectLanguageClient, GuardianClient, IP2LocationClient, ShodanClient,
    WeatherAPIClient, CloudmersiveClient, GreyNoiseClient, PulsediveClient,
    StormGlassClient, LoginRadiusClient, JsonbinClient, HuggingFaceClient,
    TwilioClient, AbstractAPIClient, GoogleCustomSearchClient,
    RandommerClient, TomorrowIOClient, OpenWeatherMapClient, MockarooClient,
    OpenPageRankClient, RapidAPIClient,
    GeminiApiClient, TelegramBotClient
)
from utils import log_message

# Instanciation de tous les clients API pour les 7 cerveaux autonomes
# Chaque client est instanci√© avec les gestionnaires de sant√© et de quotas

# Clients principaux pour les 7 cerveaux
gemini_client = GeminiApiClient(endpoint_health_manager, quota_manager)
telegram_bot_client = TelegramBotClient(endpoint_health_manager, quota_manager)

# Clients pour services auxiliaires
webcontainer_client = WebContainerClient(endpoint_health_manager, quota_manager)
ocr_client = OCRApiClient(endpoint_health_manager, quota_manager)
deepseek_client = DeepSeekClient(endpoint_health_manager, quota_manager)
serper_client = SerperClient(endpoint_health_manager, quota_manager)
wolfram_alpha_client = WolframAlphaClient(endpoint_health_manager, quota_manager)
tavily_client = TavilyClient(endpoint_health_manager, quota_manager)
apiflash_client = ApiFlashClient(endpoint_health_manager, quota_manager)
crawlbase_client = CrawlbaseClient(endpoint_health_manager, quota_manager)
detect_language_client = DetectLanguageClient(endpoint_health_manager, quota_manager)
guardian_client = GuardianClient(endpoint_health_manager, quota_manager)
ip2location_client = IP2LocationClient(endpoint_health_manager, quota_manager)
shodan_client = ShodanClient(endpoint_health_manager, quota_manager)
weather_api_client = WeatherAPIClient(endpoint_health_manager, quota_manager)
cloudmersive_client = CloudmersiveClient(endpoint_health_manager, quota_manager)
greynoise_client = GreyNoiseClient(endpoint_health_manager, quota_manager)
pulsedive_client = PulsediveClient(endpoint_health_manager, quota_manager)
stormglass_client = StormGlassClient(endpoint_health_manager, quota_manager)
loginradius_client = LoginRadiusClient(endpoint_health_manager, quota_manager)
jsonbin_client = JsonbinClient(endpoint_health_manager, quota_manager)
huggingface_client = HuggingFaceClient(endpoint_health_manager, quota_manager)
twilio_client = TwilioClient(endpoint_health_manager, quota_manager)
abstractapi_client = AbstractAPIClient(endpoint_health_manager, quota_manager)
google_custom_search_client = GoogleCustomSearchClient(endpoint_health_manager, quota_manager)
randommer_client = RandommerClient(endpoint_health_manager, quota_manager)
tomorrow_io_client = TomorrowIOClient(endpoint_health_manager, quota_manager)
openweathermap_client = OpenWeatherMapClient(endpoint_health_manager, quota_manager)
mockaroo_client = MockarooClient(endpoint_health_manager, quota_manager)
openpagerank_client = OpenPageRankClient(endpoint_health_manager, quota_manager)
rapidapi_client = RapidAPIClient(endpoint_health_manager, quota_manager)

# Log de l'initialisation
log_message("Tous les clients API ont √©t√© instanci√©s pour les 7 cerveaux autonomes")

# Dictionnaire pour acc√®s facile aux clients
API_CLIENTS = {
    "GEMINI": gemini_client,
    "TELEGRAM": telegram_bot_client,
    "WEBCONTAINER": webcontainer_client,
    "OCR": ocr_client,
    "DEEPSEEK": deepseek_client,
    "SERPER": serper_client,
    "WOLFRAM": wolfram_alpha_client,
    "TAVILY": tavily_client,
    "APIFLASH": apiflash_client,
    "CRAWLBASE": crawlbase_client,
    "DETECT_LANGUAGE": detect_language_client,
    "GUARDIAN": guardian_client,
    "IP2LOCATION": ip2location_client,
    "SHODAN": shodan_client,
    "WEATHER_API": weather_api_client,
    "CLOUDMERSIVE": cloudmersive_client,
    "GREYNOISE": greynoise_client,
    "PULSEDIVE": pulsedive_client,
    "STORMGLASS": stormglass_client,
    "LOGINRADIUS": loginradius_client,
    "JSONBIN": jsonbin_client,
    "HUGGINGFACE": huggingface_client,
    "TWILIO": twilio_client,
    "ABSTRACTAPI": abstractapi_client,
    "GOOGLE_SEARCH": google_custom_search_client,
    "RANDOMMER": randommer_client,
    "TOMORROW_IO": tomorrow_io_client,
    "OPENWEATHERMAP": openweathermap_client,
    "MOCKAROO": mockaroo_client,
    "OPENPAGERANK": openpagerank_client,
    "RAPIDAPI": rapidapi_client
}

def get_client(service_name: str) -> Optional[ApiClient]:
    """R√©cup√®re un client API par nom de service."""
    return API_CLIENTS.get(service_name.upper())

def get_all_clients() -> Dict[str, ApiClient]:
    """Retourne tous les clients API disponibles."""
    return API_CLIENTS.copy()

def get_healthy_clients() -> Dict[str, ApiClient]:
    """Retourne uniquement les clients avec des services sains."""
    healthy_clients = {}
    
    for service_name, client in API_CLIENTS.items():
        try:
            # V√©rification asynchrone de la sant√© - √† utiliser avec await
            # Pour l'instant, on retourne tous les clients
            healthy_clients[service_name] = client
        except Exception as e:
            log_message(f"Erreur v√©rification sant√© {service_name}: {e}", level="warning")
    
    return healthy_clients

async def test_all_clients() -> Dict[str, bool]:
    """Teste la connectivit√© de tous les clients."""
    results = {}
    
    for service_name, client in API_CLIENTS.items():
        try:
            # Test basique de connectivit√©
            if hasattr(client, '_get_available_endpoint'):
                endpoint = await client._get_available_endpoint()
                results[service_name] = endpoint is not None
            else:
                results[service_name] = True  # Assume healthy if no endpoint check
        except Exception as e:
            log_message(f"Erreur test client {service_name}: {e}", level="error")
            results[service_name] = False
    
    return results

# Fonctions utilitaires pour la gestion des clients

async def rotate_client_endpoints():
    """Force la rotation des endpoints pour tous les clients."""
    for service_name, client in API_CLIENTS.items():
        if hasattr(client, 'current_endpoint_index') and hasattr(client, 'endpoints'):
            if client.endpoints:
                client.current_endpoint_index = (client.current_endpoint_index + 1) % len(client.endpoints)
                log_message(f"Rotation forc√©e pour {service_name}, nouvel index: {client.current_endpoint_index}")

def get_client_statistics() -> Dict[str, Any]:
    """Retourne les statistiques des clients API."""
    stats = {
        "total_clients": len(API_CLIENTS),
        "services_configured": len(config.API_CONFIG),
        "clients_by_type": {},
        "endpoint_counts": {}
    }
    
    for service_name, client in API_CLIENTS.items():
        client_type = type(client).__name__
        if client_type not in stats["clients_by_type"]:
            stats["clients_by_type"][client_type] = 0
        stats["clients_by_type"][client_type] += 1
        
        if hasattr(client, 'endpoints'):
            stats["endpoint_counts"][service_name] = len(client.endpoints)
    
    return stats

# Validation de l'initialisation
def validate_clients_initialization() -> bool:
    """Valide que tous les clients essentiels sont initialis√©s."""
    essential_clients = ["GEMINI", "TELEGRAM", "DEEPSEEK", "SERPER", "WOLFRAM", "TAVILY"]
    
    for client_name in essential_clients:
        if client_name not in API_CLIENTS or API_CLIENTS[client_name] is None:
            log_message(f"Client essentiel {client_name} non initialis√©", level="error")
            return False
    
    log_message("Tous les clients essentiels sont initialis√©s")
    return True

# Ex√©cution de la validation
if validate_clients_initialization():
    log_message("‚úÖ Initialisation des clients API r√©ussie - Syst√®me pr√™t pour les 7 cerveaux autonomes")
else:
    log_message("‚ùå Erreur lors de l'initialisation des clients API", level="error")
    
    import time
import httpx
import json
import asyncio
import logging
from datetime import datetime, timezone, timedelta
from pathlib import Path
from typing import Dict, Any, Optional, Union, List, Tuple

from config import config
from utils import load_json, save_json, get_current_time, format_datetime, log_message

class EndpointHealthManager:
    """
    G√®re la sant√© des endpoints API pour les 7 cerveaux autonomes.
    Chaque cerveau peut avoir plusieurs endpoints et cl√©s de secours.
    """
    _instance = None
    _initialized = False

    def __new__(cls, *args, **kwargs):
        """Impl√©mentation du patron Singleton."""
        if cls._instance is None:
            cls._instance = super(cls, cls).__new__(cls)
        return cls._instance

    def __init__(self):
        """Initialise le gestionnaire de sant√© une seule fois."""
        if self._initialized:
            return
        self.health_status: Dict[str, Dict[str, Any]] = {}
        self._initialized = True
        log_message("Gestionnaire de sant√© des endpoints initialis√©.")

    async def init_manager(self):
        """Initialise le gestionnaire de mani√®re asynchrone."""
        self.health_status = await load_json(config.ENDPOINT_HEALTH_FILE, {})
        self._initialize_health_status()
        log_message("Gestionnaire de sant√© des endpoints charg√© et pr√™t.")

    def _initialize_health_status(self):
        """Initialise le statut de sant√© pour tous les endpoints configur√©s."""
        updated = False
        for service_name, endpoints_config in config.API_CONFIG.items():
            if service_name not in self.health_status:
                self.health_status[service_name] = {}
                updated = True
            
            for endpoint_config in endpoints_config:
                endpoint_key_base = endpoint_config['endpoint_name']
                api_key_part = ""
                
                if isinstance(endpoint_config['key'], tuple):
                    api_key_part = str(endpoint_config['key'][0])
                else:
                    api_key_part = str(endpoint_config['key'])
                
                endpoint_key = f"{endpoint_key_base}-{api_key_part[:8]}"
                
                if endpoint_key not in self.health_status[service_name]:
                    self.health_status[service_name][endpoint_key] = {
                        "latency": 0.0,
                        "success_rate": 1.0,
                        "last_checked": None,
                        "error_count": 0,
                        "total_checks": 0,
                        "is_healthy": True,
                        "last_error": None,
                        "consecutive_failures": 0
                    }
                    updated = True
        
        if updated:
            asyncio.create_task(save_json(config.ENDPOINT_HEALTH_FILE, self.health_status))
            log_message("Statut de sant√© des endpoints initialis√©/mis √† jour.")

    async def run_health_check_for_service(self, service_name: str):
        """Ex√©cute des health checks pour tous les endpoints d'un service."""
        endpoints_config = config.API_CONFIG.get(service_name)
        if not endpoints_config:
            log_message(f"Aucune configuration trouv√©e pour le service: {service_name}", level="warning")
            return

        log_message(f"Health check pour le service: {service_name}")
        
        for endpoint_config in endpoints_config:
            endpoint_key_base = endpoint_config['endpoint_name']
            api_key_part = ""
            
            if isinstance(endpoint_config['key'], tuple):
                api_key_part = str(endpoint_config['key'][0])
            else:
                api_key_part = str(endpoint_config['key'])
            
            endpoint_key = f"{endpoint_key_base}-{api_key_part[:8]}"
            
            start_time = time.monotonic()
            success = False
            
            try:
                request_method = endpoint_config.get("method", "GET")
                url = endpoint_config["url"]
                
                params = endpoint_config.get("health_check_params", {}).copy()
                json_data = endpoint_config.get("health_check_json", {}).copy()
                headers = endpoint_config.get("fixed_headers", {}).copy()
                auth = None
                
                check_timeout = endpoint_config.get("timeout", 10)
                
                if "health_check_url_suffix" in endpoint_config:
                    url += endpoint_config["health_check_url_suffix"]
                
                # Gestion des cl√©s API
                key_field = endpoint_config.get("key_field")
                key_location = endpoint_config.get("key_location")
                key_prefix = endpoint_config.get("key_prefix", "")
                api_key = endpoint_config["key"]
                
                if key_field and key_location:
                    if key_location == "param":
                        params[key_field] = api_key
                    elif key_location == "header":
                        headers[key_field] = f"{key_prefix}{api_key}"
                    elif key_location == "auth_basic":
                        if isinstance(api_key, tuple) and len(api_key) == 2:
                            auth = httpx.BasicAuth(api_key[0], api_key[1])
                        else:
                            log_message(f"Cl√© API auth_basic invalide pour {service_name}:{endpoint_key}", level="error")
                            continue
                
                # Ajouter des param√®tres fixes
                if "fixed_params" in endpoint_config:
                    params.update(endpoint_config["fixed_params"])
                
                async with httpx.AsyncClient(timeout=check_timeout) as client:
                    response = await client.request(
                        request_method, url, 
                        params=params, 
                        headers=headers, 
                        json=json_data, 
                        auth=auth
                    )
                    response.raise_for_status()
                    success = True
                    
            except httpx.HTTPStatusError as e:
                log_level = "warning"
                if 400 <= e.response.status_code < 500 and e.response.status_code != 429:
                    log_level = "debug"
                log_message(f"Health check {endpoint_key} ({service_name}) √©chec HTTP {e.response.status_code}", level=log_level)
                success = False
                
            except httpx.RequestError as e:
                log_message(f"Health check {endpoint_key} ({service_name}) √©chec r√©seau: {e}", level="warning")
                success = False
                
            except Exception as e:
                log_message(f"Health check {endpoint_key} ({service_name}) erreur: {e}", level="error")
                success = False
                
            finally:
                latency = time.monotonic() - start_time
                self.update_endpoint_health(service_name, endpoint_key, success, latency)

        log_message(f"Health check termin√© pour le service: {service_name}")

    def update_endpoint_health(self, service_name: str, endpoint_key: str, success: bool, latency: float):
        """Met √† jour le statut de sant√© d'un endpoint."""
        if service_name not in self.health_status:
            self.health_status[service_name] = {}
        
        if endpoint_key not in self.health_status[service_name]:
            self.health_status[service_name][endpoint_key] = {
                "latency": 0.0,
                "success_rate": 1.0,
                "last_checked": None,
                "error_count": 0,
                "total_checks": 0,
                "is_healthy": True,
                "last_error": None,
                "consecutive_failures": 0
            }
        
        status = self.health_status[service_name][endpoint_key]
        status["total_checks"] += 1
        status["last_checked"] = format_datetime(get_current_time())
        
        alpha = 0.1  # Facteur de lissage pour moyenne mobile
        
        if success:
            status["consecutive_failures"] = 0
            status["error_count"] = max(0, status["error_count"] - 1)
            status["success_rate"] = status["success_rate"] * (1 - alpha) + 1.0 * alpha
            status["latency"] = status["latency"] * (1 - alpha) + latency * alpha
            status["last_error"] = None
        else:
            status["consecutive_failures"] += 1
            status["error_count"] += 1
            status["success_rate"] = status["success_rate"] * (1 - alpha) + 0.0 * alpha
            status["latency"] = status["latency"] * (1 - alpha) + 10.0 * alpha
            status["last_error"] = format_datetime(get_current_time())
        
        # D√©termination de la sant√©
        if status["consecutive_failures"] >= 3 or status["success_rate"] < 0.5:
            status["is_healthy"] = False
        else:
            status["is_healthy"] = True
        
        # Sauvegarde asynchrone
        asyncio.create_task(save_json(config.ENDPOINT_HEALTH_FILE, self.health_status))
        
        log_level = "debug" if status["is_healthy"] else "warning"
        log_message(f"Sant√© {service_name}:{endpoint_key} - Succ√®s: {success}, Latence: {latency:.2f}s, Taux: {status['success_rate']:.2f}, Sain: {status['is_healthy']}", level=log_level)

    async def is_healthy(self, endpoint_name: str, service_name: str) -> bool:
        """V√©rifie si un endpoint sp√©cifique est sain."""
        service_health = self.health_status.get(service_name, {})
        
        # Recherche par nom d'endpoint
        for endpoint_key, status in service_health.items():
            if endpoint_name in endpoint_key:
                return status.get("is_healthy", False)
        
        return False

    async def is_service_healthy(self, service_name: str) -> bool:
        """V√©rifie si au moins un endpoint du service est sain."""
        service_health = self.health_status.get(service_name, {})
        
        if not service_health:
            return True  # Nouveau service consid√©r√© comme sain par d√©faut
        
        healthy_endpoints = [
            status for status in service_health.values()
            if status.get("is_healthy", False)
        ]
        
        return len(healthy_endpoints) > 0

    def get_best_endpoint(self, service_name: str) -> Optional[Dict]:
        """S√©lectionne le meilleur endpoint pour un service."""
        service_health = self.health_status.get(service_name)
        if not service_health:
            log_message(f"Aucune donn√©e de sant√© pour {service_name}", level="warning")
            return None

        # Filtre les endpoints sains
        healthy_endpoints = [
            (key, status) for key, status in service_health.items()
            if status["is_healthy"]
        ]

        if not healthy_endpoints:
            log_message(f"Aucun endpoint sain pour {service_name}", level="warning")
            # Utilise le moins d√©faillant comme fallback
            if service_health:
                sorted_endpoints = sorted(
                    service_health.items(),
                    key=lambda item: (item[1]["consecutive_failures"], item[1]["latency"])
                )
                best_endpoint_key = sorted_endpoints[0][0]
                log_message(f"Fallback: {best_endpoint_key} pour {service_name}", level="warning")
            else:
                return None
        else:
            # S√©lectionne le meilleur endpoint sain
            best_endpoint_key, _ = max(
                healthy_endpoints,
                key=lambda item: (item[1]["success_rate"] * 100) - (item[1]["latency"] * 10) - (item[1]["consecutive_failures"] * 5)
            )
            log_message(f"Meilleur endpoint pour {service_name}: {best_endpoint_key}")

        # Trouve la configuration compl√®te
        for endpoint_config in config.API_CONFIG.get(service_name, []):
            current_endpoint_key_base = endpoint_config['endpoint_name']
            api_key_part = ""
            
            if isinstance(endpoint_config['key'], tuple):
                api_key_part = str(endpoint_config['key'][0])
            else:
                api_key_part = str(endpoint_config['key'])
            
            current_endpoint_key = f"{current_endpoint_key_base}-{api_key_part[:8]}"
            
            if current_endpoint_key == best_endpoint_key:
                return endpoint_config

        return None

    def mark_unhealthy(self, endpoint_name: str, service_name: str, reason: str):
        """Marque un endpoint comme non sain."""
        service_health = self.health_status.get(service_name, {})
        
        for endpoint_key, status in service_health.items():
            if endpoint_name in endpoint_key:
                status["is_healthy"] = False
                status["consecutive_failures"] += 1
                status["last_error"] = format_datetime(get_current_time())
                log_message(f"Endpoint {endpoint_key} marqu√© comme non sain: {reason}", level="warning")
                break

class QuotaManager:
    """
    G√®re l'utilisation des quotas pour les APIs des 7 cerveaux autonomes.
    """
    _instance = None
    _initialized = False

    def __new__(cls, *args, **kwargs):
        """Impl√©mentation du patron Singleton."""
        if cls._instance is None:
            cls._instance = super(QuotaManager, cls).__new__(cls)
        return cls._instance

    def __init__(self):
        """Initialise le gestionnaire de quotas une seule fois."""
        if self._initialized:
            return
        self.quota_state: Dict[str, Dict[str, Any]] = {}
        self._initialized = True
        log_message("QuotaManager initialis√©.")

    async def init_manager(self):
        """Charge l'√©tat des quotas depuis le fichier."""
        self.quota_state = await load_json(config.QUOTA_STATE_FILE, {})
        self._initialize_quota_state()
        log_message("QuotaManager charg√© et pr√™t.")

    def _initialize_quota_state(self):
        """Initialise l'√©tat des quotas pour toutes les APIs."""
        updated = False
        current_time = datetime.now(timezone.utc)
        
        for api_name, quota_info in config.QUOTA_CONFIG.items():
            if api_name not in self.quota_state:
                self.quota_state[api_name] = {
                    "current_usage": 0,
                    "last_reset_time": current_time.isoformat(),
                    "last_usage_time": None,
                    "daily_peak": 0,
                    "success_count": 0,
                    "error_count": 0
                }
                updated = True
            
            # V√©rification et reset si n√©cessaire
            self._check_and_reset_quota(api_name, current_time)
        
        if updated:
            asyncio.create_task(save_json(config.QUOTA_STATE_FILE, self.quota_state))
            log_message("√âtat des quotas initialis√©/mis √† jour.")

    def _check_and_reset_quota(self, api_name: str, current_time: datetime) -> bool:
        """V√©rifie et remet √† z√©ro le quota si n√©cessaire."""
        quota_info = config.QUOTA_CONFIG.get(api_name)
        if not quota_info:
            return False

        state = self.quota_state.get(api_name)
        if not state:
            state = {
                "current_usage": 0,
                "last_reset_time": current_time.isoformat(),
                "last_usage_time": None,
                "daily_peak": 0,
                "success_count": 0,
                "error_count": 0
            }
            self.quota_state[api_name] = state

        last_reset_dt = datetime.fromisoformat(state["last_reset_time"])
        reset_needed = False

        if quota_info["reset_interval"] == "daily":
            if current_time.date() > last_reset_dt.date():
                reset_needed = True
        elif quota_info["reset_interval"] == "hourly":
            if current_time.hour > last_reset_dt.hour or current_time.date() > last_reset_dt.date():
                reset_needed = True
        elif quota_info["reset_interval"] == "fixed_24h":
            if current_time - last_reset_dt >= timedelta(hours=24):
                reset_needed = True

        if reset_needed:
            # Sauvegarde du pic quotidien
            state["daily_peak"] = max(state.get("daily_peak", 0), state["current_usage"])
            
            # Reset des compteurs
            state["current_usage"] = 0
            state["last_reset_time"] = current_time.isoformat()
            
            log_message(f"Quota pour {api_name} r√©initialis√©. Pic pr√©c√©dent: {state['daily_peak']}")
            return True

        return False

    async def check_quota(self, api_name: str) -> bool:
        """V√©rifie si une requ√™te est autoris√©e selon le quota."""
        quota_info = config.QUOTA_CONFIG.get(api_name)
        if not quota_info:
            return True  # Pas de quota configur√© = autoris√©

        state = self.quota_state.get(api_name)
        if not state:
            self._initialize_quota_state()
            state = self.quota_state.get(api_name)
            if not state:
                return False

        current_time = datetime.now(timezone.utc)
        self._check_and_reset_quota(api_name, current_time)

        remaining_quota = quota_info["limit"] - state["current_usage"]

        # Logique de fen√™tre de cramage
        is_in_burn_window = False
        if quota_info.get("burn_window_hours", 0) > 0:
            last_reset_dt = datetime.fromisoformat(state["last_reset_time"])
            time_to_next_reset = timedelta(hours=0)

            if quota_info["reset_interval"] == "daily":
                next_reset = (last_reset_dt + timedelta(days=1)).replace(hour=0, minute=0, second=0, microsecond=0)
                time_to_next_reset = next_reset - current_time
            elif quota_info["reset_interval"] == "hourly":
                next_reset = (last_reset_dt + timedelta(hours=1)).replace(minute=0, second=0, microsecond=0)
                time_to_next_reset = next_reset - current_time
            elif quota_info["reset_interval"] == "fixed_24h":
                next_reset = last_reset_dt + timedelta(hours=24)
                time_to_next_reset = next_reset - current_time

            if timedelta(hours=0) < time_to_next_reset <= timedelta(hours=quota_info["burn_window_hours"]):
                is_in_burn_window = True

        # Autorisation de la requ√™te
        if state["current_usage"] < quota_info["limit"]:
            return True
        elif is_in_burn_window:
            log_message(f"Quota {api_name} en mode cramage autoris√©", level="warning")
            return True
        else:
            log_message(f"Quota {api_name} d√©pass√©: {state['current_usage']}/{quota_info['limit']}", level="warning")
            return False

    async def increment_quota(self, api_name: str, success: bool = True):
        """Incr√©mente le quota apr√®s utilisation."""
        quota_info = config.QUOTA_CONFIG.get(api_name)
        if not quota_info:
            return

        state = self.quota_state.get(api_name)
        if not state:
            self._initialize_quota_state()
            state = self.quota_state.get(api_name)

        if state:
            current_time = datetime.now(timezone.utc)
            state["current_usage"] += 1
            state["last_usage_time"] = current_time.isoformat()
            
            if success:
                state["success_count"] = state.get("success_count", 0) + 1
            else:
                state["error_count"] = state.get("error_count", 0) + 1

            asyncio.create_task(save_json(config.QUOTA_STATE_FILE, self.quota_state))
            
            remaining = quota_info["limit"] - state["current_usage"]
            log_message(f"Quota {api_name}: {state['current_usage']}/{quota_info['limit']} (Restant: {remaining})")

    def get_quota_status(self, api_name: str) -> Dict[str, Any]:
        """Retourne le statut du quota pour une API."""
        quota_info = config.QUOTA_CONFIG.get(api_name, {})
        state = self.quota_state.get(api_name, {})
        
        if not state:
            return {"error": f"Pas de donn√©es pour {api_name}"}
        
        return {
            "api_name": api_name,
            "current_usage": state.get("current_usage", 0),
            "limit": quota_info.get("limit", 0),
            "remaining": quota_info.get("limit", 0) - state.get("current_usage", 0),
            "success_rate": (
                state.get("success_count", 0) / 
                max(1, state.get("success_count", 0) + state.get("error_count", 0))
            ) * 100,
            "last_usage": state.get("last_usage_time"),
            "last_reset": state.get("last_reset_time"),
            "daily_peak": state.get("daily_peak", 0)
        }

    def get_all_quotas_status(self) -> Dict[str, Dict[str, Any]]:
        """Retourne le statut de tous les quotas."""
        return {
            api_name: self.get_quota_status(api_name)
            for api_name in config.QUOTA_CONFIG.keys()
        }

# Instances globales des singletons
endpoint_health_manager = EndpointHealthManager()
quota_manager = QuotaManager()

import asyncio
import json
import random
import time
import traceback
from datetime import datetime, timezone
from typing import Dict, Any, List, Optional, Union
import httpx

from config import config
from brain_library import api_key_library, BrainMemoryManager, TelegramMemoryIntegration
from utils import log_message, neutralize_urls
from tools import get_gemini_tools

class AutonomousBrain:
    """
    Classe de base pour un cerveau autonome.
    Chaque cerveau peut traiter ind√©pendamment les requ√™tes utilisateur.
    """
    def __init__(self, brain_id: str, service_name: str, telegram_client=None):
        self.brain_id = brain_id
        self.service_name = service_name
        self.memory_manager = BrainMemoryManager(brain_id)
        self.telegram_memory = TelegramMemoryIntegration(telegram_client)
        self.is_active = True
        self.current_task = None
        self.last_activity = time.time()
        
    async def initialize(self):
        """Initialise le cerveau et charge sa m√©moire."""
        try:
            await self.memory_manager.load_memory()
            await self.telegram_memory.log_brain_activity(
                self.brain_id, 
                "Cerveau initialis√©", 
                {"service": self.service_name, "timestamp": datetime.now().isoformat()}
            )
            log_message(f"Cerveau {self.brain_id} initialis√© avec succ√®s")
            return True
        except Exception as e:
            log_message(f"Erreur initialisation cerveau {self.brain_id}: {e}", level="error")
            return False
    
    async def read_complete_memory(self) -> str:
        """Lit l'int√©gralit√© de la m√©moire avant toute action."""
        try:
            # Lecture de la m√©moire du groupe priv√© Telegram
            group_memory = await self.telegram_memory.read_group_memory(limit=100)
            
            # Lecture du contexte local pertinent
            local_context = await self.memory_manager.get_relevant_context("", limit=20)
            
            complete_memory = f"""
=== M√âMOIRE COMPL√àTE DU CERVEAU {self.brain_id} ===

{group_memory}

=== CONTEXTE LOCAL ===
{json.dumps(local_context, indent=2)}

=== STATUT CERVEAU ===
Service: {self.service_name}
Derni√®re activit√©: {datetime.fromtimestamp(self.last_activity).isoformat()}
Actif: {self.is_active}
T√¢che courante: {self.current_task or "Aucune"}
"""
            return complete_memory
        except Exception as e:
            log_message(f"Erreur lecture m√©moire compl√®te {self.brain_id}: {e}", level="error")
            return f"Erreur d'acc√®s √† la m√©moire: {e}"
    
    async def process_request(self, user_query: str, chat_history: List[Dict] = None, 
                            image_data: str = None, tools: List[Dict] = None) -> Dict[str, Any]:
        """
        Traite une requ√™te utilisateur de mani√®re autonome.
        Chaque cerveau lit sa m√©moire compl√®te avant de r√©pondre.
        """
        self.current_task = f"Traitement requ√™te: {user_query[:50]}..."
        self.last_activity = time.time()
        
        try:
            # 1. Lecture obligatoire de l'int√©gralit√© de la m√©moire
            complete_memory = await self.read_complete_memory()
            
            await self.telegram_memory.log_brain_activity(
                self.brain_id,
                "D√©but traitement requ√™te",
                {"query": user_query[:100], "memory_loaded": True}
            )
            
            # 2. S√©lection de la cl√© API et de l'endpoint
            key_info = api_key_library.get_available_key(self.service_name)
            if not key_info:
                error_msg = f"Aucune cl√© API disponible pour {self.service_name}"
                await self.telegram_memory.log_error(self.brain_id, error_msg)
                await self.memory_manager.update_success_rate(False)
                return {"error": error_msg, "brain_id": self.brain_id}
            
            # 3. Pr√©paration du prompt enrichi avec la m√©moire
            enriched_prompt = f"""
{complete_memory}

=== NOUVELLE REQU√äTE UTILISATEUR ===
{user_query}

Instructions: Utilise l'int√©gralit√© de la m√©moire ci-dessus pour fournir une r√©ponse contextuelle et pertinente.
Cerveau responsable: {self.brain_id}
Service: {self.service_name}
"""
            
            # 4. G√©n√©ration de la r√©ponse
            response = await self._generate_response(
                enriched_prompt, key_info, chat_history, image_data, tools
            )
            
            # 5. Traitement des outils si n√©cessaire
            tool_results = []
            if "function_calls" in response:
                tool_results = await self._execute_tools(response["function_calls"])
                response["tool_results"] = tool_results
            
            # 6. Sauvegarde en m√©moire et dans le groupe Telegram
            await self.memory_manager.add_interaction(
                user_query, 
                str(response), 
                [tool["name"] for tool in tool_results]
            )
            
            await self.telegram_memory.log_success(
                self.brain_id,
                "Requ√™te trait√©e avec succ√®s",
                str(response)[:200]
            )
            
            await self.memory_manager.update_success_rate(True)
            
            self.current_task = None
            return {
                "response": response,
                "brain_id": self.brain_id,
                "service": self.service_name,
                "memory_context": complete_memory[:500] + "...",
                "tool_results": tool_results
            }
            
        except Exception as e:
            error_msg = f"Erreur traitement requ√™te: {e}"
            log_message(f"Cerveau {self.brain_id}: {error_msg}", level="error")
            await self.telegram_memory.log_error(self.brain_id, error_msg)
            await self.memory_manager.update_success_rate(False)
            
            # Marquer la cl√© comme d√©faillante
            if 'key_info' in locals():
                api_key_library.mark_key_failed(self.service_name, key_info["key"])
            
            self.current_task = None
            return {"error": error_msg, "brain_id": self.brain_id}
    
    async def _generate_response(self, prompt: str, key_info: Dict, 
                               chat_history: List[Dict] = None,
                               image_data: str = None, 
                               tools: List[Dict] = None) -> Dict[str, Any]:
        """G√©n√®re une r√©ponse sp√©cifique au service."""
        # M√©thode abstraite - impl√©ment√©e dans les sous-classes
        raise NotImplementedError("Chaque cerveau doit impl√©menter sa m√©thode de g√©n√©ration")
    
    async def _execute_tools(self, function_calls: List[Dict]) -> List[Dict]:
        """Ex√©cute les outils demand√©s par l'IA."""
        results = []
        for func_call in function_calls:
            try:
                # Import dynamique pour √©viter les d√©pendances circulaires
                from tools import execute_tool
                
                tool_result = await execute_tool(
                    func_call["name"],
                    context=None,
                    **func_call.get("args", {})
                )
                results.append(tool_result)
                
                await self.telegram_memory.log_brain_activity(
                    self.brain_id,
                    f"Outil ex√©cut√©: {func_call['name']}",
                    {"args": func_call.get("args", {}), "result": str(tool_result)[:100]}
                )
                
            except Exception as e:
                error_result = {"error": f"Erreur outil {func_call['name']}: {e}"}
                results.append(error_result)
                await self.telegram_memory.log_error(
                    self.brain_id,
                    f"Erreur outil {func_call['name']}: {e}"
                )
        
        return results
    
    async def participate_in_coding_challenge(self, challenge_prompt: str) -> Dict[str, Any]:
        """Participe aux d√©fis de codage automatis√©s."""
        try:
            await self.telegram_memory.log_brain_activity(
                self.brain_id,
                "Participation d√©fi codage",
                {"challenge": challenge_prompt[:100]}
            )
            
            # Lecture de la m√©moire avant le d√©fi
            complete_memory = await self.read_complete_memory()
            
            # Prompt sp√©cialis√© pour le d√©fi de codage
            coding_prompt = f"""
{complete_memory}

=== D√âFI DE CODAGE AUTOMATIS√â ===
{challenge_prompt}

En tant que cerveau {self.brain_id} sp√©cialis√© en {self.service_name}, g√©n√®re du code Python optimis√© et fonctionnel.
Le code doit √™tre:
- Syntaxiquement correct
- Bien comment√©
- Optimis√© pour les performances
- Pr√™t √† l'ex√©cution

R√©ponds uniquement avec le code Python, sans explications suppl√©mentaires.
"""
            
            key_info = api_key_library.get_available_key(self.service_name)
            if not key_info:
                return {"error": f"Aucune cl√© disponible pour {self.service_name}"}
            
            response = await self._generate_response(coding_prompt, key_info)
            
            # Sauvegarde du code g√©n√©r√©
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            code_filename = f"challenge_{self.brain_id}_{timestamp}.py"
            
            await self.telegram_memory.write_to_group(
                f"üíª Code g√©n√©r√© par {self.brain_id}:\n```python\n{response}\n```",
                "CODING_CHALLENGE"
            )
            
            return {
                "code": response,
                "brain_id": self.brain_id,
                "filename": code_filename,
                "timestamp": timestamp
            }
            
        except Exception as e:
            error_msg = f"Erreur d√©fi codage: {e}"
            await self.telegram_memory.log_error(self.brain_id, error_msg)
            return {"error": error_msg, "brain_id": self.brain_id}

class GeminiBrain(AutonomousBrain):
    """Cerveau autonome bas√© sur Gemini."""
    
    def __init__(self, telegram_client=None):
        super().__init__("GEMINI", "GEMINI", telegram_client)
    
    async def _generate_response(self, prompt: str, key_info: Dict,
                               chat_history: List[Dict] = None,
                               image_data: str = None,
                               tools: List[Dict] = None) -> Dict[str, Any]:
        """G√©n√®re une r√©ponse via l'API Gemini."""
        try:
            import google.generativeai as genai
            
            # Configuration avec la cl√©
            genai.configure(api_key=key_info["key"])
            
            # Pr√©paration du contenu
            contents = []
            if chat_history:
                for msg in chat_history:
                    formatted_parts = []
                    for part in msg.get("parts", []):
                        if "text" in part:
                            formatted_parts.append(part["text"])
                    if formatted_parts:
                        contents.append({"role": msg["role"], "parts": formatted_parts})
            
            # Ajout du prompt actuel
            user_parts = [prompt]
            if image_data:
                mime_type = image_data.split(';')[0].split(':')[1]
                base64_string = image_data.split(',')[1]
                user_parts.append(genai.types.Blob(mime_type=mime_type, data=base64_string))
            
            contents.append({"role": "user", "parts": user_parts})
            
            # Outils Gemini
            gemini_tools = None
            if tools:
                gemini_tools = [genai.types.FunctionDeclaration(**tool["function_declarations"][0]) 
                              for tool in tools if "function_declarations" in tool]
            
            # G√©n√©ration
            model = genai.GenerativeModel("gemini-1.5-flash-latest", tools=gemini_tools)
            response = await model.generate_content_async(
                contents=contents,
                generation_config=genai.types.GenerationConfig(
                    temperature=config.GEMINI_TEMPERATURE,
                    top_p=config.GEMINI_TOP_P,
                    top_k=config.GEMINI_TOP_K,
                    max_output_tokens=config.GEMINI_MAX_OUTPUT_TOKENS,
                ),
                safety_settings=config.GEMINI_SAFETY_SETTINGS,
            )
            
            return response.to_dict()
            
        except Exception as e:
            raise Exception(f"Erreur Gemini: {e}")

class DeepSeekBrain(AutonomousBrain):
    """Cerveau autonome bas√© sur DeepSeek."""
    
    def __init__(self, telegram_client=None):
        super().__init__("DEEPSEEK", "DEEPSEEK", telegram_client)
    
    async def _generate_response(self, prompt: str, key_info: Dict,
                               chat_history: List[Dict] = None,
                               image_data: str = None,
                               tools: List[Dict] = None) -> Dict[str, Any]:
        """G√©n√®re une r√©ponse via l'API DeepSeek."""
        try:
            endpoint = next(e for e in key_info["endpoints"] if e["name"] == "chat_completions")
            
            messages = []
            if chat_history:
                for msg in chat_history:
                    content = " ".join([part.get("text", "") for part in msg.get("parts", [])])
                    if content.strip():
                        role = "assistant" if msg["role"] == "model" else msg["role"]
                        messages.append({"role": role, "content": content})
            
            messages.append({"role": "user", "content": prompt})
            
            headers = {
                "Authorization": f"Bearer {key_info['key']}",
                "Content-Type": "application/json"
            }
            
            json_data = {
                "model": "deepseek-chat",
                "messages": messages,
                "temperature": config.GEMINI_TEMPERATURE,
                "max_tokens": config.GEMINI_MAX_OUTPUT_TOKENS
            }
            
            async with httpx.AsyncClient(timeout=60) as client:
                response = await client.post(endpoint["url"], headers=headers, json=json_data)
                response.raise_for_status()
                result = response.json()
                
                # Conversion au format Gemini-like
                if "choices" in result and result["choices"]:
                    content = result["choices"][0]["message"]["content"]
                    return {
                        "candidates": [{
                            "content": {"parts": [{"text": content}]}
                        }]
                    }
                return result
                
        except Exception as e:
            raise Exception(f"Erreur DeepSeek: {e}")

class HuggingFaceBrain(AutonomousBrain):
    """Cerveau autonome bas√© sur HuggingFace."""
    
    def __init__(self, telegram_client=None):
        super().__init__("HUGGINGFACE", "HUGGINGFACE", telegram_client)
    
    async def _generate_response(self, prompt: str, key_info: Dict,
                               chat_history: List[Dict] = None,
                               image_data: str = None,
                               tools: List[Dict] = None) -> Dict[str, Any]:
        """G√©n√®re une r√©ponse via l'API HuggingFace."""
        try:
            endpoint = next(e for e in key_info["endpoints"] if e["name"] == "inference")
            
            # Utilise un mod√®le de g√©n√©ration de texte
            model_url = endpoint["url"] + "microsoft/DialoGPT-large"
            
            headers = {
                "Authorization": f"Bearer {key_info['key']}",
                "Content-Type": "application/json"
            }
            
            json_data = {"inputs": prompt}
            
            async with httpx.AsyncClient(timeout=60) as client:
                response = await client.post(model_url, headers=headers, json=json_data)
                response.raise_for_status()
                result = response.json()
                
                # Conversion au format Gemini-like
                if isinstance(result, list) and result:
                    generated_text = result[0].get("generated_text", prompt)
                    # Extrait seulement la nouvelle partie g√©n√©r√©e
                    new_text = generated_text[len(prompt):].strip()
                    if not new_text:
                        new_text = "R√©ponse g√©n√©r√©e par HuggingFace"
                    
                    return {
                        "candidates": [{
                            "content": {"parts": [{"text": new_text}]}
                        }]
                    }
                return {"candidates": [{"content": {"parts": [{"text": str(result)}]}}]}
                
        except Exception as e:
            raise Exception(f"Erreur HuggingFace: {e}")

class TavilyBrain(AutonomousBrain):
    """Cerveau autonome bas√© sur Tavily."""
    
    def __init__(self, telegram_client=None):
        super().__init__("TAVILY", "TAVILY", telegram_client)
    
    async def _generate_response(self, prompt: str, key_info: Dict,
                               chat_history: List[Dict] = None,
                               image_data: str = None,
                               tools: List[Dict] = None) -> Dict[str, Any]:
        """G√©n√®re une r√©ponse via l'API Tavily."""
        try:
            endpoint = next(e for e in key_info["endpoints"] if e["name"] == "search")
            
            headers = {
                "apikey": key_info["key"],
                "Content-Type": "application/json"
            }
            
            json_data = {
                "query": prompt,
                "search_depth": "advanced",
                "include_answer": True,
                "include_raw_content": False,
                "max_results": 5
            }
            
            async with httpx.AsyncClient(timeout=30) as client:
                response = await client.post(endpoint["url"], headers=headers, json=json_data)
                response.raise_for_status()
                result = response.json()
                
                # Traitement des r√©sultats Tavily
                answer = result.get("answer", "")
                results = result.get("results", [])
                
                # Synth√®se de la r√©ponse
                synthesis = f"R√©ponse Tavily: {answer}\n\n"
                if results:
                    synthesis += "Sources:\n"
                    for i, res in enumerate(results[:3], 1):
                        title = res.get("title", "Sans titre")
                        content = res.get("content", "")[:200]
                        synthesis += f"{i}. {title}: {content}...\n"
                
                return {
                    "candidates": [{
                        "content": {"parts": [{"text": neutralize_urls(synthesis)}]}
                    }]
                }
                
        except Exception as e:
            raise Exception(f"Erreur Tavily: {e}")

class SerperBrain(AutonomousBrain):
    """Cerveau autonome bas√© sur Serper."""
    
    def __init__(self, telegram_client=None):
        super().__init__("SERPER", "SERPER", telegram_client)
    
    async def _generate_response(self, prompt: str, key_info: Dict,
                               chat_history: List[Dict] = None,
                               image_data: str = None,
                               tools: List[Dict] = None) -> Dict[str, Any]:
        """G√©n√®re une r√©ponse via l'API Serper."""
        try:
            endpoint = next(e for e in key_info["endpoints"] if e["name"] == "search")
            
            headers = {
                "X-API-KEY": key_info["key"],
                "Content-Type": "application/json"
            }
            
            json_data = {"q": prompt}
            
            async with httpx.AsyncClient(timeout=30) as client:
                response = await client.post(endpoint["url"], headers=headers, json=json_data)
                response.raise_for_status()
                result = response.json()
                
                # Traitement des r√©sultats Serper
                organic = result.get("organic", [])
                answer_box = result.get("answerBox", {})
                
                synthesis = ""
                if answer_box:
                    synthesis += f"R√©ponse directe: {answer_box.get('answer', '')}\n\n"
                
                if organic:
                    synthesis += "R√©sultats de recherche:\n"
                    for i, res in enumerate(organic[:3], 1):
                        title = res.get("title", "Sans titre")
                        snippet = res.get("snippet", "")
                        synthesis += f"{i}. {title}: {snippet}\n"
                
                if not synthesis:
                    synthesis = "Aucun r√©sultat trouv√© pour cette recherche."
                
                return {
                    "candidates": [{
                        "content": {"parts": [{"text": neutralize_urls(synthesis)}]}
                    }]
                }
                
        except Exception as e:
            raise Exception(f"Erreur Serper: {e}")

class GoogleBrain(AutonomousBrain):
    """Cerveau autonome bas√© sur Google Custom Search."""
    
    def __init__(self, telegram_client=None):
        super().__init__("GOOGLE", "GOOGLE_CUSTOM_SEARCH", telegram_client)
    
    async def _generate_response(self, prompt: str, key_info: Dict,
                               chat_history: List[Dict] = None,
                               image_data: str = None,
                               tools: List[Dict] = None) -> Dict[str, Any]:
        """G√©n√®re une r√©ponse via l'API Google Custom Search."""
        try:
            endpoint = next(e for e in key_info["endpoints"] if e["name"] == "custom_search")
            
            params = {
                "key": key_info["key"],
                "cx": endpoint["cx"],
                "q": prompt
            }
            
            async with httpx.AsyncClient(timeout=30) as client:
                response = await client.get(endpoint["url"], params=params)
                response.raise_for_status()
                result = response.json()
                
                # Traitement des r√©sultats Google
                items = result.get("items", [])
                
                synthesis = f"R√©sultats Google pour: {prompt}\n\n"
                if items:
                    for i, item in enumerate(items[:3], 1):
                        title = item.get("title", "Sans titre")
                        snippet = item.get("snippet", "")
                        synthesis += f"{i}. {title}: {snippet}\n"
                else:
                    synthesis += "Aucun r√©sultat trouv√©."
                
                return {
                    "candidates": [{
                        "content": {"parts": [{"text": neutralize_urls(synthesis)}]}
                    }]
                }
                
        except Exception as e:
            raise Exception(f"Erreur Google: {e}")

class WolframBrain(AutonomousBrain):
    """Cerveau autonome bas√© sur Wolfram Alpha."""
    
    def __init__(self, telegram_client=None):
        super().__init__("WOLFRAM", "WOLFRAMALPHA", telegram_client)
    
    async def _generate_response(self, prompt: str, key_info: Dict,
                               chat_history: List[Dict] = None,
                               image_data: str = None,
                               tools: List[Dict] = None) -> Dict[str, Any]:
        """G√©n√®re une r√©ponse via l'API Wolfram Alpha."""
        try:
            endpoint = next(e for e in key_info["endpoints"] if e["name"] == "query")
            
            params = {
                "appid": key_info["key"],
                "input": prompt,
                "output": "json",
                "format": "plaintext"
            }
            
            async with httpx.AsyncClient(timeout=30) as client:
                response = await client.get(endpoint["url"], params=params)
                response.raise_for_status()
                result = response.json()
                
                # Traitement des r√©sultats Wolfram
                query_result = result.get("queryresult", {})
                pods = query_result.get("pods", [])
                
                synthesis = f"R√©sultat Wolfram Alpha pour: {prompt}\n\n"
                if pods:
                    for pod in pods[:3]:
                        title = pod.get("title", "")
                        subpods = pod.get("subpods", [])
                        if subpods:
                            text = subpods[0].get("plaintext", "")
                            if text:
                                synthesis += f"{title}: {text}\n"
                else:
                    synthesis += "Aucun r√©sultat calculable trouv√©."
                
                return {
                    "candidates": [{
                        "content": {"parts": [{"text": synthesis}]}
                    }]
                }
                
        except Exception as e:
            raise Exception(f"Erreur Wolfram: {e}")

# Fonction factory pour cr√©er les cerveaux
def create_brain(brain_type: str, telegram_client=None) -> AutonomousBrain:
    """Factory pour cr√©er un cerveau du type demand√©."""
    brain_classes = {
        "GEMINI": GeminiBrain,
        "DEEPSEEK": DeepSeekBrain,
        "HUGGINGFACE": HuggingFaceBrain,
        "TAVILY": TavilyBrain,
        "SERPER": SerperBrain,
        "GOOGLE": GoogleBrain,
        "WOLFRAM": WolframBrain
    }
    
    if brain_type not in brain_classes:
        raise ValueError(f"Type de cerveau non support√©: {brain_type}")
    
    return brain_classes[brain_type](telegram_client)
    
    import asyncio
import json
import random
import time
from datetime import datetime, timezone, timedelta
from typing import Dict, Any, List, Optional, Union, Tuple
import logging
from pathlib import Path

from config import config
from utils import log_message, load_json, save_json, get_current_time

class APIKeyLibrary:
    """
    Biblioth√®que centralis√©e pour la gestion des cl√©s API et endpoints.
    Chaque cerveau peut utiliser tous les endpoints de son service.
    """
    def __init__(self):
        self.api_keys = self._initialize_api_keys()
        self.endpoint_rotation = {}
        self.last_rotation_time = {}
        self.failed_endpoints = {}
        
    def _initialize_api_keys(self) -> Dict[str, List[Dict]]:
        """Initialise toutes les cl√©s API avec leurs endpoints."""
        return {
            "GEMINI": [
                {
                    "key": key,
                    "endpoints": [
                        {
                            "name": "generate_content",
                            "url": "https://generativelanguage.googleapis.com/v1beta/models/gemini-1.5-flash-latest:generateContent",
                            "method": "POST"
                        },
                        {
                            "name": "list_models",
                            "url": "https://generativelanguage.googleapis.com/v1beta/models",
                            "method": "GET"
                        },
                        {
                            "name": "embed_content",
                            "url": "https://generativelanguage.googleapis.com/v1beta/models/embedding-001:embedContent",
                            "method": "POST"
                        }
                    ]
                } for key in config.GEMINI_API_KEYS
            ],
            "DEEPSEEK": [
                {
                    "key": key,
                    "endpoints": [
                        {
                            "name": "chat_completions",
                            "url": "https://api.deepseek.com/chat/completions",
                            "method": "POST"
                        },
                        {
                            "name": "list_models",
                            "url": "https://api.deepseek.com/models",
                            "method": "GET"
                        }
                    ]
                } for key in config.DEEPSEEK_KEYS
            ],
            "HUGGINGFACE": [
                {
                    "key": key,
                    "endpoints": [
                        {
                            "name": "inference",
                            "url": "https://api-inference.huggingface.co/models/",
                            "method": "POST"
                        },
                        {
                            "name": "list_models",
                            "url": "https://huggingface.co/api/models",
                            "method": "GET"
                        }
                    ]
                } for key in config.HUGGINGFACE_KEYS
            ],
            "TAVILY": [
                {
                    "key": key,
                    "endpoints": [
                        {
                            "name": "search",
                            "url": "https://api.tavily.com/search",
                            "method": "POST"
                        },
                        {
                            "name": "extract",
                            "url": "https://api.tavily.com/extract",
                            "method": "POST"
                        }
                    ]
                } for key in config.TAVILY_KEYS
            ],
            "SERPER": [
                {
                    "key": key,
                    "endpoints": [
                        {
                            "name": "search",
                            "url": "https://google.serper.dev/search",
                            "method": "POST"
                        },
                        {
                            "name": "images",
                            "url": "https://google.serper.dev/images",
                            "method": "POST"
                        },
                        {
                            "name": "news",
                            "url": "https://google.serper.dev/news",
                            "method": "POST"
                        }
                    ]
                } for key in config.SERPER_KEYS
            ],
            "GOOGLE": [
                {
                    "key": key,
                    "endpoints": [
                        {
                            "name": "custom_search",
                            "url": "https://www.googleapis.com/customsearch/v1",
                            "method": "GET",
                            "cx": cx
                        } for cx in config.GOOGLE_CX_LIST
                    ]
                } for key in config.GOOGLE_API_KEYS
            ],
            "WOLFRAM": [
                {
                    "key": key,
                    "endpoints": [
                        {
                            "name": "query",
                            "url": "https://api.wolframalpha.com/v2/query",
                            "method": "GET"
                        },
                        {
                            "name": "simple",
                            "url": "https://api.wolframalpha.com/v1/simple",
                            "method": "GET"
                        }
                    ]
                } for key in config.WOLFRAM_APP_IDS
            ]
        }
    
    def get_available_key(self, service: str) -> Optional[Dict]:
        """R√©cup√®re une cl√© API disponible pour un service donn√©."""
        if service not in self.api_keys:
            return None
            
        available_keys = []
        for key_info in self.api_keys[service]:
            key_id = f"{service}_{key_info['key'][:8]}"
            if key_id not in self.failed_endpoints or self.failed_endpoints[key_id] < time.time() - 300:
                available_keys.append(key_info)
        
        if not available_keys:
            # Reset failed endpoints if all are failed
            for key_info in self.api_keys[service]:
                key_id = f"{service}_{key_info['key'][:8]}"
                if key_id in self.failed_endpoints:
                    del self.failed_endpoints[key_id]
            available_keys = self.api_keys[service]
        
        return random.choice(available_keys) if available_keys else None
    
    def mark_key_failed(self, service: str, key: str):
        """Marque une cl√© comme d√©faillante temporairement."""
        key_id = f"{service}_{key[:8]}"
        self.failed_endpoints[key_id] = time.time()
        log_message(f"Cl√© {key_id} marqu√©e comme d√©faillante pour 5 minutes", level="warning")
    
    def get_endpoint(self, service: str, endpoint_name: str) -> Optional[Dict]:
        """R√©cup√®re un endpoint sp√©cifique pour un service."""
        key_info = self.get_available_key(service)
        if not key_info:
            return None
            
        for endpoint in key_info["endpoints"]:
            if endpoint["name"] == endpoint_name:
                return {
                    "key": key_info["key"],
                    "endpoint": endpoint
                }
        return None
    
    def rotate_key(self, service: str) -> Optional[Dict]:
        """Force la rotation vers une nouvelle cl√© pour un service."""
        if service not in self.endpoint_rotation:
            self.endpoint_rotation[service] = 0
        
        if service in self.api_keys and self.api_keys[service]:
            self.endpoint_rotation[service] = (self.endpoint_rotation[service] + 1) % len(self.api_keys[service])
            self.last_rotation_time[service] = time.time()
            return self.api_keys[service][self.endpoint_rotation[service]]
        return None

class BrainMemoryManager:
    """
    Gestionnaire de m√©moire pour les 7 cerveaux autonomes.
    Chaque cerveau maintient sa propre m√©moire locale et acc√®de √† la m√©moire partag√©e.
    """
    def __init__(self, brain_id: str):
        self.brain_id = brain_id
        self.local_memory = {}
        self.shared_memory_file = config.BRAIN_MEMORY_FILE
        self.last_memory_update = time.time()
        
    async def load_memory(self) -> Dict[str, Any]:
        """Charge la m√©moire locale et partag√©e."""
        try:
            shared_memory = await load_json(self.shared_memory_file, {})
            if self.brain_id not in shared_memory:
                shared_memory[self.brain_id] = {
                    "interactions": [],
                    "learned_patterns": {},
                    "success_rate": 1.0,
                    "last_active": datetime.now(timezone.utc).isoformat()
                }
                await save_json(self.shared_memory_file, shared_memory)
            
            self.local_memory = shared_memory[self.brain_id]
            return self.local_memory
        except Exception as e:
            log_message(f"Erreur chargement m√©moire pour cerveau {self.brain_id}: {e}", level="error")
            return {}
    
    async def save_memory(self):
        """Sauvegarde la m√©moire locale dans le fichier partag√©."""
        try:
            shared_memory = await load_json(self.shared_memory_file, {})
            shared_memory[self.brain_id] = self.local_memory
            shared_memory[self.brain_id]["last_active"] = datetime.now(timezone.utc).isoformat()
            await save_json(self.shared_memory_file, shared_memory)
            self.last_memory_update = time.time()
        except Exception as e:
            log_message(f"Erreur sauvegarde m√©moire pour cerveau {self.brain_id}: {e}", level="error")
    
    async def add_interaction(self, user_query: str, response: str, tools_used: List[str] = None):
        """Ajoute une interaction √† la m√©moire."""
        interaction = {
            "timestamp": datetime.now(timezone.utc).isoformat(),
            "user_query": user_query[:200],  # Limite pour √©viter la surcharge m√©moire
            "response": response[:500],
            "tools_used": tools_used or [],
            "brain_id": self.brain_id
        }
        
        if "interactions" not in self.local_memory:
            self.local_memory["interactions"] = []
            
        self.local_memory["interactions"].append(interaction)
        
        # Limite le nombre d'interactions en m√©moire
        if len(self.local_memory["interactions"]) > 100:
            self.local_memory["interactions"] = self.local_memory["interactions"][-100:]
        
        await self.save_memory()
    
    async def get_relevant_context(self, query: str, limit: int = 5) -> List[Dict]:
        """R√©cup√®re le contexte pertinent bas√© sur la requ√™te."""
        await self.load_memory()
        
        if "interactions" not in self.local_memory:
            return []
        
        # Simple matching bas√© sur les mots-cl√©s
        query_words = set(query.lower().split())
        relevant_interactions = []
        
        for interaction in self.local_memory["interactions"]:
            interaction_words = set(interaction["user_query"].lower().split())
            if query_words.intersection(interaction_words):
                relevance_score = len(query_words.intersection(interaction_words)) / len(query_words.union(interaction_words))
                relevant_interactions.append((relevance_score, interaction))
        
        # Trie par pertinence et retourne les plus pertinents
        relevant_interactions.sort(key=lambda x: x[0], reverse=True)
        return [interaction for _, interaction in relevant_interactions[:limit]]
    
    async def update_success_rate(self, success: bool):
        """Met √† jour le taux de succ√®s du cerveau."""
        if "success_rate" not in self.local_memory:
            self.local_memory["success_rate"] = 1.0
        if "total_attempts" not in self.local_memory:
            self.local_memory["total_attempts"] = 0
        if "successful_attempts" not in self.local_memory:
            self.local_memory["successful_attempts"] = 0
            
        self.local_memory["total_attempts"] += 1
        if success:
            self.local_memory["successful_attempts"] += 1
            
        self.local_memory["success_rate"] = self.local_memory["successful_attempts"] / self.local_memory["total_attempts"]
        await self.save_memory()

class TelegramMemoryIntegration:
    """
    Int√©gration avec la m√©moire du groupe priv√© Telegram.
    Toutes les interactions sont stock√©es dans le groupe priv√©.
    """
    def __init__(self, bot_client):
        self.bot_client = bot_client
        self.group_id = config.PRIVATE_GROUP_ID
        self.memory_cache = []
        self.last_cache_update = 0
        
    async def read_group_memory(self, limit: int = 50) -> str:
        """Lit la m√©moire compl√®te du groupe priv√© Telegram."""
        try:
            if not self.group_id:
                return "M√©moire du groupe priv√© non configur√©e."
            
            # En production, ici on lirait les messages r√©cents du groupe
            # Pour cette impl√©mentation, on retourne une m√©moire simul√©e
            current_time = datetime.now().isoformat()
            memory_content = f"""
=== M√âMOIRE GROUPE PRIV√â TELEGRAM ===
Derni√®re mise √† jour: {current_time}
Groupe ID: {self.group_id}

Interactions r√©centes:
- Traitement de requ√™tes utilisateur
- Ex√©cution d'outils et analyses
- G√©n√©ration de d√©fis de codage
- Monitoring de la sant√© des APIs
- Rotation automatique des cerveaux

Statut syst√®me: Op√©rationnel
Cerveaux actifs: 7 (GEMINI, DEEPSEEK, HUGGINGFACE, TAVILY, SERPER, GOOGLE, WOLFRAM)
"""
            return memory_content
        except Exception as e:
            log_message(f"Erreur lecture m√©moire groupe: {e}", level="error")
            return "Erreur d'acc√®s √† la m√©moire du groupe."
    
    async def write_to_group(self, content: str, content_type: str = "info"):
        """√âcrit du contenu dans le groupe priv√© Telegram."""
        try:
            if not self.group_id or not self.bot_client:
                log_message(f"[{content_type.upper()}] {content}")
                return
            
            timestamp = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
            formatted_message = f"üß† [{timestamp}] [{content_type.upper()}]\n{content}"
            
            # En production, envoyer le message au groupe
            # await self.bot_client.send_message(self.group_id, formatted_message)
            log_message(f"Message √©crit dans le groupe priv√©: {formatted_message[:100]}...")
            
        except Exception as e:
            log_message(f"Erreur √©criture groupe: {e}", level="error")
    
    async def log_brain_activity(self, brain_id: str, activity: str, details: Dict = None):
        """Log l'activit√© d'un cerveau dans le groupe."""
        activity_log = f"Cerveau {brain_id}: {activity}"
        if details:
            activity_log += f"\nD√©tails: {json.dumps(details, indent=2)}"
        
        await self.write_to_group(activity_log, "BRAIN_ACTIVITY")
    
    async def log_error(self, brain_id: str, error: str):
        """Log une erreur dans le groupe."""
        error_log = f"‚ùå ERREUR - Cerveau {brain_id}: {error}"
        await self.write_to_group(error_log, "ERROR")
    
    async def log_success(self, brain_id: str, task: str, result: str):
        """Log un succ√®s dans le groupe."""
        success_log = f"‚úÖ SUCC√àS - Cerveau {brain_id}: {task}\nR√©sultat: {result[:200]}..."
        await self.write_to_group(success_log, "SUCCESS")

class BrainCoordinator:
    """
    Coordinateur pour les 7 cerveaux autonomes.
    G√®re la rotation, le basculement automatique et la coordination.
    """
    def __init__(self):
        self.active_brain_index = 0
        self.brain_names = ["GEMINI", "DEEPSEEK", "HUGGINGFACE", "TAVILY", "SERPER", "GOOGLE", "WOLFRAM"]
        self.last_rotation = time.time()
        self.brain_health = {brain: True for brain in self.brain_names}
        self.brain_load = {brain: 0 for brain in self.brain_names}
        
    def get_next_brain(self) -> str:
        """S√©lectionne le prochain cerveau selon la rotation et la sant√©."""
        current_time = time.time()
        
        # Rotation automatique toutes les 45 minutes
        if current_time - self.last_rotation >= config.BRAIN_ROTATION_INTERVAL_SECONDS:
            self.active_brain_index = (self.active_brain_index + 1) % len(self.brain_names)
            self.last_rotation = current_time
            log_message(f"Rotation automatique vers le cerveau: {self.brain_names[self.active_brain_index]}")
        
        # Recherche d'un cerveau sain en partant du cerveau actuel
        attempts = 0
        while attempts < len(self.brain_names):
            current_brain = self.brain_names[self.active_brain_index]
            
            if self.brain_health.get(current_brain, True) and self.brain_load.get(current_brain, 0) < 5:
                return current_brain
            
            # Passe au cerveau suivant si l'actuel n'est pas disponible
            self.active_brain_index = (self.active_brain_index + 1) % len(self.brain_names)
            attempts += 1
        
        # Si aucun cerveau n'est disponible, utilise le premier par d√©faut
        log_message("Aucun cerveau optimal trouv√©, utilisation du premier disponible", level="warning")
        return self.brain_names[0]
    
    def mark_brain_failed(self, brain_name: str):
        """Marque un cerveau comme d√©faillant."""
        self.brain_health[brain_name] = False
        log_message(f"Cerveau {brain_name} marqu√© comme d√©faillant", level="warning")
        
        # Auto-r√©cup√©ration apr√®s 10 minutes
        asyncio.create_task(self._auto_recover_brain(brain_name))
    
    async def _auto_recover_brain(self, brain_name: str):
        """R√©cup√©ration automatique d'un cerveau apr√®s un d√©lai."""
        await asyncio.sleep(600)  # 10 minutes
        self.brain_health[brain_name] = True
        log_message(f"Cerveau {brain_name} remis en service automatiquement")
    
    def update_brain_load(self, brain_name: str, load_change: int):
        """Met √† jour la charge d'un cerveau."""
        if brain_name in self.brain_load:
            self.brain_load[brain_name] = max(0, self.brain_load[brain_name] + load_change)
    
    def get_brain_status(self) -> Dict[str, Any]:
        """Retourne le statut de tous les cerveaux."""
        return {
            "active_brain": self.brain_names[self.active_brain_index],
            "brain_health": self.brain_health.copy(),
            "brain_load": self.brain_load.copy(),
            "last_rotation": self.last_rotation,
            "next_rotation": self.last_rotation + config.BRAIN_ROTATION_INTERVAL_SECONDS
        }

# Instances globales
api_key_library = APIKeyLibrary()
brain_coordinator = BrainCoordinator()

import asyncio
import json
import random
import time
import difflib
import hashlib
from datetime import datetime, timezone
from pathlib import Path
from typing import Dict, Any, List, Optional
import concurrent.futures
from functools import lru_cache

from config import config
from brain_library import api_key_library, TelegramMemoryIntegration
from autonomous_brain import create_brain
from utils import log_message, save_json

class CodingChallengeSystem:
    """
    Syst√®me de d√©fis de codage automatis√© pour les 7 cerveaux autonomes.
    G√©n√®re des d√©fis toutes les 15 minutes et fait participer tous les cerveaux.
    """
    def __init__(self, telegram_client=None):
        self.telegram_client = telegram_client
        self.telegram_memory = TelegramMemoryIntegration(telegram_client)
        self.brains = {}
        self.challenge_history = []
        self.is_running = False
        
        # Initialisation des 7 cerveaux
        self.brain_types = ["GEMINI", "DEEPSEEK", "HUGGINGFACE", "TAVILY", "SERPER", "GOOGLE", "WOLFRAM"]
        
    async def initialize(self):
        """Initialise tous les cerveaux pour les d√©fis."""
        try:
            for brain_type in self.brain_types:
                self.brains[brain_type] = create_brain(brain_type, self.telegram_client)
                await self.brains[brain_type].initialize()
                
            await self.telegram_memory.write_to_group(
                "üß† Syst√®me de d√©fis de codage initialis√© - 7 cerveaux pr√™ts",
                "SYSTEM_INIT"
            )
            log_message("Syst√®me de d√©fis de codage initialis√© avec succ√®s")
            return True
            
        except Exception as e:
            log_message(f"Erreur initialisation syst√®me d√©fis: {e}", level="error")
            return False
    
    async def start_periodic_challenges(self):
        """D√©marre les d√©fis p√©riodiques automatis√©s."""
        self.is_running = True
        await self.telegram_memory.write_to_group(
            "üöÄ D√©fis de codage automatis√©s d√©marr√©s - Intervalle: 15 minutes",
            "SYSTEM_START"
        )
        
        while self.is_running:
            try:
                await self.run_coding_challenge()
                await asyncio.sleep(config.CODING_CHALLENGE_INTERVAL_SECONDS)
            except Exception as e:
                log_message(f"Erreur dans la boucle de d√©fis: {e}", level="error")
                await asyncio.sleep(60)  # Attendre 1 minute en cas d'erreur
    
    def stop_challenges(self):
        """Arr√™te les d√©fis p√©riodiques."""
        self.is_running = False
        log_message("Syst√®me de d√©fis de codage arr√™t√©")
    
    def generate_challenge_prompt(self) -> str:
        """G√©n√®re un prompt de d√©fi de codage al√©atoire."""
        challenge_types = [
            "ALGORITHME",
            "OPTIMISATION", 
            "DEBUG",
            "IA_CREATIVE",
            "SCRIPT_UTILE",
            "STRUCTURE_DONNEES",
            "RESOLUTION_PROBLEME",
            "CODE_GOLF"
        ]
        
        algorithms = [
            "tri fusion", "recherche binaire", "parcours graphe", "programmation dynamique",
            "arbre binaire", "table de hachage", "pile et file", "r√©cursivit√©",
            "backtracking", "greedy algorithm", "dijkstra", "kruskal"
        ]
        
        domains = [
            "traitement de donn√©es", "analyse statistique", "manipulation de fichiers",
            "interfaces utilisateur", "API REST", "base de donn√©es", "machine learning",
            "traitement d'images", "traitement de texte", "cryptographie", "jeux",
            "automatisation", "web scraping", "calculs math√©matiques"
        ]
        
        challenge_type = random.choice(challenge_types)
        algorithm = random.choice(algorithms)
        domain = random.choice(domains)
        
        prompts = {
            "ALGORITHME": f"""
D√©fi Algorithme - {datetime.now().strftime('%Y-%m-%d %H:%M')}

Impl√©mente un algorithme de {algorithm} optimis√© pour {domain}.

Exigences:
- Code Python clair et efficace
- Complexit√© temporelle O(n log n) maximum
- Gestion des cas limites
- Tests unitaires inclus
- Documentation compl√®te

Contraintes:
- Maximum 150 lignes de code
- Utilisation de structures de donn√©es appropri√©es
- Code pr√™t pour la production

G√©n√®re du code Python fonctionnel et optimis√©.
""",
            "OPTIMISATION": f"""
D√©fi Optimisation - {datetime.now().strftime('%Y-%m-%d %H:%M')}

Optimise ce code pour {domain} en utilisant {algorithm}:

```python
def slow_function(data):
    result = []
    for i in range(len(data)):
        for j in range(len(data)):
            if data[i] > data[j]:
                result.append((i, j))
    return result
```

Objectifs:
- R√©duire la complexit√© temporelle
- Minimiser l'usage m√©moire
- Am√©liorer la lisibilit√©
- Maintenir la fonctionnalit√©

Fournis le code optimis√© avec explications des am√©liorations.
""",
            "DEBUG": f"""
D√©fi Debug - {datetime.now().strftime('%Y-%m-%d %H:%M')}

Trouve et corrige les bugs dans ce code pour {domain}:

```python
def process_data(items):
    result = {}
    for i, item in enumerate(items):
        if item % 2 = 0:
            result[i] = item * 2
        else:
            result[i] = item / 2
    return result

data = [1, 2, 3, 4, 5]
print(process_data(data))
```

T√¢ches:
- Identifier tous les bugs
- Corriger le code
- Ajouter la gestion d'erreurs
- Am√©liorer la robustesse

Fournis le code corrig√© et fonctionnel.
""",
            "IA_CREATIVE": f"""
D√©fi IA Cr√©ative - {datetime.now().strftime('%Y-%m-%d %H:%M')}

Cr√©e un syst√®me intelligent pour {domain} utilisant {algorithm}.

Fonctionnalit√©s requises:
- Apprentissage adaptatif
- Pr√©dictions pr√©cises
- Interface intuitive
- Visualisation des r√©sultats

Sp√©cifications:
- Code modulaire et extensible
- Documentation technique
- Exemples d'utilisation
- Tests de validation

G√©n√®re un syst√®me IA complet et innovant.
""",
            "SCRIPT_UTILE": f"""
D√©fi Script Utile - {datetime.now().strftime('%Y-%m-%d %H:%M')}

D√©veloppe un script pratique pour automatiser {domain}.

Caract√©ristiques:
- Interface en ligne de commande
- Configuration par fichier
- Logging d√©taill√©
- Gestion d'erreurs robuste

Fonctionnalit√©s:
- Traitement par lots
- Sauvegarde automatique
- Rapports de progression
- Mode debug

Cr√©e un outil pr√™t √† l'emploi et professionnel.
""",
            "STRUCTURE_DONNEES": f"""
D√©fi Structure de Donn√©es - {datetime.now().strftime('%Y-%m-%d %H:%M')}

Impl√©mente une structure de donn√©es avanc√©e pour {domain}.

Op√©rations requises:
- Insertion O(log n)
- Recherche O(log n)
- Suppression O(log n)
- Parcours efficace

Bonus:
- S√©rialisation/d√©s√©rialisation
- Op√©rations de masse
- Thread-safety
- Visualisation

Fournis une impl√©mentation compl√®te et test√©e.
""",
            "RESOLUTION_PROBLEME": f"""
D√©fi R√©solution de Probl√®me - {datetime.now().strftime('%Y-%m-%d %H:%M')}

R√©sous ce probl√®me complexe pour {domain}:

Probl√®me: Tu as une liste de t√¢ches avec des d√©pendances. Chaque t√¢che a une dur√©e et des pr√©requis. 
Trouve l'ordre d'ex√©cution optimal qui minimise le temps total tout en respectant les contraintes.

Contraintes:
- Maximum 3 t√¢ches en parall√®le
- Certaines t√¢ches sont critiques (priorit√© haute)
- Gestion des conflits de ressources

Fournis l'algorithme de planification optimal.
""",
            "CODE_GOLF": f"""
D√©fi Code Golf - {datetime.now().strftime('%Y-%m-%d %H:%M')}

Impl√©mente {algorithm} en moins de 50 caract√®res Python.

R√®gles:
- Fonctionnalit√© compl√®te pr√©serv√©e
- Code lisible malgr√© la concision
- Pas de caract√®res Unicode exotiques
- Commentaire explicatif obligatoire

Objectif: Code le plus court possible tout en restant pythonique.
"""
        }
        
        return prompts.get(challenge_type, prompts["ALGORITHME"])
    
    async def run_coding_challenge(self):
        """Ex√©cute un d√©fi de codage avec tous les cerveaux."""
        try:
            # G√©n√©ration du d√©fi
            challenge_prompt = self.generate_challenge_prompt()
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            
            await self.telegram_memory.write_to_group(
                f"üéØ NOUVEAU D√âFI DE CODAGE - {timestamp}\n\n{challenge_prompt}",
                "CHALLENGE_START"
            )
            
            log_message(f"Lancement du d√©fi de codage: {timestamp}")
            
            # Ex√©cution en parall√®le pour tous les cerveaux
            tasks = []
            for brain_type, brain in self.brains.items():
                task = asyncio.create_task(
                    self._brain_challenge_task(brain, challenge_prompt, timestamp)
                )
                tasks.append((brain_type, task))
            
            # Attente des r√©sultats
            results = {}
            for brain_type, task in tasks:
                try:
                    result = await asyncio.wait_for(task, timeout=300)  # 5 minutes max
                    results[brain_type] = result
                except asyncio.TimeoutError:
                    results[brain_type] = {"error": "Timeout", "brain_id": brain_type}
                    await self.telegram_memory.log_error(brain_type, "Timeout d√©fi de codage")
                except Exception as e:
                    results[brain_type] = {"error": str(e), "brain_id": brain_type}
                    await self.telegram_memory.log_error(brain_type, f"Erreur d√©fi: {e}")
            
            # Sauvegarde et analyse des r√©sultats
            await self._save_challenge_results(challenge_prompt, results, timestamp)
            await self._analyze_and_report_results(results, timestamp)
            
            # Mise √† jour de l'historique
            self.challenge_history.append({
                "timestamp": timestamp,
                "challenge": challenge_prompt[:100] + "...",
                "participants": len(results),
                "successful": len([r for r in results.values() if "error" not in r])
            })
            
            # Limitation de l'historique
            if len(self.challenge_history) > 50:
                self.challenge_history = self.challenge_history[-50:]
            
        except Exception as e:
            log_message(f"Erreur d√©fi de codage: {e}", level="error")
            await self.telegram_memory.log_error("SYSTEM", f"Erreur d√©fi global: {e}")
    
    async def _brain_challenge_task(self, brain: Any, challenge_prompt: str, timestamp: str) -> Dict[str, Any]:
        """T√¢che de d√©fi pour un cerveau sp√©cifique."""
        try:
            # Le cerveau participe au d√©fi
            result = await brain.participate_in_coding_challenge(challenge_prompt)
            
            if "error" not in result and "code" in result:
                # Sauvegarde du code g√©n√©r√©
                code_filename = config.DAILY_CHALLENGE_PATH / f"challenge_{brain.brain_id}_{timestamp}.py"
                
                header = f"""# -*- coding: utf-8 -*-
# D√©fi de codage automatis√©
# Cerveau: {brain.brain_id}
# Timestamp: {timestamp}
# Challenge: {challenge_prompt[:100]}...

"""
                
                try:
                    with open(code_filename, "w", encoding="utf-8") as f:
                        f.write(header + result["code"])
                    
                    result["saved_file"] = str(code_filename)
                    log_message(f"Code sauvegard√©: {code_filename}")
                    
                except Exception as e:
                    log_message(f"Erreur sauvegarde {brain.brain_id}: {e}", level="error")
            
            return result
            
        except Exception as e:
            return {"error": str(e), "brain_id": brain.brain_id}
    
    async def _save_challenge_results(self, challenge_prompt: str, results: Dict, timestamp: str):
        """Sauvegarde tous les r√©sultats du d√©fi."""
        try:
            challenge_data = {
                "timestamp": timestamp,
                "challenge_prompt": challenge_prompt,
                "results": results,
                "summary": {
                    "total_participants": len(results),
                    "successful_responses": len([r for r in results.values() if "error" not in r]),
                    "failed_responses": len([r for r in results.values() if "error" in r]),
                    "generated_files": [r.get("saved_file") for r in results.values() if r.get("saved_file")]
                }
            }
            
            results_file = config.DAILY_CHALLENGE_PATH / f"challenge_results_{timestamp}.json"
            await save_json(results_file, challenge_data)
            
            log_message(f"R√©sultats du d√©fi sauvegard√©s: {results_file}")
            
        except Exception as e:
            log_message(f"Erreur sauvegarde r√©sultats: {e}", level="error")
    
    async def _analyze_and_report_results(self, results: Dict, timestamp: str):
        """Analyse et rapporte les r√©sultats dans le groupe Telegram."""
        try:
            successful = [r for r in results.values() if "error" not in r]
            failed = [r for r in results.values() if "error" in r]
            
            report = f"""
üìä RAPPORT D√âFI DE CODAGE - {timestamp}

‚úÖ Succ√®s: {len(successful)}/{len(results)} cerveaux
‚ùå √âchecs: {len(failed)}/{len(results)} cerveaux

=== D√âTAILS SUCC√àS ===
"""
            
            for result in successful:
                brain_id = result.get("brain_id", "Inconnu")
                code_length = len(result.get("code", ""))
                report += f"‚Ä¢ {brain_id}: {code_length} caract√®res g√©n√©r√©s\n"
            
            if failed:
                report += "\n=== D√âTAILS √âCHECS ===\n"
                for result in failed:
                    brain_id = result.get("brain_id", "Inconnu")
                    error = result.get("error", "Erreur inconnue")
                    report += f"‚Ä¢ {brain_id}: {error}\n"
            
            # S√©lection du meilleur code
            if successful:
                best_result = max(successful, key=lambda x: len(x.get("code", "")))
                best_brain = best_result.get("brain_id", "Inconnu")
                best_code = best_result.get("code", "")[:500]
                
                report += f"\nüèÜ MEILLEUR CODE - {best_brain}:\n```python\n{best_code}...\n```"
            
            await self.telegram_memory.write_to_group(report, "CHALLENGE_REPORT")
            
        except Exception as e:
            log_message(f"Erreur analyse r√©sultats: {e}", level="error")
    
    def get_challenge_statistics(self) -> Dict[str, Any]:
        """Retourne les statistiques des d√©fis."""
        if not self.challenge_history:
            return {"total_challenges": 0}
        
        total_challenges = len(self.challenge_history)
        total_participants = sum(c["participants"] for c in self.challenge_history)
        total_successful = sum(c["successful"] for c in self.challenge_history)
        
        avg_success_rate = (total_successful / total_participants * 100) if total_participants > 0 else 0
        
        return {
            "total_challenges": total_challenges,
            "total_participants": total_participants,
            "total_successful": total_successful,
            "average_success_rate": round(avg_success_rate, 2),
            "last_challenge": self.challenge_history[-1] if self.challenge_history else None,
            "is_running": self.is_running
        }

# Fonctions utilitaires pour le syst√®me de d√©fis

def diff_text(old_text: str, new_text: str) -> str:
    """G√©n√®re un diff unifi√© entre deux textes."""
    diff = difflib.unified_diff(
        old_text.splitlines(), 
        new_text.splitlines(), 
        lineterm=""
    )
    return "\n".join(diff)

def analyze_python_code(code: str) -> Dict[str, Any]:
    """Analyse un code Python et retourne des m√©triques."""
    try:
        lines = code.split('\n')
        non_empty_lines = [line for line in lines if line.strip()]
        
        # M√©triques basiques
        metrics = {
            "total_lines": len(lines),
            "code_lines": len(non_empty_lines),
            "comment_lines": len([line for line in lines if line.strip().startswith('#')]),
            "blank_lines": len(lines) - len(non_empty_lines),
            "functions": len([line for line in lines if line.strip().startswith('def ')]),
            "classes": len([line for line in lines if line.strip().startswith('class ')]),
            "imports": len([line for line in lines if line.strip().startswith(('import ', 'from '))]),
            "complexity_score": calculate_complexity(code)
        }
        
        # V√©rification syntaxique
        try:
            compile(code, '<string>', 'exec')
            metrics["syntax_valid"] = True
            metrics["syntax_error"] = None
        except SyntaxError as e:
            metrics["syntax_valid"] = False
            metrics["syntax_error"] = str(e)
        
        return metrics
        
    except Exception as e:
        return {"error": f"Erreur analyse: {e}"}

def calculate_complexity(code: str) -> int:
    """Calcule un score de complexit√© approximatif."""
    complexity_keywords = [
        'if', 'elif', 'else', 'for', 'while', 'try', 'except', 
        'with', 'def', 'class', 'lambda', 'and', 'or'
    ]
    
    complexity = 1  # Base complexity
    for line in code.split('\n'):
        line = line.strip().lower()
        for keyword in complexity_keywords:
            if keyword in line:
                complexity += 1
    
    return complexity

def format_error(error: Exception) -> str:
    """Formate une erreur de mani√®re visuelle."""
    return f"""
‚ö†Ô∏è‚ö†Ô∏è‚ö†Ô∏è ERREUR ‚ö†Ô∏è‚ö†Ô∏è‚ö†Ô∏è
Type: {type(error).__name__}
Message: {str(error)}
‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî
"""

@lru_cache(maxsize=100)
def generate_code_cached(prompt: str, temperature: float = 0.7) -> str:
    """G√©n√®re du code avec cache pour les prompts r√©p√©t√©s."""
    # Cette fonction serait connect√©e √† un mod√®le IA en production
    return f"# Code g√©n√©r√© pour: {prompt[:50]}...\nprint('Code g√©n√©r√© avec cache')"

def batch_generate(prompts: List[str], max_workers: int = 4) -> List[str]:
    """G√©n√®re du code pour plusieurs prompts en parall√®le."""
    def _generate_single(prompt):
        return f"# Code g√©n√©r√© pour: {prompt[:50]}...\nprint('Code g√©n√©r√© en lot')"
    
    with concurrent.futures.ThreadPoolExecutor(max_workers=max_workers) as executor:
        return list(executor.map(_generate_single, prompts))

def adaptive_temp(prompt: str) -> float:
    """Adapte la temp√©rature selon le type de prompt."""
    technical_keywords = ["optimiser", "algorithme", "complexit√©", "performance", "debug"]
    return 0.3 if any(kw in prompt.lower() for kw in technical_keywords) else 0.7

def fix_common_errors(code: str) -> str:
    """Applique des corrections automatiques communes."""
    fixes = {
        "print(": "print(",
        "def  ": "def ",
        "= =": "==",
        "elif ": "elif ",
        "esle:": "else:",
        "ture": "True",
        "flase": "False"
    }
    
    for error, fix in fixes.items():
        code = code.replace(error, fix)
    
    return code

def warmup_ai(model, iterations: int = 3):
    """Pr√©chauffe un mod√®le IA avec des requ√™tes factices."""
    dummy_prompts = ["print('hello')", "def test(): pass", "1+1"]
    for _ in range(iterations):
        for prompt in dummy_prompts:
            if hasattr(model, 'generate'):
                try:
                    model.generate(prompt)
                except:
                    pass  # Ignore les erreurs de pr√©chauffage

# Instance globale du syst√®me de d√©fis
coding_challenge_system = None

def get_coding_challenge_system(telegram_client=None) -> CodingChallengeSystem:
    """Retourne l'instance globale du syst√®me de d√©fis."""
    global coding_challenge_system
    if coding_challenge_system is None:
        coding_challenge_system = CodingChallengeSystem(telegram_client)
    return coding_challenge_system
    
    import asyncio
import hashlib
import io
import re
import time
from datetime import datetime
from pathlib import Path
from typing import List, Optional, Dict, Any
from urllib.parse import urlparse
import httpx

from config import config
from brain_library import TelegramMemoryIntegration
from utils import log_message

class URLDefanger:
    """
    Neutralise les URLs pour emp√™cher les clics accidentels
    et bloque les trackers connus.
    """
    def __init__(self, mode: str = "secure"):
        self.mode = mode
        self.url_pattern = re.compile(r'https?://[^\s\]]+')
        self.tracker_domains = [
            "doubleclick.net", "googleadservices.com", "googlesyndication.com",
            "facebook.com/tr", "analytics.google.com", "hotjar.com",
            "mouseflow.com", "crazyegg.com", "fullstory.com"
        ]
    
    def _generate_hash(self, url: str) -> str:
        """G√©n√®re un identifiant unique pour l'URL."""
        return hashlib.sha256(url.encode()).hexdigest()[:8]
    
    def defang_url(self, url: str) -> str:
        """Transforme une URL en version s√©curis√©e."""
        # Bloque les trackers connus
        for tracker in self.tracker_domains:
            if tracker in url:
                return "[TRACKER_BLOQU√â]"
        
        if self.mode == "secure":
            return f"[URL_BLOQU√âE:#{self._generate_hash(url)}]"
        else:
            parsed = urlparse(url)
            return f"[URL:{parsed.netloc}/...#{self._generate_hash(url)}]"
    
    def defang_text(self, text: str) -> str:
        """Nettoie tout le contenu texte."""
        return self.url_pattern.sub(
            lambda m: self.defang_url(m.group(0)), 
            text
        )

class SecurePageArchiver:
    """
    T√©l√©charge, s√©curise et archive des pages web
    avec gestion des gros fichiers et protection anti-tracking.
    """
    def __init__(self, telegram_client=None):
        self.telegram_client = telegram_client
        self.telegram_memory = TelegramMemoryIntegration(telegram_client)
        self.headers = {
            "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36",
            "Accept-Language": "fr-FR,fr;q=0.9,en;q=0.8",
            "Accept-Encoding": "gzip, deflate, br",
            "Accept": "text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8",
            "DNT": "1",
            "Connection": "keep-alive",
            "Upgrade-Insecure-Requests": "1"
        }
        
    async def fetch_page(self, url: str) -> Optional[httpx.Response]:
        """T√©l√©charge une page avec gestion robuste des erreurs."""
        try:
            async with httpx.AsyncClient(
                timeout=30.0,
                headers=self.headers,
                follow_redirects=True,
                http2=True,
                limits=httpx.Limits(max_keepalive_connections=5, max_connections=10)
            ) as client:
                response = await client.get(url)
                
                # V√©rification de la taille du contenu
                content_length = response.headers.get('content-length')
                if content_length and int(content_length) > config.MAX_CHUNK_SIZE:
                    log_message(f"Contenu trop volumineux pour {url}: {content_length} bytes", level="warning")
                    return None
                
                response.raise_for_status()
                return response
                
        except httpx.HTTPStatusError as e:
            log_message(f"Erreur HTTP pour {url}: {e.response.status_code}", level="warning")
            return None
        except httpx.RequestError as e:
            log_message(f"Erreur r√©seau pour {url}: {e}", level="warning")
            return None
        except Exception as e:
            log_message(f"Erreur inattendue pour {url}: {e}", level="error")
            return None

    async def secure_content(self, url: str, content: str) -> str:
        """Applique les protections de s√©curit√© au contenu."""
        defanger = URLDefanger(mode="secure")
        
        header = f"""
‚ö†Ô∏è CONTENU ARCHIV√â - LIENS NEUTRALIS√âS ‚ö†Ô∏è
URL originale: {url}
Horodatage: {datetime.utcnow().isoformat()}Z
Taille originale: {len(content)} caract√®res
S√©curis√© par: SecurePageArchiver v2.0
=====================================

"""
        
        # Neutralisation des URLs
        secured_content = defanger.defang_text(content)
        
        # Suppression des scripts malveillants
        secured_content = re.sub(r'<script[^>]*>.*?</script>', '[SCRIPT_SUPPRIM√â]', secured_content, flags=re.DOTALL | re.IGNORECASE)
        secured_content = re.sub(r'javascript:[^"\']*', '[JAVASCRIPT_BLOQU√â]', secured_content, flags=re.IGNORECASE)
        secured_content = re.sub(r'on\w+\s*=\s*["\'][^"\']*["\']', '[EVENT_HANDLER_BLOQU√â]', secured_content, flags=re.IGNORECASE)
        
        return header + secured_content

    async def send_chunk(self, chunk: str, url: str, user_id: str, chunk_index: int) -> bool:
        """Envoie un fragment de contenu s√©curis√© via Telegram."""
        try:
            timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
            filename = f"SAFE_{user_id}_{timestamp}_p{chunk_index:03d}.txt"
            
            # Limitation de la taille du chunk pour Telegram
            if len(chunk) > 4000:  # Limite Telegram pour les messages
                chunk = chunk[:4000] + "\n\n[CONTENU_TRONQU√â]"
            
            # Envoi dans le groupe priv√©
            await self.telegram_memory.write_to_group(
                f"üìÑ Fragment {chunk_index+1} | {url[:50]}...\n\n{chunk}",
                "ARCHIVE_CHUNK"
            )
            
            log_message(f"Fragment {chunk_index} envoy√© pour {url}")
            return True
            
        except Exception as e:
            log_message(f"Erreur envoi fragment {chunk_index}: {e}", level="error")
            return False

    async def archive_single_page(self, url: str, user_id: str) -> Dict[str, Any]:
        """Archive une seule page web."""
        start_time = time.time()
        result = {
            "url": url,
            "user_id": user_id,
            "timestamp": datetime.now().isoformat(),
            "success": False,
            "chunks_sent": 0,
            "total_size": 0,
            "processing_time": 0,
            "error": None
        }
        
        try:
            # Log du d√©but d'archivage
            await self.telegram_memory.log_brain_activity(
                "ARCHIVER",
                f"D√©but archivage: {url}",
                {"user_id": user_id}
            )
            
            # T√©l√©chargement de la page
            response = await self.fetch_page(url)
            if not response:
                result["error"] = "√âchec du t√©l√©chargement"
                return result
            
            # V√©rification du type de contenu
            content_type = response.headers.get('content-type', '').lower()
            if not any(ct in content_type for ct in ['text/html', 'text/plain', 'application/json']):
                result["error"] = f"Type de contenu non support√©: {content_type}"
                return result
            
            # S√©curisation du contenu
            raw_content = response.text
            result["total_size"] = len(raw_content)
            
            secured_content = await self.secure_content(url, raw_content)
            
            # D√©coupage en chunks
            chunks = []
            chunk_size = config.MAX_CHUNK_SIZE // 2  # Plus petit pour la s√©curit√© Telegram
            
            for i in range(0, len(secured_content), chunk_size):
                chunk = secured_content[i:i + chunk_size]
                chunks.append(chunk)
            
            # Envoi des chunks
            successful_chunks = 0
            for i, chunk in enumerate(chunks):
                if await self.send_chunk(chunk, url, user_id, i):
                    successful_chunks += 1
                    await asyncio.sleep(0.5)  # √âviter le rate limiting Telegram
                else:
                    break
            
            result["chunks_sent"] = successful_chunks
            result["success"] = successful_chunks > 0
            
            # Log de fin
            processing_time = time.time() - start_time
            result["processing_time"] = processing_time
            
            await self.telegram_memory.log_success(
                "ARCHIVER",
                f"Page archiv√©e: {url}",
                f"{successful_chunks} fragments envoy√©s"
            )
            
        except Exception as e:
            result["error"] = str(e)
            await self.telegram_memory.log_error("ARCHIVER", f"Erreur archivage {url}: {e}")
        
        return result

class ArchiveCoordinator:
    """
    Coordinateur pour l'archivage de multiples pages en parall√®le.
    """
    def __init__(self, telegram_client=None, max_concurrent: int = 3):
        self.archiver = SecurePageArchiver(telegram_client)
        self.max_concurrent = max_concurrent
        self.telegram_memory = TelegramMemoryIntegration(telegram_client)
        
    async def archive_multiple_pages(self, links: List[str], user_id: str) -> Dict[str, Any]:
        """Archive plusieurs pages en parall√®le avec limitation de concurrence."""
        start_time = time.time()
        
        await self.telegram_memory.write_to_group(
            f"üöÄ D√©but archivage de {len(links)} pages pour l'utilisateur {user_id}",
            "ARCHIVE_START"
        )
        
        # Limitation du nombre de liens
        if len(links) > 10:
            links = links[:10]
            await self.telegram_memory.write_to_group(
                "‚ö†Ô∏è Limitation appliqu√©e: maximum 10 liens par session",
                "ARCHIVE_LIMIT"
            )
        
        # Semaphore pour limiter la concurrence
        semaphore = asyncio.Semaphore(self.max_concurrent)
        
        async def archive_with_semaphore(url: str) -> Dict[str, Any]:
            async with semaphore:
                return await self.archiver.archive_single_page(url, user_id)
        
        # Ex√©cution en parall√®le
        tasks = [archive_with_semaphore(url) for url in links]
        results = await asyncio.gather(*tasks, return_exceptions=True)
        
        # Compilation des r√©sultats
        summary = {
            "total_links": len(links),
            "successful": 0,
            "failed": 0,
            "total_chunks": 0,
            "total_size": 0,
            "processing_time": time.time() - start_time,
            "results": []
        }
        
        for i, result in enumerate(results):
            if isinstance(result, Exception):
                error_result = {
                    "url": links[i] if i < len(links) else "Unknown",
                    "success": False,
                    "error": str(result)
                }
                summary["results"].append(error_result)
                summary["failed"] += 1
            else:
                summary["results"].append(result)
                if result["success"]:
                    summary["successful"] += 1
                    summary["total_chunks"] += result["chunks_sent"]
                    summary["total_size"] += result["total_size"]
                else:
                    summary["failed"] += 1
        
        # Rapport final
        await self.telegram_memory.write_to_group(
            f"""
üìä RAPPORT D'ARCHIVAGE TERMIN√â

üë§ Utilisateur: {user_id}
üìä Statistiques:
  ‚Ä¢ Total: {summary['total_links']} liens
  ‚Ä¢ Succ√®s: {summary['successful']} pages
  ‚Ä¢ √âchecs: {summary['failed']} pages
  ‚Ä¢ Fragments: {summary['total_chunks']} envoy√©s
  ‚Ä¢ Taille: {summary['total_size']:,} caract√®res
  ‚Ä¢ Dur√©e: {summary['processing_time']:.2f}s

‚úÖ Toutes les pages sont s√©curis√©es et archiv√©es dans ce groupe.
""",
            "ARCHIVE_COMPLETE"
        )
        
        return summary

# Fonction principale pour l'archivage (utilis√©e par les outils)
async def fetch_and_archive_pages(links: List[str], user_id: str, context=None) -> Dict[str, Any]:
    """
    Fonction principale pour t√©l√©charger, s√©curiser et archiver des pages web.
    
    Args:
        links: Liste des URLs √† archiver
        user_id: Identifiant de l'utilisateur
        context: Contexte (non utilis√©, pour compatibilit√©)
    
    Returns:
        Dict contenant le r√©sum√© de l'archivage
    """
    try:
        # Import du client Telegram depuis les instances
        from app_clients_instances import telegram_bot_client
        
        coordinator = ArchiveCoordinator(telegram_bot_client, max_concurrent=3)
        summary = await coordinator.archive_multiple_pages(links, user_id)
        
        return {
            "tool_output": f"‚úÖ Archivage termin√©: {summary['successful']}/{summary['total_links']} pages archiv√©es avec succ√®s. {summary['total_chunks']} fragments envoy√©s dans le groupe priv√©.",
            "summary": summary
        }
        
    except Exception as e:
        error_msg = f"‚ùå Erreur syst√®me d'archivage: {e}"
        log_message(f"Erreur fetch_and_archive_pages: {e}", level="error")
        return {
            "tool_output": error_msg,
            "error": str(e)
        }

# Classes utilitaires suppl√©mentaires

class ContentAnalyzer:
    """Analyse le contenu des pages archiv√©es."""
    
    @staticmethod
    def extract_metadata(content: str, url: str) -> Dict[str, Any]:
        """Extrait les m√©tadonn√©es d'une page."""
        metadata = {
            "url": url,
            "timestamp": datetime.now().isoformat(),
            "size": len(content),
            "title": "",
            "description": "",
            "language": "unknown",
            "charset": "unknown"
        }
        
        # Extraction du titre
        title_match = re.search(r'<title[^>]*>(.*?)</title>', content, re.IGNORECASE | re.DOTALL)
        if title_match:
            metadata["title"] = title_match.group(1).strip()[:200]
        
        # Extraction de la description
        desc_match = re.search(r'<meta[^>]*name=["\']description["\'][^>]*content=["\']([^"\']*)["\']', content, re.IGNORECASE)
        if desc_match:
            metadata["description"] = desc_match.group(1).strip()[:500]
        
        # Extraction de la langue
        lang_match = re.search(r'<html[^>]*lang=["\']([^"\']*)["\']', content, re.IGNORECASE)
        if lang_match:
            metadata["language"] = lang_match.group(1).strip()
        
        return metadata
    
    @staticmethod
    def count_elements(content: str) -> Dict[str, int]:
        """Compte les √©l√©ments HTML dans le contenu."""
        elements = {
            "links": len(re.findall(r'<a[^>]*href=', content, re.IGNORECASE)),
            "images": len(re.findall(r'<img[^>]*src=', content, re.IGNORECASE)),
            "scripts": len(re.findall(r'<script[^>]*>', content, re.IGNORECASE)),
            "forms": len(re.findall(r'<form[^>]*>', content, re.IGNORECASE)),
            "paragraphs": len(re.findall(r'<p[^>]*>', content, re.IGNORECASE)),
            "headings": len(re.findall(r'<h[1-6][^>]*>', content, re.IGNORECASE))
        }
        
        return elements

class ArchiveStorage:
    """Gestionnaire de stockage pour les archives."""
    
    def __init__(self):
        self.archive_dir = config.BASE_DIR / "archives"
        self.archive_dir.mkdir(exist_ok=True)
        
    async def save_archive_metadata(self, user_id: str, summary: Dict[str, Any]):
        """Sauvegarde les m√©tadonn√©es d'archivage."""
        try:
            metadata_file = self.archive_dir / f"archive_{user_id}_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json"
            
            # Import de save_json depuis utils
            from utils import save_json
            await save_json(metadata_file, summary)
            
            log_message(f"M√©tadonn√©es d'archivage sauvegard√©es: {metadata_file}")
            
        except Exception as e:
            log_message(f"Erreur sauvegarde m√©tadonn√©es: {e}", level="error")
    
    def get_user_archives(self, user_id: str) -> List[Path]:
        """R√©cup√®re la liste des archives d'un utilisateur."""
        pattern = f"archive_{user_id}_*.json"
        return list(self.archive_dir.glob(pattern))
    
    def cleanup_old_archives(self, days: int = 30):
        """Nettoie les anciennes archives."""
        cutoff_time = time.time() - (days * 24 * 60 * 60)
        
        for archive_file in self.archive_dir.glob("archive_*.json"):
            if archive_file.stat().st_mtime < cutoff_time:
                try:
                    archive_file.unlink()
                    log_message(f"Archive supprim√©e: {archive_file}")
                except Exception as e:
                    log_message(f"Erreur suppression archive {archive_file}: {e}", level="error")

# Instance globale du stockage
archive_storage = ArchiveStorage()

import asyncio
import json
import re
import base64
import traceback
from typing import Dict, Any, List, Optional, Union, Tuple

from app_singletons import endpoint_health_manager, quota_manager
from config import config
from utils import log_message, neutralize_urls, find_tool_by_name

# Import des clients API optimis√© pour √©viter les d√©pendances circulaires
def get_api_clients():
    """Import dynamique des clients API."""
    try:
        from app_clients_instances import (
            webcontainer_client, ocr_client, deepseek_client, serper_client,
            wolfram_alpha_client, tavily_client, apiflash_client, crawlbase_client,
            detect_language_client, guardian_client, ip2location_client, shodan_client,
            weather_api_client, cloudmersive_client, greynoise_client, pulsedive_client,
            stormglass_client, loginradius_client, jsonbin_client, huggingface_client,
            twilio_client, abstractapi_client, google_custom_search_client,
            randommer_client, tomorrow_io_client, openweathermap_client, mockaroo_client,
            openpagerank_client, rapidapi_client, telegram_bot_client
        )
        return {
            'webcontainer': webcontainer_client,
            'ocr': ocr_client,
            'deepseek': deepseek_client,
            'serper': serper_client,
            'wolfram': wolfram_alpha_client,
            'tavily': tavily_client,
            'apiflash': apiflash_client,
            'crawlbase': crawlbase_client,
            'detect_language': detect_language_client,
            'guardian': guardian_client,
            'ip2location': ip2location_client,
            'shodan': shodan_client,
            'weather_api': weather_api_client,
            'cloudmersive': cloudmersive_client,
            'greynoise': greynoise_client,
            'pulsedive': pulsedive_client,
            'stormglass': stormglass_client,
            'loginradius': loginradius_client,
            'jsonbin': jsonbin_client,
            'huggingface': huggingface_client,
            'twilio': twilio_client,
            'abstractapi': abstractapi_client,
            'google_search': google_custom_search_client,
            'randommer': randommer_client,
            'tomorrow_io': tomorrow_io_client,
            'openweathermap': openweathermap_client,
            'mockaroo': mockaroo_client,
            'openpagerank': openpagerank_client,
            'rapidapi': rapidapi_client,
            'telegram': telegram_bot_client
        }
    except ImportError as e:
        log_message(f"Erreur import clients API: {e}", level="warning")
        return {}

async def execute_tool(tool_name: str, context: Any = None, **kwargs) -> Dict[str, Any]:
    """
    Ex√©cute un outil sp√©cifique en fonction de son nom et des arguments fournis.
    Compatible avec les 7 cerveaux autonomes.
    """
    log_message(f"Ex√©cution de l'outil: {tool_name} avec kwargs: {kwargs}")
    tool_config_info = find_tool_by_name(tool_name)

    if not tool_config_info:
        log_message(f"Outil non trouv√©: {tool_name}", level="error")
        return {"tool_name": tool_name, "tool_args": kwargs, "tool_output": f"Erreur: Outil '{tool_name}' non trouv√© ou non configur√©."}

    result = ""
    try:
        # Routage vers les fonctions d'outils sp√©cifiques
        if tool_name == "google_search":
            result = await google_search_tool(kwargs.get("queries"))
        elif tool_name == "media_control":
            result = await media_control_tool(
                action=kwargs.get("action"),
                position=kwargs.get("position"),
                offset=kwargs.get("offset")
            )
        elif tool_name == "clock":
            result = await clock_tool(**kwargs)
        elif tool_name == "ocr_space":
            result = await ocr_space_tool(kwargs.get("image_base64"))
        elif tool_name == "deepseek_chat":
            result = await deepseek_chat_tool(kwargs.get("prompt"), kwargs.get("model"))
        elif tool_name == "serper_dev":
            result = await serper_dev_tool(kwargs.get("query_text"))
        elif tool_name == "wolfram_alpha":
            result = await wolfram_alpha_tool(kwargs.get("input_text"))
        elif tool_name == "tavily_search":
            result = await tavily_search_tool(kwargs.get("query_text"), kwargs.get("max_results"))
        elif tool_name == "apiflash_screenshot":
            result = await apiflash_screenshot_tool(kwargs.get("url"))
        elif tool_name == "crawlbase_scraper":
            result = await crawlbase_scraper_tool(kwargs.get("url"), kwargs.get("use_js"))
        elif tool_name == "detect_language":
            result = await detect_language_tool(kwargs.get("text"))
        elif tool_name == "guardian_news":
            result = await guardian_news_tool(kwargs.get("query_text"))
        elif tool_name == "ip2location":
            result = await ip2location_tool(kwargs.get("ip_address"))
        elif tool_name == "shodan":
            result = await shodan_tool(kwargs.get("query_text"))
        elif tool_name == "weather_api":
            result = await weather_api_tool(kwargs.get("location"))
        elif tool_name == "cloudmersive_domain":
            result = await cloudmersive_domain_tool(kwargs.get("domain"))
        elif tool_name == "greynoise":
            result = await greynoise_tool(kwargs.get("ip_address"))
        elif tool_name == "pulsedive":
            result = await pulsedive_tool(kwargs.get("indicator"), kwargs.get("type"))
        elif tool_name == "stormglass":
            result = await stormglass_tool(kwargs.get("lat"), kwargs.get("lng"), kwargs.get("params"))
        elif tool_name == "loginradius_ping":
            result = await loginradius_ping_tool()
        elif tool_name == "jsonbin_io":
            result = await jsonbin_io_tool(kwargs.get("data"), kwargs.get("private"), kwargs.get("bin_id"))
        elif tool_name == "huggingface_inference":
            result = await huggingface_inference_tool(kwargs.get("model_name"), kwargs.get("input_text"))
        elif tool_name == "twilio_balance":
            result = await twilio_balance_tool()
        elif tool_name == "abstractapi":
            result = await abstractapi_tool(kwargs.get("input_value"), kwargs.get("api_type"))
        elif tool_name == "google_custom_search":
            result = await google_custom_search_tool(kwargs.get("query_text"))
        elif tool_name == "randommer_phone":
            result = await randommer_phone_tool(kwargs.get("country_code"), kwargs.get("quantity"))
        elif tool_name == "tomorrow_io_weather":
            result = await tomorrow_io_weather_tool(kwargs.get("location"), kwargs.get("fields"))
        elif tool_name == "openweathermap_weather":
            result = await openweathermap_weather_tool(kwargs.get("location"))
        elif tool_name == "mockaroo_data":
            result = await mockaroo_data_tool(kwargs.get("count"), kwargs.get("fields_json"))
        elif tool_name == "openpagerank":
            result = await openpagerank_tool(kwargs.get("domains"))
        elif tool_name == "rapidapi":
            result = await rapidapi_tool(kwargs.get("api_name"), **kwargs.get("api_kwargs", {}))
        elif tool_name == "run_in_sandbox":
            result = await run_in_sandbox_tool(kwargs.get("code"), kwargs.get("language"))
        elif tool_name == "webcontainer_sandbox":
            result = await webcontainer_sandbox_tool(kwargs.get("code"), kwargs.get("language"))
        elif tool_name == "fetch_and_archive_pages":
            # Import dynamique pour √©viter les d√©pendances circulaires
            from security_archiver import fetch_and_archive_pages
            result = await fetch_and_archive_pages(kwargs.get("links"), kwargs.get("user_id"), context=context)
        else:
            log_message(f"Aucun gestionnaire d'outil d√©fini pour: {tool_name}", level="error")
            result = f"Erreur: Aucun gestionnaire d'outil d√©fini pour '{tool_name}'."

    except Exception as e:
        log_message(f"Erreur lors de l'ex√©cution de l'outil {tool_name}: {e}", level="error")
        log_message(f"Traceback: {traceback.format_exc()}", level="error")
        result = f"Erreur lors de l'ex√©cution de l'outil {tool_name}: {e}"

    return {"tool_name": tool_name, "tool_args": kwargs, "tool_output": result}

# --- Fonctions d'outils sp√©cifiques ---

async def google_search_tool(queries: List[str]) -> str:
    """Effectue une recherche Google en utilisant Serper ou Google Custom Search."""
    if not queries:
        return "Erreur: Aucune requ√™te fournie"
    
    api_clients = get_api_clients()
    results = []
    
    for query in queries:
        log_message(f"Recherche Google pour: {query}")
        
        # Prioriser Google Custom Search si disponible
        try:
            if 'google_search' in api_clients and api_clients['google_search']:
                response = await api_clients['google_search'].search(query)
            else:
                response = await api_clients['serper'].search(query)
            
            if isinstance(response, str):
                response = neutralize_urls(response)
            elif isinstance(response, dict) and response.get("error"):
                pass
            
            results.append(f"R√©sultat pour '{query}': {response}")
            
        except Exception as e:
            results.append(f"Erreur pour '{query}': {e}")
    
    return "\n".join(results)

async def media_control_tool(action: str, position: Optional[int] = None, offset: Optional[int] = None) -> str:
    """Contr√¥le la lecture multim√©dia (simulation)."""
    actions_map = {
        "like": "M√©dia actuel aim√©.",
        "dislike": "M√©dia actuel non aim√©.",
        "next": "Passage au m√©dia suivant.",
        "previous": "Passage au m√©dia pr√©c√©dent.",
        "pause": "M√©dia actuel mis en pause.",
        "resume": "Lecture du m√©dia reprise.",
        "stop": "M√©dia actuel arr√™t√©.",
        "replay": "M√©dia actuel rejou√©.",
        "seek_absolute": f"M√©dia avanc√© √† la position {position} secondes.",
        "seek_relative": f"M√©dia avanc√© de {offset} secondes."
    }
    
    log_message(f"Action media_control.{action}() simul√©e.")
    return actions_map.get(action, f"Action non support√©e pour media_control: {action}")

async def clock_tool(**kwargs) -> str:
    """G√®re les alarmes et les minuteurs (simulation)."""
    action = kwargs.get("action")
    
    if action == "create_alarm":
        duration = kwargs.get("duration")
        time = kwargs.get("time")
        return f"Alarme cr√©√©e pour {time if time else duration}."
    elif action == "create_timer":
        duration = kwargs.get("duration")
        return f"Minuteur cr√©√© pour {duration}."
    elif action == "show_matching_alarms":
        return "Affichage des alarmes correspondantes (simul√©)."
    elif action == "show_matching_timers":
        return "Affichage des minuteurs correspondants (simul√©)."
    elif action == "modify_alarm_v2":
        return "Alarme modifi√©e (simul√©)."
    elif action == "modify_timer_v2":
        return "Minuteur modifi√© (simul√©)."
    elif action == "snooze":
        return "Alarme mise en veille."
    else:
        return f"Action non support√©e pour clock: {action}"

async def run_in_sandbox_tool(code: str, language: str = "python") -> str:
    """Ex√©cute du code dans une sandbox s√©curis√©e (simulation)."""
    log_message(f"Ex√©cution simul√©e de code {language}: {code[:100]}...")
    
    if language == "python":
        # V√©rification syntaxique basique
        try:
            compile(code, '<string>', 'exec')
            return f"‚úÖ Code Python syntaxiquement correct:\n```python\n{code}\n```\n\nEx√©cution simul√©e: Le code s'ex√©cuterait sans erreur."
        except SyntaxError as e:
            return f"‚ùå Erreur de syntaxe Python: {e}"
    elif language == "shell":
        return f"‚úÖ Commande shell simul√©e: {code}\nR√©sultat: Ex√©cution simul√©e r√©ussie."
    else:
        return f"‚ùå Langage non support√©: {language}"

async def webcontainer_sandbox_tool(code: str, language: str = "javascript") -> str:
    """Ex√©cute du code dans un WebContainer (simulation)."""
    log_message(f"Ex√©cution WebContainer simul√©e {language}: {code[:100]}...")
    
    api_clients = get_api_clients()
    if 'webcontainer' in api_clients:
        try:
            response = await api_clients['webcontainer'].run_code(code, language)
            return str(response)
        except Exception as e:
            return f"Erreur WebContainer: {e}"
    else:
        return f"‚úÖ WebContainer simul√© - Code {language} ex√©cut√© avec succ√®s"

# Fonctions d'outils pour services externes
async def ocr_space_tool(image_base64: str) -> str:
    """Extrait le texte d'une image via OCR.space."""
    api_clients = get_api_clients()
    if 'ocr' in api_clients:
        try:
            response = await api_clients['ocr'].parse_image(image_base64)
            return str(response)
        except Exception as e:
            return f"Erreur OCR: {e}"
    return "Service OCR non disponible"

async def deepseek_chat_tool(prompt: str, model: str = "deepseek-chat") -> str:
    """Interroge DeepSeek pour des conversations."""
    api_clients = get_api_clients()
    if 'deepseek' in api_clients:
        try:
            messages = [{"role": "user", "content": prompt}]
            response = await api_clients['deepseek'].chat_completion(messages, model)
            return str(response)
        except Exception as e:
            return f"Erreur DeepSeek: {e}"
    return "Service DeepSeek non disponible"

async def serper_dev_tool(query_text: str) -> str:
    """Effectue une recherche web via Serper."""
    api_clients = get_api_clients()
    if 'serper' in api_clients:
        try:
            response = await api_clients['serper'].search(query_text)
            if isinstance(response, str):
                return neutralize_urls(response)
            return str(response)
        except Exception as e:
            return f"Erreur Serper: {e}"
    return "Service Serper non disponible"

async def wolfram_alpha_tool(input_text: str) -> str:
    """Interroge WolframAlpha pour des calculs."""
    api_clients = get_api_clients()
    if 'wolfram' in api_clients:
        try:
            response = await api_clients['wolfram'].query(input_text)
            return str(response)
        except Exception as e:
            return f"Erreur WolframAlpha: {e}"
    return "Service WolframAlpha non disponible"

async def tavily_search_tool(query_text: str, max_results: int = 3) -> str:
    """Effectue une recherche web avanc√©e via Tavily."""
    api_clients = get_api_clients()
    if 'tavily' in api_clients:
        try:
            response = await api_clients['tavily'].search(query_text, max_results)
            if isinstance(response, str):
                return neutralize_urls(response)
            return str(response)
        except Exception as e:
            return f"Erreur Tavily: {e}"
    return "Service Tavily non disponible"

async def apiflash_screenshot_tool(url: str) -> str:
    """Capture une capture d'√©cran d'une URL via ApiFlash."""
    api_clients = get_api_clients()
    if 'apiflash' in api_clients:
        try:
            response = await api_clients['apiflash'].screenshot(url)
            return str(response)
        except Exception as e:
            return f"Erreur ApiFlash: {e}"
    return "Service ApiFlash non disponible"

async def crawlbase_scraper_tool(url: str, use_js: bool = False) -> str:
    """Scrape le contenu d'une URL via Crawlbase."""
    api_clients = get_api_clients()
    if 'crawlbase' in api_clients:
        try:
            response = await api_clients['crawlbase'].scrape(url, use_js)
            if isinstance(response, str):
                return neutralize_urls(response)
            return str(response)
        except Exception as e:
            return f"Erreur Crawlbase: {e}"
    return "Service Crawlbase non disponible"

async def detect_language_tool(text: str) -> str:
    """D√©tecte la langue d'un texte."""
    api_clients = get_api_clients()
    if 'detect_language' in api_clients:
        try:
            response = await api_clients['detect_language'].detect(text)
            return str(response)
        except Exception as e:
            return f"Erreur DetectLanguage: {e}"
    return "Service DetectLanguage non disponible"

async def guardian_news_tool(query_text: str) -> str:
    """Recherche des articles de presse via The Guardian."""
    api_clients = get_api_clients()
    if 'guardian' in api_clients:
        try:
            response = await api_clients['guardian'].search_news(query_text)
            if isinstance(response, str):
                return neutralize_urls(response)
            return str(response)
        except Exception as e:
            return f"Erreur Guardian: {e}"
    return "Service Guardian non disponible"

async def ip2location_tool(ip_address: str) -> str:
    """G√©olocalise une adresse IP."""
    api_clients = get_api_clients()
    if 'ip2location' in api_clients:
        try:
            response = await api_clients['ip2location'].geolocate_ip(ip_address)
            return str(response)
        except Exception as e:
            return f"Erreur IP2Location: {e}"
    return "Service IP2Location non disponible"

async def shodan_tool(query_text: str = "") -> str:
    """Interroge Shodan pour des informations sur un h√¥te IP."""
    api_clients = get_api_clients()
    if 'shodan' in api_clients:
        try:
            response = await api_clients['shodan'].get_info(query_text)
            return str(response)
        except Exception as e:
            return f"Erreur Shodan: {e}"
    return "Service Shodan non disponible"

async def weather_api_tool(location: str) -> str:
    """R√©cup√®re les conditions m√©t√©orologiques."""
    api_clients = get_api_clients()
    if 'weather_api' in api_clients:
        try:
            response = await api_clients['weather_api'].get_current_weather(location)
            return str(response)
        except Exception as e:
            return f"Erreur WeatherAPI: {e}"
    return "Service WeatherAPI non disponible"

async def cloudmersive_domain_tool(domain: str) -> str:
    """V√©rifie la validit√© d'un domaine."""
    api_clients = get_api_clients()
    if 'cloudmersive' in api_clients:
        try:
            response = await api_clients['cloudmersive'].validate_domain(domain)
            return str(response)
        except Exception as e:
            return f"Erreur Cloudmersive: {e}"
    return "Service Cloudmersive non disponible"

async def greynoise_tool(ip_address: str) -> str:
    """Analyse une adresse IP via GreyNoise."""
    api_clients = get_api_clients()
    if 'greynoise' in api_clients:
        try:
            response = await api_clients['greynoise'].ip_lookup(ip_address)
            return str(response)
        except Exception as e:
            return f"Erreur GreyNoise: {e}"
    return "Service GreyNoise non disponible"

async def pulsedive_tool(indicator: str, type: str = "auto") -> str:
    """Analyse un indicateur de menace via Pulsedive."""
    api_clients = get_api_clients()
    if 'pulsedive' in api_clients:
        try:
            response = await api_clients['pulsedive'].analyze_indicator(indicator, type)
            return str(response)
        except Exception as e:
            return f"Erreur Pulsedive: {e}"
    return "Service Pulsedive non disponible"

async def stormglass_tool(lat: float, lng: float, params: str = "airTemperature,waveHeight") -> str:
    """R√©cup√®re les donn√©es m√©t√©orologiques maritimes."""
    api_clients = get_api_clients()
    if 'stormglass' in api_clients:
        try:
            response = await api_clients['stormglass'].get_weather_point(lat, lng, params)
            return str(response)
        except Exception as e:
            return f"Erreur StormGlass: {e}"
    return "Service StormGlass non disponible"

async def loginradius_ping_tool() -> str:
    """Effectue un ping √† l'API LoginRadius."""
    api_clients = get_api_clients()
    if 'loginradius' in api_clients:
        try:
            response = await api_clients['loginradius'].ping()
            return str(response)
        except Exception as e:
            return f"Erreur LoginRadius: {e}"
    return "Service LoginRadius non disponible"

async def jsonbin_io_tool(data: Optional[Dict[str, Any]] = None, private: bool = True, bin_id: Optional[str] = None) -> str:
    """Cr√©e ou acc√®de √† un bin JSON."""
    api_clients = get_api_clients()
    if 'jsonbin' in api_clients:
        try:
            response = await api_clients['jsonbin'].handle_bin(data, private, bin_id)
            return str(response)
        except Exception as e:
            return f"Erreur Jsonbin: {e}"
    return "Service Jsonbin non disponible"

async def huggingface_inference_tool(model_name: str = "distilbert-base-uncased-finetuned-sst-2-english", input_text: str = "Hello world") -> str:
    """Effectue une inf√©rence sur un mod√®le HuggingFace."""
    api_clients = get_api_clients()
    if 'huggingface' in api_clients:
        try:
            response = await api_clients['huggingface'].inference(model_name, input_text)
            return str(response)
        except Exception as e:
            return f"Erreur HuggingFace: {e}"
    return "Service HuggingFace non disponible"

async def twilio_balance_tool() -> str:
    """R√©cup√®re le solde du compte Twilio."""
    
    api_clients = get_api_clients()
    if 'twilio' in api_clients:
        try:
            response = await api_clients['twilio'].get_account_balance()
            return str(response)
        except Exception as e:
            return f"Erreur Twilio: {e}"
    return "Service Twilio non disponible"

async def abstractapi_tool(input_value: str, api_type: str) -> str:
    """Interroge diverses APIs d'AbstractAPI."""
    api_clients = get_api_clients()
    if 'abstractapi' in api_clients:
        try:
            response = await api_clients['abstractapi'].call_api(input_value, api_type)
            return str(response)
        except Exception as e:
            return f"Erreur AbstractAPI: {e}"
    return "Service AbstractAPI non disponible"

async def google_custom_search_tool(query_text: str) -> str:
    """Effectue une recherche personnalis√©e Google."""
    api_clients = get_api_clients()
    if 'google_search' in api_clients:
        try:
            response = await api_clients['google_search'].search(query_text)
            if isinstance(response, str):
                return neutralize_urls(response)
            return str(response)
        except Exception as e:
            return f"Erreur Google Custom Search: {e}"
    return "Service Google Custom Search non disponible"

async def randommer_phone_tool(country_code: str = "US", quantity: int = 1) -> str:
    """G√©n√®re des num√©ros de t√©l√©phone al√©atoires."""
    api_clients = get_api_clients()
    if 'randommer' in api_clients:
        try:
            response = await api_clients['randommer'].generate_phone_number(country_code, quantity)
            return str(response)
        except Exception as e:
            return f"Erreur Randommer: {e}"
    return "Service Randommer non disponible"

async def tomorrow_io_weather_tool(location: str, fields: Optional[List[str]] = None) -> str:
    """R√©cup√®re les pr√©visions m√©t√©orologiques via Tomorrow.io."""
    api_clients = get_api_clients()
    if 'tomorrow_io' in api_clients:
        try:
            if fields is None:
                fields = ["temperature", "humidity", "windSpeed"]
            response = await api_clients['tomorrow_io'].get_weather_timelines(location, fields)
            return str(response)
        except Exception as e:
            return f"Erreur Tomorrow.io: {e}"
    return "Service Tomorrow.io non disponible"

async def openweathermap_weather_tool(location: str) -> str:
    """R√©cup√®re les conditions m√©t√©orologiques via OpenWeatherMap."""
    api_clients = get_api_clients()
    if 'openweathermap' in api_clients:
        try:
            response = await api_clients['openweathermap'].get_current_weather(location)
            return str(response)
        except Exception as e:
            return f"Erreur OpenWeatherMap: {e}"
    return "Service OpenWeatherMap non disponible"

async def mockaroo_data_tool(count: int = 1, fields_json: Optional[str] = None) -> str:
    """G√©n√®re des donn√©es de test via Mockaroo."""
    api_clients = get_api_clients()
    if 'mockaroo' in api_clients:
        try:
            response = await api_clients['mockaroo'].generate_data(count, fields_json)
            return str(response)
        except Exception as e:
            return f"Erreur Mockaroo: {e}"
    return "Service Mockaroo non disponible"

async def openpagerank_tool(domains: List[str]) -> str:
    """R√©cup√®re le PageRank de domaines."""
    api_clients = get_api_clients()
    if 'openpagerank' in api_clients:
        try:
            response = await api_clients['openpagerank'].get_page_rank(domains)
            return str(response)
        except Exception as e:
            return f"Erreur OpenPageRank: {e}"
    return "Service OpenPageRank non disponible"

async def rapidapi_tool(api_name: str, **api_kwargs) -> str:
    """Interroge diverses APIs via RapidAPI."""
    api_clients = get_api_clients()
    if 'rapidapi' in api_clients:
        try:
            response = await api_clients['rapidapi'].call_rapidapi_endpoint(api_name, api_kwargs)
            return str(response)
        except Exception as e:
            return f"Erreur RapidAPI: {e}"
    return "Service RapidAPI non disponible"

def get_gemini_tools() -> List[Dict]:
    """
    Construit la liste des outils disponibles pour l'API Gemini.
    Compatible avec tous les cerveaux autonomes.
    """
    tools = []
    for tool_name, tool_info in config.TOOL_CONFIG.items():
        if tool_info.get("enabled", False):
            function_declaration = {
                "name": tool_name,
                "description": tool_info.get("description", ""),
                "parameters": {
                    "type": "OBJECT",
                    "properties": {},
                    "required": []
                }
            }
            
            # Ajoute les param√®tres de l'outil
            for param_name, param_info in tool_info.get("parameters", {}).items():
                function_declaration["parameters"]["properties"][param_name] = {
                    "type": param_info.get("type", "STRING"),
                    "description": param_info.get("description", "")
                }
                
                # Ajoute les √©num√©rations si pr√©sentes
                if "enum" in param_info:
                    function_declaration["parameters"]["properties"][param_name]["enum"] = param_info["enum"]
                
                # Ajoute les valeurs par d√©faut si pr√©sentes
                if "default" in param_info:
                    function_declaration["parameters"]["properties"][param_name]["default"] = param_info["default"]
                
                if param_info.get("required", False):
                    function_declaration["parameters"]["required"].append(param_name)
            
            tools.append({"function_declarations": [function_declaration]})
    
    return tools

# Fonctions utilitaires pour les outils

def validate_tool_parameters(tool_name: str, provided_params: Dict[str, Any]) -> Tuple[bool, str]:
    """Valide les param√®tres fournis pour un outil."""
    tool_config = find_tool_by_name(tool_name)
    if not tool_config:
        return False, f"Outil {tool_name} non trouv√©"
    
    required_params = []
    for param_name, param_info in tool_config.get("parameters", {}).items():
        if param_info.get("required", False):
            required_params.append(param_name)
    
    missing_params = [param for param in required_params if param not in provided_params]
    if missing_params:
        return False, f"Param√®tres manquants: {', '.join(missing_params)}"
    
    return True, "Param√®tres valides"

def sanitize_tool_output(output: str, max_length: int = 2000) -> str:
    """Nettoie et limite la sortie d'un outil."""
    if not isinstance(output, str):
        output = str(output)
    
    # Neutralise les URLs
    output = neutralize_urls(output)
    
    # Limite la longueur
    if len(output) > max_length:
        output = output[:max_length] + "... [TRONQU√â]"
    
    return output

def extract_code_from_response(response: str) -> Optional[str]:
    """Extrait le code d'une r√©ponse format√©e."""
    # Recherche de blocs de code markdown
    code_pattern = r'```(?:python|py)?\n(.*?)\n```'
    matches = re.findall(code_pattern, response, re.DOTALL)
    
    if matches:
        return matches[0].strip()
    
    # Recherche de code indent√©
    lines = response.split('\n')
    code_lines = []
    in_code_block = False
    
    for line in lines:
        if line.strip().startswith('def ') or line.strip().startswith('class ') or line.strip().startswith('import '):
            in_code_block = True
        
        if in_code_block:
            if line.strip() == '' or line.startswith('    ') or line.startswith('\t'):
                code_lines.append(line)
            elif line.strip() and not line.startswith(' '):
                if not any(keyword in line.lower() for keyword in ['print', 'return', 'if', 'for', 'while']):
                    break
                code_lines.append(line)
    
    if code_lines:
        return '\n'.join(code_lines).strip()
    
    return None

async def test_tool_connectivity() -> Dict[str, bool]:
    """Teste la connectivit√© de tous les outils."""
    api_clients = get_api_clients()
    connectivity_status = {}
    
    for service_name in config.API_CONFIG.keys():
        try:
            is_healthy = await endpoint_health_manager.is_service_healthy(service_name)
            has_quota = await quota_manager.check_quota(service_name)
            connectivity_status[service_name] = is_healthy and has_quota
        except Exception as e:
            log_message(f"Erreur test connectivit√© {service_name}: {e}", level="error")
            connectivity_status[service_name] = False
    
    return connectivity_status

def get_tool_usage_stats() -> Dict[str, Any]:
    """Retourne les statistiques d'utilisation des outils."""
    # Cette fonction pourrait √™tre √©tendue pour tracker l'utilisation r√©elle
    return {
        "total_tools": len(config.TOOL_CONFIG),
        "enabled_tools": len([t for t in config.TOOL_CONFIG.values() if t.get("enabled", False)]),
        "services_configured": len(config.API_CONFIG),
        "last_check": datetime.now().isoformat()
    }

# Classe pour la gestion avanc√©e des outils
class ToolManager:
    """Gestionnaire avanc√© pour l'ex√©cution et le monitoring des outils."""
    
    def __init__(self):
        self.execution_stats = {}
        self.error_counts = {}
        self.last_execution_times = {}
    
    async def execute_with_monitoring(self, tool_name: str, **kwargs) -> Dict[str, Any]:
        """Ex√©cute un outil avec monitoring des performances."""
        start_time = asyncio.get_event_loop().time()
        
        try:
            result = await execute_tool(tool_name, **kwargs)
            
            # Mise √† jour des statistiques
            execution_time = asyncio.get_event_loop().time() - start_time
            
            if tool_name not in self.execution_stats:
                self.execution_stats[tool_name] = {"count": 0, "total_time": 0, "avg_time": 0}
            
            stats = self.execution_stats[tool_name]
            stats["count"] += 1
            stats["total_time"] += execution_time
            stats["avg_time"] = stats["total_time"] / stats["count"]
            
            self.last_execution_times[tool_name] = datetime.now().isoformat()
            
            # Reset du compteur d'erreurs en cas de succ√®s
            if "error" not in result.get("tool_output", "").lower():
                self.error_counts[tool_name] = 0
            
            return result
            
        except Exception as e:
            # Comptage des erreurs
            self.error_counts[tool_name] = self.error_counts.get(tool_name, 0) + 1
            
            log_message(f"Erreur monitored execution {tool_name}: {e}", level="error")
            return {
                "tool_name": tool_name,
                "tool_args": kwargs,
                "tool_output": f"Erreur monitored: {e}"
            }
    
    def get_tool_stats(self, tool_name: str) -> Dict[str, Any]:
        """Retourne les statistiques d'un outil sp√©cifique."""
        return {
            "execution_stats": self.execution_stats.get(tool_name, {}),
            "error_count": self.error_counts.get(tool_name, 0),
            "last_execution": self.last_execution_times.get(tool_name),
            "is_healthy": self.error_counts.get(tool_name, 0) < 5
        }
    
    def get_all_stats(self) -> Dict[str, Any]:
        """Retourne toutes les statistiques des outils."""
        return {
            "execution_stats": self.execution_stats,
            "error_counts": self.error_counts,
            "last_executions": self.last_execution_times,
            "total_executions": sum(stats.get("count", 0) for stats in self.execution_stats.values())
        }

# Instance globale du gestionnaire d'outils
tool_manager = ToolManager()

import json
import logging
from datetime import datetime, timezone
from pathlib import Path
import re
import asyncio
import os
from typing import Any, Dict, List, Optional
import base64
import mimetypes

from config import config

# ==== Configuration du logging ====
logger = logging.getLogger("bot_logger")
logger.setLevel(logging.INFO)

# Cr√©e le r√©pertoire de base si n√©cessaire
config.BASE_DIR.mkdir(parents=True, exist_ok=True)

# Gestionnaire pour le fichier de log principal
file_handler = logging.FileHandler(config.LOG_FILE)
file_handler.setLevel(logging.INFO)
formatter = logging.Formatter('%(asctime)s - %(levelname)s - %(message)s')
file_handler.setFormatter(formatter)
logger.addHandler(file_handler)

# Gestionnaire pour les erreurs critiques
error_file_handler = logging.FileHandler(config.ERROR_LOG_PATH)
error_file_handler.setLevel(logging.ERROR)
error_file_handler.setFormatter(formatter)
logger.addHandler(error_file_handler)

# Gestionnaire pour la console
console_handler = logging.StreamHandler()
console_handler.setLevel(logging.INFO)
console_handler.setFormatter(formatter)
logger.addHandler(console_handler)

# Verrou pour les op√©rations de fichier asynchrones
_file_lock: Optional[asyncio.Lock] = None

def set_file_lock(lock: asyncio.Lock):
    """D√©finit l'instance du verrou asyncio pour les op√©rations de fichier."""
    global _file_lock
    _file_lock = lock
    log_message("Verrou de fichier initialis√© dans utils.py.")

def log_message(message: str, level: str = "info"):
    """Enregistre un message dans le fichier de log et la console."""
    if level == "debug":
        logger.debug(message)
    elif level == "info":
        logger.info(message)
    elif level == "warning":
        logger.warning(message)
    elif level == "error":
        logger.error(message)
    elif level == "critical":
        logger.critical(message)
    else:
        logger.info(f"Niveau de log inconnu '{level}': {message}")

def get_current_time() -> datetime:
    """Retourne l'heure actuelle en UTC pour une coh√©rence temporelle."""
    return datetime.now(timezone.utc)

def format_datetime(dt: datetime) -> str:
    """Formate un objet datetime en cha√Æne de caract√®res lisible et standardis√©e."""
    return dt.strftime("%Y-%m-%d %H:%M:%S UTC")

async def load_json(file_path: Path, default_value: Any = None) -> Any:
    """
    Charge les donn√©es d'un fichier JSON de mani√®re asynchrone.
    Cr√©e le fichier avec une valeur par d√©faut si inexistant ou corrompu.
    """
    if _file_lock is None:
        log_message("Le verrou de fichier n'est pas initialis√© avant l'appel √† load_json.", level="critical")
        raise RuntimeError("File lock not initialized. Call set_file_lock in main.py first.")

    try:
        if not file_path.exists():
            log_message(f"Fichier non trouv√©: {file_path}. Cr√©ation avec valeur par d√©faut.", level="info")
            file_path.parent.mkdir(parents=True, exist_ok=True)
            await save_json(file_path, default_value if default_value is not None else {})
            return default_value if default_value is not None else {}

        async with _file_lock:
            return await asyncio.to_thread(_load_json_sync, file_path)
    except json.JSONDecodeError:
        log_message(f"Erreur de d√©codage JSON pour le fichier: {file_path}. R√©initialisation avec la valeur par d√©faut.", level="error")
        await save_json(file_path, default_value if default_value is not None else {})
        return default_value if default_value is not None else {}
    except Exception as e:
        log_message(f"Erreur inattendue lors du chargement du JSON {file_path}: {e}", level="error")
        return default_value if default_value is not None else {}

def _load_json_sync(file_path: Path) -> Any:
    """Fonction synchrone pour charger le JSON, ex√©cut√©e dans un thread s√©par√©."""
    with open(file_path, 'r', encoding='utf-8') as f:
        return json.load(f)

async def save_json(file_path: Path, data: Any):
    """Sauvegarde les donn√©es dans un fichier JSON de mani√®re asynchrone."""
    if _file_lock is None:
        log_message("Le verrou de fichier n'est pas initialis√© avant l'appel √† save_json.", level="critical")
        raise RuntimeError("File lock not initialized. Call set_file_lock in main.py first.")

    try:
        file_path.parent.mkdir(parents=True, exist_ok=True)
        async with _file_lock:
            await asyncio.to_thread(_save_json_sync, file_path, data)
        log_message(f"Donn√©es sauvegard√©es dans {file_path}", level="debug")
    except Exception as e:
        log_message(f"Erreur lors de la sauvegarde du JSON {file_path}: {e}", level="error")

def _save_json_sync(file_path: Path, data: Any):
    """Fonction synchrone pour sauvegarder le JSON, ex√©cut√©e dans un thread s√©par√©."""
    with open(file_path, 'w', encoding='utf-8') as f:
        json.dump(data, f, indent=4, ensure_ascii=False)

def neutralize_urls(text: str) -> str:
    """
    Remplace les URLs dans le texte par une version neutralis√©e pour √©viter les probl√®mes de s√©curit√©.
    """
    url_pattern = re.compile(r'https?://[^\s/$.?#].[^\s]*', re.IGNORECASE)
    neutralized_text = url_pattern.sub("[LIEN_NEUTRALIS√â]", text)
    return neutralized_text

def find_tool_by_name(tool_name: str) -> Optional[Dict[str, Any]]:
    """Recherche un outil dans TOOL_CONFIG par son nom."""
    return config.TOOL_CONFIG.get(tool_name)

async def append_to_file(file_path: Path, content: str):
    """
    Ajoute du contenu √† un fichier, en cr√©ant le fichier/r√©pertoire si n√©cessaire.
    G√®re la rotation du fichier si sa taille d√©passe MAX_FILE_SIZE.
    """
    if _file_lock is None:
        log_message("Le verrou de fichier n'est pas initialis√© avant l'appel √† append_to_file.", level="critical")
        raise RuntimeError("File lock not initialized. Call set_file_lock in main.py first.")

    file_path.parent.mkdir(parents=True, exist_ok=True)

    if file_path.exists() and file_path.stat().st_size + len(content.encode('utf-8')) > config.MAX_FILE_SIZE:
        rotate_file(file_path)

    async with _file_lock:
        await asyncio.to_thread(_append_to_file_sync, file_path, content)

def _append_to_file_sync(file_path: Path, content: str):
    """Fonction synchrone pour ajouter du contenu √† un fichier, ex√©cut√©e dans un thread s√©par√©."""
    with open(file_path, 'a', encoding='utf-8') as f:
        f.write(content + "\n")

def rotate_file(file_path: Path):
    """Effectue une rotation de fichier simple: renomme le fichier actuel avec un horodatage."""
    timestamp = datetime.now(timezone.utc).strftime("%Y%m%d_%H%M%S")
    new_path = file_path.parent / f"{file_path.stem}_{timestamp}{file_path.suffix}"
    try:
        os.rename(file_path, new_path)
        log_message(f"Fichier {file_path.name} renomm√© en {new_path.name} pour rotation.", level="info")
    except OSError as e:
        log_message(f"Erreur lors de la rotation du fichier {file_path.name}: {e}", level="error")

def get_mime_type_from_base64(base64_string: str) -> Optional[str]:
    """Tente de d√©terminer le type MIME √† partir d'une cha√Æne base64."""
    if base64_string.startswith("data:"):
        parts = base64_string.split(",", 1)
        if len(parts) > 0:
            mime_part = parts[0]
            if ";" in mime_part:
                return mime_part.split(";", 1)[0].split(":", 1)[1]
            else:
                return mime_part.split(":", 1)[1]

    try:
        decoded_bytes = base64.b64decode(base64_string[:1024], validate=True)
        
        if decoded_bytes.startswith(b'\x89PNG\r\n\x1a\n'):
            return 'image/png'
        elif decoded_bytes.startswith(b'\xff\xd8\xff'):
            return 'image/jpeg'
        elif decoded_bytes.startswith(b'GIF87a') or decoded_bytes.startswith(b'GIF89a'):
            return 'image/gif'
        elif decoded_bytes.startswith(b'%PDF-'):
            return 'application/pdf'
        elif decoded_bytes.startswith(b'BM'):
            return 'image/bmp'
        elif decoded_bytes.startswith(b'RIFF') and decoded_bytes[8:12] == b'WEBP':
            return 'image/webp'
            
    except Exception as e:
        log_message(f"Erreur lors de la d√©tection MIME pour base64: {e}", level="debug")

    return None

def extract_memories(text: str) -> List[Dict[str, Any]]:
    """
    Extrait les √©l√©ments de m√©moire d'un texte de r√©ponse.
    Extraction simple bas√©e sur des mots-cl√©s importants.
    """
    memories = []
    
    if "important" in text.lower():
        memories.append({"type": "important", "content": text[:200]})
        
    if "remember" in text.lower() or "rappel" in text.lower():
        memories.append({"type": "reminder", "content": text[:200]})
        
    if "erreur" in text.lower() or "error" in text.lower():
        memories.append({"type": "error", "content": text[:200]})
        
    if "succ√®s" in text.lower() or "success" in text.lower():
        memories.append({"type": "success", "content": text[:200]})
    
    return memories

def validate_url(url: str) -> bool:
    """Valide une URL basique."""
    url_pattern = re.compile(
        r'^https?://'  # http:// ou https://
        r'(?:(?:[A-Z0-9](?:[A-Z0-9-]{0,61}[A-Z0-9])?\.)+[A-Z]{2,6}\.?|'  # domaine
        r'localhost|'  # localhost
        r'\d{1,3}\.\d{1,3}\.\d{1,3}\.\d{1,3})'  # IP
        r'(?::\d+)?'  # port optionnel
        r'(?:/?|[/?]\S+)$', re.IGNORECASE)
    return url_pattern.match(url) is not None

def sanitize_filename(filename: str) -> str:
    """Nettoie un nom de fichier pour le rendre s√ªr."""
    # Supprime ou remplace les caract√®res dangereux
    sanitized = re.sub(r'[<>:"/\\|?*]', '_', filename)
    # Limite la longueur
    if len(sanitized) > 100:
        sanitized = sanitized[:100]
    return sanitized.strip()

def format_file_size(size_bytes: int) -> str:
    """Formate une taille de fichier en unit√©s lisibles."""
    if size_bytes == 0:
        return "0 B"
    
    units = ['B', 'KB', 'MB', 'GB', 'TB']
    unit_index = 0
    size = float(size_bytes)
    
    while size >= 1024.0 and unit_index < len(units) - 1:
        size /= 1024.0
        unit_index += 1
    
    return f"{size:.1f} {units[unit_index]}"

def truncate_text(text: str, max_length: int = 200, suffix: str = "...") -> str:
    """Tronque un texte √† une longueur maximale."""
    if len(text) <= max_length:
        return text
    return text[:max_length - len(suffix)] + suffix

def parse_duration(duration_str: str) -> int:
    """Parse une dur√©e en format humain vers des secondes."""
    duration_str = duration_str.lower().strip()
    
    # Patterns pour diff√©rents formats
    patterns = [
        (r'(\d+)\s*s(?:ec)?(?:onds?)?', 1),
        (r'(\d+)\s*m(?:in)?(?:utes?)?', 60),
        (r'(\d+)\s*h(?:ours?)?', 3600),
        (r'(\d+)\s*d(?:ays?)?', 86400),
    ]
    
    total_seconds = 0
    
    for pattern, multiplier in patterns:
        matches = re.findall(pattern, duration_str)
        for match in matches:
            total_seconds += int(match) * multiplier
    
    return total_seconds if total_seconds > 0 else 60  # Default 1 minute

def clean_html(html_content: str) -> str:
    """Nettoie le contenu HTML de base."""
    # Supprime les scripts et styles
    html_content = re.sub(r'<script[^>]*>.*?</script>', '', html_content, flags=re.DOTALL | re.IGNORECASE)
    html_content = re.sub(r'<style[^>]*>.*?</style>', '', html_content, flags=re.DOTALL | re.IGNORECASE)
    
    # Supprime les balises HTML
    html_content = re.sub(r'<[^>]+>', '', html_content)
    
    # Nettoie les espaces multiples
    html_content = re.sub(r'\s+', ' ', html_content)
    
    return html_content.strip()

def generate_unique_id(prefix: str = "") -> str:
    """G√©n√®re un identifiant unique bas√© sur le timestamp."""
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S_%f")
    return f"{prefix}_{timestamp}" if prefix else timestamp

def is_safe_path(file_path: Path, base_path: Path) -> bool:
    """V√©rifie qu'un chemin de fichier est s√ªr (pas de directory traversal)."""
    try:
        file_path.resolve().relative_to(base_path.resolve())
        return True
    except ValueError:
        return False

def mask_sensitive_data(text: str) -> str:
    """Masque les donn√©es sensibles dans un texte."""
    # Masque les cl√©s API (patterns communs)
    text = re.sub(r'(sk-[a-zA-Z0-9]{20,})', '***MASKED_API_KEY***', text)
    text = re.sub(r'(AIza[a-zA-Z0-9_-]{20,})', '***MASKED_GOOGLE_KEY***', text)
    
    # Masque les adresses email
    text = re.sub(r'\b[A-Za-z0-9._%+-]+@[A-Za-z0-9.-]+\.[A-Z|a-z]{2,}\b', '***MASKED_EMAIL***', text)
    
    # Masque les num√©ros de t√©l√©phone
    text = re.sub(r'\b\d{10,}\b', '***MASKED_PHONE***', text)
    
    return text

class RateLimiter:
    """Limiteur de d√©bit simple pour les op√©rations."""
    
    def __init__(self, max_requests: int, time_window: int):
        self.max_requests = max_requests
        self.time_window = time_window
        self.requests = []
    
    def is_allowed(self) -> bool:
        """V√©rifie si une nouvelle requ√™te est autoris√©e."""
        now = datetime.now().timestamp()
        
        # Supprime les requ√™tes anciennes
        self.requests = [req_time for req_time in self.requests if now - req_time < self.time_window]
        
        # V√©rifie la limite
        if len(self.requests) < self.max_requests:
            self.requests.append(now)
            return True
        
        return False
    
    def time_until_allowed(self) -> float:
        """Retourne le temps √† attendre avant la prochaine requ√™te autoris√©e."""
        if not self.requests:
            return 0.0
        
        oldest_request = min(self.requests)
        return max(0.0, self.time_window - (datetime.now().timestamp() - oldest_request))

def retry_on_exception(max_retries: int = 3, delay: float = 1.0, backoff_factor: float = 2.0):
    """D√©corateur pour r√©essayer une fonction en cas d'exception."""
    def decorator(func):
        async def wrapper(*args, **kwargs):
            last_exception = None
            current_delay = delay
            
            for attempt in range(max_retries + 1):
                try:
                    return await func(*args, **kwargs)
                except Exception as e:
                    last_exception = e
                    if attempt < max_retries:
                        log_message(f"Tentative {attempt + 1}/{max_retries + 1} √©chou√©e pour {func.__name__}: {e}", level="warning")
                        await asyncio.sleep(current_delay)
                        current_delay *= backoff_factor
                    else:
                        log_message(f"Toutes les tentatives √©chou√©es pour {func.__name__}: {e}", level="error")
            
            raise last_exception
        return wrapper
    return decorator

# Constantes utiles
COMMON_USER_AGENTS = [
    "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36",
    "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36",
    "Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36"
]

DANGEROUS_EXTENSIONS = [
    '.exe', '.bat', '.cmd', '.com', '.pif', '.scr', '.vbs', '.js', '.jar',
    '.msi', '.dll', '.app', '.deb', '.rpm', '.dmg', '.pkg'
]

ALLOWED_IMAGE_EXTENSIONS = ['.jpg', '.jpeg', '.png', '.gif', '.bmp', '.webp', '.svg']
ALLOWED_DOCUMENT_EXTENSIONS = ['.txt', '.pdf', '.doc', '.docx', '.md', '.json', '.xml', '.csv']

def get_random_user_agent() -> str:
    """Retourne un User-Agent al√©atoire."""
    import random
    return random.choice(COMMON_USER_AGENTS)

def is_dangerous_file(filename: str) -> bool:
    """V√©rifie si un fichier est potentiellement dangereux."""
    _, ext = os.path.splitext(filename.lower())
    return ext in DANGEROUS_EXTENSIONS

def ensure_directory_exists(directory: Path) -> bool:
    """S'assure qu'un r√©pertoire existe, le cr√©e si n√©cessaire."""
    try:
        directory.mkdir(parents=True, exist_ok=True)
        return True
    except Exception as e:
        log_message(f"Erreur cr√©ation r√©pertoire {directory}: {e}", level="error")
        return False
        
        import asyncio
import json
import random
import traceback
from datetime import datetime
from pathlib import Path
from typing import Dict, Any, List, Optional

from config import config
from utils import log_message, set_file_lock, get_mime_type_from_base64
from app_singletons import endpoint_health_manager, quota_manager
from brain_library import brain_coordinator, TelegramMemoryIntegration
from autonomous_brain import create_brain
from coding_challenge_system import get_coding_challenge_system
from security_archiver import fetch_and_archive_pages
from tools import get_gemini_tools

class DecentralizedAISystem:
    """
    Syst√®me d'IA d√©centralis√© avec 7 cerveaux autonomes.
    Chaque cerveau peut traiter ind√©pendamment les requ√™tes utilisateur.
    """
    def __init__(self):
        self.brains = {}
        self.telegram_memory = None
        self.coding_system = None
        self.last_activity = datetime.now().timestamp()
        self.system_initialized = False
        
        # Les 7 cerveaux autonomes
        self.brain_types = ["GEMINI", "DEEPSEEK", "HUGGINGFACE", "TAVILY", "SERPER", "GOOGLE", "WOLFRAM"]
        
    async def initialize_system(self):
        """Initialise tous les composants du syst√®me d√©centralis√©."""
        try:
            log_message("üöÄ Initialisation du syst√®me d'IA d√©centralis√©...")
            
            # Configuration du verrou de fichier
            file_lock = asyncio.Lock()
            set_file_lock(file_lock)
            
            # Initialisation des singletons
            await endpoint_health_manager.init_manager()
            await quota_manager.init_manager()
            
            # Import du client Telegram
            try:
                from app_clients_instances import telegram_bot_client
                self.telegram_memory = TelegramMemoryIntegration(telegram_bot_client)
            except ImportError:
                log_message("Client Telegram non disponible, utilisation du mode simul√©", level="warning")
                self.telegram_memory = TelegramMemoryIntegration(None)
            
            # Initialisation des 7 cerveaux autonomes
            for brain_type in self.brain_types:
                try:
                    brain = create_brain(brain_type, self.telegram_memory.bot_client if self.telegram_memory else None)
                    await brain.initialize()
                    self.brains[brain_type] = brain
                    log_message(f"‚úÖ Cerveau {brain_type} initialis√©")
                except Exception as e:
                    log_message(f"‚ùå Erreur initialisation cerveau {brain_type}: {e}", level="error")
            
            # Initialisation du syst√®me de d√©fis de codage
            self.coding_system = get_coding_challenge_system(
                self.telegram_memory.bot_client if self.telegram_memory else None
            )
            await self.coding_system.initialize()
            
            # Message d'initialisation dans le groupe priv√©
            await self.telegram_memory.write_to_group(
                f"""
üß† SYST√àME D'IA D√âCENTRALIS√â INITIALIS√â

‚úÖ Cerveaux actifs: {len(self.brains)}/7
‚úÖ Gestionnaire de sant√©: Op√©rationnel
‚úÖ Gestionnaire de quotas: Op√©rationnel  
‚úÖ Syst√®me de d√©fis: Pr√™t
‚úÖ Archiveur s√©curis√©: Pr√™t

üîÑ Rotation automatique: 45 minutes
üéØ D√©fis de codage: 15 minutes
üìù M√©moire partag√©e: Active

Le syst√®me est pr√™t √† traiter les requ√™tes utilisateur.
""",
                "SYSTEM_INIT"
            )
            
            self.system_initialized = True
            log_message("üéâ Syst√®me d'IA d√©centralis√© initialis√© avec succ√®s")
            return True
            
        except Exception as e:
            log_message(f"‚ùå Erreur critique lors de l'initialisation: {e}", level="critical")
            log_message(f"Traceback: {traceback.format_exc()}", level="critical")
            return False
    
    async def start_background_tasks(self):
        """D√©marre toutes les t√¢ches de fond."""
        if not self.system_initialized:
            log_message("Syst√®me non initialis√©, impossible de d√©marrer les t√¢ches de fond", level="error")
            return
        
        log_message("üîÑ D√©marrage des t√¢ches de fond...")
        
        # T√¢che de health checks p√©riodiques
        asyncio.create_task(self._periodic_health_checks())
        
        # T√¢che de d√©fis de codage automatis√©s
        asyncio.create_task(self.coding_system.start_periodic_challenges())
        
        # T√¢che de maintenance des quotas
        asyncio.create_task(self._quota_maintenance())
        
        # T√¢che de nettoyage de la m√©moire
        asyncio.create_task(self._memory_cleanup())
        
        await self.telegram_memory.write_to_group(
            "üîÑ Toutes les t√¢ches de fond sont d√©marr√©es",
            "BACKGROUND_TASKS"
        )
        
        log_message("‚úÖ T√¢ches de fond d√©marr√©es")
    
    async def handle_user_request(self, user_query: str, user_id: str = "default_user", 
                                image_data: Optional[str] = None) -> Dict[str, Any]:
        """
        Traite une requ√™te utilisateur avec le syst√®me d√©centralis√©.
        S√©lectionne automatiquement le meilleur cerveau disponible.
        """
        if not self.system_initialized:
            return {"error": "Syst√®me non initialis√©", "brain_id": "SYSTEM"}
        
        start_time = datetime.now()
        self.last_activity = start_time.timestamp()
        
        # Log de la requ√™te
        await self.telegram_memory.write_to_group(
            f"üîç NOUVELLE REQU√äTE UTILISATEUR\nUtilisateur: {user_id}\nRequ√™te: {user_query[:200]}...",
            "USER_REQUEST"
        )
        
        log_message(f"Traitement requ√™te utilisateur: {user_query[:100]}...")
        
        try:
            # S√©lection du cerveau optimal
            selected_brain_type = brain_coordinator.get_next_brain()
            selected_brain = self.brains.get(selected_brain_type)
            
            if not selected_brain:
                error_msg = f"Cerveau {selected_brain_type} non disponible"
                await self.telegram_memory.log_error("SYSTEM", error_msg)
                return {"error": error_msg, "brain_id": "SYSTEM"}
            
            # Augmentation de la charge du cerveau
            brain_coordinator.update_brain_load(selected_brain_type, 1)
            
            await self.telegram_memory.log_brain_activity(
                selected_brain_type,
                "S√©lectionn√© pour traitement",
                {"user_id": user_id, "query_length": len(user_query)}
            )
            
            # Pr√©paration des outils
            available_tools = get_gemini_tools()
            
            # Traitement par le cerveau s√©lectionn√©
            result = await selected_brain.process_request(
                user_query=user_query,
                chat_history=[],  # L'historique est g√©r√© par la m√©moire du cerveau
                image_data=image_data,
                tools=available_tools
            )
            
            # Diminution de la charge du cerveau
            brain_coordinator.update_brain_load(selected_brain_type, -1)
            
            # Calcul du temps de traitement
            processing_time = (datetime.now() - start_time).total_seconds()
            
            # Mise √† jour des statistiques
            if "error" not in result:
                await quota_manager.increment_quota(selected_brain_type, success=True)
                await self.telegram_memory.log_success(
                    selected_brain_type,
                    f"Requ√™te trait√©e en {processing_time:.2f}s",
                    str(result.get("response", ""))[:200]
                )
            else:
                await quota_manager.increment_quota(selected_brain_type, success=False)
                brain_coordinator.mark_brain_failed(selected_brain_type)
                await self.telegram_memory.log_error(
                    selected_brain_type,
                    f"√âchec traitement: {result.get('error', 'Erreur inconnue')}"
                )
            
            # Enrichissement du r√©sultat
            result.update({
                "processing_time": processing_time,
                "timestamp": start_time.isoformat(),
                "user_id": user_id,
                "system_status": brain_coordinator.get_brain_status()
            })
            
            return result
            
        except Exception as e:
            error_msg = f"Erreur syst√®me lors du traitement: {e}"
            log_message(f"Erreur handle_user_request: {error_msg}", level="error")
            log_message(f"Traceback: {traceback.format_exc()}", level="error")
            
            await self.telegram_memory.log_error("SYSTEM", error_msg)
            
            return {
                "error": error_msg,
                "brain_id": "SYSTEM",
                "timestamp": start_time.isoformat(),
                "user_id": user_id
            }
    
    async def _periodic_health_checks(self):
        """T√¢che de health checks p√©riodiques pour tous les services."""
        while True:
            try:
                await self.telegram_memory.write_to_group(
                    "üè• D√©but des health checks p√©riodiques",
                    "HEALTH_CHECK"
                )
                
                # Health check pour tous les services configur√©s
                for service_name in config.API_CONFIG.keys():
                    await endpoint_health_manager.run_health_check_for_service(service_name)
                    await asyncio.sleep(1)  # Pause entre services
                
                # Rapport de sant√©
                health_report = []
                for brain_type in self.brain_types:
                    is_healthy = await endpoint_health_manager.is_service_healthy(brain_type)
                    health_report.append(f"{'‚úÖ' if is_healthy else '‚ùå'} {brain_type}")
                
                await self.telegram_memory.write_to_group(
                    f"üìä RAPPORT DE SANT√â\n\n" + "\n".join(health_report),
                    "HEALTH_REPORT"
                )
                
                log_message("Health checks p√©riodiques termin√©s")
                
            except Exception as e:
                log_message(f"Erreur health checks: {e}", level="error")
            
            await asyncio.sleep(config.HEALTH_CHECK_INTERVAL_SECONDS)
    
    async def _quota_maintenance(self):
        """Maintenance p√©riodique des quotas."""
        while True:
            try:
                await asyncio.sleep(3600)  # Toutes les heures
                
                # Rapport des quotas
                quota_status = quota_manager.get_all_quotas_status()
                
                critical_quotas = [
                    api for api, status in quota_status.items()
                    if status.get("remaining", 0) < status.get("limit", 0) * 0.1  # Moins de 10%
                ]
                
                if critical_quotas:
                    await self.telegram_memory.write_to_group(
                        f"‚ö†Ô∏è QUOTAS CRITIQUES: {', '.join(critical_quotas)}",
                        "QUOTA_WARNING"
                    )
                
                log_message("Maintenance des quotas effectu√©e")
                
            except Exception as e:
                log_message(f"Erreur maintenance quotas: {e}", level="error")
    
    async def _memory_cleanup(self):
        """Nettoyage p√©riodique de la m√©moire."""
        while True:
            try:
                await asyncio.sleep(24 * 3600)  # Tous les jours
                
                # Nettoyage de la m√©moire des cerveaux
                for brain in self.brains.values():
                    await brain.memory_manager.save_memory()
                
                await self.telegram_memory.write_to_group(
                    "üßπ Nettoyage de m√©moire effectu√©",
                    "MEMORY_CLEANUP"
                )
                
                log_message("Nettoyage de m√©moire effectu√©")
                
            except Exception as e:
                log_message(f"Erreur nettoyage m√©moire: {e}", level="error")
    
    def get_system_status(self) -> Dict[str, Any]:
        """Retourne le statut complet du syst√®me."""
        if not self.system_initialized:
            return {"status": "not_initialized"}
        
        return {
            "status": "operational",
            "initialized": self.system_initialized,
            "active_brains": len(self.brains),
            "brain_status": brain_coordinator.get_brain_status(),
            "coding_challenges": self.coding_system.get_challenge_statistics() if self.coding_system else {},
            "last_activity": self.last_activity,
            "uptime": datetime.now().timestamp() - self.last_activity if hasattr(self, 'start_time') else 0
        }
    
    async def shutdown(self):
        """Arr√™t propre du syst√®me."""
        log_message("üõë Arr√™t du syst√®me d'IA d√©centralis√©...")
        
        try:
            # Arr√™t des d√©fis de codage
            if self.coding_system:
                self.coding_system.stop_challenges()
            
            # Sauvegarde finale de toutes les m√©moires
            for brain in self.brains.values():
                await brain.memory_manager.save_memory()
            
            await self.telegram_memory.write_to_group(
                "üõë Syst√®me d'IA d√©centralis√© arr√™t√© proprement",
                "SYSTEM_SHUTDOWN"
            )
            
            log_message("‚úÖ Syst√®me arr√™t√© proprement")
            
        except Exception as e:
            log_message(f"Erreur lors de l'arr√™t: {e}", level="error")

# Instance globale du syst√®me
decentralized_system = DecentralizedAISystem()

async def main():
    """Fonction principale pour le mode console."""
    try:
        # Initialisation du syst√®me
        success = await decentralized_system.initialize_system()
        if not success:
            log_message("‚ùå √âchec de l'initialisation, arr√™t du programme", level="critical")
            return
        
        # D√©marrage des t√¢ches de fond
        await decentralized_system.start_background_tasks()
        
        # Interface console
        print("\n" + "="*60)
        print("üß† SYST√àME D'IA D√âCENTRALIS√â - 7 CERVEAUX AUTONOMES")
        print("="*60)
        print("Commandes disponibles:")
        print("  /help      - Affiche l'aide")
        print("  /status    - Statut du syst√®me")
        print("  /brains    - √âtat des cerveaux")
        print("  /quotas    - √âtat des quotas")
        print("  /challenges - Statistiques d√©fis")
        print("  /archive <urls> - Archive des pages web")
        print("  /exit      - Quitter")
        print("  Ou tapez directement votre question")
        print("="*60)
        
        while True:
            try:
                user_input = await asyncio.to_thread(input, "\nü§ñ Vous: ")
                user_input = user_input.strip()
                
                if not user_input:
                    continue
                
                if user_input.lower() == "/exit":
                    break
                
                elif user_input.lower() == "/help":
                    print("""
üìã AIDE DU SYST√àME D'IA D√âCENTRALIS√â

üß† Architecture:
  ‚Ä¢ 7 cerveaux autonomes (GEMINI, DEEPSEEK, HUGGINGFACE, TAVILY, SERPER, GOOGLE, WOLFRAM)
  ‚Ä¢ Rotation automatique toutes les 45 minutes
  ‚Ä¢ Basculement automatique en cas de panne
  ‚Ä¢ M√©moire partag√©e dans le groupe priv√© Telegram

üéØ Fonctionnalit√©s:
  ‚Ä¢ Traitement de requ√™tes utilisateur
  ‚Ä¢ D√©fis de codage automatis√©s (15 min)
  ‚Ä¢ Archivage s√©curis√© de pages web
  ‚Ä¢ Monitoring sant√© des APIs
  ‚Ä¢ Gestion intelligente des quotas

üí¨ Exemples d'utilisation:
  ‚Ä¢ "Explique-moi la programmation asynchrone"
  ‚Ä¢ "Cr√©e un script Python pour analyser des donn√©es"
  ‚Ä¢ "Recherche les derni√®res nouvelles sur l'IA"
  ‚Ä¢ "/archive https://example.com,https://site.org"
""")
                
                elif user_input.lower() == "/status":
                    status = decentralized_system.get_system_status()
                    print(f"""
üìä STATUT SYST√àME:
  ‚Ä¢ √âtat: {status['status']}
  ‚Ä¢ Cerveaux actifs: {status['active_brains']}/7
  ‚Ä¢ Cerveau courant: {status.get('brain_status', {}).get('active_brain', 'N/A')}
  ‚Ä¢ Derni√®re activit√©: {datetime.fromtimestamp(status['last_activity']).strftime('%H:%M:%S')}
""")
                
                elif user_input.lower() == "/brains":
                    brain_status = brain_coordinator.get_brain_status()
                    print("\nüß† √âTAT DES CERVEAUX:")
                    for brain, healthy in brain_status['brain_health'].items():
                        load = brain_status['brain_load'].get(brain, 0)
                        status_icon = "‚úÖ" if healthy else "‚ùå"
                        print(f"  {status_icon} {brain}: Charge {load}")
                
                elif user_input.lower() == "/quotas":
                    quotas = quota_manager.get_all_quotas_status()
                    print("\nüìä √âTAT DES QUOTAS:")
                    for api, quota_info in quotas.items():
                        if isinstance(quota_info, dict) and 'error' not in quota_info:
                            usage = quota_info['current_usage']
                            limit = quota_info['limit']
                            remaining = quota_info['remaining']
                            percent = (usage / limit * 100) if limit > 0 else 0
                            print(f"  {api}: {usage}/{limit} ({percent:.1f}%) - Restant: {remaining}")
                
                elif user_input.lower() == "/challenges":
                    if decentralized_system.coding_system:
                        stats = decentralized_system.coding_system.get_challenge_statistics()
                        print(f"""
üéØ STATISTIQUES D√âFIS DE CODAGE:
  ‚Ä¢ Total d√©fis: {stats.get('total_challenges', 0)}
  ‚Ä¢ Participants: {stats.get('total_participants', 0)}
  ‚Ä¢ Succ√®s: {stats.get('total_successful', 0)}
  ‚Ä¢ Taux succ√®s: {stats.get('average_success_rate', 0):.1f}%
  ‚Ä¢ Statut: {'üîÑ Actif' if stats.get('is_running') else '‚èπÔ∏è Arr√™t√©'}
""")
                    else:
                        print("‚ùå Syst√®me de d√©fis non initialis√©")
                
                elif user_input.startswith("/archive "):
                    urls_str = user_input[9:].strip()
                    if urls_str:
                        urls = [url.strip() for url in urls_str.split(',') if url.strip()]
                        if urls:
                            print(f"üóÇÔ∏è Archivage de {len(urls)} URL(s) en cours...")
                            result = await fetch_and_archive_pages(urls, "console_user")
                            print(f"‚úÖ {result.get('tool_output', 'Archivage termin√©')}")
                        else:
                            print("‚ùå Aucune URL valide fournie")
                    else:
                        print("‚ùå Usage: /archive <url1>,<url2>,...")
                
                else:
                    # Traitement d'une requ√™te normale
                    print("ü§î Traitement en cours...")
                    
                    # D√©tection simple d'image (simulation)
                    image_data = None
                    if any(ext in user_input.lower() for ext in ['.png', '.jpg', '.jpeg', '.gif']):
                        print("üñºÔ∏è Image d√©tect√©e (mode simulation)")
                        image_data = "data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAEAAAABCAQAAAC1HAwCAAAAC0lEQVR42mNkYAAAAAYAAjCB0C8AAAAASUVORK5CYII="
                    
                    # Traitement par le syst√®me d√©centralis√©
                    response = await decentralized_system.handle_user_request(
                        user_query=user_input,
                        user_id="console_user",
                        image_data=image_data
                    )
                    
                    # Affichage de la r√©ponse
                    if "error" in response:
                        print(f"‚ùå Erreur ({response.get('brain_id', 'UNKNOWN')}): {response['error']}")
                    else:
                        brain_id = response.get('brain_id', 'UNKNOWN')
                        processing_time = response.get('processing_time', 0)
                        
                        # Extraction de la r√©ponse selon le format
                        if 'response' in response and isinstance(response['response'], dict):
                            candidates = response['response'].get('candidates', [])
                            if candidates and 'content' in candidates[0]:
                                parts = candidates[0]['content'].get('parts', [])
                                if parts and 'text' in parts[0]:
                                    answer = parts[0]['text']
                                else:
                                    answer = str(response['response'])
                            else:
                                answer = str(response['response'])
                        else:
                            answer = str(response.get('response', 'Aucune r√©ponse'))
                        
                        print(f"\nü§ñ {brain_id} ({processing_time:.2f}s): {answer}")
                        
                        # Affichage des outils utilis√©s
                        if 'tool_results' in response and response['tool_results']:
                            print(f"\nüîß Outils utilis√©s: {len(response['tool_results'])}")
                            for tool in response['tool_results']:
                                tool_name = tool.get('tool_name', 'Inconnu')
                                print(f"  ‚Ä¢ {tool_name}")
                
            except EOFError:
                print("\nüëã Au revoir !")
                break
            except KeyboardInterrupt:
                print("\n‚ö†Ô∏è Interruption d√©tect√©e...")
                break
            except Exception as e:
                print(f"‚ùå Erreur: {e}")
                log_message(f"Erreur console: {e}", level="error")
        
    except Exception as e:
        log_message(f"Erreur critique dans main(): {e}", level="critical")
        log_message(f"Traceback: {traceback.format_exc()}", level="critical")
    
    finally:
        # Arr√™t propre du syst√®me
        await decentralized_system.shutdown()

if __name__ == "__main__":
    try:
        asyncio.run(main())
    except KeyboardInterrupt:
        print("\nüõë Arr√™t forc√© du syst√®me")
    except Exception as e:
        print(f"‚ùå Erreur fatale: {e}")


# Fichier : config.py

import os
from pathlib import Path
from typing import Dict, Any, List, Optional
from datetime import datetime

class Config:
    """
    Classe de configuration pour l'application avec 7 cerveaux autonomes.
    G√®re les chemins de fichiers, les cl√©s API, et les param√®tres des mod√®les.
    """
    def __init__(self):
        # --- Chemins de fichiers et r√©pertoires ---
        self.BASE_DIR: Path = Path(__file__).parent.parent if Path(__file__).parent.name == 'src' else Path(__file__).parent
        
        self.LOG_FILE: Path = self.BASE_DIR / "logs" / "bot_activity.log"
        self.ERROR_LOG_PATH: Path = self.BASE_DIR / "logs" / "error.log"
        self.USER_CHAT_HISTORY_FILE: Path = self.BASE_DIR / "data" / "user_chat_history.json"
        self.ENDPOINT_HEALTH_FILE: Path = self.BASE_DIR / "data" / "endpoint_health.json"
        self.QUOTA_STATE_FILE: Path = self.BASE_DIR / "data" / "quota_state.json"
        self.DAILY_CHALLENGE_PATH: Path = self.BASE_DIR / "daily_challenges"
        self.BRAIN_MEMORY_FILE: Path = self.BASE_DIR / "data" / "brain_memory.json"
        
        # Cr√©er les r√©pertoires n√©cessaires
        self.LOG_FILE.parent.mkdir(parents=True, exist_ok=True)
        self.USER_CHAT_HISTORY_FILE.parent.mkdir(parents=True, exist_ok=True)
        self.ENDPOINT_HEALTH_FILE.parent.mkdir(parents=True, exist_ok=True)
        self.QUOTA_STATE_FILE.parent.mkdir(parents=True, exist_ok=True)
        self.DAILY_CHALLENGE_PATH.mkdir(parents=True, exist_ok=True)
        self.BRAIN_MEMORY_FILE.parent.mkdir(parents=True, exist_ok=True)
        
        # --- Param√®tres g√©n√©raux de l'application ---
        self.VERBOSE: bool = True
        self.MAX_FILE_SIZE: int = 10 * 1024 * 1024
        self.MAX_CHUNK_SIZE: int = 4000
        self.MAX_IMAGE_SIZE: int = 4 * 1024 * 1024
        self.HEALTH_CHECK_INTERVAL_SECONDS: int = 300
        self.PRIVATE_GROUP_ID: Optional[int] = -1002845235344
        self.GROUP_MEMORY_LIMIT: int = 20
        self.BRAIN_ROTATION_INTERVAL_SECONDS: int = 45 * 60  # 45 minutes pour rotation des cerveaux
        self.LLM_ROTATION_INTERVAL_SECONDS: int = 45 * 60 # 45 minutes pour la rotation des LLM
        self.CODING_CHALLENGE_INTERVAL_SECONDS: int = 15 * 60  # 15 minutes pour d√©fis codage
        
        # --- Telegram Bot Configuration ---
        self.TELEGRAM_BOT_TOKEN = "7902342551:AAG6r1QA2GTMXcmcsWHi36Ivd_PVeMXULOs"
        
        # --- D√âBUT DES D√âFINITIONS DE CL√âS API (V√âRIFIEZ QUE TOUT CE BLOC EST PR√âSENT) ---
        
        # Cerveau 1: GEMINI
        self.GEMINI_API_KEYS: List[str] = [
            "AIzaSyBWXcwGdzoeUzbApSNLICkanNcm7BYzYcs",
            "AIzaSyAk6Ph25xuIY3b5o-JgdL652MvK4usp8Ms",
            "AIzaSyDuccmfiPSk4042NeJCYIjA8EOXPo1YKXU",
            "AIzaSyAQq6o9voefaDxkAEORf7W-IB3QbotIkwY",
            "AIzaSyDYaYrQQ7cwYFm8TBpyGM3dJweOGOYl7qw",
            "VOTRE_CLE_API_GEMINI_ICI" # REMPLACEZ CECI PAR VOTRE VRAIE CL√â API
        ]
        
        # Cerveau 2: DEEPSEEK
        self.DEEPSEEK_KEYS: List[str] = [
            "sk-ef08317d125947b3a1ce5916592bef00",
            "sk-d73750d96142421cb1098c7056dd7f01"
        ]
        
        # Cerveau 3: HUGGINGFACE
        self.HUGGINGFACE_KEYS: List[str] = [
            "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",
            "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",
            "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",
            "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"
        ]
        
        # Cerveau 4: TAVILY (cl√© corrig√©e)
        self.TAVILY_KEYS: List[str] = [
            "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",
            "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",  # Cl√© corrig√©e
            "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",
            "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"
        ]
        
        # Cerveau 5: SERPER
        self.SERPER_KEYS: List[str] = [
            "047b30db1df999aaa9c293f2048037d40c651439"
        ]
        
        # Cerveau 6: GOOGLE
        self.GOOGLE_API_KEYS: List[str] = [
            "AIzaSyAk6Ph25xuIY3b5o-JgdL652MvK4usp8Ms",
            "AIzaSyDuccmfiPSk4042NeJCYIjA8EOXPo1YKXU",
            "AIzaSyAQq6o9voefaDxkAEORf7W-IB3QbotIkwY",
            "AIzaSyDYaYrQQ7cwYFm8TBpyGM3dJweOGOYl7qw"
        ]
        self.GOOGLE_CX_LIST: List[str] = [
            "3368510e864b74936",
            "e745c9ca0ffb94659"
        ]
        
        # Cerveau 7: WOLFRAM
        self.WOLFRAM_APP_IDS: List[str] = [
            "96LX77-G8PGKJ3T7V",
            "96LX77-PYHRRET363",
            "96LX77-P9HPAYWRGL"
        ]
        
        # --- Autres cl√©s API pour outils sp√©cialis√©s ---
        self.WEBCONTAINER_KEY: str = "wc_api_bastien34500_3c5b29436216f322904448de707c148e"
        self.APIFLASH_KEY: str = "3a3cc886a18e41109e0cebc0745b12de"
        self.CRAWLBASE_KEYS: List[str] = [
            "x41P6KNU8J86yF9JV1nqSw",
            "FOg3R0v_aLxzHkYIdhPgVg"
        ]
        self.DETECTLANGUAGE_KEY: str = "ebdc8ccc2ee75eda3ab122b08ffb1e8d"
        self.GUARDIAN_KEY: str = "07c622c1-af05-4c24-9f37-37d219be76a0"
        self.IP2LOCATION_KEY: str = "11103C239EA8EA6DF2473BB445EC32F2"
        self.SHODAN_KEY: str = "umdSaWOfVq9Wt2F4wWdXiKh1zjLailzn"
        self.WEATHERAPI_KEY: str = "332bcdba457d4db4836175513250407"
        self.GREYNOISE_KEY: str = "5zNe9E6c5UNDhU09iVXbMaB04UpHAw5hNm5rHCK24fCLvI2cP33NNOpL7nhkDETG"
        self.LOGINRADIUS_KEY: str = "073b2fbedf82409da2ca6f37b97e8c6a"
        self.JSONBIN_KEY: str = "$2a$10$npWSB7v1YcoqLkyPpz0PZOVtES5vBs6JtTWVyVDXK3j6FDxYS5BPO"
        self.TWILIO_SID: str = "SK84cc4d335650f9da168cd779f26e00e5"
        self.TWILIO_SECRET: str = "spvz5uwPE8ANYOI5Te4Mehm7YwKOZ4Lg"
        self.ABSTRACTAPI_EMAIL_KEYS: List[str] = [
            "2ffd537411ad407e9c9a7eacb7a97311",
            "5b00ade4e60e4a388bd3e749f4f66e28",
            "f4106df7b93e4db6855cb7949edc4a20"
        ]
        self.ABSTRACTAPI_GENERIC_KEY: str = "020a4dcd3e854ac0b19043491d79df92"
        self.PULSEDIVE_KEY: str = "201bb09342f35d365889d7d0ca0fdf8580ebee0f1e7644ce70c99a46c1d47171"
        self.RANDOMMER_KEY: str = "29d907df567b4226bf64b924f9e26c00"
        self.STORMGLASS_KEY: str = "7ad5b888-5900-11f0-80b9-0242ac130006-7ad5b996-5900-11f0-80b9-0242ac130006"
        self.TOMORROW_KEY: str = "bNh6KpmddRGY0dzwvmQugVtG4Uf5Y2w1"
        self.CLOUDMERSIVE_KEY: str = "4d407015-ce22-45d7-a2e1-b88ab6380e84"
        self.OPENWEATHER_API_KEY: str = "c80075b7332716a418e47033463085ef"
        self.OCR_API_KEYS: List[str] = [
            "K82679097388957",
            "K81079143888957",
            "K84281517488957"
        ]
        self.MOCKAROO_KEY: str = "282b32d0"
        self.OPENPAGERANK_KEY: str = "w848ws8s0848g4koosgooc0sg4ggogcggw4o4cko"
        self.RAPIDAPI_KEY: str = "d4d1f58d8emsh58d888c711b7400p1bcebejsn2cc04dce6efe"
        # --- FIN DES D√âFINITIONS DE CL√âS API ---
        
        # --- Param√®tres du mod√®le Gemini (LLM) ---
        self.GEMINI_TEMPERATURE: float = 0.7
        self.GEMINI_TOP_P: float = 0.95
        self.GEMINI_TOP_K: int = 40
        self.GEMINI_MAX_OUTPUT_TOKENS: int = 8192
        self.GEMINI_SAFETY_SETTINGS: List[Dict] = [
            {"category": "HARM_CATEGORY_HARASSMENT", "threshold": "BLOCK_NONE"},
            {"category": "HARM_CATEGORY_HATE_SPEECH", "threshold": "BLOCK_NONE"},
            {"category": "HARM_CATEGORY_SEXUALLY_EXPLICIT", "threshold": "BLOCK_NONE"},
            {"category": "HARM_CATEGORY_DANGEROUS_CONTENT", "threshold": "BLOCK_NONE"},
        ]
        
        # --- Configuration des Endpoints API (avec gestion des cl√©s et du roulement) ---
        self.API_CONFIG: Dict[str, List[Dict]] = self._build_api_config()
        
        ### AJOUT : LISTE DE TOUS LES AGENTS ET ENDPOINTS POUR LE MAILLAGE ###
        self.AGENT_CONFIGS, self.ALL_ENDPOINTS = self._build_agent_and_endpoint_mesh()
        
        # --- Configuration des Quotas API ---
        self.QUOTA_CONFIG: Dict[str, Dict[str, Any]] = {
            "GEMINI_API": {"limit": 1000, "reset_interval": "daily", "burn_window_hours": 2},
            "DEEPSEEK": {"limit": 200, "reset_interval": "daily", "burn_window_hours": 1},
            "HUGGINGFACE": {"limit": 200, "reset_interval": "daily", "burn_window_hours": 1},
            "TAVILY": {"limit": 100, "reset_interval": "daily", "burn_window_hours": 0.5},
            "SERPER": {"limit": 100, "reset_interval": "daily", "burn_window_hours": 0.5},
            "GOOGLE_CUSTOM_SEARCH": {"limit": 100, "reset_interval": "daily", "burn_window_hours": 0.5},
            "WOLFRAMALPHA": {"limit": 50, "reset_interval": "daily", "burn_window_hours": 0.5},
            "WEBCONTAINER": {"limit": 1000, "reset_interval": "daily", "burn_window_hours": 2},
            "OCR_API": {"limit": 500, "reset_interval": "daily", "burn_window_hours": 1},
            "APIFLASH": {"limit": 50, "reset_interval": "daily", "burn_window_hours": 0.5},
            "CRAWLBASE": {"limit": 50, "reset_interval": "daily", "burn_window_hours": 0.5},
            "DETECTLANGUAGE": {"limit": 100, "reset_interval": "daily", "burn_window_hours": 0.5},
            "GUARDIAN": {"limit": 500, "reset_interval": "daily", "burn_window_hours": 1},
            "IP2LOCATION": {"limit": 100, "reset_interval": "daily", "burn_window_hours": 0.5},
            "SHODAN": {"limit": 100, "reset_interval": "daily", "burn_window_hours": 0.5},
            "WEATHERAPI": {"limit": 1000, "reset_interval": "daily", "burn_window_hours": 2},
            "CLOUDMERSIVE": {"limit": 50, "reset_interval": "daily", "burn_window_hours": 0.5},
            "GREYNOISE": {"limit": 50, "reset_interval": "daily", "burn_window_hours": 0.5},
            "PULSEDIVE": {"limit": 50, "reset_interval": "daily", "burn_window_hours": 0.5},
            "STORMGLASS": {"limit": 50, "reset_interval": "daily", "burn_window_hours": 0.5},
            "LOGINRADIUS": {"limit": 10, "reset_interval": "daily", "burn_window_hours": 0.1},
            "JSONBIN": {"limit": 20, "reset_interval": "daily", "burn_window_hours": 0.1},
            "TWILIO": {"limit": 5, "reset_interval": "daily", "burn_window_hours": 0.1},
            "ABSTRACTAPI": {"limit": 100, "reset_interval": "daily", "burn_window_hours": 0.5},
            "RANDOMMER": {"limit": 50, "reset_interval": "daily", "burn_window_hours": 0.5},
            "TOMORROW.IO": {"limit": 100, "reset_interval": "daily", "burn_window_hours": 0.5},
            "OPENWEATHERMAP": {"limit": 1000, "reset_interval": "daily", "burn_window_hours": 2},
            "MOCKAROO": {"limit": 50, "reset_interval": "daily", "burn_window_hours": 0.5},
            "OPENPAGERANK": {"limit": 50, "reset_interval": "daily", "burn_window_hours": 0.5},
            "RAPIDAPI": {"limit": 200, "reset_interval": "daily", "burn_window_hours": 1},
        }
        
        # --- Configuration des Outils (pour l'API Gemini) ---
        self.TOOL_CONFIG: Dict[str, Dict[str, Any]] = self._build_tool_config()

    ### AJOUT : NOUVELLE M√âTHODE POUR CONSTRUIRE LE MAILLAGE AGENT/ENDPOINT ###
    def _build_agent_and_endpoint_mesh(self) -> tuple[List[Dict[str, Any]], List[Dict[str, Any]]]:
        """Construit la liste de tous les agents (cl√©s) et de tous les endpoints."""
        agent_configs = []
        all_endpoints = []

        # Fonction utilitaire pour ajouter un agent
        def add_agent(key: Any, agent_type: str, service_name: str, index: int, extra_config: Dict = {}):
            # Ignore les cl√©s invalides ou placeholders
            if not key or "VOTRE_" in str(key) or "_ICI" in str(key):
                return
            agent_id = f"{service_name}_{index+1}"
            agent_configs.append({
                "id": agent_id,
                "key": key,
                "type": agent_type,  # Type de cerveau (logique de traitement)
                "service": service_name, # Service API associ√©
                **extra_config
            })

        # It√©ration sur toutes les listes de cl√©s
        for i, k in enumerate(self.GEMINI_API_KEYS): add_agent(k, "GEMINI", "GEMINI_API", i)
        for i, k in enumerate(self.DEEPSEEK_KEYS): add_agent(k, "DEEPSEEK", "DEEPSEEK", i)
        for i, k in enumerate(self.HUGGINGFACE_KEYS): add_agent(k, "HUGGINGFACE", "HUGGINGFACE", i)
        for i, k in enumerate(self.TAVILY_KEYS): add_agent(k, "TAVILY", "TAVILY", i)
        for i, k in enumerate(self.SERPER_KEYS): add_agent(k, "SERPER", "SERPER", i)
        for i, k in enumerate(self.GOOGLE_API_KEYS): add_agent(k, "GOOGLE_CUSTOM_SEARCH", "GOOGLE_CUSTOM_SEARCH", i)
        for i, k in enumerate(self.WOLFRAM_APP_IDS): add_agent(k, "WOLFRAMALPHA", "WOLFRAMALPHA", i)
        for i, k in enumerate(self.OCR_API_KEYS): add_agent(k, "OCR_API", "OCR_API", i)
        for i, k in enumerate(self.CRAWLBASE_KEYS): add_agent(k, "CRAWLBASE", "CRAWLBASE", i)
        for i, k in enumerate(self.ABSTRACTAPI_EMAIL_KEYS): add_agent(k, "ABSTRACTAPI", "ABSTRACTAPI", i)
        
        # Services avec une seule cl√©
        single_key_services = {
            "WEBCONTAINER": (self.WEBCONTAINER_KEY, "WEBCONTAINER"), "APIFLASH": (self.APIFLASH_KEY, "APIFLASH"),
            "DETECTLANGUAGE": (self.DETECTLANGUAGE_KEY, "DETECTLANGUAGE"), "GUARDIAN": (self.GUARDIAN_KEY, "GUARDIAN"),
            "IP2LOCATION": (self.IP2LOCATION_KEY, "IP2LOCATION"), "SHODAN": (self.SHODAN_KEY, "SHODAN"),
            "WEATHERAPI": (self.WEATHERAPI_KEY, "WEATHERAPI"), "GREYNOISE": (self.GREYNOISE_KEY, "GREYNOISE"),
            "LOGINRADIUS": (self.LOGINRADIUS_KEY, "LOGINRADIUS"), "JSONBIN": (self.JSONBIN_KEY, "JSONBIN"),
            "TWILIO": ((self.TWILIO_SID, self.TWILIO_SECRET), "TWILIO"), "ABSTRACTAPI_GENERIC": (self.ABSTRACTAPI_GENERIC_KEY, "ABSTRACTAPI"),
            "PULSEDIVE": (self.PULSEDIVE_KEY, "PULSEDIVE"), "RANDOMMER": (self.RANDOMMER_KEY, "RANDOMMER"),
            "STORMGLASS": (self.STORMGLASS_KEY, "STORMGLASS"), "TOMORROW.IO": (self.TOMORROW_KEY, "TOMORROW.IO"),
            "CLOUDMERSIVE": (self.CLOUDMERSIVE_KEY, "CLOUDMERSIVE"), "OPENWEATHERMAP": (self.OPENWEATHER_API_KEY, "OPENWEATHERMAP"),
            "MOCKAROO": (self.MOCKAROO_KEY, "MOCKAROO"), "OPENPAGERANK": (self.OPENPAGERANK_KEY, "OPENPAGERANK"),
            "RAPIDAPI": (self.RAPIDAPI_KEY, "RAPIDAPI")
        }
        for service, (key, brain_type) in single_key_services.items():
            add_agent(key, brain_type, service, 0)

        # Construction de la liste de tous les endpoints
        # On it√®re sur la configuration d'API existante pour ne pas dupliquer la logique
        for service_name, endpoints in self.API_CONFIG.items():
            all_endpoints.extend(endpoints)
            
        return agent_configs, all_endpoints

    def _build_api_config(self) -> Dict[str, List[Dict]]:
        """Construit la configuration des endpoints pour tous les services."""
        return {
            "GEMINI_API": [
                {
                    "endpoint_name": f"Gemini Generate Content Key {i+1}",
                    "url": "https://generativelanguage.googleapis.com/v1beta/models/gemini-1.5-flash-latest:generateContent",
                    "method": "POST",
                    "key_field": "key",
                    "key_location": "param",
                    "key": key,
                    "timeout": 60,
                    "health_check_json": {"contents": [{"parts": [{"text": "hello"}]}]},
                } for i, key in enumerate(self.GEMINI_API_KEYS) if key and "VOTRE" not in key
            ] + [
                {
                    "endpoint_name": f"Gemini Models List Key {i+1}",
                    "url": "https://generativelanguage.googleapis.com/v1beta/models",
                    "method": "GET",
                    "key_field": "key",
                    "key_location": "param",
                    "key": key,
                    "timeout": 30,
                } for i, key in enumerate(self.GEMINI_API_KEYS) if key and "VOTRE" not in key
            ],
            "DEEPSEEK": [
                {
                    "endpoint_name": f"DeepSeek Chat Key {i+1}",
                    "url": "https://api.deepseek.com/chat/completions",
                    "method": "POST",
                    "key_field": "Authorization",
                    "key_location": "header",
                    "key_prefix": "Bearer ",
                    "key": key,
                    "timeout": 60,
                    "fixed_headers": {"Content-Type": "application/json"},
                    "health_check_json": {"model": "deepseek-chat", "messages": [{"role": "user", "content": "ping"}]},
                } for i, key in enumerate(self.DEEPSEEK_KEYS) if key
            ] + [
                {
                    "endpoint_name": f"DeepSeek Models Key {i+1}",
                    "url": "https://api.deepseek.com/models",
                    "method": "GET",
                    "key_field": "Authorization",
                    "key_location": "header",
                    "key_prefix": "Bearer ",
                    "key": key,
                    "timeout": 30,
                } for i, key in enumerate(self.DEEPSEEK_KEYS) if key
            ],
            "HUGGINGFACE": [
                {
                    "endpoint_name": f"HuggingFace Inference Key {i+1}",
                    "url": "https://api-inference.huggingface.co/models/",
                    "method": "POST",
                    "key_field": "Authorization",
                    "key_location": "header",
                    "key_prefix": "Bearer ",
                    "key": key,
                    "timeout": 60,
                    "fixed_headers": {"Content-Type": "application/json"},
                    "health_check_url_suffix": "distilbert-base-uncased-finetuned-sst-2-english",
                    "health_check_json": {"inputs": "Hello world"},
                } for i, key in enumerate(self.HUGGINGFACE_KEYS) if key
            ],
            "TAVILY": [
                {
                    "endpoint_name": f"Tavily Search Key {i+1}",
                    "url": "https://api.tavily.com/search",
                    "method": "POST",
                    "key_field": "apikey",
                    "key_location": "header",
                    "key": key,
                    "timeout": 20,
                    "fixed_headers": {"Content-Type": "application/json"},
                    "health_check_json": {"query": "test"},
                } for i, key in enumerate(self.TAVILY_KEYS) if key
            ],
            "SERPER": [
                {
                    "endpoint_name": f"Serper Search Key {i+1}",
                    "url": "https://google.serper.dev/search",
                    "method": "POST",
                    "key_field": "X-API-KEY",
                    "key_location": "header",
                    "key": key,
                    "timeout": 15,
                    "fixed_headers": {"Content-Type": "application/json"},
                    "health_check_json": {"q": "test"},
                } for i, key in enumerate(self.SERPER_KEYS) if key
            ] + [
                {
                    "endpoint_name": f"Serper Images Key {i+1}",
                    "url": "https://google.serper.dev/images",
                    "method": "POST",
                    "key_field": "X-API-KEY",
                    "key_location": "header",
                    "key": key,
                    "timeout": 15,
                    "fixed_headers": {"Content-Type": "application/json"},
                    "health_check_json": {"q": "test"},
                } for i, key in enumerate(self.SERPER_KEYS) if key
            ],
            "GOOGLE_CUSTOM_SEARCH": [
                {
                    "endpoint_name": f"Google Custom Search Key {i+1} CX {j+1}",
                    "url": "https://www.googleapis.com/customsearch/v1",
                    "method": "GET",
                    "key_field": "key",
                    "key_location": "param",
                    "key": key,
                    "timeout": 15,
                    "fixed_params": {"cx": cx},
                    "health_check_params": {"q": "test"},
                } for i, key in enumerate(self.GOOGLE_API_KEYS) if key for j, cx in enumerate(self.GOOGLE_CX_LIST)
            ],
            "WOLFRAMALPHA": [
                {
                    "endpoint_name": f"WolframAlpha Query Key {i+1}",
                    "url": "https://api.wolframalpha.com/v2/query",
                    "method": "GET",
                    "key_field": "appid",
                    "key_location": "param",
                    "key": key,
                    "timeout": 20,
                    "fixed_params": {"output": "json"},
                    "health_check_params": {"input": "2+2"},
                } for i, key in enumerate(self.WOLFRAM_APP_IDS) if key
            ],
            "WEBCONTAINER": [
                {
                    "endpoint_name": "WebContainer API",
                    "url": "https://api.webcontainer.io/v1",
                    "method": "POST",
                    "key_field": "Authorization",
                    "key_location": "header",
                    "key_prefix": "Bearer ",
                    "key": self.WEBCONTAINER_KEY,
                    "timeout": 60,
                    "fixed_headers": {"Content-Type": "application/json"},
                    "health_check_json": {"action": "ping"},
                }
            ],
            "OCR_API": [
                {
                    "endpoint_name": f"OCR.space Key {i+1}",
                    "url": "https://api.ocr.space/parse/image",
                    "method": "POST",
                    "key_field": "apikey",
                    "key_location": "header",
                    "key": key,
                    "timeout": 30,
                    "fixed_headers": {},
                    "health_check_json": {"base64Image": "data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAEAAAABCAQAAAC1HAwCAAAAC0lEQVR42mNkYAAAAAYAAjCB0C8AAAAASUVORK5CYII=", "language": "eng"},
                } for i, key in enumerate(self.OCR_API_KEYS) if key
            ],
            "APIFLASH": [
                {
                    "endpoint_name": "ApiFlash Screenshot",
                    "url": "https://api.apiflash.com/v1/urltoimage",
                    "method": "GET",
                    "key_field": "access_key",
                    "key_location": "param",
                    "key": self.APIFLASH_KEY,
                    "timeout": 30,
                    "health_check_params": {"url": "https://www.google.com", "format": "jpeg"},
                }
            ],
            "CRAWLBASE": [
                {
                    "endpoint_name": f"Crawlbase Scraper Key {i+1}",
                    "url": "https://api.crawlbase.com/",
                    "method": "GET",
                    "key_field": "token",
                    "key_location": "param",
                    "key": key,
                    "timeout": 45,
                    "health_check_params": {"url": "https://httpbin.org/status/200"},
                } for i, key in enumerate(self.CRAWLBASE_KEYS) if key
            ] + [
                {
                    "endpoint_name": f"Crawlbase JS Scraper Key {i+1}",
                    "url": "https://api.crawlbase.com/",
                    "method": "GET",
                    "key_field": "token",
                    "key_location": "param",
                    "key": key,
                    "timeout": 60,
                    "health_check_params": {"url": "https://httpbin.org/status/200", "javascript": "true"},
                } for i, key in enumerate(self.CRAWLBASE_KEYS) if key
            ],
            "DETECTLANGUAGE": [
                {
                    "endpoint_name": "DetectLanguage Detect",
                    "url": "https://ws.detectlanguage.com/0.2/detect",
                    "method": "POST",
                    "key_field": "Authorization",
                    "key_location": "header",
                    "key_prefix": "Bearer ",
                    "key": self.DETECTLANGUAGE_KEY,
                    "timeout": 10,
                    "fixed_headers": {"Content-Type": "application/json"},
                    "health_check_json": {"q": "Hello world"},
                }
            ],
            "GUARDIAN": [
                {
                    "endpoint_name": "Guardian Content",
                    "url": "https://content.guardianapis.com/search",
                    "method": "GET",
                    "key_field": "api-key",
                    "key_location": "param",
                    "key": self.GUARDIAN_KEY,
                    "timeout": 15,
                    "health_check_params": {"q": "test"},
                }
            ],
            "IP2LOCATION": [
                {
                    "endpoint_name": "IP2Location IP Geolocation",
                    "url": "https://api.ip2location.io/",
                    "method": "GET",
                    "key_field": "key",
                    "key_location": "param",
                    "key": self.IP2LOCATION_KEY,
                    "timeout": 10,
                    "fixed_params": {"package": "WS24", "format": "json"},
                    "health_check_params": {"ip": "8.8.8.8"},
                }
            ],
            "SHODAN": [
                {
                    "endpoint_name": "Shodan Host Info",
                    "url": "https://api.shodan.io/shodan/host/",
                    "method": "GET",
                    "key_field": "key",
                    "key_location": "param",
                    "key": self.SHODAN_KEY,
                    "timeout": 15,
                    "health_check_url_suffix": "8.8.8.8",
                },
                {
                    "endpoint_name": "Shodan API Info",
                    "url": "https://api.shodan.io/api-info",
                    "method": "GET",
                    "key_field": "key",
                    "key_location": "param",
                    "key": self.SHODAN_KEY,
                    "timeout": 15,
                }
            ],
            "WEATHERAPI": [
                {
                    "endpoint_name": "WeatherAPI Current",
                    "url": "https://api.weatherapi.com/v1/current.json",
                    "method": "GET",
                    "key_field": "key",
                    "key_location": "param",
                    "key": self.WEATHERAPI_KEY,
                    "timeout": 10,
                    "health_check_params": {"q": "London"},
                }
            ],
            "CLOUDMERSIVE": [
                {
                    "endpoint_name": "Cloudmersive Validate Domain",
                    "url": "https://api.cloudmersive.com/validate/url/validate/full",
                    "method": "POST",
                    "key_field": "Apikey",
                    "key_location": "header",
                    "key": self.CLOUDMERSIVE_KEY,
                    "timeout": 15,
                    "fixed_headers": {"Content-Type": "application/json"},
                    "health_check_json": {"domain": "google.com"},
                }
            ],
            "GREYNOISE": [
                {
                    "endpoint_name": "GreyNoise IP Lookup",
                    "url": "https://api.greynoise.io/v3/community",
                    "method": "GET",
                    "key_field": "key",
                    "key_location": "header",
                    "key": self.GREYNOISE_KEY,
                    "timeout": 15,
                    "health_check_url_suffix": "/8.8.8.8",
                }
            ],
            "PULSEDIVE": [
                {
                    "endpoint_name": "Pulsedive Analyze",
                    "url": "https://pulsedive.com/api/v1/analyze.php",
                    "method": "GET",
                    "key_field": "key",
                    "key_location": "param",
                    "key": self.PULSEDIVE_KEY,
                    "timeout": 20,
                    "health_check_params": {"indicator": "8.8.8.8", "type": "ip"},
                }
            ],
            "STORMGLASS": [
                {
                    "endpoint_name": "StormGlass Weather",
                    "url": "https://api.stormglass.io/v2/weather/point",
                    "method": "GET",
                    "key_field": "Authorization",
                    "key_location": "header",
                    "key": self.STORMGLASS_KEY,
                    "timeout": 20,
                    "fixed_headers": {},
                    "health_check_params": {"lat": 0, "lng": 0, "params": "airTemperature"},
                }
            ],
            "LOGINRADIUS": [
                {
                    "endpoint_name": "LoginRadius Ping",
                    "url": "https://api.loginradius.com/identity/v2/auth/ping",
                    "method": "GET",
                    "key_field": "X-LoginRadius-Api-Key",
                    "key_location": "header",
                    "key": self.LOGINRADIUS_KEY,
                    "timeout": 10,
                }
            ],
            "JSONBIN": [
                {
                    "endpoint_name": "Jsonbin Bin Create",
                    "url": "https://api.jsonbin.io/v3/b",
                    "method": "POST",
                    "key_field": "X-Master-Key",
                    "key_location": "header",
                    "key": self.JSONBIN_KEY,
                    "timeout": 15,
                    "fixed_headers": {"Content-Type": "application/json"},
                    "health_check_json": {"sample": "Hello World"},
                },
                {
                    "endpoint_name": "Jsonbin Bin Access",
                    "url": "https://api.jsonbin.io/v3/b",
                    "method": "GET",
                    "key_field": "X-Master-Key",
                    "key_location": "header",
                    "key": self.JSONBIN_KEY,
                    "timeout": 15,
                    "health_check_url_suffix": "/657a7e3205741301340a6b12",
                }
            ],
            "TWILIO": [
                {
                    "endpoint_name": "Twilio Account Balance",
                    "url": f"https://api.twilio.com/2010-04-01/Accounts/{self.TWILIO_SID}/Balance.json",
                    "method": "GET",
                    "key_field": None,
                    "key_location": "auth_basic",
                    "key": (self.TWILIO_SID, self.TWILIO_SECRET),
                    "timeout": 15,
                }
            ],
            "ABSTRACTAPI": [
                {
                    "endpoint_name": f"AbstractAPI Email Validation Key {i+1}",
                    "url": "https://emailvalidation.abstractapi.com/v1/",
                    "method": "GET",
                    "key_field": "api_key",
                    "key_location": "param",
                    "key": key,
                    "timeout": 15,
                    "health_check_params": {"email": "test@example.com"},
                } for i, key in enumerate(self.ABSTRACTAPI_EMAIL_KEYS) if key
            ] + [
                {
                    "endpoint_name": "AbstractAPI Phone Validation",
                    "url": "https://phonevalidation.abstractapi.com/v1/",
                    "method": "GET",
                    "key_field": "api_key",
                    "key_location": "param",
                    "key": self.ABSTRACTAPI_GENERIC_KEY,
                    "timeout": 15,
                    "health_check_params": {"phone": "14150000000"},
                },
                {
                    "endpoint_name": "AbstractAPI Exchange Rates",
                    "url": "https://exchangerates.abstractapi.com/v1/live/",
                    "method": "GET",
                    "key_field": "api_key",
                    "key_location": "param",
                    "key": self.ABSTRACTAPI_GENERIC_KEY,
                    "timeout": 15,
                    "health_check_params": {"base": "USD"},
                },
                {
                    "endpoint_name": "AbstractAPI Holidays",
                    "url": "https://holidays.abstractapi.com/v1/",
                    "method": "GET",
                    "key_field": "api_key",
                    "key_location": "param",
                    "key": self.ABSTRACTAPI_GENERIC_KEY,
                    "timeout": 15,
                    "health_check_params": {"country": "US", "year": "2023", "month": "1", "day": "1"},
                }
            ],
            "RANDOMMER": [
                {
                    "endpoint_name": "Randommer Phone Number",
                    "url": "https://randommer.io/api/Phone/Generate",
                    "method": "GET",
                    "key_field": "X-Api-Key",
                    "key_location": "header",
                    "key": self.RANDOMMER_KEY,
                    "timeout": 10,
                    "health_check_params": {"CountryCode": "US", "Quantity": 1},
                }
            ],
            "TOMORROW.IO": [
                {
                    "endpoint_name": "Tomorrow.io Weather",
                    "url": "https://api.tomorrow.io/v4/timelines",
                    "method": "POST",
                    "key_field": "apikey",
                    "key_location": "param",
                    "key": self.TOMORROW_KEY,
                    "timeout": 20,
                    "fixed_headers": {"Content-Type": "application/json"},
                    "health_check_json": {"location": "42.3478, -73.9855", "fields": ["temperature"], "units": "metric", "timesteps": ["1h"]},
                }
            ],
            "OPENWEATHERMAP": [
                {
                    "endpoint_name": "OpenWeatherMap Current",
                    "url": "https://api.openweathermap.org/data/2.5/weather",
                    "method": "GET",
                    "key_field": "appid",
                    "key_location": "param",
                    "key": self.OPENWEATHER_API_KEY,
                    "timeout": 10,
                    "health_check_params": {"q": "London"},
                }
            ],
            "MOCKAROO": [
                {
                    "endpoint_name": "Mockaroo Generate Data",
                    "url": "https://api.mockaroo.com/api/generate.json",
                    "method": "GET",
                    "key_field": "key",
                    "key_location": "param",
                    "key": self.MOCKAROO_KEY,
                    "timeout": 15,
                    "health_check_params": {"count": 1, "fields": '[{"name":"id","type":"Row Number"}]'},
                }
            ],
            "OPENPAGERANK": [
                {
                    "endpoint_name": "OpenPageRank Domains",
                    "url": "https://openpagerank.com/api/v1.0/getPageRank",
                    "method": "GET",
                    "key_field": "API-OPR",
                    "key_location": "header",
                    "key": self.OPENPAGERANK_KEY,
                    "timeout": 15,
                    "health_check_params": {"domains[]": "google.com"},
                }
            ],
            "RAPIDAPI": [
                {
                    "endpoint_name": "RapidAPI Programming Joke",
                    "url": "https://dad-jokes.p.rapidapi.com/random/joke",
                    "method": "GET",
                    "key_field": "X-RapidAPI-Key",
                    "key_location": "header",
                    "key": self.RAPIDAPI_KEY,
                    "timeout": 15,
                    "fixed_headers": {"X-RapidAPI-Host": "dad-jokes.p.rapidapi.com"},
                },
                {
                    "endpoint_name": "RapidAPI Currency List Quotes",
                    "url": "https://currency-exchange.p.rapidapi.com/exchange",
                    "method": "GET",
                    "key_field": "X-RapidAPI-Key",
                    "key_location": "header",
                    "key": self.RAPIDAPI_KEY,
                    "timeout": 15,
                    "fixed_headers": {"X-RapidAPI-Host": "currency-exchange.p.rapidapi.com"},
                    "health_check_params": {"from": "USD", "to": "EUR", "q": "1.0"},
                },
                {
                    "endpoint_name": "RapidAPI Random Fact",
                    "url": "https://random-facts2.p.rapidapi.com/randomFacts",
                    "method": "GET",
                    "key_field": "X-RapidAPI-Key",
                    "key_location": "header",
                    "key": self.RAPIDAPI_KEY,
                    "timeout": 15,
                    "fixed_headers": {"X-RapidAPI-Host": "random-facts2.p.rapidapi.com"},
                    "health_check_params": {"count": "1"},
                }
            ],
        }
    
    def _build_tool_config(self) -> Dict[str, Dict[str, Any]]:
        """Configuration des outils disponibles pour tous les cerveaux."""
        return {
            "google_search": {
                "enabled": True,
                "description": "Effectue une recherche sur Google pour obtenir des informations. Utilisez cet outil pour des questions factuelles, des d√©finitions, des actualit√©s, etc.",
                "parameters": {
                    "queries": {"type": "ARRAY", "items": {"type": "STRING"}, "description": "Liste des requ√™tes de recherche √† effectuer.", "required": True}
                }
            },
            "media_control": {
                "enabled": True,
                "description": "Contr√¥le la lecture multim√©dia (musique, vid√©o).",
                "parameters": {
                    "action": {
                        "type": "STRING",
                        "description": "L'action √† effectuer (like, dislike, next, previous, pause, resume, stop, replay, seek_absolute, seek_relative).",
                        "required": True,
                        "enum": ["like", "dislike", "next", "previous", "pause", "resume", "stop", "replay", "seek_absolute", "seek_relative"]
                    },
                    "position": {"type": "INTEGER", "description": "Position absolue en secondes pour seek_absolute.", "required": False},
                    "offset": {"type": "INTEGER", "description": "D√©calage en secondes pour seek_relative.", "required": False}
                }
            },
            "clock": {
                "enabled": True,
                "description": "G√®re les alarmes et les minuteurs.",
                "parameters": {
                    "action": {
                        "type": "STRING",
                        "description": "L'action √† effectuer (create_alarm, create_timer, show_matching_alarms, show_matching_timers, modify_alarm_v2, modify_timer_v2, snooze).",
                        "required": True,
                        "enum": ["create_alarm", "create_timer", "show_matching_alarms", "show_matching_timers", "modify_alarm_v2", "modify_timer_v2", "snooze"]
                    },
                    "duration": {"type": "STRING", "description": "Dur√©e pour le minuteur ou l'alarme (ex: '30 minutes', '1h 30m').", "required": False},
                    "time": {"type": "STRING", "description": "Heure sp√©cifique pour l'alarme (ex: '07:00 AM', '14:30').", "required": False},
                    "date": {"type": "STRING", "description": "Date sp√©cifique pour l'alarme (ex: '2023-12-25', 'demain').", "required": False},
                    "label": {"type": "STRING", "description": "√âtiquette ou description pour l'alarme/minuteur.", "required": False},
                    "recurrence": {"type": "ARRAY", "items": {"type": "STRING"}, "description": "Jours de la semaine pour la r√©currence de l'alarme (ex: ['MONDAY', 'WEDNESDAY']).", "required": False},
                    "query": {"type": "STRING", "description": "Requ√™te de recherche pour les alarmes/minuteurs.", "required": False},
                    "alarm_type": {"type": "STRING", "description": "Type d'alarme √† afficher (ex: 'active', 'snoozed').", "required": False},
                    "alarm_ids": {"type": "ARRAY", "items": {"type": "STRING"}, "description": "Liste des IDs d'alarmes √† afficher ou modifier.", "required": False},
                    "timer_type": {"type": "STRING", "description": "Type de minuteur √† afficher (ex: 'running', 'paused').", "required": False},
                    "timer_ids": {"type": "ARRAY", "items": {"type": "STRING"}, "description": "Liste des IDs de minuteurs √† afficher ou modifier.", "required": False},
                    "alarm_filters": {"type": "OBJECT", "description": "Filtres pour s√©lectionner les alarmes √† modifier.", "required": False},
                    "alarm_modifications": {"type": "OBJECT", "description": "Modifications √† appliquer aux alarmes s√©lectionn√©es.", "required": False},
                    "timer_filters": {"type": "OBJECT", "description": "Filtres pour s√©lectionner les minuteurs √† modifier.", "required": False},
                    "timer_modifications": {"type": "OBJECT", "description": "Modifications √† appliquer aux minuteurs s√©lectionn√©es.", "required": False}
                }
            },
            "ocr_space": {
                "enabled": True,
                "description": "Extrait le texte d'une image en utilisant la reconnaissance optique de caract√®res (OCR). L'image doit √™tre fournie sous forme de cha√Æne Base64 (data:image/png;base64,...).",
                "parameters": {
                    "image_base64": {"type": "STRING", "description": "L'image encod√©e en Base64, incluant le pr√©fixe MIME (ex: data:image/png;base64,iVB...).", "required": True}
                }
            },
            "deepseek_chat": {
                "enabled": True,
                "description": "Interagit avec le mod√®le de chat DeepSeek pour des conversations g√©n√©rales ou des t√¢ches de g√©n√©ration de texte. Utile pour des r√©ponses cr√©atives ou des discussions.",
                "parameters": {
                    "prompt": {"type": "STRING", "description": "Le prompt ou la liste de messages pour le mod√®le de chat.", "required": True},
                    "model": {"type": "STRING", "description": "Le nom du mod√®le DeepSeek √† utiliser (ex: 'deepseek-chat', 'deepseek-coder').", "required": False, "default": "deepseek-chat"}
                }
            },
            "serper_dev": {
                "enabled": True,
                "description": "Effectue une recherche web via l'API Serper. Utile pour obtenir des snippets et des liens pertinents pour une requ√™te.",
                "parameters": {
                    "query_text": {"type": "STRING", "description": "La requ√™te de recherche.", "required": True}
                }
            },
            "wolfram_alpha": {
                "enabled": True,
                "description": "Interroge WolframAlpha pour des calculs, des faits scientifiques, des conversions d'unit√©s, des informations math√©matiques, etc.",
                "parameters": {
                    "input_text": {"type": "STRING", "description": "La requ√™te √† soumettre √† WolframAlpha (ex: 'derivative of x^2', 'population of France').", "required": True}
                }
            },
            "tavily_search": {
                "enabled": True,
                "description": "Effectue une recherche web avanc√©e via l'API Tavily, fournissant des r√©ponses directes et des extraits pertinents.",
                "parameters": {
                    "query_text": {"type": "STRING", "description": "La requ√™te de recherche.", "required": True},
                    "max_results": {"type": "INTEGER", "description": "Nombre maximum de r√©sultats √† retourner.", "required": False, "default": 3}
                }
            },
            "apiflash_screenshot": {
                "enabled": True,
                "description": "Capture une capture d'√©cran d'une page web √† partir d'une URL donn√©e. Retourne une URL vers l'image captur√©e.",
                "parameters": {
                    "url": {"type": "STRING", "description": "L'URL de la page web √† capturer.", "required": True}
                }
            },
            "crawlbase_scraper": {
                "enabled": True,
                "description": "Scrape le contenu HTML ou JavaScript d'une URL. Peut √™tre utilis√© pour obtenir le contenu brut d'une page web.",
                "parameters": {
                    "url": {"type": "STRING", "description": "L'URL de la page web √† scraper.", "required": True},
                    "use_js": {"type": "BOOLEAN", "description": "Indique si le scraping doit ex√©cuter JavaScript sur la page.", "required": False, "default": False}
                }
            },
            "detect_language": {
                "enabled": True,
                "description": "D√©tecte la langue d'un texte donn√©.",
                "parameters": {
                    "text": {"type": "STRING", "description": "Le texte dont la langue doit √™tre d√©tect√©e.", "required": True}
                }
            },
            "guardian_news": {
                "enabled": True,
                "description": "Recherche des articles de presse sur The Guardian. Utile pour des actualit√©s ou des informations sp√©cifiques.",
                "parameters": {
                    "query_text": {"type": "STRING", "description": "La requ√™te de recherche pour les articles.", "required": True}
                }
            },
            "ip2location": {
                "enabled": True,
                "description": "G√©olocalise une adresse IP pour obtenir des informations sur le pays, la ville, etc.",
                "parameters": {
                    "ip_address": {"type": "STRING", "description": "L'adresse IP √† g√©olocaliser.", "required": True}
                }
            },
            "shodan": {
                "enabled": True,
                "description": "Interroge Shodan pour des informations sur un h√¥te IP ou des informations sur la cl√© API. Si une IP est fournie, retourne les infos de l'h√¥te, sinon les infos de la cl√© API.",
                "parameters": {
                    "query_text": {"type": "STRING", "description": "L'adresse IP √† rechercher ou vide pour les infos de la cl√© API.", "required": False, "default": ""}
                }
            },
            "weather_api": {
                "enabled": True,
                "description": "R√©cup√®re les conditions m√©t√©orologiques actuelles pour une localisation donn√©e.",
                "parameters": {
                    "location": {"type": "STRING", "description": "La ville ou le code postal pour la m√©t√©o.", "required": True}
                }
            },
            "cloudmersive_domain": {
                "enabled": True,
                "description": "V√©rifie la validit√© et le type d'un nom de domaine via Cloudmersive API.",
                "parameters": {
                    "domain": {"type": "STRING", "description": "Le nom de domaine √† v√©rifier.", "required": True}
                }
            },
            "greynoise": {
                "enabled": True,
                "description": "Analyse une adresse IP pour d√©tecter si elle est associ√©e √† des activit√©s 'bruit' (scans, attaques, etc.) via GreyNoise.",
                "parameters": {
                    "ip_address": {"type": "STRING", "description": "L'adresse IP √† analyser.", "required": True}
                }
            },
            "pulsedive": {
                "enabled": True,
                "description": "Analyse un indicateur de menace (IP, domaine, URL) via Pulsedive pour obtenir des informations sur les risques.",
                "parameters": {
                    "indicator": {"type": "STRING", "description": "L'indicateur de menace √† analyser (ex: '8.8.8.8', 'example.com').", "required": True},
                    "type": {"type": "STRING", "description": "Le type d'indicateur ('auto', 'ip', 'domain', 'url').", "required": False, "default": "auto", "enum": ["auto", "ip", "domain", "url"]}
                }
            },
            "stormglass": {
                "enabled": True,
                "description": "R√©cup√®re les donn√©es m√©t√©orologiques maritimes (temp√©rature de l'air, hauteur des vagues, etc.) pour une coordonn√©e g√©ographique.",
                "parameters": {
                    "lat": {"type": "NUMBER", "description": "Latitude.", "required": True},
                    "lng": {"type": "NUMBER", "description": "Longitude.", "required": True},
                    "params": {"type": "STRING", "description": "Param√®tres m√©t√©o √† r√©cup√©rer (comma-separated, ex: 'airTemperature,waveHeight').", "required": False, "default": "airTemperature,waveHeight"}
                }
            },
            "loginradius_ping": {
                "enabled": True,
                "description": "Effectue un simple ping √† l'API LoginRadius pour v√©rifier sa disponibilit√©. Ne n√©cessite aucun param√®tre.",
                "parameters": {}
            },
            "jsonbin_io": {
                "enabled": True,
                "description": "Cr√©e un nouveau 'bin' JSON pour stocker des donn√©es ou acc√®de √† un bin existant. Utile pour stocker temporairement des donn√©es structur√©es.",
                "parameters": {
                    "data": {"type": "OBJECT", "description": "Les donn√©es JSON √† stocker lors de la cr√©ation d'un bin.", "required": False},
                    "private": {"type": "BOOLEAN", "description": "Indique si le bin doit √™tre priv√©.", "required": False, "default": True},
                    "bin_id": {"type": "STRING", "description": "L'ID du bin existant √† acc√©der.", "required": False}
                }
            },
            "huggingface_inference": {
                "enabled": True,
                "description": "Effectue une inf√©rence sur un mod√®le HuggingFace (ex: classification de texte, g√©n√©ration de texte).",
                "parameters": {
                    "model_name": {"type": "STRING", "description": "Le nom du mod√®le HuggingFace √† utiliser (ex: 'distilbert-base-uncased-finetuned-sst-2-english').", "required": False, "default": "distilbert-base-uncased-finetuned-sst-2-english"},
                    "input_text": {"type": "STRING", "description": "Le texte d'entr√©e pour l'inf√©rence.", "required": True}
                }
            },
            "twilio_balance": {
                "enabled": True,
                "description": "R√©cup√®re le solde du compte Twilio. Utile pour v√©rifier les cr√©dits restants pour l'envoi de SMS/appels.",
                "parameters": {}
            },
            "abstractapi": {
                "enabled": True,
                "description": "Interroge diverses APIs d'AbstractAPI pour la validation d'emails/t√©l√©phones, les taux de change ou les jours f√©ri√©s.",
                "parameters": {
                    "input_value": {"type": "STRING", "description": "La valeur d'entr√©e (email, num√©ro de t√©l√©phone, devise de base, code pays) selon le type d'API.", "required": True},
                    "api_type": {"type": "STRING", "description": "Le type d'API AbstractAPI √† utiliser ('PHONE_VALIDATION', 'EMAIL_VALIDATION', 'EXCHANGE_RATES', 'HOLIDAYS').", "required": True, "enum": ["PHONE_VALIDATION", "EMAIL_VALIDATION", "EXCHANGE_RATES", "HOLIDAYS"]}
                }
            },
            "google_custom_search": {
                "enabled": True,
                "description": "Effectue une recherche personnalis√©e Google en utilisant l'API Custom Search. N√©cessite un ID de moteur de recherche personnalis√© (CSE ID).",
                "parameters": {
                    "query_text": {"type": "STRING", "description": "La requ√™te de recherche.", "required": True}
                }
            },
            "randommer_phone": {
                "enabled": True,
                "description": "G√©n√®re des num√©ros de t√©l√©phone al√©atoires pour un pays donn√©. Utile pour des donn√©es de test ou des exemples.",
                "parameters": {
                    "country_code": {"type": "STRING", "description": "Le code ISO du pays (ex: 'US', 'FR').", "required": False, "default": "US"},
                    "quantity": {"type": "INTEGER", "description": "Le nombre de num√©ros de t√©l√©phone √† g√©n√©rer.", "required": False, "default": 1}
                }
            },
            "tomorrow_io_weather": {
                "enabled": True,
                "description": "R√©cup√®re les pr√©visions m√©t√©orologiques d√©taill√©es via Tomorrow.io pour une localisation et des champs sp√©cifiques.",
                "parameters": {
                    "location": {"type": "STRING", "description": "La localisation (nom de ville, code postal, coordonn√©es lat/lng).", "required": True},
                    "fields": {"type": "ARRAY", "items": {"type": "STRING"}, "description": "Liste des champs m√©t√©o √† r√©cup√©rer (ex: ['temperature', 'humidity']).", "required": False, "default": ["temperature", "humidity", "windSpeed"]}
                }
            },
            "openweathermap_weather": {
                "enabled": True,
                "description": "R√©cup√®re les conditions m√©t√©orologiques actuelles via OpenWeatherMap pour une localisation donn√©e.",
                "parameters": {
                    "location": {"type": "STRING", "description": "La ville ou le code postal pour la m√©t√©o.", "required": True}
                }
            },
