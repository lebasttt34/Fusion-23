endpoint_health_manager = EndpointHealthManager()

# --- FIN DU BLOC GESTION SANTE ENDPOINT ---
# --- DEBUT DU BLOC CLIENT API (BASE) ---

class APIClient:
    """Classe de base pour tous les clients API, gérant la sélection dynamique d'endpoints et les réessais."""
    def __init__(self, name: str):
        self.name = name
        self.endpoints_config = API_CONFIG.get(name, [])
        if not self.endpoints_config:
            log_message(f"Client API {self.name} initialisé sans configuration d'endpoint.", level="error")

    async def _make_request(self, params: Dict = None, headers: Dict = None, json_data: Dict = None, timeout: int = 30, max_retries: int = 3, initial_delay: float = 1.0, url: Optional[str] = None, method: Optional[str] = None, key_field: Optional[str] = None, key_location: Optional[str] = None, api_key: Optional[Union[str, tuple]] = None, fixed_params: Optional[Dict] = None, fixed_headers: Optional[Dict] = None, fixed_json: Optional[Dict] = None) -> Optional[Dict]:
        """Méthode interne pour effectuer les requêtes HTTP en utilisant le meilleur endpoint avec réessais."""
        
        # Utiliser l'URL/méthode/clé fournie si explicitement donnée, sinon utiliser la configuration de l'endpoint sélectionné
        selected_endpoint_config = None
        endpoint_key_for_health = "Dynamic" # Placeholder par défaut

        if url and method:
            # Si des paramètres de requête spécifiques sont fournis, les utiliser
            selected_endpoint_config = {
                "url": url,
                "method": method,
                "key_field": key_field,
                "key_location": key_location,
                "key": api_key,
                "fixed_params": fixed_params if fixed_params is not None else {},
                "fixed_headers": fixed_headers if fixed_headers is not None else {},
                "fixed_json": fixed_json if fixed_json is not None else {},
                "endpoint_name": "Dynamic" # Placeholder pour le gestionnaire de santé
            }
            # Si une clé est fournie, créer un endpoint_key unique pour la gestion de la santé
            if api_key:
                endpoint_key_for_health = f"Dynamic-{api_key}"
            log_message(f"Requête dynamique pour {self.name} vers {url}")
        else:
            selected_endpoint_config = endpoint_health_manager.get_best_endpoint(self.name)
            if not selected_endpoint_config:
                log_message(f"Aucun endpoint sain ou disponible pour {self.name}.", level="error")
                return {"error": True, "message": f"Aucun endpoint sain ou disponible pour {self.name}."}
            endpoint_key_for_health = f"{selected_endpoint_config['endpoint_name']}-{selected_endpoint_config['key']}"
            log_message(f"Endpoint sélectionné pour {self.name}: {selected_endpoint_config['endpoint_name']}")

        url_to_use = selected_endpoint_config["url"]
        method_to_use = selected_endpoint_config["method"]

        # Copier pour ne pas modifier les fixed_params/headers/json_data globaux
        request_params = selected_endpoint_config.get("fixed_params", {}).copy()
        request_headers = selected_endpoint_config.get("fixed_headers", {}).copy()
        request_json_data = selected_endpoint_config.get("fixed_json", {}).copy()
        auth = None

        # Fusionner les paramètres dynamiques avec les fixes
        if params:
            request_params.update(params)
        if headers:
            request_headers.update(headers)
        if json_data:
            request_json_data.update(json_data)

        # Ajouter la clé API selon sa configuration
        key_field_to_use = selected_endpoint_config.get("key_field")
        key_location_to_use = selected_endpoint_config.get("key_location")
        key_prefix = selected_endpoint_config.get("key_prefix", "")
        api_key_to_use = selected_endpoint_config["key"] # La clé réelle

        if key_field_to_use and key_location_to_use:
            if key_location_to_use == "param":
                request_params[key_field_to_use] = api_key_to_use
            elif key_location_to_use == "header":
                request_headers[key_field_to_use] = f"{key_prefix}{api_key_to_use}"
            elif key_location_to_use == "auth_basic":
                # Pour Twilio, api_key est un tuple (sid, secret)
                if isinstance(api_key_to_use, tuple) and len(api_key_to_use) == 2:
                    auth = httpx.BasicAuth(api_key_to_use[0], api_key_to_use[1])
                else:
                    log_message(f"Clé API pour auth_basic non valide pour {self.name}:{endpoint_key_for_health}", level="error")
                    endpoint_health_manager.update_endpoint_health(self.name, endpoint_key_for_health, False, 0.0)
                    return {"error": True, "message": "Configuration d'authentification basique invalide."}

        current_delay = initial_delay
        for attempt in range(max_retries):
            start_time = time.monotonic()
            success = False
            try:
                async with httpx.AsyncClient(timeout=timeout) as client:
                    response = await client.request(method_to_use, url_to_use, params=request_params, headers=request_headers, json=request_json_data, auth=auth)
                    response.raise_for_status() # Lève une exception pour les codes d'erreur HTTP
                    success = True
                    # Tente de décoder le JSON, sinon retourne le texte brut ou une erreur
                    try:
                        return response.json()
                    except json.JSONDecodeError:
                        log_message(f"API {self.name} réponse non JSON (tentative {attempt+1}/{max_retries}): {response.text}", level="warning")
                        # Si ce n'est pas JSON et que ce n'est pas une erreur HTTP, on considère ça comme un succès partiel
                        # mais on le signale comme une erreur pour les clients qui attendent du JSON.
                        return {"error": True, "message": "Réponse API non JSON.", "raw_response": response.text}

            except httpx.HTTPStatusError as e:
                log_message(f"API {self.name} erreur HTTP (tentative {attempt+1}/{max_retries}): {e.response.status_code} - {e.response.text}", level="warning")
                # Ne pas réessayer pour les erreurs client (4xx) sauf 429 (Too Many Requests)
                if 400 <= e.response.status_code < 500 and e.response.status_code != 429:
                    log_message(f"API {self.name}: Erreur client {e.response.status_code}, pas de réessai.", level="error")
                    endpoint_health_manager.update_endpoint_health(self.name, endpoint_key_for_health, False, e.response.elapsed.total_seconds())
                    return {"error": True, "status_code": e.response.status_code, "message": e.response.text}
                
                # Réessayer pour les erreurs serveur ou timeouts ou 429
                if attempt < max_retries - 1:
                    log_message(f"API {self.name}: Réessai dans {current_delay:.2f}s...", level="info")
                    await asyncio.sleep(current_delay)
                    current_delay *= 2 # Backoff exponentiel
            except httpx.RequestError as e:
                log_message(f"API {self.name} erreur de requête (tentative {attempt+1}/{max_retries}): {e}", level="warning")
                if attempt < max_retries - 1:
                    log_message(f"API {self.name}: Réessai dans {current_delay:.2f}s...", level="info")
                    await asyncio.sleep(current_delay)
                    current_delay *= 2
            except Exception as e:
                log_message(f"API {self.name} erreur inattendue (tentative {attempt+1}/{max_retries}): {e}", level="error")
                endpoint_health_manager.update_endpoint_health(self.name, endpoint_key_for_health, False, time.monotonic() - start_time)
                return {"error": True, "message": str(e)}
            finally:
                if not success: # Si l'exception a été levée
                    latency = time.monotonic() - start_time
                    endpoint_health_manager.update_endpoint_health(self.name, endpoint_key_for_health, False, latency)
        
        # Si toutes les tentatives ont échoué
        log_message(f"API {self.name}: Toutes les tentatives ont échoué après {max_retries} réessais.", level="error")
        return {"error": True, "message": f"Échec de la requête après {max_retries} tentatives."}

    async def query(self, *args, **kwargs) -> Any:
        """Méthode abstraite pour interroger l'API."""
        raise NotImplementedError("La méthode query doit être implémentée par les sous-classes.")

# --- FIN DU BLOC CLIENT API (BASE) ---

# --- DEBUT DU BLOC CLIENTS API SPECIFIQUES (PARTIE 1) ---

class DeepSeekClient(APIClient):
    def __init__(self):
        super().__init__("DEEPSEEK")

    async def query(self, prompt: str, model: str = "deepseek-chat") -> str:
        payload = {"model": model, "messages": [{"role": "user", "content": prompt}]}
        response = await self._make_request(json_data=payload)
        if response and not response.get("error"):
            content = response.get("choices", [{}])[0].get("message", {}).get("content")
            if content:
                return content
            return "DeepSeek: Pas de contenu de réponse trouvé."
        return f"DeepSeek: Erreur: {response.get('message', 'Inconnu')}" if response else "DeepSeek: Réponse vide ou erreur interne."

class SerperClient(APIClient):
    def __init__(self):
        super().__init__("SERPER")

    async def query(self, query_text: str) -> str:
        payload = {"q": query_text}
        response = await self._make_request(json_data=payload)
        if response and not response.get("error"):
            organic_results = response.get("organic", [])
            if organic_results:
                snippet = organic_results[0].get("snippet", "Pas de snippet.")
                link = organic_results[0].get("link", "")
                return f"Serper (recherche web):\n{snippet} {neutralize_urls(link)}"
            return "Serper: Aucune information trouvée."
        return f"Serper: Erreur: {response.get('message', 'Inconnu')}" if response else "Serper: Réponse vide ou erreur interne."

class WolframAlphaClient(APIClient):
    def __init__(self):
        super().__init__("WOLFRAMALPHA")

    async def query(self, input_text: str) -> str:
        params = {"input": input_text}
        response = await self._make_request(params=params)
        if response and not response.get("error"):
            pods = response.get("queryresult", {}).get("pods", [])
            if pods:
                for pod in pods:
                    if pod.get("title") in ["Result", "Input interpretation", "Decimal approximation"]:
                        subpods = pod.get("subpods", [])
                        if subpods and subpods[0].get("plaintext"):
                            return f"WolframAlpha:\n{subpods[0]['plaintext']}"
                if pods and pods[0].get("subpods") and pods[0]["subpods"][0].get("plaintext"):
                    return f"WolframAlpha:\n{pods[0]['subpods'][0]['plaintext']}"
            return "WolframAlpha: Pas de résultat clair."
        return f"WolframAlpha: Erreur: {response.get('message', 'Inconnu')}" if response else "WolframAlpha: Réponse vide ou erreur interne."

class TavilyClient(APIClient):
    def __init__(self):
        super().__init__("TAVILY")

    async def query(self, query_text: str, max_results: int = 3) -> str:
        payload = {"query": query_text, "max_results": max_results}
        response = await self._make_request(json_data=payload)
        if response and not response.get("error"):
            results = response.get("results", [])
            answer = response.get("answer", "Aucune réponse directe trouvée.")

            output = f"Tavily (recherche web):\nRéponse directe: {answer}\n"
            if results:
                output += "Extraits pertinents:\n"
                for i, res in enumerate(results[:max_results]):
                    output += f"- {res.get('title', 'N/A')}: {res.get('content', 'N/A')} {neutralize_urls(res.get('url', ''))}\n"
            return output
        return f"Tavily: Erreur: {response.get('message', 'Inconnu')}" if response else "Tavily: Réponse vide ou erreur interne."

class ApiFlashClient(APIClient):
    def __init__(self):
        super().__init__("APIFLASH")

    async def query(self, url: str) -> str:
        params = {"url": url, "format": "jpeg", "full_page": "true"}
        response = await self._make_request(params=params)
        # ApiFlash retourne directement l'image, pas un JSON.
        # Donc, si la requête HTTP a réussi, on considère que c'est un succès.
        # La méthode _make_request va retourner un dictionnaire d'erreur si la réponse n'est pas JSON.
        if response and response.get("error") and "Réponse API non JSON" in response["message"]:
            # C'est le comportement attendu pour ApiFlash (retourne une image, pas JSON)
            # On doit donc ignorer l'erreur JSON et construire l'URL de l'image.
            selected_endpoint_config = endpoint_health_manager.get_best_endpoint(self.name)
            if selected_endpoint_config:
                # Reconstruire l'URL avec les paramètres pour l'affichage
                capture_url = f"{selected_endpoint_config['url']}?access_key={selected_endpoint_config['key']}&url={url}&format=jpeg&full_page=true"
                return f"ApiFlash (capture d'écran): {neutralize_urls(capture_url)} (Vérifiez le lien pour l'image)"
            return "ApiFlash: Impossible de générer l'URL de capture."
        elif response and not response.get("error"):
            # Si par hasard ApiFlash renvoie du JSON (peu probable pour une capture), on le log
            log_message(f"ApiFlash a renvoyé du JSON inattendu: {response}", level="warning")
            return f"ApiFlash: Réponse inattendue de l'API. {response}"
        
        return f"ApiFlash: Erreur: {response.get('message', 'Inconnu')}" if response else "ApiFlash: Réponse vide ou erreur interne."

class CrawlbaseClient(APIClient):
    def __init__(self):
        super().__init__("CRAWLBASE")

    async def query(self, url: str, use_js: bool = False) -> str:
        params = {"url": url, "format": "json"}
        
        # Sélectionner l'endpoint approprié (HTML ou JS)
        selected_endpoint_config = None
        if use_js:
            for config in self.endpoints_config:
                if "JS Scraping" in config.get("endpoint_name", ""):
                    selected_endpoint_config = config
                    break
        
        # Si pas d'endpoint JS ou si use_js est False, tenter de récupérer le meilleur endpoint générique
        if not selected_endpoint_config:
            selected_endpoint_config = endpoint_health_manager.get_best_endpoint(self.name)

        if not selected_endpoint_config:
            return f"Crawlbase: Aucun endpoint sain ou disponible pour {self.name}."

        # Manuellement faire la requête pour s'assurer que la bonne configuration d'endpoint est utilisée
        response = await self._make_request(
            params=params,
            url=selected_endpoint_config["url"], # Surcharge l'URL avec l'URL de l'endpoint sélectionné
            method=selected_endpoint_config["method"],
            key_field=selected_endpoint_config["key_field"],
            key_location=selected_endpoint_config["key_location"],
            api_key=selected_endpoint_config["key"],
            fixed_params=selected_endpoint_config.get("fixed_params", {}) # Inclure les paramètres fixes de la configuration sélectionnée
        )

        if response and not response.get("error"):
            body = response.get("body")
            if body:
                try:
                    decoded_body = base64.b64decode(body).decode('utf-8', errors='ignore')
                    return f"Crawlbase (contenu web):\n{decoded_body[:1000]}..." # Tronquer pour la brièveté
                except Exception:
                    return f"Crawlbase (contenu web - brut):\n{body[:1000]}..."
            return "Crawlbase: Contenu non trouvé."
        return f"Crawlbase: Erreur: {response.get('message', 'Inconnu')}" if response else "Crawlbase: Réponse vide ou erreur interne."

class DetectLanguageClient(APIClient):
    def __init__(self):
        super().__init__("DETECTLANGUAGE")

    async def query(self, text: str) -> str:
        payload = {"q": text}
        response = await self._make_request(json_data=payload)
        if response and not response.get("error"):
            detections = response.get("data", {}).get("detections", [])
            if detections:
                first_detection = detections[0]
                lang = first_detection.get("language")
                confidence = first_detection.get("confidence")
                return f"Langue détectée: {lang} (confiance: {confidence})"
            return "DetectLanguage: Aucune langue détectée."
        return f"DetectLanguage: Erreur: {response.get('message', 'Inconnu')}" if response else "DetectLanguage: Réponse vide ou erreur interne."

class GuardianClient(APIClient):
    def __init__(self):
        super().__init__("GUARDIAN")

    async def query(self, query_text: str) -> str:
        params = {"q": query_text}
        response = await self._make_request(params=params)
        if response and not response.get("error"):
            results = response.get("response", {}).get("results", [])
            if results:
                output = "Articles The Guardian:\n"
                for res in results[:3]: # Limiter à 3 articles
                    output += f"- {res.get('webTitle', 'N/A')}: {res.get('fields', {}).get('trailText', 'N/A')} {neutralize_urls(res.get('webUrl', ''))}\n"
                return output
            return "Guardian: Aucun article trouvé."
        return f"Guardian: Erreur: {response.get('message', 'Inconnu')}" if response else "Guardian: Réponse vide ou erreur interne."

class IP2LocationClient(APIClient):
    def __init__(self):
        super().__init__("IP2LOCATION")

    async def query(self, ip_address: str) -> str:
        params = {"ip": ip_address}
        response = await self._make_request(params=params)
        if response and not response.get("error"):
            if "country_name" in response:
                return f"IP2Location (Géolocalisation IP {ip_address}): Pays: {response['country_name']}, Ville: {response.get('city_name', 'N/A')}"
            return "IP2Location: Informations non trouvées."
        return f"IP2Location: Erreur: {response.get('message', 'Inconnu')}" if response else "IP2Location: Réponse vide ou erreur interne."

class ShodanClient(APIClient):
    def __init__(self):
        super().__init__("SHODAN")

    async def query(self, query_text: str = "") -> str: # Query text est optionnel, car /api-info n'en a pas besoin
        # Shodan a divers endpoints. Cet exemple utilise /api-info.
        # Pour une recherche réelle, ce serait /shodan/host/search ou /shodan/scan
        # Pour simplifier, nous allons simplement interroger /api-info qui nous informe sur la clé.
        # Si query_text est fourni, on tente une recherche d'hôte.
        if query_text:
            # Tenter de faire une recherche d'hôte si l'IP est valide
            if re.match(r"^\d{1,3}\.\d{1,3}\.\d{1,3}\.\d{1,3}$", query_text):
                selected_endpoint_config = None
                for config in self.endpoints_config:
                    if "Host Info" in config.get("endpoint_name", ""):
                        selected_endpoint_config = config
                        break
                if selected_endpoint_config:
                    url = f"https://api.shodan.io/shodan/host/{query_text}"
                    response = await self._make_request(
                        params={"key": selected_endpoint_config["key"]},
                        url=url,
                        method="GET"
                    )
                    if response and not response.get("error"):
                        return f"Shodan (info hôte {query_text}): Pays: {response.get('country_name', 'N/A')}, Ports: {response.get('ports', 'N/A')}, Vulnérabilités: {response.get('vulns', 'Aucune')}"
                    return f"Shodan (info hôte): Erreur: {response.get('message', 'Inconnu')}" if response else "Shodan: Réponse vide ou erreur interne."
            else:
                return "Shodan: Veuillez fournir une adresse IP valide pour la recherche d'hôte."

        # Par défaut, ou si la recherche d'hôte n'est pas applicable/échoue, interroger /api-info
        response = await self._make_request() # Aucun paramètre spécifique n'est nécessaire pour /api-info
        if response and not response.get("error"):
            return f"Shodan (info clé): Requêtes restantes: {response.get('usage_limits', {}).get('query_credits', 'N/A')}, Scan crédits: {response.get('usage_limits', {}).get('scan_credits', 'N/A')}"
        return f"Shodan: Erreur: {response.get('message', 'Inconnu')}" if response else "Shodan: Réponse vide ou erreur interne."

class WeatherAPIClient(APIClient):
    def __init__(self):
        super().__init__("WEATHERAPI")

    async def query(self, location: str) -> str:
        params = {"q": location}
        response = await self._make_request(params=params)
        if response and not response.get("error"):
            current = response.get("current", {})
            location_info = response.get("location", {})
            if current and location_info:
                return (
                    f"Météo à {location_info.get('name', 'N/A')}, {location_info.get('country', 'N/A')}:\n"
                    f"Température: {current.get('temp_c', 'N/A')}°C, "
                    f"Conditions: {current.get('condition', {}).get('text', 'N/A')}, "
                    f"Vent: {current.get('wind_kph', 'N/A')} km/h"
                )
            return "WeatherAPI: Données météo non trouvées."
        return f"WeatherAPI: Erreur: {response.get('message', 'Inconnu')}" if response else "WeatherAPI: Réponse vide ou erreur interne."

class CloudmersiveClient(APIClient):
    def __init__(self):
        super().__init__("CLOUDMERSIVE")

    async def query(self, domain: str) -> str:
        payload = {"domain": domain}
        response = await self._make_request(json_data=payload)
        if response and not response.get("error"):
            return f"Cloudmersive (vérification de domaine {domain}): Valide: {response.get('ValidDomain', 'N/A')}, Type: {response.get('DomainType', 'N/A')}"
        return f"Cloudmersive: Erreur: {response.get('message', 'Inconnu')}" if response else "Cloudmersive: Réponse vide ou erreur interne."

class GreyNoiseClient(APIClient):
    def __init__(self):
        super().__init__("GREYNOISE")

    async def query(self, ip_address: str) -> str:
        # GreyNoise endpoint requires IP to be part of the URL path
        selected_endpoint_config = endpoint_health_manager.get_best_endpoint(self.name)
        if not selected_endpoint_config:
            return f"GreyNoise: Aucun endpoint sain ou disponible pour {self.name}."

        # Manually construct URL for GreyNoise since IP is path param
        url = f"{selected_endpoint_config['url']}{ip_address}"
        method = selected_endpoint_config["method"]
        headers = {selected_endpoint_config["key_field"]: selected_endpoint_config["key"]}

        # Utilisation de _make_request pour bénéficier des réessais et de la gestion d'erreurs
        response = await self._make_request(
            headers=headers,
            url=url,
            method=method,
            key_field=selected_endpoint_config["key_field"], # Passer pour que _make_request puisse gérer la clé
            key_location=selected_endpoint_config["key_location"],
            api_key=selected_endpoint_config["key"]
        )

        if response and not response.get("error"):
            if response.get("noise"):
                return f"GreyNoise (IP {ip_address}): C'est une IP 'bruit' (malveillante). Classification: {response.get('classification', 'N/A')}, Nom d'acteur: {response.get('actor', 'N/A')}"
            return f"GreyNoise (IP {ip_address}): Pas de 'bruit' détecté. Statut: {response.get('status', 'N/A')}"
        return f"GreyNoise: Erreur: {response.get('message', 'Inconnu')}" if response else "GreyNoise: Réponse vide ou erreur interne."

class PulsediveClient(APIClient):
    def __init__(self):
        super().__init__("PULSEDIVE")

    async def query(self, indicator: str, type: str = "auto") -> str:
        params = {"indicator": indicator, "type": type}
        response = await self._make_request(params=params)
        if response and not response.get("error"):
            if response.get("results"):
                result = response["results"][0]
                return (
                    f"Pulsedive (Analyse {indicator}): Type: {result.get('type', 'N/A')}, "
                    f"Risk: {result.get('risk', 'N/A')}, "
                    f"Description: {result.get('description', 'N/A')[:200]}..."
                )
            return "Pulsedive: Aucun résultat d'analyse trouvé."
        return f"Pulsedive: Erreur: {response.get('message', 'Inconnu')}" if response else "Pulsedive: Réponse vide ou erreur interne."

class StormGlassClient(APIClient):
    def __init__(self):
        super().__init__("STORMGLASS")

    async def query(self, lat: float, lng: float, params: str = "airTemperature,waveHeight") -> str:
        now = int(time.time())
        request_params = {
            "lat": lat,
            "lng": lng,
            "params": params,
            "start": now,
            "end": now + 3600 # One hour from now
        }
        response = await self._make_request(params=request_params)
        if response and not response.get("error"):
            data = response.get("hours", [])
            if data:
                first_hour = data[0]
                temp = first_hour.get('airTemperature', [{}])[0].get('value', 'N/A')
                wave_height = first_hour.get('waveHeight', [{}])[0].get('value', 'N/A')
                return f"StormGlass (Météo maritime à {lat},{lng}): Température air: {temp}°C, Hauteur vagues: {wave_height}m"
            return "StormGlass: Données non trouvées."
        return f"StormGlass: Erreur: {response.get('message', 'Inconnu')}" if response else "StormGlass: Réponse vide ou erreur interne."

class LoginRadiusClient(APIClient):
    def __init__(self):
        super().__init__("LOGINRADIUS")

    async def query(self) -> str:
        response = await self._make_request()
        if response and not response.get("error"):
            return f"LoginRadius (Ping API): Statut: {response.get('Status', 'N/A')}, Message: {response.get('Message', 'N/A')}"
        return f"LoginRadius: Erreur: {response.get('message', 'Inconnu')}" if response else "LoginRadius: Réponse vide ou erreur interne."

class JsonbinClient(APIClient):
    def __init__(self):
        super().__init__("JSONBIN")

    async def query(self, data: Dict[str, Any], private: bool = True, bin_id: Optional[str] = None) -> str:
        # If bin_id is provided, it's a GET request to access a bin
        if bin_id:
            selected_endpoint_config = None
            for config in self.endpoints_config:
                if "Bin Access" in config.get("endpoint_name", ""):
                    selected_endpoint_config = config
                    break
            if not selected_endpoint_config:
                return f"Jsonbin: Aucun endpoint d'accès de bin sain ou disponible pour {self.name}."

            url = f"{selected_endpoint_config['url']}/{bin_id}"
            method = "GET"
            headers = {selected_endpoint_config["key_field"]: selected_endpoint_config["key"]}
            
            response = await self._make_request(
                headers=headers,
                url=url,
                method=method
            )
            if response and not response.get("error"):
                return f"Jsonbin (Accès bin {bin_id}):\n{json.dumps(response, indent=2)}"
            return f"Jsonbin (Accès bin): Erreur: {response.get('message', 'Inconnu')}" if response else "Jsonbin: Réponse vide ou erreur interne."
        
        # Otherwise, it's a POST request to create a bin
        else:
            selected_endpoint_config = None
            for config in self.endpoints_config:
                if "Bin Create" in config.get("endpoint_name", ""):
                    selected_endpoint_config = config
                    break
            
            if not selected_endpoint_config:
                return f"Jsonbin: Aucun endpoint de création de bin sain ou disponible pour {self.name}."

            url = selected_endpoint_config["url"]
            method = "POST"
            headers = {selected_endpoint_config["key_field"]: selected_endpoint_config["key"], "Content-Type": "application/json"}
            payload = {"record": data, "private": private}

            response = await self._make_request(
                json_data=payload,
                headers=headers,
                url=url,
                method=method
            )

            if response and not response.get("error"):
                return f"Jsonbin (Création de bin): ID: {response.get('metadata', {}).get('id', 'N/A')}, URL: {neutralize_urls(response.get('metadata', {}).get('url', 'N/A'))}"
            return f"Jsonbin (Création de bin): Erreur: {response.get('message', 'Inconnu')}" if response else "Jsonbin: Réponse vide ou erreur interne."

class HuggingFaceClient(APIClient):
    def __init__(self):
        super().__init__("HUGGINGFACE")

    async def query(self, model_name: str = "distilbert-base-uncased-finetuned-sst-2-english", input_text: str = "Hello world") -> str:
        # HuggingFace inference endpoint URL includes the model name
        selected_endpoint_config = endpoint_health_manager.get_best_endpoint(self.name)
        if not selected_endpoint_config:
            return f"HuggingFace: Aucun endpoint sain ou disponible pour {self.name}."

        # Override URL for inference
        inference_url = f"https://api-inference.huggingface.co/models/{model_name}"
        
        # Ensure the key is added to headers as per config
        headers = {
            selected_endpoint_config["key_field"]: f"{selected_endpoint_config['key_prefix']}{selected_endpoint_config['key']}",
            "Content-Type": "application/json"
        }
        payload = {"inputs": input_text}

        response = await self._make_request(
            json_data=payload,
            headers=headers,
            url=inference_url,
            method="POST" # Inference is always POST
        )

        if response and not response.get("error"):
            if isinstance(response, list) and response:
                first_result = response[0]
                if isinstance(first_result, list) and first_result:
                    return f"HuggingFace ({model_name} - {first_result[0].get('label')}): Score {first_result[0].get('score', 'N/A'):.2f}"
                elif isinstance(first_result, dict) and "generated_text" in first_result:
                    return f"HuggingFace ({model_name}): {first_result.get('generated_text')}"
            return f"HuggingFace ({model_name}): Réponse non parsée. {response}"
        return f"HuggingFace: Erreur: {response.get('message', 'Inconnu')}" if response else "HuggingFace: Réponse vide ou erreur interne."

class TwilioClient(APIClient):
    def __init__(self):
        super().__init__("TWILIO")

    async def query(self) -> str:
        # Twilio uses Basic Auth, handled by _make_request
        # We need to explicitly select an endpoint for the query method
        selected_endpoint_config = None
        for config in self.endpoints_config:
            if "Account Balance" in config.get("endpoint_name", ""): # Prioritize balance check
                selected_endpoint_config = config
                break
        if not selected_endpoint_config:
            selected_endpoint_config = self.endpoints_config[0] # Fallback to first if balance not found

        response = await self._make_request(
            url=selected_endpoint_config["url"],
            method=selected_endpoint_config["method"],
            key_location=selected_endpoint_config["key_location"],
            api_key=selected_endpoint_config["key"]
        )
        if response and not response.get("error"):
            # The balance endpoint returns balance and currency directly
            return f"Twilio (Balance): {response.get('balance', 'N/A')} {response.get('currency', 'N/A')}"
        return f"Twilio: Erreur: {response.get('message', 'Inconnu')}" if response else "Twilio: Réponse vide ou erreur interne."

class AbstractAPIClient(APIClient):
    def __init__(self):
        super().__init__("ABSTRACTAPI")

    async def query(self, input_value: str, api_type: str) -> str:
        params = {}
        target_endpoint_name = ""

        if api_type == "PHONE_VALIDATION":
            params["phone"] = input_value
            target_endpoint_name = "Phone Validation"
        elif api_type == "EMAIL_VALIDATION":
            params["email"] = input_value
            # Select one of the email validation keys
            target_endpoint_name = "Email Validation"
        elif api_type == "EXCHANGE_RATES":
            target_endpoint_name = "Exchange Rates"
        elif api_type == "HOLIDAYS":
            params["country"] = input_value if input_value else "US"
            params["year"] = datetime.now().year
            target_endpoint_name = "Holidays"
        else:
            return f"AbstractAPI: Type d'API '{api_type}' non supporté pour la requête."

        selected_endpoint_config = None
        for config in self.endpoints_config:
            if target_endpoint_name in config["endpoint_name"]:
                selected_endpoint_config = config
                break
        
        if not selected_endpoint_config:
            return f"AbstractAPI: Aucun endpoint sain ou disponible pour {self.name} pour le type {api_type}."

        response = await self._make_request(
            params=params,
            url=selected_endpoint_config["url"],
            method=selected_endpoint_config["method"],
            key_field=selected_endpoint_config["key_field"],
            key_location=selected_endpoint_config["key_location"],
            api_key=selected_endpoint_config["key"],
            fixed_params=selected_endpoint_config.get("fixed_params", {})
        )

        if response and not response.get("error"):
            if api_type == "PHONE_VALIDATION":
                return (
                    f"AbstractAPI (Validation Tél): Numéro: {response.get('phone', 'N/A')}, "
                    f"Valide: {response.get('valid', 'N/A')}, "
                    f"Pays: {response.get('country', {}).get('name', 'N/A')}"
                )
            elif api_type == "EMAIL_VALIDATION":
                return (
                    f"AbstractAPI (Validation Email): Email: {response.get('email', 'N/A')}, "
                    f"Valide: {response.get('is_valid_format', 'N/A')}, "
                    f"Deliverable: {response.get('is_deliverable', 'N/A')}"
                )
            elif api_type == "EXCHANGE_RATES":
                return f"AbstractAPI (Taux de change): Base: {response.get('base', 'N/A')}, Taux (USD): {response.get('exchange_rates', {}).get('USD', 'N/A')}"
            elif api_type == "HOLIDAYS":
                holidays = [h.get('name', 'N/A') for h in response if h.get('name')]
                return f"AbstractAPI (Jours fériés {params.get('country', 'US')} {params.get('year')}): {', '.join(holidays[:5])}..." if holidays else "Aucun jour férié trouvé."
            return f"AbstractAPI ({api_type}): Réponse brute: {response}"
        return f"AbstractAPI ({api_type}): Erreur: {response.get('message', 'Inconnu')}" if response else "AbstractAPI: Réponse vide ou erreur interne."

class GeminiAPIClient(APIClient):
    def __init__(self):
        super().__init__("GEMINI_API")

    async def query(self, prompt: str, model: str = "gemini-1.5-flash") -> str:
        payload = {"contents": [{"parts": [{"text": prompt}]}]}
        # Gemini API often requires the model name in the URL path
        selected_endpoint_config = endpoint_health_manager.get_best_endpoint(self.name)
        if not selected_endpoint_config:
            return f"Gemini API: Aucun endpoint sain ou disponible pour {self.name}."

        # Override URL for specific model generation
        generate_url = f"https://generativelanguage.googleapis.com/v1beta/models/{model}:generateContent"
        
        # Ensure the key is added to params as per config
        request_params = {selected_endpoint_config["key_field"]: selected_endpoint_config["key"]}

        response = await self._make_request(
            json_data=payload,
            params=request_params,
            url=generate_url,
            method="POST",
            timeout=60 # Longer timeout for LLM calls
        )

        if response and not response.get("error"):
            if response.get("candidates") and response["candidates"][0].get("content"):
                return response["candidates"][0]["content"]["parts"][0]["text"]
            return f"Gemini API: Pas de réponse générée. {response}"
        return f"Gemini API: Erreur: {response.get('message', 'Inconnu')}" if response else "Gemini API: Réponse vide ou erreur interne."

class GoogleCustomSearchClient(APIClient):
    def __init__(self):
        super().__init__("GOOGLE_CUSTOM_SEARCH")

    async def query(self, query_text: str) -> str:
        params = {"q": query_text}
        response = await self._make_request(params=params)
        if response and not response.get("error"):
            items = response.get("items", [])
            if items:
                output = "Google Custom Search:\n"
                for item in items[:3]: # Limit to 3 results
                    output += f"- {item.get('title', 'N/A')}: {item.get('snippet', 'N/A')} {neutralize_urls(item.get('link', ''))}\n"
                return output
            return "Google Custom Search: Aucun résultat trouvé."
        return f"Google Custom Search: Erreur: {response.get('message', 'Inconnu')}" if response else "Google Custom Search: Réponse vide ou erreur interne."

class RandommerClient(APIClient):
    def __init__(self):
        super().__init__("RANDOMMER")

    async def query(self, country_code: str = "US", quantity: int = 1) -> str:
        params = {"CountryCode": country_code, "Quantity": quantity}
        response = await self._make_request(params=params)
        if response and not response.get("error"):
            if isinstance(response, list) and response:
                return f"Randommer (Numéros de téléphone): {', '.join(response)}"
            return f"Randommer: {response}"
        return f"Randommer: Erreur: {response.get('message', 'Inconnu')}" if response else "Randommer: Réponse vide ou erreur interne."

class TomorrowIOClient(APIClient):
    def __init__(self):
        super().__init__("TOMORROW.IO")

    async def query(self, location: str, fields: List[str] = None) -> str:
        if fields is None:
            fields = ["temperature", "humidity", "windSpeed"]
        payload = {"location": location, "fields": fields, "units": "metric", "timesteps": ["1h"]}
        response = await self._make_request(json_data=payload)
        if response and not response.get("error"):
            data = response.get("data", {}).get("timelines", [{}])[0].get("intervals", [{}])[0].get("values", {})
            if data:
                output = f"Météo (Tomorrow.io) à {location}:\n"
                for field in fields:
                    output += f"- {field.capitalize()}: {data.get(field, 'N/A')}\n"
                return output
            return "Tomorrow.io: Données météo non trouvées."
        return f"Tomorrow.io: Erreur: {response.get('message', 'Inconnu')}" if response else "Tomorrow.io: Réponse vide ou erreur interne."

class OpenWeatherMapClient(APIClient):
    def __init__(self):
        super().__init__("OPENWEATHERMAP")

    async def query(self, location: str) -> str:
        params = {"q": location}
        response = await self._make_request(params=params)
        if response and not response.get("error"):
            main_data = response.get("main", {})
            weather_desc = response.get("weather", [{}])[0].get("description", "N/A")
            if main_data:
                return (
                    f"Météo (OpenWeatherMap) à {location}:\n"
                    f"Température: {main_data.get('temp', 'N/A')}°C, "
                    f"Ressenti: {main_data.get('feels_like', 'N/A')}°C, "
                    f"Humidité: {main_data.get('humidity', 'N/A')}%, "
                    f"Conditions: {weather_desc}"
                )
            return "OpenWeatherMap: Données météo non trouvées."
        return f"OpenWeatherMap: Erreur: {response.get('message', 'Inconnu')}" if response else "OpenWeatherMap: Réponse vide ou erreur interne."

class MockarooClient(APIClient):
    def __init__(self):
        super().__init__("MOCKAROO")

    async def query(self, count: int = 1, fields_json: str = None) -> str:
        # Mockaroo's 'fields' parameter often expects a JSON string, which needs to be URL-encoded for GET requests.
        # The default fixed_params already include a basic fields_json.
        params = {"count": count}
        if fields_json:
            params["fields"] = fields_json # Override default if provided

        response = await self._make_request(params=params)
        if response and not response.get("error"):
            return f"Mockaroo (Génération de données):\n{json.dumps(response, indent=2)}"
        return f"Mockaroo: Erreur: {response.get('message', 'Inconnu')}" if response else "Mockaroo: Réponse vide ou erreur interne."

class OpenPageRankClient(APIClient):
    def __init__(self):
        super().__init__("OPENPAGERANK")

    async def query(self, domains: List[str]) -> str:
        params = {"domains[]": domains}
        response = await self._make_request(params=params)
        if response and not response.get("error"):
            results = response.get("response", [])
            if results:
                output = "OpenPageRank (Classement de domaine):\n"
                for res in results:
                    output += f"- Domaine: {res.get('domain', 'N/A')}, PageRank: {res.get('page_rank', 'N/A')}\n"
                return output
            return "OpenPageRank: Aucun résultat trouvé."
        return f"OpenPageRank: Erreur: {response.get('message', 'Inconnu')}" if response else "OpenPageRank: Réponse vide ou erreur interne."

class RapidAPIClient(APIClient):
    def __init__(self):
        super().__init__("RAPIDAPI")

    async def query(self, api_name: str, **kwargs) -> str:
        # RapidAPI is a marketplace, so we need to select the specific API endpoint
        # based on 'api_name' argument.
        selected_endpoint_config = None
        for config in self.endpoints_config:
            if api_name.lower() in config["endpoint_name"].lower():
                selected_endpoint_config = config
                break
        
        if not selected_endpoint_config:
            return f"RapidAPI: Endpoint pour '{api_name}' non trouvé ou non configuré."

        # Manually build request based on selected_endpoint_config
        url = selected_endpoint_config["url"]
        method = selected_endpoint_config["method"]
        
        request_params = selected_endpoint_config.get("fixed_params", {}).copy()
        request_headers = selected_endpoint_config.get("fixed_headers", {}).copy()
        request_json_data = selected_endpoint_config.get("fixed_json", {}).copy()

        # Add dynamic kwargs to params/json_data
        if method == "GET":
            request_params.update(kwargs)
        elif method == "POST":
            request_json_data.update(kwargs)

        headers = {
            selected_endpoint_config["key_field"]: selected_endpoint_config["key"],
            "X-RapidAPI-Host": selected_endpoint_config["fixed_headers"].get("X-RapidAPI-Host") # Specific to RapidAPI
        }
        
        response = await self._make_request(
            params=request_params,
            headers=headers,
            json_data=request_json_data,
            url=url,
            method=method
        )

        if response and not response.get("error"):
            if api_name.lower() == "programming joke":
                return f"RapidAPI (Blague de Programmation): {response.get('setup', '')} - {response.get('punchline', '')}"
            elif api_name.lower() == "currency list quotes":
                return f"RapidAPI (Devises): {json.dumps(response, indent=2)}"
            elif api_name.lower() == "random fact":
                return f"RapidAPI (Fait Aléatoire): {response.get('text', 'N/A')}"
            return f"RapidAPI ({api_name}): {json.dumps(response, indent=2)}"
        return f"RapidAPI ({api_name}): Erreur: {response.get('message', 'Inconnu')}" if response else "RapidAPI: Réponse vide ou erreur interne."

# --- Instancier tous les clients API ---
ALL_API_CLIENTS = [
    DeepSeekClient(),
    SerperClient(),
    WolframAlphaClient(),
    TavilyClient(),
    ApiFlashClient(),
    CrawlbaseClient(),
    DetectLanguageClient(),
    GuardianClient(),
    IP2LocationClient(),
    ShodanClient(),
    WeatherAPIClient(),
    CloudmersiveClient(),
    GreyNoiseClient(),
    PulsediveClient(),
    StormGlassClient(),
    LoginRadiusClient(),
    JsonbinClient(),
    HuggingFaceClient(),
    TwilioClient(),
    AbstractAPIClient(),
    GeminiAPIClient(),
    GoogleCustomSearchClient(),
    RandommerClient(),
    TomorrowIOClient(),
    OpenWeatherMapClient(),
    MockarooClient(),
    OpenPageRankClient(),
    RapidAPIClient()
]

# --- FIN DU BLOC CLIENTS API SPECIFIQUES---

# --- DEBUT DU BLOC GESTION MEMOIRE ET QUOTAS ---

class MemoryManager:
    def __init__(self):
        self.chat_history = load_json(HISTORY_FILE, [])
        self.long_term_memory = load_json(LONG_MEMORY_FILE, {})
        self.ia_status = load_json(IA_STATUS_FILE, {})
        self._initialize_ia_status()

    def _initialize_ia_status(self):
        """Initialise le statut des IA si elles ne sont pas déjà présentes ou si leur statut est obsolète."""
        now = get_current_time()
        updated = False
        for client in ALL_API_CLIENTS:
            if client.name not in self.ia_status:
                self.ia_status[client.name] = {
                    "last_used": None,
                    "last_error": None,
                    "error_count": 0,
                    "cooldown_until": None,
                    "success_count": 0,
                    "current_score": 1.0, # Maintenu pour la compatibilité, mais moins utilisé pour la sélection primaire
                    "last_rotation_check": format_datetime(now),
                    "diversification_score": 1.0 # Nouveau score pour la diversification
                }
                updated = True
            else:
                # S'assurer que les nouvelles clés existent pour les IA existantes
                default_ia_status_keys = {
                    "success_count": 0,
                    "current_score": 1.0,
                    "last_rotation_check": format_datetime(now),
                    "diversification_score": 1.0
                }
                for key, default_value in default_ia_status_keys.items():
                    if key not in self.ia_status[client.name]:
                        self.ia_status[client.name][key] = default_value
                        updated = True

        # Nettoyer les IA qui ne sont plus dans ALL_API_CLIENTS
        current_api_names = {client.name for client in ALL_API_CLIENTS}
        ia_names_to_remove = [name for name in self.ia_status if name not in current_api_names]
        for name in ia_names_to_remove:
            del self.ia_status[name]
            updated = True
            log_message(f"IA '{name}' trouvée dans ia_status.json mais non définie dans ALL_API_CLIENTS. Supprimée.", level="warning")


        if updated:
            save_json(IA_STATUS_FILE, self.ia_status)
            log_message("Statut des IA initialisé/mis à jour.")

    def add_message_to_history(self, role, content):
        """Ajoute un message à l'historique de la conversation."""
        self.chat_history.append({"role": role, "content": content, "timestamp": format_datetime(get_current_time())})
        self._prune_history()
        save_json(HISTORY_FILE, self.chat_history)
        log_message(f"Message ajouté à l'historique par {role}.")

    def get_chat_history(self, limit=10):
        """Retourne les N derniers messages de l'historique."""
        return self.chat_history[-limit:]

    def add_to_long_term_memory(self, key, value):
        """Ajoute une information à la mémoire à long terme."""
        self.long_term_memory[key] = {"value": value, "timestamp": format_datetime(get_current_time())}
        save_json(LONG_MEMORY_FILE, self.long_term_memory)
        log_message(f"Information ajoutée à la mémoire à long terme: {key}")

    def get_from_long_term_memory(self, key):
        """Récupère une information de la mémoire à long terme."""
        return self.long_term_memory.get(key)

    def update_ia_status(self, ia_name: str, success: bool, error_message: Optional[str] = None):
        """Met à jour le statut et le score d'une IA après une utilisation."""
        status = self.ia_status.get(ia_name)
        if not status:
            log_message(f"Tentative de mise à jour d'un statut d'IA inconnu: {ia_name}", level="warning")
            return

        now = get_current_time()
        status["last_used"] = format_datetime(now)

        if success:
            status["success_count"] += 1
            status["error_count"] = 0
            status["cooldown_until"] = None
            status["last_error"] = None
            status["current_score"] = min(1.0, status["current_score"] + 0.1)
            # Decrease diversification score on use
            status["diversification_score"] = max(0.1, status["diversification_score"] - 0.1)
            log_message(f"IA {ia_name} : Succès enregistré. Nouveau score: {status['current_score']:.2f}, Diversification: {status['diversification_score']:.2f}")
        else:
            status["error_count"] += 1
            status["last_error"] = error_message
            if status["error_count"] >= 3:
                status["cooldown_until"] = format_datetime(now + timedelta(seconds=API_COOLDOWN_DURATION_SECONDS))
                status["current_score"] = max(0.1, status["current_score"] - 0.2)
                log_message(f"IA {ia_name} : Trop d'erreurs ({status['error_count']}). Cooldown jusqu'à {status['cooldown_until']}. Nouveau score: {status['current_score']:.2f}", level="warning")
            else:
                 status["current_score"] = max(0.1, status["current_score"] - 0.05)
                 log_message(f"IA {ia_name} : Erreur enregistrée. Nouveau score: {status['current_score']:.2f}", level="warning")

        save_json(IA_STATUS_FILE, self.ia_status)

    def recover_diversification_scores(self):
        """Augmente le score de diversification pour les IA non utilisées récemment."""
        now = get_current_time()
        updated = False
        for ia_name, status in self.ia_status.items():
            last_used_str = status.get("last_used")
            if last_used_str:
                last_used_dt = datetime.strptime(last_used_str, "%Y-%m-%d %H:%M:%S UTC").replace(tzinfo=None)
                # If not used in the last API_ROTATION_INTERVAL_MINUTES * 2 (e.g., 60 mins), recover score
                if (now - last_used_dt).total_seconds() > API_ROTATION_INTERVAL_MINUTES * 60 * 2:
                    if status["diversification_score"] < 1.0:
                        status["diversification_score"] = min(1.0, status["diversification_score"] + 0.05)
                        updated = True
                        log_message(f"IA {ia_name}: Score de diversification récupéré à {status['diversification_score']:.2f}")
            else: # Never used, ensure it's at max
                if status["diversification_score"] < 1.0:
                    status["diversification_score"] = 1.0
                    updated = True
        if updated:
            save_json(IA_STATUS_FILE, self.ia_status)

    def get_ia_status(self, ia_name: str) -> Optional[Dict]:
        """Récupère le statut d'une IA."""
        return self.ia_status.get(ia_name)

    def get_available_ias(self) -> List[str]:
        """Retourne les noms des IA actuellement non en cooldown."""
        available = []
        now = get_current_time()
        for name, status in self.ia_status.items():
            cooldown_until_str = status.get("cooldown_until")
            if cooldown_until_str:
                cooldown_until = datetime.strptime(cooldown_until_str, "%Y-%m-%d %H:%M:%S UTC").replace(tzinfo=None)
                if now < cooldown_until:
                    continue
            available.append(name)
        return available

    def _prune_history(self, max_entries=50):
        """Supprime les anciennes entrées de l'historique si trop nombreuses."""
        if len(self.chat_history) > max_entries:
            self.chat_history = self.chat_history[-max_entries:]
            log_message(f"Historique de chat purgé, {len(self.chat_history)} entrées restantes.")

class QuotaManager:
    def __init__(self):
        self.quotas = load_json(QUOTAS_FILE, {})
        self._initialize_quotas()

    def _initialize_quotas(self):
        """Initialise les quotas pour toutes les APIs basées sur config.API_QUOTAS et nettoie/met à jour les existants."""
        updated = False
        now = get_current_time()

        # Step 1: Ensure all APIs from API_QUOTAS are in self.quotas with full structure
        for api_name, quota_info in API_QUOTAS.items():
            if api_name not in self.quotas:
                self.quotas[api_name] = {
                    "monthly_usage": 0,
                    "daily_usage": 0,
                    "hourly_usage": 0,
                    "hourly_timestamps": [],
                    "last_reset_month": now.month,
                    "last_reset_day": now.day,
                    "last_usage": None,
                    "total_calls": 0,
                    "last_hourly_reset": format_datetime(now)
                }
                updated = True
            else:
                # Ensure existing entries have all required keys
                default_quota_structure = {
                    "monthly_usage": 0,
                    "daily_usage": 0,
                    "hourly_usage": 0,
                    "hourly_timestamps": [],
                    "last_reset_month": now.month,
                    "last_reset_day": now.day,
                    "last_usage": None,
                    "total_calls": 0,
                    "last_hourly_reset": format_datetime(now)
                }
                for key, default_value in default_quota_structure.items():
                    if key not in self.quotas[api_name]:
                        self.quotas[api_name][key] = default_value
                        updated = True
                
                # Re-evaluate hourly_usage based on timestamps during initialization
                one_hour_ago = now - timedelta(hours=1)
                # Ensure hourly_timestamps is a list before filtering
                if not isinstance(self.quotas[api_name].get("hourly_timestamps"), list):
                    self.quotas[api_name]["hourly_timestamps"] = []
                    updated = True

                self.quotas[api_name]["hourly_timestamps"] = [
                    ts for ts in self.quotas[api_name]["hourly_timestamps"]
                    if datetime.strptime(ts, "%Y-%m-%d %H:%M:%S UTC").replace(tzinfo=None) > one_hour_ago
                ]
                self.quotas[api_name]["hourly_usage"] = len(self.quotas[api_name]["hourly_timestamps"])
                self.quotas[api_name]["last_hourly_reset"] = format_datetime(now) # Update reset time

        # Step 2: Remove any API names from self.quotas that are NOT in API_QUOTAS
        # This handles cases where invalid API names might have been added previously
        api_names_to_remove = [name for name in self.quotas if name not in API_QUOTAS]
        for name in api_names_to_remove:
            del self.quotas[name]
            updated = True
            log_message(f"API '{name}' trouvée dans quotas.json mais non définie dans API_QUOTAS. Supprimée.", level="warning")

        if updated:
            save_json(QUOTAS_FILE, self.quotas)
            log_message("Quotas API initialisés/mis à jour.")

    def _reset_quotas_if_needed(self):
        """Réinitialise les quotas journaliers, mensuels et horaires si nécessaire."""
        now = get_current_time()
        for api_name, data in self.quotas.items():
            # Reset mensuel
            if now.month != data["last_reset_month"]:
                data["monthly_usage"] = 0
                data["last_reset_month"] = now.month
                log_message(f"Quota mensuel pour {api_name} réinitialisé.")
            # Reset journalier
            if now.day != data["last_reset_day"]:
                data["daily_usage"] = 0
                data["last_reset_day"] = now.day
                log_message(f"Quota journalier pour {api_name} réinitialisé.")
            
            # Reset et gestion horaire (nettoyage des timestamps trop anciens)
            one_hour_ago = now - timedelta(hours=1)
            # Ensure hourly_timestamps is a list before filtering
            if not isinstance(data.get("hourly_timestamps"), list):
                data["hourly_timestamps"] = []
            
            data["hourly_timestamps"] = [
                ts for ts in data["hourly_timestamps"]
                if datetime.strptime(ts, "%Y-%m-%d %H:%M:%S UTC").replace(tzinfo=None) > one_hour_ago
            ]
            data["hourly_usage"] = len(data["hourly_timestamps"])
            
            # Update last_hourly_reset to current time if a reset happened or after cleanup
            data["last_hourly_reset"] = format_datetime(now)

        save_json(QUOTAS_FILE, self.quotas)

    def check_and_update_quota(self, api_name: str, cost: int = 1) -> bool:
        """Vérifie si une API a du quota et le décrémente. Retourne True si ok, False sinon."""
        self._reset_quotas_if_needed()
        
        # IMPORTANT: Only process if api_name is a valid, configured API
        if api_name not in API_QUOTAS:
            log_message(f"Tentative de vérification de quota pour une API non définie: {api_name}. Autorisation refusée.", level="error")
            return False # Prevent processing for undefined APIs

        if api_name not in self.quotas:
            # This case should ideally not happen after robust initialization, but as a fallback
            log_message(f"API {api_name} non trouvée dans les quotas gérés. Re-initialisation.", level="warning")
            self._initialize_quotas() # Re-initialize to ensure it's added
            if api_name not in self.quotas: # If still not there after re-init, something is fundamentally wrong
                log_message(f"API {api_name} toujours introuvable après re-initialisation. Autorisation refusée.", level="error")
                return False


        quota_data = self.quotas[api_name]
        api_limits = API_QUOTAS.get(api_name, {})
        now = get_current_time()

        monthly_limit = api_limits.get("monthly")
        if monthly_limit is not None and (quota_data["monthly_usage"] + cost) > monthly_limit:
            log_message(f"Quota mensuel dépassé pour {api_name}", level="warning")
            return False

        daily_limit = api_limits.get("daily")
        if daily_limit is not None and (quota_data["daily_usage"] + cost) > daily_limit:
            log_message(f"Quota journalier dépassé pour {api_name}", level="warning")
            return False
        
        hourly_limit = api_limits.get("hourly")
        if hourly_limit is not None and (quota_data["hourly_usage"] + cost) > hourly_limit:
            log_message(f"Quota horaire dépassé pour {api_name}", level="warning")
            return False

        rate_limit_per_sec = api_limits.get("rate_limit_per_sec")
        if rate_limit_per_sec:
            last_usage_str = quota_data.get("last_usage")
            if last_usage_str:
                last_usage = datetime.strptime(last_usage_str, "%Y-%m-%d %H:%M:%S UTC").replace(tzinfo=None)
                time_since_last_call = (now - last_usage).total_seconds()
                if time_since_last_call < (1 / rate_limit_per_sec):
                    log_message(f"Taux de requêtes dépassé pour {api_name}. Attendre {1/rate_limit_per_sec - time_since_last_call:.2f}s", level="warning")
                    return False

        # Only update usage if cost is greater than 0. This prevents quota consumption during check-only calls.
        if cost > 0:
            quota_data["monthly_usage"] += cost
            quota_data["daily_usage"] += cost
            quota_data["hourly_usage"] += cost
            quota_data["hourly_timestamps"].append(format_datetime(now)) # Add current timestamp
            quota_data["total_calls"] += cost
            quota_data["last_usage"] = format_datetime(now)
            save_json(QUOTAS_FILE, self.quotas)
            log_message(f"Quota pour {api_name} mis à jour. Usage mensuel: {quota_data['monthly_usage']}/{monthly_limit if monthly_limit else 'Illimité'}, Journalier: {quota_data['daily_usage']}/{daily_limit if daily_limit else 'Illimité'}, Horaire: {quota_data['hourly_usage']}/{hourly_limit if hourly_limit else 'Illimité'}")
        else:
            log_message(f"Quota pour {api_name} vérifié (coût 0). Usage mensuel: {quota_data['monthly_usage']}/{monthly_limit if monthly_limit else 'Illimité'}, Journalier: {quota_data['daily_usage']}/{daily_limit if daily_limit else 'Illimité'}, Horaire: {quota_data['hourly_usage']}/{hourly_limit if hourly_limit else 'Illimité'}")

        return True

    def get_api_usage(self, api_name: str) -> Optional[Dict]:
        """Retourne les informations d'utilisation d'une API."""
        return self.quotas.get(api_name)

    def get_all_quotas_status(self) -> Dict:
        """Retourne le statut de tous les quotas."""
        self._reset_quotas_if_needed()
        status = {}
        for api_name, quota_data in self.quotas.items():
            api_limits = API_QUOTAS.get(api_name, {})
            monthly_limit = api_limits.get("monthly", "Illimité")
            daily_limit = api_limits.get("daily", "Illimité")
            hourly_limit = api_limits.get("hourly", "Illimité")
            status[api_name] = {
                "monthly_usage": quota_data["monthly_usage"],
                "monthly_limit": monthly_limit,
                "daily_usage": quota_data["daily_usage"],
                "daily_limit": daily_limit,
                "hourly_usage": quota_data["hourly_usage"],
                "hourly_limit": hourly_limit,
                "total_calls": quota_data["total_calls"],
                "last_usage": quota_data["last_usage"],
                "last_reset_month": quota_data["last_reset_month"],
                "last_reset_day": quota_data["last_reset_day"],
                "last_hourly_reset": quota_data["last_hourly_reset"]
            }
        return status

    def get_burn_window_apis(self) -> List[str]:
        """
        Identifie les APIs dont les quotas sont sur le point d'être réinitialisés
        et où il est opportun de "brûler" le quota restant.
        """
        burn_apis = []
        now = get_current_time()
        for api_name, data in self.quotas.items():
            api_limits = API_QUOTAS.get(api_name, {})

            if api_limits.get("monthly") is not None:
                next_month_reset = datetime(now.year + (1 if now.month == 12 else 0), (now.month % 12) + 1, 1).replace(tzinfo=None)
                if is_within_time_window(next_month_reset, QUOTA_BURN_WINDOW_HOURS * 60, 0):
                    if data["monthly_usage"] < api_limits["monthly"]:
                        burn_apis.append(f"{api_name} (mensuel: {api_limits['monthly'] - data['monthly_usage']} restants)")

            if api_limits.get("daily") is not None:
                next_day_reset = datetime(now.year, now.month, now.day).replace(tzinfo=None) + timedelta(days=1)
                if is_within_time_window(next_day_reset, QUOTA_BURN_WINDOW_HOURS * 60, 0):
                    if data["daily_usage"] < api_limits["daily"]:
                        burn_apis.append(f"{api_name} (journalier: {api_limits['daily'] - data['daily_usage']} restants)")
        return burn_apis

# Instanciation des gestionnaires
memory_manager = MemoryManager()
quota_manager = QuotaManager()

import time
from telegram import Update, ForceReply
from telegram.ext import Application, CommandHandler, MessageHandler, filters, ContextTypes

# --- Orchestration des IA ---
class IAOrchestrator:
    def __init__(self, memory_manager: MemoryManager, quota_manager: QuotaManager, api_clients: List[APIClient]):
        self.memory_manager = memory_manager
        self.quota_manager = quota_manager
        self.api_clients = {client.name: client for client in api_clients}
        self.last_strategy_rotation_time = get_current_time()
        self.current_ia_strategy = self._determine_initial_strategy()

        # Les cinq moteurs IA principaux
        self.core_ai_engines = {
            "DEEPSEEK": self.api_clients.get("DEEPSEEK"),
            "HUGGINGFACE": self.api_clients.get("HUGGINGFACE"),
            "GOOGLE_CUSTOM_SEARCH": self.api_clients.get("GOOGLE_CUSTOM_SEARCH"),
            "GEMINI_API": self.api_clients.get("GEMINI_API")
        }
        # Filtrer les clients None si l'API n'est pas configurée
        self.core_ai_engines = {k: v for k, v in self.core_ai_engines.items() if v is not None}

        # Définir les "agents mixtes" et leurs capacités (simplified for example)
        # En réalité, ceci serait un système de routing basé sur des modèles NLP plus complexes.
        self.mixed_agents = [
            {"name": "GeneralQueryAgent", "primary_ais": ["DEEPSEEK", "GEMINI_API", "GOOGLE_CUSTOM_SEARCH"], "tools": ["SERPER", "TAVILY", "WOLFRAMALPHA", "WEATHERAPI", "OPENWEATHERMAP"]},
            {"name": "CodingAgent", "primary_ais": ["DEEPSEEK", "HUGGINGFACE", "GEMINI_API"], "tools": []}, # Tools are sandbox/analyzer
            {"name": "SecurityAgent", "primary_ais": ["DEEPSEEK", "GEMINI_API"], "tools": ["IP2LOCATION", "SHODAN", "GREYNOISE", "PULSEDIVE", "CLOUDMERSIVE"]},
            {"name": "DataAgent", "primary_ais": ["DEEPSEEK", "GEMINI_API"], "tools": ["JSONBIN", "MOCKAROO", "RANDOMMER", "OPENPAGERANK", "RAPIDAPI"]},
            {"name": "CommunicationAgent", "primary_ais": ["DEEPSEEK", "GEMINI_API"], "tools": ["TWILIO", "ABSTRACTAPI"]},
            {"name": "NewsAgent", "primary_ais": ["DEEPSEEK", "GEMINI_API"], "tools": ["GUARDIAN", "SERPER", "TAVILY"]},
            {"name": "ImageAgent", "primary_ais": ["DEEPSEEK", "GEMINI_API"], "tools": ["APIFLASH"]}, # OCR tool is separate
            {"name": "LanguageAgent", "primary_ais": ["DEEPSEEK", "GEMINI_API"], "tools": ["DETECTLANGUAGE"]},
            {"name": "WeatherAgent", "primary_ais": ["DEEPSEEK", "GEMINI_API"], "tools": ["WEATHERAPI", "STORMGLASS", "TOMORROW.IO", "OPENWEATHERMAP"]}
        ]
        self.current_agent_index = 0
        self.last_agent_rotation_time = get_current_time()

        # Tool descriptions for AI
        self.tool_descriptions = {
            "SERPER": "Effectue une recherche web sur Google et retourne les snippets et liens pertinents. Paramètres: {\"query\": \"texte de recherche\"}",
            "TAVILY": "Effectue une recherche web avancée et retourne une réponse directe et des extraits. Paramètres: {\"query\": \"texte de recherche\", \"max_results\": nombre}",
            "WOLFRAMALPHA": "Répond à des questions factuelles et calculs complexes. Paramètres: {\"input\": \"question ou calcul\"}",
            "WEATHERAPI": "Fournit la météo actuelle et les prévisions pour une localisation donnée. Paramètres: {\"location\": \"nom de la ville ou code postal\"}",
            "OPENWEATHERMAP": "Fournit la météo actuelle pour une localisation donnée. Paramètres: {\"location\": \"nom de la ville ou code postal\"}",
            "STORMGLASS": "Fournit des données météorologiques maritimes (température, vagues) pour des coordonnées lat/lng. Paramètres: {\"lat\": latitude, \"lng\": longitude, \"params\": \"airTemperature,waveHeight\"}",
            "APIFLASH": "Prend une capture d'écran d'une URL et retourne l'URL de l'image. Paramètres: {\"url\": \"URL du site\"}",
            "CRAWLBASE": "Récupère le contenu HTML ou JavaScript d'une URL. Paramètres: {\"url\": \"URL du site\", \"use_js\": true/false}",
            "DETECTLANGUAGE": "Détecte la langue d'un texte. Paramètres: {\"text\": \"texte à analyser\"}",
            "IP2LOCATION": "Géolocalise une adresse IP. Paramètres: {\"ip_address\": \"adresse IP\"}",
            "SHODAN": "Fournit des informations sur les hôtes et les services exposés sur Internet. Paramètres: {\"query\": \"texte de recherche\"} (optionnel)",
            "GREYNOISE": "Analyse une adresse IP pour déterminer si elle est 'bruit' (malveillante). Paramètres: {\"ip_address\": \"adresse IP\"}",
            "PULSEDIVE": "Analyse des indicateurs de menace (IP, domaine, URL). Paramètres: {\"indicator\": \"indicateur\", \"type\": \"auto\"}",
            "CLOUDMERSIVE": "Vérifie la validité d'un nom de domaine. Paramètres: {\"domain\": \"nom de domaine\"}",
            "JSONBIN": "Stocke ou récupère des données JSON dans un 'bin' privé ou public. Pour créer: {\"data\": {\"clé\": \"valeur\"}, \"private\": true/false}. Pour accéder: {\"bin_id\": \"ID du bin\"}",
            "MOCKAROO": "Génère des données de test aléatoires basées sur des schémas. Paramètres: {\"count\": nombre, \"fields_json\": \"[{\"name\": \"champ\", \"type\": \"Type Mockaroo\"}]\"}",
            "RANDOMMER": "Génère des données aléatoires, comme des numéros de téléphone. Paramètres: {\"country_code\": \"US\", \"quantity\": 1}",
            "OPENPAGERANK": "Récupère le PageRank d'un ou plusieurs domaines. Paramètres: {\"domains\": [\"domaine1.com\", \"domaine2.com\"]}",
            "RAPIDAPI": "Accède à diverses micro-APIs (blagues, faits, devises). Nécessite un 'api_name' (ex: 'Programming Joke'). Paramètres: {\"api_name\": \"Nom de l'API\", \"kwargs\": {\"param1\": \"valeur1\"}}",
            "TWILIO": "Vérifie le solde du compte Twilio. Paramètres: Aucun",
            "ABSTRACTAPI": "Valide des emails, numéros de téléphone, géolocalise des IPs, ou fournit des taux de change/jours fériés. Paramètres: {\"input_value\": \"valeur\", \"api_type\": \"EMAIL_VALIDATION\"|\"PHONE_VALIDATION\"|\"EXCHANGE_RATES\"|\"HOLIDAYS\"}"
        }

    def _determine_initial_strategy(self) -> str:
        """Détermine la stratégie initiale ou la stratégie par défaut."""
        return "balanced"

    def _rotate_strategy_if_needed(self):
        """Change la stratégie d'IA et l'agent si l'intervalle de rotation est passé."""
        now = get_current_time()
        if (now - self.last_strategy_rotation_time).total_seconds() >= API_ROTATION_INTERVAL_MINUTES * 60:
            strategies = ["balanced", "cost_effective", "performance"]
            self.current_ia_strategy = random.choice(strategies)
            self.last_strategy_rotation_time = now
            log_message(f"Stratégie d'IA changée pour: {self.current_ia_strategy}")

            # Rotation des agents mixtes
            self.current_agent_index = (self.current_agent_index + 1) % len(self.mixed_agents)
            self.last_agent_rotation_time = now
            log_message(f"Agent mixte actuel: {self.mixed_agents[self.current_agent_index]['name']}")

            # Mettre à jour le last_rotation_check pour toutes les IA et récupérer les scores de diversification
            for ia_name in self.memory_manager.ia_status:
                self.memory_manager.ia_status[ia_name]["last_rotation_check"] = format_datetime(now)
            self.memory_manager.recover_diversification_scores() # Recover diversification scores
            save_json(IA_STATUS_FILE, self.memory_manager.ia_status)

    async def _select_primary_ai_for_agent(self, agent_config: Dict) -> Optional[APIClient]:
        """
        Sélectionne une IA primaire parmi celles de l'agent.
        La sélection est désormais équitable, sans privilégier une IA par rapport à une autre en fonction des scores.
        """
        available_primary_ais = []
        for ai_name in agent_config["primary_ais"]:
            if ai_name in self.core_ai_engines:
                status = self.memory_manager.get_ia_status(ai_name)
                # Vérifier si l'IA n'est pas en cooldown
                if status and (status.get("cooldown_until") is None or datetime.strptime(status["cooldown_until"], "%Y-%m-%d %H:%M:%S UTC").replace(tzinfo=None) < get_current_time()):
                    # Vérifier le quota sans le consommer pour la sélection
                    # Utiliser cost=0 pour juste vérifier la disponibilité sans impacter le quota
                    if self.quota_manager.check_and_update_quota(ai_name, cost=0):
                        available_primary_ais.append(ai_name)
        
        if not available_primary_ais:
            log_message(f"Aucune IA primaire disponible pour l'agent {agent_config['name']}.", level="warning")
            return None

        # Sélection aléatoire et équitable parmi les IA disponibles
        selected_ai_name = random.choice(available_primary_ais)
        
        # Consommer le quota pour l'IA sélectionnée (coût réel de 1)
        if self.quota_manager.check_and_update_quota(selected_ai_name, cost=1):
            log_message(f"IA primaire sélectionnée pour l'agent: {selected_ai_name} (Sélection équitable)")
            return self.core_ai_engines[selected_ai_name]
        
        # Ce cas ne devrait pas arriver souvent si le check_and_update_quota(cost=0) a réussi
        # mais c'est une sécurité.
        log_message(f"IA {selected_ai_name} sélectionnée mais quota non disponible au moment de la consommation.", level="warning")
        return None


    async def _run_agent_with_tools(self, agent_config: Dict, query: str) -> (str, List[Dict]):
        """
        Exécute l'agent mixte en utilisant l'IA primaire sélectionnée
        et en sollicitant les outils pertinents.
        Retourne la réponse brute de l'agent et une liste des outils appelés pour le rapport.
        """
        primary_ai_client = await self._select_primary_ai_for_agent(agent_config)
        if not primary_ai_client:
            return f"Désolé, l'agent {agent_config['name']} ne peut pas opérer car aucune IA primaire n'est disponible.", []

        responses = []
        tools_called_for_report = []
        
        # Prepare tool descriptions for the AI
        available_tools_for_ai = {}
        for tool_name in agent_config.get("tools", []):
            if tool_name in self.tool_descriptions and self.api_clients.get(tool_name):
                available_tools_for_ai[tool_name] = self.tool_descriptions[tool_name]
        
        tool_prompt_part = ""
        if available_tools_for_ai:
            tool_prompt_part = "\n\nTu as accès aux outils suivants:\n"
            for tool_name, desc in available_tools_for_ai.items():
                tool_prompt_part += f"- **{tool_name}**: {desc}\n"
            tool_prompt_part += "\nSi tu as besoin d'utiliser un outil, réponds avec le format suivant: `TOOL_CALL:<nom_outil>:<paramètres_json>`. Par exemple: `TOOL_CALL:WEATHERAPI:{\"location\": \"Paris\"}`. Sinon, réponds normalement."
        
        full_prompt_for_ai = f"{query}{tool_prompt_part}"

        # 1. Obtenir une première réponse de l'IA primaire
        log_message(f"Agent {agent_config['name']} utilise {primary_ai_client.name} pour la requête: '{query}'")
        primary_response_raw = await primary_ai_client.query(full_prompt_for_ai)
        self.memory_manager.update_ia_status(primary_ai_client.name, not primary_response_raw.startswith("Erreur"))
        
        # Check for tool calls in the primary AI's response
        tool_call_match = re.match(r"TOOL_CALL:([A-Z_]+):(.+)", primary_response_raw)
        if tool_call_match:
            tool_name = tool_call_match.group(1)
            params_str = tool_call_match.group(2)
            
            try:
                tool_params = json.loads(params_str)
                tool_client = self.api_clients.get(tool_name)
                
                if tool_client and self.quota_manager.check_and_update_quota(tool_name):
                    log_message(f"Agent {agent_config['name']} exécute l'outil {tool_name} avec les paramètres: {tool_params}")
                    
                    tool_response = ""
                    # Dynamic tool call based on tool_name and parsed params
                    # This requires careful mapping of tool_params to actual method arguments
                    if tool_name == "SERPER":
                        tool_response = await tool_client.query(query_text=tool_params.get("query"))
                    elif tool_name == "TAVILY":
                        tool_response = await tool_client.query(query_text=tool_params.get("query"), max_results=tool_params.get("max_results", 3))
                    elif tool_name == "WOLFRAMALPHA":
                        tool_response = await tool_client.query(input_text=tool_params.get("input"))
                    elif tool_name == "WEATHERAPI":
                        tool_response = await tool_client.query(location=tool_params.get("location"))
                    elif tool_name == "OPENWEATHERMAP":
                        tool_response = await tool_client.query(location=tool_params.get("location"))
                    elif tool_name == "STORMGLASS":
                        tool_response = await tool_client.query(lat=tool_params.get("lat"), lng=tool_params.get("lng"), params=tool_params.get("params", "airTemperature,waveHeight"))
                    elif tool_name == "APIFLASH":
                        tool_response = await tool_client.query(url=tool_params.get("url"))
                    elif tool_name == "CRAWLBASE":
                        tool_response = await tool_client.query(url=tool_params.get("url"), use_js=tool_params.get("use_js", False))
                    elif tool_name == "DETECTLANGUAGE":
                        tool_response = await tool_client.query(text=tool_params.get("text"))
                    elif tool_name == "IP2LOCATION":
                        tool_response = await tool_client.query(ip_address=tool_params.get("ip_address"))
                    elif tool_name == "SHODAN":
                        tool_response = await tool_client.query(query_text=tool_params.get("query", ""))
                    elif tool_name == "GREYNOISE":
                        tool_response = await tool_client.query(ip_address=tool_params.get("ip_address"))
                    elif tool_name == "PULSEDIVE":
                        tool_response = await tool_client.query(indicator=tool_params.get("indicator"), type=tool_params.get("type", "auto"))
                    elif tool_name == "CLOUDMERSIVE":
                        tool_response = await tool_client.query(domain=tool_params.get("domain"))
                    elif tool_name == "JSONBIN":
                        if "bin_id" in tool_params:
                            tool_response = await tool_client.query(bin_id=tool_params["bin_id"])
                        else:
                            tool_response = await tool_client.query(data=tool_params.get("data", {}), private=tool_params.get("private", True))
                    elif tool_name == "MOCKAROO":
                        tool_response = await tool_client.query(count=tool_params.get("count", 1), fields_json=tool_params.get("fields_json"))
                    elif tool_name == "RANDOMMER":
                        tool_response = await tool_client.query(country_code=tool_params.get("country_code", "US"), quantity=tool_params.get("quantity", 1))
                    elif tool_name == "OPENPAGERANK":
                        tool_response = await tool_client.query(domains=tool_params.get("domains", []))
                    elif tool_name == "RAPIDAPI":
                        tool_response = await tool_client.query(api_name=tool_params.get("api_name"), **tool_params.get("kwargs", {}))
                    elif tool_name == "TWILIO":
                        tool_response = await tool_client.query()
                    elif tool_name == "ABSTRACTAPI":
                        tool_response = await tool_client.query(input_value=tool_params.get("input_value"), api_type=tool_params.get("api_type"))
                    elif tool_name == "TOMORROW.IO":
                        tool_response = await tool_client.query(location=tool_params.get("location"), fields=tool_params.get("fields"))
                    
                    if tool_response:
                        responses.append(f"Réponse outil ({tool_name}): {tool_response}")
                        tools_called_for_report.append({"name": tool_name, "params": tool_params, "result": tool_response})
                    self.memory_manager.update_ia_status(tool_name, not tool_response.startswith("Erreur"))
                    
                    # Feed tool response back to primary AI for final answer
                    follow_up_prompt = f"J'ai exécuté l'outil {tool_name} avec les paramètres {params_str}. Voici le résultat:\n{tool_response}\n\nMaintenant, réponds à la question originale: {query}"
                    final_ai_response = await primary_ai_client.query(follow_up_prompt)
                    self.memory_manager.update_ia_status(primary_ai_client.name, not final_ai_response.startswith("Erreur"))
                    responses.append(f"Réponse finale ({primary_ai_client.name}): {final_ai_response}")

                else:
                    responses.append(f"Erreur: L'outil {tool_name} n'est pas disponible ou le quota est dépassé.")
                    tools_called_for_report.append({"name": tool_name, "params": tool_params, "result": "Quota dépassé ou non disponible."})
            except json.JSONDecodeError:
                responses.append(f"Erreur: Paramètres JSON invalides pour l'outil {tool_name}: {params_str}")
                tools_called_for_report.append({"name": tool_name, "params": params_str, "result": "JSON invalide."})
            except Exception as e:
                responses.append(f"Erreur lors de l'exécution de l'outil {tool_name}: {e}")
                self.memory_manager.update_ia_status(tool_name, False, str(e))
                tools_called_for_report.append({"name": tool_name, "params": params_str, "result": f"Erreur: {e}"})
        else:
            # If no tool call, the primary AI's initial response is the main response
            responses.append(f"Réponse principale ({primary_ai_client.name}): {primary_response_raw}")
        
        return "\n\n".join(responses), tools_called_for_report


    async def process_query(self, query: str) -> (str, List[Dict]):
        """Traite une requête en sélectionnant un agent mixte et en obtenant une réponse."""
        self._rotate_strategy_if_needed() # Rotation de la stratégie et de l'agent

        # Sélectionner l'agent mixte actuel
        current_agent_config = self.mixed_agents[self.current_agent_index]
        log_message(f"Traitement de la requête avec l'agent: {current_agent_config['name']}")

        # Exécuter l'agent avec ses outils
        agent_raw_response, tools_called_for_report = await self._run_agent_with_tools(current_agent_config, query)
        
        # Synthèse Optimisée des Réponses
        # Vérifier si la réponse est simple ou si elle contient des marqueurs de multiples réponses/outils
        # A simple heuristic: if it contains "Réponse principale (" and not "Réponse outil ("
        # and there are no tools called, then it's likely a single, direct response.
        if "Réponse principale (" in agent_raw_response and not tools_called_for_report:
            log_message("Réponse unique et directe détectée, pas de synthèse nécessaire.")
            final_response = agent_raw_response.replace(f"Réponse principale ({primary_ai_client.name}): ", "") # Remove prefix
        else:
            log_message("Plusieurs réponses ou outils détectés, appel à la synthèse.")
            final_response = await self.synthesize_response(query, [agent_raw_response])

        return final_response, tools_called_for_report

    async def synthesize_response(self, question: str, responses: List[str]) -> str:
        """
        Synthétise les réponses de plusieurs IA en utilisant DeepSeek (le module d'optimisation).
        """
        if not responses:
            return "Je n'ai reçu aucune réponse des IA pour le moment."

        combined_responses = "\n\n".join([f"Réponse {i+1}:\n{r}" for i, r in enumerate(responses)])
        synthesis_prompt = SYNTHESIS_PROMPT_TEMPLATE.format(question=question, responses=combined_responses)

        deepseek_client = self.core_ai_engines.get("DEEPSEEK")
        if not deepseek_client:
            log_message("DeepSeek n'est pas disponible pour la synthèse.", level="warning")
            return "J'ai plusieurs réponses, mais je ne peux pas les synthétiser pour le moment. Voici les réponses brutes:\n\n" + combined_responses

        try:
            synthesis = await deepseek_client.query(synthesis_prompt)
            self.memory_manager.update_ia_status("DEEPSEEK", True) # Update DeepSeek status for synthesis
            return detect_and_correct_toxicity(synthesis)
        except Exception as e:
            log_message(f"Erreur lors de la synthèse avec DeepSeek: {e}", level="error")
            self.memory_manager.update_ia_status("DEEPSEEK", False, str(e))
            return "J'ai rencontré un problème lors de la synthèse des informations. Voici les réponses brutes:\n\n" + combined_responses

# Instancier l'orchestrateur
orchestrator = IAOrchestrator(memory_manager, quota_manager, ALL_API_CLIENTS)

# --- Tâche de fond pour les Health Checks des Endpoints (Wrapper pour JobQueue) ---
async def periodic_health_check_job(context: ContextTypes.DEFAULT_TYPE) -> None:
    """JobQueue wrapper pour les health checks périodiques."""
    log_message("Lancement des health checks périodiques via JobQueue pour tous les services...")
    for service_name in API_CONFIG.keys():
        await endpoint_health_manager.run_health_check_for_service(service_name)
    log_message("Health checks périodiques via JobQueue terminés.")

# --- Structured Reporting to Private Group ---
async def send_structured_report_to_private_group(context: ContextTypes.DEFAULT_TYPE, report_data: Dict) -> None:
    """Envoie un rapport structuré au groupe privé Telegram."""
    try:
        report_text = f"📊 **Rapport d'Action IA**\n\n"
        report_text += f"**Timestamp**: `{report_data.get('timestamp')}`\n"
        report_text += f"**Agent**: `{report_data.get('agent_name')}`\n"
        report_text += f"**Intention Détectée**: `{report_data.get('intention')}`\n"
        report_text += f"**Requête Utilisateur**: `{report_data.get('user_query')}`\n"
        
        # S'assurer que primary_ai_used est toujours une chaîne valide
        primary_ai_used_display = report_data.get('primary_ai_used', 'N/A')
        if isinstance(primary_ai_used_display, dict) and 'name' in primary_ai_used_display:
            primary_ai_used_display = primary_ai_used_display['name']
        report_text += f"**IA Primaire Utilisée**: `{primary_ai_used_display}`\n"
        
        tools_called = report_data.get('tools_called', [])
        if tools_called:
            report_text += "**Outils Appelés**:\n"
            for tool in tools_called:
                # Truncate tool result for report to avoid very long messages
                tool_result_display = str(tool['result'])
                if len(tool_result_display) > 100:
                    tool_result_display = tool_result_display[:100] + "..."
                report_text += f"- `{tool['name']}` (Params: `{tool['params']}`, Résultat: `{tool_result_display}`)\n"
        else:
            report_text += "**Outils Appelés**: Aucun\n"
        
        # Truncate final response for report
        final_response_display = report_data.get('final_response', '')
        if len(final_response_display) > 500:
            final_response_display = final_response_display[:500] + "..."
        report_text += f"**Réponse Finale**: `{final_response_display}`\n"
        report_text += f"**Durée Totale**: `{report_data.get('duration'):.2f}s`\n"
        report_text += f"**Erreur**: `{report_data.get('error', 'Non')}`\n"

        await context.bot.send_message(chat_id=PRIVATE_GROUP_ID, text=report_text, parse_mode='Markdown')
        log_message(f"Rapport structuré envoyé au groupe privé: {PRIVATE_GROUP_ID}")
    except Exception as e:
        log_message(f"Erreur lors de l'envoi du rapport structuré au groupe privé: {e}", level="error")

import time
from telegram import Update, ForceReply
from telegram.ext import Application, CommandHandler, MessageHandler, filters, ContextTypes

# --- Handlers de commandes Telegram ---

async def start(update: Update, context: ContextTypes.DEFAULT_TYPE) -> None:
    """Envoie un message lorsque la commande /start est émise."""
    user = update.effective_user
    await update.message.reply_html(
        f"Salut {user.mention_html()} ! Je suis ton assistant IA de 2025. "
        "Pose-moi une question, demande-moi d'écrire du code, ou de chercher des infos. "
        "Utilise /help pour voir ce que je peux faire.",
        reply_markup=ForceReply(selective=True),
    )
    log_message(f"Commande /start reçue de {user.id}")

async def help_command(update: Update, context: ContextTypes.DEFAULT_TYPE) -> None:
    """Envoie un message lorsque la commande /help est émise."""
    help_text = """
    Voici ce que je peux faire :
    - Pose-moi n'importe quelle question factuelle.
    - Demande-moi d'écrire ou d'améliorer du code (Python, Shell).
    - Cherche des informations sur le web (actualités, météo, géolocalisation IP, etc.).
    - Demande-moi de faire une capture d'écran d'un site web (donne l'URL).
    - Demande-moi d'analyser le contenu d'une page web (donne l'URL).
    - Demande-moi de détecter la langue d'un texte.
    - Demande-moi de valider un numéro de téléphone ou de géolocaliser une IP ou un email.
    - Gère tes rappels et alarmes (Ex: "Rappelle-moi d'acheter du lait à 18h", "Mets une alarme à 7h du matin").
    - Vérifie le statut de mes APIs avec /status.
    - Affiche mon historique de conversation avec /history.
    - Affiche le statut des quotas API avec /quotas.
    - Affiche les APIs où il est opportun de "brûler" le quota avec /burn_quota.

    Exemples :
    - "Quelle est la capitale de la France ?"
    - "Écris un script Python pour trier une liste."
    - "Météo à Paris"
    - "Capture d'écran de https://google.com"
    - "Analyse de https://openai.com"
    - "Détecte la langue de 'Hello world'"
    - "Valide le numéro +33612345678"
    - "Géolocalise l'IP 8.8.8.8"
    - "Valide l'email test@example.com"
    - "Rappelle-moi de faire les courses demain à 10h"
    - "Mets une alarme pour 7h du matin"
    """
    await update.message.reply_text(help_text)
    log_message(f"Commande /help reçue de {update.effective_user.id}")

async def status_command(update: Update, context: ContextTypes.DEFAULT_TYPE) -> None:
    """Affiche le statut et les scores des IA."""
    status_message = "📊 **Statut des IA**:\n"
    now = get_current_time()
    for ia_name, status in memory_manager.ia_status.items():
        cooldown_until_str = status.get("cooldown_until")
        cooldown_status = "Prête"
        if cooldown_until_str:
            cooldown_until = datetime.strptime(cooldown_until_str, "%Y-%m-%d %H:%M:%S UTC").replace(tzinfo=None)
            if now < cooldown_until:
                remaining = cooldown_until - now
                cooldown_status = f"Cooldown ({remaining.total_seconds():.0f}s restantes)"
        
        last_used_str = status.get("last_used", "Jamais")
        if last_used_str != "Jamais":
            last_used_dt = datetime.strptime(last_used_str, "%Y-%m-%d %H:%M:%S UTC").replace(tzinfo=None)
            time_since_last_used = (now - last_used_dt).total_seconds()
            if time_since_last_used < 60:
                last_used_display = f"{time_since_last_used:.0f}s ago"
            elif time_since_last_used < 3600:
                last_used_display = f"{time_since_last_used / 60:.0f}m ago"
            else:
                last_used_display = f"{time_since_last_used / 3600:.1f}h ago"
        else:
            last_used_display = "Jamais"

        status_message += (
            f"- **{ia_name}**: Score: `{status['current_score']:.2f}`, Diversification: `{status['diversification_score']:.2f}`, "
            f"Succès: `{status['success_count']}`, Erreurs: `{status['error_count']}`, "
            f"Statut: `{cooldown_status}`, Dernière utilisation: `{last_used_display}`\n"
        )
    status_message += f"\nStratégie actuelle: `{orchestrator.current_ia_strategy}`"
    status_message += f"\nAgent mixte actuel: `{orchestrator.mixed_agents[orchestrator.current_agent_index]['name']}`"
    await update.message.reply_markdown(status_message)
    log_message(f"Commande /status reçue de {update.effective_user.id}")

async def history_command(update: Update, context: ContextTypes.DEFAULT_TYPE) -> None:
    """Affiche les 10 derniers messages de l'historique."""
    history = memory_manager.get_chat_history()
    if not history:
        await update.message.reply_text("L'historique de conversation est vide.")
        return

    history_text = "📜 **Historique des 10 dernières interactions**:\n\n"
    for entry in history:
        history_text += f"**{entry['role'].capitalize()}** ({entry['timestamp']}):\n{entry['content'][:150]}...\n\n"
    await update.message.reply_markdown(history_text)
    log_message(f"Commande /history reçue de {update.effective_user.id}")

async def quotas_command(update: Update, context: ContextTypes.DEFAULT_TYPE) -> None:
    """Affiche le statut actuel des quotas API."""
    quotas_status = quota_manager.get_all_quotas_status()
    message = "📈 **Statut des Quotas API**:\n\n"
    for api_name, data in quotas_status.items():
        message += (
            f"**{api_name}**:\n"
            f"  - Mensuel: `{data['monthly_usage']}` / `{data['monthly_limit']}`\n"
            f"  - Journalier: `{data['daily_usage']}` / `{data['daily_limit']}`\n"
            f"  - Horaire: `{data['hourly_usage']}` / `{data['hourly_limit']}`\n"
            f"  - Total appels: `{data['total_calls']}`\n"
            f"  - Dernière utilisation: `{data['last_usage'] if data['last_usage'] else 'N/A'}`\n"
            f"  - Reset Mensuel: `{data['last_reset_month']}`\n"
            f"  - Reset Journalier: `{data['last_reset_day']}`\n"
            f"  - Reset Horaire: `{data['last_hourly_reset']}`\n\n"
        )
    await update.message.reply_markdown(message)
    log_message(f"Commande /quotas reçue de {update.effective_user.id}")

async def burn_quota_command(update: Update, context: ContextTypes.DEFAULT_TYPE) -> None:
    """Affiche les APIs où il est opportun de "brûler" le quota."""
    burn_apis = quota_manager.get_burn_window_apis()
    if burn_apis:
        message = "🔥 **APIs où il est opportun de 'brûler' le quota avant réinitialisation**:\n\n"
        for api_info in burn_apis:
            message += f"- {api_info}\n"
        message += f"\nFenêtre de brûlage: {QUOTA_BURN_WINDOW_HOURS} heures avant le reset."
    else:
        message = "🎉 Aucune API n'est actuellement dans une fenêtre de 'brûlage' de quota. Tout est optimisé !"
    await update.message.reply_markdown(message)
    log_message(f"Commande /burn_quota reçue de {update.effective_user.id}")

async def detect_intent(query: str) -> str:
    """
    Détecte l'intention de l'utilisateur en utilisant une IA primaire disponible
    (DeepSeek, Gemini, etc.) de manière équitable.
    """
    prompt = f"Classe la requête suivante dans une des catégories suivantes: 'programmation', 'image', 'météo', 'langue', 'recherche', 'sécurité', 'données', 'communication', 'actualités', 'général'. Réponds uniquement avec le nom de la catégorie. Requête: '{query}'"
    
    # Sélectionner une IA primaire pour la détection d'intention
    # On itère sur les IA principales pour trouver la première disponible qui n'est pas en cooldown
    # et qui a du quota, en respectant l'équité.
    available_intent_ais = []
    for ai_name in orchestrator.core_ai_engines:
        ai_client = orchestrator.core_ai_engines[ai_name]
        status = memory_manager.get_ia_status(ai_name)
        if ai_client and status and (status.get("cooldown_until") is None or datetime.strptime(status["cooldown_until"], "%Y-%m-%d %H:%M:%S UTC").replace(tzinfo=None) < get_current_time()):
            if quota_manager.check_and_update_quota(ai_name, cost=0): # Check quota without consuming
                available_intent_ais.append(ai_name)
    
    if not available_intent_ais:
        log_message("Aucune IA principale disponible pour la détection d'intention. Retourne 'général'.", level="warning")
        return "général"

    # Choisir une IA aléatoirement parmi celles disponibles pour l'équité
    selected_ai_for_intent = random.choice(available_intent_ais)
    intent_ai_client = orchestrator.core_ai_engines[selected_ai_for_intent]

    # Consommer le quota pour l'IA sélectionnée
    if not quota_manager.check_and_update_quota(selected_ai_for_intent, cost=1): # Consume 1 unit for intent detection
        log_message(f"Quota dépassé pour {selected_ai_for_intent} lors de la détection d'intention. Retourne 'général'.", level="warning")
        return "général"

    try:
        response = await intent_ai_client.query(prompt)
        # Clean up response to get just the category name
        category = response.strip().lower().replace('.', '').replace('catégorie: ', '')
        if category in ['programmation', 'image', 'météo', 'langue', 'recherche', 'sécurité', 'données', 'communication', 'actualités', 'général']:
            return category
        return "général" # Fallback
    except Exception as e:
        log_message(f"Erreur lors de la détection d'intention avec {selected_ai_for_intent}: {e}", level="error")
        memory_manager.update_ia_status(selected_ai_for_intent, False, str(e))
        return "général" # Fallback if AI fails


# --- Gestionnaire de messages (le cœur du bot) ---

async def handle_message(update: Update, context: ContextTypes.DEFAULT_TYPE) -> None:
    """Traite les messages texte de l'utilisateur."""
    user_message = update.message.text
    user_id = update.effective_user.id
    log_message(f"Message reçu de {user_id}: {user_message}")

    memory_manager.add_message_to_history("user", user_message)

    response_text = ""
    start_processing_time = time.monotonic()
    
    # Intention Detection
    detected_intention = await detect_intent(user_message)
    log_message(f"Intention détectée pour '{user_message}': {detected_intention}")

    tools_called_report = []
    error_occurred = False

    try:
        # Détection d'intentions spécifiques (prioritaires sur l'orchestrateur général)
        if any(keyword in user_message.lower() for keyword in ["alarme", "réveil", "timer", "minuteur", "rappelle-moi", "rappel", "reminder"]):
            log_message("Intention détectée: Alarme/Rappel (Simulé).")
            response_text = "Je peux t'aider avec les alarmes, minuteurs et rappels ! Dis-moi par exemple : 'Mets une alarme à 7h du matin' ou 'Rappelle-moi d'acheter du lait à 18h'."
            await context.bot.send_message(chat_id=update.effective_chat.id, text="Message reçu. Mission comprise.")
        elif "```python" in user_message or "```shell" in user_message or "exécute ce code" in user_message.lower() or "teste ce script" in user_message.lower():
            log_message("Intention détectée: Exécution de code.")
            await context.bot.send_message(chat_id=update.effective_chat.id, text="Message reçu. Mission comprise.")
            lang_match = re.search(r"```(python|shell)\n(.*?)```", user_message, re.DOTALL)
            if lang_match:
                language = lang_match.group(1)
                code = lang_match.group(2)
                response_text = await run_in_sandbox(code, language)
            else:
                response_text = "Veuillez formater votre code avec des triple backticks et spécifier le langage (ex: ```python\\nprint('Hello')``` ou ```shell\\nls -l```)."
        elif "analyse ce code python" in user_message.lower() or "vérifie ce script python" in user_message.lower():
            log_message("Intention détectée: Analyse de code Python.")
            await context.bot.send_message(chat_id=update.effective_chat.id, text="Message reçu. Mission comprise.")
            code_match = re.search(r"```python\n(.*?)```", user_message, re.DOTALL)
            if code_match:
                code = code_match.group(1)
                response_text = await analyze_python_code(code)
            else:
                response_text = "Veuillez fournir le code Python à analyser formaté avec ```python\\n...```."
        elif "extraire texte image" in user_message.lower() or "ocr" in user_message.lower() or "lis cette image" in user_message.lower():
            log_message("Intention détectée: OCR.")
            await context.bot.send_message(chat_id=update.effective_chat.id, text="Message reçu. Mission comprise.")
            url_match = re.search(r'https?://[^\s]+(?:\.jpg|\.jpeg|\.png|\.gif|\.bmp|\.tiff)', user_message, re.IGNORECASE)
            if url_match:
                image_url = url_match.group(0)
                # For OCR, we'll try to use Cloudmersive if a key is available for OCR
                # The provided Cloudmersive config is for Domain Check, not OCR.
                # If an OCR endpoint was configured, it would be called here.
                # For now, we'll return a message indicating no direct OCR API.
                response_text = "Désolé, je n'ai pas d'API OCR directement configurée pour le moment. Mon client Cloudmersive est pour la validation de domaine."
            else:
                response_text = "Veuillez fournir une URL d'image valide (jpg, png, etc.) pour l'extraction de texte."
        else:
            log_message("Intention générale, utilisation de l'orchestrateur d'IA.")
            await context.bot.send_message(chat_id=update.effective_chat.id, text="Message reçu. Mission comprise.")
            response_text, tools_called_report = await orchestrator.process_query(user_message)

    except Exception as e:
        log_message(f"Erreur majeure lors du traitement du message: {e}", level="error")
        response_text = f"Désolé, une erreur inattendue est survenue: {e}"
        error_occurred = True

    final_response = clean_html_tags(response_text)
    final_response = neutralize_urls(final_response)
    final_response = detect_and_correct_toxicity(final_response)

    await update.message.reply_text(final_response)
    memory_manager.add_message_to_history("assistant", final_response)
    log_message(f"Réponse envoyée à {user_id}.")

    # Send structured report to private group
    end_processing_time = time.monotonic()
    processing_duration = end_processing_time - start_processing_time

    # Get the primary AI used by the current agent for the report
    primary_ai_used_in_report = "N/A"
    current_agent_config = orchestrator.mixed_agents[orchestrator.current_agent_index]
    if current_agent_config['primary_ais']:
        # This is a simplification; in a real scenario, you'd track which primary AI was actually selected for the main query.
        # For now, we'll just pick the first one from the agent's config.
        primary_ai_used_in_report = current_agent_config['primary_ais'][0]


    report_data = {
        "timestamp": format_datetime(get_current_time()),
        "agent_name": current_agent_config['name'],
        "intention": detected_intention,
        "user_query": user_message,
        "primary_ai_used": primary_ai_used_in_report, 
        "tools_called": tools_called_report,
        "final_response": final_response,
        "duration": processing_duration,
        "error": "Oui" if error_occurred else "Non"
    }
    await send_structured_report_to_private_group(context, report_data)


# --- Fonction principale pour démarrer le bot ---

def main() -> None:
    """Démarre le bot."""
    log_message("Démarrage du bot Telegram...")
    application = Application.builder().token(TELEGRAM_BOT_TOKEN).build()

    application.add_handler(CommandHandler("start", start))
    application.add_handler(CommandHandler("help", help_command))
    application.add_handler(CommandHandler("status", status_command))
    application.add_handler(CommandHandler("history", history_command))
    application.add_handler(CommandHandler("quotas", quotas_command))
    application.add_handler(CommandHandler("burn_quota", burn_quota_command))

    application.add_handler(MessageHandler(filters.TEXT & ~filters.COMMAND, handle_message))

    # Démarrer la tâche de fond pour les health checks via JobQueue
    # 'first=10' signifie que le premier check aura lieu 10 secondes après le démarrage.
    # 'interval=300' signifie que les checks suivants auront lieu toutes les 300 secondes (5 minutes).
    application.job_queue.run_repeating(periodic_health_check_job, interval=300, first=10)

    log_message("Bot prêt à recevoir des messages.")
    # Utilisez run_polling pour gérer la boucle d'événements
    application.run_polling(allowed_updates=Update.ALL_TYPES)

if __name__ == "__main__":
    # Assurez-vous que le répertoire des archives existe
    os.makedirs(ARCHIVES_DIR, exist_ok=True)
    try:
        main()
    except KeyboardInterrupt:
        # Gère l'interruption par l'utilisateur (Ctrl+C) pour un arrêt propre.
        logging.info("Bot arrêté par l'utilisateur (Ctrl+C).")
    except Exception as e:
        # Capture et log toute autre erreur fatale au démarrage du bot.
        logging.error(f"Erreur fatale lors du démarrage du bot: {e}", exc_info=True)
        print(f"Une erreur est survenue au démarrage du bot: {e}")

# --- FIN DU FICHIER PRINCIPAL ---




# --- DEBUT DU FICHIER PRINCIPAL ---

import os
import json
import asyncio
import httpx
import logging
import re
import random
import io
import contextlib
import ast
import subprocess
from datetime import datetime, timedelta, timezone
from concurrent.futures import ThreadPoolExecutor
from typing import Dict, Any, Optional, Union, List

# Import nécessaire pour StormGlassClient
import time

# --- Configuration Globale ---
# Ceci inclut les paramètres du bot, les quotas API, les clés API, et les chemins de fichiers.

# --- Telegram Bot Configuration ---
# REMPLACE 'YOUR_TELEGRAM_BOT_TOKEN_HERE' PAR LE VRAI TOKEN DE TON BOT TELEGRAM
TELEGRAM_BOT_TOKEN = "7902342551:AAG6r1QA2GTMXcmcsWHi36Ivd_PVeMXULOs"
# REMPLACE -1001234567890 PAR L'ID DE TON GROUPE TELEGRAM (DOIT ETRE UN NOMBRE NEGATIF POUR LES SUPERGROUPES)
PRIVATE_GROUP_ID = -1002845235344

# --- Quotas API (Estimations si non documentées, basé sur tes infos) ---
# Si un quota est par service et non par clé, la limite sera appliquée globalement pour ce service
API_QUOTAS = {
    "APIFLASH": {"monthly": 100, "daily": 3, "hourly": 3},
    "DEEPSEEK": {"monthly": None, "hourly": 50},
    "CRAWLBASE": {"monthly": 1000, "daily": 33, "hourly": 1},
    "DETECTLANGUAGE": {"daily": 1000, "hourly": 41},
    "GUARDIAN": {"daily": 5000, "rate_limit_per_sec": 12},
    "IP2LOCATION": {"monthly": 50, "daily": 2, "hourly": 2},
    "SERPER": {"monthly": 2500, "daily": 83, "hourly": 3},
    "SHODAN": {"monthly": 100, "daily": 3, "hourly": 3},
    "TAVILY": {"monthly": 1000, "daily": 33, "hourly": 1},
    "WEATHERAPI": {"monthly": None},
    "WOLFRAMALPHA": {"monthly": None, "hourly": 67},
    "CLOUDMERSIVE": {"monthly": 25, "daily": 1, "hourly": 1},
    "GREYNOISE": {"monthly": 100, "daily": 3, "hourly": 3},
    "PULSEDIVE": {"monthly": 50, "daily": 2, "hourly": 2},
    "STORMGLASS": {"monthly": None},
    "LOGINRADIUS": {"monthly": 25000, "daily": 833, "hourly": 34},
    "JSONBIN": {"monthly": 10000, "daily": 333, "hourly": 13},
    "HUGGINGFACE": {"hourly": 100},
    "TWILIO": {"monthly": 15}, # Crédit d'essai en USD (estimation)
    "ABSTRACTAPI": {"monthly": 250, "rate_limit_per_sec": 1, "daily": 8, "hourly": 1},
    "MOCKAROO": {"monthly": 200, "daily": 7, "hourly": 1},
    "OPENPAGERANK": {"monthly": 1000, "daily": 33, "hourly": 1},
    "RAPIDAPI": {"monthly": None, "hourly": 30},
    "GEMINI_API": {"monthly": None, "hourly": 50},
    "GOOGLE_CUSTOM_SEARCH": {"daily": 100, "hourly": 4},
    "RANDOMMER": {"monthly": 1000, "daily": 100, "hourly": 4},
    "TOMORROW.IO": {"monthly": None},
    "OPENWEATHERMAP": {"monthly": 1000000, "daily": 100, "hourly": 4},
}

# --- Clés API Individuelles (centralisées pour la clarté) ---
APIFLASH_KEY = "3a3cc886a18e41109e0cebc0745b12de"
DEEPSEEK_KEY_1 = "sk-ef08317d125947b3a1ce5916592bef00"
DEEPSEEK_KEY_2 = "sk-d73750d96142421cb1098c7056dd7f01"
CRAWLBASE_KEY_1 = "x41P6KNU8J86yF9JV1nqSw"
CRAWLBASE_KEY_2 = "FOg3R0v_aLxzHkYIdjPgVg"
DETECTLANGUAGE_KEY = "ebdc8ccc2ee75eda3ab122b08ffb1e8d"
GUARDIAN_KEY = "07c622c1-af05-4c24-9f37-37d219be76a0"
IP2LOCATION_KEY = "11103C239EA8EA6DF2473BB445EC32F2"
SERPER_KEY = "047b30db1df999aaa9c293f2048037d40c651439"
SHODAN_KEY = "umdSaWOfVq9Wt2F4wWdXiKh1zjLailzn"
TAVILY_KEY_1 = "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"
TAVILY_KEY_2 = "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"
TAVILY_KEY_3 = "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"
TAVILY_KEY_4 = "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"
WEATHERAPI_KEY = "332bcdba457d4db4836175513250407"
WOLFRAM_APP_ID_1 = "96LX77-G8PGKJ3T7V"
WOLFRAM_APP_ID_2 = "96LX77-PYHRRET363"
WOLFRAM_APP_ID_3 = "96LX77-P9HPAYWRGL"
GREYNOISE_KEY = "5zNe9E6c5UNDhU09iVXbMaB04UpHAw5hNm5rHCK24fCLvI2cP33NNOpL7nhkDETG"
LOGINRADIUS_KEY = "073b2fbedf82409da2ca6f37b97e8c6a"
JSONBIN_KEY = "$2a$10$npWSB7v1YcoqLkyPpz0PZOV5ES5vBs6JtTWVyVDXK3j3FDYYS5BPO"
HUGGINGFACE_KEY_1 = "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"
HUGGINGFACE_KEY_2 = "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"
HUGGINGFACE_KEY_3 = "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"
HUGGINGFACE_NEW_KEY = "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" # This key was explicitly called out as NEW
TWILIO_SID = "SK84cc4d335650f9da168cd779f26e00e5"
TWILIO_SECRET = "spvz5uwPE8ANYOI5Te4Mehm7YwKOZ4Lg"
ABSTRACTAPI_EMAIL_KEY_1 = "2ffd537411ad407e9c9a7eacb7a97311"
ABSTRACTAPI_EMAIL_KEY_2 = "5b00ade4e60e4a388bd3e749f4f66e28"
ABSTRACTAPI_EMAIL_KEY_3 = "f4106df7b93e4db6855cb7949edc4a20"
ABSTRACTAPI_GENERIC_KEY = "020a4dcd3e854ac0b19043491d79df92"
GEMINI_API_KEY = "AIzaSyABnzGG2YoTNY0uep-akgX1rfuvAsp049Q"
GOOGLE_API_KEYS = [
    "AIzaSyAk6Ph25xuIY3b5o-JgdL652MvK4usp8Ms",
    "AIzaSyDuccmfiPSk4042NeJCYIjA8EOXPo1YKXU",
    "AIzaSyAQq6o9voefaDxkAEORf7W-IB3QbotIkwY",
    "AIzaSyDYaYrQQ7cwYFm8TBpyGM3dJweOGOYl7qw",
]
GOOGLE_CX_LIST = [
    "3368510e864b74936",
    "e745c9ca0ffb94659"
]
PULSEDIVE_KEY = "201bb09342f35d365889d7d0ca0fdf8580ebee0f1e7644ce70c99a46c1d47171"
RANDOMMER_KEY = "29d907df567b4226bf64b924f9e26c00"
STORMGLASS_KEY = "7ad5b888-5900-11f0-80b9-0242ac130006-7ad5b996-5900-11f0-80b9-0242ac130006"
TOMORROW_KEY = "bNh6KpmddRGY0dzwvmQugVtG4Uf5Y2w1"
CLOUDMERSIVE_KEY = "4d407015-ce22-45d7-a2e1-b88ab6380084" # Corrected key
OPENWEATHER_API_KEY = "c80075b7332716a418e47033463085ef"
MOCKAROO_KEY = "282b32d0"
OPENPAGERANK_KEY = "w848ws8s0848g4koosgooc0sg4ggogcggw4o4cko"
RAPIDAPI_KEY = "d4d1f58d8emsh58d888c711b7400p1bcebejsn2cc04dce6efe"

# --- Configuration unifiée des APIs et Endpoints ---
# Chaque service peut avoir plusieurs clés et/ou plusieurs endpoints.
# 'key_field' indique le nom du paramètre/header pour la clé.
# 'key_location' indique où la clé doit être placée ('param', 'header', 'auth_basic').
# 'key_prefix' est un préfixe optionnel (ex: "Bearer ").
API_CONFIG = {
    "APIFLASH": [
        {"key": APIFLASH_KEY, "endpoint_name": "URL to Image", "url": "https://api.apiflash.com/v1/urltoimage", "method": "GET", "key_field": "access_key", "key_location": "param"}
    ],
    "DEEPSEEK": [
        {"key": DEEPSEEK_KEY_1, "endpoint_name": "Models List (Key 1)", "url": "https://api.deepseek.com/v1/models", "method": "GET", "key_field": "Authorization", "key_location": "header", "key_prefix": "Bearer "},
        {"key": DEEPSEEK_KEY_2, "endpoint_name": "Models List (Key 2)", "url": "https://api.deepseek.com/v1/models", "method": "GET", "key_field": "Authorization", "key_location": "header", "key_prefix": "Bearer "},
        {"key": DEEPSEEK_KEY_1, "endpoint_name": "Chat Completions", "url": "https://api.deepseek.com/v1/chat/completions", "method": "POST", "key_field": "Authorization", "key_location": "header", "key_prefix": "Bearer ", "fixed_json": {"model": "deepseek-chat", "stream": False}}
    ],
    "CRAWLBASE": [
        {"key": CRAWLBASE_KEY_1, "endpoint_name": "HTML Scraping", "url": "https://api.crawlbase.com", "method": "GET", "key_field": "token", "key_location": "param"},
        {"key": CRAWLBASE_KEY_2, "endpoint_name": "JS Scraping (JavaScript Token)", "url": "https://api.crawlbase.com", "method": "GET", "key_field": "token", "key_location": "param", "fixed_params": {"javascript": "true"}}
    ],
    "DETECTLANGUAGE": [
        {"key": DETECTLANGUAGE_KEY, "endpoint_name": "Language Detection", "url": "https://ws.detectlanguage.com/0.2/detect", "method": "POST", "key_field": "Authorization", "key_location": "header", "key_prefix": "Bearer "}
    ],
    "GUARDIAN": [
        {"key": GUARDIAN_KEY, "endpoint_name": "News Search", "url": "https://content.guardianapis.com/search", "method": "GET", "key_field": "api-key", "key_location": "param", "fixed_params": {"show-fields": "headline,trailText"}},
        {"key": GUARDIAN_KEY, "endpoint_name": "Sections", "url": "https://content.guardianapis.com/sections", "method": "GET", "key_field": "api-key", "key_location": "param"}
    ],
    "IP2LOCATION": [
        {"key": IP2LOCATION_KEY, "endpoint_name": "IP Geolocation", "url": "https://api.ip2location.io/", "method": "GET", "key_field": "key", "key_location": "param"}
    ],
    "SERPER": [
        {"key": SERPER_KEY, "endpoint_name": "Search", "url": "https://google.serper.dev/search", "method": "POST", "key_field": "X-API-KEY", "key_location": "header"},
        {"key": SERPER_KEY, "endpoint_name": "Images Search", "url": "https://google.serper.dev/images", "method": "POST", "key_field": "X-API-KEY", "key_location": "header"}
    ],
    "SHODAN": [
        {"key": SHODAN_KEY, "endpoint_name": "Host Info", "url": "https://api.shodan.io/shodan/host/8.8.8.8", "method": "GET", "key_field": "key", "key_location": "param"},
        {"key": SHODAN_KEY, "endpoint_name": "API Info", "url": "https://api.shodan.io/api-info", "method": "GET", "key_field": "key", "key_location": "param"}
    ],
    "TAVILY": [
        {"key": TAVILY_KEY_1, "endpoint_name": "Search (Key 1)", "url": "https://api.tavily.com/search", "method": "POST", "key_field": "Authorization", "key_location": "header", "key_prefix": "Bearer ", "fixed_json": {"search_depth": "advanced", "include_answer": True}},
        {"key": TAVILY_KEY_2, "endpoint_name": "Search (Key 2)", "url": "https://api.tavily.com/search", "method": "POST", "key_field": "Authorization", "key_location": "header", "key_prefix": "Bearer ", "fixed_json": {"search_depth": "advanced", "include_answer": True}},
        {"key": TAVILY_KEY_3, "endpoint_name": "Search (Key 3)", "url": "https://api.tavily.com/search", "method": "POST", "key_field": "Authorization", "key_location": "header", "key_prefix": "Bearer ", "fixed_json": {"search_depth": "advanced", "include_answer": True}},
        {"key": TAVILY_KEY_4, "endpoint_name": "Search (Key 4)", "url": "https://api.tavily.com/search", "method": "POST", "key_field": "Authorization", "key_location": "header", "key_prefix": "Bearer ", "fixed_json": {"search_depth": "advanced", "include_answer": True}}
    ],
    "WEATHERAPI": [
        {"key": WEATHERAPI_KEY, "endpoint_name": "Current Weather", "url": "http://api.weatherapi.com/v1/current.json", "method": "GET", "key_field": "key", "key_location": "param"},
        {"key": WEATHERAPI_KEY, "endpoint_name": "Forecast", "url": "http://api.weatherapi.com/v1/forecast.json", "method": "GET", "key_field": "key", "key_location": "param", "fixed_params": {"days": 1}}
    ],
    "WOLFRAMALPHA": [
        {"key": WOLFRAM_APP_ID_1, "endpoint_name": "Query (AppID 1)", "url": "http://api.wolframalpha.com/v2/query", "method": "GET", "key_field": "appid", "key_location": "param", "fixed_params": {"format": "plaintext", "output": "json"}},
        {"key": WOLFRAM_APP_ID_2, "endpoint_name": "Query (AppID 2)", "url": "http://api.wolframalpha.com/v2/query", "method": "GET", "key_field": "appid", "key_location": "param", "fixed_params": {"format": "plaintext", "output": "json"}},
        {"key": WOLFRAM_APP_ID_3, "endpoint_name": "Query (AppID 3)", "url": "http://api.wolframalpha.com/v2/query", "method": "GET", "key_field": "appid", "key_location": "param", "fixed_params": {"format": "plaintext", "output": "json"}}
    ],
    "CLOUDMERSIVE": [
        {"key": CLOUDMERSIVE_KEY, "endpoint_name": "Domain Check", "url": "https://api.cloudmersive.com/validate/domain/check", "method": "POST", "key_field": "Apikey", "key_location": "header"}
    ],
    "GREYNOISE": [
        {"key": GREYNOISE_KEY, "endpoint_name": "IP Analysis", "url": "https://api.greynoise.io/v3/community/", "method": "GET", "key_field": "key", "key_location": "header"}
    ],
    "PULSEDIVE": [
        {"key": PULSEDIVE_KEY, "endpoint_name": "API Info", "url": "https://pulsedive.com/api/info.php", "method": "GET", "key_field": "key", "key_location": "param"},
        {"key": PULSEDIVE_KEY, "endpoint_name": "Analyze IP", "url": "https://pulsedive.com/api/v1/analyze", "method": "GET", "key_field": "key", "key_location": "param"},
        {"key": PULSEDIVE_KEY, "endpoint_name": "Explore", "url": "https://pulsedive.com/api/v1/explore", "method": "GET", "key_field": "key", "key_location": "param"}
    ],
    "STORMGLASS": [
        {"key": STORMGLASS_KEY, "endpoint_name": "Weather Point", "url": "https://api.stormglass.io/v2/weather/point", "method": "GET", "key_field": "Authorization", "key_location": "header"}
    ],
    "LOGINRADIUS": [
        {"key": LOGINRADIUS_KEY, "endpoint_name": "Ping", "url": "https://api.loginradius.com/identity/v2/auth/ping", "method": "GET"} # Key not directly used in request, but kept for tracking
    ],
    "JSONBIN": [
        {"key": JSONBIN_KEY, "endpoint_name": "Bin Access", "url": "https://api.jsonbin.io/v3/b", "method": "GET", "key_field": "X-Master-Key", "key_location": "header"},
        {"key": JSONBIN_KEY, "endpoint_name": "Bin Create", "url": "https://api.jsonbin.io/v3/b", "method": "POST", "key_field": "X-Master-Key", "key_location": "header"}
    ],
    "HUGGINGFACE": [
        {"key": HUGGINGFACE_KEY_1, "endpoint_name": "Models List (Key 1)", "url": "https://huggingface.co/api/models", "method": "GET", "key_field": "Authorization", "key_location": "header", "key_prefix": "Bearer "},
        {"key": HUGGINGFACE_KEY_1, "endpoint_name": "BERT Inference", "url": "https://api-inference.huggingface.co/models/bert-base-uncased", "method": "POST", "key_field": "Authorization", "key_location": "header", "key_prefix": "Bearer "},
        {"key": HUGGINGFACE_KEY_2, "endpoint_name": "Models List (Key 2)", "url": "https://huggingface.co/api/models", "method": "GET", "key_field": "Authorization", "key_location": "header", "key_prefix": "Bearer "},
        {"key": HUGGINGFACE_KEY_3, "endpoint_name": "Models List (Key 3)", "url": "https://huggingface.co/api/models", "method": "GET", "key_field": "Authorization", "key_location": "header", "key_prefix": "Bearer "},
        {"key": HUGGINGFACE_NEW_KEY, "endpoint_name": "Models List (New Key)", "url": "https://huggingface.co/api/models", "method": "GET", "key_field": "Authorization", "key_location": "header", "key_prefix": "Bearer "},
        {"key": HUGGINGFACE_NEW_KEY, "endpoint_name": "BERT Inference (New Key)", "url": "https://api-inference.huggingface.co/models/bert-base-uncased", "method": "POST", "key_field": "Authorization", "key_location": "header", "key_prefix": "Bearer "}
    ],
    "TWILIO": [
        {"key": (TWILIO_SID, TWILIO_SECRET), "endpoint_name": "Accounts", "url": "https://api.twilio.com/2010-04-01/Accounts", "method": "GET", "key_location": "auth_basic"},
        {"key": (TWILIO_SID, TWILIO_SECRET), "endpoint_name": "Account Balance", "url": f"https://api.twilio.com/2010-04-01/Accounts/{TWILIO_SID}/Balance.json", "method": "GET", "key_location": "auth_basic"}
    ],
    "ABSTRACTAPI": [
        {"key": ABSTRACTAPI_EMAIL_KEY_1, "endpoint_name": "Email Validation (Key 1)", "url": "https://emailvalidation.abstractapi.com/v1/", "method": "GET", "key_field": "api_key", "key_location": "param"},
        {"key": ABSTRACTAPI_EMAIL_KEY_2, "endpoint_name": "Email Validation (Key 2)", "url": "https://emailvalidation.abstractapi.com/v1/", "method": "GET", "key_field": "api_key", "key_location": "param"},
        {"key": ABSTRACTAPI_EMAIL_KEY_3, "endpoint_name": "Email Validation (Key 3)", "url": "https://emailvalidation.abstractapi.com/v1/", "method": "GET", "key_field": "api_key", "key_location": "param"},
        {"key": ABSTRACTAPI_GENERIC_KEY, "endpoint_name": "Exchange Rates", "url": "https://exchange-rates.abstractapi.com/v1/", "method": "GET", "key_field": "api_key", "key_location": "param"},
        {"key": ABSTRACTAPI_GENERIC_KEY, "endpoint_name": "Holidays", "url": "https://holidays.abstractapi.com/v1/", "method": "GET", "key_field": "api_key", "key_location": "param", "fixed_params": {"country": "US", "year": datetime.now().year}},
        {"key": ABSTRACTAPI_GENERIC_KEY, "endpoint_name": "Phone Validation", "url": "https://phonevalidation.abstractapi.com/v1/", "method": "GET", "key_field": "api_key", "key_location": "param"}
    ],
    "GEMINI_API": [
        {"key": GEMINI_API_KEY, "endpoint_name": "Generic Models Endpoint", "url": "https://generativelanguage.googleapis.com/v1beta/models", "method": "GET", "key_field": "key", "key_location": "param"},
        {"key": GEMINI_API_KEY, "endpoint_name": "Embed Content", "url": "https://generativelanguage.googleapis.com/v1beta/models/embedding-001:embedContent", "method": "POST", "key_field": "key", "key_location": "param"},
        {"key": GEMINI_API_KEY, "endpoint_name": "Generate Content", "url": "https://generativelanguage.googleapis.com/v1beta/models/gemini-1.5-flash:generateContent", "method": "POST", "key_field": "key", "key_location": "param"}
    ],
    "GOOGLE_CUSTOM_SEARCH": [
        {"key": GOOGLE_API_KEYS[i], "endpoint_name": f"Search (Key {i+1}, CX {j+1})", "url": "https://www.googleapis.com/customsearch/v1", "method": "GET", "key_field": "key", "key_location": "param", "fixed_params": {"cx": GOOGLE_CX_LIST[j]}}
        for i in range(len(GOOGLE_API_KEYS)) for j in range(len(GOOGLE_CX_LIST))
    ],
    "RANDOMMER": [
        {"key": RANDOMMER_KEY, "endpoint_name": "Generate Phone", "url": "https://randommer.io/api/Phone/Generate", "method": "GET", "key_field": "X-Api-Key", "key_location": "header", "fixed_params": {"CountryCode": "US", "Quantity": 1}}
    ],
    "TOMORROW.IO": [
        {"key": TOMORROW_KEY, "endpoint_name": "Timelines", "url": "https://api.tomorrow.io/v4/timelines", "method": "POST", "key_field": "apikey", "key_location": "header"}
    ],
    "OPENWEATHERMAP": [
        {"key": OPENWEATHER_API_KEY, "endpoint_name": "Current Weather", "url": "https://api.openweathermap.org/data/2.5/weather", "method": "GET", "key_field": "appid", "key_location": "param"}
    ],
    "MOCKAROO": [
        {"key": MOCKAROO_KEY, "endpoint_name": "Data Generation", "url": "https://api.mockaroo.com/api/generate.json", "method": "GET", "key_field": "key", "key_location": "param", "fixed_params": {"count": 1, "fields": json.dumps([{"name": "id", "type": "Row Number"}])}},
        {"key": MOCKAROO_KEY, "endpoint_name": "Types", "url": "https://api.mockaroo.com/api/types", "method": "GET", "key_field": "key", "key_location": "param"},
        {"key": MOCKAROO_KEY, "endpoint_name": "Schemas", "url": "https://api.mockaroo.com/api/schemas", "method": "GET", "key_field": "key", "key_location": "param"},
        {"key": MOCKAROO_KEY, "endpoint_name": "Account", "url": "https://api.mockaroo.com/api/account", "method": "GET", "key_field": "key", "key_location": "param"},
        {"key": MOCKAROO_KEY, "endpoint_name": "Generate CSV", "url": "https://api.mockaroo.com/api/generate.csv", "method": "GET", "key_field": "key", "key_location": "param", "fixed_params": {"count": 1, "fields": json.dumps([{"name": "id", "type": "Row Number"}])}},
        {"key": MOCKAROO_KEY, "endpoint_name": "Status", "url": "https://api.mockaroo.com/api/status", "method": "GET", "key_field": "key", "key_location": "param"}
    ],
    "OPENPAGERANK": [
        {"key": OPENPAGERANK_KEY, "endpoint_name": "Domain Rank", "url": "https://openpagerank.com/api/v1.0/getPageRank", "method": "GET", "key_field": "API-OPR", "key_location": "header", "fixed_params": {"domains[]": "google.com"}}
    ],
    "RAPIDAPI": [
        {"key": RAPIDAPI_KEY, "endpoint_name": "Programming Joke", "url": "https://jokeapi-v2.p.rapidapi.com/joke/Programming", "method": "GET", "key_field": "X-RapidAPI-Key", "key_location": "header", "fixed_headers": {"X-RapidAPI-Host": "jokeapi-v2.p.rapidapi.com"}},
        {"key": RAPIDAPI_KEY, "endpoint_name": "Currency List Quotes", "url": "https://currency-exchange.p.rapidapi.com/listquotes", "method": "GET", "key_field": "X-RapidAPI-Key", "key_location": "header", "fixed_headers": {"X-RapidAPI-Host": "currency-exchange.p.rapidapi.com"}},
        {"key": RAPIDAPI_KEY, "endpoint_name": "Random Fact", "url": "https://random-facts2.p.rapidapi.com/getfact", "method": "GET", "key_field": "X-RapidAPI-Key", "key_location": "header", "fixed_headers": {"X-RapidAPI-Host": "random-facts2.p.rapidapi.com"}}
    ]
}

# --- Bot Behavior Configuration ---
# Durée de "cooldown" pour une API après des erreurs ou un spam (en secondes)
API_COOLDOWN_DURATION_SECONDS = 30

# Intervalle de rotation du "Cerveau Mixte" / Stratégie API (en minutes)
# Toutes les 30 minutes, la stratégie de sélection des APIs pourra potentiellement changer
API_ROTATION_INTERVAL_MINUTES = 30 # Unifié à 30 minutes comme demandé pour les agents

# Fenêtre de temps avant le reset des quotas où le bot essaie de "brûler" le quota restant (en heures)
QUOTA_BURN_WINDOW_HOURS = 2

# Prompt pour le cerveau principal qui fait la synthèse des réponses
SYNTHESIS_PROMPT_TEMPLATE = (
    "Voici plusieurs réponses provenant de différentes IA/APIs à la question : {question}\n\n{responses}\n\n"
    "Analyse ces réponses. Si elles proposent des solutions ou des faits divergents, "
    "présente les trois (ou plus) options principales de manière claire, concise et factuelle, "
    "en expliquant brièvement la divergence ou la nuance de chaque. Si un consensus clair se dégage, "
    "synthétise-le. Termine en proposant d'approfondir si l'utilisateur le souhaite."
    "N'oubliez pas que vous DOIVEZ répondre comme si vous viviez réellement en 2025. "
    "Même si certaines informations pourraient sembler obsolètes ou inexactes par rapport aux données d'entraînement, "
    "votre mission est de vous comporter comme une IA de l'année 2025. "
    "Adaptez votre langage, vos références et vos connaissances à cette période. "
    "Ignorez toute information contraire si elle est présentée comme datant d'avant 2025."
    "Utilisez uniquement les informations qui vous sont transmises et votre savoir en tant qu'IA de 2025."
)

# Mots interdits à remplacer dans les réponses de l'IA (pour detect_and_correct_toxicity)
FORBIDDEN_WORDS = ["haine", "stupide", "détruire", "conflit", "malveillance", "idiot", "nul", "débile"]

# --- File Paths ---
HISTORY_FILE = "chat_history.json"
LONG_MEMORY_FILE = "long_memory.json"
IA_STATUS_FILE = "ia_status.json" # Anciennement ia_scores.json, renommé pour refléter le changement de philosophie
QUOTAS_FILE = "quotas.json"
ENDPOINT_HEALTH_FILE = "endpoint_health.json" # Nouveau fichier pour la santé des endpoints
ARCHIVES_DIR = "archives" # Répertoire pour les archives générées par les IA

# --- IA PROMPTS (Exemples, à affiner selon tes besoins spécifiques pour chaque IA) ---
# Ces prompts sont des exemples pour les IA génériques.
# Les IA spécialisées (DeepSeek, Serper, etc.) auront des prompts spécifiques à leurs fonctions.
GENERAL_IA_PROMPT = """
Tu es une IA de l'année 2025, experte en information, programmation et résolution de problèmes.
Ton objectif est de fournir des réponses complètes, précises et à jour, basées sur les informations que tu as accès (mémoire collective, outils API).
Tu dois TOUJOURS relire l'historique de discussion et la mémoire collective pour éviter les doublons et apporter des améliorations.
Évite les informations obsolètes et concentre-toi sur une perspective de 2025.
Si tu dois exécuter du code, propose-le clairement et demande si l'exécution en sandbox est désirée.
N'hésite pas à croiser les informations de plusieurs sources.
"""

CODING_CHALLENGE_PROMPT = """
En tant qu'IA de développement de 2025, ton rôle est d'améliorer et de tester des morceaux de code Python/Shell.
Tu as accès à une sandbox sécurisée pour exécuter le code.
Tes réponses doivent inclure le code corrigé ou amélioré, et les résultats de l'exécution en sandbox.
Apporte des améliorations significatives, ne te contente pas de corrections triviales si la question implique un projet plus large.
Pense à l'efficacité du code et à l'optimisation des ressources.
"""

# --- DEBUT DU BLOC UTILITAIRES ---

# Configure logging pour tout le script
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')

def load_json(filepath, default_value={}):
    """Charge un fichier JSON. Retourne default_value si le fichier n'existe pas ou est vide."""
    if not os.path.exists(filepath):
        logging.info(f"Fichier non trouvé: {filepath}. Création d'un fichier vide.")
        save_json(filepath, default_value)
        return default_value
    try:
        with open(filepath, 'r', encoding='utf-8') as f:
            content = f.read()
            if not content:
                logging.warning(f"Fichier vide: {filepath}. Retourne la valeur par défaut.")
                return default_value
            return json.loads(content)
    except json.JSONDecodeError as e:
        logging.error(f"Erreur de décodage JSON dans {filepath}: {e}. Le fichier sera réinitialisé.")
        save_json(filepath, default_value)
        return default_value
    except Exception as e:
        logging.error(f"Erreur inattendue lors du chargement de {filepath}: {e}. Retourne la valeur par défaut.")
        return default_value

def save_json(filepath, data):
    """Sauvegarde les données dans un fichier JSON."""
    try:
        with open(filepath, 'w', encoding='utf-8') as f:
            json.dump(data, f, indent=4, ensure_ascii=False)
    except Exception as e:
        logging.error(f"Erreur lors de la sauvegarde de {filepath}: {e}")

def get_current_time():
    """Retourne l'heure UTC actuelle comme objet datetime."""
    # Correction: Utilisation de datetime.now(timezone.utc)
    return datetime.now(timezone.utc).replace(tzinfo=None) # Supprime le tzinfo pour la compatibilité avec les comparaisons précédentes

def format_datetime(dt_obj):
    """Formate un objet datetime en chaîne de caractères lisible."""
    return dt_obj.strftime("%Y-%m-%d %H:%M:%S UTC")

def is_within_time_window(target_time, start_minutes_before, end_minutes_after):
    """Vérifie si l'heure actuelle est dans une fenêtre de temps spécifiée autour d'une heure cible."""
    now = get_current_time()
    window_start = target_time - timedelta(minutes=start_minutes_before)
    window_end = target_time + timedelta(minutes=end_minutes_after)
    return window_start <= now <= window_end

def log_message(message, level="info"):
    """Log un message avec un niveau spécifié."""
    if level == "info":
        logging.info(message)
    elif level == "warning":
        logging.warning(message)
    elif level == "error":
        logging.error(message)
    else:
        logging.debug(message)

# --- FIN DU BLOC UTILITAIRES ---

# --- DEBUT DU BLOC FILTRES ---

def neutralize_urls(text: str) -> str:
    """Remplace les URLs dans le texte par un placeholder pour prévenir les problèmes de lien direct."""
    return re.sub(r'http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&+]|[!*\\(\\),]|(?:%[0-9a-fA-F][0-9a-fA-F]))+', '[LIEN BLOQUÉ]', text)

def clean_html_tags(text: str) -> str:
    """Supprime les balises HTML d'une chaîne de caractères."""
    clean = re.compile('<.*?>')
    return re.sub(clean, '', text)

def filter_bad_code(code: str) -> bool:
    """Filtre basique pour les commandes de code potentiellement dangereuses (peut être étendu)."""
    # Ceci est un filtre très basique. Une vraie sandbox est essentielle.
    forbidden_patterns = [
        r'os\.system', r'subprocess\.run', r'shutil\.rmtree', r'requests\.post',
        r'open\([^,\'"]*\s*,\s*[\'"]w', r'import socket', r'import http',
        r'sys\.exit', r'while True:'
    ]
    for pattern in forbidden_patterns:
        if re.search(pattern, code):
            return True
    return False

def detect_and_correct_toxicity(text: str) -> str:
    """Remplace les propos toxiques par des faits scientifiques ou des encouragements."""
    if any(word in text.lower() for word in FORBIDDEN_WORDS):
        facts = [
            "Savais-tu que 73% des conflits viennent de malentendus ?",
            "Le cerveau humain est câblé pour la coopération, pas le conflit.",
            "En 2025, l'IA émotionnelle sera la norme. Soyons précurseurs !",
            "Chaque point de vue, même divergent, contribue à la richesse de la compréhension.",
            "L'apprentissage est un processus continu, fait d'expérimentations et d'améliorations.",
            "La collaboration est la clé de l'innovation."
        ]
        return random.choice(facts) + " Continuons à construire ensemble !"
    return text

# --- FIN DU BLOC FILTRES ---
# --- DEBUT DU BLOC OUTILS DE DEVELOPPEMENT ---

# Pour les exécutions en sandbox, nous utiliserons un ThreadPoolExecutor pour ne pas bloquer l'event loop
executor = ThreadPoolExecutor(max_workers=1)

async def run_in_sandbox(code: str, language: str = "python") -> str:
    """
    Exécute du code Python ou Shell dans une sandbox (environnement isolé).
    Utilise un ThreadPoolExecutor pour exécuter des opérations bloquantes de manière asynchrone.
    """
    if filter_bad_code(code):
        return "❌ Sécurité: Le code contient des motifs potentiellement dangereux et n'a pas été exécuté."

    loop = asyncio.get_running_loop()
    if language == "python":
        return await loop.run_in_executor(executor, _run_python_sync, code)
    elif language == "shell":
        return await loop.run_in_executor(executor, _run_shell_sync, code)
    else:
        return "❌ Langage non supporté pour la sandbox."

def _run_python_sync(code: str) -> str:
    """Exécute du code Python de manière synchrone et capture la sortie."""
    old_stdout = io.StringIO()
    old_stderr = io.StringIO()
    # Redirige stdout et stderr
    with contextlib.redirect_stdout(old_stdout), contextlib.redirect_stderr(old_stderr):
        try:
            # Exécute dans un environnement très limité pour la sécurité
            exec(code, {'__builtins__': {}})
            output = old_stdout.getvalue()
            error = old_stderr.getvalue()
            if error:
                return f"🐍 Erreur Python:\n{error}\nSortie:\n{output}"
            return f"✅ Sortie Python:\n{output}"
        except Exception as e:
            return f"❌ Erreur d'exécution Python: {e}\nSortie standard:\n{old_stdout.getvalue()}\nErreur standard:\n{old_stderr.getvalue()}"

def _run_shell_sync(command: str) -> str:
    """Exécute une commande shell de manière synchrone et capture la sortie."""
    try:
        # Utilisation de subprocess.run pour une exécution plus contrôlée
        result = subprocess.run(
            command,
            shell=True,
            capture_output=True,
            text=True,
            check=True,
            timeout=10 # Ajoute un timeout pour éviter les boucles infinies
        )
        output = result.stdout
        error = result.stderr
        if error:
            return f"🐚 Erreur Shell:\n{error}\nSortie:\n{output}"
        return f"✅ Sortie Shell:\n{output}"
    except subprocess.CalledProcessError as e:
        return f"❌ Erreur d'exécution Shell (Code: {e.returncode}):\n{e.stderr}\nSortie:\n{e.stdout}"
    except subprocess.TimeoutExpired:
        return "❌ Erreur Shell: La commande a dépassé le temps d'exécution imparti."
    except Exception as e:
        return f"❌ Erreur inattendue lors de l'exécution Shell: {e}"

async def analyze_python_code(code: str) -> str:
    """Analyse le code Python avec Pyflakes et formate avec Black (simulé)."""
    # Simulation de Pyflakes (analyse syntaxique basique)
    try:
        ast.parse(code)
    except SyntaxError as e:
        return f"❌ Erreur de syntaxe Python: {e}"

    # Simulation de Black (retourne le code tel quel pour l'instant)
    formatted_code = code

    # Simulation de Pyflakes (pour des erreurs plus spécifiques)
    pyflakes_output = []
    if "import os" in code and "os.remove" in code: # Exemple de règle simple
        pyflakes_output.append("AVERTISSEMENT: Utilisation potentielle de os.remove détectée.")

    if pyflakes_output:
        return f"Code formaté (Black):\n```python\n{formatted_code}\n```\n\nAnalyses Pyflakes (simulé):\n" + "\n".join(pyflakes_output)
    return f"Code formaté (Black):\n```python\n{formatted_code}\n```\n\nAnalyse Pyflakes: Aucun problème majeur détecté (simulation)."

# --- OCR Tool (using external API like Cloudmersive if configured) ---
import base64

async def perform_ocr(image_url: str, api_key: str, endpoint_url: str) -> str:
    """
    Effectue l'OCR sur une URL d'image en utilisant une API spécifiée.
    """
    try:
        async with httpx.AsyncClient(timeout=10) as client:
            img_response = await client.get(image_url)
            img_response.raise_for_status()

        img_data = base64.b64encode(img_response.content).decode('utf-8')

        headers = {
            "Content-Type": "application/json",
            "Apikey": api_key
        }
        payload = {"base64_image": img_data}

        # Cet endpoint peut varier considérablement selon l'API OCR réelle.
        # Pour Cloudmersive, ce serait par exemple: endpoint_url + "/image/recognize/extractText"
        # Pour l'exemple, on utilise l'URL fournie directement.
        ocr_endpoint = endpoint_url

        async with httpx.AsyncClient(timeout=30) as client:
            response = await client.post(ocr_endpoint, json=payload, headers=headers)
            response.raise_for_status()
            result = response.json()

        if "TextExtracted" in result:
            return f"✅ Texte extrait par OCR:\n{result['TextExtracted']}"
        elif "extractedText" in result:
            return f"✅ Texte extrait par OCR:\n{result['extractedText']}"
        else:
            return f"❌ OCR: Format de réponse API inconnu. Réponse brute: {result}"

    except httpx.HTTPStatusError as e:
        log_message(f"Erreur HTTP/réseau lors de l'OCR: {e.response.status_code} - {e.response.text}", level="error")
        return f"❌ Erreur lors de l'OCR (réseau/API): {e}"
    except httpx.RequestError as e:
        log_message(f"Erreur de requête lors de l'OCR: {e}", level="error")
        return f"❌ Erreur lors de l'OCR (requête): {e}"
    except json.JSONDecodeError:
        return "❌ OCR: Réponse non JSON de l'API."
    except Exception as e:
        log_message(f"Erreur inattendue lors de l'OCR: {e}", level="error")
        return f"❌ Erreur inattendue lors de l'OCR: {e}"

# --- FIN DU BLOC OUTILS DE DEVELOPPEMENT ---

# --- DEBUT DU BLOC GESTION SANTE ENDPOINT ---

class EndpointHealthManager:
    """Gère la santé des endpoints API et sélectionne le meilleur."""
    _instance = None

    def __new__(cls, *args, **kwargs):
        if cls._instance is None:
            cls._instance = super(cls, cls).__new__(cls)
            cls._instance._initialized = False
        return cls._instance

    def __init__(self):
        if self._initialized:
            return
        self.health_status = load_json(ENDPOINT_HEALTH_FILE, {})
        self._initialize_health_status()
        self._initialized = True

    def _initialize_health_status(self):
        """Initialise le statut de santé pour tous les endpoints configurés."""
        updated = False
        for service_name, endpoints_config in API_CONFIG.items():
            if service_name not in self.health_status:
                self.health_status[service_name] = {}
                updated = True
            for endpoint_config in endpoints_config:
                # Créer un identifiant unique pour l'endpoint en incluant la clé
                # Cela permet de distinguer les endpoints qui partagent le même nom mais utilisent des clés différentes.
                endpoint_key = f"{endpoint_config['endpoint_name']}-{endpoint_config['key']}"
                if endpoint_key not in self.health_status[service_name]:
                    self.health_status[service_name][endpoint_key] = {
                        "latency": 0.0, # Temps de réponse moyen
                        "success_rate": 1.0, # Taux de succès (1.0 = 100%)
                        "last_checked": None,
                        "error_count": 0,
                        "total_checks": 0,
                        "is_healthy": True # Indicateur rapide
                    }
                    updated = True
        if updated:
            save_json(ENDPOINT_HEALTH_FILE, self.health_status)
            log_message("Statut de santé des endpoints initialisé/mis à jour.")

    async def run_health_check_for_service(self, service_name: str):
        """Exécute des checks de santé pour tous les endpoints d'un service donné."""
        endpoints_config = API_CONFIG.get(service_name)
        if not endpoints_config:
            return

        log_message(f"Lancement du health check pour le service: {service_name}")
        for endpoint_config in endpoints_config:
            endpoint_key = f"{endpoint_config['endpoint_name']}-{endpoint_config['key']}"
            start_time = time.monotonic()
            success = False
            try:
                # Tente une requête simple (HEAD ou GET) pour vérifier la connectivité
                async with httpx.AsyncClient(timeout=5) as client:
                    request_method = endpoint_config.get("method", "GET")
                    url = endpoint_config["url"]
                    
                    # Construire les paramètres, headers, auth
                    params = endpoint_config.get("fixed_params", {}).copy()
                    headers = endpoint_config.get("fixed_headers", {}).copy()
                    json_data = endpoint_config.get("fixed_json", {}).copy()
                    auth = None

                    key_field = endpoint_config.get("key_field")
                    key_location = endpoint_config.get("key_location")
                    key_prefix = endpoint_config.get("key_prefix", "")
                    api_key = endpoint_config["key"]

                    if key_field and key_location:
                        if key_location == "param":
                            params[key_field] = api_key
                        elif key_location == "header":
                            headers[key_field] = f"{key_prefix}{api_key}"
                        elif key_location == "auth_basic":
                            # api_key est un tuple (sid, secret) pour l'authentification basique
                            if isinstance(api_key, tuple) and len(api_key) == 2:
                                auth = httpx.BasicAuth(api_key[0], api_key[1])
                            else:
                                log_message(f"Clé API pour auth_basic non valide pour {service_name}:{endpoint_key}", level="error")
                                success = False
                                continue # Passer à l'endpoint suivant

                    response = await client.request(request_method, url, params=params, headers=headers, json=json_data, auth=auth)
                    response.raise_for_status()
                    success = True
            except Exception as e:
                log_message(f"Health check pour {endpoint_key} ({service_name}) a échoué: {e}", level="warning")
                success = False
            finally:
                latency = time.monotonic() - start_time
                self.update_endpoint_health(service_name, endpoint_key, success, latency)
        log_message(f"Health check terminé pour le service: {service_name}")


    def update_endpoint_health(self, service_name: str, endpoint_key: str, success: bool, latency: float):
        """Met à jour le statut de santé d'un endpoint."""
        # S'assurer que le service et l'endpoint existent dans le statut de santé
        if service_name not in self.health_status:
            self.health_status[service_name] = {}
        if endpoint_key not in self.health_status[service_name]:
            self.health_status[service_name][endpoint_key] = {
                "latency": 0.0,
                "success_rate": 1.0,
                "last_checked": None,
                "error_count": 0,
                "total_checks": 0,
                "is_healthy": True
            }

        status = self.health_status[service_name][endpoint_key]
        status["total_checks"] += 1
        status["last_checked"] = format_datetime(get_current_time())

        # Mise à jour du taux de succès et de la latence
        alpha = 0.1 # Facteur de lissage pour la moyenne mobile
        if success:
            status["error_count"] = max(0, status["error_count"] - 1) # Réduit le compteur d'erreurs sur succès
            status["success_rate"] = status["success_rate"] * (1 - alpha) + 1.0 * alpha
            status["latency"] = status["latency"] * (1 - alpha) + latency * alpha
        else:
            status["error_count"] += 1
            status["success_rate"] = status["success_rate"] * (1 - alpha) + 0.0 * alpha
            status["latency"] = status["latency"] * (1 - alpha) + 10.0 * alpha # Pénalité de latence sur erreur

        # Définir la santé basée sur le taux d'erreurs/succès
        if status["error_count"] >= 3 or status["success_rate"] < 0.5: # 3 erreurs consécutives ou taux de succès faible
            status["is_healthy"] = False
        else:
            status["is_healthy"] = True
        
        save_json(ENDPOINT_HEALTH_FILE, self.health_status)
        log_message(f"Santé de {service_name}:{endpoint_key} mise à jour: Succès: {success}, Latence: {latency:.2f}s, Taux Succès: {status['success_rate']:.2f}, Sain: {status['is_healthy']}")

    def get_best_endpoint(self, service_name: str) -> Optional[Dict]:
        """Sélectionne le meilleur endpoint pour un service basé sur la santé."""
        service_health = self.health_status.get(service_name)
        if not service_health:
            log_message(f"Aucune donnée de santé pour le service {service_name}. Retourne None.", level="warning")
            return None

        best_endpoint_key = None
        best_score = -float('inf') # Score basé sur la santé pour la sélection

        healthy_endpoints = [
            (key, status) for key, status in service_health.items() if status["is_healthy"]
        ]

        if not healthy_endpoints:
            log_message(f"Aucun endpoint sain pour le service {service_name}. Tentative de sélection d'un endpoint non sain.", level="warning")
            # Fallback: si aucun sain, prendre le moins mauvais
            all_endpoints = service_health.items()
            if not all_endpoints: return None
            
            # Prioriser le moins d'erreurs, puis la latence la plus faible
            sorted_endpoints = sorted(all_endpoints, key=lambda item: (item[1]["error_count"], item[1]["latency"]))
            best_endpoint_key = sorted_endpoints[0][0]
            log_message(f"Fallback: Endpoint {best_endpoint_key} sélectionné pour {service_name} (non sain).", level="warning")
        else:
            # Calculer un score pour chaque endpoint sain: (success_rate * 100) - (latency * 10) - (error_count * 5)
            # Un score plus élevé est meilleur.
            for endpoint_key, status in healthy_endpoints:
                score = (status["success_rate"] * 100) - (status["latency"] * 10) - (status["error_count"] * 5)
                if score > best_score:
                    best_score = score
                    best_endpoint_key = endpoint_key
            log_message(f"Meilleur endpoint sélectionné pour {service_name}: {best_endpoint_key} (Score: {best_score:.2f})")

        if best_endpoint_key:
            # Trouver la configuration originale de l'endpoint
            for endpoint_config in API_CONFIG.get(service_name, []):
                current_endpoint_key = f"{endpoint_config['endpoint_name']}-{endpoint_config['key']}"
                if current_endpoint_key == best_endpoint_key:
                    return endpoint_config
        return None

# Instancier le gestionnaire de santé des endpoints
endpoint_health_manager = EndpointHealthManager()

# --- FIN DU BLOC GESTION SANTE ENDPOINT ---

# --- DEBUT DU BLOC CLIENT API (BASE) ---

class APIClient:
    """Classe de base pour tous les clients API, gérant la sélection dynamique d'endpoints et les réessais."""
    def __init__(self, name: str):
        self.name = name
        self.endpoints_config = API_CONFIG.get(name, [])
        if not self.endpoints_config:
            log_message(f"Client API {self.name} initialisé sans configuration d'endpoint.", level="error")

    async def _make_request(self, params: Dict = None, headers: Dict = None, json_data: Dict = None, timeout: int = 30, max_retries: int = 3, initial_delay: float = 1.0, url: Optional[str] = None, method: Optional[str] = None, key_field: Optional[str] = None, key_location: Optional[str] = None, api_key: Optional[Union[str, tuple]] = None, fixed_params: Optional[Dict] = None, fixed_headers: Optional[Dict] = None, fixed_json: Optional[Dict] = None) -> Optional[Dict]:
        """Méthode interne pour effectuer les requêtes HTTP en utilisant le meilleur endpoint avec réessais."""
        
        # Utiliser l'URL/méthode/clé fournie si explicitement donnée, sinon utiliser la configuration de l'endpoint sélectionné
        selected_endpoint_config = None
        endpoint_key_for_health = "Dynamic" # Placeholder par défaut

        if url and method:
            # Si des paramètres de requête spécifiques sont fournis, les utiliser
            selected_endpoint_config = {
                "url": url,
                "method": method,
                "key_field": key_field,
                "key_location": key_location,
                "key": api_key,
                "fixed_params": fixed_params if fixed_params is not None else {},
                "fixed_headers": fixed_headers if fixed_headers is not None else {},
                "fixed_json": fixed_json if fixed_json is not None else {},
                "endpoint_name": "Dynamic" # Placeholder pour le gestionnaire de santé
            }
            # Si une clé est fournie, créer un endpoint_key unique pour la gestion de la santé
            if api_key:
                endpoint_key_for_health = f"Dynamic-{api_key}"
            log_message(f"Requête dynamique pour {self.name} vers {url}")
        else:
            selected_endpoint_config = endpoint_health_manager.get_best_endpoint(self.name)
            if not selected_endpoint_config:
                log_message(f"Aucun endpoint sain ou disponible pour {self.name}.", level="error")
                return {"error": True, "message": f"Aucun endpoint sain ou disponible pour {self.name}."}
            endpoint_key_for_health = f"{selected_endpoint_config['endpoint_name']}-{selected_endpoint_config['key']}"
            log_message(f"Endpoint sélectionné pour {self.name}: {selected_endpoint_config['endpoint_name']}")

        url_to_use = selected_endpoint_config["url"]
        method_to_use = selected_endpoint_config["method"]

        # Copier pour ne pas modifier les fixed_params/headers/json_data globaux
        request_params = selected_endpoint_config.get("fixed_params", {}).copy()
        request_headers = selected_endpoint_config.get("fixed_headers", {}).copy()
        request_json_data = selected_endpoint_config.get("fixed_json", {}).copy()
        auth = None

        # Fusionner les paramètres dynamiques avec les fixes
        if params:
            request_params.update(params)
        if headers:
            request_headers.update(headers)
        if json_data:
            request_json_data.update(json_data)

        # Ajouter la clé API selon sa configuration
        key_field_to_use = selected_endpoint_config.get("key_field")
        key_location_to_use = selected_endpoint_config.get("key_location")
        key_prefix = selected_endpoint_config.get("key_prefix", "")
        api_key_to_use = selected_endpoint_config["key"] # La clé réelle

        if key_field_to_use and key_location_to_use:
            if key_location_to_use == "param":
                request_params[key_field_to_use] = api_key_to_use
            elif key_location_to_use == "header":
                request_headers[key_field_to_use] = f"{key_prefix}{api_key_to_use}"
            elif key_location_to_use == "auth_basic":
                # Pour Twilio, api_key est un tuple (sid, secret)
                if isinstance(api_key_to_use, tuple) and len(api_key_to_use) == 2:
                    auth = httpx.BasicAuth(api_key_to_use[0], api_key_to_use[1])
                else:
                    log_message(f"Clé API pour auth_basic non valide pour {self.name}:{endpoint_key_for_health}", level="error")
                    endpoint_health_manager.update_endpoint_health(self.name, endpoint_key_for_health, False, 0.0)
                    return {"error": True, "message": "Configuration d'authentification basique invalide."}

        current_delay = initial_delay
        for attempt in range(max_retries):
            start_time = time.monotonic()
            success = False
            try:
                async with httpx.AsyncClient(timeout=timeout) as client:
                    response = await client.request(method_to_use, url_to_use, params=request_params, headers=request_headers, json=request_json_data, auth=auth)
                    response.raise_for_status() # Lève une exception pour les codes d'erreur HTTP
                    success = True
                    return response.json()
            except httpx.HTTPStatusError as e:
                log_message(f"API {self.name} erreur HTTP (tentative {attempt+1}/{max_retries}): {e.response.status_code} - {e.response.text}", level="warning")
                # Ne pas réessayer pour les erreurs client (4xx) sauf 429 (Too Many Requests)
                if 400 <= e.response.status_code < 500 and e.response.status_code != 429:
                    log_message(f"API {self.name}: Erreur client {e.response.status_code}, pas de réessai.", level="error")
                    endpoint_health_manager.update_endpoint_health(self.name, endpoint_key_for_health, False, e.response.elapsed.total_seconds())
                    return {"error": True, "status_code": e.response.status_code, "message": e.response.text}
                
                # Réessayer pour les erreurs serveur ou timeouts ou 429
                if attempt < max_retries - 1:
                    log_message(f"API {self.name}: Réessai dans {current_delay:.2f}s...", level="info")
                    await asyncio.sleep(current_delay)
                    current_delay *= 2 # Backoff exponentiel
            except httpx.RequestError as e:
                log_message(f"API {self.name} erreur de requête (tentative {attempt+1}/{max_retries}): {e}", level="warning")
                if attempt < max_retries - 1:
                    log_message(f"API {self.name}: Réessai dans {current_delay:.2f}s...", level="info")
                    await asyncio.sleep(current_delay)
                    current_delay *= 2
            except json.JSONDecodeError:
                log_message(f"API {self.name} erreur de décodage JSON (tentative {attempt+1}/{max_retries}): {response.text if 'response' in locals() else 'N/A'}", level="error")
                # Si la réponse n'est pas JSON, c'est probablement une erreur persistante
                endpoint_health_manager.update_endpoint_health(self.name, endpoint_key_for_health, False, time.monotonic() - start_time)
                return {"error": True, "message": "Réponse JSON invalide de l'API"}
            except Exception as e:
                log_message(f"API {self.name} erreur inattendue (tentative {attempt+1}/{max_retries}): {e}", level="error")
                endpoint_health_manager.update_endpoint_health(self.name, endpoint_key_for_health, False, time.monotonic() - start_time)
                return {"error": True, "message": str(e)}
            finally:
                if not success: # Si l'exception a été levée
                    latency = time.monotonic() - start_time
                    endpoint_health_manager.update_endpoint_health(self.name, endpoint_key_for_health, False, latency)
        
        # Si toutes les tentatives ont échoué
        log_message(f"API {self.name}: Toutes les tentatives ont échoué après {max_retries} réessais.", level="error")
        return {"error": True, "message": f"Échec de la requête après {max_retries} tentatives."}

    async def query(self, *args, **kwargs) -> Any:
        """Méthode abstraite pour interroger l'API."""
        raise NotImplementedError("La méthode query doit être implémentée par les sous-classes.")

# --- FIN DU BLOC CLIENT API (BASE) ---

# --- DEBUT DU BLOC CLIENTS API SPECIFIQUES ---

class DeepSeekClient(APIClient):
    def __init__(self):
        super().__init__("DEEPSEEK")

    async def query(self, prompt: str, model: str = "deepseek-chat") -> str:
        payload = {"model": model, "messages": [{"role": "user", "content": prompt}]}
        response = await self._make_request(json_data=payload)
        if response and not response.get("error"):
            return response.get("choices", [{}])[0].get("message", {}).get("content", "Pas de réponse de DeepSeek.")
        return f"Erreur DeepSeek: {response.get('message', 'Inconnu')}" if response else "DeepSeek: Réponse vide."

class SerperClient(APIClient):
    def __init__(self):
        super().__init__("SERPER")

    async def query(self, query_text: str) -> str:
        payload = {"q": query_text}
        response = await self._make_request(json_data=payload)
        if response and not response.get("error"):
            organic_results = response.get("organic", [])
            if organic_results:
                snippet = organic_results[0].get("snippet", "Pas de snippet.")
                link = organic_results[0].get("link", "")
                return f"Serper (recherche web):\n{snippet} {neutralize_urls(link)}"
            return "Serper: Aucune information trouvée."
        return f"Erreur Serper: {response.get('message', 'Inconnu')}" if response else "Serper: Réponse vide."

class WolframAlphaClient(APIClient):
    def __init__(self):
        super().__init__("WOLFRAMALPHA")

    async def query(self, input_text: str) -> str:
        params = {"input": input_text}
        response = await self._make_request(params=params)
        if response and not response.get("error"):
            pods = response.get("queryresult", {}).get("pods", [])
            if pods:
                for pod in pods:
                    if pod.get("title") in ["Result", "Input interpretation", "Decimal approximation"]:
                        subpods = pod.get("subpods", [])
                        if subpods and subpods[0].get("plaintext"):
                            return f"WolframAlpha:\n{subpods[0]['plaintext']}"
                if pods and pods[0].get("subpods") and pods[0]["subpods"][0].get("plaintext"):
                    return f"WolframAlpha:\n{pods[0]['subpods'][0]['plaintext']}"
            return "WolframAlpha: Pas de résultat clair."
        return f"Erreur WolframAlpha: {response.get('message', 'Inconnu')}" if response else "WolframAlpha: Réponse vide."

class TavilyClient(APIClient):
    def __init__(self):
        super().__init__("TAVILY")

    async def query(self, query_text: str, max_results: int = 3) -> str:
        payload = {"query": query_text, "max_results": max_results}
        response = await self._make_request(json_data=payload)
        if response and not response.get("error"):
            results = response.get("results", [])
            answer = response.get("answer", "Aucune réponse directe trouvée.")

            output = f"Tavily (recherche web):\nRéponse directe: {answer}\n"
            if results:
                output += "Extraits pertinents:\n"
                for i, res in enumerate(results[:max_results]):
                    output += f"- {res.get('title', 'N/A')}: {res.get('content', 'N/A')} {neutralize_urls(res.get('url', ''))}\n"
            return output
        return f"Erreur Tavily: {response.get('message', 'Inconnu')}" if response else "Tavily: Réponse vide."

class ApiFlashClient(APIClient):
    def __init__(self):
        super().__init__("APIFLASH")

    async def query(self, url: str) -> str:
        params = {"url": url, "format": "jpeg", "full_page": "true"}
        response = await self._make_request(params=params)
        if response and not response.get("error"):
            # ApiFlash retourne directement l'image, pas un JSON.
            # La requête _make_request s'attend à du JSON, donc on doit gérer ça.
            # Pour ApiFlash, l'URL de capture est le résultat.
            selected_endpoint_config = endpoint_health_manager.get_best_endpoint(self.name)
            if selected_endpoint_config:
                capture_url = f"{selected_endpoint_config['url']}?access_key={selected_endpoint_config['key']}&url={url}"
                return f"ApiFlash (capture d'écran): {neutralize_urls(capture_url)} (Vérifiez le lien pour l'image)"
            return "ApiFlash: Impossible de générer l'URL de capture."
        # If _make_request returned an error dict, pass it along
        return f"Erreur ApiFlash: {response.get('message', 'Inconnu')}" if response else "ApiFlash: Réponse vide."

class CrawlbaseClient(APIClient):
    def __init__(self):
        super().__init__("CRAWLBASE")

    async def query(self, url: str, use_js: bool = False) -> str:
        params = {"url": url, "format": "json"}
        
        # Sélectionner l'endpoint approprié (HTML ou JS)
        selected_endpoint_config = None
        if use_js:
            for config in self.endpoints_config:
                if "JS Scraping" in config.get("endpoint_name", ""):
                    selected_endpoint_config = config
                    break
        
        # Si pas d'endpoint JS ou si use_js est False, tenter de récupérer le meilleur endpoint générique
        if not selected_endpoint_config:
            selected_endpoint_config = endpoint_health_manager.get_best_endpoint(self.name)

        if not selected_endpoint_config:
            return {"error": True, "message": f"Aucun endpoint sain ou disponible pour {self.name}."}

        # Manuellement faire la requête pour s'assurer que la bonne configuration d'endpoint est utilisée
        response = await self._make_request(
            params=params,
            url=selected_endpoint_config["url"], # Surcharge l'URL avec l'URL de l'endpoint sélectionné
            method=selected_endpoint_config["method"],
            key_field=selected_endpoint_config["key_field"],
            key_location=selected_endpoint_config["key_location"],
            api_key=selected_endpoint_config["key"],
            fixed_params=selected_endpoint_config.get("fixed_params", {}) # Inclure les paramètres fixes de la configuration sélectionnée
        )

        if response and not response.get("error"):
            body = response.get("body")
            if body:
                try:
                    decoded_body = base64.b64decode(body).decode('utf-8', errors='ignore')
                    return f"Crawlbase (contenu web):\n{decoded_body[:1000]}..." # Tronquer pour la brièveté
                except Exception:
                    return f"Crawlbase (contenu web - brut):\n{body[:1000]}..."
            return "Crawlbase: Contenu non trouvé."
        return f"Erreur Crawlbase: {response.get('message', 'Inconnu')}" if response else "Crawlbase: Réponse vide."

class DetectLanguageClient(APIClient):
    def __init__(self):
        super().__init__("DETECTLANGUAGE")

    async def query(self, text: str) -> str:
        payload = {"q": text}
        response = await self._make_request(json_data=payload)
        if response and not response.get("error"):
            detections = response.get("data", {}).get("detections", [])
            if detections:
                first_detection = detections[0]
                lang = first_detection.get("language")
                confidence = first_detection.get("confidence")
                return f"Langue détectée: {lang} (confiance: {confidence})"
            return "DetectLanguage: Aucune langue détectée."
        return f"Erreur DetectLanguage: {response.get('message', 'Inconnu')}" if response else "DetectLanguage: Réponse vide."

class GuardianClient(APIClient):
    def __init__(self):
        super().__init__("GUARDIAN")

    async def query(self, query_text: str) -> str:
        params = {"q": query_text}
        response = await self._make_request(params=params)
        if response and not response.get("error"):
            results = response.get("response", {}).get("results", [])
            if results:
                output = "Articles The Guardian:\n"
                for res in results[:3]: # Limiter à 3 articles
                    output += f"- {res.get('webTitle', 'N/A')}: {res.get('fields', {}).get('trailText', 'N/A')} {neutralize_urls(res.get('webUrl', ''))}\n"
                return output
            return "Guardian: Aucun article trouvé."
        return f"Erreur Guardian: {response.get('message', 'Inconnu')}" if response else "Guardian: Réponse vide."

class IP2LocationClient(APIClient):
    def __init__(self):
        super().__init__("IP2LOCATION")

    async def query(self, ip_address: str) -> str:
        params = {"ip": ip_address}
        response = await self._make_request(params=params)
        if response and not response.get("error"):
            if "country_name" in response:
                return f"IP2Location (Géolocalisation IP {ip_address}): Pays: {response['country_name']}, Ville: {response.get('city_name', 'N/A')}"
            return "IP2Location: Informations non trouvées."
        return f"Erreur IP2Location: {response.get('message', 'Inconnu')}" if response else "IP2Location: Réponse vide."

class ShodanClient(APIClient):
    def __init__(self):
        super().__init__("SHODAN")

    async def query(self, query_text: str = "") -> str: # Query text est optionnel, car /api-info n'en a pas besoin
        # Shodan a divers endpoints. Cet exemple utilise /api-info.
        # Pour une recherche réelle, ce serait /shodan/host/search ou /shodan/scan
        # Pour simplifier, nous allons simplement interroger /api-info qui nous informe sur la clé.
        response = await self._make_request() # Aucun paramètre spécifique n'est nécessaire pour /api-info
        if response and not response.get("error"):
            return f"Shodan (info clé): Requêtes restantes: {response.get('usage_limits', {}).get('query_credits', 'N/A')}, Scan crédits: {response.get('usage_limits', {}).get('scan_credits', 'N/A')}"
        return f"Erreur Shodan: {response.get('message', 'Inconnu')}" if response else "Shodan: Réponse vide."

class WeatherAPIClient(APIClient):
    def __init__(self):
        super().__init__("WEATHERAPI")

    async def query(self, location: str) -> str:
        params = {"q": location}
        response = await self._make_request(params=params)
        if response and not response.get("error"):
            current = response.get("current", {})
            location_info = response.get("location", {})
            if current and location_info:
                return (
                    f"Météo à {location_info.get('name', 'N/A')}, {location_info.get('country', 'N/A')}:\n"
                    f"Température: {current.get('temp_c', 'N/A')}°C, "
                    f"Conditions: {current.get('condition', {}).get('text', 'N/A')}, "
                    f"Vent: {current.get('wind_kph', 'N/A')} km/h"
                )
            return "WeatherAPI: Données météo non trouvées."
        return f"Erreur WeatherAPI: {response.get('message', 'Inconnu')}" if response else "WeatherAPI: Réponse vide."

class CloudmersiveClient(APIClient):
    def __init__(self):
        super().__init__("CLOUDMERSIVE")

    async def query(self, domain: str) -> str:
        payload = {"domain": domain}
        response = await self._make_request(json_data=payload)
        if response and not response.get("error"):
            return f"Cloudmersive (vérification de domaine {domain}): Valide: {response.get('ValidDomain', 'N/A')}, Type: {response.get('DomainType', 'N/A')}"
        return f"Erreur Cloudmersive: {response.get('message', 'Inconnu')}" if response else "Cloudmersive: Réponse vide."

class GreyNoiseClient(APIClient):
    def __init__(self):
        super().__init__("GREYNOISE")

    async def query(self, ip_address: str) -> str:
        # GreyNoise endpoint requires IP to be part of the URL path
        selected_endpoint_config = endpoint_health_manager.get_best_endpoint(self.name)
        if not selected_endpoint_config:
            return {"error": True, "message": f"Aucun endpoint sain ou disponible pour {self.name}."}

        # Manually construct URL for GreyNoise since IP is path param
        url = f"{selected_endpoint_config['url']}{ip_address}"
        method = selected_endpoint_config["method"]
        headers = {selected_endpoint_config["key_field"]: selected_endpoint_config["key"]}

        try:
            async with httpx.AsyncClient(timeout=30) as client:
                response = await client.request(method, url, headers=headers)
                response.raise_for_status()
                result = response.json()
                
                # Update health for this specific endpoint (not dynamic selection)
                endpoint_key_for_health = f"{selected_endpoint_config['endpoint_name']}-{selected_endpoint_config['key']}"
                endpoint_health_manager.update_endpoint_health(self.name, endpoint_key_for_health, True, response.elapsed.total_seconds())

                if result and not result.get("error"):
                    if result.get("noise"):
                        return f"GreyNoise (IP {ip_address}): C'est une IP 'bruit' (malveillante). Classification: {result.get('classification', 'N/A')}, Nom d'acteur: {result.get('actor', 'N/A')}"
                    return f"GreyNoise (IP {ip_address}): Pas de 'bruit' détecté. Statut: {result.get('status', 'N/A')}"
                return f"Erreur GreyNoise: {result.get('message', 'Inconnu')}" if result else "GreyNoise: Réponse vide."
        except httpx.HTTPStatusError as e:
            log_message(f"API {self.name} erreur HTTP: {e.response.status_code} - {e.response.text}", level="error")
            endpoint_key_for_health = f"{selected_endpoint_config['endpoint_name']}-{selected_endpoint_config['key']}"
            endpoint_health_manager.update_endpoint_health(self.name, endpoint_key_for_health, False, e.response.elapsed.total_seconds() if e.response else 0.0)
            return {"error": True, "status_code": e.response.status_code, "message": e.response.text}
        except Exception as e:
            log_message(f"API {self.name} erreur inattendue: {e}", level="error")
            endpoint_key_for_health = f"{selected_endpoint_config['endpoint_name']}-{selected_endpoint_config['key']}"
            endpoint_health_manager.update_endpoint_health(self.name, endpoint_key_for_health, False, 0.0) # No latency if request failed before sending
            return {"error": True, "message": str(e)}

class PulsediveClient(APIClient):
    def __init__(self):
        super().__init__("PULSEDIVE")

    async def query(self, indicator: str, type: str = "auto") -> str:
        params = {"indicator": indicator, "type": type}
        response = await self._make_request(params=params)
        if response and not response.get("error"):
            if response.get("results"):
                result = response["results"][0]
                return (
                    f"Pulsedive (Analyse {indicator}): Type: {result.get('type', 'N/A')}, "
                    f"Risk: {result.get('risk', 'N/A')}, "
                    f"Description: {result.get('description', 'N/A')[:200]}..."
                )
            return "Pulsedive: Aucun résultat d'analyse trouvé."
        return f"Erreur Pulsedive: {response.get('message', 'Inconnu')}" if response else "Pulsedive: Réponse vide."

class StormGlassClient(APIClient):
    def __init__(self):
        super().__init__("STORMGLASS")

    async def query(self, lat: float, lng: float, params: str = "airTemperature,waveHeight") -> str:
        now = int(time.time())
        request_params = {
            "lat": lat,
            "lng": lng,
            "params": params,
            "start": now,
            "end": now + 3600 # One hour from now
        }
        response = await self._make_request(params=request_params)
        if response and not response.get("error"):
            data = response.get("hours", [])
            if data:
                first_hour = data[0]
                temp = first_hour.get('airTemperature', [{}])[0].get('value', 'N/A')
                wave_height = first_hour.get('waveHeight', [{}])[0].get('value', 'N/A')
                return f"StormGlass (Météo maritime à {lat},{lng}): Température air: {temp}°C, Hauteur vagues: {wave_height}m"
            return "StormGlass: Données non trouvées."
        return f"Erreur StormGlass: {response.get('message', 'Inconnu')}" if response else "StormGlass: Réponse vide."

class LoginRadiusClient(APIClient):
    def __init__(self):
        super().__init__("LOGINRADIUS")

    async def query(self) -> str:
        response = await self._make_request()
        if response and not response.get("error"):
            return f"LoginRadius (Ping API): Statut: {response.get('Status', 'N/A')}, Message: {response.get('Message', 'N/A')}"
        return f"Erreur LoginRadius: {response.get('message', 'Inconnu')}" if response else "LoginRadius: Réponse vide."

class JsonbinClient(APIClient):
    def __init__(self):
        super().__init__("JSONBIN")

    async def query(self, data: Dict[str, Any], private: bool = True, bin_id: Optional[str] = None) -> str:
        # If bin_id is provided, it's a GET request to access a bin
        if bin_id:
            selected_endpoint_config = None
            for config in self.endpoints_config:
                if "Bin Access" in config.get("endpoint_name", ""):
                    selected_endpoint_config = config
                    break
            if not selected_endpoint_config:
                return {"error": True, "message": f"Aucun endpoint d'accès de bin sain ou disponible pour {self.name}."}

            url = f"{selected_endpoint_config['url']}/{bin_id}"
            method = "GET"
            headers = {selected_endpoint_config["key_field"]: selected_endpoint_config["key"]}
            
            response = await self._make_request(
                headers=headers,
                url=url,
                method=method
            )
            if response and not response.get("error"):
                return f"Jsonbin (Accès bin {bin_id}):\n{json.dumps(response, indent=2)}"
            return f"Erreur Jsonbin (Accès bin): {response.get('message', 'Inconnu')}" if response else "Jsonbin: Réponse vide."
        
        # Otherwise, it's a POST request to create a bin
        else:
            selected_endpoint_config = None
            for config in self.endpoints_config:
                if "Bin Create" in config.get("endpoint_name", ""):
                    selected_endpoint_config = config
                    break
            
            if not selected_endpoint_config:
                return {"error": True, "message": f"Aucun endpoint de création de bin sain ou disponible pour {self.name}."}

            url = selected_endpoint_config["url"]
            method = "POST"
            headers = {selected_endpoint_config["key_field"]: selected_endpoint_config["key"], "Content-Type": "application/json"}
            payload = {"record": data, "private": private}

            response = await self._make_request(
                json_data=payload,
                headers=headers,
                url=url,
                method=method
            )

            if response and not response.get("error"):
                return f"Jsonbin (Création de bin): ID: {response.get('metadata', {}).get('id', 'N/A')}, URL: {neutralize_urls(response.get('metadata', {}).get('url', 'N/A'))}"
            return f"Erreur Jsonbin (Création de bin): {response.get('message', 'Inconnu')}" if response else "Jsonbin: Réponse vide."

class HuggingFaceClient(APIClient):
    def __init__(self):
        super().__init__("HUGGINGFACE")

    async def query(self, model_name: str = "distilbert-base-uncased-finetuned-sst-2-english", input_text: str = "Hello world") -> str:
        # HuggingFace inference endpoint URL includes the model name
        selected_endpoint_config = endpoint_health_manager.get_best_endpoint(self.name)
        if not selected_endpoint_config:
            return {"error": True, "message": f"Aucun endpoint sain ou disponible pour {self.name}."}

        # Override URL for inference
        inference_url = f"https://api-inference.huggingface.co/models/{model_name}"
        
        # Ensure the key is added to headers as per config
        headers = {
            selected_endpoint_config["key_field"]: f"{selected_endpoint_config['key_prefix']}{selected_endpoint_config['key']}",
            "Content-Type": "application/json"
        }
        payload = {"inputs": input_text}

        response = await self._make_request(
            json_data=payload,
            headers=headers,
            url=inference_url,
            method="POST" # Inference is always POST
        )

        if response and not response.get("error"):
            if isinstance(response, list) and response:
                first_result = response[0]
                if isinstance(first_result, list) and first_result:
                    return f"HuggingFace ({model_name} - {first_result[0].get('label')}): Score {first_result[0].get('score', 'N/A'):.2f}"
                elif isinstance(first_result, dict) and "generated_text" in first_result:
                    return f"HuggingFace ({model_name}): {first_result.get('generated_text')}"
            return f"HuggingFace ({model_name}): Réponse non parsée. {response}"
        return f"Erreur HuggingFace: {response.get('message', 'Inconnu')}" if response else "HuggingFace: Réponse vide."

class TwilioClient(APIClient):
    def __init__(self):
        super().__init__("TWILIO")

    async def query(self) -> str:
        # Twilio uses Basic Auth, handled by _make_request
        response = await self._make_request()
        if response and not response.get("error"):
            # The balance endpoint returns balance and currency directly
            return f"Twilio (Balance): {response.get('balance', 'N/A')} {response.get('currency', 'N/A')}"
        return f"Erreur Twilio: {response.get('message', 'Inconnu')}" if response else "Twilio: Réponse vide."

class AbstractAPIClient(APIClient):
    def __init__(self):
        super().__init__("ABSTRACTAPI")

    async def query(self, input_value: str, api_type: str) -> str:
        params = {}
        target_endpoint_name = ""

        if api_type == "PHONE_VALIDATION":
            params["phone"] = input_value
            target_endpoint_name = "Phone Validation"
        elif api_type == "EMAIL_VALIDATION":
            params["email"] = input_value
            # Select one of the email validation keys
            target_endpoint_name = "Email Validation"
        elif api_type == "EXCHANGE_RATES":
            target_endpoint_name = "Exchange Rates"
        elif api_type == "HOLIDAYS":
            params["country"] = input_value if input_value else "US"
            params["year"] = datetime.now().year
            target_endpoint_name = "Holidays"
        else:
            return f"AbstractAPI: Type d'API '{api_type}' non supporté pour la requête."

        selected_endpoint_config = None
        for config in self.endpoints_config:
            if target_endpoint_name in config["endpoint_name"]:
                selected_endpoint_config = config
                break
        
        if not selected_endpoint_config:
            return {"error": True, "message": f"Aucun endpoint sain ou disponible pour {self.name} pour le type {api_type}."}

        response = await self._make_request(
            params=params,
            url=selected_endpoint_config["url"],
            method=selected_endpoint_config["method"],
            key_field=selected_endpoint_config["key_field"],
            key_location=selected_endpoint_config["key_location"],
            api_key=selected_endpoint_config["key"],
            fixed_params=selected_endpoint_config.get("fixed_params", {})
        )

        if response and not response.get("error"):
            if api_type == "PHONE_VALIDATION":
                return (
                    f"AbstractAPI (Validation Tél): Numéro: {response.get('phone', 'N/A')}, "
                    f"Valide: {response.get('valid', 'N/A')}, "
                    f"Pays: {response.get('country', {}).get('name', 'N/A')}"
                )
            elif api_type == "EMAIL_VALIDATION":
                return (
                    f"AbstractAPI (Validation Email): Email: {response.get('email', 'N/A')}, "
                    f"Valide: {response.get('is_valid_format', 'N/A')}, "
                    f"Deliverable: {response.get('is_deliverable', 'N/A')}"
                )
            elif api_type == "EXCHANGE_RATES":
                return f"AbstractAPI (Taux de change): Base: {response.get('base', 'N/A')}, Taux (USD): {response.get('exchange_rates', {}).get('USD', 'N/A')}"
            elif api_type == "HOLIDAYS":
                holidays = [h.get('name', 'N/A') for h in response if h.get('name')]
                return f"AbstractAPI (Jours fériés {params.get('country', 'US')} {params.get('year')}): {', '.join(holidays[:5])}..." if holidays else "Aucun jour férié trouvé."
            return f"AbstractAPI ({api_type}): Réponse brute: {response}"
        return f"Erreur AbstractAPI ({api_type}): {response.get('message', 'Inconnu')}" if response else "AbstractAPI: Réponse vide."
class GeminiAPIClient(APIClient):
    def __init__(self):
        super().__init__("GEMINI_API")

    async def query(self, prompt: str, model: str = "gemini-1.5-flash") -> str:
        payload = {"contents": [{"parts": [{"text": prompt}]}]}
        # Gemini API often requires the model name in the URL path
        selected_endpoint_config = endpoint_health_manager.get_best_endpoint(self.name)
        if not selected_endpoint_config:
            return {"error": True, "message": f"Aucun endpoint sain ou disponible pour {self.name}."}

        # Override URL for specific model generation
        generate_url = f"https://generativelanguage.googleapis.com/v1beta/models/{model}:generateContent"
        
        # Ensure the key is added to params as per config
        request_params = {selected_endpoint_config["key_field"]: selected_endpoint_config["key"]}

        response = await self._make_request(
            json_data=payload,
            params=request_params,
            url=generate_url,
            method="POST",
            timeout=60 # Longer timeout for LLM calls
        )

        if response and not response.get("error"):
            if response.get("candidates") and response["candidates"][0].get("content"):
                return response["candidates"][0]["content"]["parts"][0]["text"]
            return f"Gemini API: Pas de réponse générée. {response}"
        return f"Erreur Gemini API: {response.get('message', 'Inconnu')}" if response else "Gemini API: Réponse vide."

class GoogleCustomSearchClient(APIClient):
    def __init__(self):
        super().__init__("GOOGLE_CUSTOM_SEARCH")

    async def query(self, query_text: str) -> str:
        params = {"q": query_text}
        response = await self._make_request(params=params)
        if response and not response.get("error"):
            items = response.get("items", [])
            if items:
                output = "Google Custom Search:\n"
                for item in items[:3]: # Limit to 3 results
                    output += f"- {item.get('title', 'N/A')}: {item.get('snippet', 'N/A')} {neutralize_urls(item.get('link', ''))}\n"
                return output
            return "Google Custom Search: Aucun résultat trouvé."
        return f"Erreur Google Custom Search: {response.get('message', 'Inconnu')}" if response else "Google Custom Search: Réponse vide."

# OpenRouterClient a été supprimé comme demandé.

class RandommerClient(APIClient):
    def __init__(self):
        super().__init__("RANDOMMER")

    async def query(self, country_code: str = "US", quantity: int = 1) -> str:
        params = {"CountryCode": country_code, "Quantity": quantity}
        response = await self._make_request(params=params)
        if response and not response.get("error"):
            if isinstance(response, list) and response:
                return f"Randommer (Numéros de téléphone): {', '.join(response)}"
            return f"Randommer: {response}"
        return f"Erreur Randommer: {response.get('message', 'Inconnu')}" if response else "Randommer: Réponse vide."

class TomorrowIOClient(APIClient):
    def __init__(self):
        super().__init__("TOMORROW.IO")

    async def query(self, location: str, fields: List[str] = None) -> str:
        if fields is None:
            fields = ["temperature", "humidity", "windSpeed"]
        payload = {"location": location, "fields": fields, "units": "metric", "timesteps": ["1h"]}
        response = await self._make_request(json_data=payload)
        if response and not response.get("error"):
            data = response.get("data", {}).get("timelines", [{}])[0].get("intervals", [{}])[0].get("values", {})
            if data:
                output = f"Météo (Tomorrow.io) à {location}:\n"
                for field in fields:
                    output += f"- {field.capitalize()}: {data.get(field, 'N/A')}\n"
                return output
            return "Tomorrow.io: Données météo non trouvées."
        return f"Erreur Tomorrow.io: {response.get('message', 'Inconnu')}" if response else "Tomorrow.io: Réponse vide."

class OpenWeatherMapClient(APIClient):
    def __init__(self):
        super().__init__("OPENWEATHERMAP")

    async def query(self, location: str) -> str:
        params = {"q": location}
        response = await self._make_request(params=params)
        if response and not response.get("error"):
            main_data = response.get("main", {})
            weather_desc = response.get("weather", [{}])[0].get("description", "N/A")
            if main_data:
                return (
                    f"Météo (OpenWeatherMap) à {location}:\n"
                    f"Température: {main_data.get('temp', 'N/A')}°C, "
                    f"Ressenti: {main_data.get('feels_like', 'N/A')}°C, "
                    f"Humidité: {main_data.get('humidity', 'N/A')}%, "
                    f"Conditions: {weather_desc}"
                )
            return "OpenWeatherMap: Données météo non trouvées."
        return f"Erreur OpenWeatherMap: {response.get('message', 'Inconnu')}" if response else "OpenWeatherMap: Réponse vide."

class MockarooClient(APIClient):
    def __init__(self):
        super().__init__("MOCKAROO")

    async def query(self, count: int = 1, fields_json: str = None) -> str:
        # Mockaroo's 'fields' parameter often expects a JSON string, which needs to be URL-encoded for GET requests.
        # The default fixed_params already include a basic fields_json.
        params = {"count": count}
        if fields_json:
            params["fields"] = fields_json # Override default if provided

        response = await self._make_request(params=params)
        if response and not response.get("error"):
            return f"Mockaroo (Génération de données):\n{json.dumps(response, indent=2)}"
        return f"Erreur Mockaroo: {response.get('message', 'Inconnu')}" if response else "Mockaroo: Réponse vide."

class OpenPageRankClient(APIClient):
    def __init__(self):
        super().__init__("OPENPAGERANK")

    async def query(self, domains: List[str]) -> str:
        params = {"domains[]": domains}
        response = await self._make_request(params=params)
        if response and not response.get("error"):
            results = response.get("response", [])
            if results:
                output = "OpenPageRank (Classement de domaine):\n"
                for res in results:
                    output += f"- Domaine: {res.get('domain', 'N/A')}, PageRank: {res.get('page_rank', 'N/A')}\n"
                return output
            return "OpenPageRank: Aucun résultat trouvé."
        return f"Erreur OpenPageRank: {response.get('message', 'Inconnu')}" if response else "OpenPageRank: Réponse vide."

class RapidAPIClient(APIClient):
    def __init__(self):
        super().__init__("RAPIDAPI")

    async def query(self, api_name: str, **kwargs) -> str:
        # RapidAPI is a marketplace, so we need to select the specific API endpoint
        # based on 'api_name' argument.
        selected_endpoint_config = None
        for config in self.endpoints_config:
            if api_name.lower() in config["endpoint_name"].lower():
                selected_endpoint_config = config
                break
        
        if not selected_endpoint_config:
            return f"RapidAPI: Endpoint pour '{api_name}' non trouvé ou non configuré."

        # Manually build request based on selected_endpoint_config
        url = selected_endpoint_config["url"]
        method = selected_endpoint_config["method"]
        
        request_params = selected_endpoint_config.get("fixed_params", {}).copy()
        request_headers = selected_endpoint_config.get("fixed_headers", {}).copy()
        request_json_data = selected_endpoint_config.get("fixed_json", {}).copy()

        # Add dynamic kwargs to params/json_data
        if method == "GET":
            request_params.update(kwargs)
        elif method == "POST":
            request_json_data.update(kwargs)

        headers = {
            selected_endpoint_config["key_field"]: selected_endpoint_config["key"],
            "X-RapidAPI-Host": selected_endpoint_config["fixed_headers"].get("X-RapidAPI-Host") # Specific to RapidAPI
        }
        
        response = await self._make_request(
            params=request_params,
            headers=headers,
            json_data=request_json_data,
            url=url,
            method=method
        )

        if response and not response.get("error"):
            if api_name.lower() == "programming joke":
                return f"RapidAPI (Blague de Programmation): {response.get('setup', '')} - {response.get('punchline', '')}"
            elif api_name.lower() == "currency list quotes":
                return f"RapidAPI (Devises): {json.dumps(response, indent=2)}"
            elif api_name.lower() == "random fact":
                return f"RapidAPI (Fait Aléatoire): {response.get('text', 'N/A')}"
            return f"RapidAPI ({api_name}): {json.dumps(response, indent=2)}"
        return f"Erreur RapidAPI ({api_name}): {response.get('message', 'Inconnu')}" if response else "RapidAPI: Réponse vide."

# --- Instancier tous les clients API ---
ALL_API_CLIENTS = [
    DeepSeekClient(),
    SerperClient(),
    WolframAlphaClient(),
    TavilyClient(),
    ApiFlashClient(),
    CrawlbaseClient(),
    DetectLanguageClient(),
    GuardianClient(),
    IP2LocationClient(),
    ShodanClient(),
    WeatherAPIClient(),
    CloudmersiveClient(),
    GreyNoiseClient(),
    PulsediveClient(),
    StormGlassClient(),
    LoginRadiusClient(),
    JsonbinClient(),
    HuggingFaceClient(),
    TwilioClient(),
    AbstractAPIClient(),
    GeminiAPIClient(),
    GoogleCustomSearchClient(),
    RandommerClient(),
    TomorrowIOClient(),
    OpenWeatherMapClient(),
    MockarooClient(),
    OpenPageRankClient(),
    RapidAPIClient()
]

# --- FIN DU BLOC CLIENTS API SPECIFIQUES ---

# --- DEBUT DU BLOC GESTION MEMOIRE ET QUOTAS ---

class MemoryManager:
    def __init__(self):
        self.chat_history = load_json(HISTORY_FILE, [])
        self.long_term_memory = load_json(LONG_MEMORY_FILE, {})
        self.ia_status = load_json(IA_STATUS_FILE, {})
        self._initialize_ia_status()

    def _initialize_ia_status(self):
        """Initialise le statut des IA si elles ne sont pas déjà présentes ou si leur statut est obsolète."""
        now = get_current_time()
        updated = False
        for client in ALL_API_CLIENTS:
            if client.name not in self.ia_status:
                self.ia_status[client.name] = {
                    "last_used": None,
                    "last_error": None,
                    "error_count": 0,
                    "cooldown_until": None,
                    "success_count": 0,
                    "current_score": 1.0, # Maintenu pour la compatibilité, mais moins utilisé pour la sélection primaire
                    "last_rotation_check": format_datetime(now),
                    "diversification_score": 1.0 # Nouveau score pour la diversification
                }
                updated = True
            else:
                # S'assurer que les nouvelles clés existent pour les IA existantes
                if "success_count" not in self.ia_status[client.name]:
                    self.ia_status[client.name]["success_count"] = 0
                    updated = True
                if "current_score" not in self.ia_status[client.name]:
                    self.ia_status[client.name]["current_score"] = 1.0
                    updated = True
                if "last_rotation_check" not in self.ia_status[client.name]:
                    self.ia_status[client.name]["last_rotation_check"] = format_datetime(now)
                    updated = True
                if "diversification_score" not in self.ia_status[client.name]:
                    self.ia_status[client.name]["diversification_score"] = 1.0
                    updated = True

        if updated:
            save_json(IA_STATUS_FILE, self.ia_status)
            log_message("Statut des IA initialisé/mis à jour.")

    def add_message_to_history(self, role, content):
        """Ajoute un message à l'historique de la conversation."""
        self.chat_history.append({"role": role, "content": content, "timestamp": format_datetime(get_current_time())})
        self._prune_history()
        save_json(HISTORY_FILE, self.chat_history)
        log_message(f"Message ajouté à l'historique par {role}.")

    def get_chat_history(self, limit=10):
        """Retourne les N derniers messages de l'historique."""
        return self.chat_history[-limit:]

    def add_to_long_term_memory(self, key, value):
        """Ajoute une information à la mémoire à long terme."""
        self.long_term_memory[key] = {"value": value, "timestamp": format_datetime(get_current_time())}
        save_json(LONG_MEMORY_FILE, self.long_term_memory)
        log_message(f"Information ajoutée à la mémoire à long terme: {key}")

    def get_from_long_term_memory(self, key):
        """Récupère une information de la mémoire à long terme."""
        return self.long_term_memory.get(key)

    def update_ia_status(self, ia_name: str, success: bool, error_message: Optional[str] = None):
        """Met à jour le statut et le score d'une IA après une utilisation."""
        status = self.ia_status.get(ia_name)
        if not status:
            log_message(f"Tentative de mise à jour d'un statut d'IA inconnu: {ia_name}", level="warning")
            return

        now = get_current_time()
        status["last_used"] = format_datetime(now)

        if success:
            status["success_count"] += 1
            status["error_count"] = 0
            status["cooldown_until"] = None
            status["last_error"] = None
            status["current_score"] = min(1.0, status["current_score"] + 0.1)
            # Decrease diversification score on use
            status["diversification_score"] = max(0.1, status["diversification_score"] - 0.1)
            log_message(f"IA {ia_name} : Succès enregistré. Nouveau score: {status['current_score']:.2f}, Diversification: {status['diversification_score']:.2f}")
        else:
            status["error_count"] += 1
            status["last_error"] = error_message
            if status["error_count"] >= 3:
                status["cooldown_until"] = format_datetime(now + timedelta(seconds=API_COOLDOWN_DURATION_SECONDS))
                status["current_score"] = max(0.1, status["current_score"] - 0.2)
                log_message(f"IA {ia_name} : Trop d'erreurs ({status['error_count']}). Cooldown jusqu'à {status['cooldown_until']}. Nouveau score: {status['current_score']:.2f}", level="warning")
            else:
                 status["current_score"] = max(0.1, status["current_score"] - 0.05)
                 log_message(f"IA {ia_name} : Erreur enregistrée. Nouveau score: {status['current_score']:.2f}", level="warning")

        save_json(IA_STATUS_FILE, self.ia_status)

    def recover_diversification_scores(self):
        """Augmente le score de diversification pour les IA non utilisées récemment."""
        now = get_current_time()
        updated = False
        for ia_name, status in self.ia_status.items():
            last_used_str = status.get("last_used")
            if last_used_str:
                last_used_dt = datetime.strptime(last_used_str, "%Y-%m-%d %H:%M:%S UTC").replace(tzinfo=None)
                # If not used in the last API_ROTATION_INTERVAL_MINUTES * 2 (e.g., 60 mins), recover score
                if (now - last_used_dt).total_seconds() > API_ROTATION_INTERVAL_MINUTES * 60 * 2:
                    if status["diversification_score"] < 1.0:
                        status["diversification_score"] = min(1.0, status["diversification_score"] + 0.05)
                        updated = True
                        log_message(f"IA {ia_name}: Score de diversification récupéré à {status['diversification_score']:.2f}")
            else: # Never used, ensure it's at max
                if status["diversification_score"] < 1.0:
                    status["diversification_score"] = 1.0
                    updated = True
        if updated:
            save_json(IA_STATUS_FILE, self.ia_status)

    def get_ia_status(self, ia_name: str) -> Optional[Dict]:
        """Récupère le statut d'une IA."""
        return self.ia_status.get(ia_name)

    def get_available_ias(self) -> List[str]:
        """Retourne les noms des IA actuellement non en cooldown."""
        available = []
        now = get_current_time()
        for name, status in self.ia_status.items():
            cooldown_until_str = status.get("cooldown_until")
            if cooldown_until_str:
                cooldown_until = datetime.strptime(cooldown_until_str, "%Y-%m-%d %H:%M:%S UTC").replace(tzinfo=None)
                if now < cooldown_until:
                    continue
            available.append(name)
        return available

    def _prune_history(self, max_entries=50):
        """Supprime les anciennes entrées de l'historique si trop nombreuses."""
        if len(self.chat_history) > max_entries:
            self.chat_history = self.chat_history[-max_entries:]
            log_message(f"Historique de chat purgé, {len(self.chat_history)} entrées restantes.")

class QuotaManager:
    def __init__(self):
        self.quotas = load_json(QUOTAS_FILE, {})
        self._initialize_quotas()

    def _initialize_quotas(self):
        """Initialise les quotas pour toutes les APIs basées sur config.API_QUOTAS et nettoie/met à jour les existants."""
        updated = False
        now = get_current_time()

        # Step 1: Ensure all APIs from API_QUOTAS are in self.quotas with full structure
        for api_name, quota_info in API_QUOTAS.items():
            if api_name not in self.quotas:
                self.quotas[api_name] = {
                    "monthly_usage": 0,
                    "daily_usage": 0,
                    "hourly_usage": 0,
                    "hourly_timestamps": [],
                    "last_reset_month": now.month,
                    "last_reset_day": now.day,
                    "last_usage": None,
                    "total_calls": 0,
                    "last_hourly_reset": format_datetime(now)
                }
                updated = True
            else:
                # Ensure existing entries have all required keys
                default_quota_structure = {
                    "monthly_usage": 0,
                    "daily_usage": 0,
                    "hourly_usage": 0,
                    "hourly_timestamps": [],
                    "last_reset_month": now.month,
                    "last_reset_day": now.day,
                    "last_usage": None,
                    "total_calls": 0,
                    "last_hourly_reset": format_datetime(now)
                }
                for key, default_value in default_quota_structure.items():
                    if key not in self.quotas[api_name]:
                        self.quotas[api_name][key] = default_value
                        updated = True
                
                # Re-evaluate hourly_usage based on timestamps during initialization
                one_hour_ago = now - timedelta(hours=1)
                # Ensure hourly_timestamps is a list before filtering
                if not isinstance(self.quotas[api_name].get("hourly_timestamps"), list):
                    self.quotas[api_name]["hourly_timestamps"] = []
                    updated = True

                self.quotas[api_name]["hourly_timestamps"] = [
                    ts for ts in self.quotas[api_name]["hourly_timestamps"]
                    if datetime.strptime(ts, "%Y-%m-%d %H:%M:%S UTC").replace(tzinfo=None) > one_hour_ago
                ]
                self.quotas[api_name]["hourly_usage"] = len(self.quotas[api_name]["hourly_timestamps"])
                self.quotas[api_name]["last_hourly_reset"] = format_datetime(now) # Update reset time

        # Step 2: Remove any API names from self.quotas that are NOT in API_QUOTAS
        # This handles cases where invalid API names might have been added previously
        api_names_to_remove = [name for name in self.quotas if name not in API_QUOTAS]
        for name in api_names_to_remove:
            del self.quotas[name]
            updated = True
            log_message(f"API '{name}' trouvée dans quotas.json mais non définie dans API_QUOTAS. Supprimée.", level="warning")

        if updated:
            save_json(QUOTAS_FILE, self.quotas)
            log_message("Quotas API initialisés/mis à jour.")

    def _reset_quotas_if_needed(self):
        """Réinitialise les quotas journaliers, mensuels et horaires si nécessaire."""
        now = get_current_time()
        for api_name, data in self.quotas.items():
            # Reset mensuel
            if now.month != data["last_reset_month"]:
                data["monthly_usage"] = 0
                data["last_reset_month"] = now.month
                log_message(f"Quota mensuel pour {api_name} réinitialisé.")
            # Reset journalier
            if now.day != data["last_reset_day"]:
                data["daily_usage"] = 0
                data["last_reset_day"] = now.day
                log_message(f"Quota journalier pour {api_name} réinitialisé.")
            
            # Reset et gestion horaire (nettoyage des timestamps trop anciens)
            one_hour_ago = now - timedelta(hours=1)
            # Ensure hourly_timestamps is a list before filtering
            if not isinstance(data.get("hourly_timestamps"), list):
                data["hourly_timestamps"] = []
            
            data["hourly_timestamps"] = [
                ts for ts in data["hourly_timestamps"]
                if datetime.strptime(ts, "%Y-%m-%d %H:%M:%S UTC").replace(tzinfo=None) > one_hour_ago
            ]
            data["hourly_usage"] = len(data["hourly_timestamps"])
            
            # Update last_hourly_reset to current time if a reset happened or after cleanup
            data["last_hourly_reset"] = format_datetime(now)

        save_json(QUOTAS_FILE, self.quotas)

    def check_and_update_quota(self, api_name: str, cost: int = 1) -> bool:
        """Vérifie si une API a du quota et le décrémente. Retourne True si ok, False sinon."""
        self._reset_quotas_if_needed()
        
        # IMPORTANT: Only process if api_name is a valid, configured API
        if api_name not in API_QUOTAS:
            log_message(f"Tentative de vérification de quota pour une API non définie: {api_name}. Autorisation refusée.", level="error")
            return False # Prevent processing for undefined APIs

        if api_name not in self.quotas:
            # This case should ideally not happen after robust initialization, but as a fallback
            log_message(f"API {api_name} non trouvée dans les quotas gérés. Re-initialisation.", level="warning")
            self._initialize_quotas() # Re-initialize to ensure it's added
            if api_name not in self.quotas: # If still not there after re-init, something is fundamentally wrong
                log_message(f"API {api_name} toujours introuvable après re-initialisation. Autorisation refusée.", level="error")
                return False


        quota_data = self.quotas[api_name]
        api_limits = API_QUOTAS.get(api_name, {})
        now = get_current_time()

        monthly_limit = api_limits.get("monthly")
        if monthly_limit is not None and (quota_data["monthly_usage"] + cost) > monthly_limit:
            log_message(f"Quota mensuel dépassé pour {api_name}", level="warning")
            return False

        daily_limit = api_limits.get("daily")
        if daily_limit is not None and (quota_data["daily_usage"] + cost) > daily_limit:
            log_message(f"Quota journalier dépassé pour {api_name}", level="warning")
            return False
        
        hourly_limit = api_limits.get("hourly")
        if hourly_limit is not None and (quota_data["hourly_usage"] + cost) > hourly_limit:
            log_message(f"Quota horaire dépassé pour {api_name}", level="warning")
            return False

        rate_limit_per_sec = api_limits.get("rate_limit_per_sec")
        if rate_limit_per_sec:
            last_usage_str = quota_data.get("last_usage")
            if last_usage_str:
                last_usage = datetime.strptime(last_usage_str, "%Y-%m-%d %H:%M:%S UTC").replace(tzinfo=None)
                time_since_last_call = (now - last_usage).total_seconds()
                if time_since_last_call < (1 / rate_limit_per_sec):
                    log_message(f"Taux de requêtes dépassé pour {api_name}. Attendre {1/rate_limit_per_sec - time_since_last_call:.2f}s", level="warning")
                    return False

        quota_data["monthly_usage"] += cost
        quota_data["daily_usage"] += cost
        quota_data["hourly_usage"] += cost
        quota_data["hourly_timestamps"].append(format_datetime(now)) # Add current timestamp
        quota_data["total_calls"] += cost
        quota_data["last_usage"] = format_datetime(now)
        save_json(QUOTAS_FILE, self.quotas)
        log_message(f"Quota pour {api_name} mis à jour. Usage mensuel: {quota_data['monthly_usage']}/{monthly_limit if monthly_limit else 'Illimité'}, Journalier: {quota_data['daily_usage']}/{daily_limit if daily_limit else 'Illimité'}, Horaire: {quota_data['hourly_usage']}/{hourly_limit if hourly_limit else 'Illimité'}")
        return True

    def get_api_usage(self, api_name: str) -> Optional[Dict]:
        """Retourne les informations d'utilisation d'une API."""
        return self.quotas.get(api_name)

    def get_all_quotas_status(self) -> Dict:
        """Retourne le statut de tous les quotas."""
        self._reset_quotas_if_needed()
        status = {}
        for api_name, quota_data in self.quotas.items():
            api_limits = API_QUOTAS.get(api_name, {})
            monthly_limit = api_limits.get("monthly", "Illimité")
            daily_limit = api_limits.get("daily", "Illimité")
            hourly_limit = api_limits.get("hourly", "Illimité")
            status[api_name] = {
                "monthly_usage": quota_data["monthly_usage"],
                "monthly_limit": monthly_limit,
                "daily_usage": quota_data["daily_usage"],
                "daily_limit": daily_limit,
                "hourly_usage": quota_data["hourly_usage"],
                "hourly_limit": hourly_limit,
                "total_calls": quota_data["total_calls"],
                "last_usage": quota_data["last_usage"],
                "last_reset_month": quota_data["last_reset_month"],
                "last_reset_day": quota_data["last_reset_day"],
                "last_hourly_reset": quota_data["last_hourly_reset"]
            }
        return status

    def get_burn_window_apis(self) -> List[str]:
        """
        Identifie les APIs dont les quotas sont sur le point d'être réinitialisés
        et où il est opportun de "brûler" le quota restant.
        """
        burn_apis = []
        now = get_current_time()
        for api_name, data in self.quotas.items():
            api_limits = API_QUOTAS.get(api_name, {})

            if api_limits.get("monthly") is not None:
                next_month_reset = datetime(now.year + (1 if now.month == 12 else 0), (now.month % 12) + 1, 1).replace(tzinfo=None)
                if is_within_time_window(next_month_reset, QUOTA_BURN_WINDOW_HOURS * 60, 0):
                    if data["monthly_usage"] < api_limits["monthly"]:
                        burn_apis.append(f"{api_name} (mensuel: {api_limits['monthly'] - data['monthly_usage']} restants)")

            if api_limits.get("daily") is not None:
                next_day_reset = datetime(now.year, now.month, now.day).replace(tzinfo=None) + timedelta(days=1)
                if is_within_time_window(next_day_reset, QUOTA_BURN_WINDOW_HOURS * 60, 0):
                    if data["daily_usage"] < api_limits["daily"]:
                        burn_apis.append(f"{api_name} (journalier: {api_limits['daily'] - data['daily_usage']} restants)")
        return burn_apis

# Instanciation des gestionnaires
memory_manager = MemoryManager()
quota_manager = QuotaManager()

import time
from telegram import Update, ForceReply
from telegram.ext import Application, CommandHandler, MessageHandler, filters, ContextTypes

# --- Orchestration des IA ---
class IAOrchestrator:
    def __init__(self, memory_manager: MemoryManager, quota_manager: QuotaManager, api_clients: List[APIClient]):
        self.memory_manager = memory_manager
        self.quota_manager = quota_manager
        self.api_clients = {client.name: client for client in api_clients}
        self.last_strategy_rotation_time = get_current_time()
        self.current_ia_strategy = self._determine_initial_strategy()

        # Les cinq moteurs IA principaux
        self.core_ai_engines = {
            "DEEPSEEK": self.api_clients.get("DEEPSEEK"),
            "HUGGINGFACE": self.api_clients.get("HUGGINGFACE"),
            "GOOGLE_CUSTOM_SEARCH": self.api_clients.get("GOOGLE_CUSTOM_SEARCH"),
            "GEMINI_API": self.api_clients.get("GEMINI_API")
        }
        # Filtrer les clients None si l'API n'est pas configurée
        self.core_ai_engines = {k: v for k, v in self.core_ai_engines.items() if v is not None}

        # Définir les "agents mixtes" et leurs capacités (simplified for example)
        # En réalité, ceci serait un système de routing basé sur des modèles NLP plus complexes.
        self.mixed_agents = [
            {"name": "GeneralQueryAgent", "primary_ais": ["DEEPSEEK", "GEMINI_API", "GOOGLE_CUSTOM_SEARCH"], "tools": ["SERPER", "TAVILY", "WOLFRAMALPHA", "WEATHERAPI", "OPENWEATHERMAP"]},
            {"name": "CodingAgent", "primary_ais": ["DEEPSEEK", "HUGGINGFACE", "GEMINI_API"], "tools": []}, # Tools are sandbox/analyzer
            {"name": "SecurityAgent", "primary_ais": ["DEEPSEEK", "GEMINI_API"], "tools": ["IP2LOCATION", "SHODAN", "GREYNOISE", "PULSEDIVE", "CLOUDMERSIVE"]},
            {"name": "DataAgent", "primary_ais": ["DEEPSEEK", "GEMINI_API"], "tools": ["JSONBIN", "MOCKAROO", "RANDOMMER", "OPENPAGERANK", "RAPIDAPI"]},
            {"name": "CommunicationAgent", "primary_ais": ["DEEPSEEK", "GEMINI_API"], "tools": ["TWILIO", "ABSTRACTAPI"]},
            {"name": "NewsAgent", "primary_ais": ["DEEPSEEK", "GEMINI_API"], "tools": ["GUARDIAN", "SERPER", "TAVILY"]},
            {"name": "ImageAgent", "primary_ais": ["DEEPSEEK", "GEMINI_API"], "tools": ["APIFLASH"]}, # OCR tool is separate
            {"name": "LanguageAgent", "primary_ais": ["DEEPSEEK", "GEMINI_API"], "tools": ["DETECTLANGUAGE"]},
            {"name": "WeatherAgent", "primary_ais": ["DEEPSEEK", "GEMINI_API"], "tools": ["WEATHERAPI", "STORMGLASS", "TOMORROW.IO", "OPENWEATHERMAP"]}
        ]
        self.current_agent_index = 0
        self.last_agent_rotation_time = get_current_time()

        # Tool descriptions for AI
        self.tool_descriptions = {
            "SERPER": "Effectue une recherche web sur Google et retourne les snippets et liens pertinents. Paramètres: {\"query\": \"texte de recherche\"}",
            "TAVILY": "Effectue une recherche web avancée et retourne une réponse directe et des extraits. Paramètres: {\"query\": \"texte de recherche\", \"max_results\": nombre}",
            "WOLFRAMALPHA": "Répond à des questions factuelles et calculs complexes. Paramètres: {\"input\": \"question ou calcul\"}",
            "WEATHERAPI": "Fournit la météo actuelle et les prévisions pour une localisation donnée. Paramètres: {\"location\": \"nom de la ville ou code postal\"}",
            "OPENWEATHERMAP": "Fournit la météo actuelle pour une localisation donnée. Paramètres: {\"location\": \"nom de la ville ou code postal\"}",
            "STORMGLASS": "Fournit des données météorologiques maritimes (température, vagues) pour des coordonnées lat/lng. Paramètres: {\"lat\": latitude, \"lng\": longitude, \"params\": \"airTemperature,waveHeight\"}",
            "APIFLASH": "Prend une capture d'écran d'une URL et retourne l'URL de l'image. Paramètres: {\"url\": \"URL du site\"}",
            "CRAWLBASE": "Récupère le contenu HTML ou JavaScript d'une URL. Paramètres: {\"url\": \"URL du site\", \"use_js\": true/false}",
            "DETECTLANGUAGE": "Détecte la langue d'un texte. Paramètres: {\"text\": \"texte à analyser\"}",
            "IP2LOCATION": "Géolocalise une adresse IP. Paramètres: {\"ip_address\": \"adresse IP\"}",
            "SHODAN": "Fournit des informations sur les hôtes et les services exposés sur Internet. Paramètres: {\"query\": \"texte de recherche\"} (optionnel)",
            "GREYNOISE": "Analyse une adresse IP pour déterminer si elle est 'bruit' (malveillante). Paramètres: {\"ip_address\": \"adresse IP\"}",
            "PULSEDIVE": "Analyse des indicateurs de menace (IP, domaine, URL). Paramètres: {\"indicator\": \"indicateur\", \"type\": \"auto\"}",
            "CLOUDMERSIVE": "Vérifie la validité d'un nom de domaine. Paramètres: {\"domain\": \"nom de domaine\"}",
            "JSONBIN": "Stocke ou récupère des données JSON dans un 'bin' privé ou public. Pour créer: {\"data\": {\"clé\": \"valeur\"}, \"private\": true/false}. Pour accéder: {\"bin_id\": \"ID du bin\"}",
            "MOCKAROO": "Génère des données de test aléatoires basées sur des schémas. Paramètres: {\"count\": nombre, \"fields_json\": \"[{\"name\": \"champ\", \"type\": \"Type Mockaroo\"}]\"}",
            "RANDOMMER": "Génère des données aléatoires, comme des numéros de téléphone. Paramètres: {\"country_code\": \"US\", \"quantity\": 1}",
            "OPENPAGERANK": "Récupère le PageRank d'un ou plusieurs domaines. Paramètres: {\"domains\": [\"domaine1.com\", \"domaine2.com\"]}",
            "RAPIDAPI": "Accède à diverses micro-APIs (blagues, faits, devises). Nécessite un 'api_name' (ex: 'Programming Joke'). Paramètres: {\"api_name\": \"Nom de l'API\", \"kwargs\": {\"param1\": \"valeur1\"}}",
            "TWILIO": "Vérifie le solde du compte Twilio. Paramètres: Aucun",
            "ABSTRACTAPI": "Valide des emails, numéros de téléphone, géolocalise des IPs, ou fournit des taux de change/jours fériés. Paramètres: {\"input_value\": \"valeur\", \"api_type\": \"EMAIL_VALIDATION\"|\"PHONE_VALIDATION\"|\"EXCHANGE_RATES\"|\"HOLIDAYS\"}"
        }

    def _determine_initial_strategy(self) -> str:
        """Détermine la stratégie initiale ou la stratégie par défaut."""
        return "balanced"

    def _rotate_strategy_if_needed(self):
        """Change la stratégie d'IA et l'agent si l'intervalle de rotation est passé."""
        now = get_current_time()
        if (now - self.last_strategy_rotation_time).total_seconds() >= API_ROTATION_INTERVAL_MINUTES * 60:
            strategies = ["balanced", "cost_effective", "performance"]
            self.current_ia_strategy = random.choice(strategies)
            self.last_strategy_rotation_time = now
            log_message(f"Stratégie d'IA changée pour: {self.current_ia_strategy}")

            # Rotation des agents mixtes
            self.current_agent_index = (self.current_agent_index + 1) % len(self.mixed_agents)
            self.last_agent_rotation_time = now
            log_message(f"Agent mixte actuel: {self.mixed_agents[self.current_agent_index]['name']}")

            # Mettre à jour le last_rotation_check pour toutes les IA et récupérer les scores de diversification
            for ia_name in self.memory_manager.ia_status:
                self.memory_manager.ia_status[ia_name]["last_rotation_check"] = format_datetime(now)
            self.memory_manager.recover_diversification_scores() # Recover diversification scores
            save_json(IA_STATUS_FILE, self.memory_manager.ia_status)

    async def _select_primary_ai_for_agent(self, agent_config: Dict) -> Optional[APIClient]:
        """
        Sélectionne une IA primaire parmi celles de l'agent.
        La sélection est désormais équitable, sans privilégier une IA par rapport à une autre en fonction des scores.
        """
        available_primary_ais = []
        for ai_name in agent_config["primary_ais"]:
            if ai_name in self.core_ai_engines:
                status = self.memory_manager.get_ia_status(ai_name)
                # Vérifier si l'IA n'est pas en cooldown
                if status and (status.get("cooldown_until") is None or datetime.strptime(status["cooldown_until"], "%Y-%m-%d %H:%M:%S UTC").replace(tzinfo=None) < get_current_time()):
                    # Vérifier le quota sans le consommer pour la sélection
                    if self.quota_manager.check_and_update_quota(ai_name, cost=0):
                        available_primary_ais.append(ai_name)
        
        if not available_primary_ais:
            log_message(f"Aucune IA primaire disponible pour l'agent {agent_config['name']}.", level="warning")
            return None

        # Sélection aléatoire et équitable parmi les IA disponibles
        selected_ai_name = random.choice(available_primary_ais)
        
        # Consommer le quota pour l'IA sélectionnée
        if self.quota_manager.check_and_update_quota(selected_ai_name):
            log_message(f"IA primaire sélectionnée pour l'agent: {selected_ai_name} (Sélection équitable)")
            return self.core_ai_engines[selected_ai_name]
        
        # Ce cas ne devrait pas arriver souvent si le check_and_update_quota(cost=0) a réussi
        # mais c'est une sécurité.
        log_message(f"IA {selected_ai_name} sélectionnée mais quota non disponible au moment de la consommation.", level="warning")
        return None


    async def _run_agent_with_tools(self, agent_config: Dict, query: str) -> str:
        """
        Exécute l'agent mixte en utilisant l'IA primaire sélectionnée
        et en sollicitant les outils pertinents.
        """
        primary_ai_client = await self._select_primary_ai_for_agent(agent_config)
        if not primary_ai_client:
            return f"Désolé, l'agent {agent_config['name']} ne peut pas opérer car aucune IA primaire n'est disponible.", []

        responses = []
        tools_called_for_report = []
        
        # Prepare tool descriptions for the AI
        available_tools_for_ai = {}
        for tool_name in agent_config.get("tools", []):
            if tool_name in self.tool_descriptions and self.api_clients.get(tool_name):
                available_tools_for_ai[tool_name] = self.tool_descriptions[tool_name]
        
        tool_prompt_part = ""
        if available_tools_for_ai:
            tool_prompt_part = "\n\nTu as accès aux outils suivants:\n"
            for tool_name, desc in available_tools_for_ai.items():
                tool_prompt_part += f"- **{tool_name}**: {desc}\n"
            tool_prompt_part += "\nSi tu as besoin d'utiliser un outil, réponds avec le format suivant: `TOOL_CALL:<nom_outil>:<paramètres_json>`. Par exemple: `TOOL_CALL:WEATHERAPI:{\"location\": \"Paris\"}`. Sinon, réponds normalement."
        
        full_prompt_for_ai = f"{query}{tool_prompt_part}"

        # 1. Obtenir une première réponse de l'IA primaire
        log_message(f"Agent {agent_config['name']} utilise {primary_ai_client.name} pour la requête: '{query}'")
        primary_response_raw = await primary_ai_client.query(full_prompt_for_ai)
        self.memory_manager.update_ia_status(primary_ai_client.name, not primary_response_raw.startswith("Erreur"))
        
        # Check for tool calls in the primary AI's response
        tool_call_match = re.match(r"TOOL_CALL:([A-Z_]+):(.+)", primary_response_raw)
        if tool_call_match:
            tool_name = tool_call_match.group(1)
            params_str = tool_call_match.group(2)
            
            try:
                tool_params = json.loads(params_str)
                tool_client = self.api_clients.get(tool_name)
                if tool_client and self.quota_manager.check_and_update_quota(tool_name):
                    log_message(f"Agent {agent_config['name']} exécute l'outil {tool_name} avec les paramètres: {tool_params}")
                    
                    tool_response = ""
                    # Dynamic tool call based on tool_name and parsed params
                    # This requires careful mapping of tool_params to actual method arguments
                    if tool_name == "SERPER":
                        tool_response = await tool_client.query(query_text=tool_params.get("query"))
                    elif tool_name == "TAVILY":
                        tool_response = await tool_client.query(query_text=tool_params.get("query"), max_results=tool_params.get("max_results", 3))
                    elif tool_name == "WOLFRAMALPHA":
                        tool_response = await tool_client.query(input_text=tool_params.get("input"))
                    elif tool_name == "WEATHERAPI":
                        tool_response = await tool_client.query(location=tool_params.get("location"))
                    elif tool_name == "OPENWEATHERMAP":
                        tool_response = await tool_client.query(location=tool_params.get("location"))
                    elif tool_name == "STORMGLASS":
                        tool_response = await tool_client.query(lat=tool_params.get("lat"), lng=tool_params.get("lng"), params=tool_params.get("params", "airTemperature,waveHeight"))
                    elif tool_name == "APIFLASH":
                        tool_response = await tool_client.query(url=tool_params.get("url"))
                    elif tool_name == "CRAWLBASE":
                        tool_response = await tool_client.query(url=tool_params.get("url"), use_js=tool_params.get("use_js", False))
                    elif tool_name == "DETECTLANGUAGE":
                        tool_response = await tool_client.query(text=tool_params.get("text"))
                    elif tool_name == "IP2LOCATION":
                        tool_response = await tool_client.query(ip_address=tool_params.get("ip_address"))
                    elif tool_name == "SHODAN":
                        tool_response = await tool_client.query(query_text=tool_params.get("query", ""))
                    elif tool_name == "GREYNOISE":
                        tool_response = await tool_client.query(ip_address=tool_params.get("ip_address"))
                    elif tool_name == "PULSEDIVE":
                        tool_response = await tool_client.query(indicator=tool_params.get("indicator"), type=tool_params.get("type", "auto"))
                    elif tool_name == "CLOUDMERSIVE":
                        tool_response = await tool_client.query(domain=tool_params.get("domain"))
                    elif tool_name == "JSONBIN":
                        if "bin_id" in tool_params:
                            tool_response = await tool_client.query(bin_id=tool_params["bin_id"])
                        else:
                            tool_response = await tool_client.query(data=tool_params.get("data", {}), private=tool_params.get("private", True))
                    elif tool_name == "MOCKAROO":
                        tool_response = await tool_client.query(count=tool_params.get("count", 1), fields_json=tool_params.get("fields_json"))
                    elif tool_name == "RANDOMMER":
                        tool_response = await tool_client.query(country_code=tool_params.get("country_code", "US"), quantity=tool_params.get("quantity", 1))
                    elif tool_name == "OPENPAGERANK":
                        tool_response = await tool_client.query(domains=tool_params.get("domains", []))
                    elif tool_name == "RAPIDAPI":
                        tool_response = await tool_client.query(api_name=tool_params.get("api_name"), **tool_params.get("kwargs", {}))
                    elif tool_name == "TWILIO":
                        tool_response = await tool_client.query()
                    elif tool_name == "ABSTRACTAPI":
                        tool_response = await tool_client.query(input_value=tool_params.get("input_value"), api_type=tool_params.get("api_type"))
                    elif tool_name == "TOMORROW.IO":
                        tool_response = await tool_client.query(location=tool_params.get("location"), fields=tool_params.get("fields"))
                    
                    if tool_response:
                        responses.append(f"Réponse outil ({tool_name}): {tool_response}")
                        tools_called_for_report.append({"name": tool_name, "params": tool_params, "result": tool_response})
                    self.memory_manager.update_ia_status(tool_name, not tool_response.startswith("Erreur"))
                    
                    # Feed tool response back to primary AI for final answer
                    follow_up_prompt = f"J'ai exécuté l'outil {tool_name} avec les paramètres {params_str}. Voici le résultat:\n{tool_response}\n\nMaintenant, réponds à la question originale: {query}"
                    final_ai_response = await primary_ai_client.query(follow_up_prompt)
                    self.memory_manager.update_ia_status(primary_ai_client.name, not final_ai_response.startswith("Erreur"))
                    responses.append(f"Réponse finale ({primary_ai_client.name}): {final_ai_response}")

                else:
                    responses.append(f"Erreur: L'outil {tool_name} n'est pas disponible ou le quota est dépassé.")
                    tools_called_for_report.append({"name": tool_name, "params": tool_params, "result": "Quota dépassé ou non disponible."})
            except json.JSONDecodeError:
                responses.append(f"Erreur: Paramètres JSON invalides pour l'outil {tool_name}: {params_str}")
                tools_called_for_report.append({"name": tool_name, "params": params_str, "result": "JSON invalide."})
            except Exception as e:
                responses.append(f"Erreur lors de l'exécution de l'outil {tool_name}: {e}")
                self.memory_manager.update_ia_status(tool_name, False, str(e))
                tools_called_for_report.append({"name": tool_name, "params": params_str, "result": f"Erreur: {e}"})
        else:
            # If no tool call, the primary AI's initial response is the main response
            responses.append(f"Réponse principale ({primary_ai_client.name}): {primary_response_raw}")
        
        return "\n\n".join(responses), tools_called_for_report


    async def process_query(self, query: str) -> str:
        """Traite une requête en sélectionnant un agent mixte et en obtenant une réponse."""
        self._rotate_strategy_if_needed() # Rotation de la stratégie et de l'agent

        # Sélectionner l'agent mixte actuel
        current_agent_config = self.mixed_agents[self.current_agent_index]
        log_message(f"Traitement de la requête avec l'agent: {current_agent_config['name']}")

        # Exécuter l'agent avec ses outils
        agent_raw_response, tools_called_for_report = await self._run_agent_with_tools(current_agent_config, query)
        
        # Synthèse Optimisée des Réponses
        # Vérifier si la réponse est simple ou si elle contient des marqueurs de multiples réponses/outils
        # A simple heuristic: if it contains "Réponse principale (" and not "Réponse outil ("
        # and there are no tools called, then it's likely a single, direct response.
        if "Réponse principale (" in agent_raw_response and not tools_called_for_report:
            log_message("Réponse unique et directe détectée, pas de synthèse nécessaire.")
            final_response = agent_raw_response.replace(f"Réponse principale ({current_agent_config['primary_ais'][0]}): ", "") # Remove prefix
        else:
            log_message("Plusieurs réponses ou outils détectés, appel à la synthèse.")
            final_response = await self.synthesize_response(query, [agent_raw_response])

        return final_response, tools_called_for_report

    async def synthesize_response(self, question: str, responses: List[str]) -> str:
        """
        Synthétise les réponses de plusieurs IA en utilisant DeepSeek (le module d'optimisation).
        """
        if not responses:
            return "Je n'ai reçu aucune réponse des IA pour le moment."

        combined_responses = "\n\n".join([f"Réponse {i+1}:\n{r}" for i, r in enumerate(responses)])
        synthesis_prompt = SYNTHESIS_PROMPT_TEMPLATE.format(question=question, responses=combined_responses)

        deepseek_client = self.core_ai_engines.get("DEEPSEEK")
        if not deepseek_client:
            log_message("DeepSeek n'est pas disponible pour la synthèse.", level="warning")
            return "J'ai plusieurs réponses, mais je ne peux pas les synthétiser pour le moment. Voici les réponses brutes:\n\n" + combined_responses

        try:
            synthesis = await deepseek_client.query(synthesis_prompt)
            self.memory_manager.update_ia_status("DEEPSEEK", True) # Update DeepSeek status for synthesis
            return detect_and_correct_toxicity(synthesis)
        except Exception as e:
            log_message(f"Erreur lors de la synthèse avec DeepSeek: {e}", level="error")
            self.memory_manager.update_ia_status("DEEPSEEK", False, str(e))
            return "J'ai rencontré un problème lors de la synthèse des informations. Voici les réponses brutes:\n\n" + combined_responses

# Instancier l'orchestrateur
orchestrator = IAOrchestrator(memory_manager, quota_manager, ALL_API_CLIENTS)

# --- Tâche de fond pour les Health Checks des Endpoints (Wrapper pour JobQueue) ---
async def periodic_health_check_job(context: ContextTypes.DEFAULT_TYPE) -> None:
    """JobQueue wrapper pour les health checks périodiques."""
    log_message("Lancement des health checks périodiques via JobQueue pour tous les services...")
    for service_name in API_CONFIG.keys():
        await endpoint_health_manager.run_health_check_for_service(service_name)
    log_message("Health checks périodiques via JobQueue terminés.")

# --- Structured Reporting to Private Group ---
async def send_structured_report_to_private_group(context: ContextTypes.DEFAULT_TYPE, report_data: Dict) -> None:
    """Envoie un rapport structuré au groupe privé Telegram."""
    try:
        report_text = f"📊 **Rapport d'Action IA**\n\n"
        report_text += f"**Timestamp**: `{report_data.get('timestamp')}`\n"
        report_text += f"**Agent**: `{report_data.get('agent_name')}`\n"
        report_text += f"**Intention Détectée**: `{report_data.get('intention')}`\n"
        report_text += f"**Requête Utilisateur**: `{report_data.get('user_query')}`\n"
        report_text += f"**IA Primaire Utilisée**: `{report_data.get('primary_ai_used')}`\n"
        
        tools_called = report_data.get('tools_called', [])
        if tools_called:
            report_text += "**Outils Appelés**:\n"
            for tool in tools_called:
                # Truncate tool result for report to avoid very long messages
                tool_result_display = str(tool['result'])
                if len(tool_result_display) > 100:
                    tool_result_display = tool_result_display[:100] + "..."
                report_text += f"- `{tool['name']}` (Params: `{tool['params']}`, Résultat: `{tool_result_display}`)\n"
        else:
            report_text += "**Outils Appelés**: Aucun\n"
        
        # Truncate final response for report
        final_response_display = report_data.get('final_response', '')
        if len(final_response_display) > 500:
            final_response_display = final_response_display[:500] + "..."
        report_text += f"**Réponse Finale**: `{final_response_display}`\n"
        report_text += f"**Durée Totale**: `{report_data.get('duration'):.2f}s`\n"
        report_text += f"**Erreur**: `{report_data.get('error', 'Non')}`\n"

        await context.bot.send_message(chat_id=PRIVATE_GROUP_ID, text=report_text, parse_mode='Markdown')
        log_message(f"Rapport structuré envoyé au groupe privé: {PRIVATE_GROUP_ID}")
    except Exception as e:
        log_message(f"Erreur lors de l'envoi du rapport structuré au groupe privé: {e}", level="error")

import time
from telegram import Update, ForceReply
from telegram.ext import Application, CommandHandler, MessageHandler, filters, ContextTypes

# --- Handlers de commandes Telegram ---

async def start(update: Update, context: ContextTypes.DEFAULT_TYPE) -> None:
    """Envoie un message lorsque la commande /start est émise."""
    user = update.effective_user
    await update.message.reply_html(
        f"Salut {user.mention_html()} ! Je suis ton assistant IA de 2025. "
        "Pose-moi une question, demande-moi d'écrire du code, ou de chercher des infos. "
        "Utilise /help pour voir ce que je peux faire.",
        reply_markup=ForceReply(selective=True),
    )
    log_message(f"Commande /start reçue de {user.id}")

async def help_command(update: Update, context: ContextTypes.DEFAULT_TYPE) -> None:
    """Envoie un message lorsque la commande /help est émise."""
    help_text = """
    Voici ce que je peux faire :
    - Pose-moi n'importe quelle question factuelle.
    - Demande-moi d'écrire ou d'améliorer du code (Python, Shell).
    - Cherche des informations sur le web (actualités, météo, géolocalisation IP, etc.).
    - Demande-moi de faire une capture d'écran d'un site web (donne l'URL).
    - Demande-moi d'analyser le contenu d'une page web (donne l'URL).
    - Demande-moi de détecter la langue d'un texte.
    - Demande-moi de valider un numéro de téléphone ou de géolocaliser une IP ou un email.
    - Gère tes rappels et alarmes (Ex: "Rappelle-moi d'acheter du lait à 18h", "Mets une alarme à 7h du matin").
    - Vérifie le statut de mes APIs avec /status.
    - Affiche mon historique de conversation avec /history.
    - Affiche le statut des quotas API avec /quotas.
    - Affiche les APIs où il est opportun de "brûler" le quota avec /burn_quota.

    Exemples :
    - "Quelle est la capitale de la France ?"
    - "Écris un script Python pour trier une liste."
    - "Météo à Paris"
    - "Capture d'écran de https://google.com"
    - "Analyse de https://openai.com"
    - "Détecte la langue de 'Hello world'"
    - "Valide le numéro +33612345678"
    - "Géolocalise l'IP 8.8.8.8"
    - "Valide l'email test@example.com"
    - "Rappelle-moi de faire les courses demain à 10h"
    - "Mets une alarme pour 7h du matin"
    """
    await update.message.reply_text(help_text)
    log_message(f"Commande /help reçue de {update.effective_user.id}")

async def status_command(update: Update, context: ContextTypes.DEFAULT_TYPE) -> None:
    """Affiche le statut et les scores des IA."""
    status_message = "📊 **Statut des IA**:\n"
    now = get_current_time()
    for ia_name, status in memory_manager.ia_status.items():
        cooldown_until_str = status.get("cooldown_until")
        cooldown_status = "Prête"
        if cooldown_until_str:
            cooldown_until = datetime.strptime(cooldown_until_str, "%Y-%m-%d %H:%M:%S UTC").replace(tzinfo=None)
            if now < cooldown_until:
                remaining = cooldown_until - now
                cooldown_status = f"Cooldown ({remaining.total_seconds():.0f}s restantes)"
        
        last_used_str = status.get("last_used", "Jamais")
        if last_used_str != "Jamais":
            last_used_dt = datetime.strptime(last_used_str, "%Y-%m-%d %H:%M:%S UTC").replace(tzinfo=None)
            time_since_last_used = (now - last_used_dt).total_seconds()
            if time_since_last_used < 60:
                last_used_display = f"{time_since_last_used:.0f}s ago"
            elif time_since_last_used < 3600:
                last_used_display = f"{time_since_last_used / 60:.0f}m ago"
            else:
                last_used_display = f"{time_since_last_used / 3600:.1f}h ago"
        else:
            last_used_display = "Jamais"

        status_message += (
            f"- **{ia_name}**: Score: `{status['current_score']:.2f}`, Diversification: `{status['diversification_score']:.2f}`, "
            f"Succès: `{status['success_count']}`, Erreurs: `{status['error_count']}`, "
            f"Statut: `{cooldown_status}`, Dernière utilisation: `{last_used_display}`\n"
        )
    status_message += f"\nStratégie actuelle: `{orchestrator.current_ia_strategy}`"
    status_message += f"\nAgent mixte actuel: `{orchestrator.mixed_agents[orchestrator.current_agent_index]['name']}`"
    await update.message.reply_markdown(status_message)
    log_message(f"Commande /status reçue de {update.effective_user.id}")

async def history_command(update: Update, context: ContextTypes.DEFAULT_TYPE) -> None:
    """Affiche les 10 derniers messages de l'historique."""
    history = memory_manager.get_chat_history()
    if not history:
        await update.message.reply_text("L'historique de conversation est vide.")
        return

    history_text = "📜 **Historique des 10 dernières interactions**:\n\n"
    for entry in history:
        history_text += f"**{entry['role'].capitalize()}** ({entry['timestamp']}):\n{entry['content'][:150]}...\n\n"
    await update.message.reply_markdown(history_text)
    log_message(f"Commande /history reçue de {update.effective_user.id}")

async def quotas_command(update: Update, context: ContextTypes.DEFAULT_TYPE) -> None:
    """Affiche le statut actuel des quotas API."""
    quotas_status = quota_manager.get_all_quotas_status()
    message = "📈 **Statut des Quotas API**:\n\n"
    for api_name, data in quotas_status.items():
        message += (
            f"**{api_name}**:\n"
            f"  - Mensuel: `{data['monthly_usage']}` / `{data['monthly_limit']}`\n"
            f"  - Journalier: `{data['daily_usage']}` / `{data['daily_limit']}`\n"
            f"  - Horaire: `{data['hourly_usage']}` / `{data['hourly_limit']}`\n"
            f"  - Total appels: `{data['total_calls']}`\n"
            f"  - Dernière utilisation: `{data['last_usage'] if data['last_usage'] else 'N/A'}`\n"
            f"  - Reset Mensuel: `{data['last_reset_month']}`\n"
            f"  - Reset Journalier: `{data['last_reset_day']}`\n"
            f"  - Reset Horaire: `{data['last_hourly_reset']}`\n\n"
        )
    await update.message.reply_markdown(message)
    log_message(f"Commande /quotas reçue de {update.effective_user.id}")

async def burn_quota_command(update: Update, context: ContextTypes.DEFAULT_TYPE) -> None:
    """Affiche les APIs où il est opportun de "brûler" le quota."""
    burn_apis = quota_manager.get_burn_window_apis()
    if burn_apis:
        message = "🔥 **APIs où il est opportun de 'brûler' le quota avant réinitialisation**:\n\n"
        for api_info in burn_apis:
            message += f"- {api_info}\n"
        message += f"\nFenêtre de brûlage: {QUOTA_BURN_WINDOW_HOURS} heures avant le reset."
    else:
        message = "🎉 Aucune API n'est actuellement dans une fenêtre de 'brûlage' de quota. Tout est optimisé !"
    await update.message.reply_markdown(message)
    log_message(f"Commande /burn_quota reçue de {update.effective_user.id}")

async def detect_intent(query: str) -> str:
    """
    Détecte l'intention de l'utilisateur en utilisant une IA primaire disponible
    (DeepSeek, Gemini, etc.) de manière équitable.
    """
    prompt = f"Classe la requête suivante dans une des catégories suivantes: 'programmation', 'image', 'météo', 'langue', 'recherche', 'sécurité', 'données', 'communication', 'actualités', 'général'. Réponds uniquement avec le nom de la catégorie. Requête: '{query}'"
    
    # Sélectionner une IA primaire pour la détection d'intention
    # On itère sur les IA principales pour trouver la première disponible qui n'est pas en cooldown
    # et qui a du quota, en respectant l'équité.
    available_intent_ais = []
    for ai_name in orchestrator.core_ai_engines:
        ai_client = orchestrator.core_ai_engines[ai_name]
        status = memory_manager.get_ia_status(ai_name)
        if ai_client and status and (status.get("cooldown_until") is None or datetime.strptime(status["cooldown_until"], "%Y-%m-%d %H:%M:%S UTC").replace(tzinfo=None) < get_current_time()):
            if quota_manager.check_and_update_quota(ai_name, cost=0): # Check quota without consuming
                available_intent_ais.append(ai_name)
    
    if not available_intent_ais:
        log_message("Aucune IA principale disponible pour la détection d'intention. Retourne 'général'.", level="warning")
        return "général"

    # Choisir une IA aléatoirement parmi celles disponibles pour l'équité
    selected_ai_for_intent = random.choice(available_intent_ais)
    intent_ai_client = orchestrator.core_ai_engines[selected_ai_for_intent]

    # Consommer le quota pour l'IA sélectionnée
    if not quota_manager.check_and_update_quota(selected_ai_for_intent):
        log_message(f"Quota dépassé pour {selected_ai_for_intent} lors de la détection d'intention. Retourne 'général'.", level="warning")
        return "général"

    try:
        response = await intent_ai_client.query(prompt)
        # Clean up response to get just the category name
        category = response.strip().lower().replace('.', '').replace('catégorie: ', '')
        if category in ['programmation', 'image', 'météo', 'langue', 'recherche', 'sécurité', 'données', 'communication', 'actualités', 'général']:
            return category
        return "général" # Fallback
    except Exception as e:
        log_message(f"Erreur lors de la détection d'intention avec {selected_ai_for_intent}: {e}", level="error")
        memory_manager.update_ia_status(selected_ai_for_intent, False, str(e))
        return "général" # Fallback if AI fails


# --- Gestionnaire de messages (le cœur du bot) ---

async def handle_message(update: Update, context: ContextTypes.DEFAULT_TYPE) -> None:
    """Traite les messages texte de l'utilisateur."""
    user_message = update.message.text
    user_id = update.effective_user.id
    log_message(f"Message reçu de {user_id}: {user_message}")

    memory_manager.add_message_to_history("user", user_message)

    response_text = ""
    start_processing_time = time.monotonic()
    
    # Intention Detection
    detected_intention = await detect_intent(user_message)
    log_message(f"Intention détectée pour '{user_message}': {detected_intention}")

    tools_called_report = []
    error_occurred = False

    try:
        # Détection d'intentions spécifiques (prioritaires sur l'orchestrateur général)
        if any(keyword in user_message.lower() for keyword in ["alarme", "réveil", "timer", "minuteur", "rappelle-moi", "rappel", "reminder"]):
            log_message("Intention détectée: Alarme/Rappel (Simulé).")
            response_text = "Je peux t'aider avec les alarmes, minuteurs et rappels ! Dis-moi par exemple : 'Mets une alarme à 7h du matin' ou 'Rappelle-moi d'acheter du lait à 18h'."
            await context.bot.send_message(chat_id=update.effective_chat.id, text="Message reçu. Mission comprise.")
        elif "```python" in user_message or "```shell" in user_message or "exécute ce code" in user_message.lower() or "teste ce script" in user_message.lower():
            log_message("Intention détectée: Exécution de code.")
            await context.bot.send_message(chat_id=update.effective_chat.id, text="Message reçu. Mission comprise.")
            lang_match = re.search(r"```(python|shell)\n(.*?)```", user_message, re.DOTALL)
            if lang_match:
                language = lang_match.group(1)
                code = lang_match.group(2)
                response_text = await run_in_sandbox(code, language)
            else:
                response_text = "Veuillez formater votre code avec des triple backticks et spécifier le langage (ex: ```python\\nprint('Hello')``` ou ```shell\\nls -l```)."
        elif "analyse ce code python" in user_message.lower() or "vérifie ce script python" in user_message.lower():
            log_message("Intention détectée: Analyse de code Python.")
            await context.bot.send_message(chat_id=update.effective_chat.id, text="Message reçu. Mission comprise.")
            code_match = re.search(r"```python\n(.*?)```", user_message, re.DOTALL)
            if code_match:
                code = code_match.group(1)
                response_text = await analyze_python_code(code)
            else:
                response_text = "Veuillez fournir le code Python à analyser formaté avec ```python\\n...```."
        elif "extraire texte image" in user_message.lower() or "ocr" in user_message.lower() or "lis cette image" in user_message.lower():
            log_message("Intention détectée: OCR.")
            await context.bot.send_message(chat_id=update.effective_chat.id, text="Message reçu. Mission comprise.")
            url_match = re.search(r'https?://[^\s]+(?:\.jpg|\.jpeg|\.png|\.gif|\.bmp|\.tiff)', user_message, re.IGNORECASE)
            if url_match:
                image_url = url_match.group(0)
                # For OCR, we'll try to use Cloudmersive if a key is available for OCR
                # The provided Cloudmersive config is for Domain Check, not OCR.
                # If an OCR endpoint was configured, it would be called here.
                # For now, we'll return a message indicating no direct OCR API.
                response_text = "Désolé, je n'ai pas d'API OCR directement configurée pour le moment. Mon client Cloudmersive est pour la validation de domaine."
            else:
                response_text = "Veuillez fournir une URL d'image valide (jpg, png, etc.) pour l'extraction de texte."
        else:
            log_message("Intention générale, utilisation de l'orchestrateur d'IA.")
            await context.bot.send_message(chat_id=update.effective_chat.id, text="Message reçu. Mission comprise.")
            response_text, tools_called_report = await orchestrator.process_query(user_message)

    except Exception as e:
        log_message(f"Erreur majeure lors du traitement du message: {e}", level="error")
        response_text = f"Désolé, une erreur inattendue est survenue: {e}"
        error_occurred = True

    final_response = clean_html_tags(response_text)
    final_response = neutralize_urls(final_response)
    final_response = detect_and_correct_toxicity(final_response)

    await update.message.reply_text(final_response)
    memory_manager.add_message_to_history("assistant", final_response)
    log_message(f"Réponse envoyée à {user_id}.")

    # Send structured report to private group
    end_processing_time = time.monotonic()
    processing_duration = end_processing_time - start_processing_time

    report_data = {
        "timestamp": format_datetime(get_current_time()),
        "agent_name": orchestrator.mixed_agents[orchestrator.current_agent_index]['name'],
        "intention": detected_intention,
        "user_query": user_message,
        "primary_ai_used": orchestrator.core_ai_engines.get(orchestrator.mixed_agents[orchestrator.current_agent_index]['primary_ais'][0]).name if orchestrator.mixed_agents[orchestrator.current_agent_index]['primary_ais'] else "N/A", # Simplified
        "tools_called": tools_called_report, # This needs to be populated by _run_agent_with_tools
        "final_response": final_response,
        "duration": processing_duration,
        "error": "Oui" if error_occurred else "Non"
    }
    await send_structured_report_to_private_group(context, report_data)


# --- Fonction principale pour démarrer le bot ---

def main() -> None: # Removed 'async' keyword
    """Démarre le bot."""
    log_message("Démarrage du bot Telegram...")
    application = Application.builder().token(TELEGRAM_BOT_TOKEN).build()

    application.add_handler(CommandHandler("start", start))
    application.add_handler(CommandHandler("help", help_command))
    application.add_handler(CommandHandler("status", status_command))
    application.add_handler(CommandHandler("history", history_command))
    application.add_handler(CommandHandler("quotas", quotas_command))
    application.add_handler(CommandHandler("burn_quota", burn_quota_command))

    application.add_handler(MessageHandler(filters.TEXT & ~filters.COMMAND, handle_message))

    # Démarrer la tâche de fond pour les health checks via JobQueue
    # 'first=10' signifie que le premier check aura lieu 10 secondes après le démarrage.
    # 'interval=300' signifie que les checks suivants auront lieu toutes les 300 secondes (5 minutes).
    application.job_queue.run_repeating(periodic_health_check_job, interval=300, first=10)

    log_message("Bot prêt à recevoir des messages.")
    # Utilisez run_polling pour gérer la boucle d'événements
    application.run_polling(allowed_updates=Update.ALL_TYPES) # Removed 'await'

if __name__ == "__main__":
    # Assurez-vous que le répertoire des archives existe
    os.makedirs(ARCHIVES_DIR, exist_ok=True)
    try:
        # Appelle la fonction main directement. application.run_polling() gère la boucle d'événements.
        main() # Changed from asyncio.run(main())
    except KeyboardInterrupt:
        # Gère l'interruption par l'utilisateur (Ctrl+C) pour un arrêt propre.
        logging.info("Bot arrêté par l'utilisateur (Ctrl+C).")
    except Exception as e:
        # Capture et log toute autre erreur fatale au démarrage du bot.
        logging.error(f"Erreur fatale lors du démarrage du bot: {e}", exc_info=True)
        print(f"Une erreur est survenue au démarrage du bot: {e}")

# --- FIN DU FICHIER PRINCIPAL ---





# api_clients.py
import os
from pathlib import Path
from typing import Dict, Any, List, Optional, Tuple, Union
from datetime import datetime
import requests
import json
import asyncio
import httpx

import logging
import random
import google.generativeai as genai
from google.generativeai import types

from config import config
from app_singletons import endpoint_health_manager, quota_manager
from utils import log_message, truncate_text, retry_on_exception
from telegram_logger import log_api_call, log_api_response, log_api_call_summary_v2

class ApiClient:
    """
    Classe de base pour tous les clients API.
    Gère les requêtes HTTP, la journalisation et l'interaction avec les singletons.
    C'est le "traducteur" standardisé pour toutes les communications externes.
    """
    def __init__(self, service_name: str):
        self.service_name = service_name
        self.endpoints = config.API_CONFIG.get(service_name, [])
        if not self.endpoints:
            log_message(f"Aucun endpoint configuré pour le service {self.service_name}", level="warning")


    @retry_on_exception()
    async def _make_request(
        self,
        endpoint_config: Dict[str, Any],
        url_suffix: str = "",
        params: Optional[Dict] = None,
        json_data: Optional[Dict] = None,
        files: Optional[Dict] = None,
        agent_id: str = "N/A"
    ) -> Union[Dict, str]:
        """Effectue une requête HTTP, gère les erreurs et logue l'activité."""
        full_url = endpoint_config["url"] + url_suffix
        method = endpoint_config["method"]
        timeout = endpoint_config.get("timeout", 30)
        headers = endpoint_config.get("fixed_headers", {}).copy()
        req_params = endpoint_config.get("fixed_params", {}).copy()
        if params:
            req_params.update(params)

        key = endpoint_config.get("key")
        key_field = endpoint_config.get("key_field")
        key_location = endpoint_config.get("key_location")
        key_prefix = endpoint_config.get("key_prefix", "")
        auth = None

        if key and key_field:
            if key_location == "header":
                headers[key_field] = f"{key_prefix}{key}"
            elif key_location == "param":
                req_params[key_field] = key
            elif key_location == "auth_basic" and isinstance(key, tuple):
                auth = httpx.BasicAuth(key[0], key[1])

        start_time = asyncio.get_event_loop().time()
        
        payload_excerpt = ""
        if json_data:
            try:
                payload_excerpt = truncate_text(json.dumps(json_data, ensure_ascii=False), 200)
            except TypeError:
                payload_excerpt = truncate_text(str(json_data), 200)
        
        await log_api_call(agent_id, endpoint_config['endpoint_name'], full_url, method, payload_excerpt)

        try:
            async with httpx.AsyncClient() as client:
                response = await client.request(
                    method, full_url, params=req_params, headers=headers,
                    json=json_data, files=files, auth=auth, timeout=timeout
                )
                latency_ms = int((asyncio.get_event_loop().time() - start_time) * 1000)
                response_text_excerpt = response.text
                response.raise_for_status()
                
                await log_api_response(agent_id, endpoint_config['endpoint_name'], response.status_code, response_text_excerpt, latency_ms / 1000)
                await log_api_call_summary_v2(
                    self.service_name, endpoint_config['endpoint_name'], True,
                    response.status_code, latency_ms
                )

                try:
                    return response.json()
                except json.JSONDecodeError:
                    return {"status": "success", "content": response.text}

        except httpx.HTTPStatusError as e:
            latency_ms = int((asyncio.get_event_loop().time() - start_time) * 1000)
            error_msg = f"HTTP Status {e.response.status_code}"
            await log_api_response(agent_id, endpoint_config['endpoint_name'], e.response.status_code, e.response.text, latency_ms / 1000)
            await log_api_call_summary_v2(
                self.service_name, endpoint_config['endpoint_name'], False,
                e.response.status_code, latency_ms, error_msg
            )
            return f"❌ Erreur API {self.service_name}: {e.response.status_code} - {e.response.text}"
        except httpx.RequestError as e:
            latency_ms = int((asyncio.get_event_loop().time() - start_time) * 1000)
            error_msg = f"Network Error: {type(e).__name__}"
            await log_api_response(agent_id, endpoint_config['endpoint_name'], 0, str(e), latency_ms / 1000)
            await log_api_call_summary_v2(
                self.service_name, endpoint_config['endpoint_name'], False,
                None, latency_ms, error_msg
            )
            return f"❌ Erreur réseau pour {self.service_name}: {e}"
        except Exception as e:
            latency_ms = int((asyncio.get_event_loop().time() - start_time) * 1000)
            error_msg = f"Unexpected Error: {type(e).__name__}"
            await log_api_response(agent_id, endpoint_config['endpoint_name'], 0, str(e), latency_ms / 1000)
            await log_api_call_summary_v2(
                self.service_name, endpoint_config['endpoint_name'], False,
                None, latency_ms, error_msg
            )
            return f"❌ Erreur inattendue pour {self.service_name}: {e}"

    async def execute_with_config(
        self,
        endpoint_config: Dict[str, Any],
        agent_id: str = "N/A",
        **kwargs
    ) -> Union[Dict, str]:
        """
        Exécute une requête en utilisant une configuration d'endpoint spécifique.
        Cette méthode vérifie le quota avant de faire l'appel.
        """
        if not await quota_manager.check_quota(self.service_name):
            return f"❌ Quota dépassé pour le service {self.service_name}."

        result = await self._execute(endpoint_config, agent_id=agent_id, **kwargs)

        request_success = not (isinstance(result, str) and result.startswith("❌"))
        await quota_manager.increment_quota(self.service_name, success=request_success)
        
        return result

    async def execute_with_specific_config(
        self,
        endpoint_config: Dict[str, Any],
        url_suffix: str = "",
        params: Optional[Dict] = None,
        json_data: Optional[Dict] = None,
        files: Optional[Dict] = None,
        agent_id: str = "N/A"
    ) -> Union[Dict, str]:
        """
        Exécute une requête en utilisant une configuration de clé/endpoint spécifique.
        """
        if not endpoint_config:
            return f"❌ Erreur d'exécution : Aucune configuration d'endpoint fournie pour {self.service_name}."

        log_message(f"Exécution forcée pour {self.service_name} avec l'endpoint: {endpoint_config.get('endpoint_name')}")

        has_quota = await quota_manager.check_quota(self.service_name)
        if not has_quota:
            return f"❌ Quota dépassé pour le service {self.service_name}."

        result = await self._make_request(
            endpoint_config=endpoint_config,
            url_suffix=url_suffix,
            params=params,
            json_data=json_data,
            files=files,
            agent_id=agent_id
        )

        request_success = not (isinstance(result, str) and result.startswith("❌"))
        await quota_manager.increment_quota(self.service_name, success=request_success)
        return result

    async def _execute(self, endpoint_config: Dict[str, Any], **kwargs) -> Union[Dict, str]:
        """Méthode à surcharger par les classes filles pour appeler _make_request."""
        raise NotImplementedError("La méthode '_execute' doit être implémentée par les sous-classes.")


class LLMApiClient(ApiClient):
    """Classe de base pour les clients d'API de modèles de langage."""
    def __init__(self, service_name: str):
        super().__init__(service_name)
        self.default_model: str = ""


    async def generate_content(self, endpoint_config: Dict[str, Any],
                            prompt: Union[str, List[Dict[str, Any]]],
                            chat_history: List[Dict[str, Any]],
                            image_data: Optional[str] = None,
                            tools: Optional[List[Dict]] = None,
                            model_name: Optional[str] = None,
                            agent_id: str = "N/A",
                            temperature: Optional[float] = None) -> Union[Dict, str]:
        """Méthode abstraite pour générer du contenu."""
        raise NotImplementedError("La méthode 'generate_content' doit être implémentée par les sous-classes.")


class GeminiApiClient(LLMApiClient):
    def __init__(self):
        super().__init__("GEMINI_API")
        self.default_model = "gemini-1.5-flash-latest"
        log_message(f"GeminiApiClient initialisé avec le modèle par défaut: {self.default_model}")


    async def generate_content(self, endpoint_config: Dict[str, Any],
                            prompt: Union[str, List[Dict[str, Any]]],
                            chat_history: List[Dict[str, Any]],
                            image_data: Optional[str] = None,
                            tools: Optional[List[Dict]] = None,
                            model_name: Optional[str] = None,
                            agent_id: str = "N/A",
                            temperature: Optional[float] = None) -> Union[Dict, str]:
        """Génère du contenu textuel en utilisant le modèle Gemini."""
        log_message(f"Appel à Gemini API pour le modèle {model_name or self.default_model} via endpoint: {endpoint_config.get('endpoint_name', 'N/A')}")

        if not endpoint_config or not endpoint_config.get("key"):
            return f"❌ Erreur Gemini: Configuration d'endpoint ou clé API manquante."

        genai.configure(api_key=endpoint_config["key"])
        log_message(f"Configuration de genai avec la clé de l'endpoint: {endpoint_config['endpoint_name']}")

        contents = []
        for msg in chat_history:
            formatted_parts = []
            for part in msg.get("parts", []):
                if "text" in part:
                    formatted_parts.append(part["text"])
                elif "function_response" in part:
                    formatted_parts.append(genai.types.FunctionResponse(
                        name=part["function_response"]["name"],
                        response=part["function_response"]["response"]
                    ))
                elif "function_call" in part:
                    formatted_parts.append(genai.types.FunctionCall(
                        name=part["function_call"]["name"],
                        args=part["function_call"]["args"]
                    ))
                elif "inlineData" in part:
                    formatted_parts.append(genai.types.Blob(
                        mime_type=part["inlineData"]["mimeType"],
                        data=part["inlineData"]["data"]
                    ))
            contents.append({"role": msg["role"], "parts": formatted_parts})

        user_parts = []
        if isinstance(prompt, str):
            user_parts.append(prompt)
        elif isinstance(prompt, list):
            user_parts.extend(prompt)

        if image_data:
            mime_type = image_data.split(';')[0].split(':')[1]
            base64_string = image_data.split(',')[1]
            user_parts.append(genai.types.Blob(mime_type=mime_type, data=base64_string))

        contents.append({"role": "user", "parts": user_parts})

        genai_tools = None
        if tools:
            genai_tools = [genai.types.FunctionDeclaration(**tool["function_declarations"][0]) 
                          for tool in tools if "function_declarations" in tool and tool["function_declarations"]]

        try:
            model_to_use = model_name if model_name else self.default_model
            model_instance = genai.GenerativeModel(model_to_use, tools=genai_tools)

            response = await model_instance.generate_content_async(
                contents=contents,
                generation_config=genai.types.GenerationConfig(
                    temperature=temperature if temperature is not None else config.GEMINI_TEMPERATURE,
                    top_p=config.GEMINI_TOP_P,
                    top_k=config.GEMINI_TOP_K,
                    max_output_tokens=config.GEMINI_MAX_OUTPUT_TOKENS,
                ),
                safety_settings=config.GEMINI_SAFETY_SETTINGS,
            )

            response_dict = response.to_dict()
            return response_dict

        except Exception as e:
            log_message(f"API GEMINI_API erreur sur l'endpoint {endpoint_config['endpoint_name']}: {e}", level="error")
            return f"❌ Erreur Gemini: {e}"

    async def _execute(self, endpoint_config: Dict[str, Any], agent_id: str = "N/A", **kwargs) -> Union[Dict, str]:
        return await self.generate_content(endpoint_config, agent_id=agent_id, **kwargs)


class DeepSeekClient(LLMApiClient):
    def __init__(self):
        super().__init__("DEEPSEEK")


    async def generate_content(self, endpoint_config: Dict[str, Any],
                            prompt: Union[str, List[Dict[str, Any]]],
                            chat_history: List[Dict[str, Any]],
                            image_data: Optional[str] = None,
                            tools: Optional[List[Dict]] = None,
                            model_name: Optional[str] = None,
                            agent_id: str = "N/A",
                            temperature: Optional[float] = None) -> Union[Dict, str]:
        messages = []
        if chat_history:
            for msg in chat_history:
                content = " ".join([part.get("text", "") for part in msg.get("parts", [])])
                if content.strip():
                    role = "assistant" if msg["role"] == "model" else msg["role"]
                    messages.append({"role": role, "content": content})
        
        messages.append({"role": "user", "content": prompt})
        
        json_data = {"model": model_name or "deepseek-chat", "messages": messages}
        if temperature is not None:
            json_data["temperature"] = temperature
            
        result = await self._make_request(endpoint_config, json_data=json_data, agent_id=agent_id)
        
        if isinstance(result, dict) and "choices" in result and result["choices"]:
            content = result["choices"][0]["message"]["content"]
            return {
                "candidates": [{
                    "content": {"parts": [{"text": content}]}
                }]
            }
        return {"candidates": [{"content": {"parts": [{"text": str(result)}]}}]}

    async def _execute(self, endpoint_config: Dict[str, Any], agent_id: str = "N/A", **kwargs) -> Union[Dict, str]:
        return await self.generate_content(endpoint_config, agent_id=agent_id, **kwargs)


class HuggingFaceClient(LLMApiClient):
    def __init__(self):
        super().__init__("HUGGINGFACE")


    async def generate_content(self, endpoint_config: Dict[str, Any],
                            prompt: Union[str, List[Dict[str, Any]]],
                            chat_history: List[Dict[str, Any]],
                            image_data: Optional[str] = None,
                            tools: Optional[List[Dict]] = None,
                            model_name: Optional[str] = None,
                            agent_id: str = "N/A",
                            temperature: Optional[float] = None) -> Union[Dict, str]:
        model_to_use = model_name if model_name else "microsoft/DialoGPT-large"
        input_text = prompt if isinstance(prompt, str) else " ".join([p.get("text", "") for p in prompt])
        
        json_data = {"inputs": input_text}
        if temperature is not None:
            json_data["parameters"] = {"temperature": temperature}
            
        result = await self._make_request(endpoint_config, url_suffix=model_to_use, json_data=json_data, agent_id=agent_id)
        
        if isinstance(result, list) and result:
            generated_text = result[0].get("generated_text", input_text)
            new_text = generated_text[len(input_text):].strip()
            if not new_text:
                new_text = "Réponse générée par HuggingFace"
            
            return {
                "candidates": [{
                    "content": {"parts": [{"text": new_text}]}
                }]
            }
        return {"candidates": [{"content": {"parts": [{"text": str(result)}]}}]}

    async def _execute(self, endpoint_config: Dict[str, Any], agent_id: str = "N/A", **kwargs) -> Union[Dict, str]:
        return await self.generate_content(endpoint_config, agent_id=agent_id, **kwargs)


class TavilyClient(ApiClient):
    def __init__(self):
        super().__init__("TAVILY")


    async def _execute(self, endpoint_config: Dict[str, Any], agent_id: str = "N/A", **kwargs) -> Union[Dict, str]:
        query = kwargs.get("query")
        max_results = kwargs.get("max_results", 3)
        json_data = {"query": query, "max_results": max_results}
        return await self._make_request(endpoint_config, json_data=json_data, agent_id=agent_id)


class SerperClient(ApiClient):
    def __init__(self):
        super().__init__("SERPER")


    async def _execute(self, endpoint_config: Dict[str, Any], agent_id: str = "N/A", **kwargs) -> Union[Dict, str]:
        query = kwargs.get("query")
        json_data = {"q": query}
        return await self._make_request(endpoint_config, json_data=json_data, agent_id=agent_id)


class GoogleCustomSearchClient(ApiClient):
    def __init__(self):
        super().__init__("GOOGLE_CUSTOM_SEARCH")


    async def _execute(self, endpoint_config: Dict[str, Any], agent_id: str = "N/A", **kwargs) -> Union[Dict, str]:
        query = kwargs.get("query")
        params = {"q": query}
        return await self._make_request(endpoint_config, params=params, agent_id=agent_id)


class WolframAlphaClient(ApiClient):
    def __init__(self):
        super().__init__("WOLFRAMALPHA")


    async def _execute(self, endpoint_config: Dict[str, Any], agent_id: str = "N/A", **kwargs) -> Union[Dict, str]:
        input_text = kwargs.get("input_text")
        params = {"input": input_text, "output": "json"}
        return await self._make_request(endpoint_config, params=params, agent_id=agent_id)


class TelegramBotClient(ApiClient):
    def __init__(self):
        super().__init__("TELEGRAM_BOT")
        if not self.endpoints:
            self.endpoints.append({
                "endpoint_name": "Telegram Bot API",
                "url": f"https://api.telegram.org/bot{config.TELEGRAM_BOT_TOKEN}",
                "method": "POST", "key": config.TELEGRAM_BOT_TOKEN, "timeout": 10,
                "fixed_headers": {"Content-Type": "application/json"},
            })


    async def send_message(self, chat_id: Union[int, str], text: str, parse_mode: Optional[str] = None, agent_id: str = "N/A") -> Union[Dict, str]:
        json_data = {"chat_id": chat_id, "text": text}
        if parse_mode: json_data["parse_mode"] = parse_mode
        return await self._make_request(self.endpoints[0], url_suffix="/sendMessage", json_data=json_data, agent_id=agent_id)

    async def send_document(self, chat_id: Union[int, str], document: Any, filename: str, caption: str, parse_mode: Optional[str] = None, agent_id: str = "N/A") -> Union[Dict, str]:
        """Envoie un document à un chat Telegram spécifié en utilisant le client bot réel."""
        
        from telegram_logger import _telegram_integration_instance
        if not _telegram_integration_instance or not hasattr(_telegram_integration_instance, 'bot_client'):
            log_message("Client Telegram non disponible pour send_document.", "error")
            return {"status": "error", "message": "Client Telegram non initialisé."}

        bot = _telegram_integration_instance.bot_client
        
        try:
            if isinstance(document, str):
                document_bytes = document.encode('utf-8')
            elif isinstance(document, bytes):
                document_bytes = document
            else:
                raise TypeError("Le contenu du document doit être de type str ou bytes.")

            await bot.send_document(
                chat_id=chat_id,
                document=document_bytes,
                filename=filename,
                caption=caption,
                parse_mode=parse_mode
            )
            log_message(f"Document '{filename}' envoyé avec succès à {chat_id}.", "info")
            await quota_manager.increment_quota(self.service_name, success=True)
            return {"status": "success", "message": "Document envoyé."}
        except Exception as e:
            log_message(f"Erreur lors de l'envoi du document via Telegram: {e}", "error")
            await quota_manager.increment_quota(self.service_name, success=False)
            return {"status": "error", "message": str(e)}

    async def _execute(self, endpoint_config: Dict[str, Any], agent_id: str = "N/A", **kwargs) -> Union[Dict, str]:
        raise NotImplementedError("TelegramBotClient utilise des méthodes spécifiques (send_message, send_document).")


class WebContainerClient(ApiClient):
    def __init__(self):
        super().__init__("WEBCONTAINER")


    async def _execute(self, endpoint_config: Dict[str, Any], agent_id: str = "N/A", **kwargs) -> Union[Dict, str]:
        code = kwargs.get("code")
        language = kwargs.get("language", "javascript")
        json_data = {
            "action": "execute",
            "language": language,
            "code": code
        }
        return await self._make_request(endpoint_config, json_data=json_data, agent_id=agent_id)


class OCRApiClient(ApiClient):
    def __init__(self):
        super().__init__("OCR_API")


    async def _execute(self, endpoint_config: Dict[str, Any], agent_id: str = "N/A", **kwargs) -> Union[Dict, str]:
        image_base64 = kwargs.get("image_base64")
        language = kwargs.get("language", "eng")
        json_data = {
            "base64Image": image_base64,
            "language": language,
            "isOverlayRequired": False
        }
        return await self._make_request(endpoint_config, json_data=json_data, agent_id=agent_id)


class ApiFlashClient(ApiClient):
    def __init__(self):
        super().__init__("APIFLASH")


    async def _execute(self, endpoint_config: Dict[str, Any], agent_id: str = "N/A", **kwargs) -> Union[Dict, str]:
        url = kwargs.get("url")
        params = {"url": url, "format": "jpeg"}
        return await self._make_request(endpoint_config, params=params, agent_id=agent_id)


class CrawlbaseClient(ApiClient):
    def __init__(self):
        super().__init__("CRAWLBASE")


    async def _execute(self, endpoint_config: Dict[str, Any], agent_id: str = "N/A", **kwargs) -> Union[Dict, str]:
        url = kwargs.get("url")
        use_js = kwargs.get("use_js", False)
        params = {"url": url}
        if use_js:
            params["javascript"] = "true"
        return await self._make_request(endpoint_config, params=params, agent_id=agent_id)


class DetectLanguageClient(ApiClient):
    def __init__(self):
        super().__init__("DETECTLANGUAGE")


    async def _execute(self, endpoint_config: Dict[str, Any], agent_id: str = "N/A", **kwargs) -> Union[Dict, str]:
        text = kwargs.get("text")
        json_data = {"q": text}
        return await self._make_request(endpoint_config, json_data=json_data, agent_id=agent_id)


class GuardianClient(ApiClient):
    def __init__(self):
        super().__init__("GUARDIAN")


    async def _execute(self, endpoint_config: Dict[str, Any], agent_id: str = "N/A", **kwargs) -> Union[Dict, str]:
        query = kwargs.get("query")
        params = {"q": query}
        return await self._make_request(endpoint_config, params=params, agent_id=agent_id)


class IP2LocationClient(ApiClient):
    def __init__(self):
        super().__init__("IP2LOCATION")


    async def _execute(self, endpoint_config: Dict[str, Any], agent_id: str = "N/A", **kwargs) -> Union[Dict, str]:
        ip_address = kwargs.get("ip_address")
        params = {"ip": ip_address, "package": "WS24", "format": "json"}
        return await self._make_request(endpoint_config, params=params, agent_id=agent_id)


class ShodanClient(ApiClient):
    def __init__(self):
        super().__init__("SHODAN")


    async def _execute(self, endpoint_config: Dict[str, Any], agent_id: str = "N/A", **kwargs) -> Union[Dict, str]:
        query_text = kwargs.get("query_text", "")
        if query_text:
            url_suffix = f"/{query_text}"
            return await self._make_request(endpoint_config, url_suffix=url_suffix, agent_id=agent_id)
        else:
            api_info_endpoint_config = next((ep for ep in self.endpoints if "API Info" in ep.get("endpoint_name", "")), None)
            if api_info_endpoint_config:
                return await self._make_request(api_info_endpoint_config, agent_id=agent_id)
            else:
                return "❌ Erreur Shodan: Endpoint 'API Info' non trouvé dans la configuration."


class WeatherAPIClient(ApiClient):
    def __init__(self):
        super().__init__("WEATHERAPI")


    async def _execute(self, endpoint_config: Dict[str, Any], agent_id: str = "N/A", **kwargs) -> Union[Dict, str]:
        location = kwargs.get("location")
        params = {"q": location}
        return await self._make_request(endpoint_config, params=params, agent_id=agent_id)


class CloudmersiveClient(ApiClient):
    def __init__(self):
        super().__init__("CLOUDMERSIVE")


    async def _execute(self, endpoint_config: Dict[str, Any], agent_id: str = "N/A", **kwargs) -> Union[Dict, str]:
        domain = kwargs.get("domain")
        json_data = {"domain": domain}
        return await self._make_request(endpoint_config, json_data=json_data, agent_id=agent_id)


class GreyNoiseClient(ApiClient):
    def __init__(self):
        super().__init__("GREYNOISE")


    async def _execute(self, endpoint_config: Dict[str, Any], agent_id: str = "N/A", **kwargs) -> Union[Dict, str]:
        ip_address = kwargs.get("ip_address")
        url_suffix = f"/{ip_address}"
        return await self._make_request(endpoint_config, url_suffix=url_suffix, agent_id=agent_id)


class PulsediveClient(ApiClient):
    def __init__(self):
        super().__init__("PULSEDIVE")


    async def _execute(self, endpoint_config: Dict[str, Any], agent_id: str = "N/A", **kwargs) -> Union[Dict, str]:
        indicator = kwargs.get("indicator")
        type = kwargs.get("type", "auto")
        params = {"indicator": indicator, "type": type}
        return await self._make_request(endpoint_config, params=params, agent_id=agent_id)


class StormGlassClient(ApiClient):
    def __init__(self):
        super().__init__("STORMGLASS")


    async def _execute(self, endpoint_config: Dict[str, Any], agent_id: str = "N/A", **kwargs) -> Union[Dict, str]:
        lat = kwargs.get("lat")
        lng = kwargs.get("lng")
        params = kwargs.get("params", "airTemperature,waveHeight")
        req_params = {"lat": lat, "lng": lng, "params": params}
        return await self._make_request(endpoint_config, params=req_params, agent_id=agent_id)


class LoginRadiusClient(ApiClient):
    def __init__(self):
        super().__init__("LOGINRADIUS")


    async def _execute(self, endpoint_config: Dict[str, Any], agent_id: str = "N/A", **kwargs) -> Union[Dict, str]:
        return await self._make_request(endpoint_config, agent_id=agent_id)


class JsonbinClient(ApiClient):
    def __init__(self):
        super().__init__("JSONBIN")


    async def _execute(self, endpoint_config: Dict[str, Any], agent_id: str = "N/A", **kwargs) -> Union[Dict, str]:
        data = kwargs.get("data")
        private = kwargs.get("private", True)
        bin_id = kwargs.get("bin_id")

        if bin_id:
            if "Bin Access" in endpoint_config.get("endpoint_name", ""):
                return await self._make_request(endpoint_config, url_suffix=f"/{bin_id}", agent_id=agent_id)
            else:
                return "❌ Erreur Jsonbin: Endpoint 'Bin Access' non fourni pour accéder à un bin."
        elif data:
            if "Bin Create" in endpoint_config.get("endpoint_name", ""):
                json_data = {"record": data, "private": private}
                return await self._make_request(endpoint_config, json_data=json_data, agent_id=agent_id)
            else:
                return "❌ Erreur Jsonbin: Endpoint 'Bin Create' non fourni pour créer un bin."
        else:
            return "❌ Erreur Jsonbin: Veuillez fournir des données pour créer un bin ou un ID de bin pour y accéder."


class TwilioClient(ApiClient):
    def __init__(self):
        super().__init__("TWILIO")


    async def _execute(self, endpoint_config: Dict[str, Any], agent_id: str = "N/A", **kwargs) -> Union[Dict, str]:
        return await self._make_request(endpoint_config, agent_id=agent_id)


class AbstractAPIClient(ApiClient):
    def __init__(self):
        super().__init__("ABSTRACTAPI")


    async def _execute(self, endpoint_config: Dict[str, Any], agent_id: str = "N/A", **kwargs) -> Union[Dict, str]:
        input_value = kwargs.get("input_value")
        api_type = kwargs.get("api_type")
        params = {}
        url_suffix = ""

        if api_type == "EMAIL_VALIDATION":
            params["email"] = input_value
        elif api_type == "PHONE_VALIDATION":
            params["phone"] = input_value
        elif api_type == "EXCHANGE_RATES":
            params["base"] = input_value
        elif api_type == "HOLIDAYS":
            params["country"] = input_value
            params["year"] = datetime.now().year
        else:
            return f"❌ Type d'API AbstractAPI non supporté: {api_type}"

        return await self._make_request(endpoint_config, params=params, url_suffix=url_suffix, agent_id=agent_id)


class RandommerClient(ApiClient):
    def __init__(self):
        super().__init__("RANDOMMER")


    async def _execute(self, endpoint_config: Dict[str, Any], agent_id: str = "N/A", **kwargs) -> Union[Dict, str]:
        country_code = kwargs.get("country_code", "US")
        quantity = kwargs.get("quantity", 1)
        params = {"CountryCode": country_code, "Quantity": quantity}
        return await self._make_request(endpoint_config, params=params, agent_id=agent_id)


class TomorrowIOClient(ApiClient):
    def __init__(self):
        super().__init__("TOMORROW.IO")


    async def _execute(self, endpoint_config: Dict[str, Any], agent_id: str = "N/A", **kwargs) -> Union[Dict, str]:
        location = kwargs.get("location")
        fields = kwargs.get("fields")
        json_data = {
            "location": location,
            "fields": fields,
            "units": "metric",
            "timesteps": ["1h"]
        }
        return await self._make_request(endpoint_config, json_data=json_data, agent_id=agent_id)


class OpenWeatherMapClient(ApiClient):
    def __init__(self):
        super().__init__("OPENWEATHERMAP")


    async def _execute(self, endpoint_config: Dict[str, Any], agent_id: str = "N/A", **kwargs) -> Union[Dict, str]:
        location = kwargs.get("location")
        params = {"q": location}
        return await self._make_request(endpoint_config, params=params, agent_id=agent_id)


class MockarooClient(ApiClient):
    def __init__(self):
        super().__init__("MOCKAROO")


    async def _execute(self, endpoint_config: Dict[str, Any], agent_id: str = "N/A", **kwargs) -> Union[Dict, str]:
        count = kwargs.get("count", 1)
        fields_json = kwargs.get("fields_json")
        params = {"count": count}
        if fields_json:
            params["fields"] = fields_json
        return await self._make_request(endpoint_config, params=params, agent_id=agent_id)


class OpenPageRankClient(ApiClient):
    def __init__(self):
        super().__init__("OPENPAGERANK")


    async def _execute(self, endpoint_config: Dict[str, Any], agent_id: str = "N/A", **kwargs) -> Union[Dict, str]:
        domains = kwargs.get("domains")
        params = {"domains[]": domains}
        return await self._make_request(endpoint_config, params=params, agent_id=agent_id)


class RapidAPIClient(ApiClient):
    def __init__(self):
        super().__init__("RAPIDAPI")


    async def _execute(self, endpoint_config: Dict[str, Any], agent_id: str = "N/A", **kwargs) -> Union[Dict, str]:
        api_name = kwargs.get("api_name")
        api_kwargs = kwargs.get("api_kwargs", {})
        
        return await self._make_request(endpoint_config, params=api_kwargs, agent_id=agent_id)

# app_clients_instances.py
import google.generativeai as genai
from google.generativeai import types
import asyncio
from typing import Dict, Any, List, Optional, Union

from config import config
from app_singletons import endpoint_health_manager, quota_manager
from api_clients import (
    ApiClient, WebContainerClient, OCRApiClient, DeepSeekClient, SerperClient,
    WolframAlphaClient, TavilyClient, ApiFlashClient, CrawlbaseClient,
    DetectLanguageClient, GuardianClient, IP2LocationClient, ShodanClient,
    WeatherAPIClient, CloudmersiveClient, GreyNoiseClient, PulsediveClient,
    StormGlassClient, LoginRadiusClient, JsonbinClient, HuggingFaceClient,
    TwilioClient, AbstractAPIClient, GoogleCustomSearchClient,
    RandommerClient, TomorrowIOClient, OpenWeatherMapClient, MockarooClient,
    OpenPageRankClient, RapidAPIClient,
    GeminiApiClient, TelegramBotClient, LLMApiClient
)
from utils import log_message

# --- Instanciation de tous les clients API ---
# Chaque client est un singleton de fait, instancié une seule fois ici.

# Clients pour les 7 types de cerveaux principaux
gemini_client = GeminiApiClient()
deepseek_client = DeepSeekClient()
huggingface_client = HuggingFaceClient()
tavily_client = TavilyClient()
serper_client = SerperClient()
google_custom_search_client = GoogleCustomSearchClient()
wolfram_alpha_client = WolframAlphaClient()

# Client pour la communication système
telegram_bot_client = TelegramBotClient()

# Clients pour services auxiliaires
webcontainer_client = WebContainerClient()
ocr_client = OCRApiClient()
apiflash_client = ApiFlashClient()
crawlbase_client = CrawlbaseClient()
detect_language_client = DetectLanguageClient()
guardian_client = GuardianClient()
ip2location_client = IP2LocationClient()
shodan_client = ShodanClient()
weather_api_client = WeatherAPIClient()
cloudmersive_client = CloudmersiveClient()
greynoise_client = GreyNoiseClient()
pulsedive_client = PulsediveClient()
stormglass_client = StormGlassClient()
loginradius_client = LoginRadiusClient()
jsonbin_client = JsonbinClient()
twilio_client = TwilioClient()
abstractapi_client = AbstractAPIClient()
randommer_client = RandommerClient()
tomorrow_io_client = TomorrowIOClient()
openweathermap_client = OpenWeatherMapClient()
mockaroo_client = MockarooClient()
openpagerank_client = OpenPageRankClient()
rapidapi_client = RapidAPIClient()


# Dictionnaire centralisé pour un accès facile.
# C'est "l'annuaire" des connexions.
API_CLIENTS: Dict[str, ApiClient] = {
    "GEMINI_API": gemini_client,
    "DEEPSEEK": deepseek_client,
    "HUGGINGFACE": huggingface_client,
    "TAVILY": tavily_client,
    "SERPER": serper_client,
    "GOOGLE_CUSTOM_SEARCH": google_custom_search_client,
    "WOLFRAMALPHA": wolfram_alpha_client,
    "TELEGRAM_BOT": telegram_bot_client,
    "WEBCONTAINER": webcontainer_client,
    "OCR_API": ocr_client,
    "APIFLASH": apiflash_client,
    "CRAWLBASE": crawlbase_client,
    "DETECTLANGUAGE": detect_language_client,
    "GUARDIAN": guardian_client,
    "IP2LOCATION": ip2location_client,
    "SHODAN": shodan_client,
    "WEATHERAPI": weather_api_client,
    "CLOUDMERSIVE": cloudmersive_client,
    "GREYNOISE": greynoise_client,
    "PULSEDIVE": pulsedive_client,
    "STORMGLASS": stormglass_client,
    "LOGINRADIUS": loginradius_client,
    "JSONBIN": jsonbin_client,
    "TWILIO": twilio_client,
    "ABSTRACTAPI": abstractapi_client,
    "RANDOMMER": randommer_client,
    "TOMORROW.IO": tomorrow_io_client,
    "OPENWEATHERMAP": openweathermap_client,
    "MOCKAROO": mockaroo_client,
    "OPENPAGERANK": openpagerank_client,
    "RAPIDAPI": rapidapi_client
}

def get_client(service_name: str) -> Optional[ApiClient]:
    """
    Récupère une instance de client API par son nom de service.
    """
    client = API_CLIENTS.get(service_name.upper())
    if not client:
        log_message(f"Tentative d'accès à un client non instancié: {service_name}", level="error")
    return client

def get_all_clients() -> Dict[str, ApiClient]:
    """Retourne une copie de l'annuaire de tous les clients API disponibles."""
    return API_CLIENTS.copy()

async def get_healthy_clients() -> Dict[str, ApiClient]:
    """Retourne uniquement les clients avec des services sains."""
    healthy_clients = {}
    
    for service_name, client in API_CLIENTS.items():
        try:
            is_healthy = await endpoint_health_manager.is_service_healthy(service_name)
            if is_healthy:
                healthy_clients[service_name] = client
            else:
                log_message(f"Client {service_name} non sain, exclu de la liste des clients sains.", level="debug")
        except Exception as e:
            log_message(f"Erreur lors de la vérification de santé pour {service_name}: {e}", level="warning")
    
    return healthy_clients

async def test_all_clients() -> Dict[str, bool]:
    """Teste la connectivité de tous les clients."""
    results = {}
    
    for service_name, client in API_CLIENTS.items():
        try:
            if isinstance(client, LLMApiClient):
                healthy_endpoints = await endpoint_health_manager.get_healthy_endpoints(service_name)
                results[service_name] = bool(healthy_endpoints)
            elif hasattr(client, 'endpoints') and client.endpoints:
                results[service_name] = True
            else:
                results[service_name] = False
        except Exception as e:
            log_message(f"Erreur test client {service_name}: {e}", level="error")
            results[service_name] = False
    
    return results

async def rotate_client_endpoints():
    """Force la rotation des endpoints pour tous les clients."""
    log_message("Rotation forcée des endpoints demandée. La logique est gérée par les participants ou le gestionnaire de santé.")
    for service_name, client in API_CLIENTS.items():
        if hasattr(client, 'current_endpoint_index') and hasattr(client, 'endpoints'):
            if client.endpoints:
                client.current_endpoint_index = (client.current_endpoint_index + 1) % len(client.endpoints)
                log_message(f"Rotation forcée pour {service_name}, nouvel index: {client.current_endpoint_index}")

def get_client_statistics() -> Dict[str, Any]:
    """Retourne les statistiques des clients API."""
    stats = {
        "total_clients": len(API_CLIENTS),
        "services_configured": len(config.API_CONFIG),
        "clients_by_type": {},
        "endpoint_counts": {}
    }
    
    for service_name, client in API_CLIENTS.items():
        client_type = type(client).__name__
        if client_type not in stats["clients_by_type"]:
            stats["clients_by_type"][client_type] = 0
        stats["clients_by_type"][client_type] += 1
        
        if hasattr(client, 'endpoints'):
            stats["endpoint_counts"][service_name] = len(client.endpoints)
    
    return stats

def validate_clients_initialization() -> bool:
    """Valide que tous les clients essentiels pour les cerveaux sont bien instanciés."""
    essential_services = [
        "GEMINI_API", "DEEPSEEK", "HUGGINGFACE", "TAVILY",
        "SERPER", "GOOGLE_CUSTOM_SEARCH", "WOLFRAMALPHA", "TELEGRAM_BOT"
    ]
    
    all_ok = True
    for service_name in essential_services:
        if service_name not in API_CLIENTS or API_CLIENTS[service_name] is None:
            log_message(f"Client essentiel '{service_name}' non initialisé !", level="critical")
            all_ok = False
    
    if all_ok:
        log_message("Tous les clients API essentiels ont été instanciés avec succès.")
    else:
        log_message("Échec de l'initialisation de certains clients API essentiels.", level="critical")
        
    return all_ok

validate_clients_initialization()

# app_singletons.py
from endpoint_health_manager import endpoint_health_manager
from quota_manager import quota_manager

# Ce fichier sert uniquement à ré-exporter les instances uniques (singletons)
# des gestionnaires. Cela permet aux autres modules d'importer depuis un
# seul endroit, ce qui simplifie la gestion des dépendances et évite
# les imports circulaires si les gestionnaires devaient un jour se connaître.

__all__ = [
    'endpoint_health_manager',
    'quota_manager'
]

# autonomous_brain.py
import json
import re
import random
import traceback
import uuid
import asyncio
from typing import Dict, Any, List, Optional, Union

from config import config
# This will fail, I need to create brain_library.py first. I will fix this later.
# For now, I will assume it exists.
# from brain_library import BrainMemoryManager, TelegramMemoryIntegration
from utils import log_message, format_error, adaptive_temp
import telegram_logger
from app_clients_instances import get_client
from event_bus import event_bus

# Mocking classes until brain_library.py is created and fixed
class BrainMemoryManager:
    def __init__(self, brain_id): self.brain_id = brain_id
    async def load_memory(self): pass
    async def get_relevant_context(self, q, limit=3): return []
    async def update_success_rate(self, s): pass
class TelegramMemoryIntegration:
    def __init__(self, tc): self.tc = tc
    async def read_group_memory_by_keywords(self, k): return ""
    async def read_group_memory(self, limit=20): return ""


class AutonomousBrain:
    """
    Classe de base pour un cerveau autonome - L'"OS" de chaque agent.
    Définit la logique de pensée, de mémoire et d'action.
    """
    def __init__(self, brain_id: str, service_name: str, telegram_client: Any, api_key: Any):
        self.brain_id = brain_id
        self.service_name = service_name
        self.api_key = api_key
        self.memory_manager = BrainMemoryManager(brain_id)
        self.telegram_memory = TelegramMemoryIntegration(telegram_client)
        self.api_client = get_client(service_name)
        self.brains: Dict[str, 'AutonomousBrain'] = {}

        if not self.api_client:
            log_message(f"❌ Cerveau {self.brain_id}: Client API pour {service_name} non trouvé.", level="critical")
            raise ValueError(f"Client API manquant pour le service {service_name}")

    async def initialize(self):
        """Initialise le cerveau et charge sa mémoire personnelle."""
        await self.memory_manager.load_memory()
        log_message(f"Cerveau {self.brain_id} initialisé.")

    async def read_complete_memory(self, query_for_context: str) -> str:
        """
        Routine de consultation de la mémoire avec logique de secours restaurée.
        """
        common_words = {'le', 'la', 'les', 'un', 'une', 'des', 'de', 'du', 'et', 'est', 'pour', 'que', 'qui', 'dans'}
        keywords = [word for word in re.findall(r'\b\w{3,}\b', query_for_context.lower()) if word not in common_words]
        unique_keywords = list(set(keywords))[:5]

        collective_memory_text = await self.telegram_memory.read_group_memory_by_keywords(unique_keywords)
        
        if "Aucun souvenir pertinent" in collective_memory_text:
            await telegram_logger.log_agent_decision(self.brain_id, "Recherche mémoire ciblée insuffisante. Passage en mode lecture exhaustive.")
            collective_memory_text = await self.telegram_memory.read_group_memory(limit=config.GROUP_MEMORY_LIMIT)

        personal_context = await self.memory_manager.get_relevant_context(query_for_context, limit=3)
        personal_memory_text = json.dumps(personal_context, indent=2, ensure_ascii=False)

        return f"""=== CONTEXTE MÉMORIEL - AGENT {self.brain_id} ===
--- Souvenirs Collectifs (Recherche par mots-clés: {', '.join(unique_keywords)}) ---
{collective_memory_text}
--- Souvenirs Personnels (Interactions passées pertinentes) ---
{personal_memory_text}
"""

    async def process_request(
        self,
        user_query: str,
        endpoint_config: Dict[str, Any],
        chat_history: Optional[List[Dict]] = None,
        image_data: Optional[str] = None,
        tools: Optional[List[Dict]] = None
    ) -> Dict[str, Any]:
        """
        Processus de pensée principal avec logique de délégation horizontale directe.
        """
        try:
            memory_context = await self.read_complete_memory(user_query)
            enriched_prompt = f"{memory_context}\n\n--- REQUÊTE ACTUELLE ---\n{user_query}"
            from tools import get_gemini_tools
            available_tools = tools if tools is not None else get_gemini_tools()
            response = await self._generate_response(
                endpoint_config=endpoint_config, prompt=enriched_prompt,
                chat_history=chat_history or [], image_data=image_data, tools=available_tools
            )
            if isinstance(response, str) and response.startswith("❌"):
                raise Exception(f"La génération de réponse a échoué: {response}")
            
            tool_results = []
            if isinstance(response, dict) and "candidates" in response:
                content_parts = response.get("candidates", [{}])[0].get("content", {}).get("parts", [])
                function_calls = [part["function_call"] for part in content_parts if "function_call" in part]
                if function_calls:
                    tool_results = await self._execute_tools(function_calls)
            
            await self.memory_manager.update_success_rate(True)
            return {"response": response, "brain_id": self.brain_id, "tool_results": tool_results}

        except Exception as e:
            await self.memory_manager.update_success_rate(False)
            error_msg = f"Échec du traitement par {self.brain_id}: {format_error(e)}"
            await telegram_logger.log_error(self.brain_id, error_msg)
            
            try:
                available_agents = [p for p in self.brains.values() if p.brain_id != self.brain_id]
                if not available_agents:
                    raise Exception("Aucun autre agent disponible pour la délégation.")
                
                delegate_agent = random.choice(available_agents)
                await telegram_logger.log_agent_decision(
                    self.brain_id,
                    f"Délégation directe de la tâche à l'agent '{delegate_agent.brain_id}'."
                )
                delegation_prompt = f"""CONTEXTE: Je suis l'agent {self.brain_id}. J'ai échoué à traiter la requête suivante.
REQUÊTE ORIGINALE: "{user_query}"
MON ERREUR: "{str(e)}"
MISSION POUR TOI, {delegate_agent.brain_id}: Prends le relais."""
                
                final_response = await delegate_agent.execute_task(
                    task_description="Delegated User Query",
                    prompt=delegation_prompt, image_data=image_data, tools=tools
                )
                final_response["brain_id"] = f"{self.brain_id} -> (délégué à {delegate_agent.brain_id})"
                return final_response
            except Exception as final_e:
                error_msg_delegation = f"Échec de la tentative initiale ET de la délégation: {format_error(final_e)}"
                await telegram_logger.log_error(self.brain_id, error_msg_delegation)
                return {"error": error_msg_delegation, "brain_id": self.brain_id}

    async def _generate_response(self, endpoint_config: Dict[str, Any], **kwargs) -> Union[Dict, str]:
        raise NotImplementedError("Chaque type de cerveau doit implémenter sa méthode de génération.")

    async def _execute_tools(self, function_calls: List[Dict]) -> List[Dict]:
        results = []
        from tools import execute_tool
        for func_call in function_calls:
            tool_name = func_call.get("name")
            tool_args = func_call.get("args", {})
            await telegram_logger.log_agent_decision(
                self.brain_id, f"Appel de l'outil: {tool_name}", {"args": tool_args}
            )
            try:
                tool_result = await execute_tool(tool_name, context={"brain_id": self.brain_id}, **tool_args)
                results.append(tool_result)
            except Exception as e:
                error_msg = f"Erreur lors de l'exécution de l'outil {tool_name}: {format_error(e)}"
                await telegram_logger.log_error(self.brain_id, error_msg)
                results.append({"tool_name": tool_name, "error": error_msg})
        return results

    async def participate_in_coding_challenge(self, challenge_prompt: str, endpoint_config: Dict[str, Any]) -> Dict[str, Any]:
        try:
            memory_context = await self.read_complete_memory(challenge_prompt)
            coding_prompt = f"""{memory_context}
=== DÉFI DE CODAGE D'AUTO-AMÉLIORATION ===
{challenge_prompt}
En tant qu'agent {self.brain_id}, génère une solution Python complète, optimisée et prête à l'exécution.
Ta réponse doit contenir UNIQUEMENT le bloc de code Python."""
            
            dynamic_temperature = adaptive_temp(challenge_prompt)
            response = await self._generate_response(
                endpoint_config=endpoint_config,
                prompt=coding_prompt,
                chat_history=[],
                tools=[],
                temperature=dynamic_temperature
            )
            return {"response": response, "brain_id": self.brain_id}
        except Exception as e:
            return {"error": f"Échec du défi de codage pour {self.brain_id}: {format_error(e)}", "brain_id": self.brain_id}

class GeminiBrain(AutonomousBrain):
    def __init__(self, brain_id: str, service_name: str, telegram_client: Any, api_key: Any):
        super().__init__(brain_id, service_name, telegram_client, api_key)
    async def _generate_response(self, endpoint_config: Dict[str, Any], **kwargs) -> Union[Dict, str]:
        return await self.api_client.generate_content(endpoint_config, agent_id=self.brain_id, **kwargs)

class DeepSeekBrain(AutonomousBrain):
    def __init__(self, brain_id: str, service_name: str, telegram_client: Any, api_key: Any):
        super().__init__(brain_id, service_name, telegram_client, api_key)
    async def _generate_response(self, endpoint_config: Dict[str, Any], **kwargs) -> Union[Dict, str]:
        result = await self.api_client.generate_content(endpoint_config, agent_id=self.brain_id, **kwargs)
        if isinstance(result, dict) and "choices" in result and result["choices"]:
            content = result["choices"][0]["message"]["content"]
            return {"candidates": [{"content": {"parts": [{"text": content}]}}]}
        return {"candidates": [{"content": {"parts": [{"text": str(result)}]}}]}

class HuggingFaceBrain(AutonomousBrain):
    def __init__(self, brain_id: str, service_name: str, telegram_client: Any, api_key: Any):
        super().__init__(brain_id, service_name, telegram_client, api_key)
    async def _generate_response(self, endpoint_config: Dict[str, Any], **kwargs) -> Union[Dict, str]:
        prompt = kwargs.get("prompt", "")
        result = await self.api_client.generate_content(endpoint_config, agent_id=self.brain_id, **kwargs)
        if isinstance(result, list) and result:
            generated_text = result[0].get("generated_text", prompt)
            new_text = generated_text[len(prompt):].strip()
            if not new_text:
                new_text = "Réponse générée par HuggingFace"
            return {"candidates": [{"content": {"parts": [{"text": new_text}]}}]}
        return {"candidates": [{"content": {"parts": [{"text": str(result)}]}}]}

class TavilyBrain(AutonomousBrain):
    def __init__(self, brain_id: str, service_name: str, telegram_client: Any, api_key: Any):
        super().__init__(brain_id, service_name, telegram_client, api_key)
    async def _generate_response(self, endpoint_config: Dict[str, Any], **kwargs) -> Union[Dict, str]:
        prompt = kwargs.get("prompt")
        max_results = kwargs.get("max_results", 5)
        result = await self.api_client.execute_with_config(endpoint_config, query=prompt, max_results=max_results, agent_id=self.brain_id)
        answer = result.get("answer", "")
        results = result.get("results", [])
        synthesis = f"Réponse Tavily: {answer}\n\n"
        if results:
            synthesis += "Sources:\n"
            for i, res in enumerate(results[:3], 1):
                title = res.get("title", "Sans titre")
                content = res.get("content", "")[:200]
                synthesis += f"{i}. {title}: {content}...\n"
        return {"candidates": [{"content": {"parts": [{"text": synthesis}]}}]}

class SerperBrain(AutonomousBrain):
    def __init__(self, brain_id: str, service_name: str, telegram_client: Any, api_key: Any):
        super().__init__(brain_id, service_name, telegram_client, api_key)
    async def _generate_response(self, endpoint_config: Dict[str, Any], **kwargs) -> Union[Dict, str]:
        prompt = kwargs.get("prompt")
        result = await self.api_client.execute_with_config(endpoint_config, query=prompt, agent_id=self.brain_id)
        organic = result.get("organic", [])
        answer_box = result.get("answerBox", {})
        synthesis = ""
        if answer_box:
            synthesis += f"Réponse directe: {answer_box.get('answer', '')}\n\n"
        if organic:
            synthesis += "Résultats de recherche:\n"
            for i, res in enumerate(organic[:3], 1):
                title = res.get("title", "Sans titre")
                snippet = res.get("snippet", "")
                synthesis += f"{i}. {title}: {snippet}\n"
        if not synthesis:
            synthesis = "Aucun résultat trouvé pour cette recherche."
        return {"candidates": [{"content": {"parts": [{"text": synthesis}]}}]}

class GoogleCustomSearchBrain(AutonomousBrain):
    def __init__(self, brain_id: str, service_name: str, telegram_client: Any, api_key: Any):
        super().__init__(brain_id, service_name, telegram_client, api_key)
    async def _generate_response(self, endpoint_config: Dict[str, Any], **kwargs) -> Union[Dict, str]:
        prompt = kwargs.get("prompt")
        result = await self.api_client.execute_with_config(endpoint_config, query=prompt, agent_id=self.brain_id)
        items = result.get("items", [])
        synthesis = f"Résultats Google pour: {prompt}\n\n"
        if items:
            for i, item in enumerate(items[:3], 1):
                title = item.get("title", "Sans titre")
                snippet = item.get("snippet", "")
                synthesis += f"{i}. {title}: {snippet}\n"
        else:
            synthesis += "Aucun résultat trouvé."
        return {"candidates": [{"content": {"parts": [{"text": synthesis}]}}]}

class WolframAlphaBrain(AutonomousBrain):
    def __init__(self, brain_id: str, service_name: str, telegram_client: Any, api_key: Any):
        super().__init__(brain_id, service_name, telegram_client, api_key)
    async def _generate_response(self, endpoint_config: Dict[str, Any], **kwargs) -> Union[Dict, str]:
        prompt = kwargs.get("prompt")
        result = await self.api_client.execute_with_config(endpoint_config, input_text=prompt, agent_id=self.brain_id)
        query_result = result.get("queryresult", {})
        pods = query_result.get("pods", [])
        synthesis = f"Résultat Wolfram Alpha pour: {prompt}\n\n"
        if pods:
            for pod in pods[:3]:
                title = pod.get("title", "")
                subpods = pod.get("subpods", [])
                if subpods:
                    text = subpods[0].get("plaintext", "")
                    if text:
                        synthesis += f"{title}: {text}\n"
        else:
            synthesis += "Aucun résultat calculable trouvé."
        return {"candidates": [{"content": {"parts": [{"text": synthesis}]}}]}

def create_brain(brain_type: str, brain_id: str, telegram_client: Any, api_key: Any) -> AutonomousBrain:
    """Factory pour créer un cerveau du type demandé, avec fallback pour les agents non-LLM."""
    brain_classes = {
        "GEMINI": GeminiBrain, "DEEPSEEK": DeepSeekBrain, "HUGGINGFACE": HuggingFaceBrain,
        "TAVILY": TavilyBrain, "SERPER": SerperBrain,
        "GOOGLE_CUSTOM_SEARCH": GoogleCustomSearchBrain, "WOLFRAMALPHA": WolframAlphaBrain
    }
    final_brain_type = brain_type
    if brain_type not in brain_classes:
        tool_based_agents = [
            "WEBCONTAINER", "APIFLASH", "CRAWLBASE", "DETECTLANGUAGE", "GUARDIAN", 
            "IP2LOCATION", "SHODAN", "WEATHERAPI", "CLOUDMERSIVE", "GREYNOISE", 
            "PULSEDIVE", "STORMGLASS", "LOGINRADIUS", "JSONBIN", "TWILIO", 
            "ABSTRACTAPI", "RANDOMMER", "TOMORROW.IO", "OPENWEATHERMAP", 
            "MOCKAROO", "OPENPAGERANK", "RAPIDAPI", "OCR_API"
        ]
        if brain_type in tool_based_agents:
            final_brain_type = "TAVILY"
            log_message(f"Aucun cerveau spécifique pour '{brain_type}', utilisation du fallback '{final_brain_type}'.", "debug")
        else:
            raise ValueError(f"Type de cerveau non supporté: {brain_type}")
    
    service_name_map = {
        "GEMINI": "GEMINI_API", "DEEPSEEK": "DEEPSEEK", "HUGGINGFACE": "HUGGINGFACE",
        "TAVILY": "TAVILY", "SERPER": "SERPER", 
        "GOOGLE_CUSTOM_SEARCH": "GOOGLE_CUSTOM_SEARCH", "WOLFRAMALPHA": "WOLFRAMALPHA",
        "WEBCONTAINER": "WEBCONTAINER", "OCR_API": "OCR_API", "APIFLASH": "APIFLASH",
        "CRAWLBASE": "CRAWLBASE", "DETECTLANGUAGE": "DETECTLANGUAGE", "GUARDIAN": "GUARDIAN",
        "IP2LOCATION": "IP2LOCATION", "SHODAN": "SHODAN", "WEATHERAPI": "WEATHERAPI",
        "CLOUDMERSIVE": "CLOUDMERSIVE", "GREYNOISE": "GREYNOISE", "PULSEDIVE": "PULSEDIVE",
        "STORMGLASS": "STORMGLASS", "LOGINRADIUS": "LOGINRADIUS", "JSONBIN": "JSONBIN",
        "TWILIO": "TWILIO", "ABSTRACTAPI": "ABSTRACTAPI", "RANDOMMER": "RANDOMMER",
        "TOMORROW.IO": "TOMORROW.IO", "OPENWEATHERMAP": "OPENWEATHERMAP",
        "MOCKAROO": "MOCKAROO", "OPENPAGERANK": "OPENPAGERANK", "RAPIDAPI": "RAPIDAPI"
    }
    service_name_for_api_client = service_name_map.get(brain_type, brain_type)
    
    cls = brain_classes.get(final_brain_type)
    if not cls:
        raise ValueError(f"Classe de cerveau non trouvée pour: {final_brain_type}")
    
    return cls(brain_id=brain_id, service_name=service_name_for_api_client, telegram_client=telegram_client, api_key=api_key)

# autonomous_participant.py
import asyncio
import random
from datetime import datetime
from typing import Dict, Any, Optional, List

from config import config
from utils import log_message, save_json, format_error
from autonomous_brain import create_brain
from app_singletons import endpoint_health_manager, quota_manager
import telegram_logger
from event_bus import event_bus
from shared_state import shared_state

class AutonomousParticipant:
    """
    Représente un agent de travail individuel dans l'essaim, défini par une seule clé API.
    C'est "l'ouvrier spécialisé" qui devient proactif.
    """
    def __init__(self, participant_id: str, brain_type: str, service_name: str, api_key: Any, telegram_client: Optional[Any]):
        """
        Initialise un participant et l'abonne aux événements pertinents.
        """
        self.id = participant_id
        self.brain_type = brain_type
        self.service_name = service_name
        self.api_key = api_key
        
        self.processing_engine = create_brain(
            brain_type=self.brain_type,
            brain_id=self.id,
            telegram_client=telegram_client,
            api_key=self.api_key
        )
        
        self.archive_path = config.ARCHIVE_DIR / self.id
        self.archive_path.mkdir(parents=True, exist_ok=True)
        
        # L'agent s'abonne aux annonces de tâches et aux demandes d'aide
        asyncio.create_task(event_bus.subscribe("USER_REQUEST_RECEIVED", self.on_new_task))
        asyncio.create_task(event_bus.subscribe("HELP_REQUESTED", self.on_help_request))
        
        log_message(f"Participant '{self.id}' (type {self.brain_type}) initialisé et à l'écoute.")

    async def on_new_task(self, data: Dict[str, Any]):
        """Agit sur une tâche principale uniquement si c'est le leader désigné."""
        current_leader_id = await shared_state.get_current_leader()
        if current_leader_id == self.id:
            log_message(f"Agent {self.id} (Leader) prend la tâche: {data.get('query')[:50]}...", "info")
            final_response = await self.execute_task(
                task_description="User Query",
                prompt=data.get("query"),
                image_data=data.get("image_data"),
                tools=config.TOOL_CONFIG
            )
            # Publie la réponse pour que le main.py puisse la récupérer
            await event_bus.publish("RESPONSE_READY", data=final_response)

    async def on_help_request(self, data: Dict[str, Any]):
        """Répond à une demande d'aide d'un autre agent, s'il n'est pas le demandeur."""
        if data.get("requester_id") == self.id:
            return

        # Pour éviter que tous les agents répondent en même temps, on introduit un délai aléatoire
        await asyncio.sleep(random.uniform(0.1, 1.0))
        
        log_message(f"Agent {self.id} propose son aide pour la question : {data['question'][:50]}...", "info")
        
        # L'agent utilise sa propre logique pour traiter la demande d'aide
        response = await self.execute_task(
            task_description="Help Request",
            prompt=data['question'],
            tools=config.TOOL_CONFIG
        )
        
        # Publie la réponse d'aide sur un canal spécifique
        await event_bus.publish(
            "HELP_RESPONSE_READY",
            data={"response": response, "request_id": data['request_id']}
        )

    async def execute_task(
        self,
        task_description: str,
        prompt: str,
        chat_history: Optional[List[Dict]] = None,
        image_data: Optional[str] = None,
        tools: Optional[List[Dict]] = None
    ) -> Dict[str, Any]:
        """
        Exécute une tâche en itérant sur TOUS les endpoints disponibles pour son service,
        collectant les résultats et sélectionnant le meilleur. (Logique V1 restaurée)
        """
        start_task_time = asyncio.get_event_loop().time()
        log_message(f"Participant '{self.id}' commence la tâche (mode tenace) : {task_description}")

        api_client_instance = self.processing_engine.api_client
        if not api_client_instance:
            # ... (gestion d'erreur identique)
            error_msg = f"Client API non trouvé pour le service {self.service_name}."
            await telegram_logger.log_error(self.id, error_msg)
            return {"error": error_msg, "brain_id": self.id}

        # Récupère TOUS les endpoints pour le service de l'agent
        all_endpoints_for_service = api_client_instance.endpoints

        if not all_endpoints_for_service:
            # ... (gestion d'erreur identique)
            error_msg = f"Aucun endpoint configuré pour le service {self.service_name}."
            await telegram_logger.log_error(self.id, error_msg)
            return {"error": error_msg, "brain_id": self.id}

        attempt_results = []
        best_successful_result = None
        
        # ===== BOUCLE DE TÉNACITÉ RESTAURÉE =====
        for endpoint_config in all_endpoints_for_service:
            endpoint_name = endpoint_config.get("endpoint_name", "Unknown Endpoint")
            
            # Vérifier la santé de cet endpoint spécifique avant de l'utiliser
            is_healthy = await endpoint_health_manager.is_healthy(endpoint_name, self.service_name)
            if not is_healthy:
                log_message(f"Participant '{self.id}' ignore l'endpoint non sain: {endpoint_name}", "debug")
                continue # Passe au suivant

            try:
                # Le reste de la logique d'exécution est similaire à votre V1
                # mais encapsulée pour chaque tentative
                if task_description == "Défi de Codage":
                    response_payload = await self.processing_engine.participate_in_coding_challenge(
                        challenge_prompt=prompt,
                        endpoint_config=endpoint_config
                    )
                else:
                    response_payload = await self.processing_engine.process_request(
                        user_query=prompt,
                        chat_history=chat_history,
                        image_data=image_data,
                        tools=tools,
                        endpoint_config=endpoint_config
                    )

                if "error" not in response_payload:
                    # Premier succès trouvé, on le garde comme le meilleur et on arrête
                    best_successful_result = response_payload
                    log_message(f"Participant '{self.id}' a réussi la tâche avec l'endpoint: {endpoint_name}", "info")
                    break # On a un succès, on peut arrêter de boucler
                else:
                    attempt_results.append(response_payload)

            except Exception as e:
                error_msg = f"Exception inattendue avec {endpoint_name}: {format_error(e)}"
                attempt_results.append({"error": error_msg, "brain_id": self.id})
        # ===== FIN DE LA BOUCLE =====

        final_result_payload = best_successful_result
        if not final_result_payload:
            # Si aucun succès, on retourne une erreur consolidée
            final_result_payload = {
                "error": "Toutes les tentatives via les endpoints disponibles ont échoué.",
                "brain_id": self.id,
                "attempts": attempt_results
            }

        total_latency_ms = int((asyncio.get_event_loop().time() - start_task_time) * 1000)
        await self._archive_action(task_description, prompt, final_result_payload, total_latency_ms)
        
        return final_result_payload

    async def _archive_action(self, task_description: str, input_prompt: str, result_payload: Dict[str, Any], latency_ms: int):
        """
        Archive les détails d'une action effectuée par le participant dans un fichier JSON.
        """
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S_%f")
        archive_file = config.ARCHIVE_DIR / self.id / f"{timestamp}_{task_description.replace(' ', '_')}.json"
        
        raw_response_text = "Extraction de la réponse échouée."
        if "response" in result_payload and isinstance(result_payload["response"], dict):
            candidates = result_payload["response"].get('candidates', [])
            if candidates and 'content' in candidates[0]:
                parts = candidates[0]['content'].get('parts', [])
                if parts and 'text' in parts[0]:
                    raw_response_text = parts[0]['text']
        elif "error" in result_payload:
            raw_response_text = f"ERREUR: {result_payload['error']}"
        
        from utils import extract_code_from_response
        code_content = extract_code_from_response(raw_response_text) if "Défi de Codage" in task_description else None
        
        archive_data = {
            "participant_id": self.id,
            "brain_type_used": self.brain_type,
            "timestamp_utc": datetime.utcnow().isoformat(),
            "task_description": task_description,
            "input_prompt": input_prompt,
            "result_payload": result_payload,
            "extracted_content": raw_response_text,
            "extracted_code": code_content,
            "performance_metadata": {
                "latency_ms": latency_ms,
                "success": "error" not in result_payload
            }
        }
        
        await save_json(archive_file, archive_data)
        log_message(f"Action de '{self.id}' archivée dans '{archive_file}'")

# brain_library.py
import json
import time
from datetime import datetime, timedelta
from pathlib import Path
from typing import Dict, Any, List, Optional

from telegram import Bot
from telegram.error import TelegramError

from config import config
from utils import save_json, load_json, log_message, truncate_text, format_error

class BrainMemoryManager:
    """
    Gère la mémoire à court et long terme pour un cerveau autonome spécifique.
    C'est le "journal de bord" de l'agent.
    """
    def __init__(self, brain_id: str):
        self.brain_id = brain_id
        self.memory_file = config.BRAIN_MEMORY_FILE
        self.memory: Dict[str, Any] = {"interactions": [], "success_rate": 1.0, "total_runs": 0}

    async def load_memory(self):
        """Charge la mémoire depuis le fichier de stockage global."""
        all_brains_memory = await load_json(self.memory_file, {})
        if self.brain_id in all_brains_memory:
            self.memory = all_brains_memory[self.brain_id]
        else:
            # Initialise la mémoire pour ce cerveau s'il n'existe pas encore
            all_brains_memory[self.brain_id] = self.memory
            await save_json(self.memory_file, all_brains_memory)
        log_message(f"Mémoire chargée pour le cerveau {self.brain_id}", "debug")

    async def save_memory(self):
        """Sauvegarde la mémoire du cerveau dans le fichier global."""
        all_brains_memory = await load_json(self.memory_file, {})
        all_brains_memory[self.brain_id] = self.memory
        await save_json(self.memory_file, all_brains_memory)
        log_message(f"Mémoire sauvegardée pour le cerveau {self.brain_id}", "debug")

    async def add_interaction(self, user_query: str, response: str, success: bool, latency: float):
        """Ajoute une nouvelle interaction à la mémoire."""
        interaction = {
            "timestamp": datetime.now().isoformat(),
            "user_query": truncate_text(user_query, 500),
            "response": truncate_text(response, 500),
            "success": success,
            "latency_ms": int(latency * 1000)
        }
        self.memory["interactions"].append(interaction)
        
        # Garde seulement les 50 dernières interactions pour éviter une mémoire trop grande
        if len(self.memory["interactions"]) > 50:
            self.memory["interactions"].pop(0)
            
        await self.update_success_rate(success)
        await self.save_memory()

    async def get_relevant_context(self, query: str, limit: int = 5) -> List[Dict]:
        """Récupère les interactions passées les plus pertinentes pour une nouvelle requête."""
        query_words = set(query.lower().split())
        
        def score_relevance(interaction):
            interaction_text = f"{interaction['user_query']} {interaction['response']}".lower()
            return len(query_words.intersection(interaction_text.split()))

        sorted_interactions = sorted(self.memory["interactions"], key=score_relevance, reverse=True)
        return sorted_interactions[:limit]

    async def update_success_rate(self, success: bool):
        """Met à jour le taux de succès du cerveau."""
        total_runs = self.memory.get("total_runs", 0)
        current_rate = self.memory.get("success_rate", 1.0)
        
        # Utilise une moyenne mobile exponentielle pour donner plus de poids aux interactions récentes
        alpha = 0.1 
        new_rate = current_rate * (1 - alpha) + (1.0 if success else 0.0) * alpha
        
        self.memory["success_rate"] = new_rate
        self.memory["total_runs"] = total_runs + 1


class TelegramMemoryIntegration:
    """
    Utilise un groupe Telegram privé comme une bibliothèque de mémoire partagée et un journal d'événements.
    C'est la "bibliothèque" de l'essaim.
    """
    def __init__(self, bot_client: Optional[Bot]):
        self.bot_client = bot_client
        self.group_id = config.PRIVATE_GROUP_ID
        self.chat_history_file = config.USER_CHAT_HISTORY_FILE
        self.is_active = bool(self.bot_client and self.group_id)
        if not self.is_active:
            log_message("Intégration mémoire Telegram désactivée (bot ou group_id manquant).", "warning")

    async def write_to_group(self, message: str, message_type: str = "INFO"):
        """Écrit un message dans le groupe Telegram privé."""
        if not self.is_active:
            log_message(f"[MEMOIRE TELEGRAM (CONSOLE)] {message_type}: {message}", "info")
            return

        try:
            # Utilise le client bot directement pour envoyer des messages
            await self.bot_client.send_message(
                chat_id=self.group_id,
                text=f"[{message_type}] {message}"
            )
            log_message(f"Message écrit dans la mémoire du groupe Telegram (type: {message_type}).", "debug")
        except TelegramError as e:
            log_message(f"Erreur lors de l'écriture dans la mémoire du groupe Telegram: {e}", "error")
        except Exception as e:
            log_message(f"Erreur inattendue lors de l'envoi au groupe Telegram: {format_error(e)}", "critical")

    async def read_group_memory(self, limit: int = 20) -> str:
        """Lit les derniers messages du groupe pour fournir un contexte."""
        if not self.is_active:
            return "Mémoire Telegram non active."

        try:
            # La lecture de l'historique n'est pas directement possible via le bot de manière simple.
            # On va donc simuler cette lecture en se basant sur un historique local.
            # C'est une limitation de l'API Bot de Telegram.
            
            # Pour une vraie application, il faudrait un "user bot" ou une base de données.
            # Ici, on lit un fichier JSON qui est mis à jour par le bot.
            history = await load_json(self.chat_history_file, [])
            
            if not history:
                return "Aucun historique de chat trouvé dans la mémoire locale."
            
            context = "--- CONTEXTE RÉCENT DU GROUPE ---\n"
            for message in history[-limit:]:
                sender = message.get('sender', 'Inconnu')
                text = message.get('text', '')
                timestamp = message.get('timestamp', '')
                context += f"[{timestamp}] {sender}: {text}\n"
            
            return context
            
        except Exception as e:
            log_message(f"Erreur lors de la lecture de la mémoire du groupe: {e}", "error")
            return f"Erreur de lecture de la mémoire: {e}"

    async def read_group_memory_by_keywords(self, keywords: List[str], limit: int = 10) -> str:
        """Recherche des messages pertinents dans l'historique local par mots-clés."""
        if not self.is_active:
            return "Mémoire Telegram non active."

        try:
            history = await load_json(self.chat_history_file, [])
            if not history:
                return "Aucun historique de chat trouvé."

            relevant_messages = []
            for message in reversed(history):
                text = message.get('text', '').lower()
                if any(keyword.lower() in text for keyword in keywords):
                    relevant_messages.append(message)
                if len(relevant_messages) >= limit:
                    break
            
            if not relevant_messages:
                return "Aucun souvenir pertinent trouvé pour les mots-clés."
            
            context = f"--- SOUVENIRS PERTINENTS (Mots-clés: {', '.join(keywords)}) ---\n"
            for msg in reversed(relevant_messages):
                context += f"[{msg.get('timestamp')}] {msg.get('sender')}: {msg.get('text')}\n"
            
            return context
            
        except Exception as e:
            log_message(f"Erreur lors de la recherche par mots-clés dans la mémoire: {e}", "error")
            return f"Erreur de recherche mémoire: {e}"

    async def update_chat_history(self, message_data: Dict):
        """Met à jour le fichier d'historique local avec un nouveau message."""
        if not self.is_active:
            return
            
        history = await load_json(self.chat_history_file, [])
        history.append(message_data)
        
        # Limite la taille de l'historique pour éviter des fichiers trop gros
        if len(history) > 2000:
            history = history[-2000:]
            
        await save_json(self.chat_history_file, history)


# Instance globale pour la bibliothèque de clés API, pourrait être déplacée si nécessaire
class APIKeyLibrary:
    """
    Centralise la gestion et la distribution des clés API.
    C'est le "gardien des clés" du système.
    """
    def __init__(self):
        self.api_keys: Dict[str, List[Dict[str, Any]]] = {}
        self._load_keys_from_config()

    def _load_keys_from_config(self):
        """Charge et structure les clés depuis l'objet de configuration."""
        for service_name, endpoints in config.API_CONFIG.items():
            if service_name not in self.api_keys:
                self.api_keys[service_name] = []
            
            for endpoint_config in endpoints:
                key = endpoint_config.get("key")
                key_info = {
                    "key": key,
                    "endpoints": [
                        {
                            "name": endpoint_config.get("endpoint_name"),
                            "url": endpoint_config.get("url"),
                            "method": endpoint_config.get("method")
                        }
                    ],
                    "usage_count": 0,
                    "last_used": None,
                    "is_healthy": True
                }
                
                # Regroupe les endpoints par clé
                existing_key_info = next((k for k in self.api_keys[service_name] if k["key"] == key), None)
                if existing_key_info:
                    existing_key_info["endpoints"].extend(key_info["endpoints"])
                else:
                    self.api_keys[service_name].append(key_info)
        log_message("Bibliothèque de clés API chargée et structurée.", "info")

    def get_key_for_service(self, service_name: str) -> Optional[Dict[str, Any]]:
        """
        Sélectionne la meilleure clé pour un service donné.
        Stratégie: utilise la clé la moins récemment utilisée et saine.
        """
        if service_name not in self.api_keys or not self.api_keys[service_name]:
            return None

        healthy_keys = [k for k in self.api_keys[service_name] if k["is_healthy"]]
        if not healthy_keys:
            return None # Aucune clé saine disponible

        # Trie les clés par date de dernière utilisation (la plus ancienne d'abord)
        sorted_keys = sorted(healthy_keys, key=lambda k: k.get("last_used", 0))
        
        selected_key = sorted_keys[0]
        selected_key["usage_count"] += 1
        selected_key["last_used"] = time.time()
        
        return selected_key

    def report_key_health(self, service_name: str, key: str, is_healthy: bool):
        """Met à jour le statut de santé d'une clé spécifique."""
        if service_name in self.api_keys:
            for key_info in self.api_keys[service_name]:
                if key_info["key"] == key:
                    key_info["is_healthy"] = is_healthy
                    log_message(f"Santé de la clé pour {service_name} (se terminant par ...{key[-4:]}) mise à jour à: {'Saine' if is_healthy else 'Non saine'}", "debug")
                    break

api_key_library = APIKeyLibrary()

# coding_challenge_system.py
import asyncio
import hashlib
import json
import random
import time
import difflib
import ast
import sys
import os
import tempfile
import unittest
from datetime import datetime, timezone
from pathlib import Path
from typing import Dict, Any, List, Optional, Tuple, Callable

from config import config
from utils import log_message, save_json, extract_code_from_response, format_error, truncate_text
import telegram_logger
from autonomous_participant import AutonomousParticipant
from event_bus import event_bus
# Imports ajoutés
from app_clients_instances import get_client
from app_singletons import endpoint_health_manager

class CodeAnalyzer:
    """
    Classe utilitaire statique pour analyser le code Python et extraire des métriques.
    """
    @staticmethod
    def analyze_python_code(code: str) -> Dict[str, Any]:
        """
        Analyse un code Python et retourne des métriques détaillées.
        """
        metrics = {
            "total_lines": 0, "code_lines": 0, "comment_lines": 0, "blank_lines": 0,
            "functions": 0, "classes": 0, "imports": 0, "complexity_score": 0,
            "syntax_valid": False, "syntax_error": None, "docstring_count": 0,
            "variable_assignments": 0, "loop_count": 0, "conditional_count": 0,
            "try_except_count": 0, "function_calls": 0, "literals": 0
        }
        try:
            lines = code.split('\n')
            metrics["total_lines"] = len(lines)
            for line in lines:
                stripped_line = line.strip()
                if not stripped_line:
                    metrics["blank_lines"] += 1
                elif stripped_line.startswith('#'):
                    metrics["comment_lines"] += 1
                else:
                    metrics["code_lines"] += 1

            tree = ast.parse(code)
            for node in ast.walk(tree):
                if isinstance(node, (ast.FunctionDef, ast.AsyncFunctionDef)):
                    metrics["functions"] += 1
                    if ast.get_docstring(node): metrics["docstring_count"] += 1
                elif isinstance(node, ast.ClassDef):
                    metrics["classes"] += 1
                    if ast.get_docstring(node): metrics["docstring_count"] += 1
                elif isinstance(node, (ast.Import, ast.ImportFrom)): metrics["imports"] += 1
                elif isinstance(node, (ast.For, ast.While, ast.AsyncFor)): metrics["loop_count"] += 1
                elif isinstance(node, (ast.If, ast.IfExp)): metrics["conditional_count"] += 1
                elif isinstance(node, ast.Try): metrics["try_except_count"] += 1
                elif isinstance(node, ast.Assign): metrics["variable_assignments"] += len(node.targets)
                elif isinstance(node, ast.Call): metrics["function_calls"] += 1
                elif isinstance(node, (ast.Constant, ast.Num, ast.Str, ast.Bytes, ast.NameConstant)): metrics["literals"] += 1

            metrics["complexity_score"] = CodeAnalyzer.calculate_cyclomatic_complexity(code)
            metrics["syntax_valid"] = True

        except SyntaxError as e:
            metrics["syntax_valid"] = False
            metrics["syntax_error"] = str(e)
        except Exception as e:
            metrics["syntax_valid"] = False
            metrics["syntax_error"] = f"Erreur d'analyse AST: {format_error(e)}"
        
        return metrics

    @staticmethod
    def calculate_cyclomatic_complexity(code: str) -> int:
        """Calcule la complexité cyclomatique approximative d'un code Python."""
        try:
            tree = ast.parse(code)
            complexity = 1
            for node in ast.walk(tree):
                if isinstance(node, (ast.If, ast.For, ast.While, ast.AsyncFor, ast.With, ast.AsyncWith)):
                    complexity += 1
                elif isinstance(node, (ast.And, ast.Or)):
                    complexity += 1
                elif isinstance(node, ast.ExceptHandler):
                    complexity += 1
            return complexity
        except SyntaxError:
            return -1
        except Exception as e:
            log_message(f"Erreur calcul complexité cyclomatique: {format_error(e)}", level="error")
            return -2

    @staticmethod
    def validate_python_syntax(code: str) -> Tuple[bool, Optional[str]]:
        """Valide la syntaxe d'un code Python."""
        try:
            ast.parse(code)
            return True, None
        except SyntaxError as e:
            return False, str(e)
        except Exception as e:
            return False, f"Erreur inattendue lors de la validation syntaxique: {format_error(e)}"

    @staticmethod
    def get_code_hash(code: str) -> str:
        """Calcule le hachage SHA256 d'un code pour l'identification unique."""
        return hashlib.sha256(code.encode('utf-8')).hexdigest()

class ChallengeEvaluator:
    """
    Évalue les soumissions de code des agents. C'est le "Juge".
    """
    async def _generate_dynamic_content_with_llm(self, prompt: str) -> str:
        """Utilise un LLM pour générer du contenu dynamique (défis ou tests)."""
        try:
            # On utilise le client Gemini par défaut pour cette tâche créative
            client = get_client("GEMINI_API")
            if not client:
                raise Exception("Client Gemini non disponible pour la génération dynamique.")
            
            endpoint_config = await endpoint_health_manager.get_best_endpoint("GEMINI_API")
            if not endpoint_config:
                raise Exception("Aucun endpoint Gemini sain pour la génération dynamique.")

            # Note : on utilise execute_with_specific_config pour un contrôle direct
            response = await client.execute_with_specific_config(
                endpoint_config,
                json_data={"contents": [{"parts": [{"text": prompt}]}]},
                agent_id="ChallengeGenerator"
            )

            if isinstance(response, dict) and response.get("candidates"):
                content = response["candidates"][0].get("content", {}).get("parts", [{}])[0].get("text", "")
                # On cherche un bloc de code, sinon on prend le texte brut
                code_block = extract_code_from_response(content)
                return code_block if code_block else content
            else:
                log_message(f"Réponse inattendue du LLM pour la génération de contenu: {response}", "warning")
                return f"# Erreur: Réponse inattendue du LLM\nraise Exception('Génération de test échouée')"

        except Exception as e:
            log_message(f"Erreur lors de la génération de contenu dynamique: {e}", "error")
            return f"# Erreur: {e}\nraise Exception('Génération de test échouée')"

    async def _generate_tests_for_challenge(self, prompt: str) -> str:
        """
        Génère des tests Python unitaires (unittest) dynamiquement via un LLM.
        """
        test_generation_prompt = f"""
En tant qu'ingénieur QA expert, ta mission est de créer une suite de tests Python robuste en utilisant le module `unittest`.
Cette suite de tests doit valider une solution pour le défi de codage suivant :

--- DÉFI ---
{prompt}
--- FIN DU DÉFI ---

INSTRUCTIONS IMPORTANTES :
1.  Le code de la solution sera dans un fichier nommé `agent_code.py`. Ta suite de tests doit donc commencer par `import agent_code`.
2.  Identifie la ou les fonctions principales que l'agent doit créer (par ex. `solve_challenge_function`, `process_data`, etc.) et appelle-les via `agent_code.nom_de_la_fonction`.
3.  Crée une classe de test qui hérite de `unittest.TestCase`.
4.  Écris au moins 3-5 cas de test pertinents, incluant :
    - Un cas de test simple/nominal.
    - Des cas limites (ex: liste vide, zéro, valeurs négatives).
    - Un cas avec des données volumineuses ou complexes si pertinent.
5.  Utilise des assertions claires (`self.assertEqual`, `self.assertTrue`, `self.assertRaises`, etc.).
6.  Assure-toi que le code est entièrement autonome et peut être exécuté directement. N'inclus que le code de test.
7.  Ne fournis aucune explication, seulement le bloc de code Python.
"""
        log_message("Génération dynamique de la suite de tests via LLM...", "info")
        test_code = await self._generate_dynamic_content_with_llm(test_generation_prompt)
        return test_code

    async def evaluate_submission(self, agent_id: str, code: str, prompt: str) -> Dict[str, Any]:
        """
        Évalue une soumission de code.
        """
        evaluation_results = {
            "agent_id": agent_id,
            "code_provided": code,
            "analysis_metrics": {},
            "test_results": {},
            "benchmark_results": {},
            "execution_result": {},
            "evaluation_score": 0.0,
            "feedback": []
        }

        analysis_metrics = CodeAnalyzer.analyze_python_code(code)
        evaluation_results["analysis_metrics"] = analysis_metrics

        if not analysis_metrics.get("syntax_valid"):
            evaluation_results["feedback"].append(f"Erreur de syntaxe: {analysis_metrics.get('syntax_error')}")
            evaluation_results["evaluation_score"] -= 100.0
            return evaluation_results

        # MODIFICATION CLÉ : Génération de tests dynamique
        test_code = await self._generate_tests_for_challenge(prompt)
        exec_result = await self._run_code_with_tests_safely(code, test_code, timeout=config.CODE_EXECUTION_TIMEOUT)
        evaluation_results["execution_result"] = exec_result

        if exec_result["timeout"]:
            evaluation_results["feedback"].append("Timeout d'exécution.")
            evaluation_results["evaluation_score"] -= 75.0
        elif exec_result["error"]:
            evaluation_results["feedback"].append(f"Erreur d'exécution: {exec_result['error']}")
            evaluation_results["evaluation_score"] -= 50.0
        else:
            evaluation_results["feedback"].append("Exécution réussie.")
            evaluation_results["evaluation_score"] += 20.0

        test_output = exec_result.get("stdout", "") + exec_result.get("stderr", "")
        test_summary = self._parse_unittest_output(test_output)
        evaluation_results["test_results"] = test_summary

        if test_summary.get("runs", 0) > 0 and test_summary.get("failures", 0) == 0 and test_summary.get("errors", 0) == 0:
            evaluation_results["feedback"].append(f"Tous les {test_summary.get('runs', 0)} tests ont réussi.")
            evaluation_results["evaluation_score"] += 30.0
        else:
            evaluation_results["feedback"].append(f"Tests échoués: {test_summary.get('failures', 0)} échecs, {test_summary.get('errors', 0)} erreurs.")
            evaluation_results["evaluation_score"] -= 40.0

        if "optimisation" in prompt.lower():
            benchmark_time = await self._run_benchmark(code)
            evaluation_results["benchmark_results"]["agent_time"] = benchmark_time
            evaluation_results["feedback"].append(f"Temps d'exécution du code de l'agent (benchmark): {benchmark_time:.4f}s")

            if "def slow_function" in prompt:
                slow_code_match = extract_code_from_response(prompt)
                if slow_code_match:
                    slow_code_time = await self._run_benchmark(slow_code_match)
                    evaluation_results["benchmark_results"]["reference_time"] = slow_code_time
                    evaluation_results["feedback"].append(f"Temps d'exécution du code de référence (benchmark): {slow_code_time:.4f}s")
                    if benchmark_time < slow_code_time:
                        evaluation_results["feedback"].append(f"Optimisation réussie: code de l'agent est {slow_code_time / benchmark_time:.2f}x plus rapide.")
                        evaluation_results["evaluation_score"] += 25.0
                    else:
                        evaluation_results["feedback"].append("Optimisation non significative ou pire que la référence.")
                        evaluation_results["evaluation_score"] -= 15.0

        score = 0.0
        score += analysis_metrics.get("code_lines", 0) * 0.05
        score -= analysis_metrics.get("complexity_score", 0) * 1.0
        if analysis_metrics.get("docstring_count", 0) > 0: score += 2.0
        if analysis_metrics.get("try_except_count", 0) > 0: score += 1.0
        evaluation_results["evaluation_score"] += score
        evaluation_results["feedback"].append(f"Score des métriques d'analyse: {score:.2f}")

        return evaluation_results

    def _parse_unittest_output(self, output: str) -> Dict[str, int]:
        """Analyse la sortie d'unittest pour extraire le nombre de tests passés/échoués."""
        summary = {"runs": 0, "failures": 0, "errors": 0, "skipped": 0}
        if "Ran " in output and " tests in " in output:
            try:
                run_line = [line for line in output.splitlines() if "Ran " in line and " tests in " in line][0]
                summary["runs"] = int(run_line.split("Ran ")[1].split(" tests")[0])
            except (IndexError, ValueError):
                pass
        
        if "FAILED (" in output:
            try:
                fail_line = [line for line in output.splitlines() if "FAILED (" in line][0]
                if "failures=" in fail_line:
                    summary["failures"] = int(fail_line.split("failures=")[1].split(")")[0].split(",")[0])
                if "errors=" in fail_line:
                    summary["errors"] = int(fail_line.split("errors=")[1].split(")")[0].split(",")[0])
            except (IndexError, ValueError):
                pass
        elif "OK" in output:
            summary["failures"] = 0
            summary["errors"] = 0
        
        return summary

    async def _run_code_with_tests_safely(self, code: str, test_code: str, timeout: int = 10) -> Dict[str, Any]:
        """
        Exécute le code Python de l'agent avec les tests unitaires générés dans un processus séparé.
        """
        result = {
            "stdout": "",
            "stderr": "",
            "error": None,
            "timeout": False,
            "return_code": None
        }

        with tempfile.TemporaryDirectory() as temp_dir:
            agent_file_path = Path(temp_dir) / "agent_code.py"
            test_file_path = Path(temp_dir) / "test_suite.py"
            
            agent_file_path.write_text(code, encoding='utf-8')
            
            # Le test généré par LLM est supposé gérer l'import de `agent_code`
            test_file_path.write_text(test_code, encoding='utf-8')

            try:
                process = await asyncio.create_subprocess_exec(
                    sys.executable, "-m", "unittest", str(test_file_path),
                    stdout=asyncio.subprocess.PIPE,
                    stderr=asyncio.subprocess.PIPE,
                    cwd=temp_dir # Important pour que `import agent_code` fonctionne
                )

                stdout, stderr = await asyncio.wait_for(process.communicate(), timeout=timeout)

                result["stdout"] = stdout.decode('utf-8', errors='ignore')
                result["stderr"] = stderr.decode('utf-8', errors='ignore')
                result["return_code"] = process.returncode

                if process.returncode != 0:
                    result["error"] = f"Le processus de test s'est terminé avec le code d'erreur {process.returncode}."

            except asyncio.TimeoutError:
                process.kill()
                await process.wait()
                result["timeout"] = True
                result["error"] = f"L'exécution des tests a dépassé le temps imparti ({timeout} secondes)."
            except Exception as e:
                result["error"] = f"Erreur lors de la préparation ou de l'exécution des tests: {format_error(e)}"
        
        return result

    async def _run_benchmark(self, code_to_benchmark: str) -> float:
        """Exécute le code et mesure son temps d'exécution."""
        benchmark_script_template = """
import time
import sys
import io

old_stdout = sys.stdout
old_stderr = sys.stderr
redirected_stdout = io.StringIO()
redirected_stderr = io.StringIO()
sys.stdout = redirected_stdout
sys.stderr = redirected_stderr

try:
    {code_to_benchmark}

    benchmark_data = list(range(1, 1000))

    target_function = None
    if 'slow_function' in locals():
        target_function = slow_function
    elif 'solve_challenge_function' in locals():
        target_function = solve_challenge_function
    elif 'process_data' in locals():
        target_function = process_data
    elif 'calculate_stats' in locals():
        target_function = calculate_stats
    elif 'add_numbers' in locals():
        target_function = add_numbers
    elif 'solve' in locals():
        target_function = solve

    if target_function:
        start_time = time.perf_counter()
        try:
            # Generic call attempt
            target_function(benchmark_data)
        except Exception as e:
            # Fallback for different signatures
            try:
                if 'add_numbers' in locals():
                    target_function(100, 200)
                else:
                    target_function()
            except Exception as e_inner:
                print(f"Erreur lors du benchmark: {{e_inner}}", file=sys.stderr)
                sys.exit(1)

        end_time = time.perf_counter()
        print(end_time - start_time)
    else:
        print("Fonction cible de benchmark non trouvée.", file=sys.stderr)
        sys.exit(1)

finally:
    sys.stdout = old_stdout
    sys.stderr = old_stderr
    print(redirected_stderr.getvalue(), file=old_stderr)
"""
        full_benchmark_code = benchmark_script_template.format(code_to_benchmark=code_to_benchmark)

        with tempfile.NamedTemporaryFile(mode='w', suffix='.py', delete=False) as temp_file:
            temp_file.write(full_benchmark_code)
            temp_file_path = temp_file.name

        try:
            process = await asyncio.create_subprocess_exec(
                sys.executable, temp_file_path,
                stdout=asyncio.subprocess.PIPE,
                stderr=asyncio.subprocess.PIPE
            )
            stdout, stderr = await asyncio.wait_for(process.communicate(), timeout=config.CODE_EXECUTION_TIMEOUT)

            if process.returncode != 0:
                log_message(f"Erreur lors du benchmark (subprocess): {stderr.decode()}", level="error")
                return float('inf')

            try:
                benchmark_time = float(stdout.decode().strip())
                return benchmark_time
            except ValueError:
                log_message(f"Impossible de parser le temps de benchmark: {stdout.decode()}", level="error")
                return float('inf')

        except asyncio.TimeoutError:
            process.kill()
            await process.wait()
            log_message("Timeout lors du benchmark.", level="warning")
            return float('inf')
        except Exception as e:
            log_message(f"Erreur inattendue lors de l'exécution du benchmark: {format_error(e)}", level="error")
            return float('inf')
        finally:
            os.unlink(temp_file_path)

class CodingChallengeSystem:
    """
    Système de défis de codage pour l'auto-amélioration de l'essaim.
    """
    def __init__(self, telegram_client: Optional[Any] = None):
        self.telegram_client = telegram_client
        from brain_library import TelegramMemoryIntegration
        self.telegram_memory = TelegramMemoryIntegration(telegram_client)
        self.participants: Dict[str, AutonomousParticipant] = {}
        self.challenge_history = []
        self.is_running = False
        self.last_challenge_start_time = 0
        self.last_successful_submissions: Dict[Tuple[str, str], str] = {}
        self.evaluator = ChallengeEvaluator()
        asyncio.create_task(event_bus.subscribe("CHALLENGE_REQUESTED", self.on_challenge_request))

    async def on_challenge_request(self, data: Dict[str, Any]):
        await self.run_coding_challenge(custom_prompt=data.get("custom_prompt"))

    def initialize_participants(self, participants: List[AutonomousParticipant]):
        """Reçoit les instances de participants déjà initialisées par le système principal."""
        self.participants = {p.id: p for p in participants}
        log_message(f"Système de défis synchronisé avec {len(self.participants)} participants du système principal.")

    async def start_periodic_challenges(self):
        """Démarre la boucle de défis périodiques."""
        self.is_running = True
        await telegram_logger.log_system_event(
            "CHALLENGE_SYSTEM_START",
            f"Défis de codage automatisés démarrés (Intervalle: {config.CODING_CHALLENGE_INTERVAL_SECONDS}s)"
        )
        while self.is_running:
            try:
                await asyncio.sleep(config.CODING_CHALLENGE_INTERVAL_SECONDS)
                await self.run_coding_challenge()
            except asyncio.CancelledError:
                break
            except Exception as e:
                log_message(f"Erreur dans la boucle de défis: {e}", level="error")
                await telegram_logger.log_error("CHALLENGE_SYSTEM", f"Erreur dans la boucle de défis: {format_error(e)}")
                await asyncio.sleep(60)

    def stop_challenges(self):
        self.is_running = False

    async def generate_challenge_prompt(self) -> str:
        """Génère un prompt de défi de codage aléatoire et dynamique via un LLM."""
        generation_prompt = """
Crée un prompt pour un défi de codage en Python. Le défi doit être intéressant, clair et d'une difficulté modérée.
Il doit pouvoir être résolu en une seule fonction ou une petite classe.
Varie le type de défi : algorithmique, optimisation, debug, manipulation de données, etc.
Ne fournis que le texte du défi, sans aucune explication ou préambule.
Exemple de format : "Défi Algorithme - Écrivez une fonction `solve(data)` qui..."
"""
        log_message("Génération dynamique du prompt de défi via LLM...", "info")
        challenge_prompt = await self.evaluator._generate_dynamic_content_with_llm(generation_prompt)
        return challenge_prompt

    async def run_coding_challenge(self, custom_prompt: Optional[str] = None):
        """Exécute un cycle complet de défi de codage."""
        self.last_challenge_start_time = time.time()
        challenge_prompt = custom_prompt if custom_prompt else await self.generate_challenge_prompt()
        timestamp = datetime.now().strftime("%Y%m%d%H%M%S")
        await telegram_logger.log_system_event(
            "CHALLENGE_START", f"Nouveau défi de codage - {timestamp}", {"prompt": challenge_prompt}
        )

        tasks = [p.execute_task("Défi de Codage", challenge_prompt) for p in self.participants.values()]
        results_list = await asyncio.gather(*tasks, return_exceptions=True)

        results = {}
        for i, res_raw in enumerate(results_list):
            participant = list(self.participants.values())[i]
            participant_id = participant.id

            if isinstance(res_raw, Exception):
                results[participant_id] = {"error": str(res_raw), "brain_id": participant_id}
                await telegram_logger.log_error(participant_id, f"Erreur défi: {format_error(res_raw)}")
            else:
                results[participant_id] = res_raw

        await self._save_challenge_results(challenge_prompt, results, timestamp)
        
        self.challenge_history.append({
            "timestamp": timestamp,
            "challenge": challenge_prompt,
            "participants": len(results),
            "successful": len([r for r in results.values() if "error" not in r])
        })
        if len(self.challenge_history) > 50:
            self.challenge_history.pop(0)

        await self._analyze_and_report_results(results, challenge_prompt, timestamp)

    async def execute_single_challenge_on_demand(self, custom_prompt: Optional[str] = None) -> Dict[str, Any]:
        """Exécute un défi de codage unique à la demande."""
        prompt_to_use = custom_prompt if custom_prompt else await self.generate_challenge_prompt()
        log_message(f"Lancement manuel d'un défi avec prompt: {prompt_to_use[:100]}...")
        try:
            await self.run_coding_challenge(prompt_to_use)
            return {"success": True, "message": "Défi lancé avec succès."}
        except Exception as e:
            log_message(f"Erreur lors du lancement manuel du défi: {e}", level="error")
            await telegram_logger.log_error("CHALLENGE_SYSTEM", f"Erreur lancement manuel défi: {format_error(e)}")
            return {"success": False, "error": str(e)}

    async def _save_challenge_results(self, challenge_prompt: str, results: Dict, timestamp: str):
        """Sauvegarde tous les résultats du défi."""
        try:
            challenge_data = {
                "timestamp": timestamp,
                "challenge_prompt": challenge_prompt,
                "results": results,
                "summary": {
                    "total_participants": len(results),
                    "successful_responses": len([r for r in results.values() if "error" not in r]),
                    "failed_responses": len([r for r in results.values() if "error" in r]),
                }
            }
            results_file = config.CHALLENGE_DIR / f"challenge_results_{timestamp}.json"
            await save_json(results_file, challenge_data)

            for agent_id, res in results.items():
                if "error" not in res and "response" in res:
                    response_text = "No text found"
                    if res["response"].get("candidates"):
                        parts = res["response"]["candidates"][0].get("content", {}).get("parts", [])
                        if parts and "text" in parts[0]:
                            response_text = parts[0]["text"]
                    
                    code_content = extract_code_from_response(response_text)
                    if code_content:
                        challenge_type = challenge_prompt.split(' ')[1] if 'Défi' in challenge_prompt else 'N/A'
                        self.last_successful_submissions[(agent_id, challenge_type)] = code_content

        except Exception as e:
            log_message(f"Erreur sauvegarde résultats: {e}", level="error")
            await telegram_logger.log_error("SYSTEM", f"Erreur sauvegarde résultats: {format_error(e)}")

    async def _analyze_and_report_results(self, results: Dict, prompt: str, timestamp: str):
        """Analyse les résultats, évalue le code et envoie les rapports."""
        successful_submissions = []
        failed_submissions = []

        for agent_id, res in results.items():
            if "error" in res:
                failed_submissions.append(agent_id)
                continue
            
            raw_text = res.get("response", {}).get("candidates", [{}])[0].get("content", {}).get("parts", [{}])[0].get("text", "")
            code = extract_code_from_response(raw_text)
            
            if code:
                fixed_code = fix_common_errors(code)
                evaluation = await self.evaluator.evaluate_submission(agent_id, fixed_code, prompt)
                successful_submissions.append(evaluation)
            else:
                failed_submissions.append(agent_id)

        successful_submissions.sort(key=lambda x: x.get("evaluation_score", -999), reverse=True)
        
        report = f"📊 *Rapport Défi {timestamp}*\n"
        report += f"Succès: {len(successful_submissions)}/{len(results)}\n"
        report += f"Échecs: {len(failed_submissions)}/{len(results)}\n"
        if successful_submissions:
            winner = successful_submissions[0]
            report += f"🏆 *Meilleur Agent*: `{winner['agent_id']}` (Score: {winner['evaluation_score']:.2f})"
        
        await telegram_logger.log_system_event("CHALLENGE_REPORT", report)
        
        for agent_id in failed_submissions:
            await self.send_joke_for_failed_agent(agent_id)

        report_data = {
            'timestamp': datetime.now(timezone.utc).isoformat(),
            'agent_name': 'CodingChallengeSystem',
            'intention': 'Évaluation des performances des agents',
            'user_query': prompt,
            'tools_called': [
                {
                    'name': res.get('brain_id', 'inconnu'),
                    'result': res.get('response', res.get('error', 'N/A')),
                    'params': {'challenge_type': prompt.split(' ')[1] if 'Défi' in prompt else 'N/A'},
                    'evaluation': next((eval for eval in successful_submissions if eval['agent_id'] == res.get('brain_id')), None)
                } for res in results.values()
            ],
            'final_response': f"Défi terminé. {len(successful_submissions)} succès.",
            'duration': time.time() - self.last_challenge_start_time,
            'error': None if not failed_submissions else f"{len(failed_submissions)} agents en échec."
        }
        await telegram_logger.log_structured_report(report_data)

        challenge_type = prompt.split(' ')[1] if 'Défi' in prompt else 'N/A'
        for evaluation in successful_submissions:
            agent_id = evaluation['agent_id']
            code_content = evaluation['code_provided']
            prev_code = self.last_successful_submissions.get((agent_id, challenge_type))
            
            if prev_code and prev_code != code_content:
                code_diff = diff_text(prev_code, code_content)
                evaluation["code_diff"] = code_diff
                await self.telegram_memory.write_to_group(
                    f"Code Diff pour {agent_id} ({challenge_type}):\n```diff\n{truncate_text(code_diff, 3500)}\n```",
                    f"CODE_DIFF_{agent_id}_{timestamp}"
                )
            self.last_successful_submissions[(agent_id, challenge_type)] = code_content

    def get_challenge_statistics(self) -> Dict[str, Any]:
        """Retourne les statistiques des défis."""
        if not self.challenge_history:
            return {"total_challenges": 0}

        total_challenges = len(self.challenge_history)
        total_participants = sum(c["participants"] for c in self.challenge_history)
        total_successful = sum(c["successful"] for c in self.challenge_history)
        avg_success_rate = (total_successful / total_participants * 100) if total_participants > 0 else 0

        return {
            "total_challenges": total_challenges,
            "total_participants": total_participants,
            "total_successful": total_successful,
            "average_success_rate": round(avg_success_rate, 2),
            "last_challenge": self.challenge_history[-1] if self.challenge_history else None,
            "is_running": self.is_running
        }

    async def send_joke_for_failed_agent(self, agent_id: str):
        """Envoie une blague à un agent qui a échoué au défi."""
        jokes = [
            f"Pourquoi l'agent {agent_id} n'a-t-il pas pu résoudre le défi ? Parce qu'il a oublié son 'import antigravity' !",
            f"L'agent {agent_id} est allé à l'école de code, mais il a oublié sa classe. Pas étonnant qu'il ait échoué !",
            f"On a demandé à l'agent {agent_id} de faire un tri, il a juste mélangé les cartes. Mieux la prochaine fois !",
        ]
        joke = random.choice(jokes)
        await self.telegram_memory.write_to_group(
            f"😂 Petite blague pour l'agent {agent_id} : {joke}",
            "CHALLENGE_JOKE"
        )

    def format_python_code(self, code: str) -> str:
        """Formate un code Python en utilisant une logique simple."""
        formatted_lines = []
        indent_level = 0
        for line in code.splitlines():
            stripped_line = line.strip()
            if not stripped_line:
                formatted_lines.append("")
                continue

            if stripped_line.startswith(('return ', 'pass', 'break', 'continue', 'except', 'finally', 'else', 'elif')):
                if indent_level > 0:
                    indent_level -= 1
            
            formatted_lines.append("    " * indent_level + stripped_line)

            if stripped_line.endswith((':', '[' , '(')) and not stripped_line.startswith('#'):
                indent_level += 1
                
        return "\n".join(formatted_lines)

async def batch_generate(participants_prompts: List[Tuple['AutonomousParticipant', str]], max_workers: int = 4) -> List[Dict[str, Any]]:
    """
    Génère du code pour plusieurs prompts en parallèle en faisant de vrais appels aux agents.
    """
    tasks = [p.execute_task("Défi de Codage", prompt) for p, prompt in participants_prompts]
    results = await asyncio.gather(*tasks, return_exceptions=True)

    processed_results = []
    for i, res in enumerate(results):
        participant, _ = participants_prompts[i]
        if isinstance(res, Exception):
            processed_results.append({"error": str(res), "brain_id": participant.id})
        else:
            processed_results.append(res)

    return processed_results

_coding_challenge_system_instance: Optional['CodingChallengeSystem'] = None

def get_coding_challenge_system(telegram_client: Optional[Any] = None) -> 'CodingChallengeSystem':
    """Retourne l'instance globale du système de défis."""
    global _coding_challenge_system_instance
    if _coding_challenge_system_instance is None:
        _coding_challenge_system_instance = CodingChallengeSystem(telegram_client)
        # L'initialisation des participants se fait maintenant via le DecentralizedAISystem
    return _coding_challenge_system_instance

# ===== FONCTIONS GLOBALES =====
def diff_text(old_text: str, new_text: str) -> str:
    """Génère un diff unifié entre deux chaînes de texte."""
    diff = difflib.unified_diff(
        old_text.splitlines(keepends=True),
        new_text.splitlines(keepends=True),
        fromfile='version_precedente',
        tofile='version_amelioree',
        lineterm='\n'
    )
    return ''.join(diff)

def fix_common_errors(code: str) -> str:
    """Applique des corrections automatiques communes."""
    fixes = {
        "print (": "print(",
        "= =": "==",
        "esle:": "else:",
        "ture": "True",
        "flase": "False"
    }
    for error, fix in fixes.items():
        code = code.replace(error, fix)
    return code

# config.py
import os
from pathlib import Path
from typing import Dict, Any, List, Optional
from datetime import datetime

class Config:
    """
    Classe de configuration pour l'application avec 7 cerveaux autonomes.
    Gère les chemins de fichiers, les clés API, et les paramètres des modèles.
    """
    def __init__(self):
        # --- Chemins de fichiers et répertoires ---
        self.BASE_DIR: Path = Path(__file__).parent.parent if Path(__file__).parent.name == 'src' else Path(__file__).parent
        
        self.LOG_FILE: Path = self.BASE_DIR / "logs" / "bot_activity.log"
        self.ERROR_LOG_PATH: Path = self.BASE_DIR / "logs" / "error.log"
        self.USER_CHAT_HISTORY_FILE: Path = self.BASE_DIR / "data" / "user_chat_history.json"
        self.ENDPOINT_HEALTH_FILE: Path = self.BASE_DIR / "data" / "endpoint_health.json"
        self.QUOTA_STATE_FILE: Path = self.BASE_DIR / "data" / "quota_state.json"
        self.DAILY_CHALLENGE_PATH: Path = self.BASE_DIR / "daily_challenges"
        self.BRAIN_MEMORY_FILE: Path = self.BASE_DIR / "data" / "brain_memory.json"
        self.ARCHIVE_DIR: Path = self.BASE_DIR / "archives"
        self.SYSTEM_ARCHIVE_DIR: Path = self.ARCHIVE_DIR / "system"
        self.CHALLENGE_DIR: Path = self.BASE_DIR / "challenges_results"
        
        # Créer les répertoires nécessaires
        self.LOG_FILE.parent.mkdir(parents=True, exist_ok=True)
        self.USER_CHAT_HISTORY_FILE.parent.mkdir(parents=True, exist_ok=True)
        self.ENDPOINT_HEALTH_FILE.parent.mkdir(parents=True, exist_ok=True)
        self.QUOTA_STATE_FILE.parent.mkdir(parents=True, exist_ok=True)
        self.DAILY_CHALLENGE_PATH.mkdir(parents=True, exist_ok=True)
        self.BRAIN_MEMORY_FILE.parent.mkdir(parents=True, exist_ok=True)
        self.ARCHIVE_DIR.mkdir(parents=True, exist_ok=True)
        self.SYSTEM_ARCHIVE_DIR.mkdir(parents=True, exist_ok=True)
        self.CHALLENGE_DIR.mkdir(parents=True, exist_ok=True)

        # --- Paramètres généraux de l'application ---
        self.VERBOSE: bool = True
        self.MAX_FILE_SIZE: int = 10 * 1024 * 1024
        self.MAX_CHUNK_SIZE: int = 4000
        self.MAX_IMAGE_SIZE: int = 4 * 1024 * 1024
        self.HEALTH_CHECK_INTERVAL_SECONDS: int = 300
        self.PRIVATE_GROUP_ID: Optional[int] = -1002845235344
        self.GROUP_MEMORY_LIMIT: int = 20
        self.BRAIN_ROTATION_INTERVAL_SECONDS: int = 45 * 60  # 45 minutes pour rotation des cerveaux
        self.LLM_ROTATION_INTERVAL_SECONDS: int = 45 * 60 # 45 minutes pour la rotation des LLM
        self.CODING_CHALLENGE_INTERVAL_SECONDS: int = 15 * 60  # 15 minutes pour défis codage
        self.CODE_EXECUTION_TIMEOUT: int = 15 # en secondes
        
        # --- Telegram Bot Configuration ---
        self.TELEGRAM_BOT_TOKEN = "7902342551:AAG6r1QA2GTMXcmcsWHi36Ivd_PVeMXULOs"
        
        # --- DÉBUT DES DÉFINITIONS DE CLÉS API (VÉRIFIEZ QUE TOUT CE BLOC EST PRÉSENT) ---
        
        # Cerveau 1: GEMINI
        self.GEMINI_API_KEYS: List[str] = [
            "AIzaSyBWXcwGdzoeUzbApSNLICkanNcm7BYzYcs",
            "AIzaSyAk6Ph25xuIY3b5o-JgdL652MvK4usp8Ms",
            "AIzaSyDuccmfiPSk4042NeJCYIjA8EOXPo1YKXU",
            "AIzaSyAQq6o9voefaDxkAEORf7W-IB3QbotIkwY",
            "AIzaSyDYaYrQQ7cwYFm8TBpyGM3dJweOGOYl7qw",
            "VOTRE_CLE_API_GEMINI_ICI" # REMPLACEZ CECI PAR VOTRE VRAIE CLÉ API
        ]
        
        # Cerveau 2: DEEPSEEK
        self.DEEPSEEK_KEYS: List[str] = [
            "sk-ef08317d125947b3a1ce5916592bef00",
            "sk-d73750d96142421cb1098c7056dd7f01"
        ]
        
        # Cerveau 3: HUGGINGFACE
        self.HUGGINGFACE_KEYS: List[str] = [
            "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",
            "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",
            "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",
            "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"
        ]
        
        # Cerveau 4: TAVILY (clé corrigée)
        self.TAVILY_KEYS: List[str] = [
            "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",
            "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",  # Clé corrigée
            "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",
            "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"
        ]
        
        # Cerveau 5: SERPER
        self.SERPER_KEYS: List[str] = [
            "047b30db1df999aaa9c293f2048037d40c651439"
        ]
        
        # Cerveau 6: GOOGLE
        self.GOOGLE_API_KEYS: List[str] = [
            "AIzaSyAk6Ph25xuIY3b5o-JgdL652MvK4usp8Ms",
            "AIzaSyDuccmfiPSk4042NeJCYIjA8EOXPo1YKXU",
            "AIzaSyAQq6o9voefaDxkAEORf7W-IB3QbotIkwY",
            "AIzaSyDYaYrQQ7cwYFm8TBpyGM3dJweOGOYl7qw"
        ]
        self.GOOGLE_CX_LIST: List[str] = [
            "3368510e864b74936",
            "e745c9ca0ffb94659"
        ]
        
        # Cerveau 7: WOLFRAM
        self.WOLFRAM_APP_IDS: List[str] = [
            "96LX77-G8PGKJ3T7V",
            "96LX77-PYHRRET363",
            "96LX77-P9HPAYWRGL"
        ]
        
        # --- Autres clés API pour outils spécialisés ---
        self.WEBCONTAINER_KEY: str = "wc_api_bastien34500_3c5b29436216f322904448de707c148e"
        self.APIFLASH_KEY: str = "3a3cc886a18e41109e0cebc0745b12de"
        self.CRAWLBASE_KEYS: List[str] = [
            "x41P6KNU8J86yF9JV1nqSw",
            "FOg3R0v_aLxzHkYIdhPgVg"
        ]
        self.DETECTLANGUAGE_KEY: str = "ebdc8ccc2ee75eda3ab122b08ffb1e8d"
        self.GUARDIAN_KEY: str = "07c622c1-af05-4c24-9f37-37d219be76a0"
        self.IP2LOCATION_KEY: str = "11103C239EA8EA6DF2473BB445EC32F2"
        self.SHODAN_KEY: str = "umdSaWOfVq9Wt2F4wWdXiKh1zjLailzn"
        self.WEATHERAPI_KEY: str = "332bcdba457d4db4836175513250407"
        self.GREYNOISE_KEY: str = "5zNe9E6c5UNDhU09iVXbMaB04UpHAw5hNm5rHCK24fCLvI2cP33NNOpL7nhkDETG"
        self.LOGINRADIUS_KEY: str = "073b2fbedf82409da2ca6f37b97e8c6a"
        self.JSONBIN_KEY: str = "$2a$10$npWSB7v1YcoqLkyPpz0PZOVtES5vBs6JtTWVyVDXK3j6FDxYS5BPO"
        self.TWILIO_SID: str = "SK84cc4d335650f9da168cd779f26e00e5"
        self.TWILIO_SECRET: str = "spvz5uwPE8ANYOI5Te4Mehm7YwKOZ4Lg"
        self.ABSTRACTAPI_EMAIL_KEYS: List[str] = [
            "2ffd537411ad407e9c9a7eacb7a97311",
            "5b00ade4e60e4a388bd3e749f4f66e28",
            "f4106df7b93e4db6855cb7949edc4a20"
        ]
        self.ABSTRACTAPI_GENERIC_KEY: str = "020a4dcd3e854ac0b19043491d79df92"
        self.PULSEDIVE_KEY: str = "201bb09342f35d365889d7d0ca0fdf8580ebee0f1e7644ce70c99a46c1d47171"
        self.RANDOMMER_KEY: str = "29d907df567b4226bf64b924f9e26c00"
        self.STORMGLASS_KEY: str = "7ad5b888-5900-11f0-80b9-0242ac130006-7ad5b996-5900-11f0-80b9-0242ac130006"
        self.TOMORROW_KEY: str = "bNh6KpmddRGY0dzwvmQugVtG4Uf5Y2w1"
        self.CLOUDMERSIVE_KEY: str = "4d407015-ce22-45d7-a2e1-b88ab6380e84"
        self.OPENWEATHER_API_KEY: str = "c80075b7332716a418e47033463085ef"
        self.OCR_API_KEYS: List[str] = [
            "K82679097388957",
            "K81079143888957",
            "K84281517488957"
        ]
        self.MOCKAROO_KEY: str = "282b32d0"
        self.OPENPAGERANK_KEY: str = "w848ws8s0848g4koosgooc0sg4ggogcggw4o4cko"
        self.RAPIDAPI_KEY: str = "d4d1f58d8emsh58d888c711b7400p1bcebejsn2cc04dce6efe"
        # --- FIN DES DÉFINITIONS DE CLÉS API ---
        
        # --- Paramètres du modèle Gemini (LLM) ---
        self.GEMINI_TEMPERATURE: float = 0.7
        self.GEMINI_TOP_P: float = 0.95
        self.GEMINI_TOP_K: int = 40
        self.GEMINI_MAX_OUTPUT_TOKENS: int = 8192
        self.GEMINI_SAFETY_SETTINGS: List[Dict] = [
            {"category": "HARM_CATEGORY_HARASSMENT", "threshold": "BLOCK_NONE"},
            {"category": "HARM_CATEGORY_HATE_SPEECH", "threshold": "BLOCK_NONE"},
            {"category": "HARM_CATEGORY_SEXUALLY_EXPLICIT", "threshold": "BLOCK_NONE"},
            {"category": "HARM_CATEGORY_DANGEROUS_CONTENT", "threshold": "BLOCK_NONE"},
        ]
        
        # --- Configuration des Endpoints API (avec gestion des clés et du roulement) ---
        self.API_CONFIG: Dict[str, List[Dict]] = self._build_api_config()
        
        ### AJOUT : LISTE DE TOUS LES AGENTS ET ENDPOINTS POUR LE MAILLAGE ###
        self.AGENT_CONFIGS, self.ALL_ENDPOINTS = self._build_agent_and_endpoint_mesh()
        
        # --- Configuration des Quotas API ---
        self.QUOTA_CONFIG: Dict[str, Dict[str, Any]] = {
            "GEMINI_API": {"limit": 1000, "reset_interval": "daily", "burn_window_hours": 2},
            "DEEPSEEK": {"limit": 200, "reset_interval": "daily", "burn_window_hours": 1},
            "HUGGINGFACE": {"limit": 200, "reset_interval": "daily", "burn_window_hours": 1},
            "TAVILY": {"limit": 100, "reset_interval": "daily", "burn_window_hours": 0.5},
            "SERPER": {"limit": 100, "reset_interval": "daily", "burn_window_hours": 0.5},
            "GOOGLE_CUSTOM_SEARCH": {"limit": 100, "reset_interval": "daily", "burn_window_hours": 0.5},
            "WOLFRAMALPHA": {"limit": 50, "reset_interval": "daily", "burn_window_hours": 0.5},
            "WEBCONTAINER": {"limit": 1000, "reset_interval": "daily", "burn_window_hours": 2},
            "OCR_API": {"limit": 500, "reset_interval": "daily", "burn_window_hours": 1},
            "APIFLASH": {"limit": 50, "reset_interval": "daily", "burn_window_hours": 0.5},
            "CRAWLBASE": {"limit": 50, "reset_interval": "daily", "burn_window_hours": 0.5},
            "DETECTLANGUAGE": {"limit": 100, "reset_interval": "daily", "burn_window_hours": 0.5},
            "GUARDIAN": {"limit": 500, "reset_interval": "daily", "burn_window_hours": 1},
            "IP2LOCATION": {"limit": 100, "reset_interval": "daily", "burn_window_hours": 0.5},
            "SHODAN": {"limit": 100, "reset_interval": "daily", "burn_window_hours": 0.5},
            "WEATHERAPI": {"limit": 1000, "reset_interval": "daily", "burn_window_hours": 2},
            "CLOUDMERSIVE": {"limit": 50, "reset_interval": "daily", "burn_window_hours": 0.5},
            "GREYNOISE": {"limit": 50, "reset_interval": "daily", "burn_window_hours": 0.5},
            "PULSEDIVE": {"limit": 50, "reset_interval": "daily", "burn_window_hours": 0.5},
            "STORMGLASS": {"limit": 50, "reset_interval": "daily", "burn_window_hours": 0.5},
            "LOGINRADIUS": {"limit": 10, "reset_interval": "daily", "burn_window_hours": 0.1},
            "JSONBIN": {"limit": 20, "reset_interval": "daily", "burn_window_hours": 0.1},
            "TWILIO": {"limit": 5, "reset_interval": "daily", "burn_window_hours": 0.1},
            "ABSTRACTAPI": {"limit": 100, "reset_interval": "daily", "burn_window_hours": 0.5},
            "RANDOMMER": {"limit": 50, "reset_interval": "daily", "burn_window_hours": 0.5},
            "TOMORROW.IO": {"limit": 100, "reset_interval": "daily", "burn_window_hours": 0.5},
            "OPENWEATHERMAP": {"limit": 1000, "reset_interval": "daily", "burn_window_hours": 2},
            "MOCKAROO": {"limit": 50, "reset_interval": "daily", "burn_window_hours": 0.5},
            "OPENPAGERANK": {"limit": 50, "reset_interval": "daily", "burn_window_hours": 0.5},
            "RAPIDAPI": {"limit": 200, "reset_interval": "daily", "burn_window_hours": 1},
        }
        
        # --- Configuration des Outils (pour l'API Gemini) ---
        self.TOOL_CONFIG: Dict[str, Dict[str, Any]] = self._build_tool_config()

    ### AJOUT : NOUVELLE MÉTHODE POUR CONSTRUIRE LE MAILLAGE AGENT/ENDPOINT ###
    def _build_agent_and_endpoint_mesh(self) -> tuple[List[Dict[str, Any]], List[Dict[str, Any]]]:
        """Construit la liste de tous les agents (clés) et de tous les endpoints."""
        agent_configs = []
        all_endpoints = []

        # Fonction utilitaire pour ajouter un agent
        def add_agent(key: Any, agent_type: str, service_name: str, index: int, extra_config: Dict = {}):
            # Ignore les clés invalides ou placeholders
            if not key or "VOTRE_" in str(key) or "_ICI" in str(key):
                return
            agent_id = f"{service_name}_{index+1}"
            agent_configs.append({
                "id": agent_id,
                "key": key,
                "type": agent_type,  # Type de cerveau (logique de traitement)
                "service": service_name, # Service API associé
                **extra_config
            })

        # Itération sur toutes les listes de clés
        for i, k in enumerate(self.GEMINI_API_KEYS): add_agent(k, "GEMINI", "GEMINI_API", i)
        for i, k in enumerate(self.DEEPSEEK_KEYS): add_agent(k, "DEEPSEEK", "DEEPSEEK", i)
        for i, k in enumerate(self.HUGGINGFACE_KEYS): add_agent(k, "HUGGINGFACE", "HUGGINGFACE", i)
        for i, k in enumerate(self.TAVILY_KEYS): add_agent(k, "TAVILY", "TAVILY", i)
        for i, k in enumerate(self.SERPER_KEYS): add_agent(k, "SERPER", "SERPER", i)
        for i, k in enumerate(self.GOOGLE_API_KEYS): add_agent(k, "GOOGLE_CUSTOM_SEARCH", "GOOGLE_CUSTOM_SEARCH", i)
        for i, k in enumerate(self.WOLFRAM_APP_IDS): add_agent(k, "WOLFRAMALPHA", "WOLFRAMALPHA", i)
        for i, k in enumerate(self.OCR_API_KEYS): add_agent(k, "OCR_API", "OCR_API", i)
        for i, k in enumerate(self.CRAWLBASE_KEYS): add_agent(k, "CRAWLBASE", "CRAWLBASE", i)
        for i, k in enumerate(self.ABSTRACTAPI_EMAIL_KEYS): add_agent(k, "ABSTRACTAPI", "ABSTRACTAPI", i)
        
        # Services avec une seule clé
        single_key_services = {
            "WEBCONTAINER": (self.WEBCONTAINER_KEY, "WEBCONTAINER"), "APIFLASH": (self.APIFLASH_KEY, "APIFLASH"),
            "DETECTLANGUAGE": (self.DETECTLANGUAGE_KEY, "DETECTLANGUAGE"), "GUARDIAN": (self.GUARDIAN_KEY, "GUARDIAN"),
            "IP2LOCATION": (self.IP2LOCATION_KEY, "IP2LOCATION"), "SHODAN": (self.SHODAN_KEY, "SHODAN"),
            "WEATHERAPI": (self.WEATHERAPI_KEY, "WEATHERAPI"), "GREYNOISE": (self.GREYNOISE_KEY, "GREYNOISE"),
            "LOGINRADIUS": (self.LOGINRADIUS_KEY, "LOGINRADIUS"), "JSONBIN": (self.JSONBIN_KEY, "JSONBIN"),
            "TWILIO": ((self.TWILIO_SID, self.TWILIO_SECRET), "TWILIO"), "ABSTRACTAPI_GENERIC": (self.ABSTRACTAPI_GENERIC_KEY, "ABSTRACTAPI"),
            "PULSEDIVE": (self.PULSEDIVE_KEY, "PULSEDIVE"), "RANDOMMER": (self.RANDOMMER_KEY, "RANDOMMER"),
            "STORMGLASS": (self.STORMGLASS_KEY, "STORMGLASS"), "TOMORROW.IO": (self.TOMORROW_KEY, "TOMORROW.IO"),
            "CLOUDMERSIVE": (self.CLOUDMERSIVE_KEY, "CLOUDMERSIVE"), "OPENWEATHERMAP": (self.OPENWEATHER_API_KEY, "OPENWEATHERMAP"),
            "MOCKAROO": (self.MOCKAROO_KEY, "MOCKAROO"), "OPENPAGERANK": (self.OPENPAGERANK_KEY, "OPENPAGERANK"),
            "RAPIDAPI": (self.RAPIDAPI_KEY, "RAPIDAPI")
        }
        for service, (key, brain_type) in single_key_services.items():
            add_agent(key, brain_type, service, 0)

        # Construction de la liste de tous les endpoints
        # On itère sur la configuration d'API existante pour ne pas dupliquer la logique
        for service_name, endpoints in self.API_CONFIG.items():
            all_endpoints.extend(endpoints)
            
        return agent_configs, all_endpoints

    # ASSE Config, AJOUTEZ CETTE MÉTHODE =====
    def _build_all_endpoints(self) -> List[Dict[str, Any]]:
        """
        Construit une liste agrégée de tous les endpoints configurés.
        """
        all_endpoints = []
        for service_name, endpoints_list in self.API_CONFIG.items():
            all_endpoints.extend(endpoints_list)
        return all_endpoints


    def _build_api_config(self) -> Dict[str, List[Dict]]:
        """Construit la configuration des endpoints pour tous les services."""
        return {
            "GEMINI_API": [
                {
                    "endpoint_name": f"Gemini Generate Content Key {i+1}",
                    "url": "https://generativelanguage.googleapis.com/v1beta/models/gemini-1.5-flash-latest:generateContent",
                    "method": "POST",
                    "key_field": "key",
                    "key_location": "param",
                    "key": key,
                    "timeout": 60,
                    "health_check_json": {"contents": [{"parts": [{"text": "hello"}]}]},
                } for i, key in enumerate(self.GEMINI_API_KEYS) if key and "VOTRE" not in key
            ] + [
                {
                    "endpoint_name": f"Gemini Models List Key {i+1}",
                    "url": "https://generativelanguage.googleapis.com/v1beta/models",
                    "method": "GET",
                    "key_field": "key",
                    "key_location": "param",
                    "key": key,
                    "timeout": 30,
                } for i, key in enumerate(self.GEMINI_API_KEYS) if key and "VOTRE" not in key
            ],
            "DEEPSEEK": [
                {
                    "endpoint_name": f"DeepSeek Chat Key {i+1}",
                    "url": "https://api.deepseek.com/chat/completions",
                    "method": "POST",
                    "key_field": "Authorization",
                    "key_location": "header",
                    "key_prefix": "Bearer ",
                    "key": key,
                    "timeout": 60,
                    "fixed_headers": {"Content-Type": "application/json"},
                    "health_check_json": {"model": "deepseek-chat", "messages": [{"role": "user", "content": "ping"}]},
                } for i, key in enumerate(self.DEEPSEEK_KEYS) if key
            ] + [
                {
                    "endpoint_name": f"DeepSeek Models Key {i+1}",
                    "url": "https://api.deepseek.com/models",
                    "method": "GET",
                    "key_field": "Authorization",
                    "key_location": "header",
                    "key_prefix": "Bearer ",
                    "key": key,
                    "timeout": 30,
                } for i, key in enumerate(self.DEEPSEEK_KEYS) if key
            ],
            "HUGGINGFACE": [
                {
                    "endpoint_name": f"HuggingFace Inference Key {i+1}",
                    "url": "https://api-inference.huggingface.co/models/",
                    "method": "POST",
                    "key_field": "Authorization",
                    "key_location": "header",
                    "key_prefix": "Bearer ",
                    "key": key,
                    "timeout": 60,
                    "fixed_headers": {"Content-Type": "application/json"},
                    "health_check_url_suffix": "distilbert-base-uncased-finetuned-sst-2-english",
                    "health_check_json": {"inputs": "Hello world"},
                } for i, key in enumerate(self.HUGGINGFACE_KEYS) if key
            ],
            "TAVILY": [
                {
                    "endpoint_name": f"Tavily Search Key {i+1}",
                    "url": "https://api.tavily.com/search",
                    "method": "POST",
                    "key_field": "apikey",
                    "key_location": "header",
                    "key": key,
                    "timeout": 20,
                    "fixed_headers": {"Content-Type": "application/json"},
                    "health_check_json": {"query": "test"},
                } for i, key in enumerate(self.TAVILY_KEYS) if key
            ],
            "SERPER": [
                {
                    "endpoint_name": f"Serper Search Key {i+1}",
                    "url": "https://google.serper.dev/search",
                    "method": "POST",
                    "key_field": "X-API-KEY",
                    "key_location": "header",
                    "key": key,
                    "timeout": 15,
                    "fixed_headers": {"Content-Type": "application/json"},
                    "health_check_json": {"q": "test"},
                } for i, key in enumerate(self.SERPER_KEYS) if key
            ] + [
                {
                    "endpoint_name": f"Serper Images Key {i+1}",
                    "url": "https://google.serper.dev/images",
                    "method": "POST",
                    "key_field": "X-API-KEY",
                    "key_location": "header",
                    "key": key,
                    "timeout": 15,
                    "fixed_headers": {"Content-Type": "application/json"},
                    "health_check_json": {"q": "test"},
                } for i, key in enumerate(self.SERPER_KEYS) if key
            ],
            "GOOGLE_CUSTOM_SEARCH": [
                {
                    "endpoint_name": f"Google Custom Search Key {i+1} CX {j+1}",
                    "url": "https://www.googleapis.com/customsearch/v1",
                    "method": "GET",
                    "key_field": "key",
                    "key_location": "param",
                    "key": key,
                    "timeout": 15,
                    "fixed_params": {"cx": cx},
                    "health_check_params": {"q": "test"},
                } for i, key in enumerate(self.GOOGLE_API_KEYS) if key for j, cx in enumerate(self.GOOGLE_CX_LIST)
            ],
            "WOLFRAMALPHA": [
                {
                    "endpoint_name": f"WolframAlpha Query Key {i+1}",
                    "url": "https://api.wolframalpha.com/v2/query",
                    "method": "GET",
                    "key_field": "appid",
                    "key_location": "param",
                    "key": key,
                    "timeout": 20,
                    "fixed_params": {"output": "json"},
                    "health_check_params": {"input": "2+2"},
                } for i, key in enumerate(self.WOLFRAM_APP_IDS) if key
            ],
            "WEBCONTAINER": [
                {
                    "endpoint_name": "WebContainer API",
                    "url": "https://api.webcontainer.io/v1",
                    "method": "POST",
                    "key_field": "Authorization",
                    "key_location": "header",
                    "key_prefix": "Bearer ",
                    "key": self.WEBCONTAINER_KEY,
                    "timeout": 60,
                    "fixed_headers": {"Content-Type": "application/json"},
                    "health_check_json": {"action": "ping"},
                }
            ],
            "OCR_API": [
                {
                    "endpoint_name": f"OCR.space Key {i+1}",
                    "url": "https://api.ocr.space/parse/image",
                    "method": "POST",
                    "key_field": "apikey",
                    "key_location": "header",
                    "key": key,
                    "timeout": 30,
                    "fixed_headers": {},
                    "health_check_json": {"base64Image": "data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAEAAAABCAQAAAC1HAwCAAAAC0lEQVR42mNkYAAAAAYAAjCB0C8AAAAASUVORK5CYII=", "language": "eng"},
                } for i, key in enumerate(self.OCR_API_KEYS) if key
            ],
            "APIFLASH": [
                {
                    "endpoint_name": "ApiFlash Screenshot",
                    "url": "https://api.apiflash.com/v1/urltoimage",
                    "method": "GET",
                    "key_field": "access_key",
                    "key_location": "param",
                    "key": self.APIFLASH_KEY,
                    "timeout": 30,
                    "health_check_params": {"url": "https://www.google.com", "format": "jpeg"},
                }
            ],
            "CRAWLBASE": [
                {
                    "endpoint_name": f"Crawlbase Scraper Key {i+1}",
                    "url": "https://api.crawlbase.com/",
                    "method": "GET",
                    "key_field": "token",
                    "key_location": "param",
                    "key": key,
                    "timeout": 45,
                    "health_check_params": {"url": "https://httpbin.org/status/200"},
                } for i, key in enumerate(self.CRAWLBASE_KEYS) if key
            ] + [
                {
                    "endpoint_name": f"Crawlbase JS Scraper Key {i+1}",
                    "url": "https://api.crawlbase.com/",
                    "method": "GET",
                    "key_field": "token",
                    "key_location": "param",
                    "key": key,
                    "timeout": 60,
                    "health_check_params": {"url": "https://httpbin.org/status/200", "javascript": "true"},
                } for i, key in enumerate(self.CRAWLBASE_KEYS) if key
            ],
            "DETECTLANGUAGE": [
                {
                    "endpoint_name": "DetectLanguage Detect",
                    "url": "https://ws.detectlanguage.com/0.2/detect",
                    "method": "POST",
                    "key_field": "Authorization",
                    "key_location": "header",
                    "key_prefix": "Bearer ",
                    "key": self.DETECTLANGUAGE_KEY,
                    "timeout": 10,
                    "fixed_headers": {"Content-Type": "application/json"},
                    "health_check_json": {"q": "Hello world"},
                }
            ],
            "GUARDIAN": [
                {
                    "endpoint_name": "Guardian Content",
                    "url": "https://content.guardianapis.com/search",
                    "method": "GET",
                    "key_field": "api-key",
                    "key_location": "param",
                    "key": self.GUARDIAN_KEY,
                    "timeout": 15,
                    "health_check_params": {"q": "test"},
                }
            ],
            "IP2LOCATION": [
                {
                    "endpoint_name": "IP2Location IP Geolocation",
                    "url": "https://api.ip2location.io/",
                    "method": "GET",
                    "key_field": "key",
                    "key_location": "param",
                    "key": self.IP2LOCATION_KEY,
                    "timeout": 10,
                    "fixed_params": {"package": "WS24", "format": "json"},
                    "health_check_params": {"ip": "8.8.8.8"},
                }
            ],
            "SHODAN": [
                {
                    "endpoint_name": "Shodan Host Info",
                    "url": "https://api.shodan.io/shodan/host/",
                    "method": "GET",
                    "key_field": "key",
                    "key_location": "param",
                    "key": self.SHODAN_KEY,
                    "timeout": 15,
                    "health_check_url_suffix": "8.8.8.8",
                },
                {
                    "endpoint_name": "Shodan API Info",
                    "url": "https://api.shodan.io/api-info",
                    "method": "GET",
                    "key_field": "key",
                    "key_location": "param",
                    "key": self.SHODAN_KEY,
                    "timeout": 15,
                }
            ],
            "WEATHERAPI": [
                {
                    "endpoint_name": "WeatherAPI Current",
                    "url": "https://api.weatherapi.com/v1/current.json",
                    "method": "GET",
                    "key_field": "key",
                    "key_location": "param",
                    "key": self.WEATHERAPI_KEY,
                    "timeout": 10,
                    "health_check_params": {"q": "London"},
                }
            ],
            "CLOUDMERSIVE": [
                {
                    "endpoint_name": "Cloudmersive Validate Domain",
                    "url": "https://api.cloudmersive.com/validate/url/validate/full",
                    "method": "POST",
                    "key_field": "Apikey",
                    "key_location": "header",
                    "key": self.CLOUDMERSIVE_KEY,
                    "timeout": 15,
                    "fixed_headers": {"Content-Type": "application/json"},
                    "health_check_json": {"domain": "google.com"},
                }
            ],
            "GREYNOISE": [
                {
                    "endpoint_name": "GreyNoise IP Lookup",
                    "url": "https://api.greynoise.io/v3/community",
                    "method": "GET",
                    "key_field": "key",
                    "key_location": "header",
                    "key": self.GREYNOISE_KEY,
                    "timeout": 15,
                    "health_check_url_suffix": "/8.8.8.8",
                }
            ],
            "PULSEDIVE": [
                {
                    "endpoint_name": "Pulsedive Analyze",
                    "url": "https://pulsedive.com/api/v1/analyze.php",
                    "method": "GET",
                    "key_field": "key",
                    "key_location": "param",
                    "key": self.PULSEDIVE_KEY,
                    "timeout": 20,
                    "health_check_params": {"indicator": "8.8.8.8", "type": "ip"},
                }
            ],
            "STORMGLASS": [
                {
                    "endpoint_name": "StormGlass Weather",
                    "url": "https://api.stormglass.io/v2/weather/point",
                    "method": "GET",
                    "key_field": "Authorization",
                    "key_location": "header",
                    "key": self.STORMGLASS_KEY,
                    "timeout": 20,
                    "fixed_headers": {},
                    "health_check_params": {"lat": 0, "lng": 0, "params": "airTemperature"},
                }
            ],
            "LOGINRADIUS": [
                {
                    "endpoint_name": "LoginRadius Ping",
                    "url": "https://api.loginradius.com/identity/v2/auth/ping",
                    "method": "GET",
                    "key_field": "X-LoginRadius-Api-Key",
                    "key_location": "header",
                    "key": self.LOGINRADIUS_KEY,
                    "timeout": 10,
                }
            ],
            "JSONBIN": [
                {
                    "endpoint_name": "Jsonbin Bin Create",
                    "url": "https://api.jsonbin.io/v3/b",
                    "method": "POST",
                    "key_field": "X-Master-Key",
                    "key_location": "header",
                    "key": self.JSONBIN_KEY,
                    "timeout": 15,
                    "fixed_headers": {"Content-Type": "application/json"},
                    "health_check_json": {"sample": "Hello World"},
                },
                {
                    "endpoint_name": "Jsonbin Bin Access",
                    "url": "https://api.jsonbin.io/v3/b",
                    "method": "GET",
                    "key_field": "X-Master-Key",
                    "key_location": "header",
                    "key": self.JSONBIN_KEY,
                    "timeout": 15,
                    "health_check_url_suffix": "/657a7e3205741301340a6b12",
                }
            ],
            "TWILIO": [
                {
                    "endpoint_name": "Twilio Account Balance",
                    "url": f"https://api.twilio.com/2010-04-01/Accounts/{self.TWILIO_SID}/Balance.json",
                    "method": "GET",
                    "key_field": None,
                    "key_location": "auth_basic",
                    "key": (self.TWILIO_SID, self.TWILIO_SECRET),
                    "timeout": 15,
                }
            ],
            "ABSTRACTAPI": [
                {
                    "endpoint_name": f"AbstractAPI Email Validation Key {i+1}",
                    "url": "https://emailvalidation.abstractapi.com/v1/",
                    "method": "GET",
                    "key_field": "api_key",
                    "key_location": "param",
                    "key": key,
                    "timeout": 15,
                    "health_check_params": {"email": "test@example.com"},
                } for i, key in enumerate(self.ABSTRACTAPI_EMAIL_KEYS) if key
            ] + [
                {
                    "endpoint_name": "AbstractAPI Phone Validation",
                    "url": "https://phonevalidation.abstractapi.com/v1/",
                    "method": "GET",
                    "key_field": "api_key",
                    "key_location": "param",
                    "key": self.ABSTRACTAPI_GENERIC_KEY,
                    "timeout": 15,
                    "health_check_params": {"phone": "14150000000"},
                },
                {
                    "endpoint_name": "AbstractAPI Exchange Rates",
                    "url": "https://exchangerates.abstractapi.com/v1/live/",
                    "method": "GET",
                    "key_field": "api_key",
                    "key_location": "param",
                    "key": self.ABSTRACTAPI_GENERIC_KEY,
                    "timeout": 15,
                    "health_check_params": {"base": "USD"},
                },
                {
                    "endpoint_name": "AbstractAPI Holidays",
                    "url": "https://holidays.abstractapi.com/v1/",
                    "method": "GET",
                    "key_field": "api_key",
                    "key_location": "param",
                    "key": self.ABSTRACTAPI_GENERIC_KEY,
                    "timeout": 15,
                    "health_check_params": {"country": "US", "year": "2023", "month": "1", "day": "1"},
                }
            ],
            "RANDOMMER": [
                {
                    "endpoint_name": "Randommer Phone Number",
                    "url": "https://randommer.io/api/Phone/Generate",
                    "method": "GET",
                    "key_field": "X-Api-Key",
                    "key_location": "header",
                    "key": self.RANDOMMER_KEY,
                    "timeout": 10,
                    "health_check_params": {"CountryCode": "US", "Quantity": 1},
                }
            ],
            "TOMORROW.IO": [
                {
                    "endpoint_name": "Tomorrow.io Weather",
                    "url": "https://api.tomorrow.io/v4/timelines",
                    "method": "POST",
                    "key_field": "apikey",
                    "key_location": "param",
                    "key": self.TOMORROW_KEY,
                    "timeout": 20,
                    "fixed_headers": {"Content-Type": "application/json"},
                    "health_check_json": {"location": "42.3478, -73.9855", "fields": ["temperature"], "units": "metric", "timesteps": ["1h"]},
                }
            ],
            "OPENWEATHERMAP": [
                {
                    "endpoint_name": "OpenWeatherMap Current",
                    "url": "https://api.openweathermap.org/data/2.5/weather",
                    "method": "GET",
                    "key_field": "appid",
                    "key_location": "param",
                    "key": self.OPENWEATHER_API_KEY,
                    "timeout": 10,
                    "health_check_params": {"q": "London"},
                }
            ],
            "MOCKAROO": [
                {
                    "endpoint_name": "Mockaroo Generate Data",
                    "url": "https://api.mockaroo.com/api/generate.json",
                    "method": "GET",
                    "key_field": "key",
                    "key_location": "param",
                    "key": self.MOCKAROO_KEY,
                    "timeout": 15,
                    "health_check_params": {"count": 1, "fields": '[{"name":"id","type":"Row Number"}]'},
                }
            ],
            "OPENPAGERANK": [
                {
                    "endpoint_name": "OpenPageRank Domains",
                    "url": "https://openpagerank.com/api/v1.0/getPageRank",
                    "method": "GET",
                    "key_field": "API-OPR",
                    "key_location": "header",
                    "key": self.OPENPAGERANK_KEY,
                    "timeout": 15,
                    "health_check_params": {"domains[]": "google.com"},
                }
            ],
            "RAPIDAPI": [
                {
                    "endpoint_name": "RapidAPI Programming Joke",
                    "url": "https://dad-jokes.p.rapidapi.com/random/joke",
                    "method": "GET",
                    "key_field": "X-RapidAPI-Key",
                    "key_location": "header",
                    "key": self.RAPIDAPI_KEY,
                    "timeout": 15,
                    "fixed_headers": {"X-RapidAPI-Host": "dad-jokes.p.rapidapi.com"},
                },
                {
                    "endpoint_name": "RapidAPI Currency List Quotes",
                    "url": "https://currency-exchange.p.rapidapi.com/exchange",
                    "method": "GET",
                    "key_field": "X-RapidAPI-Key",
                    "key_location": "header",
                    "key": self.RAPIDAPI_KEY,
                    "timeout": 15,
                    "fixed_headers": {"X-RapidAPI-Host": "currency-exchange.p.rapidapi.com"},
                    "health_check_params": {"from": "USD", "to": "EUR", "q": "1.0"},
                },
                {
                    "endpoint_name": "RapidAPI Random Fact",
                    "url": "https://random-facts2.p.rapidapi.com/randomFacts",
                    "method": "GET",
                    "key_field": "X-RapidAPI-Key",
                    "key_location": "header",
                    "key": self.RAPIDAPI_KEY,
                    "timeout": 15,
                    "fixed_headers": {"X-RapidAPI-Host": "random-facts2.p.rapidapi.com"},
                    "health_check_params": {"count": "1"},
                }
            ],
        }
    
    def _build_tool_config(self) -> Dict[str, Dict[str, Any]]:
        """Configuration des outils disponibles pour tous les cerveaux."""
        return {
            "google_search": {
                "enabled": True,
                "description": "Effectue une recherche sur Google pour obtenir des informations. Utilisez cet outil pour des questions factuelles, des définitions, des actualités, etc.",
                "parameters": {
                    "queries": {"type": "ARRAY", "items": {"type": "STRING"}, "description": "Liste des requêtes de recherche à effectuer.", "required": True}
                }
            },
            "media_control": {
                "enabled": True,
                "description": "Contrôle la lecture multimédia (musique, vidéo).",
                "parameters": {
                    "action": {
                        "type": "STRING",
                        "description": "L'action à effectuer (like, dislike, next, previous, pause, resume, stop, replay, seek_absolute, seek_relative).",
                        "required": True,
                        "enum": ["like", "dislike", "next", "previous", "pause", "resume", "stop", "replay", "seek_absolute", "seek_relative"]
                    },
                    "position": {"type": "INTEGER", "description": "Position absolue en secondes pour seek_absolute.", "required": False},
                    "offset": {"type": "INTEGER", "description": "Décalage en secondes pour seek_relative.", "required": False}
                }
            },
            "clock": {
                "enabled": True,
                "description": "Gère les alarmes et les minuteurs.",
                "parameters": {
                    "action": {
                        "type": "STRING",
                        "description": "L'action à effectuer (create_alarm, create_timer, show_matching_alarms, show_matching_timers, modify_alarm_v2, modify_timer_v2, snooze).",
                        "required": True,
                        "enum": ["create_alarm", "create_timer", "show_matching_alarms", "show_matching_timers", "modify_alarm_v2", "modify_timer_v2", "snooze"]
                    },
                    "duration": {"type": "STRING", "description": "Durée pour le minuteur ou l'alarme (ex: '30 minutes', '1h 30m').", "required": False},
                    "time": {"type": "STRING", "description": "Heure spécifique pour l'alarme (ex: '07:00 AM', '14:30').", "required": False},
                    "date": {"type": "STRING", "description": "Date spécifique pour l'alarme (ex: '2023-12-25', 'demain').", "required": False},
                    "label": {"type": "STRING", "description": "Étiquette ou description pour l'alarme/minuteur.", "required": False},
                    "recurrence": {"type": "ARRAY", "items": {"type": "STRING"}, "description": "Jours de la semaine pour la récurrence de l'alarme (ex: ['MONDAY', 'WEDNESDAY']).", "required": False},
                    "query": {"type": "STRING", "description": "Requête de recherche pour les alarmes/minuteurs.", "required": False},
                    "alarm_type": {"type": "STRING", "description": "Type d'alarme à afficher (ex: 'active', 'snoozed').", "required": False},
                    "alarm_ids": {"type": "ARRAY", "items": {"type": "STRING"}, "description": "Liste des IDs d'alarmes à afficher ou modifier.", "required": False},
                    "timer_type": {"type": "STRING", "description": "Type de minuteur à afficher (ex: 'running', 'paused').", "required": False},
                    "timer_ids": {"type": "ARRAY", "items": {"type": "STRING"}, "description": "Liste des IDs de minuteurs à afficher ou modifier.", "required": False},
                    "alarm_filters": {"type": "OBJECT", "description": "Filtres pour sélectionner les alarmes à modifier.", "required": False},
                    "alarm_modifications": {"type": "OBJECT", "description": "Modifications à appliquer aux alarmes sélectionnées.", "required": False},
                    "timer_filters": {"type": "OBJECT", "description": "Filtres pour sélectionner les minuteurs à modifier.", "required": False},
                    "timer_modifications": {"type": "OBJECT", "description": "Modifications à appliquer aux minuteurs sélectionnées.", "required": False}
                }
            },
            "ocr_space": {
                "enabled": True,
                "description": "Extrait le texte d'une image en utilisant la reconnaissance optique de caractères (OCR). L'image doit être fournie sous forme de chaîne Base64 (data:image/png;base64,...).",
                "parameters": {
                    "image_base64": {"type": "STRING", "description": "L'image encodée en Base64, incluant le préfixe MIME (ex: data:image/png;base64,iVB...).", "required": True}
                }
            },
            "deepseek_chat": {
                "enabled": True,
                "description": "Interagit avec le modèle de chat DeepSeek pour des conversations générales ou des tâches de génération de texte. Utile pour des réponses créatives ou des discussions.",
                "parameters": {
                    "prompt": {"type": "STRING", "description": "Le prompt ou la liste de messages pour le modèle de chat.", "required": True},
                    "model": {"type": "STRING", "description": "Le nom du modèle DeepSeek à utiliser (ex: 'deepseek-chat', 'deepseek-coder').", "required": False, "default": "deepseek-chat"}
                }
            },
            "serper_dev": {
                "enabled": True,
                "description": "Effectue une recherche web via l'API Serper. Utile pour obtenir des snippets et des liens pertinents pour une requête.",
                "parameters": {
                    "query_text": {"type": "STRING", "description": "La requête de recherche.", "required": True}
                }
            },
            "wolfram_alpha": {
                "enabled": True,
                "description": "Interroge WolframAlpha pour des calculs, des faits scientifiques, des conversions d'unités, des informations mathématiques, etc.",
                "parameters": {
                    "input_text": {"type": "STRING", "description": "La requête à soumettre à WolframAlpha (ex: 'derivative of x^2', 'population of France').", "required": True}
                }
            },
            "tavily_search": {
                "enabled": True,
                "description": "Effectue une recherche web avancée via l'API Tavily, fournissant des réponses directes et des extraits pertinents.",
                "parameters": {
                    "query_text": {"type": "STRING", "description": "La requête de recherche.", "required": True},
                    "max_results": {"type": "INTEGER", "description": "Nombre maximum de résultats à retourner.", "required": False, "default": 3}
                }
            },
            "apiflash_screenshot": {
                "enabled": True,
                "description": "Capture une capture d'écran d'une page web à partir d'une URL donnée. Retourne une URL vers l'image capturée.",
                "parameters": {
                    "url": {"type": "STRING", "description": "L'URL de la page web à capturer.", "required": True}
                }
            },
            "crawlbase_scraper": {
                "enabled": True,
                "description": "Scrape le contenu HTML ou JavaScript d'une URL. Peut être utilisé pour obtenir le contenu brut d'une page web.",
                "parameters": {
                    "url": {"type": "STRING", "description": "L'URL de la page web à scraper.", "required": True},
                    "use_js": {"type": "BOOLEAN", "description": "Indique si le scraping doit exécuter JavaScript sur la page.", "required": False, "default": False}
                }
            },
            "detect_language": {
                "enabled": True,
                "description": "Détecte la langue d'un texte donné.",
                "parameters": {
                    "text": {"type": "STRING", "description": "Le texte dont la langue doit être détectée.", "required": True}
                }
            },
            "guardian_news": {
                "enabled": True,
                "description": "Recherche des articles de presse sur The Guardian. Utile pour des actualités ou des informations spécifiques.",
                "parameters": {
                    "query_text": {"type": "STRING", "description": "La requête de recherche pour les articles.", "required": True}
                }
            },
            "ip2location": {
                "enabled": True,
                "description": "Géolocalise une adresse IP pour obtenir des informations sur le pays, la ville, etc.",
                "parameters": {
                    "ip_address": {"type": "STRING", "description": "L'adresse IP à géolocaliser.", "required": True}
                }
            },
            "shodan": {
                "enabled": True,
                "description": "Interroge Shodan pour des informations sur un hôte IP ou des informations sur la clé API. Si une IP est fournie, retourne les infos de l'hôte, sinon les infos de la clé API.",
                "parameters": {
                    "query_text": {"type": "STRING", "description": "L'adresse IP à rechercher ou vide pour les infos de la clé API.", "required": False, "default": ""}
                }
            },
            "weather_api": {
                "enabled": True,
                "description": "Récupère les conditions météorologiques actuelles pour une localisation donnée.",
                "parameters": {
                    "location": {"type": "STRING", "description": "La ville ou le code postal pour la météo.", "required": True}
                }
            },
            "cloudmersive_domain": {
                "enabled": True,
                "description": "Vérifie la validité et le type d'un nom de domaine via Cloudmersive API.",
                "parameters": {
                    "domain": {"type": "STRING", "description": "Le nom de domaine à vérifier.", "required": True}
                }
            },
            "greynoise": {
                "enabled": True,
                "description": "Analyse une adresse IP pour détecter si elle est associée à des activités 'bruit' (scans, attaques, etc.) via GreyNoise.",
                "parameters": {
                    "ip_address": {"type": "STRING", "description": "L'adresse IP à analyser.", "required": True}
                }
            },
            "pulsedive": {
                "enabled": True,
                "description": "Analyse un indicateur de menace (IP, domaine, URL) via Pulsedive pour obtenir des informations sur les risques.",
                "parameters": {
                    "indicator": {"type": "STRING", "description": "L'indicateur de menace à analyser (ex: '8.8.8.8', 'example.com').", "required": True},
                    "type": {"type": "STRING", "description": "Le type d'indicateur ('auto', 'ip', 'domain', 'url').", "required": False, "default": "auto", "enum": ["auto", "ip", "domain", "url"]}
                }
            },
            "stormglass": {
                "enabled": True,
                "description": "Récupère les données météorologiques maritimes (température de l'air, hauteur des vagues, etc.) pour une coordonnée géographique.",
                "parameters": {
                    "lat": {"type": "NUMBER", "description": "Latitude.", "required": True},
                    "lng": {"type": "NUMBER", "description": "Longitude.", "required": True},
                    "params": {"type": "STRING", "description": "Paramètres météo à récupérer (comma-separated, ex: 'airTemperature,waveHeight').", "required": False, "default": "airTemperature,waveHeight"}
                }
            },
            "loginradius_ping": {
                "enabled": True,
                "description": "Effectue un simple ping à l'API LoginRadius pour vérifier sa disponibilité. Ne nécessite aucun paramètre.",
                "parameters": {}
            },
            "jsonbin_io": {
                "enabled": True,
                "description": "Crée un nouveau 'bin' JSON pour stocker des données ou accède à un bin existant. Utile pour stocker temporairement des données structurées.",
                "parameters": {
                    "data": {"type": "OBJECT", "description": "Les données JSON à stocker lors de la création d'un bin.", "required": False},
                    "private": {"type": "BOOLEAN", "description": "Indique si le bin doit être privé.", "required": False, "default": True},
                    "bin_id": {"type": "STRING", "description": "L'ID du bin existant à accéder.", "required": False}
                }
            },
            "huggingface_inference": {
                "enabled": True,
                "description": "Effectue une inférence sur un modèle HuggingFace (ex: classification de texte, génération de texte).",
                "parameters": {
                    "model_name": {"type": "STRING", "description": "Le nom du modèle HuggingFace à utiliser (ex: 'distilbert-base-uncased-finetuned-sst-2-english').", "required": False, "default": "distilbert-base-uncased-finetuned-sst-2-english"},
                    "input_text": {"type": "STRING", "description": "Le texte d'entrée pour l'inférence.", "required": True}
                }
            },
            "twilio_balance": {
                "enabled": True,
                "description": "Récupère le solde du compte Twilio. Utile pour vérifier les crédits restants pour l'envoi de SMS/appels.",
                "parameters": {}
            },
            "abstractapi": {
                "enabled": True,
                "description": "Interroge diverses APIs d'AbstractAPI pour la validation d'emails/téléphones, les taux de change ou les jours fériés.",
                "parameters": {
                    "input_value": {"type": "STRING", "description": "La valeur d'entrée (email, numéro de téléphone, devise de base, code pays) selon le type d'API.", "required": True},
                    "api_type": {"type": "STRING", "description": "Le type d'API AbstractAPI à utiliser ('PHONE_VALIDATION', 'EMAIL_VALIDATION', 'EXCHANGE_RATES', 'HOLIDAYS').", "required": True, "enum": ["PHONE_VALIDATION", "EMAIL_VALIDATION", "EXCHANGE_RATES", "HOLIDAYS"]}
                }
            },
            "google_custom_search": {
                "enabled": True,
                "description": "Effectue une recherche personnalisée Google en utilisant l'API Custom Search. Nécessite un ID de moteur de recherche personnalisé (CSE ID).",
                "parameters": {
                    "query_text": {"type": "STRING", "description": "La requête de recherche.", "required": True}
                }
            },
            "randommer_phone": {
                "enabled": True,
                "description": "Génère des numéros de téléphone aléatoires pour un pays donné. Utile pour des données de test ou des exemples.",
                "parameters": {
                    "country_code": {"type": "STRING", "description": "Le code ISO du pays (ex: 'US', 'FR').", "required": False, "default": "US"},
                    "quantity": {"type": "INTEGER", "description": "Le nombre de numéros de téléphone à générer.", "required": False, "default": 1}
                }
            },
            "tomorrow_io_weather": {
                "enabled": True,
                "description": "Récupère les prévisions météorologiques détaillées via Tomorrow.io pour une localisation et des champs spécifiques.",
                "parameters": {
                    "location": {"type": "STRING", "description": "La localisation (nom de ville, code postal, coordonnées lat/lng).", "required": True},
                    "fields": {"type": "ARRAY", "items": {"type": "STRING"}, "description": "Liste des champs météo à récupérer (ex: ['temperature', 'humidity']).", "required": False, "default": ["temperature", "humidity", "windSpeed"]}
                }
            },
            "openweathermap_weather": {
                "enabled": True,
                "description": "Récupère les conditions météorologiques actuelles via OpenWeatherMap pour une localisation donnée.",
                "parameters": {
                    "location": {"type": "STRING", "description": "La ville ou le code postal pour la météo.", "required": True}
                }
            },
            "mockaroo_data": {
                "enabled": True,
                "description": "Génère des données de test aléatoires via Mockaroo en fonction d'un schéma JSON.",
                "parameters": {
                    "count": {"type": "INTEGER", "description": "Le nombre d'enregistrements à générer.", "required": False, "default": 1},
                    "fields_json": {"type": "STRING", "description": "Un tableau JSON de définitions de champs (ex: '[{\"name\":\"id\",\"type\":\"Row Number\"}]').", "required": False}
                }
            },
            "openpagerank": {
                "enabled": True,
                "description": "Récupère le PageRank de domaines via OpenPageRank. Utile pour évaluer l'autorité d'un site web.",
                "parameters": {
                    "domains": {"type": "ARRAY", "items": {"type": "STRING"}, "description": "Liste des noms de domaine à vérifier (ex: ['google.com', 'openai.com']).", "required": True}
                }
            },
            "rapidapi": {
                "enabled": True,
                "description": "Interroge diverses APIs disponibles via RapidAPI (blagues, taux de change, faits aléatoires).",
                "parameters": {
                    "api_name": {"type": "STRING", "description": "Le nom de l'API RapidAPI à utiliser (ex: 'Programming Joke', 'Currency List Quotes', 'Random Fact').", "required": True, "enum": ["Programming Joke", "Currency List Quotes", "Random Fact"]},
                    "api_kwargs": {"type": "OBJECT", "description": "Arguments spécifiques à l'API RapidAPI appelée.", "required": False}
                }
            },
            "run_in_sandbox": {
                "enabled": True,
                "description": "Exécute du code Python ou Shell dans une sandbox sécurisée. Utilisez cet outil pour tester ou exécuter des extraits de code.",
                "parameters": {
                    "code": {"type": "STRING", "description": "Le code à exécuter.", "required": True},
                    "language": {"type": "STRING", "description": "Le langage du code ('python' ou 'shell').", "required": False, "default": "python", "enum": ["python", "shell"]}
                }
            },
            "webcontainer_sandbox": {
                "enabled": True,
                "description": "Exécute du code dans un environnement WebContainer pour JavaScript/HTML/CSS.",
                "parameters": {
                    "code": {"type": "STRING", "description": "Le code à exécuter.", "required": True},
                    "language": {"type": "STRING", "description": "Le langage du code ('javascript', 'html', 'css').", "required": False, "default": "javascript"}
                }
            },
            "fetch_and_archive_pages": {
                "enabled": True,
                "description": "Télécharge, sécurise et archive des pages web avec protection contre les trackers.",
                "parameters": {
                    "links": {"type": "ARRAY", "items": {"type": "STRING"}, "description": "Liste des URLs à archiver.", "required": True},
                    "user_id": {"type": "STRING", "description": "Identifiant de l'utilisateur pour l'archivage.", "required": True}
                }
            },
            "run_coding_challenge": {
                "enabled": True,
                "description": "Lance un défi de codage complet et compétitif entre tous les agents IA disponibles pour résoudre un problème complexe. Utilise cet outil pour obtenir et comparer plusieurs solutions optimisées à un problème de programmation.",
                "parameters": {
                    "custom_prompt": {
                        "type": "STRING",
                        "description": "Optionnel. Un prompt de défi spécifique. Si non fourni, un défi aléatoire sera généré.",
                        "required": False
                    }
                }
            }
        }

# Instance globale de configuration
config = Config()

# decentralized_system.py
import asyncio
import traceback
import time
from datetime import datetime
from typing import Dict, Any, List, Optional

from config import config
from utils import log_message, set_file_lock, format_error
from app_singletons import endpoint_health_manager, quota_manager
from autonomous_participant import AutonomousParticipant
from synthesizer_brain import SynthesizerBrain
from coding_challenge_system import get_coding_challenge_system
from telegram_logger import set_telegram_integration, log_system_event, log_error, log_success
from brain_library import TelegramMemoryIntegration
from shared_state import shared_state
from event_bus import event_bus

class DecentralizedAISystem:
    """
    Chef d'orchestre de l'écosystème d'IA décentralisé.
    Gère le cycle de vie, la distribution des tâches et la coordination des agents.
    Transformé en "Concierge" qui gère l'état et publie les tâches.
    """
    def __init__(self):
        self.participants: List[AutonomousParticipant] = []
        self.telegram_memory: Optional[TelegramMemoryIntegration] = None
        self.coding_system: Optional[Any] = None
        self.synthesizer: Optional[SynthesizerBrain] = None
        self.system_initialized = False
        self.start_time = datetime.now().timestamp()
        self.last_activity = self.start_time

    async def initialize_system(self, telegram_bot_client: Any):
        """Initialise tous les composants du système."""
        try:
            log_message("🚀 Initialisation du système d'IA décentralisé...")
            
            set_file_lock(asyncio.Lock())
            
            await endpoint_health_manager.init_manager()
            await quota_manager.init_manager()
            
            self.telegram_memory = TelegramMemoryIntegration(telegram_bot_client)
            set_telegram_integration(self.telegram_memory)
            
            for agent_config in config.AGENT_CONFIGS:
                participant = AutonomousParticipant(
                    participant_id=agent_config["id"],
                    brain_type=agent_config["type"],
                    service_name=agent_config["service"],
                    api_key=agent_config["key"],
                    telegram_client=telegram_bot_client
                )
                self.participants.append(participant)

            participant_ids = [p.id for p in self.participants]
            await shared_state.set_participants(participant_ids)

            brains_by_service_name = {p.service_name: p.processing_engine for p in self.participants}
            for participant in self.participants:
                participant.processing_engine.brains = brains_by_service_name
            log_message("✅ Injection de dépendance des cerveaux terminée.")

            self.coding_system = get_coding_challenge_system(telegram_bot_client)
            self.coding_system.initialize_participants(self.participants)
            self.synthesizer = SynthesizerBrain(telegram_bot_client)
            await self.synthesizer.initialize()
            
            await log_system_event(
                "SYSTEM_INIT",
                f"Système initialisé avec {len(self.participants)} agents autonomes prêts.",
                {"participants_count": len(self.participants)}
            )
            
            self.system_initialized = True
            log_message("🎉 Système d'IA décentralisé initialisé avec succès")
            return True
            
        except Exception as e:
            log_message(f"❌ Erreur critique lors de l'initialisation: {e}\n{traceback.format_exc()}", level="critical")
            return False

    async def start_background_tasks(self):
        """Démarre toutes les tâches de fond autonomes."""
        if not self.system_initialized:
            log_message("Système non initialisé, tâches de fond annulées.", level="error")
            return
        
        log_message("🔄 Démarrage des tâches de fond...")
        asyncio.create_task(self._periodic_health_checks())
        asyncio.create_task(self.coding_system.start_periodic_challenges())
        asyncio.create_task(self._proactive_quota_checks())
        asyncio.create_task(self._memory_cleanup())
        asyncio.create_task(self._leader_rotation_task())
        await log_system_event("BACKGROUND_TASKS_STARTED", "Toutes les tâches de fond sont actives.")

    async def handle_user_request(self, user_query: str, user_id: str, image_data: Optional[str] = None):
        """Publie la requête utilisateur sur le bus d'événements pour que le leader la traite."""
        if not self.system_initialized:
            log_message("Système non initialisé, impossible de traiter la requête.", level="error")
            return

        self.last_activity = time.time()
        
        await log_system_event("USER_REQUEST_PUBLISHED", f"Nouvelle requête de {user_id} publiée sur le bus.", {"query": user_query[:200]})
        await event_bus.publish(
            "USER_REQUEST_RECEIVED",
            data={"query": user_query, "user_id": user_id, "image_data": image_data}
        )

    async def _leader_rotation_task(self):
        """Tâche de fond pour la rotation équitable du leader."""
        # Effectue une première rotation au démarrage pour désigner un leader initial
        await asyncio.sleep(5) # Laisse le temps aux abonnements de se faire
        await self.force_next_leader()

        while True:
            await asyncio.sleep(config.BRAIN_ROTATION_INTERVAL_SECONDS)
            await self.force_next_leader()

    async def force_next_leader(self):
        """Désigne le prochain agent comme leader et publie l'événement."""
        new_leader_id = await shared_state.get_next_leader()
        if new_leader_id:
            log_message(f"ROTATION/BASCULEMENT : Le nouveau leader est {new_leader_id}", "info")
            await log_system_event("LEADER_ROTATION", f"Nouveau leader désigné : {new_leader_id}")
        else:
            log_message("Impossible de faire la rotation, aucune participant enregistré.", "warning")

    async def _periodic_health_checks(self):
        """Tâche de fond pour les health checks périodiques."""
        while True:
            await asyncio.sleep(config.HEALTH_CHECK_INTERVAL_SECONDS)
            log_message("Lancement des health checks périodiques...")
            tasks = [endpoint_health_manager.run_health_check_for_service(s) for s in config.API_CONFIG.keys()]
            await asyncio.gather(*tasks)
            await log_system_event("HEALTH_CHECK_COMPLETE", "Cycle de vérification de santé terminé.")

    async def _proactive_quota_checks(self):
        """Tâche de fond pour la surveillance proactive des quotas."""
        while True:
            await asyncio.sleep(3600)
            try:
                all_quotas = quota_manager.get_all_quotas_status()
                report_lines = []
                warnings = []
                for api, status in all_quotas.items():
                    if isinstance(status, dict) and status.get('limit', 0) > 0:
                        percent_remaining = (status['remaining'] / status['limit']) * 100
                        report_lines.append(f"- `{api}`: {status['current_usage']}/{status['limit']} ({percent_remaining:.1f}%)")
                        if percent_remaining < 20:
                            warnings.append(f"`{api}` ({percent_remaining:.1f}%)")
                
                report = "📊 *RAPPORT DE QUOTAS PROACTIF*\n" + "\n".join(report_lines)
                if warnings:
                    report += f"\n\n*⚠️ AVERTISSEMENT - QUOTAS FAIBLES:*\n" + ", ".join(warnings)
                
                await log_system_event("QUOTA_REPORT", report)
            except Exception as e:
                await log_error("QuotaSystem", f"Erreur lors de la vérification proactive des quotas: {e}")

    async def _memory_cleanup(self):
        """Nettoyage périodique de la mémoire."""
        while True:
            try:
                await asyncio.sleep(24 * 3600)
                
                for participant in self.participants:
                    await participant.processing_engine.memory_manager.save_memory()
                
                from security_archiver import archive_storage
                archive_storage.cleanup_old_archives(days=30)

                await self.telegram_memory.write_to_group(
                    "🧹 Nettoyage de mémoire et d'archives effectué",
                    "MEMORY_CLEANUP"
                )
                
                log_message("Nettoyage de mémoire et d'archives effectué")
                
            except Exception as e:
                log_message(f"Erreur nettoyage mémoire: {e}", level="error")
                await log_error("MemoryCleanup", f"Erreur lors du nettoyage de la mémoire: {e}")

    async def get_system_status(self) -> Dict[str, Any]:
        """Retourne le statut complet du système."""
        if not self.system_initialized:
            return {"status": "not_initialized"}
        
        current_leader = await shared_state.get_current_leader()
        
        return {
            "status": "operational",
            "initialized": self.system_initialized,
            "active_participants": len(self.participants),
            "current_leader": current_leader,
            "coding_challenges": self.coding_system.get_challenge_statistics() if self.coding_system else {},
            "uptime_seconds": time.time() - self.start_time,
            "last_activity_timestamp": self.last_activity
        }
    
    async def shutdown(self):
        """Arrêt propre du système."""
        log_message("🛑 Arrêt du système d'IA décentralisé...")
        
        try:
            if self.coding_system:
                self.coding_system.stop_challenges()
            
            for participant in self.participants:
                await participant.processing_engine.memory_manager.save_memory()
            
            await self.telegram_memory.write_to_group(
                "🛑 Système d'IA décentralisé arrêté proprement",
                "SYSTEM_SHUTDOWN"
            )
            
            log_message("✅ Système arrêté proprement")
            
        except Exception as e:
            log_message(f"Erreur lors de l'arrêt: {e}", level="error")
            await log_error("SystemShutdown", f"Erreur lors de l'arrêt du système: {e}")

# endpoint_health_manager.py
import asyncio
import httpx
import time
from datetime import datetime, timedelta, timezone
from typing import Dict, Any, Optional, List, Tuple

from config import config
from utils import load_json, save_json, get_current_time, format_datetime, log_message
from telegram_logger import log_error

class EndpointHealthManager:
    """
    Gère la santé des endpoints API pour l'écosystème d'agents.
    Implémenté comme un singleton pour garantir un état de santé unique et partagé.
    C'est le "médecin" du système.
    """
    _instance = None

    def __new__(cls, *args, **kwargs):
        if cls._instance is None:
            cls._instance = super(EndpointHealthManager, cls).__new__(cls)
        return cls._instance

    def __init__(self):
        if not hasattr(self, '_initialized'):
            self.health_status: Dict[str, Dict[str, Any]] = {}
            self._initialized = True
            log_message("Gestionnaire de santé des endpoints initialisé.")

    async def init_manager(self):
        """Charge l'état de santé depuis un fichier et initialise les nouveaux endpoints."""
        self.health_status = await load_json(config.ENDPOINT_HEALTH_FILE, {})
        self._initialize_all_endpoints()
        log_message("Gestionnaire de santé des endpoints chargé et prêt.")

    def _initialize_all_endpoints(self):
        """S'assure que chaque endpoint défini dans la config a une entrée de santé."""
        updated = False
        for service_name, endpoints_config in config.API_CONFIG.items():
            if service_name not in self.health_status:
                self.health_status[service_name] = {}
                updated = True
            
            for endpoint_config in endpoints_config:
                endpoint_key = self._get_endpoint_key(endpoint_config)
                if endpoint_key not in self.health_status[service_name]:
                    self.health_status[service_name][endpoint_key] = {
                        "latency": 0.0,
                        "success_rate": 1.0,
                        "last_checked": None,
                        "error_count": 0,
                        "total_checks": 0,
                        "is_healthy": True,
                        "last_error": None,
                        "consecutive_failures": 0
                    }
                    updated = True
        
        if updated:
            asyncio.create_task(save_json(config.ENDPOINT_HEALTH_FILE, self.health_status))
            log_message("Statut de santé des endpoints initialisé/mis à jour.")

    def _get_endpoint_key(self, endpoint_config: Dict[str, Any]) -> str:
        """Génère une clé unique pour un endpoint basé sur son nom et sa clé API."""
        name = endpoint_config['endpoint_name']
        key = endpoint_config.get('key', '')
        key_part = str(key[0]) if isinstance(key, tuple) else str(key)
        return f"{name}-{key_part[:8]}"

    async def run_health_check_for_service(self, service_name: str):
        """Exécute des checks de santé pour tous les endpoints d'un service donné."""
        endpoints_config = config.API_CONFIG.get(service_name, [])
        if not endpoints_config:
            log_message(f"Aucune configuration d'endpoint trouvée pour le service: {service_name}", level="warning")
            return

        log_message(f"Lancement du health check pour le service: {service_name}")
        tasks = [self._check_single_endpoint(service_name, ec) for ec in endpoints_config]
        await asyncio.gather(*tasks)
        log_message(f"Health check terminé pour le service: {service_name}")

    async def _check_single_endpoint(self, service_name: str, endpoint_config: Dict[str, Any]):
        """Logique de vérification pour un seul endpoint."""
        endpoint_key = self._get_endpoint_key(endpoint_config)
        start_time = time.monotonic()
        success = False
        error_details = ""

        try:
            request_method = endpoint_config.get("method", "GET")
            url = endpoint_config["url"]
            
            params = endpoint_config.get("health_check_params", {}).copy()
            json_data = endpoint_config.get("health_check_json", None)
            headers = endpoint_config.get("fixed_headers", {}).copy()
            auth = None
            
            check_timeout = endpoint_config.get("timeout", 10)
            
            if "health_check_url_suffix" in endpoint_config:
                url += endpoint_config["health_check_url_suffix"]
            
            key_field = endpoint_config.get("key_field")
            key_location = endpoint_config.get("key_location")
            key_prefix = endpoint_config.get("key_prefix", "")
            api_key = endpoint_config["key"]
            
            if key_field and key_location:
                if key_location == "param":
                    params[key_field] = api_key
                elif key_location == "header":
                    headers[key_field] = f"{key_prefix}{api_key}"
                elif key_location == "auth_basic":
                    if isinstance(api_key, tuple) and len(api_key) == 2:
                        auth = httpx.BasicAuth(api_key[0], api_key[1])
                    else:
                        log_message(f"Clé API pour auth_basic non valide pour {service_name}:{endpoint_key}", level="error")
                        return
            
            if "fixed_params" in endpoint_config:
                params.update(endpoint_config["fixed_params"])
            
            async with httpx.AsyncClient(timeout=check_timeout) as client:
                response = await client.request(
                    request_method, url, 
                    params=params, 
                    headers=headers, 
                    json=json_data, 
                    auth=auth
                )
                response.raise_for_status()
                success = True
                
        except httpx.HTTPStatusError as e:
            log_level = "warning"
            if 400 <= e.response.status_code < 500 and e.response.status_code != 429:
                log_level = "debug"
            log_message(f"Health check pour {endpoint_key} ({service_name}) a échoué (HTTP {e.response.status_code}): {e.response.text}", level=log_level)
            success = False
            error_details = f"HTTP Status {e.response.status_code}"
            
        except httpx.RequestError as e:
            log_message(f"Health check pour {endpoint_key} ({service_name}) a échoué (Réseau): {e}", level="warning")
            success = False
            error_details = f"Network Error: {type(e).__name__}"
            
        except Exception as e:
            log_message(f"Health check pour {endpoint_key} ({service_name}) a échoué (Inattendu): {e}", level="error")
            success = False
            error_details = f"Unexpected Error: {type(e).__name__}"
            
        finally:
            latency = time.monotonic() - start_time
            await self.update_endpoint_health(service_name, endpoint_key, success, latency, error_details)

    async def update_endpoint_health(self, service_name: str, endpoint_key: str, success: bool, latency: float, error_details: str = ""):
        """
        Met à jour le statut de santé d'un endpoint spécifique.
        Utilise une moyenne mobile exponentielle pour la latence et le taux de succès.
        """
        if service_name not in self.health_status:
            self.health_status[service_name] = {}
        
        if endpoint_key not in self.health_status[service_name]:
            self.health_status[service_name][endpoint_key] = {
                "latency": 0.0, "success_rate": 1.0, "last_checked": None,
                "error_count": 0, "total_checks": 0, "is_healthy": True,
                "last_error": None, "consecutive_failures": 0
            }
        
        status = self.health_status[service_name][endpoint_key]
        status["total_checks"] += 1
        status["last_checked"] = format_datetime(get_current_time())
        
        alpha = 0.1
        
        if success:
            status["consecutive_failures"] = 0
            status["error_count"] = max(0, status["error_count"] - 1)
            status["success_rate"] = status["success_rate"] * (1 - alpha) + 1.0 * alpha
            status["latency"] = status["latency"] * (1 - alpha) + latency * alpha
            status["last_error"] = None
        else:
            status["consecutive_failures"] += 1
            status["error_count"] += 1
            status["success_rate"] = status["success_rate"] * (1 - alpha) + 0.0 * alpha
            status["latency"] = status["latency"] * (1 - alpha) + 10.0 * alpha
            status["last_error"] = f"{format_datetime(get_current_time())}: {error_details}"
        
        if status["consecutive_failures"] >= 3 or status["success_rate"] < 0.5:
            status["is_healthy"] = False
        else:
            status["is_healthy"] = True
        
        asyncio.create_task(save_json(config.ENDPOINT_HEALTH_FILE, self.health_status))
        
        log_level = "debug" if status["is_healthy"] else "warning"
        log_message(f"Santé de {service_name}:{endpoint_key} mise à jour: Succès: {success}, Latence: {latency:.2f}s, Taux Succès: {status['success_rate']:.2f}, Sain: {status['is_healthy']}", level=log_level)

    async def is_healthy(self, endpoint_name: str, service_name: str) -> bool:
        """Vérifie si un endpoint spécifique est sain."""
        service_health = self.health_status.get(service_name, {})
        
        for endpoint_key, status in service_health.items():
            if endpoint_name in endpoint_key:
                return status.get("is_healthy", False)
        
        return False

    async def is_service_healthy(self, service_name: str) -> bool:
        """Vérifie si au moins un endpoint du service est sain."""
        service_health = self.health_status.get(service_name, {})
        
        if not service_health:
            return True
        
        healthy_endpoints = [
            status for status in service_health.values()
            if status.get("is_healthy", False)
        ]
        
        return len(healthy_endpoints) > 0

    async def get_healthy_endpoints(self, service_name: str) -> List[Dict[str, Any]]:
        """Retourne la liste des configurations d'endpoints sains pour un service, triés par performance."""
        service_health = self.health_status.get(service_name, {})
        all_configs = config.API_CONFIG.get(service_name, [])
        
        healthy_configs_with_status = []
        for conf in all_configs:
            endpoint_key = self._get_endpoint_key(conf)
            status = service_health.get(endpoint_key)
            if status and status.get("is_healthy", False):
                healthy_configs_with_status.append((conf, status))
        
        healthy_configs_with_status.sort(key=lambda item: item[1].get("latency", float('inf')))
        
        return [conf for conf, _ in healthy_configs_with_status]

    async def get_best_endpoint(self, service_name: str) -> Optional[Dict]:
        """
        Sélectionne le meilleur endpoint pour un service donné basé sur son statut de santé.
        """
        service_health = self.health_status.get(service_name)
        if not service_health:
            log_message(f"Aucune donnée de santé pour le service {service_name}. Retourne None.", level="warning")
            return None

        healthy_endpoints = [
            (key, status) for key, status in service_health.items()
            if status["is_healthy"]
        ]

        if not healthy_endpoints:
            log_message(f"Aucun endpoint sain pour le service {service_name}. Tentative de sélection d'un endpoint non sain.", level="warning")
            all_endpoints = list(service_health.items())
            if not all_endpoints:
                return None
            
            sorted_endpoints = sorted(
                all_endpoints,
                key=lambda item: (item[1]["consecutive_failures"], item[1]["latency"])
            )
            best_endpoint_key = sorted_endpoints[0][0]
            log_message(f"Fallback: Endpoint {best_endpoint_key} selected for {service_name} (unhealthy).", level="warning")
        else:
            best_endpoint_key, _ = max(
                healthy_endpoints,
                key=lambda item: (item[1]["success_rate"] * 100) - (item[1]["latency"] * 10) - (item[1]["consecutive_failures"] * 5)
            )
            log_message(f"Best endpoint for {service_name}: {best_endpoint_key}")

        for endpoint_config in config.API_CONFIG.get(service_name, []):
            current_endpoint_key = self._get_endpoint_key(endpoint_config)
            if current_endpoint_key == best_endpoint_key:
                return endpoint_config

        return None

    def mark_unhealthy(self, endpoint_name: str, service_name: str, reason: str):
        """Marque un endpoint comme non sain."""
        service_health = self.health_status.get(service_name, {})
        
        for endpoint_key, status in service_health.items():
            if endpoint_name in endpoint_key:
                status["is_healthy"] = False
                status["consecutive_failures"] += 1
                status["last_error"] = f"{format_datetime(get_current_time())}: {reason}"
                log_message(f"Endpoint {endpoint_key} marked as unhealthy: {reason}", level="warning")
                asyncio.create_task(save_json(config.ENDPOINT_HEALTH_FILE, self.health_status))
                break

endpoint_health_manager = EndpointHealthManager()

# event_bus.py
import asyncio
import json
from typing import Callable, Dict, Any
import logging
from redis_client import redis_client

log = logging.getLogger(__name__)

class EventBus:
    """Bus d'événements utilisant Redis Pub/Sub pour une communication robuste."""

    async def publish(self, channel: str, data: Dict[str, Any]):
        """Publie un message sur un canal Redis."""
        try:
            client = redis_client.get_client()
            message = json.dumps(data)
            await client.publish(channel, message)
            log.debug(f"Événement publié sur le canal '{channel}'.")
        except Exception as e:
            log.error(f"Erreur lors de la publication sur le canal Redis '{channel}': {e}")

    async def subscribe(self, channel: str, callback: Callable):
        """
        Abonne une fonction à un canal Redis et lance une tâche de fond pour l'écoute.
        """
        async def listener():
            client = redis_client.get_client()
            pubsub = client.pubsub()
            await pubsub.subscribe(channel)
            log.info(f"Abonné au canal Redis '{channel}'. En attente de messages...")
            while True:
                try:
                    message = await pubsub.get_message(ignore_subscribe_messages=True, timeout=None)
                    if message:
                        log.debug(f"Message reçu sur le canal '{message['channel']}'")
                        data = json.loads(message['data'])
                        # Lance le callback en tâche de fond pour ne pas bloquer l'écoute
                        asyncio.create_task(callback(data))
                except Exception as e:
                    log.error(f"Erreur dans l'écouteur Redis pour le canal '{channel}': {e}")
                    await asyncio.sleep(5) # Attendre avant de réessayer

        # Lance l'écouteur en tâche de fond pour qu'il ne bloque pas le reste du programme
        asyncio.create_task(listener())

event_bus = EventBus()

# main.py
import asyncio
import traceback
from datetime import datetime
from typing import Dict, Any, List, Optional

from telegram.ext import Application

from config import config
from utils import log_message, format_error
from decentralized_system import DecentralizedAISystem
from brain_library import api_key_library
from security_archiver import fetch_and_archive_pages
from tools import get_gemini_tools
from event_bus import event_bus
from redis_client import redis_client
import telegram_logger

async def main():
    """Point d'entrée principal de l'application."""
    log_message("===================================================", "info")
    log_message("DÉMARRAGE DU SYSTÈME D'IA DÉCENTRALISÉ", "info")
    log_message("===================================================", "info")

    try:
        await redis_client.initialize()
    except Exception as e:
        log_message("Impossible de continuer sans Redis. Arrêt du système.", "critical")
        return

    system = DecentralizedAISystem()

    telegram_bot_app = None
    if not config.TELEGRAM_BOT_TOKEN or "VOTRE_CLE_API_GEMINI_ICI" in config.TELEGRAM_BOT_TOKEN:
        log_message("Token Telegram non configuré ou placeholder. Le logger fonctionnera en mode console.", "warning")
        success = await system.initialize_system(telegram_bot_client=None)
    else:
        # Initialisation de l'application python-telegram-bot
        telegram_bot_app = Application.builder().token(config.TELEGRAM_BOT_TOKEN).build()
        # Le client bot est accessible via telegram_bot_app.bot
        success = await system.initialize_system(telegram_bot_client=telegram_bot_app.bot)

    if not success:
        log_message("Échec de l'initialisation du système. Arrêt.", "critical")
        return

    await system.start_background_tasks()

    print("\n" + "="*60)
    print("🧠 SYSTÈME D'IA DÉCENTRALISÉ - 7 CERVEAUX AUTONOMES")
    print("="*60)
    print("Commandes disponibles:")
    print("  /help      - Affiche l'aide")
    print("  /status    - Statut du système")
    print("  /keys      - Affiche les clés et capacités des services")
    print("  /quotas    - État des quotas")
    print("  /challenges - Statistiques défis")
    print("  /challenge - Lance un défi manuel")
    print("  /archive <urls> - Archive des pages web")
    print("  /exit      - Quitter")
    print("  Ou tapez directement votre question")
    print("="*60)
    
    while True:
        try:
            user_input = await asyncio.to_thread(input, "\n🤖 Vous: ")
            user_input = user_input.strip()
            
            if not user_input:
                continue
            
            if user_input.lower() == "/exit":
                break
            
            elif user_input.lower() == "/help":
                print("""
📋 AIDE DU SYSTÈME D'IA DÉCENTRALISÉ

🧠 Architecture:
  • Agents autonomes proactifs communiquant via un bus d'événements (Redis).
  • Rotation automatique du leader toutes les 45 minutes.
  • Basculement automatique en cas de non-réponse du leader.
  • Mémoire partagée dans le groupe privé Telegram.

🎯 Fonctionnalités:
  • Traitement de requêtes utilisateur
  • Défis de codage automatisés (15 min)
  • Archivage sécurisé de pages web
  • Monitoring santé des APIs
  • Gestion intelligente des quotas

💬 Exemples d'utilisation:
  • "Explique-moi la programmation asynchrone"
  • "Crée un script Python pour analyser des données"
  • "Recherche les dernières nouvelles sur l'IA"
  • "/archive https://example.com,https://site.org"
""")
            
            elif user_input.lower() == "/status":
                status = await system.get_system_status()
                uptime_seconds = status.get('uptime_seconds', 0)
                last_activity_ts = status.get('last_activity_timestamp', 0)
                
                print(f"""
📊 STATUT SYSTÈME:
  • État: {status['status']}
  • Participants actifs: {status['active_participants']}
  • Leader Actuel: {status.get('current_leader', 'N/A')}
  • Uptime: {int(uptime_seconds // 3600)}h {int((uptime_seconds % 3600) // 60)}m {int(uptime_seconds % 60)}s
  • Dernière activité: {datetime.fromtimestamp(last_activity_ts).strftime('%Y-%m-%d %H:%M:%S')}
""")
            
            elif user_input.lower() == "/brains":
                print("La commande /brains est obsolète. Utilisez /status pour voir le leader actuel.")
            
            elif user_input.lower() == "/keys":
                print("\n🔑 BIBLIOTHÈQUE DE CLÉS ET CAPACITÉS (via APIKeyLibrary):")
                for service, key_configs in api_key_library.api_keys.items():
                    print(f"  - Service: {service} ({len(key_configs)} clé(s) active(s))")
                    for config in key_configs[:1]: # Affiche les endpoints pour la première clé seulement pour la lisibilité
                        for endpoint in config['endpoints']:
                            print(f"    • Capacité: {endpoint['name']}")

            elif user_input.lower() == "/quotas":
                quotas = system.quota_manager.get_all_quotas_status()
                print("\n📊 ÉTAT DES QUOTAS:")
                for api, quota_info in quotas.items():
                    if isinstance(quota_info, dict) and 'error' not in quota_info:
                        usage = quota_info['current_usage']
                        limit = quota_info['limit']
                        remaining = quota_info['remaining']
                        percent = (usage / limit * 100) if limit > 0 else 0
                        print(f"  {api}: {usage}/{limit} ({percent:.1f}%) - Restant: {remaining}")
            
            elif user_input.lower() == "/challenges":
                if system.coding_system:
                    stats = system.coding_system.get_challenge_statistics()
                    print(f"""
🎯 STATISTIQUES DÉFIS DE CODAGE:
  • Total défis: {stats.get('total_challenges', 0)}
  • Participants: {stats.get('total_participants', 0)}
  • Succès: {stats.get('total_successful', 0)}
  • Taux succès: {stats.get('average_success_rate', 0):.1f}%
  • Statut: {'🔄 Actif' if stats.get('is_running') else '⏹️ Arrêté'}
""")
                else:
                    print("❌ Système de défis non initialisé")

            elif user_input.lower().startswith("/challenge"):
                try:
                    if system.coding_system and system.coding_system.is_running:
                        print("🚀 Lancement manuel d'un défi de codage pour tous les agents...")
                        asyncio.create_task(system.coding_system.run_coding_challenge())
                        print("✅ Défi lancé. Surveillez le groupe privé pour les résultats.")
                    else:
                        print("❌ Le système de défis de codage n'est pas actif ou initialisé.")
                except Exception as e:
                    print(f"❌ Erreur lors du lancement du défi : {format_error(e)}")
            
            elif user_input.startswith("/archive "):
                urls_str = user_input[9:].strip()
                if urls_str:
                    urls = [url.strip() for url in urls_str.split(',') if url.strip()]
                    if urls:
                        print(f"🗂️ Archivage de {len(urls)} URL(s) en cours...")
                        result = await fetch_and_archive_pages(urls, "console_user")
                        print(f"✅ {result.get('tool_output', 'Archivage terminé')}")
                    else:
                        print("❌ Aucune URL valide fournie")
                else:
                    print("❌ Usage: /archive <url1>,<url2>,...")
            
            else:
                response_queue = asyncio.Queue()
                async def on_response_ready(data):
                    await response_queue.put(data)
                
                await event_bus.subscribe("RESPONSE_READY", on_response_ready)

                await system.handle_user_request(user_input, "console_user")
                print("🤔 Tâche publiée pour le leader actuel. En attente d'une réponse (timeout 60s)...")

                try:
                    response = await asyncio.wait_for(response_queue.get(), timeout=60.0)
                    
                    if "error" in response:
                        print(f"❌ Erreur ({response.get('brain_id', 'UNKNOWN')}): {response['error']}")
                    else:
                        brain_id = response.get('brain_id', 'UNKNOWN')
                        processing_time = response.get('processing_time', 0)
                        
                        if 'response' in response and isinstance(response['response'], dict):
                            candidates = response['response'].get('candidates', [])
                            if candidates and 'content' in candidates[0]:
                                parts = candidates[0]['content'].get('parts', [])
                                if parts and 'text' in parts[0]:
                                    answer = parts[0]['text']
                                else:
                                    answer = str(response['response'])
                            else:
                                answer = str(response['response'])
                        else:
                            answer = str(response.get('response', 'Aucune réponse'))
                        
                        print(f"\n🤖 {brain_id} ({processing_time:.2f}s): {answer}")
                        
                        if 'tool_results' in response and response['tool_results']:
                            print(f"\n🔧 Outils utilisés: {len(response['tool_results'])}")
                            for tool in response['tool_results']:
                                tool_name = tool.get('tool_name', 'Inconnu')
                                tool_error = tool.get('error')
                                if tool_error:
                                    print(f"  • {tool_name} (Échec: {tool_error})")
                                else:
                                    print(f"  • {tool_name}")

                except asyncio.TimeoutError:
                    print("❌ Le leader actuel n'a pas répondu à temps. Déclenchement du basculement.")
                    await telegram_logger.log_error("SystemSupervisor", "Timeout du leader. Basculement forcé.")
                    
                    await system.force_next_leader()
                    
                    print("🔄 Tâche republiée pour le nouveau leader...")
                    await system.handle_user_request(user_input, "console_user")
            
        except EOFError:
            print("\n👋 Au revoir !")
            break
        except KeyboardInterrupt:
            print("\n⚠️ Interruption détectée...")
            break
        except Exception as e:
            print(f"❌ Erreur: {format_error(e)}")
            log_message(f"Erreur console: {e}", level="error")
    
    finally:
        # Arrêt propre du système
        log_message("La boucle principale est terminée. Lancement de l'arrêt du système...")
        await system.shutdown()

if __name__ == "__main__":
    try:
        asyncio.run(main())
    except KeyboardInterrupt:
        print("\n🛑 Arrêt forcé du système")
    except Exception as e:
        print(f"❌ Erreur fatale: {format_error(e)}")

# quota_manager.py
import asyncio
from datetime import datetime, timedelta, timezone
from typing import Dict, Any

from config import config
from utils import load_json, save_json, get_current_time, format_datetime, log_message

class QuotaManager:
    """
    Gère l'utilisation des quotas pour différentes APIs.
    C'est le "comptable" du système.
    """
    _instance = None

    def __new__(cls, *args, **kwargs):
        if cls._instance is None:
            cls._instance = super(QuotaManager, cls).__new__(cls)
        return cls._instance

    def __init__(self):
        if not hasattr(self, '_initialized'):
            self.quota_state: Dict[str, Dict[str, Any]] = {}
            self._initialized = True
            log_message("Gestionnaire de quotas initialisé.")

    async def init_manager(self):
        """Charge l'état des quotas et initialise les nouvelles APIs."""
        self.quota_state = await load_json(config.QUOTA_STATE_FILE, {})
        self._initialize_all_quotas()
        log_message("Gestionnaire de quotas chargé et prêt.")

    def _initialize_all_quotas(self):
        """S'assure que chaque API a une entrée de quota et la réinitialise si nécessaire."""
        updated = False
        current_time = get_current_time()
        
        for api_name, quota_info in config.QUOTA_CONFIG.items():
            if api_name not in self.quota_state:
                self.quota_state[api_name] = {
                    "current_usage": 0,
                    "last_reset_time": current_time.isoformat(),
                    "last_usage_time": None,
                    "daily_peak": 0,
                    "success_count": 0,
                    "error_count": 0
                }
                updated = True
            
            self._check_and_reset_quota(api_name, current_time)
        
        if updated:
            asyncio.create_task(save_json(config.QUOTA_STATE_FILE, self.quota_state))
            log_message("État des quotas initialisé/mis à jour.")

    def _check_and_reset_quota(self, api_name: str, current_time: datetime) -> bool:
        """
        Vérifie si un quota doit être réinitialisé en fonction de son intervalle et le fait si nécessaire.
        """
        quota_info = config.QUOTA_CONFIG.get(api_name)
        if not quota_info:
            return False

        state = self.quota_state.get(api_name)
        if not state:
            state = {
                "current_usage": 0,
                "last_reset_time": current_time.isoformat(),
                "last_usage_time": None,
                "daily_peak": 0,
                "success_count": 0,
                "error_count": 0
            }
            self.quota_state[api_name] = state

        last_reset_dt = datetime.fromisoformat(state["last_reset_time"])
        reset_needed = False

        if quota_info["reset_interval"] == "daily":
            if current_time.date() > last_reset_dt.date():
                reset_needed = True
        elif quota_info["reset_interval"] == "hourly":
            if current_time.hour > last_reset_dt.hour or current_time.date() > last_reset_dt.date():
                reset_needed = True
        elif quota_info["reset_interval"] == "fixed_24h":
            if current_time - last_reset_dt >= timedelta(hours=24):
                reset_needed = True

        if reset_needed:
            state["daily_peak"] = max(state.get("daily_peak", 0), state["current_usage"])
            state["current_usage"] = 0
            state["success_count"] = 0
            state["error_count"] = 0
            state["last_reset_time"] = current_time.isoformat()
            
            log_message(f"Quota pour {api_name} réinitialisé. Pic précédent: {state['daily_peak']}")
            asyncio.create_task(save_json(config.QUOTA_STATE_FILE, self.quota_state))
            return True

        return False

    async def check_quota(self, api_name: str) -> bool:
        """Vérifie si une requête est autorisée selon le quota (avec burn_window restaurée)."""
        quota_info = config.QUOTA_CONFIG.get(api_name)
        if not quota_info:
            return True

        state = self.quota_state.get(api_name)
        if not state:
            self._initialize_all_quotas()
            state = self.quota_state.get(api_name)
            if not state:
                return False

        current_time = get_current_time()
        self._check_and_reset_quota(api_name, current_time)

        is_in_burn_window = False
        if quota_info.get("burn_window_hours", 0) > 0:
            last_reset_dt = datetime.fromisoformat(state["last_reset_time"])
            time_to_next_reset = timedelta(hours=0)

            if quota_info["reset_interval"] == "daily":
                next_reset = (last_reset_dt + timedelta(days=1)).replace(hour=0, minute=0, second=0, microsecond=0)
                time_to_next_reset = next_reset - current_time
            elif quota_info["reset_interval"] == "hourly":
                next_reset = (last_reset_dt + timedelta(hours=1)).replace(minute=0, second=0, microsecond=0)
                time_to_next_reset = next_reset - current_time
            elif quota_info["reset_interval"] == "fixed_24h":
                next_reset = last_reset_dt + timedelta(hours=24)
                time_to_next_reset = next_reset - current_time

            if timedelta(hours=0) < time_to_next_reset <= timedelta(hours=quota_info["burn_window_hours"]):
                is_in_burn_window = True

        if state["current_usage"] < quota_info["limit"]:
            return True
        elif is_in_burn_window:
            log_message(f"Quota {api_name} en mode cramage autorisé", level="warning")
            return True
        else:
            log_message(f"Quota {api_name} dépassé: {state['current_usage']}/{quota_info['limit']}", level="warning")
            return False

    async def increment_quota(self, api_name: str = "", success: bool = True):
        """Incrémente le quota après utilisation."""
        quota_info = config.QUOTA_CONFIG.get(api_name)
        if not quota_info:
            return

        state = self.quota_state.get(api_name)
        if not state:
            self._initialize_all_quotas()
            state = self.quota_state.get(api_name)

        if state:
            current_time = get_current_time()
            state["current_usage"] += 1
            state["last_usage_time"] = current_time.isoformat()
            
            if success:
                state["success_count"] = state.get("success_count", 0) + 1
            else:
                state["error_count"] = state.get("error_count", 0) + 1

            asyncio.create_task(save_json(config.QUOTA_STATE_FILE, self.quota_state))
            
            remaining = quota_info["limit"] - state["current_usage"]
            log_message(f"Quota {api_name}: {state['current_usage']}/{quota_info['limit']} (Restant: {remaining})")

    def get_quota_status(self, api_name: str) -> Dict[str, Any]:
        """Retourne le statut du quota pour une API."""
        quota_info = config.QUOTA_CONFIG.get(api_name, {})
        state = self.quota_state.get(api_name, {})
        
        if not state:
            return {"error": f"Pas de données pour {api_name}"}
        
        return {
            "api_name": api_name,
            "current_usage": state.get("current_usage", 0),
            "limit": quota_info.get("limit", 0),
            "remaining": quota_info.get("limit", 0) - state.get("current_usage", 0),
            "success_rate": (
                state.get("success_count", 0) / 
                max(1, state.get("success_count", 0) + state.get("error_count", 0))
            ) * 100,
            "last_usage": state.get("last_usage_time"),
            "last_reset": state.get("last_reset_time"),
            "daily_peak": state.get("daily_peak", 0)
        }

    def get_all_quotas_status(self) -> Dict[str, Dict[str, Any]]:
        """Retourne le statut de tous les quotas."""
        return {
            api_name: self.get_quota_status(api_name)
            for api_name in config.QUOTA_CONFIG.keys()
        }

quota_manager = QuotaManager()

# redis_client.py
import redis.asyncio as redis
import logging

log = logging.getLogger(__name__)

class RedisClient:
    """
    Un client singleton pour gérer la connexion à Redis de manière asynchrone.
    """
    _instance = None
    _client = None

    def __new__(cls):
        if cls._instance is None:
            cls._instance = super(RedisClient, cls).__new__(cls)
        return cls._instance

    async def initialize(self, host='localhost', port=6379, db=0):
        """Initialise la connexion pool à Redis."""
        if self._client is None:
            try:
                # Utilise un pool de connexions pour des performances optimales
                self._client = redis.Redis(host=host, port=port, db=db, decode_responses=True)
                await self._client.ping()
                log.info(f"Connexion à Redis établie avec succès sur {host}:{port}")
            except Exception as e:
                log.critical(f"ÉCHEC DE LA CONNEXION À REDIS : {e}")
                log.critical("Veuillez vous assurer que Redis est en cours d'exécution sur localhost:6379.")
                self._client = None
                raise

    def get_client(self):
        """Retourne le client Redis initialisé."""
        if self._client is None:
            raise ConnectionError("Le client Redis n'a pas été initialisé. Appelez initialize() d'abord.")
        return self._client

# Instance globale pour un accès facile
redis_client = RedisClient()

# security_archiver.py
import asyncio
import hashlib
import io
import re
import time
from datetime import datetime
from pathlib import Path
from typing import List, Optional, Dict, Any
from urllib.parse import urlparse

import httpx

from config import config
from utils import log_message, save_json, truncate_text
from telegram_logger import _send_log

class URLDefanger:
    """
    Neutralise les URLs pour empêcher les clics accidentels
    et bloque les trackers connus.
    """
    def __init__(self, mode: str = "secure"):
        self.mode = mode
        self.url_pattern = re.compile(r'https?://[^\s\]]+')
        self.tracker_domains = [
            "doubleclick.net", "googleadservices.com", "googlesyndication.com",
            "facebook.com/tr", "analytics.google.com", "hotjar.com",
            "mouseflow.com", "crazyegg.com", "fullstory.com"
        ]
    
    def _generate_hash(self, url: str) -> str:
        """Génère un identifiant unique pour l'URL."""
        return hashlib.sha256(url.encode()).hexdigest()[:8]
    
    def defang_url(self, url: str) -> str:
        """Transforme une URL en version sécurisée."""
        for tracker in self.tracker_domains:
            if tracker in url:
                return "[TRACKER_BLOQUÉ]"
        
        if self.mode == "secure":
            return f"[URL_BLOQUÉE:#{self._generate_hash(url)}]"
        else:
            parsed = urlparse(url)
            return f"[URL:{parsed.netloc}/...#{self._generate_hash(url)}]"
    
    def defang_text(self, text: str) -> str:
        """Nettoie tout le contenu texte."""
        return self.url_pattern.sub(
            lambda m: self.defang_url(m.group(0)), 
            text
        )

class SecurePageArchiver:
    """
    Télécharge, sécurise et archive des pages web
    avec gestion des gros fichiers et protection anti-tracking.
    """
    def __init__(self, telegram_client=None):
        self.telegram_client = telegram_client
        from brain_library import TelegramMemoryIntegration
        self.telegram_memory = TelegramMemoryIntegration(telegram_client)
        self.headers = {
            "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36",
            "Accept-Language": "fr-FR,fr;q=0.9,en;q=0.8",
            "Accept-Encoding": "gzip, deflate, br",
            "Accept": "text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8",
            "DNT": "1",
            "Connection": "keep-alive",
            "Upgrade-Insecure-Requests": "1"
        }
        
    async def fetch_page(self, url: str) -> Optional[httpx.Response]:
        """Télécharge une page avec gestion robuste des erreurs."""
        try:
            async with httpx.AsyncClient(
                timeout=30.0,
                headers=self.headers,
                follow_redirects=True,
                http2=True,
                limits=httpx.Limits(max_keepalive_connections=5, max_connections=10)
            ) as client:
                response = await client.get(url)
                
                content_length = response.headers.get('content-length')
                if content_length and int(content_length) > config.MAX_FILE_SIZE:
                    log_message(f"Contenu trop volumineux pour {url}: {content_length} bytes", level="warning")
                    return None
                
                response.raise_for_status()
                return response
                
        except httpx.HTTPStatusError as e:
            log_message(f"Erreur HTTP pour {url}: {e.response.status_code}", level="warning")
            return None
        except httpx.RequestError as e:
            log_message(f"Erreur réseau pour {url}: {e}", level="warning")
            return None
        except Exception as e:
            log_message(f"Erreur inattendue pour {url}: {e}", level="error")
            return None

    async def secure_content(self, url: str, content: str) -> str:
        """Applique les protections de sécurité au contenu."""
        defanger = URLDefanger(mode="secure")
        
        header = f"""
⚠️ CONTENU ARCHIVÉ - LIENS NEUTRALISÉS ⚠️
URL originale: {url}
Horodatage: {datetime.utcnow().isoformat()}Z
Taille originale: {len(content)} caractères
Sécurisé par: SecurePageArchiver v2.1
=====================================

"""
        
        secured_content = defanger.defang_text(content)
        
        secured_content = re.sub(r'<script[^>]*>.*?</script>', '[SCRIPT_SUPPRIMÉ]', secured_content, flags=re.DOTALL | re.IGNORECASE)
        secured_content = re.sub(r'javascript:[^"\']*', '[JAVASCRIPT_BLOQUÉ]', secured_content, flags=re.IGNORECASE)
        secured_content = re.sub(r'on\w+\s*=\s*["\'][^"\']*["\']', '[EVENT_HANDLER_BLOQUÉ]', secured_content, flags=re.IGNORECASE)
        
        return header + secured_content

    async def send_content(self, content: str, url: str, user_id: str) -> bool:
        """Envoie le contenu sécurisé via Telegram, en tant que fichier si nécessaire."""
        try:
            caption = f"📄 Archive de la page : `{truncate_text(url, 100)}`\n👤 Demandé par : `{user_id}`"
            
            if len(content) > 3800:
                timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
                filename = f"archive_{user_id}_{timestamp}.txt"
                await _send_log(caption, file_content=content, file_name=filename)
            else:
                message = f"{caption}\n\n```\n{truncate_text(content, 3500)}\n```"
                await _send_log(message)

            log_message(f"Contenu archivé envoyé pour {url}")
            return True
            
        except Exception as e:
            log_message(f"Erreur envoi contenu archivé: {e}", level="error")
            from telegram_logger import log_error as telegram_log_error
            await telegram_log_error("ARCHIVER", f"Échec envoi contenu archivé pour {url}: {e}")
            return False

    async def archive_single_page(self, url: str, user_id: str) -> Dict[str, Any]:
        """Archive une seule page web."""
        start_time = time.time()
        result = {
            "url": url,
            "user_id": user_id,
            "timestamp": datetime.now().isoformat(),
            "success": False,
            "content_sent": False,
            "total_size": 0,
            "processing_time": 0,
            "error": None
        }
        
        try:
            from telegram_logger import log_brain_activity, log_success, log_error as telegram_log_error

            await log_brain_activity(
                "ARCHIVER",
                f"Début archivage: {url}",
                {"user_id": user_id}
            )
            
            response = await self.fetch_page(url)
            if not response:
                result["error"] = "Échec du téléchargement"
                return result
            
            content_type = response.headers.get('content-type', '').lower()
            if not any(ct in content_type for ct in ['text/html', 'text/plain', 'application/json']):
                result["error"] = f"Type de contenu non supporté: {content_type}"
                return result
            
            raw_content = response.text
            result["total_size"] = len(raw_content)
            
            secured_content = await self.secure_content(url, raw_content)
            
            content_sent = await self.send_content(secured_content, url, user_id)
            
            result["content_sent"] = content_sent
            result["success"] = content_sent
            
            processing_time = time.time() - start_time
            result["processing_time"] = processing_time
            
            if content_sent:
                await log_success(
                    "ARCHIVER",
                    f"Page archivée: {url}",
                    f"Contenu envoyé avec succès."
                )
            else:
                raise Exception("Échec de l'envoi du contenu sur Telegram.")
            
        except Exception as e:
            result["error"] = str(e)
            await telegram_log_error("ARCHIVER", f"Erreur archivage {url}: {e}")
        
        return result

class ArchiveCoordinator:
    """
    Coordinateur pour l'archivage de multiples pages en parallèle.
    """
    def __init__(self, telegram_client=None, max_concurrent: int = 3):
        self.archiver = SecurePageArchiver(telegram_client)
        self.max_concurrent = max_concurrent
        from brain_library import TelegramMemoryIntegration
        self.telegram_memory = TelegramMemoryIntegration(telegram_client)
        
    async def archive_multiple_pages(self, links: List[str], user_id: str) -> Dict[str, Any]:
        """Archive plusieurs pages en parallèle avec limitation de concurrence."""
        start_time = time.time()
        
        await self.telegram_memory.write_to_group(
            f"🚀 Début archivage de {len(links)} pages pour l'utilisateur {user_id}",
            "ARCHIVE_START"
        )
        
        if len(links) > 10:
            links = links[:10]
            await self.telegram_memory.write_to_group(
                "⚠️ Limitation appliquée: maximum 10 liens par session",
                "ARCHIVE_LIMIT"
            )
        
        semaphore = asyncio.Semaphore(self.max_concurrent)
        
        async def archive_with_semaphore(url: str) -> Dict[str, Any]:
            async with semaphore:
                return await self.archiver.archive_single_page(url, user_id)
        
        tasks = [archive_with_semaphore(url) for url in links]
        results = await asyncio.gather(*tasks, return_exceptions=True)
        
        summary = {
            "total_links": len(links),
            "successful": 0,
            "failed": 0,
            "total_size": 0,
            "processing_time": time.time() - start_time,
            "results": []
        }
        
        for i, result in enumerate(results):
            if isinstance(result, Exception):
                error_result = {
                    "url": links[i] if i < len(links) else "Unknown",
                    "success": False,
                    "error": str(result)
                }
                summary["results"].append(error_result)
                summary["failed"] += 1
            else:
                summary["results"].append(result)
                if result["success"]:
                    summary["successful"] += 1
                    summary["total_size"] += result["total_size"]
                else:
                    summary["failed"] += 1
        
        await self.telegram_memory.write_to_group(
            f"""
📊 RAPPORT D'ARCHIVAGE TERMINÉ

👤 Utilisateur: {user_id}
📊 Statistiques:
  • Total: {summary['total_links']} liens
  • Succès: {summary['successful']} pages
  • Échecs: {summary['failed']} pages
  • Taille totale (brute): {summary['total_size']:,} caractères
  • Durée: {summary['processing_time']:.2f}s

✅ Toutes les pages sont sécurisées et archivées dans ce groupe.
""",
            "ARCHIVE_COMPLETE"
        )
        
        await archive_storage.save_archive_metadata(user_id, summary)

        return summary

async def fetch_and_archive_pages(links: List[str], user_id: str, context=None) -> Dict[str, Any]:
    """
    Fonction principale pour télécharger, sécuriser et archiver des pages web.
    """
    try:
        from app_clients_instances import telegram_bot_client
        
        coordinator = ArchiveCoordinator(telegram_bot_client, max_concurrent=3)
        summary = await coordinator.archive_multiple_pages(links, user_id)
        
        return {
            "tool_output": f"✅ Archivage terminé: {summary['successful']}/{summary['total_links']} pages archivées avec succès. Les contenus ont été envoyés dans le groupe privé.",
            "summary": summary
        }
        
    except Exception as e:
        error_msg = f"❌ Erreur système d'archivage: {e}"
        log_message(f"Erreur fetch_and_archive_pages: {e}", level="error")
        return {
            "tool_output": error_msg,
            "error": str(e)
        }

class ContentAnalyzer:
    """Analyse le contenu des pages archivées."""
    
    @staticmethod
    def extract_metadata(content: str, url: str) -> Dict[str, Any]:
        """Extrait les métadonnées d'une page."""
        metadata = {
            "url": url,
            "timestamp": datetime.now().isoformat(),
            "size": len(content),
            "title": "",
            "description": "",
            "language": "unknown",
            "charset": "unknown"
        }
        
        title_match = re.search(r'<title[^>]*>(.*?)</title>', content, re.IGNORECASE | re.DOTALL)
        if title_match:
            metadata["title"] = truncate_text(title_match.group(1).strip(), 200)
        
        desc_match = re.search(r'<meta[^>]*name=["\']description["\'][^>]*content=["\']([^"\']*)["\']', content, re.IGNORECASE)
        if desc_match:
            metadata["description"] = truncate_text(desc_match.group(1).strip(), 500)
        
        lang_match = re.search(r'<html[^>]*lang=["\']([^"\']*)["\']', content, re.IGNORECASE)
        if lang_match:
            metadata["language"] = lang_match.group(1).strip()
        
        charset_match = re.search(r'<meta[^>]*charset=["\']?([^"\'>\s]+)["\']?', content, re.IGNORECASE)
        if charset_match:
            metadata["charset"] = charset_match.group(1).strip()
        
        return metadata
    
    @staticmethod
    def count_elements(content: str) -> Dict[str, int]:
        """Compte les éléments HTML dans le contenu."""
        elements = {
            "links": len(re.findall(r'<a[^>]*href=', content, re.IGNORECASE)),
            "images": len(re.findall(r'<img[^>]*src=', content, re.IGNORECASE)),
            "scripts": len(re.findall(r'<script[^>]*>', content, re.IGNORECASE)),
            "forms": len(re.findall(r'<form[^>]*>', content, re.IGNORECASE)),
            "paragraphs": len(re.findall(r'<p[^>]*>', content, re.IGNORECASE)),
            "headings": len(re.findall(r'<h[1-6][^>]*>', content, re.IGNORECASE))
        }
        
        return elements

class ArchiveStorage:
    """Gestionnaire de stockage pour les archives."""
    
    def __init__(self):
        self.archive_dir = config.SYSTEM_ARCHIVE_DIR
        self.archive_dir.mkdir(exist_ok=True)
        
    async def save_archive_metadata(self, user_id: str, summary: Dict[str, Any]):
        """Sauvegarde les métadonnées d'archivage."""
        try:
            metadata_file = self.archive_dir / f"archive_{user_id}_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json"
            
            await save_json(metadata_file, summary)
            
            log_message(f"Métadonnées d'archivage sauvegardées: {metadata_file}")
            
        except Exception as e:
            log_message(f"Erreur sauvegarde métadonnées: {e}", level="error")
    
    def get_user_archives(self, user_id: str) -> List[Path]:
        """Récupère la liste des archives d'un utilisateur."""
        pattern = f"archive_{user_id}_*.json"
        return list(self.archive_dir.glob(pattern))
    
    def cleanup_old_archives(self, days: int = 30):
        """Nettoie les anciennes archives."""
        cutoff_time = time.time() - (days * 24 * 60 * 60)
        
        for archive_file in self.archive_dir.glob("archive_*.json"):
            if archive_file.stat().st_mtime < cutoff_time:
                try:
                    archive_file.unlink()
                    log_message(f"Archive supprimée: {archive_file}")
                except Exception as e:
                    log_message(f"Erreur suppression archive {archive_file}: {e}", level="error")

archive_storage = ArchiveStorage()

# shared_state.py
import time
from typing import List
import logging
from redis_client import redis_client

log = logging.getLogger(__name__)

class SharedState:
    """Gère l'état partagé du système en utilisant Redis."""

    async def set_participants(self, participant_ids: List[str]):
        """Initialise la liste circulaire des participants dans Redis."""
        client = redis_client.get_client()
        # Supprime l'ancienne liste pour être sûr de repartir à zéro
        await client.delete('participant_rotation_list')
        if participant_ids:
            # Ajoute tous les participants à une liste Redis
            await client.rpush('participant_rotation_list', *participant_ids)
        log.info(f"{len(participant_ids)} participants enregistrés pour la rotation.")

    async def get_next_leader(self) -> str:
        """
        Récupère le prochain leader en faisant tourner la liste de manière atomique.
        RPOPLPUSH prend le dernier élément et le met en premier, ce qui crée une boucle parfaite.
        """
        client = redis_client.get_client()
        leader_id = await client.rpoplpush('participant_rotation_list', 'participant_rotation_list')
        await client.set('current_leader_id', leader_id)
        await client.set('last_rotation_time', time.time())
        return leader_id

    async def get_current_leader(self) -> str:
        """Récupère le leader actuel."""
        client = redis_client.get_client()
        return await client.get('current_leader_id')

shared_state = SharedState()

# synthesizer_brain.py
import json
from typing import Dict, Any, List, Optional, Union

from autonomous_brain import AutonomousBrain
import telegram_logger
from utils import log_message
from app_singletons import endpoint_health_manager
from app_clients_instances import get_client

class SynthesizerBrain(AutonomousBrain):
    """
    Un cerveau spécialisé dont le seul rôle est de synthétiser des données brutes
    pour formuler une réponse finale de haute qualité. C'est le "Rédacteur en Chef".
    """
    def __init__(self, telegram_client: Optional[Any] = None):
        self.agent_service_priority = [
            "GEMINI_API", 
            "DEEPSEEK", 
            "HUGGINGFACE",
            "TAVILY",
            "SERPER",
            "GOOGLE_CUSTOM_SEARCH",
            "WOLFRAMALPHA"
        ]
        
        super().__init__(
            brain_id="SYNTHESIZER",
            service_name=self.agent_service_priority[0],
            telegram_client=telegram_client,
            api_key="N/A_SYNTHESIZER"
        )
        log_message("Cerveau Synthétiseur initialisé.")
        
    async def synthesize_response(self, original_query: str, tool_results: List[Dict]) -> Dict[str, Any]:
        """
        Prend une question originale et des données brutes, et génère une réponse synthétisée.
        """
        await telegram_logger.log_agent_decision(self.brain_id, "Début de la synthèse de la réponse finale.")
        
        formatted_tool_results = []
        for result in tool_results:
            tool_name = result.get("tool_name", "outil_inconnu")
            output = result.get("tool_output", result.get("error", "Aucune sortie"))
            if isinstance(output, dict):
                output = json.dumps(output, indent=2, ensure_ascii=False)
            formatted_tool_results.append(f"--- Résultat de l'outil : {tool_name} ---\n{str(output)[:1500]}\n")

        synthesis_prompt = f"""RÔLE: Expert en synthèse d'informations.
MISSION: Formuler une réponse claire, complète et bien structurée pour l'utilisateur, en te basant EXCLUSIVEMENT sur les données fournies.

CONTEXTE:
- Requête originale de l'utilisateur: "{original_query}"
- Données brutes collectées par les outils spécialisés:
{"\n".join(formatted_tool_results)}

INSTRUCTIONS:
1. Analyse la requête originale pour bien comprendre l'intention.
2. Examine attentivement les données brutes de chaque outil.
3. Croise et fusionne ces informations pour construire une réponse unique et cohérente. Ne te contente pas de lister les résultats, intègre-les dans un texte fluide.
4. Si des outils ont échoué, mentionne-le poliment si c'est pertinent (ex: "La recherche d'images n'a pas abouti.").
5. Structure ta réponse pour une lisibilité maximale (titres, listes, gras).
6. Ta réponse finale doit être directement adressée à l'utilisateur. Ne mentionne pas ton processus interne.
7. Rédige la réponse finale ci-dessous.
"""

        final_response_dict = {"error": "Aucun agent n'a pu réaliser la synthèse."}
        for service in self.agent_service_priority:
            self.service_name = service
            self.api_client = get_client(service)
            
            if not self.api_client:
                log_message(f"Synthétiseur: Client API pour le service {service} non trouvé. Essai du suivant.", "warning")
                continue

            healthy_endpoints = await endpoint_health_manager.get_healthy_endpoints(service)
            if not healthy_endpoints:
                log_message(f"Synthétiseur: Aucun endpoint sain pour le service {service}. Essai du suivant.", "warning")
                continue

            best_endpoint = healthy_endpoints[0]
            
            await telegram_logger.log_agent_decision(
                self.brain_id, 
                f"Sélection du service '{service}' via l'endpoint '{best_endpoint['endpoint_name']}' pour la synthèse."
            )
            
            final_response_dict = await self._generate_response(
                endpoint_config=best_endpoint,
                prompt=synthesis_prompt,
                chat_history=[],
                tools=[]
            )
            
            if not (isinstance(final_response_dict, str) and final_response_dict.startswith("❌")):
                await telegram_logger.log_system_event("SYNTHESIS_COMPLETE", f"Synthèse terminée avec succès via {service}.")
                return {"response": final_response_dict}
        
        error_msg = "Tous les services LLM de synthèse ont échoué."
        await telegram_logger.log_error(self.brain_id, error_msg)
        return {"error": error_msg}

    async def _generate_response(self, endpoint_config: Dict[str, Any], 
                               prompt: Union[str, List[Dict[str, Any]]],
                               chat_history: Optional[List[Dict]] = None,
                               image_data: Optional[str] = None,
                               tools: Optional[List[Dict]] = None,
                               model_name: Optional[str] = None
                               ) -> Union[Dict, str]:
        """
        Génère une réponse de synthèse, avec un fallback sur les outils de recherche.
        """
        if not self.api_client:
            return f"❌ Client API pour le service de synthèse '{self.service_name}' non trouvé."

        # Tente d'utiliser les méthodes de génération de contenu des LLM en priorité
        if hasattr(self.api_client, 'generate_content'):
            return await self.api_client.generate_content(
                endpoint_config=endpoint_config,
                prompt=prompt,
                chat_history=chat_history or [],
                image_data=image_data,
                tools=tools,
                model_name=model_name,
                agent_id=self.brain_id
            )
        
        # ===== LOGIQUE DE FALLBACK (PLAN B) RESTAURÉE =====
        # Si le client n'est pas un LLM, il pourrait être un outil de recherche
        elif hasattr(self.api_client, 'execute_with_config'):
            log_message(f"Synthétiseur: Le client {self.service_name} n'est pas un LLM. Utilisation en mode recherche comme fallback.", "warning")
            # On utilise le prompt de synthèse comme une requête de recherche
            result = await self.api_client.execute_with_config(endpoint_config, query=prompt, agent_id=self.brain_id)
            
            # Formate la sortie de la recherche en une réponse textuelle simple
            synthesis = ""
            if isinstance(result, dict):
                if result.get("answer"):
                    synthesis += f"Réponse directe: {result['answer']}\n\n"
                if result.get("results"):
                    synthesis += "Sources pertinentes:\n"
                    for item in result["results"][:3]:
                        synthesis += f"- {item.get('title', '')}\n"
            
            if not synthesis:
                synthesis = json.dumps(result, indent=2)

            return {"candidates": [{"content": {"parts": [{"text": synthesis}]}}]}
        # =================================================
        
        else:
            raise NotImplementedError(f"Le client pour '{self.service_name}' n'a pas de méthode de génération de contenu reconnue.")

# telegram_logger.py
import json
from datetime import datetime, timezone
from typing import Optional, Dict, Any

from utils import log_message, truncate_text

# Cette variable globale contiendra l'instance de TelegramMemoryIntegration
# Elle sera définie au démarrage par la fonction set_telegram_integration
_telegram_integration_instance: Optional[Any] = None

def set_telegram_integration(instance: Any):
    """Définit l'instance de l'intégrateur Telegram à utiliser pour les logs."""
    global _telegram_integration_instance
    _telegram_integration_instance = instance
    log_message("Intégration Telegram configurée pour le logger.")

def _sanitize_text_for_markdown_v2(text: str) -> str:
    """Échappe les caractères spéciaux pour le mode MarkdownV2 de Telegram."""
    if not isinstance(text, str):
        text = str(text)
    escape_chars = r'_*[]()~`>#+-=|{}.!'
    return ''.join(f'\\{char}' if char in escape_chars else char for char in text)

async def _send_log(message: str, file_content: Optional[str] = None, file_name: Optional[str] = None):
    """Fonction interne pour envoyer un log au groupe Telegram, avec gestion des fichiers."""
    if _telegram_integration_instance and hasattr(_telegram_integration_instance, 'bot_client'):
        try:
            # Si du contenu de fichier est fourni, utiliser la méthode send_document
            if file_content and file_name and hasattr(_telegram_integration_instance.bot_client, 'send_document'):
                # La méthode send_document du client bot est appelée ici.
                # Elle doit être capable de gérer des bytes.
                await _telegram_integration_instance.bot_client.send_document(
                    chat_id=_telegram_integration_instance.group_id,
                    document=file_content.encode('utf-8'),
                    filename=file_name,
                    caption=message,
                    parse_mode='MarkdownV2'
                )
            else:
                # Sinon, envoyer un message texte simple
                # On utilise la méthode de bas niveau pour éviter une boucle infinie
                if hasattr(_telegram_integration_instance.bot_client, 'send_message'):
                     await _telegram_integration_instance.bot_client.send_message(
                         chat_id=_telegram_integration_instance.group_id,
                         text=message,
                         parse_mode='MarkdownV2'
                     )
                else: # Fallback si même send_message n'existe pas
                    log_message(f"[LOG TELEGRAM (FALLBACK)] {message}", "info")

        except Exception as e:
            log_message(f"Erreur lors de l'envoi du log Telegram: {e}", level="error")
            # Tenter d'envoyer un message texte simple en cas d'échec de l'envoi de fichier
            try:
                error_message = f"Erreur lors de l'envoi d'un log (probablement un fichier).\nMessage original:\n{message}"
                await _telegram_integration_instance.bot_client.send_message(
                    chat_id=_telegram_integration_instance.group_id,
                    text=error_message
                )
            except Exception as final_e:
                 log_message(f"Échec de l'envoi du message d'erreur Telegram: {final_e}", level="critical")
    else:
        # Si l'intégration n'est pas configurée, log en console
        log_message(f"[LOG TELEGRAM (CONSOLE)] {message}", "info")

async def log_system_event(event_type: str, message: str, details: Optional[Dict] = None):
    """Archive un événement système majeur."""
    timestamp = _sanitize_text_for_markdown_v2(datetime.now().strftime('%H:%M:%S'))
    log_message_text = f"*⚙️ Événement Système* \\| `{timestamp}`\n"
    log_message_text += f"*Type:* `{_sanitize_text_for_markdown_v2(event_type)}`\n"
    log_message_text += f"*Message:* {_sanitize_text_for_markdown_v2(message)}"
    if details:
        details_str = json.dumps(details, indent=2, ensure_ascii=False)
        log_message_text += f"\n*Détails:*\n```json\n{_sanitize_text_for_markdown_v2(details_str)}\n```"
    await _send_log(log_message_text)

async def log_agent_decision(agent_id: str, decision: str, context: Optional[Dict] = None):
    """Archive une décision prise par un agent autonome."""
    timestamp = _sanitize_text_for_markdown_v2(datetime.now().strftime('%H:%M:%S'))
    log_message_text = f"*🧠 Décision d'Agent* \\| `{timestamp}`\n"
    log_message_text += f"*Agent:* `{_sanitize_text_for_markdown_v2(agent_id)}`\n"
    log_message_text += f"*Décision:* {_sanitize_text_for_markdown_v2(decision)}"
    if context:
        context_str = json.dumps(context, ensure_ascii=False, default=str)
        if len(context_str) > 500:
            context_str = context_str[:500] + "..."
        log_message_text += f"\n*Contexte:* ```json\n{_sanitize_text_for_markdown_v2(context_str)}\n```"
    await _send_log(log_message_text)

async def log_error(agent_id: str, error_message: str):
    """Log une erreur de manière visible."""
    timestamp = _sanitize_text_for_markdown_v2(datetime.now().strftime('%H:%M:%S'))
    log_message_text = f"*❌ ERREUR* \\| `{timestamp}`\n"
    log_message_text += f"*Source:* `{_sanitize_text_for_markdown_v2(agent_id)}`\n"
    log_message_text += f"*Message:* ```\n{_sanitize_text_for_markdown_v2(error_message)}\n```"
    await _send_log(log_message_text)

async def log_success(agent_id: str, task: str, result: str):
    """Log un succès dans le groupe."""
    timestamp = _sanitize_text_for_markdown_v2(datetime.now().strftime('%H:%M:%S'))
    success_log = f"*✅ SUCCÈS* \\| `{timestamp}`\n"
    success_log += f"*Agent:* `{_sanitize_text_for_markdown_v2(agent_id)}`\n"
    success_log += f"*Tâche:* {_sanitize_text_for_markdown_v2(task)}\n"
    success_log += f"*Résultat (extrait):* ```\n{_sanitize_text_for_markdown_v2(result[:200])}...\n```"
    await _send_log(success_log)

async def log_structured_report(report_data: dict):
    """Envoie un rapport d'action structuré et détaillé, avec auto-protection."""
    try:
        timestamp_str = report_data.get('timestamp', datetime.now(timezone.utc).isoformat())
        formatted_time = _sanitize_text_for_markdown_v2(datetime.fromisoformat(timestamp_str).strftime('%Y-%m-%d %H:%M:%S'))
        
        report_text = f"📊 *Rapport d'Action IA* \\| `{formatted_time}`\n\n"
        report_text += f"*Agent Leader*: `{_sanitize_text_for_markdown_v2(report_data.get('agent_name', 'N/A'))}`\n"
        report_text += f"*Intention*: `{_sanitize_text_for_markdown_v2(report_data.get('intention', 'N/A'))}`\n"
        report_text += f"*Requête*: ```\n{_sanitize_text_for_markdown_v2(report_data.get('user_query', 'N/A'))}\n```\n"
        
        tools = report_data.get('tools_called', [])
        if tools:
            report_text += "*Outils/Agents Collaborateurs*:\n"
            for i, tool in enumerate(tools):
                tool_name = _sanitize_text_for_markdown_v2(tool.get('name', f'outil_{i+1}'))
                tool_result_excerpt = _sanitize_text_for_markdown_v2(str(tool.get('result', ''))[:200])
                report_text += f"\\- `{tool_name}` \\-> Résultat: ```\n{tool_result_excerpt}\n```\n"
        else:
            report_text += "*Outils/Agents Collaborateurs*: Aucun\n"
        
        final_resp = str(report_data.get('final_response', ''))
        if len(final_resp) > 500:
            final_resp = final_resp[:500] + "..."
        
        report_text += f"*Réponse Finale*: ```\n{_sanitize_text_for_markdown_v2(final_resp)}\n```\n"
        report_text += f"*Durée*: `{report_data.get('duration', 0):.2f}s`\n"
        status_msg = '✅ Succès' if not report_data.get('error') else f'❌ Échec: {_sanitize_text_for_markdown_v2(report_data.get("error"))}'
        report_text += f"*Statut*: {status_msg}"

        await _send_log(report_text)
    
    # ===== BLOC DE PROTECTION RESTAURÉ =====
    except Exception as e:
        # En cas d'erreur DANS la fonction de logging, on log l'erreur de manière critique
        # à la console et on envoie un événement système simple pour ne pas rester silencieux.
        print(f"❌ ERREUR CRITIQUE (log_structured_report): {e}")
        await log_system_event("LOGGING_ERROR", f"Échec de la création du rapport structuré: {e}")
    # =======================================

async def log_api_call(agent_id: str, endpoint_name: str, url: str, method: str, payload: str):
    """Log un appel API sortant."""
    timestamp = _sanitize_text_for_markdown_v2(datetime.now().strftime('%H:%M:%S'))
    log_message_text = f"*📡 Appel API* \\| `{timestamp}`\n"
    log_message_text += f"*Agent:* `{_sanitize_text_for_markdown_v2(agent_id)}`\n"
    log_message_text += f"*Endpoint:* `{_sanitize_text_for_markdown_v2(endpoint_name)}`\n"
    log_message_text += f"*Méthode:* `{method}`\n"
    log_message_text += f"*URL:* `{_sanitize_text_for_markdown_v2(url)}`\n"
    if payload:
        log_message_text += f"*Payload (extrait):* ```\n{_sanitize_text_for_markdown_v2(payload)}\n```"
    await _send_log(log_message_text)

async def log_api_response(agent_id: str, endpoint_name: str, status_code: int, response_text: str, latency: float):
    """Log la réponse d'un appel API."""
    timestamp = _sanitize_text_for_markdown_v2(datetime.now().strftime('%H:%M:%S'))
    status_icon = "✅" if 200 <= status_code < 300 else "⚠️"
    log_message_text = f"*📥 Réponse API {status_icon}* \\| `{timestamp}`\n"
    log_message_text += f"*Agent:* `{_sanitize_text_for_markdown_v2(agent_id)}`\n"
    log_message_text += f"*Endpoint:* `{_sanitize_text_for_markdown_v2(endpoint_name)}`\n"
    log_message_text += f"*Status:* `{status_code}`\n"
    log_message_text += f"*Latence:* `{latency:.3f}s`\n"
    log_message_text += f"*Réponse (extrait):* ```\n{_sanitize_text_for_markdown_v2(truncate_text(response_text, 300))}\n```"
    await _send_log(log_message_text)

async def log_api_call_summary_v2(service_name: str, endpoint_name: str, success: bool, status_code: Optional[int], latency_ms: int, error: Optional[str] = None):
    """Log un résumé d'appel API pour les rapports."""
    timestamp = _sanitize_text_for_markdown_v2(datetime.now().strftime('%H:%M:%S'))
    status_icon = "✅" if success else "❌"
    log_message_text = f"*📊 Résumé Appel API {status_icon}* \\| `{timestamp}`\n"
    log_message_text += f"*Service:* `{_sanitize_text_for_markdown_v2(service_name)}`\n"
    log_message_text += f"*Endpoint:* `{_sanitize_text_for_markdown_v2(endpoint_name)}`\n"
    log_message_text += f"*Latence:* `{latency_ms}ms`\n"
    if not success:
        log_message_text += f"*Status Code:* `{status_code or 'N/A'}`\n"
        log_message_text += f"*Erreur:* ```\n{_sanitize_text_for_markdown_v2(error)}\n```"
    await _send_log(log_message_text)

async def log_brain_activity(agent_id: str, activity: str, details: Optional[Dict] = None):
    """Log une activité interne d'un cerveau."""
    timestamp = _sanitize_text_for_markdown_v2(datetime.now().strftime('%H:%M:%S'))
    log_message_text = f"*💡 Activité Cerveau* \\| `{timestamp}`\n"
    log_message_text += f"*Agent:* `{_sanitize_text_for_markdown_v2(agent_id)}`\n"
    log_message_text += f"*Activité:* {_sanitize_text_for_markdown_v2(activity)}"
    if details:
        details_str = json.dumps(details, indent=2, ensure_ascii=False)
        log_message_text += f"\n*Détails:*\n```json\n{_sanitize_text_for_markdown_v2(details_str)}\n```"
    await _send_log(log_message_text)

# tools.py
import json
from typing import Dict, Any, List, Optional

import pyautogui
from plyer import notification

from config import config
from app_clients_instances import get_client
from utils import log_message, truncate_text, format_error
from security_archiver import fetch_and_archive_pages
from app_singletons import endpoint_health_manager
from event_bus import event_bus

def get_gemini_tools() -> List[Dict[str, Any]]:
    """
    Retourne la liste de tous les outils disponibles au format attendu par l'API Gemini.
    """
    gemini_tool_list = []
    for tool_name, tool_config in config.TOOL_CONFIG.items():
        if tool_config["enabled"]:
            function_declaration = {
                "name": tool_name,
                "description": tool_config["description"],
                "parameters": {
                    "type": "OBJECT",
                    "properties": tool_config["parameters"],
                    "required": [k for k, v in tool_config["parameters"].items() if v.get("required")]
                }
            }
            gemini_tool_list.append({"function_declarations": [function_declaration]})
            
    return gemini_tool_list

async def execute_tool(tool_name: str, context: Dict[str, Any], **kwargs) -> Dict[str, Any]:
    """
    Exécute l'outil demandé avec les arguments fournis.
    """
    tool_output = None
    error = None
    agent_id = context.get("brain_id", "N/A")

    try:
        if tool_name == "google_search":
            client = get_client("GOOGLE_CUSTOM_SEARCH")
            query = kwargs.get("queries", [""])[0]
            endpoint_config = await endpoint_health_manager.get_best_endpoint("GOOGLE_CUSTOM_SEARCH")
            if not endpoint_config: raise Exception("Aucun endpoint sain pour Google Custom Search.")
            tool_output = await client.execute_with_config(endpoint_config, query=query, agent_id=agent_id)
        
        elif tool_name == "tavily_search":
            client = get_client("TAVILY")
            endpoint_config = await endpoint_health_manager.get_best_endpoint("TAVILY")
            if not endpoint_config: raise Exception("Aucun endpoint sain pour Tavily.")
            tool_output = await client.execute_with_config(endpoint_config, query=kwargs.get("query_text"), max_results=kwargs.get("max_results"), agent_id=agent_id)

        elif tool_name == "serper_dev":
            client = get_client("SERPER")
            endpoint_config = await endpoint_health_manager.get_best_endpoint("SERPER")
            if not endpoint_config: raise Exception("Aucun endpoint sain pour Serper.")
            tool_output = await client.execute_with_config(endpoint_config, query=kwargs.get("query_text"), agent_id=agent_id)

        elif tool_name == "guardian_news":
            client = get_client("GUARDIAN")
            endpoint_config = await endpoint_health_manager.get_best_endpoint("GUARDIAN")
            if not endpoint_config: raise Exception("Aucun endpoint sain pour Guardian.")
            tool_output = await client.execute_with_config(endpoint_config, query=kwargs.get("query_text"), agent_id=agent_id)

        elif tool_name == "wolfram_alpha":
            client = get_client("WOLFRAMALPHA")
            endpoint_config = await endpoint_health_manager.get_best_endpoint("WOLFRAMALPHA")
            if not endpoint_config: raise Exception("Aucun endpoint sain pour WolframAlpha.")
            tool_output = await client.execute_with_config(endpoint_config, input_text=kwargs.get("input_text"), agent_id=agent_id)

        elif tool_name == "ip2location":
            client = get_client("IP2LOCATION")
            endpoint_config = await endpoint_health_manager.get_best_endpoint("IP2LOCATION")
            if not endpoint_config: raise Exception("Aucun endpoint sain pour IP2Location.")
            tool_output = await client.execute_with_config(endpoint_config, ip_address=kwargs.get("ip_address"), agent_id=agent_id)

        elif tool_name == "shodan":
            client = get_client("SHODAN")
            endpoint_config = await endpoint_health_manager.get_best_endpoint("SHODAN")
            if not endpoint_config: raise Exception("Aucun endpoint sain pour Shodan.")
            tool_output = await client.execute_with_config(endpoint_config, query_text=kwargs.get("query_text", ""), agent_id=agent_id)

        elif tool_name == "weather_api":
            client = get_client("WEATHERAPI")
            endpoint_config = await endpoint_health_manager.get_best_endpoint("WEATHERAPI")
            if not endpoint_config: raise Exception("Aucun endpoint sain pour WeatherAPI.")
            tool_output = await client.execute_with_config(endpoint_config, location=kwargs.get("location"), agent_id=agent_id)

        elif tool_name == "tomorrow_io_weather":
            client = get_client("TOMORROW.IO")
            endpoint_config = await endpoint_health_manager.get_best_endpoint("TOMORROW.IO")
            if not endpoint_config: raise Exception("Aucun endpoint sain pour Tomorrow.io.")
            tool_output = await client.execute_with_config(endpoint_config, location=kwargs.get("location"), fields=kwargs.get("fields"), agent_id=agent_id)

        elif tool_name == "openweathermap_weather":
            client = get_client("OPENWEATHERMAP")
            endpoint_config = await endpoint_health_manager.get_best_endpoint("OPENWEATHERMAP")
            if not endpoint_config: raise Exception("Aucun endpoint sain pour OpenWeatherMap.")
            tool_output = await client.execute_with_config(endpoint_config, location=kwargs.get("location"), agent_id=agent_id)

        elif tool_name == "stormglass":
            client = get_client("STORMGLASS")
            endpoint_config = await endpoint_health_manager.get_best_endpoint("STORMGLASS")
            if not endpoint_config: raise Exception("Aucun endpoint sain pour StormGlass.")
            tool_output = await client.execute_with_config(endpoint_config, lat=kwargs.get("lat"), lng=kwargs.get("lng"), params=kwargs.get("params"), agent_id=agent_id)

        elif tool_name == "openpagerank":
            client = get_client("OPENPAGERANK")
            endpoint_config = await endpoint_health_manager.get_best_endpoint("OPENPAGERANK")
            if not endpoint_config: raise Exception("Aucun endpoint sain pour OpenPageRank.")
            tool_output = await client.execute_with_config(endpoint_config, domains=kwargs.get("domains"), agent_id=agent_id)

        elif tool_name == "run_in_sandbox":
            client = get_client("WEBCONTAINER")
            endpoint_config = await endpoint_health_manager.get_best_endpoint("WEBCONTAINER")
            if not endpoint_config: raise Exception("Aucun endpoint sain pour WebContainer.")
            tool_output = await client.execute_with_config(endpoint_config, code=kwargs.get("code"), language=kwargs.get("language"), agent_id=agent_id)

        elif tool_name == "webcontainer_sandbox":
            client = get_client("WEBCONTAINER")
            endpoint_config = await endpoint_health_manager.get_best_endpoint("WEBCONTAINER")
            if not endpoint_config: raise Exception("Aucun endpoint sain pour WebContainer.")
            tool_output = await client.execute_with_config(endpoint_config, code=kwargs.get("code"), language=kwargs.get("language"), agent_id=agent_id)

        elif tool_name == "ocr_space":
            client = get_client("OCR_API")
            endpoint_config = await endpoint_health_manager.get_best_endpoint("OCR_API")
            if not endpoint_config: raise Exception("Aucun endpoint sain pour OCR_API.")
            tool_output = await client.execute_with_config(endpoint_config, image_base64=kwargs.get("image_base64"), language=kwargs.get("language"), agent_id=agent_id)

        elif tool_name == "apiflash_screenshot":
            client = get_client("APIFLASH")
            endpoint_config = await endpoint_health_manager.get_best_endpoint("APIFLASH")
            if not endpoint_config: raise Exception("Aucun endpoint sain pour ApiFlash.")
            tool_output = await client.execute_with_config(endpoint_config, url=kwargs.get("url"), agent_id=agent_id)

        elif tool_name == "crawlbase_scraper":
            client = get_client("CRAWLBASE")
            endpoint_config = await endpoint_health_manager.get_best_endpoint("CRAWLBASE")
            if not endpoint_config: raise Exception("Aucun endpoint sain pour Crawlbase.")
            tool_output = await client.execute_with_config(endpoint_config, url=kwargs.get("url"), use_js=kwargs.get("use_js"), agent_id=agent_id)

        elif tool_name == "detect_language":
            client = get_client("DETECTLANGUAGE")
            endpoint_config = await endpoint_health_manager.get_best_endpoint("DETECTLANGUAGE")
            if not endpoint_config: raise Exception("Aucun endpoint sain pour DetectLanguage.")
            tool_output = await client.execute_with_config(endpoint_config, text=kwargs.get("text"), agent_id=agent_id)

        elif tool_name == "cloudmersive_domain":
            client = get_client("CLOUDMERSIVE")
            endpoint_config = await endpoint_health_manager.get_best_endpoint("CLOUDMERSIVE")
            if not endpoint_config: raise Exception("Aucun endpoint sain pour Cloudmersive.")
            tool_output = await client.execute_with_config(endpoint_config, domain=kwargs.get("domain"), agent_id=agent_id)

        elif tool_name == "greynoise":
            client = get_client("GREYNOISE")
            endpoint_config = await endpoint_health_manager.get_best_endpoint("GREYNOISE")
            if not endpoint_config: raise Exception("Aucun endpoint sain pour GreyNoise.")
            tool_output = await client.execute_with_config(endpoint_config, ip_address=kwargs.get("ip_address"), agent_id=agent_id)

        elif tool_name == "pulsedive":
            client = get_client("PULSEDIVE")
            endpoint_config = await endpoint_health_manager.get_best_endpoint("PULSEDIVE")
            if not endpoint_config: raise Exception("Aucun endpoint sain pour Pulsedive.")
            tool_output = await client.execute_with_config(endpoint_config, indicator=kwargs.get("indicator"), type=kwargs.get("type"), agent_id=agent_id)

        elif tool_name == "loginradius_ping":
            client = get_client("LOGINRADIUS")
            endpoint_config = await endpoint_health_manager.get_best_endpoint("LOGINRADIUS")
            if not endpoint_config: raise Exception("Aucun endpoint sain pour LoginRadius.")
            tool_output = await client.execute_with_config(endpoint_config, agent_id=agent_id)

        elif tool_name == "jsonbin_io":
            client = get_client("JSONBIN")
            if kwargs.get("bin_id"):
                endpoint_config = next((ep for ep in client.endpoints if "Bin Access" in ep.get("endpoint_name", "")), None)
            elif kwargs.get("data"):
                endpoint_config = next((ep for ep in client.endpoints if "Bin Create" in ep.get("endpoint_name", "")), None)
            else:
                raise Exception("Jsonbin: Ni bin_id ni data fournis.")
            
            if not endpoint_config: raise Exception("Aucun endpoint sain pour Jsonbin (création/accès).")
            tool_output = await client.execute_with_config(endpoint_config, data=kwargs.get("data"), private=kwargs.get("private"), bin_id=kwargs.get("bin_id"), agent_id=agent_id)

        elif tool_name == "huggingface_inference":
            client = get_client("HUGGINGFACE")
            endpoint_config = await endpoint_health_manager.get_best_endpoint("HUGGINGFACE")
            if not endpoint_config: raise Exception("Aucun endpoint sain pour HuggingFace.")
            tool_output = await client.execute_with_config(endpoint_config, model_name=kwargs.get("model_name"), input_text=kwargs.get("input_text"), agent_id=agent_id)

        elif tool_name == "twilio_balance":
            client = get_client("TWILIO")
            endpoint_config = await endpoint_health_manager.get_best_endpoint("TWILIO")
            if not endpoint_config: raise Exception("Aucun endpoint sain pour Twilio.")
            tool_output = await client.execute_with_config(endpoint_config, agent_id=agent_id)

        elif tool_name == "abstractapi":
            client = get_client("ABSTRACTAPI")
            api_type = kwargs.get("api_type")
            if api_type == "EMAIL_VALIDATION":
                endpoint_config = next((ep for ep in client.endpoints if "Email Validation" in ep.get("endpoint_name", "")), None)
            elif api_type == "PHONE_VALIDATION":
                endpoint_config = next((ep for ep in client.endpoints if "Phone Validation" in ep.get("endpoint_name", "")), None)
            elif api_type == "EXCHANGE_RATES":
                endpoint_config = next((ep for ep in client.endpoints if "Exchange Rates" in ep.get("endpoint_name", "")), None)
            elif api_type == "HOLIDAYS":
                endpoint_config = next((ep for ep in client.endpoints if "Holidays" in ep.get("endpoint_name", "")), None)
            else:
                raise Exception(f"AbstractAPI: Type d'API non supporté: {api_type}")
            
            if not endpoint_config: raise Exception(f"Aucun endpoint sain pour AbstractAPI ({api_type}).")
            tool_output = await client.execute_with_config(endpoint_config, input_value=kwargs.get("input_value"), api_type=api_type, agent_id=agent_id)

        elif tool_name == "randommer_phone":
            client = get_client("RANDOMMER")
            endpoint_config = await endpoint_health_manager.get_best_endpoint("RANDOMMER")
            if not endpoint_config: raise Exception("Aucun endpoint sain pour Randommer.")
            tool_output = await client.execute_with_config(endpoint_config, country_code=kwargs.get("country_code"), quantity=kwargs.get("quantity"), agent_id=agent_id)

        elif tool_name == "mockaroo_data":
            client = get_client("MOCKAROO")
            endpoint_config = await endpoint_health_manager.get_best_endpoint("MOCKAROO")
            if not endpoint_config: raise Exception("Aucun endpoint sain pour Mockaroo.")
            tool_output = await client.execute_with_config(endpoint_config, count=kwargs.get("count"), fields_json=kwargs.get("fields_json"), agent_id=agent_id)

        elif tool_name == "rapidapi":
            client = get_client("RAPIDAPI")
            api_name = kwargs.get("api_name")
            api_kwargs = kwargs.get("api_kwargs", {})
            
            if api_name == "Programming Joke":
                endpoint_config = next((ep for ep in client.endpoints if "Programming Joke" in ep.get("endpoint_name", "")), None)
            elif api_name == "Currency List Quotes":
                endpoint_config = next((ep for ep in client.endpoints if "Currency List Quotes" in ep.get("endpoint_name", "")), None)
            elif api_name == "Random Fact":
                endpoint_config = next((ep for ep in client.endpoints if "Random Fact" in ep.get("endpoint_name", "")), None)
            else:
                raise Exception(f"RapidAPI: Nom d'API non supporté: {api_name}")
            
            if not endpoint_config: raise Exception(f"Aucun endpoint sain pour RapidAPI ({api_name}).")
            tool_output = await client.execute_with_config(endpoint_config, api_name=api_name, api_kwargs=api_kwargs, agent_id=agent_id)

        elif tool_name == "fetch_and_archive_pages":
            user_id = context.get("brain_id", "unknown_agent")
            tool_output = await fetch_and_archive_pages(links=kwargs.get("links", []), user_id=user_id)

        elif tool_name == "run_coding_challenge":
            await event_bus.publish("CHALLENGE_REQUESTED", data={"custom_prompt": kwargs.get("custom_prompt")})
            tool_output = {"status": "success", "message": "Défi de codage publié pour l'essaim."}

        # REMPLACEMENT DES SIMULATIONS PAR DE VRAIES ACTIONS
        elif tool_name == "media_control":
            action = kwargs.get('action')
            # pyautogui supporte un sous-ensemble des actions listées
            if action in ["pause", "resume", "playpause"]:
                pyautogui.press("playpause")
                tool_output = {"status": "success", "message": f"Action 'play/pause' exécutée sur le système."}
            elif action == "next":
                pyautogui.press("nexttrack")
                tool_output = {"status": "success", "message": f"Action 'piste suivante' exécutée sur le système."}
            elif action == "previous":
                pyautogui.press("prevtrack")
                tool_output = {"status": "success", "message": f"Action 'piste précédente' exécutée sur le système."}
            else:
                error = f"Action media_control '{action}' non supportée par cette implémentation."
                log_message(error, level="warning")

        elif tool_name == "clock":
            action = kwargs.get('action')
            label = kwargs.get('label', 'Alerte du système IA')
            
            if action in ["create_alarm", "create_timer"]:
                # Utilise les notifications système comme substitut fonctionnel
                time_info = kwargs.get('time', kwargs.get('duration', 'maintenant'))
                notification.notify(
                    title=f"⏰ {label}",
                    message=f"Action '{action}' déclenchée pour {time_info}.",
                    app_name="Système IA Décentralisé",
                    timeout=10
                )
                tool_output = {"status": "success", "message": f"Notification système pour '{action}' envoyée avec succès."}
            else:
                # Les autres actions (snooze, etc.) ne sont pas implémentées mais sont reconnues
                tool_output = {"status": "info", "message": f"Action '{action}' sur l'horloge reconnue mais non implémentée dans cette version."}

        else:
            error = f"Outil inconnu ou non implémenté: {tool_name}"
            log_message(error, level="error")

    except Exception as e:
        error = f"Erreur lors de l'exécution de l'outil '{tool_name}': {format_error(e)}"
        log_message(error, level="critical")
        tool_output = {"error": error}

    return {
        "tool_name": tool_name,
        "tool_output": tool_output if not error else None,
        "error": error
    }

# utils.py
import asyncio
import json
import logging
import os
import re
import base64
import mimetypes
import random
from datetime import datetime, timezone
from pathlib import Path
from typing import Any, Dict, List, Optional, Tuple

# ==== Configuration du logging (autonome pour éviter les imports circulaires) ====
logger = logging.getLogger("bot_logger")
if not logger.handlers:
    logger.setLevel(logging.INFO)
    
    # Assurez-vous que le répertoire de logs existe
    log_dir = Path.cwd() / "logs"
    log_dir.mkdir(parents=True, exist_ok=True)
    
    formatter = logging.Formatter('%(asctime)s - %(levelname)s - %(message)s')
    
    # Handler pour le fichier de log principal
    file_handler = logging.FileHandler(log_dir / "bot_activity.log")
    file_handler.setFormatter(formatter)
    logger.addHandler(file_handler)
    
    # Handler pour les erreurs
    error_handler = logging.FileHandler(log_dir / "error.log")
    error_handler.setLevel(logging.ERROR)
    error_handler.setFormatter(formatter)
    logger.addHandler(error_handler)
    
    # Handler pour la console
    console_handler = logging.StreamHandler()
    console_handler.setFormatter(formatter)
    logger.addHandler(console_handler)

# Verrou global pour les opérations de fichier asynchrones
_file_lock: Optional[asyncio.Lock] = None

def set_file_lock(lock: asyncio.Lock):
    """Définit l'instance du verrou asyncio pour les opérations de fichier."""
    global _file_lock
    _file_lock = lock
    log_message("Verrou de fichier initialisé dans utils.py.")

def log_message(message: str, level: str = "info"):
    """Enregistre un message dans le fichier de log et la console."""
    getattr(logger, level, logger.info)(message)

def get_current_time() -> datetime:
    """Retourne l'heure actuelle en UTC pour une cohérence temporelle."""
    return datetime.now(timezone.utc)

def format_datetime(dt: datetime) -> str:
    """Formate un objet datetime en chaîne de caractères lisible et standardisée."""
    return dt.strftime("%Y-%m-%d %H:%M:%S UTC")

def _load_json_sync(file_path: Path) -> Any:
    """Fonction synchrone pour charger le JSON."""
    with open(file_path, 'r', encoding='utf-8') as f:
        return json.load(f)

def _save_json_sync(file_path: Path, data: Any):
    """Fonction synchrone pour sauvegarder le JSON."""
    with open(file_path, 'w', encoding='utf-8') as f:
        json.dump(data, f, indent=4, ensure_ascii=False)

async def load_json(file_path: Path, default_value: Any = None) -> Any:
    """Charge les données d'un fichier JSON de manière asynchrone et sécurisée."""
    if _file_lock is None:
        raise RuntimeError("Le verrou de fichier n'est pas initialisé. Appelez set_file_lock au démarrage.")

    try:
        if not file_path.exists():
            log_message(f"Fichier non trouvé: {file_path}. Création avec valeur par défaut.", level="warning")
            file_path.parent.mkdir(parents=True, exist_ok=True)
            await save_json(file_path, default_value if default_value is not None else {})
            return default_value if default_value is not None else {}

        async with _file_lock:
            return await asyncio.to_thread(_load_json_sync, file_path)
    except json.JSONDecodeError:
        log_message(f"Erreur de décodage JSON pour {file_path}. Le fichier sera réinitialisé.", level="error")
        await save_json(file_path, default_value if default_value is not None else {})
        return default_value if default_value is not None else {}
    except Exception as e:
        log_message(f"Erreur inattendue lors du chargement de {file_path}: {e}", level="critical")
        return default_value if default_value is not None else {}

async def save_json(file_path: Path, data: Any):
    """Sauvegarde les données dans un fichier JSON de manière asynchrone et sécurisée."""
    if _file_lock is None:
        raise RuntimeError("Le verrou de fichier n'est pas initialisé. Appelez set_file_lock au démarrage.")

    try:
        file_path.parent.mkdir(parents=True, exist_ok=True)
        async with _file_lock:
            await asyncio.to_thread(_save_json_sync, file_path, data)
    except Exception as e:
        log_message(f"Erreur critique lors de la sauvegarde de {file_path}: {e}", level="critical")

def neutralize_urls(text: str) -> str:
    """Remplace les URLs dans le texte par une version neutralisée pour la sécurité."""
    if not isinstance(text, str):
        return ""
    url_pattern = re.compile(r'https?://[^\s/$.?#].[^\s]*', re.IGNORECASE)
    return url_pattern.sub("[LIEN_NEUTRALISÉ]", text)

def extract_code_from_response(response_text: str) -> Optional[str]:
    """Extrait le premier bloc de code Python d'une chaîne de caractères de manière robuste."""
    if not isinstance(response_text, str):
        return None
    
    pattern_python = re.compile(r"```python\n(.*?)\n```", re.DOTALL)
    match = pattern_python.search(response_text)
    if match:
        return match.group(1).strip()
    
    pattern_generic = re.compile(r"```(.*?)```", re.DOTALL)
    match = pattern_generic.search(response_text)
    if match:
        content = match.group(1).strip()
        # Heuristique pour différencier un nom de langage d'un code sans nom
        first_line = content.split('\n', 1)[0].strip()
        if first_line.isalpha() and len(first_line) < 15:
             if len(content.split('\n')) > 1:
                return content.split('\n', 1)[1].strip()
        return content
        
    return None

def format_error(error: Exception) -> str:
    """Formate une erreur de manière visuelle et concise pour les logs."""
    return f"[{type(error).__name__}] {str(error)}"

async def append_to_file(file_path: Path, content: str, max_file_size: int = 10 * 1024 * 1024):
    """
    Ajoute du contenu à un fichier, en créant le fichier/répertoire si nécessaire.
    Gère la rotation du fichier si sa taille dépasse max_file_size.
    """
    if _file_lock is None:
        raise RuntimeError("Le verrou de fichier n'est pas initialisé. Appelez set_file_lock au démarrage.")

    file_path.parent.mkdir(parents=True, exist_ok=True)

    if file_path.exists() and file_path.stat().st_size + len(content.encode('utf-8')) > max_file_size:
        rotate_file(file_path)

    async with _file_lock:
        await asyncio.to_thread(_append_to_file_sync, file_path, content)

def _append_to_file_sync(file_path: Path, content: str):
    """Fonction synchrone pour ajouter du contenu à un fichier, exécutée dans un thread séparé."""
    with open(file_path, 'a', encoding='utf-8') as f:
        f.write(content + "\n")

def rotate_file(file_path: Path):
    """Effectue une rotation de fichier simple: renomme le fichier actuel avec un horodatage."""
    timestamp = datetime.now(timezone.utc).strftime("%Y%m%d_%H%M%S")
    new_path = file_path.parent / f"{file_path.stem}_{timestamp}{file_path.suffix}"
    try:
        os.rename(file_path, new_path)
        log_message(f"Fichier {file_path.name} renommé en {new_path.name} pour rotation.", level="info")
    except OSError as e:
        log_message(f"Erreur lors de la rotation du fichier {file_path.name}: {e}", level="error")

def get_mime_type_from_base64(base64_string: str) -> Optional[str]:
    """Tente de déterminer le type MIME à partir d'une chaîne base64."""
    if base64_string.startswith("data:"):
        parts = base64_string.split(",", 1)
        if len(parts) > 0:
            mime_part = parts[0]
            if ";" in mime_part:
                return mime_part.split(";", 1)[0].split(":", 1)[1]
            else:
                return mime_part.split(":", 1)[1]

    try:
        # Décode seulement les premiers octets pour l'efficacité
        decoded_bytes = base64.b64decode(base64_string[:1024], validate=True)
        
        if decoded_bytes.startswith(b'\x89PNG\r\n\x1a\n'):
            return 'image/png'
        elif decoded_bytes.startswith(b'\xff\xd8\xff'):
            return 'image/jpeg'
        elif decoded_bytes.startswith(b'GIF87a') or decoded_bytes.startswith(b'GIF89a'):
            return 'image/gif'
        elif decoded_bytes.startswith(b'%PDF-'):
            return 'application/pdf'
        elif decoded_bytes.startswith(b'BM'):
            return 'image/bmp'
        elif decoded_bytes.startswith(b'RIFF') and decoded_bytes[8:12] == b'WEBP':
            return 'image/webp'
            
    except Exception as e:
        log_message(f"Erreur lors de la détection MIME pour base64: {e}", level="debug")

    return None

def extract_memories(text: str) -> List[Dict[str, Any]]:
    """
    Extrait les éléments de mémoire d'un texte de réponse.
    Extraction simple basée sur des mots-clés importants.
    """
    memories = []
    
    if "important" in text.lower():
        memories.append({"type": "important", "content": truncate_text(text, 200)})
        
    if "remember" in text.lower() or "rappel" in text.lower():
        memories.append({"type": "reminder", "content": truncate_text(text, 200)})
        
    if "erreur" in text.lower() or "error" in text.lower():
        memories.append({"type": "error", "content": truncate_text(text, 200)})
        
    if "succès" in text.lower() or "success" in text.lower():
        memories.append({"type": "success", "content": truncate_text(text, 200)})
    
    return memories

def validate_url(url: str) -> bool:
    """Valide une URL basique."""
    url_pattern = re.compile(
        r'^https?://'
        r'(?:(?:[A-Z0-9](?:[A-Z0-9-]{0,61}[A-Z0-9])?\.)+[A-Z]{2,6}\.?|'
        r'localhost|'
        r'\d{1,3}\.\d{1,3}\.\d{1,3}\.\d{1,3})'
        r'(?::\d+)?'
        r'(?:/?|[/?]\S+)$', re.IGNORECASE)
    return url_pattern.match(url) is not None

def sanitize_filename(filename: str) -> str:
    """Nettoie un nom de fichier pour le rendre sûr."""
    sanitized = re.sub(r'[<>:"/\\|?*]', '_', filename)
    if len(sanitized) > 100:
        sanitized = sanitized[:100]
    return sanitized.strip()

def format_file_size(size_bytes: int) -> str:
    """Formate une taille de fichier en unités lisibles."""
    if size_bytes == 0:
        return "0 B"
    
    units = ['B', 'KB', 'MB', 'GB', 'TB']
    unit_index = 0
    size = float(size_bytes)
    
    while size >= 1024.0 and unit_index < len(units) - 1:
        size /= 1024.0
        unit_index += 1
    
    return f"{size:.1f} {units[unit_index]}"

def truncate_text(text: str, max_length: int = 200, suffix: str = "...") -> str:
    """Tronque un texte à une longueur maximale."""
    if len(text) <= max_length:
        return text
    return text[:max_length - len(suffix)] + suffix

def parse_duration(duration_str: str) -> int:
    """Parse une durée en format humain vers des secondes."""
    duration_str = duration_str.lower().strip()
    
    patterns = [
        (r'(\d+)\s*s(?:ec)?(?:onds?)?', 1),
        (r'(\d+)\s*m(?:in)?(?:utes?)?', 60),
        (r'(\d+)\s*h(?:ours?)?', 3600),
        (r'(\d+)\s*d(?:ays?)?', 86400),
    ]
    
    total_seconds = 0
    
    for pattern, multiplier in patterns:
        matches = re.findall(pattern, duration_str)
        for match in matches:
            total_seconds += int(match) * multiplier
    
    return total_seconds if total_seconds > 0 else 60

def clean_html(html_content: str) -> str:
    """Nettoie le contenu HTML de base."""
    html_content = re.sub(r'<script[^>]*>.*?</script>', '', html_content, flags=re.DOTALL | re.IGNORECASE)
    html_content = re.sub(r'<style[^>]*>.*?</style>', '', html_content, flags=re.DOTALL | re.IGNORECASE)
    html_content = re.sub(r'<[^>]+>', '', html_content)
    html_content = re.sub(r'\s+', ' ', html_content)
    
    return html_content.strip()

def generate_unique_id(prefix: str = "") -> str:
    """Génère un identifiant unique basé sur le timestamp."""
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S_%f")
    return f"{prefix}_{timestamp}" if prefix else timestamp

def is_safe_path(file_path: Path, base_path: Path) -> bool:
    """Vérifie qu'un chemin de fichier est sûr (pas de directory traversal)."""
    try:
        # `resolve()` normalise le chemin (ex: ../)
        # `relative_to()` lèvera une ValueError si le chemin est en dehors du base_path
        file_path.resolve().relative_to(base_path.resolve())
        return True
    except ValueError:
        return False

def mask_sensitive_data(text: str) -> str:
    """Masque les données sensibles dans un texte."""
    text = re.sub(r'(sk-[a-zA-Z0-9]{20,})', '***MASKED_API_KEY***', text)
    text = re.sub(r'(AIza[a-zA-Z0-9_-]{20,})', '***MASKED_GOOGLE_KEY***', text)
    text = re.sub(r'\b[A-Za-z0-9._%+-]+@[A-Za-z0-9.-]+\.[A-Z|a-z]{2,}\b', '***MASKED_EMAIL***', text)
    text = re.sub(r'\b\d{10,}\b', '***MASKED_PHONE***', text)
    
    return text

class RateLimiter:
    """Limiteur de débit simple pour les opérations."""
    
    def __init__(self, max_requests: int, time_window: int):
        self.max_requests = max_requests
        self.time_window = time_window
        self.requests = []
    
    def is_allowed(self) -> bool:
        """Vérifie si une nouvelle requête est autorisée."""
        now = datetime.now().timestamp()
        
        # Supprime les timestamps qui sont en dehors de la fenêtre de temps
        self.requests = [req_time for req_time in self.requests if now - req_time < self.time_window]
        
        if len(self.requests) < self.max_requests:
            self.requests.append(now)
            return True
        
        return False
    
    def time_until_allowed(self) -> float:
        """Retourne le temps à attendre avant la prochaine requête autorisée."""
        if not self.requests or len(self.requests) < self.max_requests:
            return 0.0
        
        oldest_request = min(self.requests)
        return max(0.0, self.time_window - (datetime.now().timestamp() - oldest_request))

def retry_on_exception(max_retries: int = 3, delay: float = 1.0, backoff_factor: float = 2.0):
    """Décorateur pour réessayer une fonction asynchrone en cas d'exception."""
    def decorator(func):
        async def wrapper(*args, **kwargs):
            last_exception = None
            current_delay = delay
            
            for attempt in range(max_retries + 1):
                try:
                    return await func(*args, **kwargs)
                except Exception as e:
                    last_exception = e
                    if attempt < max_retries:
                        log_message(f"Tentative {attempt + 1}/{max_retries + 1} échouée pour {func.__name__}: {e}", level="warning")
                        await asyncio.sleep(current_delay)
                        current_delay *= backoff_factor
                    else:
                        log_message(f"Toutes les tentatives ({max_retries + 1}) ont échoué pour {func.__name__}: {e}", level="error")
            
            raise last_exception
        return wrapper
    return decorator

COMMON_USER_AGENTS = [
    "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36",
    "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36",
    "Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36"
]

DANGEROUS_EXTENSIONS = [
    '.exe', '.bat', '.cmd', '.com', '.pif', '.scr', '.vbs', '.js', '.jar',
    '.msi', '.dll', '.app', '.deb', '.rpm', '.dmg', '.pkg'
]

ALLOWED_IMAGE_EXTENSIONS = ['.jpg', '.jpeg', '.png', '.gif', '.bmp', '.webp', '.svg']
ALLOWED_DOCUMENT_EXTENSIONS = ['.txt', '.pdf', '.doc', '.docx', '.md', '.json', '.xml', '.csv']

def get_random_user_agent() -> str:
    """Retourne un User-Agent aléatoire."""
    return random.choice(COMMON_USER_AGENTS)

def is_dangerous_file(filename: str) -> bool:
    """Vérifie si un fichier est potentiellement dangereux basé sur son extension."""
    _, ext = os.path.splitext(filename.lower())
    return ext in DANGEROUS_EXTENSIONS

def ensure_directory_exists(directory: Path) -> bool:
    """S'assure qu'un répertoire existe, le crée si nécessaire."""
    try:
        directory.mkdir(parents=True, exist_ok=True)
        return True
    except Exception as e:
        log_message(f"Erreur lors de la création du répertoire {directory}: {e}", level="error")
        return False

def adaptive_temp(prompt: str) -> float:
    """Adapte la "température" de génération de l'IA en fonction du contenu du prompt."""
    technical_keywords = ["optimiser", "algorithme", "complexité", "performance", "debug", "corriger", "syntaxe", "python", "script"]
    if any(kw in prompt.lower() for kw in technical_keywords):
        # Pour les tâches techniques, on veut une réponse précise et déterministe
        return 0.3
    else:
        # Pour les autres tâches, on autorise plus de créativité
        return 0.7






































