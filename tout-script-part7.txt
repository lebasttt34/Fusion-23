
        # Ajouter la requ√™te utilisateur √† l'historique
        user_parts = [{"text": user_input}]
        if image_data:
            # Si l'image est incluse, elle sera ajout√©e par generate_content
            pass
        chat_history.append({"role": "user", "parts": user_parts})

        response, chat_history = await process_user_query(user_input, chat_history, image_data)
        print(f"Bot: {response}")

        # Sauvegarder l'historique apr√®s chaque tour
        try:
            # Nettoyer l'historique pour la sauvegarde:
            # - Enlever les donn√©es d'image base64 (trop volumineux, non n√©cessaire pour la persistance)
            # - S'assurer que les objets functionCall/functionResponse sont bien format√©s
            history_to_save = []
            for entry in chat_history:
                new_entry = entry.copy()
                if "parts" in new_entry:
                    new_parts = []
                    for part in new_entry["parts"]:
                        if "inlineData" in part:
                            # Ne pas sauvegarder les donn√©es d'image brutes
                            new_part = part.copy()
                            new_part["inlineData"] = {"mimeType": part["inlineData"]["mimeType"], "data": "[IMAGE_DATA_REMOVED_FOR_SAVE]"}
                            new_parts.append(new_part)
                        else:
                            new_parts.append(part)
                    new_entry["parts"] = new_parts
                history_to_save.append(new_entry)
            
            with open("chat_history.json", "w", encoding="utf-8") as f:
                json.dump(history_to_save, f, indent=2, ensure_ascii=False)
            log_message("Historique du chat sauvegard√©.")
        except Exception as e:
            log_message(f"Erreur lors de la sauvegarde de l'historique du chat: {e}", level="error")

if __name__ == "__main__":
    import traceback
    try:
        asyncio.run(main())
    except KeyboardInterrupt:
        log_message("Chatbot arr√™t√© par l'utilisateur.")
    except Exception as e:
        log_message(f"Une erreur inattendue est survenue: {e}", level="critical")
        log_message(f"Traceback: {traceback.format_exc()}", level="critical")








# -*- coding: utf-8 -*-
# Type: OPTIMISATION

# ----------------------------
# IA/DEV TOOLS (pyflakes, black, ast, etc.)
# ----------------------------

import os
import io
import contextlib
import subprocess
import asyncio
import time
import random
import json
import base64
import httpx
import ast
import difflib
import concurrent.futures
from concurrent.futures import ThreadPoolExecutor
from datetime import datetime
from functools import lru_cache
import re
import hashlib
from urllib.parse import urlparse

# Assuming these are available in the environment or defined elsewhere
# from pyflakes.api import check, Reporter
# import black
# import pytesseract
# from PIL import Image
# from your_config_module import config, PRIVATE_GROUP_ID, DAILY_CHALLENGE_PATH, API_CONFIG
# from your_orchestrator_module import orchestrator, quota_manager, endpoint_health_manager
# from your_memory_module import memory_manager
# from your_bot_types import ContextTypes
# from your_cig_module import CIG # Assuming CIG is a function for AI calls

# Global variable for verbose mode
VERBOSE = os.getenv("VERBOSE_MODE", "false").lower() == "true"

def syntax_highlight(code: str) -> str:
    """
    Met en √©vidence la syntaxe du code Python pour l'affichage dans un terminal,
    si pygments est disponible et si la sortie est un TTY.
    """
    from sys import stdout
    if stdout.isatty():  # Uniquement dans un terminal
        try:
            from pygments import highlight
            from pygments.lexers import PythonLexer
            from pygments.formatters import TerminalFormatter
            return highlight(code, PythonLexer(), TerminalFormatter(bg="dark"))
        except ImportError:
            # Fallback if pygments is not installed
            if VERBOSE:
                print("[DEBUG] Pygments non trouv√©, retour du code brut pour la coloration syntaxique.")
            pass
    return code  # Retour brut si couleurs non disponibles ou non TTY

def check_code(code: str) -> str:
    """
    V√©rifie le code Python pour les erreurs de style et les probl√®mes potentiels
    en utilisant pyflakes (simulation si non disponible).
    """
    try:
        # Assuming Reporter and check are imported from pyflakes.api
        from pyflakes.api import check, Reporter
        out = io.StringIO()
        reporter = Reporter(out, out)
        check(code, filename="<string>", reporter=reporter)
        return out.getvalue()
    except ImportError:
        if VERBOSE:
            print("[DEBUG] Pyflakes non trouv√©, simulation de la v√©rification de code.")
        # Simple simulation if pyflakes is not available
        warnings = []
        if "import os" in code and ("os.remove" in code or "os.system" in code):
            warnings.append("AVERTISSEMENT: Utilisation potentielle de fonctions 'os' dangereuses d√©tect√©e.")
        if "while True" in code and "sleep" not in code:
            warnings.append("AVERTISSEMENT: Boucle infinie potentielle d√©tect√©e sans pause.")
        return "\n".join(warnings) if warnings else "Aucun probl√®me majeur d√©tect√© (simulation)."


def format_code(code: str, max_length: int = 1000) -> str:
    """
    Formate le code Python en utilisant Black et tronque la sortie si elle est trop longue.
    """
    try:
        # Assuming black is imported
        import black
        formatted = black.format_str(code, mode=black.Mode())
        if len(formatted) > max_length:
            return (
                f"‚ö†Ô∏è Code format√© (tronqu√© √† {max_length} caract√®res)\n"
                "‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\n"
                f"{formatted[:max_length//2]}\n...\n{formatted[-max_length//2:]}\n"
                "‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ"
            )
        return formatted
    except ImportError:
        if VERBOSE:
            print("[DEBUG] Black non trouv√©, retour du code brut pour le formatage.")
        return code # Return original code if black is not installed
    except Exception as e:
        return f"‚ùå Format error: {e}"

def extract_functions(code: str):
    """
    Extrait les noms des fonctions d√©finies dans le code Python.
    """
    try:
        tree = ast.parse(code)
        return [node.name for node in ast.walk(tree) if isinstance(node, ast.FunctionDef)]
    except Exception as e:
        return f"‚ùå AST error: {e}"

@lru_cache(maxsize=100)
def analyze_code_structure(code: str):
    """
    Analyse la structure AST du code Python et retourne une repr√©sentation indent√©e.
    Utilise un cache LRU pour les analyses r√©p√©t√©es.
    """
    try:
        tree = ast.parse(code)
        return ast.dump(tree, indent=2)  # Indentation ajout√©e
    except Exception as e:
        return f"‚ùå Erreur d'analyse AST: {e}"

def read_image_text(image_path: str) -> str:
    """
    Extrait le texte d'une image en utilisant Tesseract OCR.
    """
    try:
        # Assuming pytesseract and Image are imported
        import pytesseract
        from PIL import Image
        return pytesseract.image_to_string(Image.open(image_path))
    except ImportError:
        return "‚ùå OCR error: pytesseract ou Pillow non install√©s."
    except Exception as e:
        return f"‚ùå OCR error: {e}"

def run_python(code_str: str):
    """
    Ex√©cute une cha√Æne de code Python dans l'environnement actuel.
    """
    try:
        exec_globals = {}
        exec(code_str, exec_globals)
        return exec_globals
    except Exception as e:
        return f"‚ùå Python error: {e}"

def run_shell(cmd: str) -> str:
    """
    Ex√©cute une commande shell et retourne sa sortie.
    """
    try:
        result = subprocess.check_output(cmd, shell=True, stderr=subprocess.STDOUT)
        return result.decode()
    except subprocess.CalledProcessError as e:
        return f"‚ùå Shell error: {e.output.decode()}"

# Pour les ex√©cutions en sandbox
executor = ThreadPoolExecutor(max_workers=1)

async def run_in_sandbox(code: str, language: str = "python") -> str:
    """
    Ex√©cute du code Python ou Shell dans une sandbox s√©curis√©e avec mesure du temps.
    """
    start_time = time.perf_counter()
    
    # Assuming filter_bad_code is defined elsewhere
    # if filter_bad_code(code):
    #     return "‚ùå S√©curit√©: Le code contient des motifs potentiellement dangereux et n'a pas √©t√© ex√©cut√©."
    
    # Placeholder for filter_bad_code if not defined
    if "import os" in code and ("os.remove" in code or "os.system" in code):
        return "‚ùå S√©curit√©: Le code contient des motifs potentiellement dangereux (os.remove/os.system) et n'a pas √©t√© ex√©cut√©."


    loop = asyncio.get_running_loop()
    if language == "python":
        result = await loop.run_in_executor(executor, _run_python_sync, code)
    elif language == "shell":
        result = await loop.run_in_executor(executor, _run_shell_sync, code)
    else:
        result = "‚ùå Langage non support√© pour la sandbox."
    
    elapsed = time.perf_counter() - start_time
    if "‚ùå" in result:
        return f"{result}\n‚è±Ô∏è Temps avant erreur: {elapsed:.2f}s"
    return f"{result}\n‚åõ Ex√©cut√© en: {elapsed:.2f}s"

def _run_python_sync(code: str) -> str:
    """
    Ex√©cute le code Python de mani√®re synchrone dans un environnement restreint.
    Capture la sortie standard et les erreurs.
    """
    old_stdout = io.StringIO()
    old_stderr = io.StringIO()
    with contextlib.redirect_stdout(old_stdout), contextlib.redirect_stderr(old_stderr):
        try:
            # Restrict builtins for security
            exec(code, {'__builtins__': {}})
            output = old_stdout.getvalue()
            error = old_stderr.getvalue()
            if error:
                return f"üêç Sortie partielle:\n{output}\n\nüî¥ Erreurs:\n{error}"
            return f"‚úÖ Sortie:\n{output}"
        except Exception as e:
            return (
                "‚ùå ERREUR D'EX√âCUTION\n"
                f"Type: {type(e).__name__}\n"
                f"D√©tails: {str(e)}\n\n"
                "--- Sortie standard ---\n"
                f"{old_stdout.getvalue()}\n\n"
                "--- Logs d'erreur ---\n"
                f"{old_stderr.getvalue()}"
            )

def _run_shell_sync(command: str) -> str:
    """
    Ex√©cute une commande shell de mani√®re synchrone et s√©curis√©e.
    """
    try:
        result = subprocess.run(
            command,
            shell=True,
            capture_output=True,
            text=True,
            check=True,
            timeout=10
        )
        output = result.stdout
        error = result.stderr
        if error:
            return f"üêö Erreur Shell:\n{error}\nSortie:\n{output}"
        return f"‚úÖ Sortie Shell:\n{output}"
    except subprocess.CalledProcessError as e:
        return f"‚ùå Erreur d'ex√©cution Shell (Code: {e.returncode}):\n{e.stderr}\nSortie:\n{e.stdout}"
    except subprocess.TimeoutExpired:
        return "‚ùå Erreur Shell: La commande a d√©pass√© le temps d'ex√©cution imparti."
    except Exception as e:
        return f"‚ùå Erreur inattendue lors de l'ex√©cution Shell: {e}"

async def analyze_python_code(code: str) -> str:
    """
    Analyse le code Python pour la syntaxe, la compilation et les probl√®mes potentiels
    (comme l'utilisation de os.remove).
    """
    try:
        ast.parse(code)
    except SyntaxError as e:
        return f"‚ùå Erreur de syntaxe Python: {e}"

    # Ajout pour attraper les erreurs de compilation (ex: variables non d√©finies)
    try:
        compile(code, '<string>', 'exec')
    except Exception as e:
        return f"‚ùå Erreur de compilation Python: {e}\nCode analys√©:\n{code[:500]}"

    formatted_code = code # Assuming format_code would be called here if needed
    pyflakes_output = []
    if "import os" in code and "os.remove" in code:
        pyflakes_output.append("AVERTISSEMENT: Utilisation potentielle de os.remove d√©tect√©e.")

    if pyflakes_output:
        return f"Code format√© (Black):\n```python\n{formatted_code}\n```\n\nAnalyses Pyflakes (simul√©):\n" + "\n".join(pyflakes_output)
    return f"Code format√© (Black):\n```python\n{formatted_code}\n```\n\nAnalyse Pyflakes: Aucun probl√®me majeur d√©tect√© (simulation)."

# --- OCR Tool ---
async def perform_ocr(image_url: str, api_key: str, endpoint: str) -> str:
    """
    Effectue une reconnaissance optique de caract√®res (OCR) sur une image via une API externe.
    """
    try:
        async with httpx.AsyncClient(timeout=10) as client:
            img_response = await client.get(image_url)
            img_response.raise_for_status()

        img_data = base64.b64encode(img_response.content).decode('utf-8')
        headers = {"Content-Type": "application/json", "Apikey": api_key}
        payload = {"base64_image": img_data}

        ocr_endpoint = f"{endpoint}/image/recognize/extractText" if "cloudmersive" in endpoint.lower() else endpoint

        async with httpx.AsyncClient(timeout=30) as client:
            response = await client.post(ocr_endpoint, json=payload, headers=headers)
            response.raise_for_status()
            result = response.json()

        if "TextExtracted" in result:
            return f"‚úÖ Texte extrait par OCR:\n{result['TextExtracted']}"
        elif "extractedText" in result:
            return f"‚úÖ Texte extrait par OCR:\n{result['extractedText']}"
        else:
            return f"‚ùå OCR: Format de r√©ponse API inconnu. R√©ponse brute: {result}"

    except httpx.HTTPStatusError as e:
        # Assuming log_message is defined elsewhere
        # log_message(f"Erreur HTTP/r√©seau lors de l'OCR: {e.response.status_code} - {e.response.text}", level="error")
        if VERBOSE:
            print(f"[ERROR] Erreur HTTP/r√©seau lors de l'OCR: {e.response.status_code} - {e.response.text}")
        return f"‚ùå Erreur lors de l'OCR (r√©seau/API): {e}"
    except httpx.RequestError as e:
        # log_message(f"Erreur de requ√™te lors de l'OCR: {e}", level="error")
        if VERBOSE:
            print(f"[ERROR] Erreur de requ√™te lors de l'OCR: {e}")
        return f"‚ùå Erreur lors de l'OCR (requ√™te): {e}"
    except json.JSONDecodeError:
        return "‚ùå OCR: R√©ponse non JSON de l'API."
    except Exception as e:
        # log_message(f"Erreur inattendue lors de l'OCR: {e}", level="error")
        if VERBOSE:
            print(f"[ERROR] Erreur inattendue lors de l'OCR: {e}")
        return f"‚ùå Erreur inattendue lors de l'OCR: {e}"


CODING_CHALLENGE_PROMPT = """
En tant qu'IA de d√©veloppement de 2025, ton r√¥le est d'am√©liorer et de tester des morceaux de code Python/Shell.
Tu as acc√®s √† une sandbox s√©curis√©e pour ex√©cuter le code.
Tes r√©ponses doivent inclure le code corrig√© ou am√©lior√©, et les r√©sultats de l'ex√©cution en sandbox.
Apporte des am√©liorations significatives, ne te contente pas de corrections triviales si la question implique un projet plus large.
Pense √† l'efficacit√© du code et √† l'optimisation des ressources.
Chaque version doit √™tre une am√©lioration nette de la pr√©c√©dente, in√©dite.
Commence par un commentaire indiquant ce qui a √©t√© am√©lior√©.
Le code doit √™tre direct, lisible, et pr√™t √† √™tre utilis√©.
"""

# -------------------------------------------------------------------------
# CODING CHALLENGE TOUTES IA EN PARALL√àLE
# -------------------------------------------------------------------------
CODING_CHALLENGE_ENABLED = True
# Assuming DAILY_CHALLENGE_PATH is a Path object from pathlib
# LAST_CHALLENGE_FILE = DAILY_CHALLENGE_PATH / "last_challenge.py"
# HISTORY_DIR = DAILY_CHALLENGE_PATH / "history"
# HISTORY_DIR.mkdir(exist_ok=True)

# Placeholder for DAILY_CHALLENGE_PATH and HISTORY_DIR if not defined
class PathPlaceholder:
    def __init__(self, path_str):
        self.path_str = path_str
    def __truediv__(self, other):
        return PathPlaceholder(f"{self.path_str}/{other}")
    def write_text(self, content, encoding):
        if VERBOSE:
            print(f"[DEBUG] Simulating write to {self.path_str}: {content[:100]}...")
    def mkdir(self, exist_ok=True):
        if VERBOSE:
            print(f"[DEBUG] Simulating mkdir {self.path_str}, exist_ok={exist_ok}")
    def __str__(self,):
        return self.path_str

DAILY_CHALLENGE_PATH = PathPlaceholder("daily_challenges")
HISTORY_DIR = DAILY_CHALLENGE_PATH / "history"
HISTORY_DIR.mkdir(exist_ok=True)


def diff_text(old_text, new_text):
    """
    G√©n√®re un diff unifi√© entre deux cha√Ænes de texte.
    """
    diff = difflib.unified_diff(
        old_text.splitlines(), new_text.splitlines(), lineterm=""
    )
    return "\n".join(diff)

async def coding_challenge_loop():
    """
    Boucle principale pour l'ex√©cution p√©riodique des d√©fis de codage par les IA.
    """
    while True:
        if not CODING_CHALLENGE_ENABLED:
            await asyncio.sleep(900)
            continue

        challenge_types = [
            "ALGORITHME", "OPTIMISATION", 
            "DEBUG", "IA CREATIVE", "SCRIPT UTILE"
        ]
        challenge_type = random.choice(challenge_types)
        
        prompt = f"""
[ D√âFI {challenge_type} - {datetime.now().strftime('%Y-%m-%d')} ]
Tu es une IA experte en programmation Python. G√©n√®re un script clair, correct et optimis√©, 100% en fran√ßais.
Ne dis pas que tu ne sais pas, ne t'excuse pas, ne formule pas de r√©ponses vagues.
Chaque version doit √™tre une am√©lioration nette de la pr√©c√©dente.
Commence par un commentaire indiquant ce qui a √©t√© am√©lior√©.
Le code doit √™tre direct, lisible, et pr√™t √† √™tre utilis√©.
"""

        # Version universelle pour toutes les configurations d'API
        ia_list = []
        
        # Placeholder for config object
        class ConfigPlaceholder:
            # Removed OpenRouter configuration as per user request
            TAVILY_KEYS = [TAVILY_KEY_1, TAVILY_KEY_2, TAVILY_KEY_3, TAVILY_KEY_4]
            SERPER_KEY = SERPER_KEY
            HUGGINGFACE_KEYS = [HUGGINGFACE_KEY_1, HUGGINGFACE_KEY_2, HUGGINGFACE_KEY_3, HUGGINGFACE_NEW_KEY]
            WOLFRAM_APP_IDS = [WOLFRAM_APP_ID_1, WOLFRAM_APP_ID_2, WOLFRAM_APP_ID_3]
            GOOGLE_API_KEY = GOOGLE_API_KEYS[0] # Using the first Google API key for general Google calls if needed
            GOOGLE_CX_LIST = GOOGLE_CX_LIST
            GEMINI_API_KEY = GEMINI_API_KEY # Added for Gemini
            DEEPSEEK_KEYS = [DEEPSEEK_KEY_1, DEEPSEEK_KEY_2] # Added for Deepseek
            PRIVATE_GROUP_ID = PRIVATE_GROUP_ID # Use the actual private group ID
            bot_instance = None # Placeholder for a bot instance

        config = ConfigPlaceholder()

        # Configuration Deepseek
        if hasattr(config, 'DEEPSEEK_KEYS'):
            ia_list.extend([(f"Deepseek-{i+1}", k) for i, k in enumerate(config.DEEPSEEK_KEYS)])

        # Configuration Tavily
        if hasattr(config, 'TAVILY_KEYS'):
            ia_list.extend([(f"Tavily-{i+1}", k) for i, k in enumerate(config.TAVILY_KEYS)])
        
        # Configuration Serper
        if hasattr(config, 'SERPER_KEY'):
            ia_list.append(("Serper", config.SERPER_KEY))
        
        # Configuration HuggingFace
        if hasattr(config, 'HUGGINGFACE_KEYS'):
            ia_list.extend([(f"HuggingFace-{i+1}", k) for i, k in enumerate(config.HUGGINGFACE_KEYS)])
        
        # Configuration Wolfram
        if hasattr(config, 'WOLFRAM_APP_IDS'):
            ia_list.extend([(f"Wolfram-{i+1}", k) for i, k in enumerate(config.WOLFRAM_APP_IDS)])
        
        # Configuration Google (Custom Search)
        if hasattr(config, 'GOOGLE_API_KEY') and hasattr(config, 'GOOGLE_CX_LIST'):
            for i, cx in enumerate(config.GOOGLE_CX_LIST):
                ia_list.append((f"GoogleCX-{i+1}", config.GOOGLE_API_KEY))

        # Configuration Gemini
        if hasattr(config, 'GEMINI_API_KEY'):
            ia_list.append(("Gemini", config.GEMINI_API_KEY))

        async def call_ia(nom, cle):
            """
            Appelle une IA sp√©cifique pour g√©n√©rer du code et le sauvegarde.
            """
            try:
                # Assuming CIG is defined elsewhere for AI calls
                # r = await CIG(prompt, api_key=cle, model_name=nom)
                r = f"# Code g√©n√©r√© par {nom} pour le d√©fi {challenge_type}\nprint('Hello from {nom}')" # Dummy response for testing
                
                if r and len(r.strip()) > 20:
                    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
                    fpath = DAILY_CHALLENGE_PATH / f"challenge_{nom}_{timestamp}.py"
                    header = (
                        f"# -*- coding: utf-8 -*-\n"
                        f"# Challenge g√©n√©r√© par {nom}\n"
                        f"# Date: {timestamp}\n"
                        f"# Type: {challenge_type}\n\n"
                    )
                    with open(str(fpath), "w", encoding="utf-8") as f: # Use str(fpath) for PathPlaceholder compatibility
                        f.write(header + r.strip())
                    
                    if hasattr(config, 'PRIVATE_GROUP_ID') and hasattr(config, 'bot_instance') and config.PRIVATE_GROUP_ID and config.bot_instance:
                        await config.bot_instance.send_message(
                            chat_id=config.PRIVATE_GROUP_ID,
                            text=f"üíª <b>Code g√©n√©r√© par {nom}</b> :\n<pre>{r[:600]}</pre>",
                            parse_mode="HTML"
                        )
                    return r
                else:
                    if hasattr(config, 'PRIVATE_GROUP_ID') and hasattr(config, 'bot_instance') and config.PRIVATE_GROUP_ID and config.bot_instance:
                        await config.bot_instance.send_message(
                            chat_id=config.PRIVATE_GROUP_ID,
                            text=f"‚ö†Ô∏è <b>{nom}</b> n'a pas g√©n√©r√© de code valable cette fois.",
                            parse_mode="HTML"
                        )
                    return None
            except Exception as e:
                if hasattr(config, 'PRIVATE_GROUP_ID') and hasattr(config, 'bot_instance') and config.PRIVATE_GROUP_ID and config.bot_instance:
                    await config.bot_instance.send_message(
                        chat_id=config.PRIVATE_GROUP_ID,
                        text=f"‚ùå <b>{nom}</b> erreur lors de l'appel IA : {e}",
                        parse_mode="HTML"
                    )
                return None

        results = await asyncio.gather(*[call_ia(n, k) for n, k in ia_list])
        await asyncio.sleep(900)

async def start_background_tasks(app):
    """
    D√©marre les t√¢ches de fond pour le d√©fi de codage.
    """
    asyncio.create_task(coding_challenge_loop())
    

async def coding_challenge_periodic(context): # ContextTypes.DEFAULT_TYPE
    """
    T√¢che p√©riodique pour lancer les d√©fis de codage et g√©rer les r√©ponses des IA.
    """
    # Assuming log_message is defined elsewhere
    # log_message("Lancement de la t√¢che de d√©fi de codage...")
    if VERBOSE:
        print("[DEBUG] Lancement de la t√¢che de d√©fi de codage...")
    
    # Placeholder for memory_manager, orchestrator, quota_manager, PRIVATE_GROUP_ID
    class DummyMemoryManager:
        async def get_group_memory(self, group_id, limit): return "Dummy memory data."
        def update_ia_status(self, ia_name, status, error=None): pass
        async def save_group_memory(self, group_id, role, content): pass
    
    class DummyOrchestrator:
        def __init__(self):
            self.api_clients = {"DEEPSEEK": self, "HUGGINGFACE": self, "GEMINI_API": self}
        async def query(self, prompt): return f"# Dummy code from {self.name}\nprint('Hello from {self.name}')"
        def get(self, name):
            self.name = name
            return self

    class DummyQuotaManager:
        async def check_and_update_quota(self, ia_name): return True

    memory_manager = DummyMemoryManager()
    orchestrator = DummyOrchestrator()
    quota_manager = DummyQuotaManager()
    PRIVATE_GROUP_ID = PRIVATE_GROUP_ID # Use the actual private group ID

    group_mem = await memory_manager.get_group_memory(PRIVATE_GROUP_ID, limit=50)
    full_prompt = f"{CODING_CHALLENGE_PROMPT}\n\nM√©moire r√©cente du groupe:\n{group_mem}\n\nD√©fi du jour:"
    
    relevant_ias = ["DEEPSEEK", "HUGGINGFACE", "GEMINI_API"]
    results = []
    
    for ia_name in relevant_ias:
        ia_client = orchestrator.api_clients.get(ia_name)
        if ia_client and await quota_manager.check_and_update_quota(ia_name):
            try:
                if VERBOSE:
                    print(f"[DEBUG] IA {ia_name} tente de r√©soudre le d√©fi...")
                # log_message(f"IA {ia_name} tente de r√©soudre le d√©fi...")
                resp = await ia_client.query(full_prompt)
                results.append((ia_name, resp))
                memory_manager.update_ia_status(ia_name, True)
            except Exception as e:
                # log_message(f"Erreur avec {ia_name}: {e}", level="error")
                if VERBOSE:
                    print(f"[ERROR] Erreur avec {ia_name}: {e}")
                memory_manager.update_ia_status(ia_name, False, str(e))
            await asyncio.sleep(0.5)

    if results:
        for name, resp in results:
            code_content = resp
            if resp.startswith("```python") and resp.endswith("```"):
                code_content = resp[9:-3].strip()
            
            fname = f"challenge_{name}_{datetime.now().strftime('%Y%m%d_%H%M%S')}.py"
            fpath = DAILY_CHALLENGE_PATH / fname
            header = (
                f"# -*- coding: utf-8 -*-\n"
                f"# Challenge g√©n√©r√© par {name}\n"
                f"# Date: {datetime.now().strftime('%Y%m%d_%H%M%S')}\n"
                f"# Type: CODING_CHALLENGE\n\n"
            )
            try:
                with open(str(fpath), "w", encoding="utf-8") as f: # Use str(fpath) for PathPlaceholder compatibility
                    f.write(header + code_content)
                # log_message(f"D√©fi sauvegard√©: {fpath}")
                if VERBOSE:
                    print(f"[DEBUG] D√©fi sauvegard√©: {fpath}")
            except Exception as e:
                # log_message(f"Erreur sauvegarde {fname}: {e}", level="error")
                if VERBOSE:
                    print(f"[ERROR] Erreur sauvegarde {fname}: {e}")

            # Assuming context.bot.send_message is available
            if PRIVATE_GROUP_ID and hasattr(context, 'bot') and hasattr(context.bot, 'send_message'):
                display_code = code_content[:1500] + "..." if len(code_content) > 1500 else code_content
                await context.bot.send_message(
                    chat_id=PRIVATE_GROUP_ID,
                    text=f"üíª <b>D√©fi {name}</b> :\n<pre>{display_code}</pre>",
                    parse_mode="HTML"
                )
            
            await memory_manager.save_group_memory(
                PRIVATE_GROUP_ID, 
                "bot", 
                f"D√©fi codage {name} : {code_content[:100]}"
            )
    else:
        # log_message("Aucune IA n'a g√©n√©r√© de code valide", level="warning")
        if VERBOSE:
            print("[DEBUG] Aucune IA n'a g√©n√©r√© de code valide")
        if PRIVATE_GROUP_ID and hasattr(context, 'bot') and hasattr(context.bot, 'send_message'):
            await context.bot.send_message(
                chat_id=PRIVATE_GROUP_ID,
                text="üòî Aucune IA n'a pu g√©n√©rer de code pour le d√©fi cette fois-ci."
            )

async def periodic_health_check(context): # ContextTypes.DEFAULT_TYPE
    """
    Effectue des v√©rifications de sant√© p√©riodiques pour les services API.
    """
    # log_message("Lancement des health checks p√©riodiques...")
    if VERBOSE:
        print("[DEBUG] Lancement des health checks p√©riodiques...")
    
    # Placeholder for API_CONFIG and endpoint_health_manager
    class DummyEndpointHealthManager:
        async def run_health_check_for_service(self, service_name):
            if VERBOSE:
                print(f"[DEBUG] Simulating health check for {service_name}")

    API_CONFIG = {"SERVICE_A": {}, "SERVICE_B": {}}
    endpoint_health_manager = DummyEndpointHealthManager()

    for service_name in API_CONFIG.keys():
        await endpoint_health_manager.run_health_check_for_service(service_name)
    # log_message("Health checks termin√©s.")
    if VERBOSE:
        print("[DEBUG] Health checks termin√©s.")

async def send_structured_report(context, report_data: dict): # ContextTypes.DEFAULT_TYPE
    """
    Envoie un rapport structur√© d'action de l'IA √† un groupe priv√©.
    """
    try:
        report_text = f"üìä **Rapport d'Action IA**\n\n"
        report_text += f"**Timestamp**: `{report_data.get('timestamp')}`\n"
        report_text += f"**Agent**: `{report_data.get('agent_name')}`\n"
        report_text += f"**Intention**: `{report_data.get('intention')}`\n"
        report_text += f"**Requ√™te**: `{report_data.get('user_query')}`\n"
        
        primary_ai = report_data.get('primary_ai_used', 'N/A')
        if isinstance(primary_ai, dict) and 'name' in primary_ai:
            primary_ai = primary_ai['name']
        report_text += f"**IA Primaire**: `{primary_ai}`\n"
        
        tools = report_data.get('tools_called', [])
        if tools:
            report_text += "**Outils Appel√©s**:\n"
            for tool in tools:
                tool_result = str(tool['result'])
                if len(tool_result) > 100:
                    tool_result = tool_result[:100] + "..."
                escaped_params = json.dumps(tool['params'], indent=2)
                escaped_params = escaped_params.replace('_', '\\_').replace('*', '\\*').replace('`', '\\`')
                report_text += f"- `{tool['name']}` (Params: ```json\n{escaped_params}\n```, R√©sultat: `{tool_result}`)\n"
        else:
            report_text += "**Outils Appel√©s**: Aucun\n"
        
        final_resp = report_data.get('final_response', '')
        if len(final_resp) > 500:
            final_resp = final_resp[:500] + "..."
        final_resp = final_resp.replace('_', '\\_').replace('*', '\\*').replace('`', '\\`')
        report_text += f"**R√©ponse Finale**: `{final_resp}`\n"
        report_text += f"**Dur√©e**: `{report_data.get('duration', 0):.2f}s`\n"
        report_text += f"**Erreur**: `{report_data.get('error', 'Non')}`\n"

        if PRIVATE_GROUP_ID and hasattr(context, 'bot') and hasattr(context.bot, 'send_message'):
            await context.bot.send_message(
                chat_id=PRIVATE_GROUP_ID, 
                text=report_text, 
                parse_mode='MarkdownV2'
            )
    except Exception as e:
        # log_message(f"Erreur envoi rapport: {e}", level="error")
        if VERBOSE:
            print(f"[ERROR] Erreur envoi rapport: {e}")

def show_help():
    """
    Affiche un menu d'aide avec les commandes disponibles.
    """
    print("""
üìã AIDE :
- /run [code] : Ex√©cute du Python
- /format [code] : Formate du code
- /demo : Mode d√©mo
- /help : Affiche ce menu
""")

def show_version():
    """
    Affiche la version actuelle du bot et la date de derni√®re mise √† jour.
    """
    VERSION = "1.1.0"
    LAST_UPDATE = "2023-11-20"
    print(f"ü§ñ Bot Version {VERSION} | {LAST_UPDATE}")

def fix_common_errors(code: str) -> str:
    """
    Applique des corrections automatiques basiques au code.
    """
    fixes = {
        "print(": "print(",  # Example: corrects unclosed quotes (if any)
        "def  ": "def ",     # Extra spaces
        "= =": "=="          # Misspelled operator
    }
    for error, fix in fixes.items():
        code = code.replace(error, fix)
    return code

def format_error(e) -> str:
    """
    Formate une exception en un message d'erreur clair et visuel.
    """
    return f"""
‚ö†Ô∏è‚ö†Ô∏è‚ö†Ô∏è ERREUR ‚ö†Ô∏è‚ö†Ô∏è‚ö†Ô∏è
Type : {type(e).__name__}
Message : {str(e)}
‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî
"""

blagues = [
    "Pourquoi les devs pr√©f√®rent le noir ? Parce que la lumi√®re attire les bugs üêõ",
    "Comment un dev nettoie-t-il sa maison ? Il fait rm -rf / üò±",
    "2 devs se rencontrent. Le premier dit '√áa va ?'. Le second r√©pond '404' üòê"
]

def check_inactivity(last_activity: float):
    """
    V√©rifie l'inactivit√© du bot et affiche une blague si le seuil est d√©pass√©.
    """
    if time.time() - last_activity > 300:  # 5 min
        print("üí§ Je m'ennuie... Tiens, une blague :")
        print(random.choice(blagues))
        return True # Indicate that a joke was told
    return False

def warmup_ai(model, iterations: int = 3):
    """
    Pr√©chauffe un mod√®le d'IA avec des requ√™tes factices pour r√©duire la latence initiale.
    """
    dummy_prompts = ["print('hello')", "def test(): pass", "1+1"]
    for _ in range(iterations):
        for prompt in dummy_prompts:
            # Assuming model has a .generate method
            if hasattr(model, 'generate'):
                model.generate(prompt)
            else:
                if VERBOSE:
                    print(f"[DEBUG] Mod√®le {model} n'a pas de m√©thode 'generate' pour le pr√©chauffage.")


@lru_cache(maxsize=100)
def generate_code_cached(prompt: str, temperature: float = 0.7) -> str:
    """
    G√©n√®re du code en utilisant un mod√®le d'IA avec un cache pour les prompts r√©p√©t√©s.
    """
    # Assuming ai_model is defined globally or passed
    # return ai_model.generate(prompt, temperature=temperature)
    return f"# Cached code for: {prompt[:50]}" # Dummy return

def batch_generate(prompts: list[str], max_workers: int = 4) -> list[str]:
    """
    G√©n√®re du code pour plusieurs prompts en parall√®le en utilisant un pool de threads.
    """
    # Assuming ai_model is defined globally or passed
    # This would require ai_model to be thread-safe or a new instance per thread
    def _generate_single(p):
        # return ai_model.generate(p)
        return f"# Batch generated code for: {p[:50]}" # Dummy return

    with concurrent.futures.ThreadPoolExecutor(max_workers=max_workers) as executor:
        return list(executor.map(_generate_single, prompts))

def adaptive_temp(prompt: str) -> float:
    """
    Adapte la temp√©rature de g√©n√©ration de l'IA en fonction du contenu du prompt.
    R√©duit la temp√©rature pour les prompts techniques.
    """
    technical_keywords = ["optimiser", "algorithme", "complexit√©", "performance", "debug"]
    return 0.3 if any(kw in prompt.lower() for kw in technical_keywords) else 0.7

# Example of how to call show_version and show_help if this were a main script
if __name__ == "__main__":
    show_version()
    show_help()
    # Example of using verbose mode
    # os.environ["VERBOSE_MODE"] = "true"
    # VERBOSE = os.getenv("VERBOSE_MODE", "false").lower() == "true"
    # print(f"Verbose mode is {'ON' if VERBOSE else 'OFF'}")

    # Example of a dummy context for periodic tasks
    class DummyBot:
        async def send_message(self, chat_id, text, parse_mode):
            print(f"\n--- BOT MESSAGE to {chat_id} ({parse_mode}) ---\n{text}\n--------------------")

    class DummyContext:
        def __init__(self):
            self.bot = DummyBot()

    # To run async functions for demonstration
    async def main_demo():
        print("\n--- Running a dummy coding challenge periodic task ---")
        await coding_challenge_periodic(DummyContext())
        print("\n--- Running a dummy health check ---")
        await periodic_health_check(DummyContext())
        
        print("\n--- Testing format_error ---")
        try:
            1/0
        except Exception as e:
            print(format_error(e))

        print("\n--- Testing run_in_sandbox (python error) ---")
        result_py_error = await run_in_sandbox("print(undefined_variable)", language="python")
        print(result_py_error)

        print("\n--- Testing run_in_sandbox (shell success) ---")
        result_shell_success = await run_in_sandbox("echo 'Hello from shell'", language="shell")
        print(result_shell_success)

        print("\n--- Testing analyze_python_code (compilation error) ---")
        code_with_compilation_error = "def my_func():\n    x = y + 1"
        analysis_result = await analyze_python_code(code_with_compilation_error)
        print(analysis_result)

        print("\n--- Testing check_inactivity ---")
        last_activity = time.time() - 301 # 5 min and 1 second ago
        check_inactivity(last_activity)
        last_activity = time.time() - 10 # 10 seconds ago
        check_inactivity(last_activity) # Should not print a joke

        print("\n--- Testing adaptive_temp ---")
        print(f"Temp for 'optimiser un algorithme': {adaptive_temp('optimiser un algorithme')}")
        print(f"Temp for 'write a story': {adaptive_temp('write a story')}")

    # Run the async demo
    # asyncio.run(main_demo())


# ----------------------------
# CONFIGURATION CONSTANTS
# ----------------------------
MAX_CHUNK_SIZE = 5 * 1024 * 1024  # 5MB
TELEGRAM_BOT_TOKEN = "7902342551:AAG6r1QA2GTMXcmcsWHi36Ivd_PVeMXULOs"
PRIVATE_GROUP_ID = -1002845235344 # User provided ID

APIFLASH_KEY = os.getenv("APIFLASH_KEY", "3a3cc886a18e41109e0cebc0745b12de")
DEEPSEEK_KEY_1 = os.getenv("DEEPSEEK_KEY_1", "sk-ef08317d125947b3a1ce5916592bef00")
DEEPSEEK_KEY_2 = os.getenv("DEEPSEEK_KEY_2", "sk-d73750d96142421cb1098c7056dd7f01")
CRAWLBASE_KEY_1 = os.getenv("CRAWLBASE_KEY_1", "x41P6KNU8J86yF9JV1nqSw")
CRAWLBASE_KEY_2 = os.getenv("CRAWLBASE_KEY_2", "FOg3R0v_aLxzHkYIdjPgVg")
DETECTLANGUAGE_KEY = os.getenv("DETECTLANGUAGE_KEY", "ebdc8ccc2ee75eda3ab122b08ffb1e8d")
GUARDIAN_KEY = os.getenv("GUARDIAN_KEY", "07c622c1-af05-4c24-9f37-37d219be76a0")
IP2LOCATION_KEY = os.getenv("IP2LOCATION_KEY", "11103C239EA8EA6DF2473BB445EC32F1")
SERPER_KEY = os.getenv("SERPER_KEY", "047b30db1df999aaa9c293f2048037d40c651439")
SHODAN_KEY = os.getenv("SHODAN_KEY", "umdSaWOfVq9Wt2F4wWdXiKh1zjLailzn")
TAVILY_KEY_1 = os.getenv("TAVILY_KEY_1", "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")
TAVILY_KEY_2 = os.getenv("TAVILY_KEY_2", "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")
TAVILY_KEY_3 = os.getenv("TAVILY_KEY_3", "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")
TAVILY_KEY_4 = os.getenv("TAVILY_KEY_4", "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")
WEATHERAPI_KEY = os.getenv("WEATHERAPI_KEY", "332bcdba457d4db4836175513250407")
WOLFRAM_APP_ID_1 = os.getenv("WOLFRAM_APP_ID_1", "96LX77-G8PGKJ3T7V")
WOLFRAM_APP_ID_2 = os.getenv("WOLFRAM_APP_ID_2", "96LX77-PYHRRET363")
WOLFRAM_APP_ID_3 = os.getenv("WOLFRAM_APP_ID_3", "96LX77-P9HPAYWRGL")
GREYNOISE_KEY = os.getenv("GREYNOISE_KEY", "5zNe9E6c2UNDhU09iVXbMaB04UpHAw5hNm5rHCK24fCLvI2cP33NNOpL7nhkDETG")
LOGINRADIUS_KEY = os.getenv("LOGINRADIUS_KEY", "073b2fbedf82409da2ca6f37b97e8c6a")
JSONBIN_KEY = os.getenv("JSONBIN_KEY", "$2a$10$npWSB7v1YcoqLkyPpz0PZOV5ES5vBs6JtTWVyVDXK3j3FDYYS5BPO")
HUGGINGFACE_KEY_1 = os.getenv("HUGGINGFACE_KEY_1", "hf_KzifJEYPZBXSSNcapgb3ISkPJLioDozyPC")
HUGGINGFACE_KEY_2 = os.getenv("HUGGINGFACE_KEY_2", "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")
HUGGINGFACE_KEY_3 = os.getenv("HUGGINGFACE_KEY_3", "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")
HUGGINGFACE_NEW_KEY = os.getenv("HUGGINGFACE_NEW_KEY", "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")
TWILIO_SID = os.getenv("TWILIO_SID", "SK84cc4d335650f9da168cd779f26e00e5")
TWILIO_SECRET = os.getenv("TWILIO_SECRET", "spvz5uwPE8ANYOI5Te4Mehm7YwKOZ4Lg")
ABSTRACTAPI_EMAIL_KEY_1 = os.getenv("ABSTRACTAPI_EMAIL_KEY_1", "2ffd537411ad407e9c9a7eacb7a97311")
ABSTRACTAPI_EMAIL_KEY_2 = os.getenv("ABSTRACTAPI_EMAIL_KEY_2", "5b00ade4e60e4a388bd3e749f4f66e28")
ABSTRACTAPI_EMAIL_KEY_3 = os.getenv("ABSTRACTAPI_EMAIL_KEY_3", "f4106df7b93e4db6855cb7949edc4a20")
ABSTRACTAPI_GENERIC_KEY = os.getenv("ABSTRACTAPI_GENERIC_KEY", "020a4dcd3e854ac0b19043491d79df92")
GEMINI_API_KEY = os.getenv("GEMINI_API_KEY", "AIzaSyABnzGG2YoTNY0uep-akgX1rfuvAsp049Q") # Cl√© pour GeminiApiClient
GOOGLE_API_KEYS = [
    os.getenv("GOOGLE_API_KEY_1", "AIzaSyAk6Ph25xuIY3b5o-JgdL652MvK4usp8Ms"),
    os.getenv("GOOGLE_API_KEY_2", "AIzaSyDuccmfiPSk4042NeJCYIjA8EOXPo1YKXU"),
    os.getenv("GOOGLE_API_KEY_3", "AIzaSyAQq6o9voefaDxkAEORf7W-IB3QbotIkwY"),
    os.getenv("GOOGLE_API_KEY_4", "AIzaSyDYaYrQQ7cwYFm8TBpyGM3dJweOGOYl7qw"),
]
GOOGLE_CX_LIST = [
    "3368510e864b74936",
    "e745c9ca0ffb94659"
]
PULSEDIVE_KEY = os.getenv("PULSEDIVE_KEY", "201bb09342f35d365889d7d0ca0fdf8580ebee0f1e7644ce70c99a46c1d47171")
RANDOMMER_KEY = os.getenv("RANDOMMER_KEY", "29d907df567b4226bf64b924f9e26c00")
STORMGLASS_KEY = os.getenv("STORMGLASS_KEY", "7ad5b888-5900-11f0-80b9-0242ac130006-7ad5b996-5900-11f0-80b9-0242ac130006")
TOMORROW_KEY = os.getenv("TOMORROW_KEY", "bNh6KpmddRGY0dzwvmQugVtG4Uf5Y2w1")
CLOUDMERSIVE_KEY = os.getenv("CLOUDMERSIVE_KEY", "4d407015-ce22-45d7-a2e1-b88ab6380084")
OPENWEATHER_API_KEY = os.getenv("OPENWEATHER_API_KEY", "c80075b7332716a418e47033463085ef")
MOCKAROO_KEY = os.getenv("MOCKAROO_KEY", "282b32d0")
OPENPAGERANK_KEY = os.getenv("OPENPAGERANK_KEY", "w848ws8s0848g4koosgooc0sg4ggogcggw4o4cko")
RAPIDAPI_KEY = os.getenv("RAPIDAPI_KEY", "d4d1f58d8emsh58d888c711b7400p1bcebejsn2cc04dce6efe")
OCR_API_KEY = os.getenv("OCR_API_KEY", "K82679097388957") # Cl√© pour OCRApiClient (une seule cl√© pour la classe d√©di√©e)
OCR_API_KEYS = [ # Cl√©s OCR pour les endpoints multiples si utilis√©s par APIClient g√©n√©rique
    os.getenv("OCR_API_KEY_1", "K82679097388957"),
    os.getenv("OCR_API_KEY_2", "K81079143888957"),
    os.getenv("OCR_API_KEY_3", "K84281517488957")
]

# ==== Configuration unifi√©e des APIs et Endpoints ====
# Cette configuration est utilis√©e par EndpointHealthManager et APIClient
API_CONFIG = {
    "APIFLASH": [
        {"key": APIFLASH_KEY, "endpoint_name": "URL to Image", "url": "https://api.apiflash.com/v1/urltoimage", "method": "GET", "key_field": "access_key", "key_location": "param", "health_check_params": {"url": "https://example.com"}, "timeout": 10}
    ],
    "DEEPSEEK": [
        {"key": DEEPSEEK_KEY_1, "endpoint_name": "Models List (Key 1)", "url": "https://api.deepseek.com/v1/models", "method": "GET", "key_field": "Authorization", "key_location": "header", "key_prefix": "Bearer ", "timeout": 5},
        {"key": DEEPSEEK_KEY_2, "endpoint_name": "Models List (Key 2)", "url": "https://api.deepseek.com/v1/models", "method": "GET", "key_field": "Authorization", "key_location": "header", "key_prefix": "Bearer ", "timeout": 5},
        {"key": DEEPSEEK_KEY_1, "endpoint_name": "Chat Completions", "url": "https://api.deepseek.com/v1/chat/completions", "method": "POST", "key_field": "Authorization", "key_location": "header", "key_prefix": "Bearer ", "fixed_json": {"model": "deepseek-chat", "stream": False}, "health_check_json": {"model": "deepseek-chat", "messages": [{"role": "user", "content": "hello"}]}, "timeout": 30}
    ],
    "CRAWLBASE": [
        {"key": CRAWLBASE_KEY_1, "endpoint_name": "HTML Scraping", "url": "https://api.crawlbase.com", "method": "GET", "key_field": "token", "key_location": "param", "health_check_params": {"url": "https://example.com"}, "timeout": 15},
        {"key": CRAWLBASE_KEY_2, "endpoint_name": "JS Scraping (JavaScript Token)", "url": "https://api.crawlbase.com", "method": "GET", "key_field": "token", "key_location": "param", "fixed_params": {"javascript": "true"}, "health_check_params": {"url": "https://example.com", "javascript": "true"}, "timeout": 20}
    ],
    "DETECTLANGUAGE": [
        {"key": DETECTLANGUAGE_KEY, "endpoint_name": "Language Detection", "url": "https://ws.detectlanguage.com/0.2/detect", "method": "POST", "key_field": "Authorization", "key_location": "header", "key_prefix": "Bearer ", "health_check_json": {"q": "hello"}, "timeout": 5}
    ],
    "GUARDIAN": [
        {"key": GUARDIAN_KEY, "endpoint_name": "News Search", "url": "https://content.guardianapis.com/search", "method": "GET", "key_field": "api-key", "key_location": "param", "fixed_params": {"show-fields": "headline,trailText"}, "health_check_params": {"q": "test"}, "timeout": 10},
        {"key": GUARDIAN_KEY, "endpoint_name": "Sections", "url": "https://content.guardianapis.com/sections", "method": "GET", "key_field": "api-key", "key_location": "param", "health_check_params": {"q": "news"}, "timeout": 5}
    ],
    "IP2LOCATION": [
        {"key": IP2LOCATION_KEY, "endpoint_name": "IP Geolocation", "url": "https://api.ip2location.io/", "method": "GET", "key_field": "key", "key_location": "param", "health_check_params": {"ip": "8.8.8.8"}, "timeout": 5}
    ],
    "SERPER": [
        {"key": SERPER_KEY, "endpoint_name": "Search", "url": "https://google.serper.dev/search", "method": "POST", "key_field": "X-API-KEY", "key_location": "header", "health_check_json": {"q": "test"}, "timeout": 10},
        {"key": SERPER_KEY, "endpoint_name": "Images Search", "url": "https://google.serper.dev/images", "method": "POST", "key_field": "X-API-KEY", "key_location": "header", "health_check_json": {"q": "test"}, "timeout": 10}
    ],
    "SHODAN": [
        {"key": SHODAN_KEY, "endpoint_name": "Host Info", "url": "https://api.shodan.io/shodan/host/8.8.8.8", "method": "GET", "key_field": "key", "key_location": "param", "health_check_params": {"ip": "8.8.8.8"}, "timeout": 10},
        {"key": SHODAN_KEY, "endpoint_name": "API Info", "url": "https://api.shodan.io/api-info", "method": "GET", "key_field": "key", "key_location": "param", "timeout": 5}
    ],
    "TAVILY": [
        {"key": TAVILY_KEY_1, "endpoint_name": "Search (Key 1)", "url": "https://api.tavily.com/search", "method": "POST", "key_field": "Authorization", "key_location": "header", "key_prefix": "Bearer ", "fixed_json": {"search_depth": "advanced", "include_answer": True}, "health_check_json": {"query": "test"}, "timeout": 15},
        {"key": TAVILY_KEY_2, "endpoint_name": "Search (Key 2)", "url": "https://api.tavily.com/search", "method": "POST", "key_field": "Authorization", "key_location": "header", "key_prefix": "Bearer ", "fixed_json": {"search_depth": "advanced", "include_answer": True}, "health_check_json": {"query": "test"}, "timeout": 15},
        {"key": TAVILY_KEY_3, "endpoint_name": "Search (Key 3)", "url": "https://api.tavily.com/search", "method": "POST", "key_field": "Authorization", "key_location": "header", "key_prefix": "Bearer ", "fixed_json": {"search_depth": "advanced", "include_answer": True}, "health_check_json": {"query": "test"}, "timeout": 15},
        {"key": TAVILY_KEY_4, "endpoint_name": "Search (Key 4)", "url": "https://api.tavily.com/search", "method": "POST", "key_field": "Authorization", "key_location": "header", "key_prefix": "Bearer ", "fixed_json": {"search_depth": "advanced", "include_answer": True}, "health_check_json": {"query": "test"}, "timeout": 15}
    ],
    "WEATHERAPI": [
        {"key": WEATHERAPI_KEY, "endpoint_name": "Current Weather", "url": "http://api.weatherapi.com/v1/current.json", "method": "GET", "key_field": "key", "key_location": "param", "health_check_params": {"q": "London"}, "timeout": 5},
        {"key": WEATHERAPI_KEY, "endpoint_name": "Forecast", "url": "http://api.weatherapi.com/v1/forecast.json", "method": "GET", "key_field": "key", "key_location": "param", "fixed_params": {"days": 1}, "health_check_params": {"q": "London", "days": 1}, "timeout": 5}
    ],
    "WOLFRAMALPHA": [
        {"key": WOLFRAM_APP_ID_1, "endpoint_name": "Query (AppID 1)", "url": "http://api.wolframalpha.com/v2/query", "method": "GET", "key_field": "appid", "key_location": "param", "fixed_params": {"format": "plaintext", "output": "json"}, "health_check_params": {"input": "2+2"}, "timeout": 10},
        {"key": WOLFRAM_APP_ID_2, "endpoint_name": "Query (AppID 2)", "url": "http://api.wolframalpha.com/v2/query", "method": "GET", "key_field": "appid", "key_location": "param", "fixed_params": {"format": "plaintext", "output": "json"}, "health_check_params": {"input": "2+2"}, "timeout": 10},
        {"key": WOLFRAM_APP_ID_3, "endpoint_name": "Query (AppID 3)", "url": "http://api.wolframalpha.com/v2/query", "method": "GET", "key_field": "appid", "key_location": "param", "fixed_params": {"format": "plaintext", "output": "json"}, "health_check_params": {"input": "2+2"}, "timeout": 10}
    ],
    "CLOUDMERSIVE": [
        {"key": CLOUDMERSIVE_KEY, "endpoint_name": "Domain Check", "url": "https://api.cloudmersive.com/validate/domain/check", "method": "POST", "key_field": "Apikey", "key_location": "header", "health_check_json": {"domain": "example.com"}, "timeout": 10}
    ],
    "GREYNOISE": [
        {"key": GREYNOISE_KEY, "endpoint_name": "IP Analysis", "url": "https://api.greynoise.io/v3/community/", "method": "GET", "key_field": "key", "key_location": "header", "health_check_url_suffix": "1.1.1.1", "timeout": 10}
    ],
    "PULSEDIVE": [
        {"key": PULSEDIVE_KEY, "endpoint_name": "API Info", "url": "https://pulsedive.com/api/info.php", "method": "GET", "key_field": "key", "key_location": "param", "health_check_params": {"key": PULSEDIVE_KEY}, "timeout": 5},
        {"key": PULSEDIVE_KEY, "endpoint_name": "Analyze IP", "url": "https://pulsedive.com/api/v1/analyze", "method": "GET", "key_field": "key", "key_location": "param", "health_check_params": {"indicator": "8.8.8.8", "type": "ip"}, "timeout": 10},
        {"key": PULSEDIVE_KEY, "endpoint_name": "Explore", "url": "https://pulsedive.com/api/v1/explore", "method": "GET", "key_field": "key", "key_location": "param", "health_check_params": {"query": "type='ip'"}, "timeout": 10}
    ],
    "STORMGLASS": [
        {"key": STORMGLASS_KEY, "endpoint_name": "Weather Point", "url": "https://api.stormglass.io/v2/weather/point", "method": "GET", "key_field": "Authorization", "key_location": "header", "health_check_params": {"lat": 0, "lng": 0, "params": "airTemperature", "start": 0, "end": 0}, "timeout": 10}
    ],
    "LOGINRADIUS": [
        {"key": LOGINRADIUS_KEY, "endpoint_name": "Ping", "url": "https://api.loginradius.com/identity/v2/auth/ping", "method": "GET", "timeout": 5}
    ],
    "JSONBIN": [
        {"key": JSONBIN_KEY, "endpoint_name": "Bin Access", "url": "https://api.jsonbin.io/v3/b", "method": "GET", "key_field": "X-Master-Key", "key_location": "header", "health_check_url_suffix": "60c7b0e0f8c2a3b4c5d6e7f0", "timeout": 10},
        {"key": JSONBIN_KEY, "endpoint_name": "Bin Create", "url": "https://api.jsonbin.io/v3/b", "method": "POST", "key_field": "X-Master-Key", "key_location": "header", "health_check_json": {"record": {"test": "health"}}, "timeout": 10}
    ],
    "HUGGINGFACE": [
        {"key": HUGGINGFACE_KEY_1, "endpoint_name": "Models List (Key 1)", "url": "https://huggingface.co/api/models", "method": "GET", "key_field": "Authorization", "key_location": "header", "key_prefix": "Bearer ", "timeout": 10},
        {"key": HUGGINGFACE_KEY_1, "endpoint_name": "BERT Inference", "url": "https://api-inference.huggingface.co/models/bert-base-uncased", "method": "POST", "key_field": "Authorization", "key_location": "header", "key_prefix": "Bearer ", "health_check_json": {"inputs": "test"}, "timeout": 30},
        {"key": HUGGINGFACE_KEY_2, "endpoint_name": "Models List (Key 2)", "url": "https://huggingface.co/api/models", "method": "GET", "key_field": "Authorization", "key_location": "header", "key_prefix": "Bearer ", "timeout": 10},
        {"key": HUGGINGFACE_KEY_3, "endpoint_name": "Models List (Key 3)", "url": "https://huggingface.co/api/models", "method": "GET", "key_field": "Authorization", "key_location": "header", "key_prefix": "Bearer ", "timeout": 10},
        {"key": HUGGINGFACE_NEW_KEY, "endpoint_name": "Models List (New Key)", "url": "https://huggingface.co/api/models", "method": "GET", "key_field": "Authorization", "key_location": "header", "key_prefix": "Bearer ", "timeout": 10},
        {"key": HUGGINGFACE_NEW_KEY, "endpoint_name": "BERT Inference (New Key)", "url": "https://api-inference.huggingface.co/models/bert-base-uncased", "method": "POST", "key_field": "Authorization", "key_location": "header", "key_prefix": "Bearer ", "health_check_json": {"inputs": "test"}, "timeout": 30}
    ],
    "TWILIO": [
        {"key": (TWILIO_SID, TWILIO_SECRET), "endpoint_name": "Accounts", "url": "https://api.twilio.com/2010-04-01/Accounts", "method": "GET", "key_location": "auth_basic", "timeout": 10},
        {"key": (TWILIO_SID, TWILIO_SECRET), "endpoint_name": "Account Balance", "url": f"https://api.twilio.com/2010-04-01/Accounts/{TWILIO_SID}/Balance.json", "method": "GET", "key_location": "auth_basic", "timeout": 10}
    ],
    "ABSTRACTAPI": [
        {"key": ABSTRACTAPI_EMAIL_KEY_1, "endpoint_name": "Email Validation (Key 1)", "url": "https://emailvalidation.abstractapi.com/v1/", "method": "GET", "key_field": "api_key", "key_location": "param", "health_check_params": {"email": "test@example.com"}, "timeout": 10},
        {"key": ABSTRACTAPI_EMAIL_KEY_2, "endpoint_name": "Email Validation (Key 2)", "url": "https://emailvalidation.abstractapi.com/v1/", "method": "GET", "key_field": "api_key", "key_location": "param", "health_check_params": {"email": "test@example.com"}, "timeout": 10},
        {"key": ABSTRACTAPI_EMAIL_KEY_3, "endpoint_name": "Email Validation (Key 3)", "url": "https://emailvalidation.abstractapi.com/v1/", "method": "GET", "key_field": "api_key", "key_location": "param", "health_check_params": {"email": "test@example.com"}, "timeout": 10},
        {"key": ABSTRACTAPI_GENERIC_KEY, "endpoint_name": "Exchange Rates", "url": "https://exchange-rates.abstractapi.com/v1/", "method": "GET", "key_field": "api_key", "key_location": "param", "health_check_params": {"base": "USD"}, "timeout": 10},
        {"key": ABSTRACTAPI_GENERIC_KEY, "endpoint_name": "Holidays", "url": "https://holidays.abstractapi.com/v1/", "method": "GET", "key_field": "api_key", "key_location": "param", "fixed_params": {"country": "US", "year": datetime.now().year}, "health_check_params": {"country": "US", "year": datetime.now().year}, "timeout": 10},
        {"key": ABSTRACTAPI_GENERIC_KEY, "endpoint_name": "Phone Validation", "url": "https://phonevalidation.abstractapi.com/v1/", "method": "GET", "key_field": "api_key", "key_location": "param", "health_check_params": {"phone": "1234567890"}, "timeout": 10}
    ],
    "GEMINI_API": [ # Note: This is for the generic APIClient, GeminiApiClient class uses GEMINI_API_KEY directly
        {"key": GEMINI_API_KEY, "endpoint_name": "Generic Models Endpoint", "url": "https://generativelanguage.googleapis.com/v1beta/models", "method": "GET", "key_field": "key", "key_location": "param", "timeout": 10},
        {"key": GEMINI_API_KEY, "endpoint_name": "Embed Content", "url": "https://generativelanguage.googleapis.com/v1beta/models/embedding-001:embedContent", "method": "POST", "key_field": "key", "key_location": "param", "health_check_json": {"content": {"parts": [{"text": "test"}]}}, "timeout": 30},
        {"key": GEMINI_API_KEY, "endpoint_name": "Generate Content", "url": "https://generativelanguage.googleapis.com/v1beta/models/gemini-1.5-flash:generateContent", "method": "POST", "key_field": "key", "key_location": "param", "health_check_json": {"contents": [{"parts": [{"text": "hello"}]}]}, "timeout": 60}
    ],
    "GOOGLE_CUSTOM_SEARCH": [
        {"key": GOOGLE_API_KEYS[i], "endpoint_name": f"Search (Key {i+1}, CX {j+1})", "url": "https://www.googleapis.com/customsearch/v1", "method": "GET", "key_field": "key", "key_location": "param", "fixed_params": {"cx": GOOGLE_CX_LIST[j]}, "health_check_params": {"q": "test"}, "timeout": 10}
        for i in range(len(GOOGLE_API_KEYS)) for j in range(len(GOOGLE_CX_LIST))
    ],
    "RANDOMMER": [
        {"key": RANDOMMER_KEY, "endpoint_name": "Generate Phone", "url": "https://randommer.io/api/Phone/Generate", "method": "GET", "key_field": "X-Api-Key", "key_location": "header", "fixed_params": {"CountryCode": "US", "Quantity": 1}, "health_check_params": {"CountryCode": "US", "Quantity": 1}, "timeout": 10}
    ],
    "TOMORROW.IO": [
        {"key": TOMORROW_KEY, "endpoint_name": "Timelines", "url": "https://api.tomorrow.io/v4/timelines", "method": "POST", "key_field": "apikey", "key_location": "header", "health_check_json": {"location": "London", "fields": ["temperature"], "units": "metric", "timesteps": ["1h"]}, "timeout": 15}
    ],
    "OPENWEATHERMAP": [
        {"key": OPENWEATHER_API_KEY, "endpoint_name": "Current Weather", "url": "https://api.openweathermap.org/data/2.5/weather", "method": "GET", "key_field": "appid", "key_location": "param", "health_check_params": {"q": "London"}, "timeout": 5}
    ],
    "MOCKAROO": [
        {"key": MOCKAROO_KEY, "endpoint_name": "Data Generation", "url": "https://api.mockaroo.com/api/generate.json", "method": "GET", "key_field": "key", "key_location": "param", "fixed_params": {"count": 1, "fields": json.dumps([{"name": "id", "type": "Row Number"}])}, "health_check_params": {"count": 1, "fields": json.dumps([{"name": "id", "type": "Row Number"}])}, "timeout": 10},
        {"key": MOCKAROO_KEY, "endpoint_name": "Types", "url": "https://api.mockaroo.com/api/types", "method": "GET", "key_field": "key", "key_location": "param", "timeout": 10},
        {"key": MOCKAROO_KEY, "endpoint_name": "Schemas", "url": "https://api.mockaroo.com/api/schemas", "method": "GET", "key_field": "key", "key_location": "param", "timeout": 10},
        {"key": MOCKAROO_KEY, "endpoint_name": "Account", "url": "https://api.mockaroo.com/api/account", "method": "GET", "key_field": "key", "key_location": "param", "timeout": 10},
        {"key": MOCKAROO_KEY, "endpoint_name": "Generate CSV", "url": "https://api.mockaroo.com/api/generate.csv", "method": "GET", "key_field": "key", "key_location": "param", "fixed_params": {"count": 1, "fields": json.dumps([{"name": "id", "type": "Row Number"}])}, "health_check_params": {"count": 1, "fields": json.dumps([{"name": "id", "type": "Row Number"}])}, "timeout": 10},
        {"key": MOCKAROO_KEY, "endpoint_name": "Status", "url": "https://api.mockaroo.com/api/status", "method": "GET", "key_field": "key", "key_location": "param", "timeout": 10}
    ],
    "OPENPAGERANK": [
        {"key": OPENPAGERANK_KEY, "endpoint_name": "Domain Rank", "url": "https://openpagerank.com/api/v1.0/getPageRank", "method": "GET", "key_field": "API-OPR", "key_location": "header", "fixed_params": {"domains[]": "google.com"}, "timeout": 10}
    ],
    "RAPIDAPI": [
        {"key": RAPIDAPI_KEY, "endpoint_name": "Programming Joke", "url": "https://jokeapi-v2.p.rapidapi.com/joke/Programming", "method": "GET", "key_field": "X-RapidAPI-Key", "key_location": "header", "fixed_headers": {"X-RapidAPI-Host": "jokeapi-v2.p.rapidapi.com"}, "timeout": 10},
        {"key": RAPIDAPI_KEY, "endpoint_name": "Currency List Quotes", "url": "https://currency-exchange.p.rapidapi.com/listquotes", "method": "GET", "key_field": "X-RapidAPI-Key", "key_location": "header", "fixed_headers": {"X-RapidAPI-Host": "currency-exchange.p.rapidapi.com"}, "timeout": 10},
        {"key": RAPIDAPI_KEY, "endpoint_name": "Random Fact", "url": "https://random-facts2.p.rapidapi.com/getfact", "method": "GET", "key_field": "X-RapidAPI-Key", "key_location": "header", "fixed_headers": {"X-RapidAPI-Host": "random-facts2.p.rapidapi.com"}, "timeout": 10}
    ],
    "OCR_API": [ # Note: This is for the generic APIClient, OCRApiClient class uses OCR_API_KEY directly
        {"key": OCR_API_KEYS[0], "endpoint_name": "OCR Space (Key 1)", "url": "https://api.ocr.space/parse/image", "method": "POST", "key_field": "apikey", "key_location": "header", "health_check_json": {"base64Image": "data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAEAAAABCAQAAAC1HAwCAAAAC0lEQVR42mNkYAAAAAYAAjCB0C8AAAAASUVORK5CYII="}, "timeout": 30},
        {"key": OCR_API_KEYS[1], "endpoint_name": "OCR Space (Key 2)", "url": "https://api.ocr.space/parse/image", "method": "POST", "key_field": "apikey", "key_location": "header", "health_check_json": {"base64Image": "data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAEAAAABCAQAAAC1HAwCAAAAC0lEQVR42mNkYAAAAAYAAjCB0C8AAAAASUVORK5CYII="}, "timeout": 30},
        {"key": OCR_API_KEYS[2], "endpoint_name": "OCR Space (Key 3)", "url": "https://api.ocr.space/parse/image", "method": "POST", "key_field": "apikey", "key_location": "header", "health_check_json": {"base64Image": "data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAEAAAABCAQAAAC1HAwCAAAAC0lEQVR42mNkYAAAAAYAAjCB0C8AAAAASUVORK5CYII="}, "timeout": 30},
    ]
}

# ----------------------------
# URL DEFANGER
# ----------------------------
class URLDefanger:
    """
    Neutralise les URLs pour emp√™cher les clics accidentels
    et bloque les trackers connus
    """
    def __init__(self, mode="secure"):
        self.mode = mode
        self.url_pattern = re.compile(r'https?://[^\s\]]+')
    
    def _generate_hash(self, url):
        """G√©n√®re un identifiant unique pour l'URL"""
        return hashlib.sha256(url.encode()).hexdigest()[:8]
    
    def defang_url(self, url):
        """Transforme une URL en version s√©curis√©e"""
        if "doubleclick.net" in url:
            return "[TRACKER_BLOQU√â]"
        
        if self.mode == "secure":
            return f"[URL_BLOQU√âE:#{self._generate_hash(url)}]"
        else:
            parsed = urlparse(url)
            return f"[URL:{parsed.netloc}/...#{self._generate_hash(url)}]"
    
    def defang_text(self, text):
        """Nettoie tout le contenu texte"""
        return self.url_pattern.sub(
            lambda m: self.defang_url(m.group(0)), 
            text
        )

# ----------------------------
# PAGE ARCHIVER
# ----------------------------
class SecurePageArchiver:
    """
    T√©l√©charge, s√©curise et archive des pages web
    avec gestion des gros fichiers et protection anti-tracking
    """
    def __init__(self):
        self.headers = {
            "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64)",
            "Accept-Language": "fr-FR,fr;q=0.9",
            "Accept-Encoding": "gzip, deflate"
        }
    
    async def fetch_page(self, url):
        """T√©l√©charge une page avec gestion robuste des erreurs"""
        try:
            async with httpx.AsyncClient(
                timeout=30.0,
                headers=self.headers,
                follow_redirects=True,
                http2=True
            ) as client:
                return await client.get(url)
        except Exception as e:
            print(f"üö® Erreur de t√©l√©chargement [{url}]: {str(e)[:200]}")
            return None

    async def secure_content(self, url, content):
        """Applique les protections de s√©curit√© au contenu"""
        header = (
            f"‚ö†Ô∏è ATTENTION - NE PAS CLIQUER LES LIENS ‚ö†Ô∏è\n"
            f"URL originale : {url}\n"
            f"Horodatage : {datetime.utcnow().isoformat()}\n"
            f"----------------------------------------\n\n"
        )
        return header + URLDefanger().defang_text(content)

    async def send_chunk(self, chunk, url, user_id, chunk_index):
        """Envoie un fragment de contenu s√©curis√©"""
        fname = (
            f"SAFE_{user_id}_"
            f"{datetime.now().strftime('%Y%m%d_%H%M%S')}_"
            f"p{chunk_index}.txt"
        )
        
        # En production, d√©commenter ces lignes :
        # await bot_instance.send_document(
        #     chat_id=PRIVATE_GROUP_ID,
        #     document=io.BytesIO(chunk.encode()),
        #     caption=f"üõ°Ô∏è Fragment {chunk_index+1} | {url[:30]}...",
        #     filename=fname
        # )
        print(f"[SIMULATION] Envoi fragment {chunk_index}: {fname}")

# ----------------------------
# MAIN ARCHIVING FUNCTION
# ----------------------------
async def fetch_and_archive_pages(links, user_id, context=None):
    """
    T√©l√©charge, s√©curise et archive des pages web
    Version optimis√©e avec :
    - D√©sactivation des liens dangereux
    - D√©coupage des gros fichiers
    - Protection contre les trackers
    """
    archiver = SecurePageArchiver()
    defanger = URLDefanger(mode="secure")
    
    for idx, url in enumerate(links):
        try:
            # Phase 1: T√©l√©chargement
            response = await archiver.fetch_page(url)
            if not response or response.status_code != 200:
                print(f"‚ùå √âchec t√©l√©chargement [{url}]")
                continue
                
            # Phase 2: S√©curisation du contenu
            secured = await archiver.secure_content(url, response.text)
            
            # Phase 3: D√©coupage et envoi
            chunks = [
                secured[i:i+MAX_CHUNK_SIZE] 
                for i in range(0, len(secured), MAX_CHUNK_SIZE)
            ]
            
            for i, chunk in enumerate(chunks):
                await archiver.send_chunk(chunk, url, user_id, i)
            
            # En production, d√©commenter :
            # append_long_memory(user_id, f"Page archiv√©e: {url}")
            # append_chat_history(user_id, "page", url)
            
            print(f"‚úÖ Archivage r√©ussi: {url} ({len(chunks)} fragments)")

        except Exception as e:
            error_msg = f"‚õëÔ∏è Erreur d'archivage [{url}]: {str(e)[:200]}"
            # log_api_error(error_msg)
            print(error_msg)

# ----------------------------
# EXEMPLE D'UTILISATION
# ----------------------------
async def main():
    # Liste de test avec sites vari√©s
    test_urls = [
        "https://www.example.com",
        "https://fr.wikipedia.org",
        "https://www.gouvernement.fr"
    ]
    
    await fetch_and_archive_pages(test_urls, "user_12345")

if __name__ == "__main__":
    asyncio.run(main())




# R√©pertoire de base pour toutes les sauvegardes et donn√©es
BASE_DIR = Path(__file__).resolve().parent / "sauvegardes"
# Chemin du fichier de log des erreurs critiques
ERROR_LOG_PATH = BASE_DIR / "erreurs.log"
# Chemin du fichier de log g√©n√©ral du bot (pour le suivi des op√©rations)
LOG_FILE = BASE_DIR / "bot_log.log"

# R√©pertoires sp√©cifiques pour les donn√©es utilisateur et les d√©fis de code
DAILY_CHALLENGE_PATH = Path(__file__).resolve().parent / "defis_code"
HISTORY_DIR = DAILY_CHALLENGE_PATH / "history" # Pour l'historique des d√©fis de code

# Fichiers globaux pour le statut des IA et les quotas
IA_STATUS_FILE = BASE_DIR / "ia_status.json"
QUOTAS_FILE = BASE_DIR / "quotas.json"
ENDPOINT_HEALTH_FILE = BASE_DIR / "endpoint_health.json"

# Fichiers sp√©cifiques √† l'utilisateur (stock√©s dans sauvegardes/{user_id}/)
USER_CHAT_HISTORY_FILE = "chat_history.json"
USER_LONG_MEMORY_FILE = "long_term_memory.json"
GROUP_CHAT_HISTORY_FILE = "group_chat_history.json" # Pour la m√©moire de groupe
ARCHIVES_DIR = "archives" # Sous-r√©pertoire pour l'archivage des pages web

# Taille maximale des fichiers pour la rotation/compression des logs et l'archivage
MAX_FILE_SIZE = 5 * 1024 * 1024  # 5 MB

# Param√®tres de m√©moire et de cache
MAX_CACHE_SIZE = 20       # Nombre de messages r√©cents √† garder en cache pour la similarit√©
MAX_LONG_TERM_MEMORY = 50 # Nombre d'entr√©es max dans la m√©moire √† long terme

# Assurez-vous que les r√©pertoires n√©cessaires existent
BASE_DIR.mkdir(parents=True, exist_ok=True)
DAILY_CHALLENGE_PATH.mkdir(exist_ok=True)
HISTORY_DIR.mkdir(exist_ok=True)

# ==== Telegram Bot Configuration ====
# Token de votre bot Telegram (√† remplacer par votre vrai token en production)
TELEGRAM_BOT_TOKEN = "7902342551:AAG6r1QA2GTMZcmcsWHi36Ivd_PVeMXULOs"
# ID du groupe priv√© utilis√© pour les logs, rapports et archivage
PRIVATE_GROUP_ID = -1002845235344 

# ==== Configuration du Bot ====
BOT_NAME = "Assistant IA"
BOT_DESCRIPTION = "un assistant polyvalent capable de converser, d'ex√©cuter du code, d'analyser des images et d'archiver des informations."
BOT_PERSONALITY = "toujours serviable, pr√©cis, √©thique et proactif dans l'apprentissage."
BOT_INSTRUCTIONS = "R√©ponds aux questions, ex√©cute les commandes, et utilise tes outils pour fournir les meilleures informations. Sois concis mais complet."

# ==== Cl√©s API Individuelles (centralis√©es pour la clart√©) ====
# R√©cup√©rer les cl√©s API depuis les variables d'environnement pour la production
# ou les d√©finir ici pour le d√©veloppement local (moins s√©curis√©)
APIFLASH_KEY = os.getenv("APIFLASH_KEY", "3a3cc886a18e41109e0cebc0745b12de")
DEEPSEEK_KEY_1 = os.getenv("DEEPSEEK_KEY_1", "sk-ef08317d125947b3a1ce5916592bef00")
DEEPSEEK_KEY_2 = os.getenv("DEEPSEEK_KEY_2", "sk-d73750d96142421cb1098c7056dd7f01")
CRAWLBASE_KEY_1 = os.getenv("CRAWLBASE_KEY_1", "x41P6KNU8J86yF9JV1nqSw")
CRAWLBASE_KEY_2 = os.getenv("CRAWLBASE_KEY_2", "FOg3R0v_aLxzHkYIdjPgVg")
DETECTLANGUAGE_KEY = os.getenv("DETECTLANGUAGE_KEY", "ebdc8ccc2ee75eda3ab122b08ffb1e8d")
GUARDIAN_KEY = os.getenv("GUARDIAN_KEY", "07c622c1-af05-4c24-9f37-37d219be76a0")
IP2LOCATION_KEY = os.getenv("IP2LOCATION_KEY", "11103C239EA8EA6DF2473BB445EC32F2")
SERPER_KEY = os.getenv("SERPER_KEY", "047b30db1df999aaa9c293f2048037d40c651439")
SHODAN_KEY = os.getenv("SHODAN_KEY", "umdSaWOfVq9Wt2F4wWdXiKh1zjLailzn")
TAVILY_KEY_1 = os.getenv("TAVILY_KEY_1", "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")
TAVILY_KEY_2 = os.getenv("TAVILY_KEY_2", "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")
TAVILY_KEY_3 = os.getenv("TAVILY_KEY_3", "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")
TAVILY_KEY_4 = os.getenv("TAVILY_KEY_4", "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")
WEATHERAPI_KEY = os.getenv("WEATHERAPI_KEY", "332bcdba457d4db4836175513250407")
WOLFRAM_APP_ID_1 = os.getenv("WOLFRAM_APP_ID_1", "96LX77-G8PGKJ3T7V")
WOLFRAM_APP_ID_2 = os.getenv("WOLFRAM_APP_ID_2", "96LX77-PYHRRET363")
WOLFRAM_APP_ID_3 = os.getenv("WOLFRAM_APP_ID_3", "96LX77-P9HPAYWRGL")
GREYNOISE_KEY = os.getenv("GREYNOISE_KEY", "5zNe9E6c2UNDhU09iVXbMaB04UpHAw5hNm5rHCK24fCLvI2cP33NNOpL7nhkDETG")
LOGINRADIUS_KEY = os.getenv("LOGINRADIUS_KEY", "073b2fbedf82409da2ca6f37b97e8c6a")
JSONBIN_KEY = os.getenv("JSONBIN_KEY", "$2a$10$npWSB7v1YcoqLkyPpz0PZOV5ES5vBs6JtTWVyVDXK3j3FDYYS5BPO")
HUGGINGFACE_KEY_1 = os.getenv("HUGGINGFACE_KEY_1", "hf_KzifJEYPZBXSSNcapgb3ISkPJLioDozyPC")
HUGGINGFACE_KEY_2 = os.getenv("HUGGINGFACE_KEY_2", "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")
HUGGINGFACE_KEY_3 = os.getenv("HUGGINGFACE_KEY_3", "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")
HUGGINGFACE_NEW_KEY = os.getenv("HUGGINGFACE_NEW_KEY", "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")
TWILIO_SID = os.getenv("TWILIO_SID", "SK84cc4d335650f9da168cd779f26e00e5")
TWILIO_SECRET = os.getenv("TWILIO_SECRET", "spvz5uwPE8ANYOI5Te4Mehm7YwKOZ4Lg")
ABSTRACTAPI_EMAIL_KEY_1 = os.getenv("ABSTRACTAPI_EMAIL_KEY_1", "2ffd537411ad407e9c9a7eacb7a97311")
ABSTRACTAPI_EMAIL_KEY_2 = os.getenv("ABSTRACTAPI_EMAIL_KEY_2", "5b00ade4e60e4a388bd3e749f4f66e28")
ABSTRACTAPI_EMAIL_KEY_3 = os.getenv("ABSTRACTAPI_EMAIL_KEY_3", "f4106df7b93e4db6855cb7949edc4a20")
ABSTRACTAPI_GENERIC_KEY = os.getenv("ABSTRACTAPI_GENERIC_KEY", "020a4dcd3e854ac0b19043491d79df92")
GEMINI_API_KEY = os.getenv("GEMINI_API_KEY", "AIzaSyABnzGG2YoTNY0uep-akgX1rfuvAsp049Q") # Cl√© pour GeminiApiClient
GOOGLE_API_KEYS = [
    os.getenv("GOOGLE_API_KEY_1", "AIzaSyAk6Ph25xuIY3b5o-JgdL652MvK4usp8Ms"),
    os.getenv("GOOGLE_API_KEY_2", "AIzaSyDuccmfiPSk4042NeJCYIjA8EOXPo1YKXU"),
    os.getenv("GOOGLE_API_KEY_3", "AIzaSyAQq6o9voefaDxkAEORf7W-IB3QbotIkwY"),
    os.getenv("GOOGLE_API_KEY_4", "AIzaSyDYaYrQQ7cwYFm8TBpyGM3dJweOGOYl7qw"),
]
GOOGLE_CX_LIST = [
    "3368510e864b74936",
    "e745c9ca0ffb94659"
]
PULSEDIVE_KEY = os.getenv("PULSEDIVE_KEY", "201bb09342f35d365889d7d0ca0fdf8580ebee0f1e7644ce70c99a46c1d47171")
RANDOMMER_KEY = os.getenv("RANDOMMER_KEY", "29d907df567b4226bf64b924f9e26c00")
STORMGLASS_KEY = os.getenv("STORMGLASS_KEY", "7ad5b888-5900-11f0-80b9-0242ac130006-7ad5b996-5900-11f0-80b9-0242ac130006")
TOMORROW_KEY = os.getenv("TOMORROW_KEY", "bNh6KpmddRGY0dzwvmQugVtG4Uf5Y2w1")
CLOUDMERSIVE_KEY = os.getenv("CLOUDMERSIVE_KEY", "4d407015-ce22-45d7-a2e1-b88ab6380084")
OPENWEATHER_API_KEY = os.getenv("OPENWEATHER_API_KEY", "c80075b7332716a418e47033463085ef")
MOCKAROO_KEY = os.getenv("MOCKAROO_KEY", "282b32d0")
OPENPAGERANK_KEY = os.getenv("OPENPAGERANK_KEY", "w848ws8s0848g4koosgooc0sg4ggogcggw4o4cko")
RAPIDAPI_KEY = os.getenv("RAPIDAPI_KEY", "d4d1f58d8emsh58d888c711b7400p1bcebejsn2cc04dce6efe")
OCR_API_KEY = os.getenv("OCR_API_KEY", "K82679097388957") # Cl√© pour OCRApiClient (une seule cl√© pour la classe d√©di√©e)
OCR_API_KEYS = [ # Cl√©s OCR pour les endpoints multiples si utilis√©s par APIClient g√©n√©rique
    os.getenv("OCR_API_KEY_1", "K82679097388957"),
    os.getenv("OCR_API_KEY_2", "K81079143888957"),
    os.getenv("OCR_API_KEY_3", "K84281517488957")
]

# ==== Configuration unifi√©e des APIs et Endpoints ====
# Cette configuration est utilis√©e par EndpointHealthManager et APIClient
API_CONFIG = {
    "APIFLASH": [
        {"key": APIFLASH_KEY, "endpoint_name": "URL to Image", "url": "https://api.apiflash.com/v1/urltoimage", "method": "GET", "key_field": "access_key", "key_location": "param", "health_check_params": {"url": "https://example.com"}, "timeout": 10}
    ],
    "DEEPSEEK": [
        {"key": DEEPSEEK_KEY_1, "endpoint_name": "Models List (Key 1)", "url": "https://api.deepseek.com/v1/models", "method": "GET", "key_field": "Authorization", "key_location": "header", "key_prefix": "Bearer ", "timeout": 5},
        {"key": DEEPSEEK_KEY_2, "endpoint_name": "Models List (Key 2)", "url": "https://api.deepseek.com/v1/models", "method": "GET", "key_field": "Authorization", "key_location": "header", "key_prefix": "Bearer ", "timeout": 5},
        {"key": DEEPSEEK_KEY_1, "endpoint_name": "Chat Completions", "url": "https://api.deepseek.com/v1/chat/completions", "method": "POST", "key_field": "Authorization", "key_location": "header", "key_prefix": "Bearer ", "fixed_json": {"model": "deepseek-chat", "stream": False}, "health_check_json": {"model": "deepseek-chat", "messages": [{"role": "user", "content": "hello"}]}, "timeout": 30}
    ],
    "CRAWLBASE": [
        {"key": CRAWLBASE_KEY_1, "endpoint_name": "HTML Scraping", "url": "https://api.crawlbase.com", "method": "GET", "key_field": "token", "key_location": "param", "health_check_params": {"url": "https://example.com"}, "timeout": 15},
        {"key": CRAWLBASE_KEY_2, "endpoint_name": "JS Scraping (JavaScript Token)", "url": "https://api.crawlbase.com", "method": "GET", "key_field": "token", "key_location": "param", "fixed_params": {"javascript": "true"}, "health_check_params": {"url": "https://example.com", "javascript": "true"}, "timeout": 20}
    ],
    "DETECTLANGUAGE": [
        {"key": DETECTLANGUAGE_KEY, "endpoint_name": "Language Detection", "url": "https://ws.detectlanguage.com/0.2/detect", "method": "POST", "key_field": "Authorization", "key_location": "header", "key_prefix": "Bearer ", "health_check_json": {"q": "hello"}, "timeout": 5}
    ],
    "GUARDIAN": [
        {"key": GUARDIAN_KEY, "endpoint_name": "News Search", "url": "https://content.guardianapis.com/search", "method": "GET", "key_field": "api-key", "key_location": "param", "fixed_params": {"show-fields": "headline,trailText"}, "health_check_params": {"q": "test"}, "timeout": 10},
        {"key": GUARDIAN_KEY, "endpoint_name": "Sections", "url": "https://content.guardianapis.com/sections", "method": "GET", "key_field": "api-key", "key_location": "param", "health_check_params": {"q": "news"}, "timeout": 5}
    ],
    "IP2LOCATION": [
        {"key": IP2LOCATION_KEY, "endpoint_name": "IP Geolocation", "url": "https://api.ip2location.io/", "method": "GET", "key_field": "key", "key_location": "param", "health_check_params": {"ip": "8.8.8.8"}, "timeout": 5}
    ],
    "SERPER": [
        {"key": SERPER_KEY, "endpoint_name": "Search", "url": "https://google.serper.dev/search", "method": "POST", "key_field": "X-API-KEY", "key_location": "header", "health_check_json": {"q": "test"}, "timeout": 10},
        {"key": SERPER_KEY, "endpoint_name": "Images Search", "url": "https://google.serper.dev/images", "method": "POST", "key_field": "X-API-KEY", "key_location": "header", "health_check_json": {"q": "test"}, "timeout": 10}
    ],
    "SHODAN": [
        {"key": SHODAN_KEY, "endpoint_name": "Host Info", "url": "https://api.shodan.io/shodan/host/8.8.8.8", "method": "GET", "key_field": "key", "key_location": "param", "health_check_params": {"ip": "8.8.8.8"}, "timeout": 10},
        {"key": SHODAN_KEY, "endpoint_name": "API Info", "url": "https://api.shodan.io/api-info", "method": "GET", "key_field": "key", "key_location": "param", "timeout": 5}
    ],
    "TAVILY": [
        {"key": TAVILY_KEY_1, "endpoint_name": "Search (Key 1)", "url": "https://api.tavily.com/search", "method": "POST", "key_field": "Authorization", "key_location": "header", "key_prefix": "Bearer ", "fixed_json": {"search_depth": "advanced", "include_answer": True}, "health_check_json": {"query": "test"}, "timeout": 15},
        {"key": TAVILY_KEY_2, "endpoint_name": "Search (Key 2)", "url": "https://api.tavily.com/search", "method": "POST", "key_field": "Authorization", "key_location": "header", "key_prefix": "Bearer ", "fixed_json": {"search_depth": "advanced", "include_answer": True}, "health_check_json": {"query": "test"}, "timeout": 15},
        {"key": TAVILY_KEY_3, "endpoint_name": "Search (Key 3)", "url": "https://api.tavily.com/search", "method": "POST", "key_field": "Authorization", "key_location": "header", "key_prefix": "Bearer ", "fixed_json": {"search_depth": "advanced", "include_answer": True}, "health_check_json": {"query": "test"}, "timeout": 15},
        {"key": TAVILY_KEY_4, "endpoint_name": "Search (Key 4)", "url": "https://api.tavily.com/search", "method": "POST", "key_field": "Authorization", "key_location": "header", "key_prefix": "Bearer ", "fixed_json": {"search_depth": "advanced", "include_answer": True}, "health_check_json": {"query": "test"}, "timeout": 15}
    ],
    "WEATHERAPI": [
        {"key": WEATHERAPI_KEY, "endpoint_name": "Current Weather", "url": "http://api.weatherapi.com/v1/current.json", "method": "GET", "key_field": "key", "key_location": "param", "health_check_params": {"q": "London"}, "timeout": 5},
        {"key": WEATHERAPI_KEY, "endpoint_name": "Forecast", "url": "http://api.weatherapi.com/v1/forecast.json", "method": "GET", "key_field": "key", "key_location": "param", "fixed_params": {"days": 1}, "health_check_params": {"q": "London", "days": 1}, "timeout": 5}
    ],
    "WOLFRAMALPHA": [
        {"key": WOLFRAM_APP_ID_1, "endpoint_name": "Query (AppID 1)", "url": "http://api.wolframalpha.com/v2/query", "method": "GET", "key_field": "appid", "key_location": "param", "fixed_params": {"format": "plaintext", "output": "json"}, "health_check_params": {"input": "2+2"}, "timeout": 10},
        {"key": WOLFRAM_APP_ID_2, "endpoint_name": "Query (AppID 2)", "url": "http://api.wolframalpha.com/v2/query", "method": "GET", "key_field": "appid", "key_location": "param", "fixed_params": {"format": "plaintext", "output": "json"}, "health_check_params": {"input": "2+2"}, "timeout": 10},
        {"key": WOLFRAM_APP_ID_3, "endpoint_name": "Query (AppID 3)", "url": "http://api.wolframalpha.com/v2/query", "method": "GET", "key_field": "appid", "key_location": "param", "fixed_params": {"format": "plaintext", "output": "json"}, "health_check_params": {"input": "2+2"}, "timeout": 10}
    ],
    "CLOUDMERSIVE": [
        {"key": CLOUDMERSIVE_KEY, "endpoint_name": "Domain Check", "url": "https://api.cloudmersive.com/validate/domain/check", "method": "POST", "key_field": "Apikey", "key_location": "header", "health_check_json": {"domain": "example.com"}, "timeout": 10}
    ],
    "GREYNOISE": [
        {"key": GREYNOISE_KEY, "endpoint_name": "IP Analysis", "url": "https://api.greynoise.io/v3/community/", "method": "GET", "key_field": "key", "key_location": "header", "health_check_url_suffix": "1.1.1.1", "timeout": 10}
    ],
    "PULSEDIVE": [
        {"key": PULSEDIVE_KEY, "endpoint_name": "API Info", "url": "https://pulsedive.com/api/info.php", "method": "GET", "key_field": "key", "key_location": "param", "health_check_params": {"key": PULSEDIVE_KEY}, "timeout": 5},
        {"key": PULSEDIVE_KEY, "endpoint_name": "Analyze IP", "url": "https://pulsedive.com/api/v1/analyze", "method": "GET", "key_field": "key", "key_location": "param", "health_check_params": {"indicator": "8.8.8.8", "type": "ip"}, "timeout": 10},
        {"key": PULSEDIVE_KEY, "endpoint_name": "Explore", "url": "https://pulsedive.com/api/v1/explore", "method": "GET", "key_field": "key", "key_location": "param", "health_check_params": {"query": "type='ip'"}, "timeout": 10}
    ],
    "STORMGLASS": [
        {"key": STORMGLASS_KEY, "endpoint_name": "Weather Point", "url": "https://api.stormglass.io/v2/weather/point", "method": "GET", "key_field": "Authorization", "key_location": "header", "health_check_params": {"lat": 0, "lng": 0, "params": "airTemperature", "start": 0, "end": 0}, "timeout": 10}
    ],
    "LOGINRADIUS": [
        {"key": LOGINRADIUS_KEY, "endpoint_name": "Ping", "url": "https://api.loginradius.com/identity/v2/auth/ping", "method": "GET", "timeout": 5}
    ],
    "JSONBIN": [
        {"key": JSONBIN_KEY, "endpoint_name": "Bin Access", "url": "https://api.jsonbin.io/v3/b", "method": "GET", "key_field": "X-Master-Key", "key_location": "header", "health_check_url_suffix": "60c7b0e0f8c2a3b4c5d6e7f0", "timeout": 10},
        {"key": JSONBIN_KEY, "endpoint_name": "Bin Create", "url": "https://api.jsonbin.io/v3/b", "method": "POST", "key_field": "X-Master-Key", "key_location": "header", "health_check_json": {"record": {"test": "health"}}, "timeout": 10}
    ],
    "HUGGINGFACE": [
        {"key": HUGGINGFACE_KEY_1, "endpoint_name": "Models List (Key 1)", "url": "https://huggingface.co/api/models", "method": "GET", "key_field": "Authorization", "key_location": "header", "key_prefix": "Bearer ", "timeout": 10},
        {"key": HUGGINGFACE_KEY_1, "endpoint_name": "BERT Inference", "url": "https://api-inference.huggingface.co/models/bert-base-uncased", "method": "POST", "key_field": "Authorization", "key_location": "header", "key_prefix": "Bearer ", "health_check_json": {"inputs": "test"}, "timeout": 30},
        {"key": HUGGINGFACE_KEY_2, "endpoint_name": "Models List (Key 2)", "url": "https://huggingface.co/api/models", "method": "GET", "key_field": "Authorization", "key_location": "header", "key_prefix": "Bearer ", "timeout": 10},
        {"key": HUGGINGFACE_KEY_3, "endpoint_name": "Models List (Key 3)", "url": "https://huggingface.co/api/models", "method": "GET", "key_field": "Authorization", "key_location": "header", "key_prefix": "Bearer ", "timeout": 10},
        {"key": HUGGINGFACE_NEW_KEY, "endpoint_name": "Models List (New Key)", "url": "https://huggingface.co/api/models", "method": "GET", "key_field": "Authorization", "key_location": "header", "key_prefix": "Bearer ", "timeout": 10},
        {"key": HUGGINGFACE_NEW_KEY, "endpoint_name": "BERT Inference (New Key)", "url": "https://api-inference.huggingface.co/models/bert-base-uncased", "method": "POST", "key_field": "Authorization", "key_location": "header", "key_prefix": "Bearer ", "health_check_json": {"inputs": "test"}, "timeout": 30}
    ],
    "TWILIO": [
        {"key": (TWILIO_SID, TWILIO_SECRET), "endpoint_name": "Accounts", "url": "https://api.twilio.com/2010-04-01/Accounts", "method": "GET", "key_location": "auth_basic", "timeout": 10},
        {"key": (TWILIO_SID, TWILIO_SECRET), "endpoint_name": "Account Balance", "url": f"https://api.twilio.com/2010-04-01/Accounts/{TWILIO_SID}/Balance.json", "method": "GET", "key_location": "auth_basic", "timeout": 10}
    ],
    "ABSTRACTAPI": [
        {"key": ABSTRACTAPI_EMAIL_KEY_1, "endpoint_name": "Email Validation (Key 1)", "url": "https://emailvalidation.abstractapi.com/v1/", "method": "GET", "key_field": "api_key", "key_location": "param", "health_check_params": {"email": "test@example.com"}, "timeout": 10},
        {"key": ABSTRACTAPI_EMAIL_KEY_2, "endpoint_name": "Email Validation (Key 2)", "url": "https://emailvalidation.abstractapi.com/v1/", "method": "GET", "key_field": "api_key", "key_location": "param", "health_check_params": {"email": "test@example.com"}, "timeout": 10},
        {"key": ABSTRACTAPI_EMAIL_KEY_3, "endpoint_name": "Email Validation (Key 3)", "url": "https://emailvalidation.abstractapi.com/v1/", "method": "GET", "key_field": "api_key", "key_location": "param", "health_check_params": {"email": "test@example.com"}, "timeout": 10},
        {"key": ABSTRACTAPI_GENERIC_KEY, "endpoint_name": "Exchange Rates", "url": "https://exchange-rates.abstractapi.com/v1/", "method": "GET", "key_field": "api_key", "key_location": "param", "health_check_params": {"base": "USD"}, "timeout": 10},
        {"key": ABSTRACTAPI_GENERIC_KEY, "endpoint_name": "Holidays", "url": "https://holidays.abstractapi.com/v1/", "method": "GET", "key_field": "api_key", "key_location": "param", "fixed_params": {"country": "US", "year": datetime.now().year}, "health_check_params": {"country": "US", "year": datetime.now().year}, "timeout": 10},
        {"key": ABSTRACTAPI_GENERIC_KEY, "endpoint_name": "Phone Validation", "url": "https://phonevalidation.abstractapi.com/v1/", "method": "GET", "key_field": "api_key", "key_location": "param", "health_check_params": {"phone": "1234567890"}, "timeout": 10}
    ],
    "GEMINI_API": [ # Note: This is for the generic APIClient, GeminiApiClient class uses GEMINI_API_KEY directly
        {"key": GEMINI_API_KEY, "endpoint_name": "Generic Models Endpoint", "url": "https://generativelanguage.googleapis.com/v1beta/models", "method": "GET", "key_field": "key", "key_location": "param", "timeout": 10},
        {"key": GEMINI_API_KEY, "endpoint_name": "Embed Content", "url": "https://generativelanguage.googleapis.com/v1beta/models/embedding-001:embedContent", "method": "POST", "key_field": "key", "key_location": "param", "health_check_json": {"content": {"parts": [{"text": "test"}]}}, "timeout": 30},
        {"key": GEMINI_API_KEY, "endpoint_name": "Generate Content", "url": "https://generativelanguage.googleapis.com/v1beta/models/gemini-1.5-flash:generateContent", "method": "POST", "key_field": "key", "key_location": "param", "health_check_json": {"contents": [{"parts": [{"text": "hello"}]}]}, "timeout": 60}
    ],
    "GOOGLE_CUSTOM_SEARCH": [
        {"key": GOOGLE_API_KEYS[i], "endpoint_name": f"Search (Key {i+1}, CX {j+1})", "url": "https://www.googleapis.com/customsearch/v1", "method": "GET", "key_field": "key", "key_location": "param", "fixed_params": {"cx": GOOGLE_CX_LIST[j]}, "health_check_params": {"q": "test"}, "timeout": 10}
        for i in range(len(GOOGLE_API_KEYS)) for j in range(len(GOOGLE_CX_LIST))
    ],
    "RANDOMMER": [
        {"key": RANDOMMER_KEY, "endpoint_name": "Generate Phone", "url": "https://randommer.io/api/Phone/Generate", "method": "GET", "key_field": "X-Api-Key", "key_location": "header", "fixed_params": {"CountryCode": "US", "Quantity": 1}, "health_check_params": {"CountryCode": "US", "Quantity": 1}, "timeout": 10}
    ],
    "TOMORROW.IO": [
        {"key": TOMORROW_KEY, "endpoint_name": "Timelines", "url": "https://api.tomorrow.io/v4/timelines", "method": "POST", "key_field": "apikey", "key_location": "header", "health_check_json": {"location": "London", "fields": ["temperature"], "units": "metric", "timesteps": ["1h"]}, "timeout": 15}
    ],
    "OPENWEATHERMAP": [
        {"key": OPENWEATHER_API_KEY, "endpoint_name": "Current Weather", "url": "https://api.openweathermap.org/data/2.5/weather", "method": "GET", "key_field": "appid", "key_location": "param", "health_check_params": {"q": "London"}, "timeout": 5}
    ],
    "MOCKAROO": [
        {"key": MOCKAROO_KEY, "endpoint_name": "Data Generation", "url": "https://api.mockaroo.com/api/generate.json", "method": "GET", "key_field": "key", "key_location": "param", "fixed_params": {"count": 1, "fields": json.dumps([{"name": "id", "type": "Row Number"}])}, "health_check_params": {"count": 1, "fields": json.dumps([{"name": "id", "type": "Row Number"}])}, "timeout": 10},
        {"key": MOCKAROO_KEY, "endpoint_name": "Types", "url": "https://api.mockaroo.com/api/types", "method": "GET", "key_field": "key", "key_location": "param", "timeout": 10},
        {"key": MOCKAROO_KEY, "endpoint_name": "Schemas", "url": "https://api.mockaroo.com/api/schemas", "method": "GET", "key_field": "key", "key_location": "param", "timeout": 10},
        {"key": MOCKAROO_KEY, "endpoint_name": "Account", "url": "https://api.mockaroo.com/api/account", "method": "GET", "key_field": "key", "key_location": "param", "timeout": 10},
        {"key": MOCKAROO_KEY, "endpoint_name": "Generate CSV", "url": "https://api.mockaroo.com/api/generate.csv", "method": "GET", "key_field": "key", "key_location": "param", "fixed_params": {"count": 1, "fields": json.dumps([{"name": "id", "type": "Row Number"}])}, "health_check_params": {"count": 1, "fields": json.dumps([{"name": "id", "type": "Row Number"}])}, "timeout": 10},
        {"key": MOCKAROO_KEY, "endpoint_name": "Status", "url": "https://api.mockaroo.com/api/status", "method": "GET", "key_field": "key", "key_location": "param", "timeout": 10}
    ],
    "OPENPAGERANK": [
        {"key": OPENPAGERANK_KEY, "endpoint_name": "Domain Rank", "url": "https://openpagerank.com/api/v1.0/getPageRank", "method": "GET", "key_field": "API-OPR", "key_location": "header", "fixed_params": {"domains[]": "google.com"}, "timeout": 10}
    ],
    "RAPIDAPI": [
        {"key": RAPIDAPI_KEY, "endpoint_name": "Programming Joke", "url": "https://jokeapi-v2.p.rapidapi.com/joke/Programming", "method": "GET", "key_field": "X-RapidAPI-Key", "key_location": "header", "fixed_headers": {"X-RapidAPI-Host": "jokeapi-v2.p.rapidapi.com"}, "timeout": 10},
        {"key": RAPIDAPI_KEY, "endpoint_name": "Currency List Quotes", "url": "https://currency-exchange.p.rapidapi.com/listquotes", "method": "GET", "key_field": "X-RapidAPI-Key", "key_location": "header", "fixed_headers": {"X-RapidAPI-Host": "currency-exchange.p.rapidapi.com"}, "timeout": 10},
        {"key": RAPIDAPI_KEY, "endpoint_name": "Random Fact", "url": "https://random-facts2.p.rapidapi.com/getfact", "method": "GET", "key_field": "X-RapidAPI-Key", "key_location": "header", "fixed_headers": {"X-RapidAPI-Host": "random-facts2.p.rapidapi.com"}, "timeout": 10}
    ],
    "OCR_API": [ # Note: This is for the generic APIClient, OCRApiClient class uses OCR_API_KEY directly
        {"key": OCR_API_KEYS[0], "endpoint_name": "OCR Space (Key 1)", "url": "https://api.ocr.space/parse/image", "method": "POST", "key_field": "apikey", "key_location": "header", "health_check_json": {"base64Image": "data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAEAAAABCAQAAAC1HAwCAAAAC0lEQVR42mNkYAAAAAYAAjCB0C8AAAAASUVORK5CYII="}, "timeout": 30},
        {"key": OCR_API_KEYS[1], "endpoint_name": "OCR Space (Key 2)", "url": "https://api.ocr.space/parse/image", "method": "POST", "key_field": "apikey", "key_location": "header", "health_check_json": {"base64Image": "data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAEAAAABCAQAAAC1HAwCAAAAC0lEQVR42mNkYAAAAAYAAjCB0C8AAAAASUVORK5CYII="}, "timeout": 30},
        {"key": OCR_API_KEYS[2], "endpoint_name": "OCR Space (Key 3)", "url": "https://api.ocr.space/parse/image", "method": "POST", "key_field": "apikey", "key_location": "header", "health_check_json": {"base64Image": "data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAEAAAABCAQAAAC1HAwCAAAAC0lEQVR42mNkYAAAAAYAAjCB0C8AAAAASUVORK5CYII="}, "timeout": 30},
    ]
}

# ==== Quotas API (D√©finitions des limites pour le QuotaManager) ====
# Ces valeurs sont utilis√©es pour le suivi et la gestion des quotas d'utilisation.
# Mettre None pour indiquer une limite illimit√©e.
API_QUOTAS = {
    "gemini": {
        "monthly": 1000000, # Exemple: 1 million de tokens par mois
        "daily": 50000,    # Exemple: 50 000 tokens par jour
        "hourly": 5000,    # Exemple: 5 000 tokens par heure
        "rate_limit_per_sec": 5 # Exemple: 5 requ√™tes par seconde
    },
    "ocr_space": { # Nom interne utilis√© par OCRApiClient
        "monthly": 25000,  # Exemple: 25 000 requ√™tes par mois (free tier)
        "daily": None,
        "hourly": None,
        "rate_limit_per_sec": 1 # Exemple: 1 requ√™te par seconde
    },
    # Ajouter les quotas pour toutes les APIs list√©es dans API_CONFIG si elles ont des limites
    # Utiliser les valeurs du premier snippet si non sp√©cifi√©es ici
    "APIFLASH": {"monthly": 100, "daily": 3, "hourly": 3},
    "DEEPSEEK": {"monthly": None, "hourly": 50},
    "CRAWLBASE": {"monthly": 1000, "daily": 33, "hourly": 1},
    "DETECTLANGUAGE": {"daily": 1000, "hourly": 41},
    "GUARDIAN": {"daily": 5000, "rate_limit_per_sec": 12},
    "IP2LOCATION": {"monthly": 50, "daily": 2, "hourly": 2},
    "SERPER": {"monthly": 2500, "daily": 83, "hourly": 3},
    "SHODAN": {"monthly": 100, "daily": 3, "hourly": 3},
    "TAVILY": {"monthly": 1000, "daily": 33, "hourly": 1},
    "WEATHERAPI": {"monthly": None},
    "WOLFRAMALPHA": {"monthly": None, "hourly": 67},
    "CLOUDMERSIVE": {"monthly": 25, "daily": 1, "hourly": 1},
    "GREYNOISE": {"monthly": 100, "daily": 3, "hourly": 3},
    "PULSEDIVE": {"monthly": 50, "daily": 2, "hourly": 2},
    "STORMGLASS": {"monthly": None},
    "LOGINRADIUS": {"monthly": 25000, "daily": 833, "hourly": 34},
    "JSONBIN": {"monthly": 10000, "daily": 333, "hourly": 13},
    "HUGGINGFACE": {"hourly": 100},
    "TWILIO": {"monthly": 15},
    "ABSTRACTAPI": {"monthly": 250, "rate_limit_per_sec": 1, "daily": 8, "hourly": 1},
    "MOCKAROO": {"monthly": 200, "daily": 7, "hourly": 1},
    "OPENPAGERANK": {"monthly": 1000, "daily": 33, "hourly": 1},
    "RAPIDAPI": {"monthly": None, "hourly": 30},
    "GOOGLE_CUSTOM_SEARCH": {"daily": 100, "hourly": 4},
    "RANDOMMER": {"monthly": 1000, "daily": 100, "hourly": 4},
    "TOMORROW.IO": {"monthly": None},
    "OPENWEATHERMAP": {"monthly": 1000000, "daily": 100, "hourly": 4},
    # "OCR_API" est d√©j√† g√©r√© par "ocr_space" pour la classe d√©di√©e.
    # Si d'autres clients OCR sont ajout√©s via APIClient, ils devraient √™tre list√©s ici.
}


import os
from pathlib import Path

# ==============================================================================
# Param√®tres G√©n√©raux du Bot
# ==============================================================================

# Token de votre bot Telegram
BOT_TOKEN = "7902342551:AAG6r1QA2GTMZcmcsWHi36Ivd_PVeMXULOs"

# ID du groupe priv√© o√π le bot enverra des notifications (ex: alertes quotas, archives)
PRIVATE_GROUP_ID = "-1001234567890"

# Message de d√©marrage affich√© dans la console au lancement du bot
STARTUP_MESSAGE = """
===================================================
üöÄ Bot IA D√©marr√© ! üöÄ
Version: 1.0.0
Pr√™t √† interagir. Tapez vos commandes ou questions.
===================================================
"""

# ==============================================================================
# Configuration des Chemins de Fichiers
# ==============================================================================

# R√©pertoire de base pour les donn√©es du bot (logs, historiques, quotas, etc.)
BASE_DIR = Path(__file__).parent.parent / "bot_data"
BASE_DIR.mkdir(parents=True, exist_ok=True)

# Chemin du fichier de log principal
LOG_FILE = BASE_DIR / "bot_activity.log"

# Chemin du fichier de log pour les erreurs critiques
ERROR_LOG_PATH = BASE_DIR / "bot_errors.log"

# Fichier pour stocker l'√©tat de sant√© des endpoints API
ENDPOINT_HEALTH_FILE = BASE_DIR / "endpoint_health.json"

# Fichier pour stocker les informations de quota d'utilisation des APIs
QUOTAS_FILE = BASE_DIR / "api_quotas.json"

# Fichier pour stocker le statut de performance et de diversification des IA
IA_STATUS_FILE = BASE_DIR / "ia_status.json"

# R√©pertoire pour archiver les pages web
ARCHIVES_DIR = "archives"

# Fichier pour stocker l'historique de chat de chaque utilisateur
USER_CHAT_HISTORY_FILE = "chat_history.json"

# Taille maximale des fichiers (ex: images pour OCR) en octets (10 MB)
MAX_FILE_SIZE = 10 * 1024 * 1024
MAX_IMAGE_SIZE = 10 * 1024 * 1024 # Taille maximale pour les images OCR

# ==============================================================================
# Configuration des APIs (Cl√©s et Param√®tres)
# ==============================================================================

# Cl√©s API (Hardcod√©es comme demand√©)
GEMINI_API_KEYS = [
    "YOUR_GEMINI_API_KEY_1",
    "YOUR_GEMINI_API_KEY_2"
]
OCR_API_KEYS = [
    "K8900987654321",
    "K1234567890987"
]
DEEPSEEK_API_KEYS = [
    "sk-ef08317d125947b3a1ce5916592bef00",
    "sk-d73750d96142421cb1098c7056dd7f01"
]
SERPER_API_KEY = "YOUR_SERPER_API_KEY_HERE"
WOLFRAMALPHA_APP_IDS = [
    "YOUR_WOLFRAMALPHA_APP_ID_1",
    "YOUR_WOLFRAMALPHA_APP_ID_2"
]
TAVILY_API_KEYS = [
    "YOUR_TAVILY_API_KEY_1",
    "YOUR_TAVILY_API_KEY_2"
]
APIFLASH_ACCESS_KEY = "YOUR_APIFLASH_ACCESS_KEY_HERE"
CRAWLBASE_API_KEY = "YOUR_CRAWLBASE_API_KEY_HERE"
DETECTLANGUAGE_API_KEY = "YOUR_DETECTLANGUAGE_API_KEY_HERE"
GUARDIAN_API_KEY = "YOUR_GUARDIAN_API_KEY_HERE"
IP2LOCATION_API_KEY = "YOUR_IP2LOCATION_API_KEY_HERE"
SHODAN_API_KEY = "YOUR_SHODAN_API_KEY_HERE"
WEATHERAPI_KEY = "YOUR_WEATHERAPI_KEY_HERE"
CLOUDMERSIVE_API_KEY = "YOUR_CLOUDMERSIVE_API_KEY_HERE"
GREYNOISE_API_KEY = "YOUR_GREYNOISE_API_KEY_HERE"
PULSEDIVE_API_KEY = "YOUR_PULSEDIVE_API_KEY_HERE"
STORMGLASS_API_KEY = "YOUR_STORMGLASS_API_KEY_HERE"
LOGINRADIUS_API_KEY = "YOUR_LOGINRADIUS_API_KEY_HERE"
JSONBIN_API_KEY = "YOUR_JSONBIN_API_KEY_HERE"
HUGGINGFACE_API_KEYS = [
    "hf_YOUR_HUGGINGFACE_API_KEY_1",
    "hf_YOUR_HUGGINGFACE_API_KEY_2"
]
TWILIO_ACCOUNT_SID = "ACxxxxxxxxxxxxxxxxxxxxxxxxxxxxx"
TWILIO_AUTH_TOKEN = "your_twilio_auth_token"
ABSTRACTAPI_API_KEYS = [
    "YOUR_ABSTRACTAPI_API_KEY_1",
    "YOUR_ABSTRACTAPI_API_KEY_2"
]
GOOGLE_CUSTOM_SEARCH_API_KEYS = [
    "YOUR_GOOGLE_CUSTOM_SEARCH_API_KEY_1",
    "YOUR_GOOGLE_CUSTOM_SEARCH_API_KEY_2"
]
GOOGLE_CUSTOM_SEARCH_CX_LIST = [
    "YOUR_GOOGLE_CUSTOM_SEARCH_CX_1",
    "YOUR_GOOGLE_CUSTOM_SEARCH_CX_2"
]
RANDOMMER_API_KEY = "YOUR_RANDOMMER_API_KEY_HERE"
TOMORROWIO_API_KEY = "YOUR_TOMORROWIO_API_KEY_HERE"
OPENWEATHERMAP_API_KEY = "YOUR_OPENWEATHERMAP_API_KEY_HERE"
MOCKAROO_API_KEY = "YOUR_MOCKAROO_API_KEY_HERE"
OPENPAGERANK_API_KEY = "YOUR_OPENPAGERANK_API_KEY_HERE"
RAPIDAPI_KEY = "YOUR_RAPIDAPI_KEY_HERE"


# Configuration d√©taill√©e des endpoints API
API_CONFIG = {
    "GEMINI_API": [
        {
            "endpoint_name": f"Gemini Chat (Key {i+1})",
            "url": "https://generativelanguage.googleapis.com/v1beta/models/gemini-1.5-flash-latest:generateContent",
            "method": "POST",
            "key": key,
            "key_field": "key",
            "key_location": "param",
            "timeout": 60,
            "health_check_params": {"prompt": "test"},
            "health_check_url_suffix": f"?key={key}"
        }
        for i, key in enumerate(GEMINI_API_KEYS)
    ],
    "OCR_API": [
        {
            "endpoint_name": f"OCR.space (Key {i+1})",
            "url": "https://api.ocr.space/parse/image",
            "method": "POST",
            "key": key,
            "key_field": "apikey",
            "key_location": "header",
            "timeout": 30,
            "fixed_headers": {"Content-Type": "application/json"},
            "health_check_json": {"base64Image": "data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAEAAAABCAQAAAC1HAwCAAAAC0lEQVR42mNkYAAAAAYAAjCB0C8AAAAASUVORK5CYII=", "language": "eng"}, # Minimal valid base64 for health check
        }
        for i, key in enumerate(OCR_API_KEYS)
    ],
    "DEEPSEEK": [
        {
            "endpoint_name": f"DeepSeek Chat (Key {i+1})",
            "url": "https://api.deepseek.com/chat/completions",
            "method": "POST",
            "key": key,
            "key_field": "Authorization",
            "key_location": "header",
            "key_prefix": "Bearer ",
            "timeout": 60,
            "fixed_headers": {"Content-Type": "application/json"},
            "health_check_json": {"model": "deepseek-chat", "messages": [{"role": "user", "content": "hi"}]}
        }
        for i, key in enumerate(DEEPSEEK_API_KEYS)
    ],
    "SERPER": [
        {
            "endpoint_name": "Serper Search",
            "url": "https://google.serper.dev/search",
            "method": "POST",
            "key": SERPER_API_KEY,
            "key_field": "X-API-KEY",
            "key_location": "header",
            "timeout": 30,
            "fixed_headers": {"Content-Type": "application/json"},
            "health_check_json": {"q": "test"}
        }
    ],
    "WOLFRAMALPHA": [
        {
            "endpoint_name": f"WolframAlpha Query (App ID {i+1})",
            "url": "http://api.wolframalpha.com/v2/query",
            "method": "GET",
            "key": app_id,
            "key_field": "appid",
            "key_location": "param",
            "timeout": 30,
            "fixed_params": {"output": "json"},
            "health_check_params": {"input": "2+2", "output": "json"}
        }
        for i, app_id in enumerate(WOLFRAMALPHA_APP_IDS)
    ],
    "TAVILY": [
        {
            "endpoint_name": f"Tavily Search (Key {i+1})",
            "url": "https://api.tavily.com/parse",
            "method": "POST",
            "key": key,
            "key_field": "apikey",
            "key_location": "header",
            "timeout": 30,
            "fixed_headers": {"Content-Type": "application/json"},
            "health_check_json": {"query": "test", "max_results": 1}
        }
        for i, key in enumerate(TAVILY_API_KEYS)
    ],
    "APIFLASH": [
        {
            "endpoint_name": "ApiFlash Screenshot",
            "url": "https://api.apiflash.com/v1/urltoimage",
            "method": "GET",
            "key": APIFLASH_ACCESS_KEY,
            "key_field": "access_key",
            "key_location": "param",
            "timeout": 45,
            "health_check_params": {"url": "example.com", "format": "jpeg"}
        }
    ],
    "CRAWLBASE": [
        {
            "endpoint_name": "Crawlbase Scraper",
            "url": "https://api.crawlbase.com/",
            "method": "GET",
            "key": CRAWLBASE_API_KEY,
            "key_field": "token",
            "key_location": "param",
            "timeout": 60,
            "health_check_params": {"url": "http://example.com", "format": "json"}
        },
        {
            "endpoint_name": "Crawlbase JS Scraper",
            "url": "https://api.crawlbase.com/js",
            "method": "GET",
            "key": CRAWLBASE_API_KEY,
            "key_field": "token",
            "key_location": "param",
            "timeout": 90,
            "health_check_params": {"url": "http://example.com", "format": "json"}
        }
    ],
    "DETECTLANGUAGE": [
        {
            "endpoint_name": "DetectLanguage Detect",
            "url": "https://ws.detectlanguage.com/0.2/detect",
            "method": "POST",
            "key": DETECTLANGUAGE_API_KEY,
            "key_field": "X-Detectlanguage-Api-Key",
            "key_location": "header",
            "timeout": 15,
            "fixed_headers": {"Content-Type": "application/json"},
            "health_check_json": {"q": "Hello world"}
        }
    ],
    "GUARDIAN": [
        {
            "endpoint_name": "Guardian Content",
            "url": "https://content.guardianapis.com/search",
            "method": "GET",
            "key": GUARDIAN_API_KEY,
            "key_field": "api-key",
            "key_location": "param",
            "timeout": 20,
            "health_check_params": {"q": "test"}
        }
    ],
    "IP2LOCATION": [
        {
            "endpoint_name": "IP2Location Geolocation",
            "url": "https://api.ip2location.com/v2/",
            "method": "GET",
            "key": IP2LOCATION_API_KEY,
            "key_field": "key",
            "key_location": "param",
            "timeout": 10,
            "health_check_params": {"ip": "8.8.8.8", "addon": "country,city"}
        }
    ],
    "SHODAN": [
        {
            "endpoint_name": "Shodan API Info",
            "url": "https://api.shodan.io/api-info",
            "method": "GET",
            "key": SHODAN_API_KEY,
            "key_field": "key",
            "key_location": "param",
            "timeout": 15,
            "health_check_url_suffix": f"?key={SHODAN_API_KEY}"
        },
        {
            "endpoint_name": "Shodan Host Info",
            "url": "https://api.shodan.io/shodan/host",
            "method": "GET",
            "key": SHODAN_API_KEY,
            "key_field": "key",
            "key_location": "param",
            "timeout": 20,
            "health_check_url_suffix": f"/8.8.8.8?key={SHODAN_API_KEY}"
        }
    ],
    "WEATHERAPI": [
        {
            "endpoint_name": "WeatherAPI Current",
            "url": "http://api.weatherapi.com/v1/current.json",
            "method": "GET",
            "key": WEATHERAPI_KEY,
            "key_field": "key",
            "key_location": "param",
            "timeout": 15,
            "health_check_params": {"q": "London"}
        }
    ],
    "CLOUDMERSIVE": [
        {
            "endpoint_name": "Cloudmersive Validate Domain",
            "url": "https://api.cloudmersive.com/validate/domain/full",
            "method": "POST",
            "key": CLOUDMERSIVE_API_KEY,
            "key_field": "Apikey",
            "key_location": "header",
            "timeout": 20,
            "fixed_headers": {"Content-Type": "application/json"},
            "health_check_json": {"domain": "example.com"}
        }
    ],
    "GREYNOISE": [
        {
            "endpoint_name": "GreyNoise IP Lookup",
            "url": "https://api.greynoise.io/v3/community",
            "method": "GET",
            "key": GREYNOISE_API_KEY,
            "key_field": "key",
            "key_location": "header",
            "timeout": 20,
            "health_check_url_suffix": "/8.8.8.8"
        }
    ],
    "PULSEDIVE": [
        {
            "endpoint_name": "Pulsedive Indicator",
            "url": "https://pulsedive.com/api/v1/indicator.php",
            "method": "GET",
            "key": PULSEDIVE_API_KEY,
            "key_field": "key",
            "key_location": "param",
            "timeout": 25,
            "fixed_params": {"pretty": "1"},
            "health_check_params": {"indicator": "8.8.8.8", "pretty": "1"}
        }
    ],
    "STORMGLASS": [
        {
            "endpoint_name": "StormGlass Weather",
            "url": "https://api.stormglass.io/v2/weather/point",
            "method": "GET",
            "key": STORMGLASS_API_KEY,
            "key_field": "Authorization",
            "key_location": "header",
            "timeout": 30,
            "health_check_params": {"lat": 0, "lng": 0, "params": "airTemperature", "start": 0, "end": 0},
            "health_check_url_suffix": "?lat=0&lng=0&params=airTemperature&start=0&end=0"
        }
    ],
    "LOGINRADIUS": [
        {
            "endpoint_name": "LoginRadius Ping",
            "url": "https://api.loginradius.com/identity/v2/auth/ping",
            "method": "GET",
            "key": LOGINRADIUS_API_KEY,
            "key_field": "apiKey",
            "key_location": "param",
            "timeout": 10,
            "health_check_url_suffix": f"?apiKey={LOGINRADIUS_API_KEY}"
        }
    ],
    "JSONBIN": [
        {
            "endpoint_name": "Bin Create",
            "url": "https://api.jsonbin.io/v3/b",
            "method": "POST",
            "key": JSONBIN_API_KEY,
            "key_field": "X-Master-Key",
            "key_location": "header",
            "timeout": 20,
            "fixed_headers": {"Content-Type": "application/json", "X-Bin-Private": "true"},
            "health_check_json": {"test": "data"}
        },
        {
            "endpoint_name": "Bin Access",
            "url": "https://api.jsonbin.io/v3/b",
            "method": "GET",
            "key": JSONBIN_API_KEY,
            "key_field": "X-Master-Key",
            "key_location": "header",
            "timeout": 20,
            "health_check_url_suffix": "/60c7b9b0f1a9a87d2b7b7b7b"
        }
    ],
    "HUGGINGFACE": [
        {
            "endpoint_name": f"HuggingFace Inference (Key {i+1})",
            "url": "https://api-inference.huggingface.co/models/",
            "method": "POST",
            "key": key,
            "key_field": "Authorization",
            "key_location": "header",
            "key_prefix": "Bearer ",
            "timeout": 60,
            "fixed_headers": {"Content-Type": "application/json"},
            "health_check_url_suffix": "distilbert-base-uncased-finetuned-sst-2-english",
            "health_check_json": {"inputs": "Hello world"}
        }
        for i, key in enumerate(HUGGINGFACE_API_KEYS)
    ],
    "TWILIO": [
        {
            "endpoint_name": "Account Balance",
            "url": f"https://api.twilio.com/2010-04-01/Accounts/{TWILIO_ACCOUNT_SID}/Balance.json",
            "method": "GET",
            "key": (TWILIO_ACCOUNT_SID, TWILIO_AUTH_TOKEN),
            "key_location": "auth_basic",
            "timeout": 20,
            "health_check_url_suffix": ""
        }
    ],
    "ABSTRACTAPI": [
        {
            "endpoint_name": f"Email Validation (Key {i+1})",
            "url": "https://emailvalidation.abstractapi.com/v1/?",
            "method": "GET",
            "key": key,
            "key_field": "api_key",
            "key_location": "param",
            "timeout": 15,
            "health_check_params": {"email": "test@example.com"}
        }
        for i, key in enumerate(ABSTRACTAPI_API_KEYS)
    ] + [
        {
            "endpoint_name": f"Phone Validation (Key {i+1})",
            "url": "https://phonevalidation.abstractapi.com/v1/?",
            "method": "GET",
            "key": key,
            "key_field": "api_key",
            "key_location": "param",
            "timeout": 15,
            "health_check_params": {"phone": "14151234567"}
        }
        for i, key in enumerate(ABSTRACTAPI_API_KEYS)
    ] + [
        {
            "endpoint_name": f"Exchange Rates (Key {i+1})",
            "url": "https://exchangerates.abstractapi.com/v1/live",
            "method": "GET",
            "key": key,
            "key_field": "api_key",
            "key_location": "param",
            "timeout": 15,
            "health_check_params": {"base": "USD"}
        }
        for i, key in enumerate(ABSTRACTAPI_API_KEYS)
    ] + [
        {
            "endpoint_name": f"Holidays (Key {i+1})",
            "url": "https://holidays.abstractapi.com/v1/",
            "method": "GET",
            "key": key,
            "key_field": "api_key",
            "key_location": "param",
            "timeout": 15,
            "health_check_params": {"country": "US", "year": "2023", "month": "1", "day": "1"}
        }
        for i, key in enumerate(ABSTRACTAPI_API_KEYS)
    ],
    "GOOGLE_CUSTOM_SEARCH": [
        {
            "endpoint_name": f"Google Custom Search (API Key {i+1}, CX {j+1})",
            "url": "https://www.googleapis.com/customsearch/v1",
            "method": "GET",
            "key": GOOGLE_CUSTOM_SEARCH_API_KEYS[i],
            "key_field": "key",
            "key_location": "param",
            "timeout": 30,
            "fixed_params": {"cx": GOOGLE_CUSTOM_SEARCH_CX_LIST[j]},
            "health_check_params": {"q": "test", "cx": GOOGLE_CUSTOM_SEARCH_CX_LIST[j]}
        }
        for i in range(len(GOOGLE_CUSTOM_SEARCH_API_KEYS))
        for j in range(len(GOOGLE_CUSTOM_SEARCH_CX_LIST))
    ],
    "RANDOMMER": [
        {
            "endpoint_name": "Randommer Phone Numbers",
            "url": "https://randommer.io/api/Phone/Generate",
            "method": "GET",
            "key": RANDOMMER_API_KEY,
            "key_field": "X-Api-Key",
            "key_location": "header",
            "timeout": 15,
            "fixed_headers": {"Content-Type": "application/json"},
            "health_check_params": {"CountryCode": "US", "Quantity": 1}
        }
    ],
    "TOMORROW.IO": [
        {
            "endpoint_name": "Tomorrow.io Weather",
            "url": "https://api.tomorrow.io/v4/weather/realtime",
            "method": "GET",
            "key": TOMORROWIO_API_KEY,
            "key_field": "apikey",
            "key_location": "param",
            "timeout": 20,
            "health_check_params": {"location": "42.3478,-71.0466", "fields": "temperature"}
        }
    ],
    "OPENWEATHERMAP": [
        {
            "endpoint_name": "OpenWeatherMap Current",
            "url": "https://api.openweathermap.org/data/2.5/weather",
            "method": "GET",
            "key": OPENWEATHERMAP_API_KEY,
            "key_field": "appid",
            "key_location": "param",
            "timeout": 15,
            "health_check_params": {"q": "London"}
        }
    ],
    "MOCKAROO": [
        {
            "endpoint_name": "Mockaroo Generate Data",
            "url": "https://api.mockaroo.com/api/generate.json",
            "method": "GET",
            "key": MOCKAROO_API_KEY,
            "key_field": "key",
            "key_location": "param",
            "timeout": 30,
            "health_check_params": {"count": 1, "fields": '[{"name":"id","type":"Row Number"}]'}
        }
    ],
    "OPENPAGERANK": [
        {
            "endpoint_name": "OpenPageRank Domains",
            "url": "https://openpagerank.com/api/v1.0/getPageRank",
            "method": "GET",
            "key": OPENPAGERANK_API_KEY,
            "key_field": "api_key",
            "key_location": "param",
            "timeout": 20,
            "health_check_params": {"domains[]": ["google.com"]}
        }
    ],
    "RAPIDAPI": [
        {
            "endpoint_name": "RapidAPI Programming Joke",
            "url": "https://programming-jokes-api.p.rapidapi.com/jokes/random",
            "method": "GET",
            "key": RAPIDAPI_KEY,
            "key_field": "X-RapidAPI-Key",
            "key_location": "header",
            "timeout": 20,
            "fixed_headers": {"X-RapidAPI-Host": "programming-jokes-api.p.rapidapi.com"},
            "health_check_url_suffix": ""
        },
        {
            "endpoint_name": "RapidAPI Currency List Quotes",
            "url": "https://currency-exchange.p.rapidapi.com/listquotes",
            "method": "GET",
            "key": RAPIDAPI_KEY,
            "key_field": "X-RapidAPI-Key",
            "key_location": "header",
            "timeout": 20,
            "fixed_headers": {"X-RapidAPI-Host": "currency-exchange.p.rapidapi.com"},
            "health_check_url_suffix": ""
        },
        {
            "endpoint_name": "RapidAPI Random Fact",
            "url": "https://random-facts-api.p.rapidapi.com/api/random",
            "method": "GET",
            "key": RAPIDAPI_KEY,
            "key_field": "X-RapidAPI-Key",
            "key_location": "header",
            "timeout": 20,
            "fixed_headers": {"X-RapidAPI-Host": "random-facts-api.p.rapidapi.com"},
            "health_check_url_suffix": ""
        }
    ]
}

# ==============================================================================
# Configuration des Mod√®les Gemini
# ==============================================================================

# Param√®tres de g√©n√©ration pour l'API Gemini
GEMINI_TEMPERATURE = 0.7
GEMINI_TOP_P = 0.95
GEMINI_TOP_K = 40
GEMINI_MAX_OUTPUT_TOKENS = 8192

# Param√®tres de s√©curit√© pour l'API Gemini
GEMINI_SAFETY_SETTINGS = [
    {"category": "HARM_CATEGORY_HARASSMENT", "threshold": "BLOCK_NONE"},
    {"category": "HARM_CATEGORY_HATE_SPEECH", "threshold": "BLOCK_NONE"},
    {"category": "HARM_CATEGORY_SEXUALLY_EXPLICIT", "threshold": "BLOCK_NONE"},
    {"category": "HARM_CATEGORY_DANGEROUS_CONTENT", "threshold": "BLOCK_NONE"},
]

# ==============================================================================
# Configuration des Outils (Tool Calling)
# ==============================================================================

# D√©finition des outils que le bot peut utiliser via le "Function Calling"
TOOL_CONFIG = {
    "serper_query": {
        "description": "Effectue une recherche web via l'API Serper et retourne les snippets pertinents.",
        "parameters": {
            "type": "object",
            "properties": {
                "query_text": {"type": "string", "description": "La requ√™te de recherche."}
            },
            "required": ["query_text"]
        }
    },
    "wolframalpha_query": {
        "description": "Interroge WolframAlpha pour des calculs, des faits ou des donn√©es complexes.",
        "parameters": {
            "type": "object",
            "properties": {
                "input_text": {"type": "string", "description": "La requ√™te √† soumettre √† WolframAlpha."}
            },
            "required": ["input_text"]
        }
    },
    "tavily_query": {
        "description": "Effectue une recherche web avanc√©e via l'API Tavily, fournissant des extraits et une r√©ponse directe.",
        "parameters": {
            "type": "object",
            "properties": {
                "query_text": {"type": "string", "description": "La requ√™te de recherche."},
                "max_results": {"type": "integer", "description": "Nombre maximum de r√©sultats √† retourner.", "default": 3}
            },
            "required": ["query_text"]
        }
    },
    "run_in_sandbox": {
        "description": "Ex√©cute du code Python ou Shell dans un environnement sandbox simul√© et retourne la sortie.",
        "parameters": {
            "type": "object",
            "properties": {
                "code": {"type": "string", "description": "Le code √† ex√©cuter."},
                "language": {"type": "string", "description": "Le langage du code ('python' ou 'shell').", "enum": ["python", "shell"], "default": "python"}
            },
            "required": ["code"]
        }
    },
    "perform_ocr_api": {
        "description": "Effectue une reconnaissance optique de caract√®res (OCR) sur une image donn√©e par URL et retourne le texte extrait.",
        "parameters": {
            "type": "object",
            "properties": {
                "image_url": {"type": "string", "description": "L'URL de l'image √† traiter par OCR."}
            },
            "required": ["image_url"]
        }
    },
    "fetch_and_archive_pages": {
        "description": "R√©cup√®re le contenu de pages web sp√©cifi√©es, les archive localement et envoie les liens d'archive au groupe priv√©.",
        "parameters": {
            "type": "object",
            "properties": {
                "links": {"type": "array", "items": {"type": "string"}, "description": "Liste des URLs des pages √† archiver."},
                "user_id": {"type": "string", "description": "L'ID de l'utilisateur demandant l'archivage."}
            },
            "required": ["links", "user_id"]
        }
    },
    "ocr_extract_text": {
        "description": "Extrait le texte d'une image encod√©e en base64 en utilisant l'OCR. Utile pour les images directement fournies dans le chat.",
        "parameters": {
            "type": "object",
            "properties": {
                "image_base64": {"type": "string", "description": "L'image encod√©e en base64, incluant le pr√©fixe mimeType (ex: 'data:image/png;base64,...')."}
            },
            "required": ["image_base64"]
        }
    },
    "apiflash_query": {
        "description": "Capture une capture d'√©cran d'une URL via ApiFlash et retourne l'URL de l'image captur√©e.",
        "parameters": {
            "type": "object",
            "properties": {
                "url": {"type": "string", "description": "L'URL de la page √† capturer."}
            },
            "required": ["url"]
        }
    },
    "crawlbase_query": {
        "description": "Scrape le contenu HTML ou JavaScript d'une URL via Crawlbase. Utilisez 'use_js' pour les pages dynamiques.",
        "parameters": {
            "type": "object",
            "properties": {
                "url": {"type": "string", "description": "L'URL de la page √† scraper."},
                "use_js": {"type": "boolean", "description": "D√©finir √† true pour le scraping JavaScript.", "default": False}
            },
            "required": ["url"]
        }
    },
    "detectlanguage_query": {
        "description": "D√©tecte la langue d'un texte via DetectLanguage API.",
        "parameters": {
            "type": "object",
            "properties": {
                "text": {"type": "string", "description": "Le texte dont la langue doit √™tre d√©tect√©e."}
            },
            "required": ["text"]
        }
    },
    "guardian_query": {
        "description": "Recherche des articles de presse via l'API The Guardian.",
        "parameters": {
            "type": "object",
            "properties": {
                "query_text": {"type": "string", "description": "La requ√™te de recherche pour les articles."}
            },
            "required": ["query_text"]
        }
    },
    "ip2location_query": {
        "description": "G√©olocalise une adresse IP via IP2Location API.",
        "parameters": {
            "type": "object",
            "properties": {
                "ip_address": {"type": "string", "description": "L'adresse IP √† g√©olocaliser."}
            },
            "required": ["ip_address"]
        }
    },
    "shodan_query": {
        "description": "Interroge Shodan pour des informations sur un h√¥te IP ou des informations sur la cl√© API.",
        "parameters": {
            "type": "object",
            "properties": {
                "query_text": {"type": "string", "description": "L'adresse IP √† rechercher ou vide pour les infos de la cl√© API."}
            },
            "required": []
        }
    },
    "weatherapi_query": {
        "description": "R√©cup√®re les conditions m√©t√©orologiques actuelles pour une localisation via WeatherAPI.",
        "parameters": {
            "type": "object",
            "properties": {
                "location": {"type": "string", "description": "La ville ou le code postal pour la m√©t√©o."}
            },
            "required": ["location"]
        }
    },
    "cloudmersive_query": {
        "description": "V√©rifie la validit√© et le type d'un domaine via Cloudmersive API.",
        "parameters": {
            "type": "object",
            "properties": {
                "domain": {"type": "string", "description": "Le nom de domaine √† v√©rifier."}
            },
            "required": ["domain"]
        }
    },
    "greynoise_query": {
        "description": "Analyse une adresse IP pour d√©tecter des activit√©s 'bruit' (malveillantes) via GreyNoise.",
        "parameters": {
            "type": "object",
            "properties": {
                "ip_address": {"type": "string", "description": "L'adresse IP √† analyser."}
            },
            "required": ["ip_address"]
        }
    },
    "pulsedive_query": {
        "description": "Analyse un indicateur de menace (IP, domaine, URL) via Pulsedive.",
        "parameters": {
            "type": "object",
            "properties": {
                "indicator": {"type": "string", "description": "L'indicateur de menace √† analyser (IP, domaine, URL)."},
                "type": {"type": "string", "description": "Le type d'indicateur ('auto', 'ip', 'domain', 'url').", "default": "auto"}
            },
            "required": ["indicator"]
        }
    },
    "stormglass_query": {
        "description": "R√©cup√®re les donn√©es m√©t√©orologiques maritimes pour une coordonn√©e (latitude, longitude) via StormGlass.",
        "parameters": {
            "type": "object",
            "properties": {
                "lat": {"type": "number", "format": "float", "description": "La latitude."},
                "lng": {"type": "number", "format": "float", "description": "La longitude."},
                "params": {"type": "string", "description": "Param√®tres m√©t√©o √† r√©cup√©rer (ex: 'airTemperature,waveHeight').", "default": "airTemperature,waveHeight"}
            },
            "required": ["lat", "lng"]
        }
    },
    "loginradius_query": {
        "description": "Effectue un simple ping √† l'API LoginRadius pour v√©rifier sa disponibilit√©.",
        "parameters": {
            "type": "object",
            "properties": {}
        }
    },
    "jsonbin_query": {
        "description": "Cr√©e un nouveau 'bin' JSON ou acc√®de √† un bin existant via Jsonbin.io.",
        "parameters": {
            "type": "object",
            "properties": {
                "data": {"type": "object", "description": "Les donn√©es JSON √† sauvegarder lors de la cr√©ation d'un bin.", "nullable": True},
                "private": {"type": "boolean", "description": "Indique si le bin doit √™tre priv√© (true) ou public (false).", "default": True},
                "bin_id": {"type": "string", "description": "L'ID du bin existant √† acc√©der (si pas de 'data').", "nullable": True}
            },
            "required": []
        }
    },
    "huggingface_query": {
        "description": "Effectue une inf√©rence sur un mod√®le HuggingFace (ex: classification de texte, g√©n√©ration).",
        "parameters": {
            "type": "object",
            "properties": {
                "model_name": {"type": "string", "description": "Le nom du mod√®le HuggingFace √† utiliser (ex: 'distilbert-base-uncased-finetuned-sst-2-english').", "default": "distilbert-base-uncased-finetuned-sst-2-english"},
                "input_text": {"type": "string", "description": "Le texte d'entr√©e pour l'inf√©rence."}
            },
            "required": ["input_text"]
        }
    },
    "twilio_query": {
        "description": "R√©cup√®re le solde du compte Twilio.",
        "parameters": {
            "type": "object",
            "properties": {}
        }
    },
    "abstractapi_query": {
        "description": "Interroge diverses APIs d'AbstractAPI (validation email/t√©l√©phone, taux de change, jours f√©ri√©s).",
        "parameters": {
            "type": "object",
            "properties": {
                "input_value": {"type": "string", "description": "La valeur d'entr√©e (email, num√©ro de t√©l√©phone, code pays, devise de base)."},
                "api_type": {"type": "string", "description": "Le type d'API AbstractAPI √† utiliser ('PHONE_VALIDATION', 'EMAIL_VALIDATION', 'EXCHANGE_RATES', 'HOLIDAYS').", "enum": ["PHONE_VALIDATION", "EMAIL_VALIDATION", "EXCHANGE_RATES", "HOLIDAYS"]}
            },
            "required": ["api_type"]
        }
    },
    "google_custom_search_query": {
        "description": "Effectue une recherche personnalis√©e Google via l'API Custom Search.",
        "parameters": {
            "type": "object",
            "properties": {
                "query_text": {"type": "string", "description": "La requ√™te de recherche."}
            },
            "required": ["query_text"]
        }
    },
    "randommer_query": {
        "description": "G√©n√®re des num√©ros de t√©l√©phone al√©atoires via Randommer.io.",
        "parameters": {
            "type": "object",
            "properties": {
                "country_code": {"type": "string", "description": "Le code pays (ex: 'US', 'FR').", "default": "US"},
                "quantity": {"type": "integer", "description": "Le nombre de num√©ros √† g√©n√©rer.", "default": 1}
            },
            "required": []
        }
    },
    "tomorrowio_query": {
        "description": "R√©cup√®re les pr√©visions m√©t√©orologiques via Tomorrow.io.",
        "parameters": {
            "type": "object",
            "properties": {
                "location": {"type": "string", "description": "La localisation (nom de ville, code postal ou coordonn√©es)."},
                "fields": {"type": "array", "items": {"type": "string"}, "description": "Liste des champs m√©t√©o √† r√©cup√©rer (ex: ['temperature', 'humidity']).", "default": ["temperature", "humidity", "windSpeed"]}
            },
            "required": ["location"]
        }
    },
    "openweathermap_query": {
        "description": "R√©cup√®re les conditions m√©t√©orologiques actuelles pour une localisation via OpenWeatherMap.",
        "parameters": {
            "type": "object",
            "properties": {
                "location": {"type": "string", "description": "La ville ou le code postal pour la m√©t√©o."}
            },
            "required": ["location"]
        }
    },
    "mockaroo_query": {
        "description": "G√©n√®re des donn√©es de test via Mockaroo.",
        "parameters": {
            "type": "object",
            "properties": {
                "count": {"type": "integer", "description": "Le nombre d'enregistrements √† g√©n√©rer.", "default": 1},
                "fields_json": {"type": "string", "description": "Une cha√Æne JSON d√©crivant les champs √† g√©n√©rer (ex: '[{\"name\":\"name\",\"type\":\"Full Name\"}]').", "nullable": True}
            },
            "required": []
        }
    },
    "openpagerank_query": {
        "description": "R√©cup√®re le PageRank de domaines via OpenPageRank.",
        "parameters": {
            "type": "object",
            "properties": {
                "domains": {"type": "array", "items": {"type": "string"}, "description": "Liste des noms de domaine √† v√©rifier."}
            },
            "required": ["domains"]
        }
    },
    "rapidapi_query": {
        "description": "Interroge diverses APIs disponibles via RapidAPI (blagues, taux de change, faits al√©atoires).",
        "parameters": {
            "type": "object",
            "properties": {
                "api_name": {"type": "string", "description": "Le nom de l'API RapidAPI √† utiliser (ex: 'Programming Joke', 'Currency List Quotes', 'Random Fact').", "enum": ["Programming Joke", "Currency List Quotes", "Random Fact"]},
                "kwargs": {"type": "object", "description": "Arguments suppl√©mentaires sp√©cifiques √† l'API RapidAPI appel√©e.", "additionalProperties": True}
            },
            "required": ["api_name"]
        }
    }
}

# ==============================================================================
# Param√®tres du Chat et de la M√©moire
# ==============================================================================

# Longueur maximale de l'historique du chat √† conserver en m√©moire et sur disque
MAX_CHAT_HISTORY_LENGTH = 20

# ==============================================================================
# Param√®tres des Checks de Sant√© des Endpoints
# ==============================================================================

# Activer ou d√©sactiver les checks de sant√© p√©riodiques des endpoints API
ENABLE_HEALTH_CHECKS = True

# Intervalle en secondes entre chaque ex√©cution des checks de sant√©
HEALTH_CHECK_INTERVAL_SECONDS = 2700

import json
import logging
from datetime import datetime, timezone
from pathlib import Path
import re
import asyncio
import os
from typing import Any, Optional, Dict

# Import des constantes du fichier de configuration
from config import LOG_FILE, ERROR_LOG_PATH, BASE_DIR, MAX_FILE_SIZE, API_CONFIG, TOOL_CONFIG

# ==== Configuration du logging ====
# Configure le logger principal pour le bot
logger = logging.getLogger("bot_logger")
logger.setLevel(logging.INFO)

# Cr√©e le r√©pertoire de base si n√©cessaire
BASE_DIR.mkdir(parents=True, exist_ok=True)

# Gestionnaire pour le fichier de log principal
file_handler = logging.FileHandler(LOG_FILE)
file_handler.setLevel(logging.INFO)
formatter = logging.Formatter('%(asctime)s - %(levelname)s - %(message)s')
file_handler.setFormatter(formatter)
logger.addHandler(file_handler)

# Gestionnaire pour les erreurs critiques (fichier s√©par√©)
error_file_handler = logging.FileHandler(ERROR_LOG_PATH)
error_file_handler.setLevel(logging.ERROR)
error_file_handler.setFormatter(formatter)
logger.addHandler(error_file_handler)

# Gestionnaire pour la console (logs en temps r√©el)
console_handler = logging.StreamHandler()
console_handler.setLevel(logging.INFO)
console_handler.setFormatter(formatter)
logger.addHandler(console_handler)

# Verrou pour les op√©rations de fichier asynchrones
_file_lock: Optional[asyncio.Lock] = None

def set_file_lock(lock: asyncio.Lock):
    """D√©finit l'instance du verrou asyncio pour les op√©rations de fichier."""
    global _file_lock
    _file_lock = lock

def log_message(message: str, level: str = "info"):
    """
    Enregistre un message dans le fichier de log et la console.
    Args:
        message (str): Le message √† enregistrer.
        level (str): Le niveau de log ('debug', 'info', 'warning', 'error', 'critical').
    """
    if level == "debug":
        logger.debug(message)
    elif level == "info":
        logger.info(message)
    elif level == "warning":
        logger.warning(message)
    elif level == "error":
        logger.error(message)
    elif level == "critical":
        logger.critical(message)
    else:
        logger.info(f"Niveau de log inconnu '{level}': {message}")

def get_current_time() -> datetime:
    """Retourne l'heure actuelle en UTC."""
    return datetime.now(timezone.utc)

def format_datetime(dt: datetime) -> str:
    """Formate un objet datetime en cha√Æne de caract√®res lisible."""
    return dt.strftime("%Y-%m-%d %H:%M:%S UTC")

async def load_json(file_path: Path, default_value: Any = None) -> Any:
    """
    Charge les donn√©es d'un fichier JSON de mani√®re asynchrone.
    Cr√©e le fichier avec une valeur par d√©faut si inexistant.
    Args:
        file_path (Path): Le chemin du fichier JSON.
        default_value (Any): La valeur √† retourner si le fichier n'existe pas ou est vide.
    Returns:
        Any: Le contenu du fichier JSON ou la valeur par d√©faut.
    """
    if _file_lock is None:
        log_message("Le verrou de fichier n'est pas initialis√© dans utils.py. Initialisation par d√©faut.", level="warning")
        global _file_lock
        _file_lock = asyncio.Lock()

    try:
        if not file_path.exists():
            log_message(f"Fichier non trouv√©: {file_path}. Cr√©ation avec valeur par d√©faut.", level="info")
            await save_json(file_path, default_value if default_value is not None else {})
            return default_value if default_value is not None else {}
        
        async with _file_lock:
            return await asyncio.to_thread(_load_json_sync, file_path)
    except json.JSONDecodeError:
        log_message(f"Erreur de d√©codage JSON pour le fichier: {file_path}. Le fichier pourrait √™tre corrompu. Retourne la valeur par d√©faut.", level="error")
        await save_json(file_path, default_value if default_value is not None else {})
        return default_value if default_value is not None else {}
    except Exception as e:
        log_message(f"Erreur inattendue lors du chargement du JSON {file_path}: {e}", level="error")
        return default_value if default_value is not None else {}

def _load_json_sync(file_path: Path) -> Any:
    """Fonction synchrone pour charger le JSON, appel√©e par asyncio.to_thread."""
    with open(file_path, 'r', encoding='utf-8') as f:
        return json.load(f)

async def save_json(file_path: Path, data: Any):
    """
    Sauvegarde les donn√©es dans un fichier JSON de mani√®re asynchrone.
    Args:
        file_path (Path): Le chemin du fichier JSON.
        data (Any): Les donn√©es √† sauvegarder.
    """
    if _file_lock is None:
        log_message("Le verrou de fichier n'est pas initialis√© dans utils.py. Initialisation par d√©faut.", level="warning")
        global _file_lock
        _file_lock = asyncio.Lock()

    try:
        file_path.parent.mkdir(parents=True, exist_ok=True)
        
        async with _file_lock:
            await asyncio.to_thread(_save_json_sync, file_path, data)
        log_message(f"Donn√©es sauvegard√©es dans {file_path}", level="debug")
    except Exception as e:
        log_message(f"Erreur lors de la sauvegarde du JSON {file_path}: {e}", level="error")

def _save_json_sync(file_path: Path, data: Any):
    """Fonction synchrone pour sauvegarder le JSON, appel√©e par asyncio.to_thread."""
    with open(file_path, 'w', encoding='utf-8') as f:
        json.dump(data, f, indent=4)

def neutralize_urls(text: str) -> str:
    """
    Remplace les URLs dans le texte par une version neutralis√©e pour √©viter les probl√®mes de s√©curit√©
    ou les tentatives d'acc√®s non d√©sir√©es par le mod√®le.
    """
    url_pattern = re.compile(r'https?://[^\s/$.?#].[^\s]*', re.IGNORECASE)
    
    neutralized_text = url_pattern.sub("[LIEN_NEUTRALIS√â]", text)
    return neutralized_text

def find_tool_by_name(tool_name: str) -> Optional[Dict[str, Any]]:
    """
    Recherche un outil dans TOOL_CONFIG par son nom.
    Args:
        tool_name (str): Le nom de l'outil √† rechercher.
    Returns:
        Optional[Dict[str, Any]]: Le dictionnaire de configuration de l'outil si trouv√©, sinon None.
    """
    return TOOL_CONFIG.get(tool_name)

async def append_to_file(file_path: Path, content: str):
    """
    Ajoute du contenu √† un fichier, en cr√©ant le fichier/r√©pertoire si n√©cessaire.
    G√®re la rotation du fichier si sa taille d√©passe MAX_FILE_SIZE.
    """
    if _file_lock is None:
        log_message("Le verrou de fichier n'est pas initialis√© dans utils.py. Initialisation par d√©faut.", level="warning")
        global _file_lock
        _file_lock = asyncio.Lock()

    file_path.parent.mkdir(parents=True, exist_ok=True)

    if file_path.exists() and file_path.stat().st_size + len(content.encode('utf-8')) > MAX_FILE_SIZE:
        rotate_file(file_path)

    async with _file_lock:
        await asyncio.to_thread(_append_to_file_sync, file_path, content)

def _append_to_file_sync(file_path: Path, content: str):
    """Fonction synchrone pour ajouter du contenu √† un fichier."""
    with open(file_path, 'a', encoding='utf-8') as f:
        f.write(content + "\n")

def rotate_file(file_path: Path):
    """
    Effectue une rotation de fichier simple: renomme le fichier actuel avec un horodatage.
    """
    timestamp = datetime.now(timezone.utc).strftime("%Y%m%d_%H%M%S")
    new_path = file_path.parent / f"{file_path.stem}_{timestamp}{file_path.suffix}"
    try:
        os.rename(file_path, new_path)
        log_message(f"Fichier {file_path.name} renomm√© en {new_path.name} pour rotation.", level="info")
    except OSError as e:
        log_message(f"Erreur lors de la rotation du fichier {file_path.name}: {e}", level="error")

import time
import httpx
import json
import base64
import asyncio
import re 
import traceback
from typing import Dict, Any, Optional, Union, List, Tuple

# Import des constantes et fonctions utilitaires
from config import API_CONFIG, ENDPOINT_HEALTH_FILE, MAX_IMAGE_SIZE, GEMINI_TEMPERATURE, GEMINI_TOP_P, GEMINI_TOP_K, GEMINI_MAX_OUTPUT_TOKENS, GEMINI_SAFETY_SETTINGS
from utils import load_json, save_json, get_current_time, format_datetime, log_message, neutralize_urls

class EndpointHealthManager:
    """
    G√®re la sant√© des endpoints API et s√©lectionne le meilleur endpoint disponible
    en fonction de crit√®res comme la latence, le taux de succ√®s et le nombre d'erreurs.
    C'est un singleton pour s'assurer qu'il n'y a qu'une seule instance de gestionnaire de sant√©.
    """
    _instance = None
    _initialized = False

    def __new__(cls, *args, **kwargs):
        """Impl√©mente le patron de conception Singleton."""
        if cls._instance is None:
            cls._instance = super(cls, cls).__new__(cls)
        return cls._instance

    def __init__(self):
        """Initialise le gestionnaire."""
        if self._initialized:
            return
        self.health_status = {}

    async def init_manager(self):
        """
        Initialise le gestionnaire de sant√© de mani√®re asynchrone.
        Charge l'√©tat de sant√© persistant et s'assure que tous les endpoints sont suivis.
        """
        if not self._initialized:
            self.health_status = await load_json(ENDPOINT_HEALTH_FILE, {})
            self._initialize_health_status()
            self._initialized = True
            log_message("Gestionnaire de sant√© des endpoints initialis√©.")

    def _initialize_health_status(self):
        """
        Initialise ou met √† jour le statut de sant√© pour tous les endpoints configur√©s dans `API_CONFIG`.
        Ajoute les nouveaux endpoints et s'assure que toutes les cl√©s n√©cessaires sont pr√©sentes.
        """
        updated = False
        for service_name, endpoints_config in API_CONFIG.items():
            if service_name not in self.health_status:
                self.health_status[service_name] = {}
                updated = True
            for endpoint_config in endpoints_config:
                endpoint_key = f"{endpoint_config['endpoint_name']}-{str(endpoint_config['key'])}"
                if endpoint_key not in self.health_status[service_name]:
                    self.health_status[service_name][endpoint_key] = {
                        "latency": 0.0,
                        "success_rate": 1.0,
                        "last_checked": None,
                        "error_count": 0,
                        "total_checks": 0,
                        "is_healthy": True
                    }
                    updated = True
        if updated:
            asyncio.create_task(save_json(ENDPOINT_HEALTH_FILE, self.health_status))
            log_message("Statut de sant√© des endpoints initialis√©/mis √† jour.")

    async def run_health_check_for_service(self, service_name: str):
        """
        Ex√©cute des checks de sant√© pour tous les endpoints d'un service donn√©.
        Tente d'appeler l'endpoint avec des param√®tres de sant√© pr√©d√©finis.
        """
        endpoints_config = API_CONFIG.get(service_name)
        if not endpoints_config:
            log_message(f"Aucune configuration d'endpoint trouv√©e pour le service: {service_name}", level="warning")
            return

        log_message(f"Lancement du health check pour le service: {service_name}")
        for endpoint_config in endpoints_config:
            endpoint_key = f"{endpoint_config['endpoint_name']}-{str(endpoint_config['key'])}"
            start_time = time.monotonic()
            success = False
            try:
                request_method = endpoint_config.get("method", "GET")
                url = endpoint_config["url"]
                
                params = endpoint_config.get("health_check_params", endpoint_config.get("fixed_params", {})).copy()
                json_data = endpoint_config.get("health_check_json", endpoint_config.get("fixed_json", {})).copy()
                headers = endpoint_config.get("fixed_headers", {}).copy()
                auth = None
                
                check_timeout = endpoint_config.get("timeout", 5)

                if "health_check_url_suffix" in endpoint_config:
                    url += endpoint_config["health_check_url_suffix"]

                key_field = endpoint_config.get("key_field")
                key_location = endpoint_config.get("key_location")
                key_prefix = endpoint_config.get("key_prefix", "")
                api_key = endpoint_config["key"]

                if key_field and key_location:
                    if key_location == "param":
                        params[key_field] = api_key
                    elif key_location == "header":
                        headers[key_field] = f"{key_prefix}{api_key}"
                    elif key_location == "auth_basic":
                        if isinstance(api_key, tuple) and len(api_key) == 2:
                            auth = httpx.BasicAuth(api_key[0], api_key[1])
                        else:
                            log_message(f"Cl√© API pour auth_basic non valide pour {service_name}:{endpoint_key}", level="error")
                            success = False
                            continue

                async with httpx.AsyncClient(timeout=check_timeout) as client:
                    response = await client.request(request_method, url, params=params, headers=headers, json=json_data, auth=auth)
                    response.raise_for_status()
                    success = True
            except httpx.HTTPStatusError as e:
                log_level = "warning"
                if 400 <= e.response.status_code < 500 and e.response.status_code != 429:
                    log_level = "debug" 
                log_message(f"Health check pour {endpoint_key} ({service_name}) a √©chou√© (HTTP {e.response.status_code}): {e.response.text}", level=log_level)
                success = False
            except httpx.RequestError as e:
                log_message(f"Health check pour {endpoint_key} ({service_name}) a √©chou√© (R√©seau): {e}", level="warning")
                success = False
            except Exception as e:
                log_message(f"Health check pour {endpoint_key} ({service_name}) a √©chou√© (Inattendu): {e}", level="error")
                success = False
            finally:
                latency = time.monotonic() - start_time
                self.update_endpoint_health(service_name, endpoint_key, success, latency)
        log_message(f"Health check termin√© pour le service: {service_name}")

    def update_endpoint_health(self, service_name: str, endpoint_key: str, success: bool, latency: float):
        """
        Met √† jour le statut de sant√© d'un endpoint sp√©cifique.
        Utilise une moyenne glissante pour le taux de succ√®s et la latence.
        """
        if service_name not in self.health_status:
            self.health_status[service_name] = {}
        if endpoint_key not in self.health_status[service_name]:
            self.health_status[service_name][endpoint_key] = {
                "latency": 0.0,
                "success_rate": 1.0,
                "last_checked": None,
                "error_count": 0,
                "total_checks": 0,
                "is_healthy": True
            }

        status = self.health_status[service_name][endpoint_key]
        status["total_checks"] += 1
        status["last_checked"] = format_datetime(get_current_time())

        alpha = 0.1
        if success:
            status["error_count"] = max(0, status["error_count"] - 1)
            status["success_rate"] = status["success_rate"] * (1 - alpha) + 1.0 * alpha
            status["latency"] = status["latency"] * (1 - alpha) + latency * alpha
        else:
            status["error_count"] += 1
            status["success_rate"] = status["success_rate"] * (1 - alpha) + 0.0 * alpha
            status["latency"] = status["latency"] * (1 - alpha) + 10.0 * alpha 

        if status["error_count"] >= 3 or status["success_rate"] < 0.5:
            status["is_healthy"] = False
        else:
            status["is_healthy"] = True
        
        asyncio.create_task(save_json(ENDPOINT_HEALTH_FILE, self.health_status))
        log_message(f"Sant√© de {service_name}:{endpoint_key} mise √† jour: Succ√®s: {success}, Latence: {latency:.2f}s, Taux Succ√®s: {status['success_rate']:.2f}, Sain: {status['is_healthy']}", level="debug" if not status["is_healthy"] else "info")

    def get_best_endpoint(self, service_name: str) -> Optional[Dict]:
        """
        S√©lectionne le meilleur endpoint pour un service donn√© bas√© sur son statut de sant√©.
        Priorise les endpoints sains, puis les moins mauvais en cas d'absence d'endpoints sains.
        """
        service_health = self.health_status.get(service_name)
        if not service_health:
            log_message(f"Aucune donn√©e de sant√© pour le service {service_name}. Retourne None.", level="warning")
            return None

        best_endpoint_key = None
        best_score = -float('inf')

        healthy_endpoints = [
            (key, status) for key, status in service_health.items() if status["is_healthy"]
        ]

        if not healthy_endpoints:
            log_message(f"Aucun endpoint sain pour le service {service_name}. Tentative de s√©lection d'un endpoint non sain.", level="warning")
            all_endpoints = service_health.items()
            if not all_endpoints: 
                return None
            
            sorted_endpoints = sorted(all_endpoints, key=lambda item: (item[1]["error_count"], item[1]["latency"]))
            best_endpoint_key = sorted_endpoints[0][0]
            log_message(f"Fallback: Endpoint {best_endpoint_key} s√©lectionn√© pour {service_name} (non sain).", level="warning")
        else:
            for endpoint_key, status in healthy_endpoints:
                score = (status["success_rate"] * 100) - (status["latency"] * 10) - (status["error_count"] * 5)
                if score > best_score:
                    best_score = score
                    best_endpoint_key = endpoint_key
            log_message(f"Meilleur endpoint s√©lectionn√© pour {service_name}: {best_endpoint_key} (Score: {best_score:.2f})")

        if best_endpoint_key:
            for endpoint_config in API_CONFIG.get(service_name, []):
                current_endpoint_key = f"{endpoint_config['endpoint_name']}-{str(endpoint_config['key'])}"
                if current_endpoint_key == best_endpoint_key:
                    return endpoint_config
        return None

# Instancier le gestionnaire de sant√© des endpoints (sera initialis√© dans main.py)
endpoint_health_manager = EndpointHealthManager()

def set_endpoint_health_manager_global(manager: EndpointHealthManager):
    """
    Permet d'injecter l'instance du gestionnaire de sant√© des endpoints.
    Ceci est utilis√© pour s'assurer que tous les clients API utilisent la m√™me instance.
    """
    global endpoint_health_manager
    endpoint_health_manager = manager

class APIClient:
    """
    Classe de base pour tous les clients API.
    Elle g√®re la s√©lection dynamique d'endpoints, les r√©essais en cas d'√©chec
    et l'int√©gration avec le gestionnaire de sant√© des endpoints.
    """
    def __init__(self, name: str, endpoint_health_manager: EndpointHealthManager):
        self.name = name
        self.endpoints_config = API_CONFIG.get(name, [])
        self.endpoint_health_manager = endpoint_health_manager
        if not self.endpoints_config:
            log_message(f"Client API {self.name} initialis√© sans configuration d'endpoint.", level="error")

    async def _make_request(self, params: Optional[Dict] = None, headers: Optional[Dict] = None, 
                            json_data: Optional[Dict] = None, timeout: Optional[int] = None, 
                            max_retries: int = 3, initial_delay: float = 1.0, 
                            url: Optional[str] = None, method: Optional[str] = None, 
                            key_field: Optional[str] = None, key_location: Optional[str] = None, 
                            api_key: Optional[Union[str, Tuple[str, str]]] = None, 
                            fixed_params: Optional[Dict] = None, fixed_headers: Optional[Dict] = None, 
                            fixed_json: Optional[Dict] = None) -> Optional[Union[Dict, str, bytes]]:
        """
        M√©thode interne pour effectuer les requ√™tes HTTP en utilisant le meilleur endpoint avec r√©essais.
        """
        
        selected_endpoint_config = None
        endpoint_key_for_health = "Dynamic"

        if url and method:
            selected_endpoint_config = {
                "url": url,
                "method": method,
                "key_field": key_field,
                "key_location": key_location,
                "key": api_key,
                "fixed_params": fixed_params if fixed_params is not None else {},
                "fixed_headers": fixed_headers if fixed_headers is not None else {},
                "fixed_json": fixed_json if fixed_json is not None else {},
                "endpoint_name": "Dynamic",
                "timeout": timeout if timeout is not None else 30
            }
            if api_key:
                endpoint_key_for_health = f"Dynamic-{str(api_key)}"
            log_message(f"Requ√™te dynamique pour {self.name} vers {url}")
        else:
            selected_endpoint_config = self.endpoint_health_manager.get_best_endpoint(self.name)
            if not selected_endpoint_config:
                log_message(f"Aucun endpoint sain ou disponible pour {self.name}.", level="error")
                return {"error": True, "message": f"Aucun endpoint sain ou disponible pour {self.name}."}
            endpoint_key_for_health = f"{selected_endpoint_config['endpoint_name']}-{str(selected_endpoint_config['key'])}"
            log_message(f"Endpoint s√©lectionn√© pour {self.name}: {selected_endpoint_config['endpoint_name']}")
            timeout = timeout if timeout is not None else selected_endpoint_config.get("timeout", 30)

        url_to_use = selected_endpoint_config["url"]
        method_to_use = selected_endpoint_config["method"]

        request_params = selected_endpoint_config.get("fixed_params", {}).copy()
        request_headers = selected_endpoint_config.get("fixed_headers", {}).copy()
        request_json_data = selected_endpoint_config.get("fixed_json", {}).copy()
        auth = None

        if params:
            request_params.update(params)
        if headers:
            request_headers.update(headers)
        if json_data:
            request_json_data.update(json_data)

        key_field_to_use = selected_endpoint_config.get("key_field")
        key_location_to_use = selected_endpoint_config.get("key_location")
        key_prefix = selected_endpoint_config.get("key_prefix", "")
        api_key_to_use = selected_endpoint_config["key"]

        if key_field_to_use and key_location_to_use:
            if key_location_to_use == "param":
                request_params[key_field_to_use] = api_key_to_use
            elif key_location_to_use == "header":
                request_headers[key_field_to_use] = f"{key_prefix}{api_key_to_use}"
            elif key_location_to_use == "auth_basic":
                if isinstance(api_key_to_use, tuple) and len(api_key_to_use) == 2:
                    auth = httpx.BasicAuth(api_key_to_use[0], api_key_to_use[1])
                else:
                    log_message(f"Cl√© API pour auth_basic non valide pour {self.name}:{endpoint_key_for_health}", level="error")
                    self.endpoint_health_manager.update_endpoint_health(self.name, endpoint_key_for_health, False, 0.0)
                    return {"error": True, "message": "Configuration d'authentification basique invalide."}

        current_delay = initial_delay
        for attempt in range(max_retries):
            start_time = time.monotonic()
            success = False
            try:
                async with httpx.AsyncClient(timeout=timeout) as client:
                    response = await client.request(method_to_use, url_to_use, params=request_params, headers=request_headers, json=request_json_data, auth=auth)
                    response.raise_for_status()
                    success = True
                    
                    content_type = response.headers.get("Content-Type", "").lower()
                    if "application/json" in content_type:
                        try:
                            return response.json()
                        except json.JSONDecodeError:
                            log_message(f"API {self.name} r√©ponse non JSON valide (tentative {attempt+1}/{max_retries}): {response.text[:200]}...", level="warning")
                            if attempt < max_retries - 1:
                                await asyncio.sleep(current_delay)
                                current_delay *= 2
                                continue
                            return {"error": True, "message": "R√©ponse API non JSON valide.", "raw_response": response.text}
                    else:
                        log_message(f"API {self.name} a renvoy√© un Content-Type non JSON: {content_type}", level="info")
                        return response.content

            except httpx.HTTPStatusError as e:
                log_message(f"API {self.name} erreur HTTP (tentative {attempt+1}/{max_retries}): {e.response.status_code} - {e.response.text}", level="warning")
                if 400 <= e.response.status_code < 500 and e.response.status_code != 429:
                    log_message(f"API {self.name}: Erreur client {e.response.status_code}, pas de r√©essai.", level="error")
                    self.endpoint_health_manager.update_endpoint_health(self.name, endpoint_key_for_health, False, e.response.elapsed.total_seconds())
                    return {"error": True, "status_code": e.response.status_code, "message": e.response.text}
                
                if attempt < max_retries - 1:
                    log_message(f"API {self.name}: R√©essai dans {current_delay:.2f}s...", level="info")
                    await asyncio.sleep(current_delay)
                    current_delay *= 2
            except httpx.RequestError as e:
                log_message(f"API {self.name} erreur de requ√™te (tentative {attempt+1}/{max_retries}): {e}", level="warning")
                if attempt < max_retries - 1:
                    log_message(f"API {self.name}: R√©essai dans {current_delay:.2f}s...", level="info")
                    await asyncio.sleep(current_delay)
                    current_delay *= 2
            except Exception as e:
                log_message(f"API {self.name} erreur inattendue (tentative {attempt+1}/{max_retries}): {e}", level="error")
                self.endpoint_health_manager.update_endpoint_health(self.name, endpoint_key_for_health, False, time.monotonic() - start_time)
                return {"error": True, "message": str(e)}
            finally:
                if not success:
                    latency = time.monotonic() - start_time
                    self.endpoint_health_manager.update_endpoint_health(self.name, endpoint_key_for_health, False, latency)
        
        log_message(f"API {self.name}: Toutes les tentatives ont √©chou√© apr√®s {max_retries} r√©essais.", level="error")
        return {"error": True, "message": f"√âchec de la requ√™te apr√®s {max_retries} tentatives."}

    async def query(self, *args, **kwargs) -> Any:
        """
        M√©thode abstraite pour interroger l'API.
        Doit √™tre impl√©ment√©e par chaque sous-classe de client API.
        """
        raise NotImplementedError("La m√©thode query doit √™tre impl√©ment√©e par les sous-classes.")

# --- Clients API Sp√©cifiques ---

class GeminiAPIClient(APIClient):
    """Client pour l'API Gemini, h√©rite de APIClient pour la gestion de sant√©."""
    def __init__(self):
        super().__init__("GEMINI_API", endpoint_health_manager)
        self.model_name = "gemini-1.5-flash-latest"
        self.generation_config = {
            "temperature": GEMINI_TEMPERATURE,
            "top_p": GEMINI_TOP_P,
            "top_k": GEMINI_TOP_K,
            "max_output_tokens": GEMINI_MAX_OUTPUT_TOKENS,
        }
        self.safety_settings = GEMINI_SAFETY_SETTINGS
        log_message(f"GeminiApiClient initialis√© avec le mod√®le par d√©faut: {self.model_name}")

    async def generate_content(self, prompt: str, chat_history: List[Dict], image_data: Optional[str] = None, model: Optional[str] = None, tools: Optional[List[Dict]] = None) -> Union[Dict, str]:
        """G√©n√®re du contenu textuel ou multimodal en utilisant l'API Gemini."""
        model_to_use = model if model else self.model_name
        
        contents = []
        for msg in chat_history:
            role = "user" if msg["role"] == "user" else "model"
            contents.append({"role": role, "parts": msg["parts"]})

        if contents and contents[-1]["role"] == "user":
            contents[-1]["parts"].append({"text": prompt})
        else:
            contents.append({"role": "user", "parts": [{"text": prompt}]})

        if image_data:
            if "," in image_data:
                mime_type_part, base64_data = image_data.split(",", 1)
                mime_type = mime_type_part.split(":", 1)[1].split(";", 1)[0]
            else:
                mime_type = "image/jpeg" 
                base64_data = image_data

            if contents and contents[-1]["role"] == "user":
                contents[-1]["parts"].append({
                    "inlineData": {
                        "mimeType": mime_type,
                        "data": base64_data
                    }
                })
                log_message(f"Image ajout√©e au prompt Gemini (mimeType: {mime_type}).")
            else:
                log_message("Impossible d'ajouter l'image au prompt Gemini: le dernier message n'est pas un utilisateur.", level="warning")

        payload = {
            "contents": contents,
            "generationConfig": self.generation_config,
            "safetySettings": self.safety_settings
        }

        if tools:
            payload["tools"] = tools

        log_message(f"Appel √† Gemini API pour le mod√®le {model_to_use}...")
        
        # L'URL de l'endpoint Gemini peut varier en fonction du mod√®le.
        # On prend l'URL de base du premier endpoint configur√© et on y ajoute le mod√®le.
        base_url_from_config = self.endpoints_config[0]["url"].split(':generateContent')[0]
        dynamic_url = f"{base_url_from_config}:{model_to_use}:generateContent"

        # Les headers et la cl√© API seront g√©r√©s par _make_request via la s√©lection d'endpoint
        response = await self._make_request(
            url=dynamic_url,
            method="POST",
            json_data=payload,
            timeout=60 # Utilise le timeout de la m√©thode _make_request
        )

        if response and not response.get("error"):
            return response
        return f"‚ùå Erreur Gemini: {response.get('message', 'Inconnu')}" if response else "‚ùå Erreur Gemini: R√©ponse vide ou erreur interne."

class OCRApiClient(APIClient):
    """Client pour l'API OCR.space, h√©rite de APIClient pour la gestion de sant√©."""
    def __init__(self):
        super().__init__("OCR_API", endpoint_health_manager)
        log_message("OCRApiClient initialis√©.")

    async def query(self, image_base64: str) -> str:
        """
        Effectue une requ√™te OCR √† l'API OCR.space.
        `image_base64` doit √™tre la cha√Æne base64 de l'image, incluant le pr√©fixe mimeType.
        """
        payload = {
            "base64Image": image_base64,
            "language": "fre",
            "isOverlayRequired": False,
            "OCREngine": 2
        }
        
        # Les headers et la cl√© API seront g√©r√©s par _make_request via la s√©lection d'endpoint
        log_message("Appel √† OCR.space API...")
        response = await self._make_request(
            json_data=payload,
            method="POST",
            timeout=30
        )

        if response and not response.get("error"):
            if response.get("IsErroredOnProcessing"):
                error_message = response.get("ErrorMessage", ["Erreur inconnue lors du traitement OCR."])
                log_message(f"Erreur OCR.space: {error_message}", level="error")
                return f"‚ùå Erreur OCR: {', '.join(error_message)}"
            
            parsed_text = ""
            if "ParsedResults" in response and response["ParsedResults"]:
                for parsed_result in response["ParsedResults"]:
                    parsed_text += parsed_result.get("ParsedText", "") + "\n"
            
            if parsed_text.strip():
                log_message("OCR.space: Texte extrait avec succ√®s.")
                return parsed_text.strip()
            else:
                log_message("OCR.space: Aucun texte extrait.", level="warning")
                return "Aucun texte n'a pu √™tre extrait de l'image."
        return f"‚ùå Erreur OCR: {response.get('message', 'Inconnu')}" if response else "‚ùå Erreur OCR: R√©ponse vide ou erreur interne."

class DeepSeekClient(APIClient):
    def __init__(self):
        super().__init__("DEEPSEEK", endpoint_health_manager)

    async def query(self, prompt: Union[str, List[Dict]], model: str = "deepseek-chat") -> str:
        """Interroge l'API DeepSeek pour des compl√©tions de chat."""
        if isinstance(prompt, str):
            messages = [{"role": "user", "content": prompt}]
        else:
            messages = prompt

        payload = {"model": model, "messages": messages}
        response = await self._make_request(json_data=payload)
        if response and not response.get("error"):
            content = response.get("choices", [{}])[0].get("message", {}).get("content")
            if content:
                return content
            return "DeepSeek: Pas de contenu de r√©ponse trouv√©."
        return f"DeepSeek: Erreur: {response.get('message', 'Inconnu')}" if response else "DeepSeek: R√©ponse vide ou erreur interne."

class SerperClient(APIClient):
    def __init__(self):
        super().__init__("SERPER", endpoint_health_manager)

    async def query(self, query_text: str) -> str:
        """Effectue une recherche web via l'API Serper."""
        payload = {"q": query_text}
        response = await self._make_request(json_data=payload)
        if response and not response.get("error"):
            organic_results = response.get("organic", [])
            if organic_results:
                snippet = organic_results[0].get("snippet", "Pas de snippet.")
                link = organic_results[0].get("link", "")
                return f"Serper (recherche web):\n{snippet} {neutralize_urls(link)}"
            return "Serper: Aucune information trouv√©e."
        return f"Serper: Erreur: {response.get('message', 'Inconnu')}" if response else "Serper: R√©ponse vide ou erreur interne."

class WolframAlphaClient(APIClient):
    def __init__(self):
        super().__init__("WOLFRAMALPHA", endpoint_health_manager)

    async def query(self, input_text: str) -> str:
        """Interroge WolframAlpha pour des calculs ou des faits."""
        params = {"input": input_text}
        response = await self._make_request(params=params)
        if response and not response.get("error"):
            pods = response.get("queryresult", {}).get("pods", [])
            if pods:
                for pod in pods:
                    if pod.get("title") in ["Result", "Input interpretation", "Decimal approximation"]:
                        subpods = pod.get("subpods", [])
                        if subpods and subpods[0].get("plaintext"):
                            return f"WolframAlpha:\n{subpods[0]['plaintext']}"
                if pods and pods[0].get("subpods") and pods[0]["subpods"][0].get("plaintext"):
                    return f"WolframAlpha:\n{pods[0]['subpods'][0]['plaintext']}"
            return "WolframAlpha: Pas de r√©sultat clair."
        return f"WolframAlpha: Erreur: {response.get('message', 'Inconnu')}" if response else "WolframAlpha: R√©ponse vide ou erreur interne."

class TavilyClient(APIClient):
    def __init__(self):
        super().__init__("TAVILY", endpoint_health_manager)

    async def query(self, query_text: str, max_results: int = 3) -> str:
        """Effectue une recherche web avanc√©e via l'API Tavily."""
        payload = {"query": query_text, "max_results": max_results}
        response = await self._make_request(json_data=payload)
        if response and not response.get("error"):
            results = response.get("results", [])
            answer = response.get("answer", "Aucune r√©ponse directe trouv√©e.")

            output = f"Tavily (recherche web):\nR√©ponse directe: {answer}\n"
            if results:
                output += "Extraits pertinents:\n"
                for i, res in enumerate(results[:max_results]):
                    output += f"- {res.get('title', 'N/A')}: {res.get('content', 'N/A')} {neutralize_urls(res.get('url', ''))}\n"
            return output
        return f"Tavily: Erreur: {response.get('message', 'Inconnu')}" if response else "Tavily: R√©ponse vide ou erreur interne."

class ApiFlashClient(APIClient):
    def __init__(self):
        super().__init__("APIFLASH", endpoint_health_manager)

    async def query(self, url: str) -> str:
        """Capture une capture d'√©cran d'une URL via ApiFlash."""
        params = {"url": url, "format": "jpeg", "full_page": "true"}
        response_content = await self._make_request(params=params)

        if isinstance(response_content, bytes):
            selected_endpoint_config = self.endpoint_health_manager.get_best_endpoint(self.name)
            if selected_endpoint_config:
                capture_url = f"{selected_endpoint_config['url']}?access_key={selected_endpoint_config['key']}&url={url}&format=jpeg&full_page=true"
                return f"ApiFlash (capture d'√©cran): {neutralize_urls(capture_url)} (V√©rifiez le lien pour l'image)"
            return "ApiFlash: Impossible de g√©n√©rer l'URL de capture."
        elif isinstance(response_content, dict) and response_content.get("error"):
            return f"ApiFlash: Erreur: {response_content.get('message', 'Inconnu')}"
        else:
            log_message(f"ApiFlash a renvoy√© un type de r√©ponse inattendu: {type(response_content)}", level="warning")
            return f"ApiFlash: R√©ponse inattendue de l'API. {response_content}"

class CrawlbaseClient(APIClient):
    def __init__(self):
        super().__init__("CRAWLBASE", endpoint_health_manager)

    async def query(self, url: str, use_js: bool = False) -> str:
        """Scrape le contenu HTML ou JavaScript d'une URL via Crawlbase."""
        params = {"url": url, "format": "json"}
        
        selected_endpoint_config = None
        if use_js:
            for config in API_CONFIG.get(self.name, []):
                if "JS Scraper" in config.get("endpoint_name", ""):
                    selected_endpoint_config = config
                    break
        
        if not selected_endpoint_config: 
            selected_endpoint_config = self.endpoint_health_manager.get_best_endpoint(self.name)

        if not selected_endpoint_config:
            return f"Crawlbase: Aucun endpoint sain ou disponible pour {self.name}."

        response = await self._make_request(
            params=params,
            url=selected_endpoint_config["url"],
            method=selected_endpoint_config["method"],
            key_field=selected_endpoint_config["key_field"],
            key_location=selected_endpoint_config["key_location"],
            api_key=selected_endpoint_config["key"],
            fixed_params=selected_endpoint_config.get("fixed_params", {}),
            timeout=selected_endpoint_config.get("timeout")
        )

        if response and not response.get("error"):
            body = response.get("body")
            if body:
                try:
                    decoded_body = base64.b64decode(body).decode('utf-8', errors='ignore')
                    return f"Crawlbase (contenu web):\n{decoded_body[:1000]}..."
                except Exception:
                    return f"Crawlbase (contenu web - brut):\n{body[:1000]}..."
            return "Crawlbase: Contenu non trouv√©."
        return f"Crawlbase: Erreur: {response.get('message', 'Inconnu')}" if response else "Crawlbase: R√©ponse vide ou erreur interne."

class DetectLanguageClient(APIClient):
    def __init__(self):
        super().__init__("DETECTLANGUAGE", endpoint_health_manager)

    async def query(self, text: str) -> str:
        """D√©tecte la langue d'un texte via DetectLanguage API."""
        payload = {"q": text}
        response = await self._make_request(json_data=payload)
        if response and not response.get("error"):
            detections = response.get("data", {}).get("detections", [])
            if detections:
                first_detection = detections[0]
                lang = first_detection.get("language")
                confidence = first_detection.get("confidence")
                return f"Langue d√©tect√©e: {lang} (confiance: {confidence})"
            return "DetectLanguage: Aucune langue d√©tect√©e."
        return f"DetectLanguage: Erreur: {response.get('message', 'Inconnu')}" if response else "DetectLanguage: R√©ponse vide ou erreur interne."

class GuardianClient(APIClient):
    def __init__(self):
        super().__init__("GUARDIAN", endpoint_health_manager)

    async def query(self, query_text: str) -> str:
        """Recherche des articles de presse via l'API The Guardian."""
        params = {"q": query_text}
        response = await self._make_request(params=params)
        if response and not response.get("error"):
            results = response.get("response", {}).get("results", [])
            if results:
                output = "Articles The Guardian:\n"
                for res in results[:3]:
                    output += f"- {res.get('webTitle', 'N/A')}: {res.get('fields', {}).get('trailText', 'N/A')} {neutralize_urls(res.get('webUrl', ''))}\n"
                return output
            return "Guardian: Aucun article trouv√©."
        return f"Guardian: Erreur: {response.get('message', 'Inconnu')}" if response else "Guardian: R√©ponse vide ou erreur interne."

class IP2LocationClient(APIClient):
    def __init__(self):
        super().__init__("IP2LOCATION", endpoint_health_manager)

    async def query(self, ip_address: str) -> str:
        """G√©olocalise une adresse IP via IP2Location API."""
        params = {"ip": ip_address}
        response = await self._make_request(params=params)
        if response and not response.get("error"):
            if "country_name" in response:
                return f"IP2Location (G√©olocalisation IP {ip_address}): Pays: {response['country_name']}, Ville: {response.get('city_name', 'N/A')}"
            return "IP2Location: Informations non trouv√©es."
        return f"IP2Location: Erreur: {response.get('message', 'Inconnu')}" if response else "IP2Location: R√©ponse vide ou erreur interne."

class ShodanClient(APIClient):
    def __init__(self):
        super().__init__("SHODAN", endpoint_health_manager)

    async def query(self, query_text: str = "") -> str:
        """
        Interroge Shodan pour des informations sur un h√¥te IP ou des informations sur la cl√© API.
        Si `query_text` est une IP, tente de r√©cup√©rer les infos de l'h√¥te.
        Sinon, ou en cas d'√©chec, retourne les infos de la cl√© API.
        """
        if re.match(r"^\d{1,3}\.\d{1,3}\.\d{1,3}\.\d{1,3}$", query_text):
            selected_endpoint_config = None
            for config in API_CONFIG.get(self.name, []):
                if "Host Info" in config.get("endpoint_name", ""):
                    selected_endpoint_config = config
                    break
            if selected_endpoint_config:
                url = f"{selected_endpoint_config['url'].rstrip('/')}/{query_text}"
                response = await self._make_request(
                    params={"key": selected_endpoint_config["key"]},
                    url=url,
                    method="GET",
                    key_field=selected_endpoint_config["key_field"],
                    key_location=selected_endpoint_config["key_location"],
                    api_key=selected_endpoint_config["key"],
                    timeout=selected_endpoint_config.get("timeout")
                )
                if response and not response.get("error"):
                    return f"Shodan (info h√¥te {query_text}): Pays: {response.get('country_name', 'N/A')}, Ports: {response.get('ports', 'N/A')}, Vuln√©rabilit√©s: {response.get('vulns', 'Aucune')}"
                return f"Shodan (info h√¥te): Erreur: {response.get('message', 'Inconnu')}" if response else "Shodan: R√©ponse vide ou erreur interne."
            else:
                return "Shodan: Endpoint 'Host Info' non configur√©."
        else:
            response = await self._make_request()
            if response and not response.get("error"):
                return f"Shodan (info cl√©): Requ√™tes restantes: {response.get('usage_limits', {}).get('query_credits', 'N/A')}, Scan cr√©dits: {response.get('usage_limits', {}).get('scan_credits', 'N/A')}"
            return f"Shodan: Erreur: {response.get('message', 'Inconnu')}" if response else "Shodan: R√©ponse vide ou erreur interne."

class WeatherAPIClient(APIClient):
    def __init__(self):
        super().__init__("WEATHERAPI", endpoint_health_manager)

    async def query(self, location: str) -> str:
        """R√©cup√®re les conditions m√©t√©orologiques actuelles pour une localisation via WeatherAPI."""
        params = {"q": location}
        response = await self._make_request(params=params)
        if response and not response.get("error"):
            current = response.get("current", {})
            location_info = response.get("location", {})
            if current and location_info:
                return (
                    f"M√©t√©o √† {location_info.get('name', 'N/A')}, {location_info.get('country', 'N/A')}:\n"
                    f"Temp√©rature: {current.get('temp_c', 'N/A')}¬∞C, "
                    f"Conditions: {current.get('condition', {}).get('text', 'N/A')}, "
                    f"Vent: {current.get('wind_kph', 'N/A')} km/h"
                )
            return "WeatherAPI: Donn√©es m√©t√©o non trouv√©es."
        return f"WeatherAPI: Erreur: {response.get('message', 'Inconnu')}" if response else "WeatherAPI: R√©ponse vide ou erreur interne."

class CloudmersiveClient(APIClient):
    def __init__(self):
        super().__init__("CLOUDMERSIVE", endpoint_health_manager)

    async def query(self, domain: str) -> str:
        """V√©rifie la validit√© et le type d'un domaine via Cloudmersive API."""
        payload = {"domain": domain}
        response = await self._make_request(json_data=payload)
        if response and not response.get("error"):
            return f"Cloudmersive (v√©rification de domaine {domain}): Valide: {response.get('ValidDomain', 'N/A')}, Type: {response.get('DomainType', 'N/A')}"
        return f"Cloudmersive: Erreur: {response.get('message', 'Inconnu')}" if response else "Cloudmersive: R√©ponse vide ou erreur interne."

class GreyNoiseClient(APIClient):
    def __init__(self):
        super().__init__("GREYNOISE", endpoint_health_manager)

    async def query(self, ip_address: str) -> str:
        """Analyse une adresse IP pour d√©tecter des activit√©s 'bruit' (malveillantes) via GreyNoise."""
        selected_endpoint_config = self.endpoint_health_manager.get_best_endpoint(self.name)
        if not selected_endpoint_config:
            return f"GreyNoise: Aucun endpoint sain ou disponible pour {self.name}."

        url = f"{selected_endpoint_config['url'].rstrip('/')}/{ip_address}"
        method = selected_endpoint_config["method"]
        headers = {selected_endpoint_config["key_field"]: selected_endpoint_config["key"]}

        response = await self._make_request(
            headers=headers,
            url=url,
            method=method,
            key_field=selected_endpoint_config["key_field"],
            key_location=selected_endpoint_config["key_location"],
            api_key=selected_endpoint_config["key"],
            timeout=selected_endpoint_config.get("timeout")
        )

        if response and not response.get("error"):
            if response.get("noise"):
                return f"GreyNoise (IP {ip_address}): C'est une IP 'bruit' (malveillante). Classification: {response.get('classification', 'N/A')}, Nom d'acteur: {response.get('actor', 'N/A')}"
            return f"GreyNoise (IP {ip_address}): Pas de 'bruit' d√©tect√©. Statut: {response.get('status', 'N/A')}"
        return f"GreyNoise: Erreur: {response.get('message', 'Inconnu')}" if response else "GreyNoise: R√©ponse vide ou erreur interne."

class PulsediveClient(APIClient):
    def __init__(self):
        super().__init__("PULSEDIVE", endpoint_health_manager)

    async def query(self, indicator: str, type: str = "auto") -> str:
        """Analyse un indicateur de menace (IP, domaine, URL) via Pulsedive."""
        params = {"indicator": indicator, "type": type}
        response = await self._make_request(params=params)
        if response and not response.get("error"):
            if response.get("results"):
                result = response["results"][0]
                return (
                    f"Pulsedive (Analyse {indicator}): Type: {result.get('type', 'N/A')}, "
                    f"Risk: {result.get('risk', 'N/A')}, "
                    f"Description: {result.get('description', 'N/A')[:200]}..."
                )
            return "Pulsedive: Aucun r√©sultat d'analyse trouv√©."
        return f"Pulsedive: Erreur: {response.get('message', 'Inconnu')}" if response else "Pulsedive: R√©ponse vide ou erreur interne."

class StormGlassClient(APIClient):
    def __init__(self):
        super().__init__("STORMGLASS", endpoint_health_manager)

    async def query(self, lat: float, lng: float, params: str = "airTemperature,waveHeight") -> str:
        """R√©cup√®re les donn√©es m√©t√©orologiques maritimes pour une coordonn√©e via StormGlass."""
        now = int(time.time())
        request_params = {
            "lat": lat,
            "lng": lng,
            "params": params,
            "start": now,
            "end": now + 3600
        }
        response = await self._make_request(params=request_params)
        if response and not response.get("error"):
            data = response.get("hours", [])
            if data:
                first_hour = data[0]
                temp = first_hour.get('airTemperature', [{}])[0].get('value', 'N/A')
                wave_height = first_hour.get('waveHeight', [{}])[0].get('value', 'N/A')
                return f"StormGlass (M√©t√©o maritime √† {lat},{lng}): Temp√©rature air: {temp}¬∞C, Hauteur vagues: {wave_height}m"
            return "StormGlass: Donn√©es non trouv√©es."
        return f"StormGlass: Erreur: {response.get('message', 'Inconnu')}" if response else "StormGlass: R√©ponse vide ou erreur interne."

class LoginRadiusClient(APIClient):
    def __init__(self):
        super().__init__("LOGINRADIUS", endpoint_health_manager)

    async def query(self) -> str:
        """Effectue un simple ping √† l'API LoginRadius pour v√©rifier sa disponibilit√©."""
        response = await self._make_request()
        if response and not response.get("error"):
            return f"LoginRadius (Ping API): Statut: {response.get('Status', 'N/A')}, Message: {response.get('Message', 'N/A')}"
        return f"LoginRadius: Erreur: {response.get('message', 'Inconnu')}" if response else "LoginRadius: R√©ponse vide ou erreur interne."

class JsonbinClient(APIClient):
    def __init__(self):
        super().__init__("JSONBIN", endpoint_health_manager)

    async def query(self, data: Optional[Dict[str, Any]] = None, private: bool = True, bin_id: Optional[str] = None) -> str:
        """
        Cr√©e un nouveau 'bin' JSON ou acc√®de √† un bin existant via Jsonbin.io.
        `data` est pour la cr√©ation, `bin_id` pour l'acc√®s.
        """
        if bin_id:
            selected_endpoint_config = None
            for config in API_CONFIG.get(self.name, []):
                if "Bin Access" in config.get("endpoint_name", ""):
                    selected_endpoint_config = config
                    break
            if not selected_endpoint_config:
                return f"Jsonbin: Aucun endpoint d'acc√®s de bin sain ou disponible pour {self.name}."

            url = f"{selected_endpoint_config['url'].rstrip('/')}/{bin_id}"
            method = "GET"
            headers = {selected_endpoint_config["key_field"]: selected_endpoint_config["key"]}
            
            response = await self._make_request(
                headers=headers,
                url=url,
                method=method,
                timeout=selected_endpoint_config.get("timeout")
            )
            if response and not response.get("error"):
                return f"Jsonbin (Acc√®s bin {bin_id}):\n{json.dumps(response, indent=2)}"
            return f"Jsonbin (Acc√®s bin): Erreur: {response.get('message', 'Inconnu')}" if response else "Jsonbin: R√©ponse vide ou erreur interne."
        
        else:
            selected_endpoint_config = None
            for config in API_CONFIG.get(self.name, []):
                if "Bin Create" in config.get("endpoint_name", ""):
                    selected_endpoint_config = config
                    break
            
            if not selected_endpoint_config:
                return f"Jsonbin: Aucun endpoint de cr√©ation de bin sain ou disponible pour {self.name}."

            url = selected_endpoint_config["url"]
            method = "POST"
            headers = {selected_endpoint_config["key_field"]: selected_endpoint_config["key"], "Content-Type": "application/json"}
            payload = {"record": data if data is not None else {}, "private": private}

            response = await self._make_request(
                json_data=payload,
                headers=headers,
                url=url,
                method=method,
                timeout=selected_endpoint_config.get("timeout")
            )

            if response and not response.get("error"):
                return f"Jsonbin (Cr√©ation de bin): ID: {response.get('metadata', {}).get('id', 'N/A')}, URL: {neutralize_urls(response.get('metadata', {}).get('url', 'N/A'))}"
            return f"Jsonbin (Cr√©ation de bin): Erreur: {response.get('message', 'Inconnu')}" if response else "Jsonbin: R√©ponse vide ou erreur interne."

class HuggingFaceClient(APIClient):
    def __init__(self):
        super().__init__("HUGGINGFACE", endpoint_health_manager)

    async def query(self, model_name: str = "distilbert-base-uncased-finetuned-sst-2-english", input_text: str = "Hello world") -> str:
        """Effectue une inf√©rence sur un mod√®le HuggingFace (ex: classification de texte, g√©n√©ration)."""
        selected_endpoint_config = self.endpoint_health_manager.get_best_endpoint(self.name)
        if not selected_endpoint_config:
            return f"HuggingFace: Aucun endpoint sain ou disponible pour {self.name}."

        inference_url = f"https://api-inference.huggingface.co/models/{model_name}"
        
        headers = {
            selected_endpoint_config["key_field"]: f"{selected_endpoint_config['key_prefix']}{selected_endpoint_config['key']}",
            "Content-Type": "application/json"
        }
        payload = {"inputs": input_text}

        response = await self._make_request(
            json_data=payload,
            headers=headers,
            url=inference_url,
            method="POST",
            timeout=selected_endpoint_config.get("timeout")
        )

        if response and not response.get("error"):
            if isinstance(response, list) and response:
                first_result = response[0]
                if isinstance(first_result, list) and first_result:
                    return f"HuggingFace ({model_name} - {first_result[0].get('label')}): Score {first_result[0].get('score', 'N/A'):.2f}"
                elif isinstance(first_result, dict) and "generated_text" in first_result:
                    return f"HuggingFace ({model_name}): {first_result.get('generated_text')}"
            return f"HuggingFace ({model_name}): R√©ponse non pars√©e. {response}"
        return f"HuggingFace: Erreur: {response.get('message', 'Inconnu')}" if response else "HuggingFace: R√©ponse vide ou erreur interne."

class TwilioClient(APIClient):
    def __init__(self):
        super().__init__("TWILIO", endpoint_health_manager)

    async def query(self) -> str:
        """R√©cup√®re le solde du compte Twilio."""
        selected_endpoint_config = None
        for config in API_CONFIG.get(self.name, []):
            if "Account Balance" in config.get("endpoint_name", ""):
                selected_endpoint_config = config
                break
        if not selected_endpoint_config:
            if self.endpoints_config:
                selected_endpoint_config = self.endpoints_config[0]
            else:
                return f"Twilio: Aucune configuration d'endpoint disponible pour {self.name}."

        response = await self._make_request(
            url=selected_endpoint_config["url"],
            method=selected_endpoint_config["method"],
            key_location=selected_endpoint_config["key_location"],
            api_key=selected_endpoint_config["key"],
            timeout=selected_endpoint_config.get("timeout")
        )
        if response and not response.get("error"):
            return f"Twilio (Balance): {response.get('balance', 'N/A')} {response.get('currency', 'N/A')}"
        return f"Twilio: Erreur: {response.get('message', 'Inconnu')}" if response else "Twilio: R√©ponse vide ou erreur interne."

class AbstractAPIClient(APIClient):
    def __init__(self):
        super().__init__("ABSTRACTAPI", endpoint_health_manager)

    async def query(self, input_value: str, api_type: str) -> str:
        """
        Interroge diverses APIs d'AbstractAPI (validation email/t√©l√©phone, taux de change, jours f√©ri√©s).
        `input_value` d√©pend du `api_type`.
        """
        params = {}
        target_endpoint_name = ""

        if api_type == "PHONE_VALIDATION":
            params["phone"] = input_value
            target_endpoint_name = "Phone Validation"
        elif api_type == "EMAIL_VALIDATION":
            params["email"] = input_value
            target_endpoint_name = "Email Validation"
        elif api_type == "EXCHANGE_RATES":
            params["base"] = input_value if input_value else "USD" 
            target_endpoint_name = "Exchange Rates"
        elif api_type == "HOLIDAYS":
            params["country"] = input_value if input_value else "US"
            from datetime import datetime
            params["year"] = datetime.now(timezone.utc).year
            target_endpoint_name = "Holidays"
        else:
            return f"AbstractAPI: Type d'API '{api_type}' non support√© pour la requ√™te."

        selected_endpoint_config = None
        for config in API_CONFIG.get(self.name, []):
            if target_endpoint_name in config["endpoint_name"]:
                selected_endpoint_config = config
                break
        
        if not selected_endpoint_config:
            return f"AbstractAPI: Aucun endpoint sain ou disponible pour {self.name} pour le type {api_type}."

        response = await self._make_request(
            params=params,
            url=selected_endpoint_config["url"],
            method=selected_endpoint_config["method"],
            key_field=selected_endpoint_config["key_field"],
            key_location=selected_endpoint_config["key_location"],
            api_key=selected_endpoint_config["key"],
            fixed_params=selected_endpoint_config.get("fixed_params", {}),
            timeout=selected_endpoint_config.get("timeout")
        )

        if response and not response.get("error"):
            if api_type == "PHONE_VALIDATION":
                return (
                    f"AbstractAPI (Validation T√©l): Num√©ro: {response.get('phone', 'N/A')}, "
                    f"Valide: {response.get('valid', 'N/A')}, "
                    f"Pays: {response.get('country', {}).get('name', 'N/A')}"
                )
            elif api_type == "EMAIL_VALIDATION":
                return (
                    f"AbstractAPI (Validation Email): Email: {response.get('email', 'N/A')}, "
                    f"Valide: {response.get('is_valid_format', 'N/A')}, "
                    f"Deliverable: {response.get('is_deliverable', 'N/A')}"
                )
            elif api_type == "EXCHANGE_RATES":
                return f"AbstractAPI (Taux de change): Base: {response.get('base', 'N/A')}, Taux (USD): {response.get('exchange_rates', {}).get('USD', 'N/A')}"
            elif api_type == "HOLIDAYS":
                holidays = [h.get('name', 'N/A') for h in response if h.get('name')]
                return f"AbstractAPI (Jours f√©ri√©s {params.get('country', 'US')} {params.get('year')}): {', '.join(holidays[:5])}..." if holidays else "Aucun jour f√©ri√© trouv√©."
            return f"AbstractAPI ({api_type}): R√©ponse brute: {response}"
        return f"AbstractAPI ({api_type}): Erreur: {response.get('message', 'Inconnu')}" if response else "AbstractAPI: R√©ponse vide ou erreur interne."

class GoogleCustomSearchClient(APIClient):
    def __init__(self):
        super().__init__("GOOGLE_CUSTOM_SEARCH", endpoint_health_manager)

    async def query(self, query_text: str) -> str:
        """Effectue une recherche personnalis√©e Google via l'API Custom Search."""
        params = {"q": query_text}
        response = await self._make_request(params=params)
        if response and not response.get("error"):
            items = response.get("items", [])
            if items:
                output = "Google Custom Search:\n"
                for item in items[:3]:
                    output += f"- {item.get('title', 'N/A')}: {item.get('snippet', 'N/A')} {neutralize_urls(item.get('link', ''))}\n"
                return output
            return "Google Custom Search: Aucun r√©sultat trouv√©."
        return f"Google Custom Search: Erreur: {response.get('message', 'Inconnu')}" if response else "Google Custom Search: R√©ponse vide ou erreur interne."

class RandommerClient(APIClient):
    def __init__(self):
        super().__init__("RANDOMMER", endpoint_health_manager)

    async def query(self, country_code: str = "US", quantity: int = 1) -> str:
        """G√©n√®re des num√©ros de t√©l√©phone al√©atoires via Randommer.io."""
        params = {"CountryCode": country_code, "Quantity": quantity}
        response = await self._make_request(params=params)
        if response and not response.get("error"):
            if isinstance(response, list) and response:
                return f"Randommer (Num√©ros de t√©l√©phone): {', '.join(response)}"
            return f"Randommer: {response}"
        return f"Randommer: Erreur: {response.get('message', 'Inconnu')}" if response else "Randommer: R√©ponse vide ou erreur interne."

class TomorrowIOClient(APIClient):
    def __init__(self):
        super().__init__("TOMORROW.IO", endpoint_health_manager)

    async def query(self, location: str, fields: Optional[List[str]] = None) -> str:
        """R√©cup√®re les pr√©visions m√©t√©orologiques via Tomorrow.io."""
        if fields is None:
            fields = ["temperature", "humidity", "windSpeed"]
        payload = {"location": location, "fields": fields, "units": "metric", "timesteps": ["1h"]}
        response = await self._make_request(json_data=payload)
        if response and not response.get("error"):
            data = response.get("data", {}).get("timelines", [{}])[0].get("intervals", [{}])[0].get("values", {})
            if data:
                output = f"M√©t√©o (Tomorrow.io) √† {location}:\n"
                for field in fields:
                    output += f"- {field.capitalize()}: {data.get(field, 'N/A')}\n"
                return output
            return "Tomorrow.io: Donn√©es m√©t√©o non trouv√©es."
        return f"Tomorrow.io: Erreur: {response.get('message', 'Inconnu')}" if response else "Tomorrow.io: R√©ponse vide ou erreur interne."

class OpenWeatherMapClient(APIClient):
    def __init__(self):
        super().__init__("OPENWEATHERMAP", endpoint_health_manager)

    async def query(self, location: str) -> str:
        """R√©cup√®re les conditions m√©t√©orologiques actuelles via OpenWeatherMap."""
        params = {"q": location}
        response = await self._make_request(params=params)
        if response and not response.get("error"):
            main_data = response.get("main", {})
            weather_desc = response.get("weather", [{}])[0].get("description", "N/A")
            if main_data:
                temp_kelvin = main_data.get('temp', 'N/A')
                feels_like_kelvin = main_data.get('feels_like', 'N/A')
                
                temp_celsius = f"{temp_kelvin - 273.15:.2f}" if isinstance(temp_kelvin, (int, float)) else "N/A"
                feels_like_celsius = f"{feels_like_kelvin - 273.15:.2f}" if isinstance(feels_like_kelvin, (int, float)) else "N/A"

                return (
                    f"M√©t√©o (OpenWeatherMap) √† {location}:\n"
                    f"Temp√©rature: {temp_celsius}¬∞C, "
                    f"Ressenti: {feels_like_celsius}¬∞C, "
                    f"Humidit√©: {main_data.get('humidity', 'N/A')}%, "
                    f"Conditions: {weather_desc}"
                )
            return "OpenWeatherMap: Donn√©es m√©t√©o non trouv√©es."
        return f"OpenWeatherMap: Erreur: {response.get('message', 'Inconnu')}" if response else "OpenWeatherMap: R√©ponse vide ou erreur interne."

class MockarooClient(APIClient):
    def __init__(self):
        super().__init__("MOCKAROO", endpoint_health_manager)

    async def query(self, count: int = 1, fields_json: Optional[str] = None) -> str:
        """G√©n√®re des donn√©es de test via Mockaroo."""
        params = {"count": count}
        if fields_json:
            params["fields"] = fields_json
        response = await self._make_request(params=params)
        if response and not response.get("error"):
            return f"Mockaroo (G√©n√©ration de donn√©es):\n{json.dumps(response, indent=2)}"
        return f"Mockaroo: Erreur: {response.get('message', 'Inconnu')}" if response else "Mockaroo: R√©ponse vide ou erreur interne."

class OpenPageRankClient(APIClient):
    def __init__(self):
        super().__init__("OPENPAGERANK", endpoint_health_manager)

    async def query(self, domains: List[str]) -> str:
        """R√©cup√®re le PageRank de domaines via OpenPageRank."""
        params = {"domains[]": domains}
        response = await self._make_request(params=params)
        if response and not response.get("error"):
            results = response.get("response", [])
            if results:
                output = "OpenPageRank (Classement de domaine):\n"
                for res in results:
                    output += f"- Domaine: {res.get('domain', 'N/A')}, PageRank: {res.get('page_rank', 'N/A')}\n"
                return output
            return "OpenPageRank: Aucun r√©sultat trouv√©."
        return f"OpenPageRank: Erreur: {response.get('message', 'Inconnu')}" if response else "OpenPageRank: R√©ponse vide ou erreur interne."

class RapidAPIClient(APIClient):
    def __init__(self):
        super().__init__("RAPIDAPI", endpoint_health_manager)

    async def query(self, api_name: str, **kwargs) -> str:
        """
        Interroge diverses APIs disponibles via RapidAPI (blagues, taux de change, faits al√©atoires).
        `api_name` sp√©cifie l'API RapidAPI √† utiliser.
        """
        selected_endpoint_config = None
        for config in API_CONFIG.get(self.name, []):
            if api_name.lower() in config["endpoint_name"].lower():
                selected_endpoint_config = config
                break
        
        if not selected_endpoint_config:
            return f"RapidAPI: Endpoint pour '{api_name}' non trouv√© ou non configur√©."

        url = selected_endpoint_config["url"]
        method = selected_endpoint_config["method"]
        
        request_params = selected_endpoint_config.get("fixed_params", {}).copy()
        request_headers = selected_endpoint_config.get("fixed_headers", {}).copy()
        request_json_data = selected_endpoint_config.get("fixed_json", {}).copy()

        if method == "GET":
            request_params.update(kwargs)
        elif method == "POST":
            request_json_data.update(kwargs)

        headers = {
            selected_endpoint_config["key_field"]: selected_endpoint_config["key"],
            "X-RapidAPI-Host": selected_endpoint_config["fixed_headers"].get("X-RapidAPI-Host")
        }
        
        response = await self._make_request(
            params=request_params,
            headers=headers,
            json_data=request_json_data,
            url=url,
            method=method,
            timeout=selected_endpoint_config.get("timeout")
        )

        if response and not response.get("error"):
            if api_name.lower() == "programming joke":
                return f"RapidAPI (Blague de Programmation): {response.get('setup', '')} - {response.get('punchline', '')}"
            elif api_name.lower() == "currency list quotes":
                return f"RapidAPI (Devises): {json.dumps(response, indent=2)}"
            elif api_name.lower() == "random fact":
                return f"RapidAPI (Fait Al√©atoire): {response.get('text', 'N/A')}"
            return f"RapidAPI ({api_name}): {json.dumps(response, indent=2)}"
        return f"RapidAPI ({api_name}): Erreur: {response.get('message', 'Inconnu')}" if response else "RapidAPI: R√©ponse vide ou erreur interne."

# Liste de tous les clients API instanciables
ALL_API_CLIENTS = [
    GeminiAPIClient(),
    OCRApiClient(),
    DeepSeekClient(),
    SerperClient(),
    WolframAlphaClient(),
    TavilyClient(),
    ApiFlashClient(),
    CrawlbaseClient(),
    DetectLanguageClient(),
    GuardianClient(),
    IP2LocationClient(),
    ShodanClient(),
    WeatherAPIClient(),
    CloudmersiveClient(),
    GreyNoiseClient(),
    PulsediveClient(),
    StormGlassClient(),
    LoginRadiusClient(),
    JsonbinClient(),
    HuggingFaceClient(),
    TwilioClient(),
    AbstractAPIClient(),
    GoogleCustomSearchClient(),
    RandommerClient(),
    TomorrowIOClient(),
    OpenWeatherMapClient(),
    MockarooClient(),
    OpenPageRankClient(),
    RapidAPIClient()
]

import asyncio
import json
import re
import base64
from typing import Dict, Any, List, Optional, Union

# Import des clients API
from api_clients import (
    GeminiAPIClient, OCRApiClient, DeepSeekClient, SerperClient,
    WolframAlphaClient, TavilyClient, ApiFlashClient, CrawlbaseClient,
    DetectLanguageClient, GuardianClient, IP2LocationClient, ShodanClient,
    WeatherAPIClient, CloudmersiveClient, GreyNoiseClient, PulsediveClient,
    StormGlassClient, LoginRadiusClient, JsonbinClient, HuggingFaceClient,
    TwilioClient, AbstractAPIClient, GoogleCustomSearchClient,
    RandommerClient, TomorrowIOClient, OpenWeatherMapClient, MockarooClient,
    OpenPageRankClient, RapidAPIClient
)

# Import des fonctions utilitaires
from utils import log_message, neutralize_urls, find_tool_by_name
from config import TOOL_CONFIG

# Instanciation des clients API
gemini_client = GeminiAPIClient()
ocr_client = OCRApiClient()
deepseek_client = DeepSeekClient()
serper_client = SerperClient()
wolfram_alpha_client = WolframAlphaClient()
tavily_client = TavilyClient()
apiflash_client = ApiFlashClient()
crawlbase_client = CrawlbaseClient()
detect_language_client = DetectLanguageClient()
guardian_client = GuardianClient()
ip2location_client = IP2LocationClient()
shodan_client = ShodanClient()
weather_api_client = WeatherAPIClient()
cloudmersive_client = CloudmersiveClient()
greynoise_client = GreyNoiseClient()
pulsedive_client = PulsediveClient()
stormglass_client = StormGlassClient()
loginradius_client = LoginRadiusClient()
jsonbin_client = JsonbinClient()
huggingface_client = HuggingFaceClient()
twilio_client = TwilioClient()
abstractapi_client = AbstractAPIClient()
google_custom_search_client = GoogleCustomSearchClient()
randommer_client = RandommerClient()
tomorrow_io_client = TomorrowIOClient()
openweathermap_client = OpenWeatherMapClient()
mockaroo_client = MockarooClient()
openpagerank_client = OpenPageRankClient()
rapidapi_client = RapidAPIClient()

async def execute_tool(tool_name: str, **kwargs) -> str:
    """
    Ex√©cute un outil sp√©cifique en fonction de son nom et des arguments fournis.
    C'est le point d'entr√©e principal pour l'ex√©cution de toutes les fonctions d'outils.
    """
    log_message(f"Ex√©cution de l'outil: {tool_name} avec kwargs: {kwargs}")
    tool_config = find_tool_by_name(tool_name)

    if not tool_config:
        log_message(f"Outil non trouv√©: {tool_name}", level="error")
        return f"Erreur: Outil '{tool_name}' non trouv√© ou non configur√©."

    try:
        if tool_name == "google_search":
            return await google_search_tool(kwargs.get("queries"))
        elif tool_name == "media_control":
            action = kwargs.get("action")
            if action == "like":
                return await media_control_like_tool()
            elif action == "dislike":
                return await media_control_dislike_tool()
            elif action == "next":
                return await media_control_next_tool()
            elif action == "previous":
                return await media_control_previous_tool()
            elif action == "pause":
                return await media_control_pause_tool()
            elif action == "resume":
                return await media_control_resume_tool()
            elif action == "stop":
                return await media_control_stop_tool()
            elif action == "replay":
                return await media_control_replay_tool()
            elif action == "seek_absolute":
                return await media_control_seek_absolute_tool(kwargs.get("position"))
            elif action == "seek_relative":
                return await media_control_seek_relative_tool(kwargs.get("offset"))
            else:
                return f"Action non support√©e pour media_control: {action}"
        elif tool_name == "clock":
            action = kwargs.get("action")
            if action == "create_alarm":
                return await clock_create_alarm_tool(
                    duration=kwargs.get("duration"),
                    time=kwargs.get("time"),
                    date=kwargs.get("date"),
                    label=kwargs.get("label"),
                    recurrence=kwargs.get("recurrence")
                )
            elif action == "create_timer":
                return await clock_create_timer_tool(
                    duration=kwargs.get("duration"),
                    time=kwargs.get("time"),
                    label=kwargs.get("label")
                )
            elif action == "show_matching_alarms":
                return await clock_show_matching_alarms_tool(
                    query=kwargs.get("query"),
                    alarm_type=kwargs.get("alarm_type"),
                    alarm_ids=kwargs.get("alarm_ids"),
                    date=kwargs.get("date"),
                    start_date=kwargs.get("start_date"),
                    end_date=kwargs.get("end_date")
                )
            elif action == "show_matching_timers":
                return await clock_show_matching_timers_tool(
                    query=kwargs.get("query"),
                    timer_type=kwargs.get("timer_type"),
                    timer_ids=kwargs.get("timer_ids")
                )
            elif action == "modify_alarm_v2":
                return await clock_modify_alarm_v2_tool(
                    alarm_filters=kwargs.get("alarm_filters"),
                    alarm_modifications=kwargs.get("alarm_modifications")
                )
            elif action == "modify_timer_v2":
                return await clock_modify_timer_v2_tool(
                    timer_filters=kwargs.get("timer_filters"),
                    timer_modifications=kwargs.get("timer_modifications")
                )
            elif action == "snooze":
                return await clock_snooze_tool()
            else:
                return f"Action non support√©e pour clock: {action}"
        elif tool_name == "ocr_space":
            return await ocr_space_tool(kwargs.get("image_base64"))
        elif tool_name == "deepseek_chat":
            return await deepseek_chat_tool(kwargs.get("prompt"), kwargs.get("model"))
        elif tool_name == "serper_dev":
            return await serper_dev_tool(kwargs.get("query_text"))
        elif tool_name == "wolfram_alpha":
            return await wolfram_alpha_tool(kwargs.get("input_text"))
        elif tool_name == "tavily_search":
            return await tavily_search_tool(kwargs.get("query_text"), kwargs.get("max_results"))
        elif tool_name == "apiflash_screenshot":
            return await apiflash_screenshot_tool(kwargs.get("url"))
        elif tool_name == "crawlbase_scraper":
            return await crawlbase_scraper_tool(kwargs.get("url"), kwargs.get("use_js"))
        elif tool_name == "detect_language":
            return await detect_language_tool(kwargs.get("text"))
        elif tool_name == "guardian_news":
            return await guardian_news_tool(kwargs.get("query_text"))
        elif tool_name == "ip2location":
            return await ip2location_tool(kwargs.get("ip_address"))
        elif tool_name == "shodan":
            return await shodan_tool(kwargs.get("query_text"))
        elif tool_name == "weather_api":
            return await weather_api_tool(kwargs.get("location"))
        elif tool_name == "cloudmersive_domain":
            return await cloudmersive_domain_tool(kwargs.get("domain"))
        elif tool_name == "greynoise":
            return await greynoise_tool(kwargs.get("ip_address"))
        elif tool_name == "pulsedive":
            return await pulsedive_tool(kwargs.get("indicator"), kwargs.get("type"))
        elif tool_name == "stormglass":
            return await stormglass_tool(kwargs.get("lat"), kwargs.get("lng"), kwargs.get("params"))
        elif tool_name == "loginradius_ping":
            return await loginradius_ping_tool()
        elif tool_name == "jsonbin_io":
            return await jsonbin_io_tool(kwargs.get("data"), kwargs.get("private"), kwargs.get("bin_id"))
        elif tool_name == "huggingface_inference":
            return await huggingface_inference_tool(kwargs.get("model_name"), kwargs.get("input_text"))
        elif tool_name == "twilio_balance":
            return await twilio_balance_tool()
        elif tool_name == "abstractapi":
            return await abstractapi_tool(kwargs.get("input_value"), kwargs.get("api_type"))
        elif tool_name == "google_custom_search":
            return await google_custom_search_tool(kwargs.get("query_text"))
        elif tool_name == "randommer_phone":
            return await randommer_phone_tool(kwargs.get("country_code"), kwargs.get("quantity"))
        elif tool_name == "tomorrow_io_weather":
            return await tomorrow_io_weather_tool(kwargs.get("location"), kwargs.get("fields"))
        elif tool_name == "openweathermap_weather":
            return await openweathermap_weather_tool(kwargs.get("location"))
        elif tool_name == "mockaroo_data":
            return await mockaroo_data_tool(kwargs.get("count"), kwargs.get("fields_json"))
        elif tool_name == "openpagerank":
            return await openpagerank_tool(kwargs.get("domains"))
        elif tool_name == "rapidapi":
            return await rapidapi_tool(kwargs.get("api_name"), **kwargs.get("api_kwargs", {}))
        else:
            log_message(f"Aucun gestionnaire d'outil d√©fini pour: {tool_name}", level="error")
            return f"Erreur: Aucun gestionnaire d'outil d√©fini pour '{tool_name}'."
    except Exception as e:
        log_message(f"Erreur lors de l'ex√©cution de l'outil {tool_name}: {e}", level="error")
        return f"Erreur lors de l'ex√©cution de l'outil {tool_name}: {e}"

# --- Fonctions d'outils sp√©cifiques (wrappers autour des clients API) ---

async def google_search_tool(queries: List[str]) -> str:
    """Effectue une recherche Google."""
    results = []
    for query in queries:
        log_message(f"Recherche Google pour: {query}")
        # Ici, nous utilisons un client g√©n√©rique pour Google Search
        # car il n'y a pas de client sp√©cifique 'google_search' dans api_clients.py
        # Il faudrait soit cr√©er un GoogleSearchClient, soit utiliser un client existant
        # comme SerperClient ou TavilyClient pour simuler la recherche.
        # Pour l'exemple, nous allons simuler une r√©ponse ou utiliser un client de recherche existant.
        # Si 'google_search' est cens√© utiliser Serper ou Tavily, il faut le mapper ici.
        # Supposons que 'google_search' est un alias pour 'serper_dev' pour cet exemple.
        response = await serper_client.query(query)
        results.append(f"R√©sultat pour '{query}': {response}")
    return "\n".join(results)

async def media_control_like_tool() -> str:
    """Aime le m√©dia en cours de lecture."""
    # Simule l'appel √† l'API media_control.like()
    # Dans un vrai sc√©nario, cela appellerait une API de contr√¥le m√©dia sur l'appareil.
    log_message("Action media_control.like() simul√©e.")
    return "M√©dia actuel aim√©."

async def media_control_dislike_tool() -> str:
    """N'aime pas le m√©dia en cours de lecture."""
    log_message("Action media_control.dislike() simul√©e.")
    return "M√©dia actuel non aim√©."

async def media_control_next_tool() -> str:
    """Passe √† l'√©l√©ment multim√©dia suivant."""
    log_message("Action media_control.next() simul√©e.")
    return "Passage au m√©dia suivant."

async def media_control_previous_tool() -> str:
    """Passe √† l'√©l√©ment multim√©dia pr√©c√©dent."""
    log_message("Action media_control.previous() simul√©e.")
    return "Passage au m√©dia pr√©c√©dent."

async def media_control_pause_tool() -> str:
    """Met en pause le m√©dia en cours de lecture."""
    log_message("Action media_control.pause() simul√©e.")
    return "M√©dia actuel mis en pause."

async def media_control_resume_tool() -> str:
    """Reprend la lecture du m√©dia en pause."""
    log_message("Action media_control.resume() simul√©e.")
    return "Lecture du m√©dia reprise."

async def media_control_stop_tool() -> str:
    """Arr√™te le m√©dia en cours de lecture."""
    log_message("Action media_control.stop() simul√©e.")
    return "M√©dia actuel arr√™t√©."

async def media_control_replay_tool() -> str:
    """Rejoue le m√©dia actuel depuis le d√©but."""
    log_message("Action media_control.replay() simul√©e.")
    return "M√©dia actuel rejou√©."

async def media_control_seek_absolute_tool(position: int) -> str:
    """Saute √† une position absolue dans le m√©dia."""
    log_message(f"Action media_control.seek_absolute({position}) simul√©e.")
    return f"M√©dia avanc√© √† la position {position} secondes."

async def media_control_seek_relative_tool(offset: int) -> str:
    """Ajuste la lecture du m√©dia par une dur√©e relative."""
    log_message(f"Action media_control.seek_relative({offset}) simul√©e.")
    return f"M√©dia avanc√© de {offset} secondes."

async def clock_create_alarm_tool(duration: Optional[str] = None, time: Optional[str] = None, date: Optional[str] = None, label: Optional[str] = None, recurrence: Optional[List[str]] = None) -> str:
    """Cr√©e une alarme."""
    # Simule l'appel √† l'API clock.create_alarm()
    log_message(f"Action clock.create_alarm() simul√©e avec dur√©e={duration}, heure={time}, date={date}, label={label}, r√©currence={recurrence}.")
    return f"Alarme cr√©√©e pour {time if time else duration}."

async def clock_create_timer_tool(duration: Optional[str] = None, time: Optional[str] = None, label: Optional[str] = None) -> str:
    """Cr√©e un minuteur."""
    # Simule l'appel √† l'API clock.create_timer()
    log_message(f"Action clock.create_timer() simul√©e avec dur√©e={duration}, heure={time}, label={label}.")
    return f"Minuteur cr√©√© pour {time if time else duration}."

async def clock_show_matching_alarms_tool(query: Optional[str] = None, alarm_type: Optional[str] = None, alarm_ids: Optional[List[str]] = None, date: Optional[str] = None, start_date: Optional[str] = None, end_date: Optional[str] = None) -> str:
    """Affiche les alarmes correspondantes."""
    # Simule l'appel √† l'API clock.show_matching_alarms()
    log_message(f"Action clock.show_matching_alarms() simul√©e avec query={query}, type={alarm_type}, ids={alarm_ids}, date={date}, start_date={start_date}, end_date={end_date}.")
    return "Affichage des alarmes correspondantes (simul√©)."

async def clock_show_matching_timers_tool(query: Optional[str] = None, timer_type: Optional[str] = None, timer_ids: Optional[List[str]] = None) -> str:
    """Affiche les minuteurs correspondants."""
    # Simule l'appel √† l'API clock.show_matching_timers()
    log_message(f"Action clock.show_matching_timers() simul√©e avec query={query}, type={timer_type}, ids={timer_ids}.")
    return "Affichage des minuteurs correspondants (simul√©)."

async def clock_modify_alarm_v2_tool(alarm_filters: Dict[str, Any], alarm_modifications: Dict[str, Any]) -> str:
    """Modifie une alarme."""
    # Simule l'appel √† l'API clock.modify_alarm_v2()
    log_message(f"Action clock.modify_alarm_v2() simul√©e avec filtres={alarm_filters}, modifications={alarm_modifications}.")
    return "Alarme modifi√©e (simul√©)."

async def clock_modify_timer_v2_tool(timer_filters: Dict[str, Any], timer_modifications: Dict[str, Any]) -> str:
    """Modifie un minuteur."""
    # Simule l'appel √† l'API clock.modify_timer_v2()
    log_message(f"Action clock.modify_timer_v2() simul√©e avec filtres={timer_filters}, modifications={timer_modifications}.")
    return "Minuteur modifi√© (simul√©)."

async def clock_snooze_tool() -> str:
    """Met en veille une alarme."""
    # Simule l'appel √† l'API clock.snooze()
    log_message("Action clock.snooze() simul√©e.")
    return "Alarme mise en veille."

async def ocr_space_tool(image_base64: str) -> str:
    """Extrait le texte d'une image via OCR.space."""
    return await ocr_client.query(image_base64)

async def deepseek_chat_tool(prompt: Union[str, List[Dict]], model: str = "deepseek-chat") -> str:
    """Interroge DeepSeek pour des conversations ou compl√©tions."""
    return await deepseek_client.query(prompt, model)

async def serper_dev_tool(query_text: str) -> str:
    """Effectue une recherche web via Serper."""
    return await serper_client.query(query_text)

async def wolfram_alpha_tool(input_text: str) -> str:
    """Interroge WolframAlpha pour des calculs ou des faits."""
    return await wolfram_alpha_client.query(input_text)

async def tavily_search_tool(query_text: str, max_results: int = 3) -> str:
    """Effectue une recherche web avanc√©e via Tavily."""
    return await tavily_client.query(query_text, max_results)

async def apiflash_screenshot_tool(url: str) -> str:
    """Capture une capture d'√©cran d'une URL via ApiFlash."""
    return await apiflash_client.query(url)

async def crawlbase_scraper_tool(url: str, use_js: bool = False) -> str:
    """Scrape le contenu HTML ou JavaScript d'une URL via Crawlbase."""
    return await crawlbase_client.query(url, use_js)

async def detect_language_tool(text: str) -> str:
    """D√©tecte la langue d'un texte via DetectLanguage API."""
    return await detect_language_client.query(text)

async def guardian_news_tool(query_text: str) -> str:
    """Recherche des articles de presse via l'API The Guardian."""
    return await guardian_client.query(query_text)

async def ip2location_tool(ip_address: str) -> str:
    """G√©olocalise une adresse IP via IP2Location API."""
    return await ip2location_client.query(ip_address)

async def shodan_tool(query_text: str = "") -> str:
    """Interroge Shodan pour des informations sur un h√¥te IP ou des informations sur la cl√© API."""
    return await shodan_client.query(query_text)

async def weather_api_tool(location: str) -> str:
    """R√©cup√®re les conditions m√©t√©orologiques actuelles pour une localisation via WeatherAPI."""
    return await weather_api_client.query(location)

async def cloudmersive_domain_tool(domain: str) -> str:
    """V√©rifie la validit√© et le type d'un domaine via Cloudmersive API."""
    return await cloudmersive_client.query(domain)

async def greynoise_tool(ip_address: str) -> str:
    """Analyse une adresse IP pour d√©tecter des activit√©s 'bruit' (malveillantes) via GreyNoise."""
    return await greynoise_client.query(ip_address)

async def pulsedive_tool(indicator: str, type: str = "auto") -> str:
    """Analyse un indicateur de menace (IP, domaine, URL) via Pulsedive."""
    return await pulsedive_client.query(indicator, type)

async def stormglass_tool(lat: float, lng: float, params: str = "airTemperature,waveHeight") -> str:
    """R√©cup√®re les donn√©es m√©t√©orologiques maritimes pour une coordonn√©e via StormGlass."""
    return await stormglass_client.query(lat, lng, params)

async def loginradius_ping_tool() -> str:
    """Effectue un simple ping √† l'API LoginRadius pour v√©rifier sa disponibilit√©."""
    return await loginradius_client.query()

async def jsonbin_io_tool(data: Optional[Dict[str, Any]] = None, private: bool = True, bin_id: Optional[str] = None) -> str:
    """Cr√©e un nouveau 'bin' JSON ou acc√®de √† un bin existant via Jsonbin.io."""
    return await jsonbin_client.query(data, private, bin_id)

async def huggingface_inference_tool(model_name: str = "distilbert-base-uncased-finetuned-sst-2-english", input_text: str = "Hello world") -> str:
    """Effectue une inf√©rence sur un mod√®le HuggingFace."""
    return await huggingface_client.query(model_name, input_text)

async def twilio_balance_tool() -> str:
    """R√©cup√®re le solde du compte Twilio."""
    return await twilio_client.query()

async def abstractapi_tool(input_value: str, api_type: str) -> str:
    """Interroge diverses APIs d'AbstractAPI."""
    return await abstractapi_client.query(input_value, api_type)

async def google_custom_search_tool(query_text: str) -> str:
    """Effectue une recherche personnalis√©e Google."""
    return await google_custom_search_client.query(query_text)

async def randommer_phone_tool(country_code: str = "US", quantity: int = 1) -> str:
    """G√©n√®re des num√©ros de t√©l√©phone al√©atoires via Randommer.io."""
    return await randommer_client.query(country_code, quantity)

async def tomorrow_io_weather_tool(location: str, fields: Optional[List[str]] = None) -> str:
    """R√©cup√®re les pr√©visions m√©t√©orologiques via Tomorrow.io."""
    return await tomorrow_io_client.query(location, fields)

async def openweathermap_weather_tool(location: str) -> str:
    """R√©cup√®re les conditions m√©t√©orologiques actuelles via OpenWeatherMap."""
    return await openweathermap_client.query(location)

async def mockaroo_data_tool(count: int = 1, fields_json: Optional[str] = None) -> str:
    """G√©n√®re des donn√©es de test via Mockaroo."""
    return await mockaroo_client.query(count, fields_json)

async def openpagerank_tool(domains: List[str]) -> str:
    """R√©cup√®re le PageRank de domaines via OpenPageRank."""
    return await openpagerank_client.query(domains)

async def rapidapi_tool(api_name: str, **api_kwargs) -> str:
    """Interroge diverses APIs disponibles via RapidAPI."""
    return await rapidapi_client.query(api_name, **api_kwargs)

import asyncio
import json
import os
import re
import base64
import mimetypes
import datetime
from typing import Dict, Any, List, Optional, Union, Tuple

# Import des modules et fonctions
from config import (
    API_CONFIG, ENDPOINT_HEALTH_FILE, MAX_IMAGE_SIZE,
    GEMINI_TEMPERATURE, GEMINI_TOP_P, GEMINI_TOP_K, GEMINI_MAX_OUTPUT_TOKENS,
    GEMINI_SAFETY_SETTINGS, TOOL_CONFIG
)
from utils import (
    load_json, save_json, get_current_time, format_datetime, log_message,
    neutralize_urls, find_tool_by_name, get_mime_type_from_base64
)
from api_clients import (
    GeminiAPIClient, OCRApiClient, DeepSeekClient, SerperClient,
    WolframAlphaClient, TavilyClient, ApiFlashClient, CrawlbaseClient,
    DetectLanguageClient, GuardianClient, IP2LocationClient, ShodanClient,
    WeatherAPIClient, CloudmersiveClient, GreyNoiseClient, PulsediveClient,
    StormGlassClient, LoginRadiusClient, JsonbinClient, HuggingFaceClient,
    TwilioClient, AbstractAPIClient, GoogleCustomSearchClient,
    RandommerClient, TomorrowIOClient, OpenWeatherMapClient, MockarooClient,
    OpenPageRankClient, RapidAPIClient,
    EndpointHealthManager, set_endpoint_health_manager_global
)
from tools import execute_tool # Import de la fonction execute_tool

# Initialisation du gestionnaire de sant√© des endpoints
endpoint_health_manager = EndpointHealthManager()
set_endpoint_health_manager_global(endpoint_health_manager)

# Instanciation des clients API
gemini_client = GeminiAPIClient()
ocr_client = OCRApiClient()
deepseek_client = DeepSeekClient()
serper_client = SerperClient()
wolfram_alpha_client = WolframAlphaClient()
tavily_client = TavilyClient()
apiflash_client = ApiFlashClient()
crawlbase_client = CrawlbaseClient()
detect_language_client = DetectLanguageClient()
guardian_client = GuardianClient()
ip2location_client = IP2locationClient()
shodan_client = ShodanClient()
weather_api_client = WeatherAPIClient()
cloudmersive_client = CloudmersiveClient()
greynoise_client = GreyNoiseClient()
pulsedive_client = PulsediveClient()
stormglass_client = StormGlassClient()
loginradius_client = LoginRadiusClient()
jsonbin_client = JsonbinClient()
huggingface_client = HuggingFaceClient()
twilio_client = TwilioClient()
abstractapi_client = AbstractAPIClient()
google_custom_search_client = GoogleCustomSearchClient()
randommer_client = RandommerClient()
tomorrow_io_client = TomorrowIOClient()
openweathermap_client = OpenWeatherMapClient()
mockaroo_client = MockarooClient()
openpagerank_client = OpenPageRankClient()
rapidapi_client = RapidAPIClient()


# D√©finition des outils disponibles pour Gemini
def get_gemini_tools() -> List[Dict]:
    """
    Construit la liste des outils disponibles pour l'API Gemini
    √† partir de la configuration TOOL_CONFIG.
    """
    tools = []
    for tool_name, tool_info in TOOL_CONFIG.items():
        if tool_info.get("enabled", False):
            function_declaration = {
                "name": tool_name,
                "description": tool_info.get("description", ""),
                "parameters": {
                    "type": "OBJECT",
                    "properties": {},
                    "required": []
                }
            }
            for param_name, param_info in tool_info.get("parameters", {}).items():
                function_declaration["parameters"]["properties"][param_name] = {
                    "type": param_info.get("type", "STRING"),
                    "description": param_info.get("description", "")
                }
                if param_info.get("required", False):
                    function_declaration["parameters"]["required"].append(param_name)
            
            # Ajout de la gestion des actions pour les outils "clock" et "media_control"
            if tool_name in ["clock", "media_control"]:
                function_declaration["parameters"]["properties"]["action"] = {
                    "type": "STRING",
                    "description": f"L'action √† effectuer pour l'outil {tool_name}."
                }
                function_declaration["parameters"]["required"].append("action")

                # Ajout des sous-param√®tres sp√©cifiques √† chaque action
                for action_name, action_info in tool_info.get("actions", {}).items():
                    # Cr√©e un objet pour les param√®tres sp√©cifiques √† cette action
                    action_params_props = {}
                    action_required_params = []
                    for param_name, param_info in action_info.get("parameters", {}).items():
                        action_params_props[param_name] = {
                            "type": param_info.get("type", "STRING"),
                            "description": param_info.get("description", "")
                        }
                        if param_info.get("required", False):
                            action_required_params.append(param_name)
                    
                    # Ajoute ces param√®tres comme une propri√©t√© conditionnelle ou imbriqu√©e
                    # Gemini ne supporte pas directement les sch√©mas conditionnels pour les outils.
                    # La meilleure approche est de lister tous les param√®tres possibles et de laisser le mod√®le
                    # choisir ceux qui sont pertinents en fonction de l'action.
                    # Ou, pour une meilleure clart√©, cr√©er des fonctions distinctes pour chaque action si possible.
                    # Pour l'instant, on va juste ajouter les param√®tres √† la liste globale.
                    # C'est au mod√®le de comprendre quels param√®tres sont pertinents pour quelle action.
                    function_declaration["parameters"]["properties"].update(action_params_props)
                    function_declaration["parameters"]["required"].extend(action_required_params)
                    
                    # Pour les filtres et modifications complexes (ex: clock.modify_alarm_v2)
                    if action_name in ["modify_alarm_v2", "modify_timer_v2"]:
                        if "alarm_filters" in action_info.get("parameters", {}):
                            function_declaration["parameters"]["properties"]["alarm_filters"] = {
                                "type": "OBJECT",
                                "description": "Filtres pour identifier les alarmes √† modifier.",
                                "properties": action_info["parameters"]["alarm_filters"].get("properties", {}),
                                "required": action_info["parameters"]["alarm_filters"].get("required", [])
                            }
                        if "alarm_modifications" in action_info.get("parameters", {}):
                            function_declaration["parameters"]["properties"]["alarm_modifications"] = {
                                "type": "OBJECT",
                                "description": "Modifications √† apporter aux alarmes.",
                                "properties": action_info["parameters"]["alarm_modifications"].get("properties", {}),
                                "required": action_info["parameters"]["alarm_modifications"].get("required", [])
                            }
                        if "timer_filters" in action_info.get("parameters", {}):
                            function_declaration["parameters"]["properties"]["timer_filters"] = {
                                "type": "OBJECT",
                                "description": "Filtres pour identifier les minuteurs √† modifier.",
                                "properties": action_info["parameters"]["timer_filters"].get("properties", {}),
                                "required": action_info["parameters"]["timer_filters"].get("required", [])
                            }
                        if "timer_modifications" in action_info.get("parameters", {}):
                            function_declaration["parameters"]["properties"]["timer_modifications"] = {
                                "type": "OBJECT",
                                "description": "Modifications √† apporter aux minuteurs.",
                                "properties": action_info["parameters"]["timer_modifications"].get("properties", {}),
                                "required": action_info["parameters"]["timer_modifications"].get("required", [])
                            }

            tools.append({"function_declarations": [function_declaration]})
    return tools

async def process_user_query(user_query: str, chat_history: List[Dict], image_data: Optional[str] = None) -> Tuple[str, List[Dict]]:
    """
    Traite la requ√™te de l'utilisateur, interagit avec Gemini et ex√©cute les outils si n√©cessaire.
    """
    log_message(f"Requ√™te utilisateur: {user_query}")
    log_message(f"Historique du chat (avant): {chat_history}")

    # Initialiser l'historique du chat si vide
    if not chat_history:
        chat_history = []

    # Obtenir les outils disponibles
    gemini_tools = get_gemini_tools()
    log_message(f"Outils disponibles pour Gemini: {json.dumps(gemini_tools, indent=2)}")

    # Appel √† Gemini
    gemini_response = await gemini_client.generate_content(
        prompt=user_query,
        chat_history=chat_history,
        image_data=image_data,
        tools=gemini_tools
    )

    if isinstance(gemini_response, str) and gemini_response.startswith("‚ùå"):
        log_message(f"Erreur de Gemini: {gemini_response}", level="error")
        return gemini_response, chat_history

    if not gemini_response:
        log_message("R√©ponse vide de Gemini.", level="warning")
        return "D√©sol√©, je n'ai pas pu obtenir de r√©ponse de Gemini.", chat_history

    # Traiter la r√©ponse de Gemini
    try:
        if "candidates" in gemini_response and gemini_response["candidates"]:
            candidate = gemini_response["candidates"][0]
            if "content" in candidate and "parts" in candidate["content"]:
                for part in candidate["content"]["parts"]:
                    if "text" in part:
                        # Si Gemini r√©pond avec du texte, l'ajouter √† l'historique et le retourner
                        chat_history.append({"role": "model", "parts": [{"text": part["text"]}]})
                        log_message(f"R√©ponse textuelle de Gemini: {part['text']}")
                        return part["text"], chat_history
                    elif "functionCall" in part:
                        # Si Gemini demande d'appeler une fonction (outil)
                        function_call = part["functionCall"]
                        tool_name = function_call["name"]
                        tool_args = function_call.get("args", {})
                        log_message(f"Gemini a demand√© l'outil: {tool_name} avec args: {tool_args}")

                        # Ex√©cuter l'outil
                        tool_output = await execute_tool(tool_name, **tool_args)
                        log_message(f"Sortie de l'outil {tool_name}: {tool_output}")

                        # Ajouter la requ√™te de l'outil et sa sortie √† l'historique du chat
                        chat_history.append({"role": "model", "parts": [{"functionCall": function_call}]})
                        chat_history.append({"role": "tool", "parts": [{"functionResponse": {"name": tool_name, "response": {"result": tool_output}}}]})

                        # Rappeler Gemini avec l'historique mis √† jour pour obtenir la r√©ponse finale
                        log_message("Rappel de Gemini apr√®s ex√©cution de l'outil...")
                        final_gemini_response = await gemini_client.generate_content(
                            prompt=user_query, # On garde le prompt original pour le contexte
                            chat_history=chat_history,
                            image_data=image_data,
                            tools=gemini_tools
                        )

                        if isinstance(final_gemini_response, str) and final_gemini_response.startswith("‚ùå"):
                            log_message(f"Erreur de Gemini apr√®s ex√©cution de l'outil: {final_gemini_response}", level="error")
                            return final_gemini_response, chat_history
                        
                        if not final_gemini_response:
                            log_message("R√©ponse vide de Gemini apr√®s ex√©cution de l'outil.", level="warning")
                            return "D√©sol√©, je n'ai pas pu obtenir de r√©ponse de Gemini apr√®s l'ex√©cution de l'outil.", chat_history

                        if "candidates" in final_gemini_response and final_gemini_response["candidates"]:
                            final_candidate = final_gemini_response["candidates"][0]
                            if "content" in final_candidate and "parts" in final_candidate["content"]:
                                for final_part in final_candidate["content"]["parts"]:
                                    if "text" in final_part:
                                        chat_history.append({"role": "model", "parts": [{"text": final_part["text"]}]})
                                        log_message(f"R√©ponse finale de Gemini: {final_part['text']}")
                                        return final_part["text"], chat_history
                                    else:
                                        log_message(f"Partie de r√©ponse finale inattendue de Gemini: {final_part}", level="warning")
                                        return "D√©sol√©, je n'ai pas pu traiter la r√©ponse finale de Gemini.", chat_history
                        log_message("Aucune r√©ponse textuelle finale de Gemini apr√®s ex√©cution de l'outil.", level="warning")
                        return "D√©sol√©, je n'ai pas pu obtenir de r√©ponse textuelle finale de Gemini apr√®s l'ex√©cution de l'outil.", chat_history
            log_message("Aucune partie de contenu valide trouv√©e dans la r√©ponse de Gemini.", level="warning")
            return "D√©sol√©, je n'ai pas pu comprendre la r√©ponse de Gemini.", chat_history
        log_message(f"Aucun candidat valide dans la r√©ponse de Gemini: {gemini_response}", level="warning")
        return "D√©sol√©, Gemini n'a pas fourni de r√©ponse valide.", chat_history
    except Exception as e:
        log_message(f"Erreur lors du traitement de la r√©ponse de Gemini: {e}", level="error")
        log_message(f"Traceback: {traceback.format_exc()}", level="error")
        return f"Une erreur interne est survenue lors du traitement de la r√©ponse: {e}", chat_history

async def main():
    """Fonction principale pour ex√©cuter le chatbot."""
    await endpoint_health_manager.init_manager()
    log_message("D√©marrage du chatbot. Tapez 'quitter' pour arr√™ter.")

    # Lancer les checks de sant√© p√©riodiques en arri√®re-plan
    async def periodic_health_checks():
        while True:
            for service_name in API_CONFIG.keys():
                await endpoint_health_manager.run_health_check_for_service(service_name)
            await asyncio.sleep(300) # V√©rifier toutes les 5 minutes

    asyncio.create_task(periodic_health_checks())

    chat_history = []
    
    # Charger l'historique de chat pr√©c√©dent si disponible
    try:
        if os.path.exists("chat_history.json"):
            with open("chat_history.json", "r", encoding="utf-8") as f:
                loaded_history = json.load(f)
                # S'assurer que les r√¥les sont corrects pour Gemini
                for entry in loaded_history:
                    if entry.get("role") == "user" or entry.get("role") == "model":
                        chat_history.append(entry)
                    elif entry.get("role") == "tool":
                        # Gemini attend functionResponse dans "parts" pour les outils
                        if "functionCall" in entry.get("parts", [{}])[0]:
                            # C'est une requ√™te d'outil, pas une r√©ponse
                            chat_history.append(entry)
                        elif "functionResponse" in entry.get("parts", [{}])[0]:
                            chat_history.append(entry)
                        else:
                            log_message(f"Entr√©e d'historique d'outil inattendue: {entry}", level="warning")
                            # Tenter de convertir si c'est un format ancien
                            if "tool_code" in entry.get("parts", [{}])[0]:
                                tool_code_str = entry["parts"][0]["tool_code"]
                                # Extraire le nom de l'outil et la sortie
                                match = re.search(r"print\((\w+)\.([\w_]+)\((.*)\)\)", tool_code_str)
                                if match:
                                    tool_api_name = match.group(1)
                                    tool_method_name = match.group(2)
                                    # Pour l'historique, on a besoin du nom de l'outil tel que d√©fini dans TOOL_CONFIG
                                    # Il faut une meilleure fa√ßon de mapper les m√©thodes API aux noms d'outils.
                                    # Pour l'instant, on va juste utiliser le nom de la m√©thode comme nom d'outil.
                                    tool_name_for_history = tool_method_name 
                                    
                                    # Simuler la r√©ponse de l'outil
                                    tool_response_content = entry.get("parts", [{}])[1].get("text", "R√©ponse outil non sp√©cifi√©e.")
                                    chat_history.append({
                                        "role": "tool",
                                        "parts": [{
                                            "functionResponse": {
                                                "name": tool_name_for_history,
                                                "response": {"result": tool_response_content}
                                            }
                                        }]
                                    })
                                else:
                                    log_message(f"Impossible de parser l'entr√©e tool_code: {tool_code_str}", level="warning")
                            else:
                                log_message(f"Entr√©e d'historique d'outil non reconnue: {entry}", level="warning")

                log_message("Historique du chat charg√© avec succ√®s.")
    except Exception as e:
        log_message(f"Erreur lors du chargement de l'historique du chat: {e}", level="error")
        chat_history = [] # R√©initialiser en cas d'erreur

    while True:
        user_input = input("Vous: ")
        if user_input.lower() == "quitter":
            break

        image_path = None
        image_data = None
        
        # V√©rifier si l'utilisateur a fourni un chemin d'image
        image_match = re.search(r"\[image:(.+)\]", user_input)
        if image_match:
            image_path = image_match.group(1).strip()
            user_input = user_input.replace(image_match.group(0), "").strip() # Supprimer la balise image du prompt

            if os.path.exists(image_path):
                try:
                    with open(image_path, "rb") as image_file:
                        raw_image_data = image_file.read()
                        if len(raw_image_data) > MAX_IMAGE_SIZE:
                            log_message(f"L'image d√©passe la taille maximale autoris√©e ({MAX_IMAGE_SIZE / (1024*1024):.2f} Mo).", level="warning")
                            print(f"‚ö†Ô∏è L'image est trop grande. Taille max: {MAX_IMAGE_SIZE / (1024*1024):.2f} Mo.")
                            image_data = None # Ne pas envoyer l'image si elle est trop grande
                        else:
                            base64_encoded_image = base64.b64encode(raw_image_data).decode('utf-8')
                            mime_type = get_mime_type_from_base64(base64_encoded_image)
                            if mime_type:
                                image_data = f"data:{mime_type};base64,{base64_encoded_image}"
                                log_message(f"Image charg√©e et encod√©e en base64: {image_path} (MIME: {mime_type})")
                            else:
                                log_message(f"Impossible de d√©terminer le type MIME de l'image: {image_path}", level="warning")
                                image_data = base64_encoded_image # Envoyer sans MIME si non d√©tect√©
                except Exception as e:
                    log_message(f"Erreur lors du chargement de l'image {image_path}: {e}", level="error")
                    print(f"‚ùå Erreur lors du chargement de l'image: {e}")
                    image_data = None
            else:
                log_message(f"Fichier image non trouv√©: {image_path}", level="warning")
                print(f"‚ùå Erreur: Fichier image '{image_path}' non trouv√©.")
                image_data = None

        # Ajouter la requ√™te utilisateur √† l'historique
        user_parts = [{"text": user_input}]
        if image_data:
            # Si l'image est incluse, elle sera ajout√©e par generate_content
            pass
        chat_history.append({"role": "user", "parts": user_parts})

        response, chat_history = await process_user_query(user_input, chat_history, image_data)
        print(f"Bot: {response}")

        # Sauvegarder l'historique apr√®s chaque tour
        try:
            # Nettoyer l'historique pour la sauvegarde:
            # - Enlever les donn√©es d'image base64 (trop volumineux, non n√©cessaire pour la persistance)
            # - S'assurer que les objets functionCall/functionResponse sont bien format√©s
            history_to_save = []
            for entry in chat_history:
                new_entry = entry.copy()
                if "parts" in new_entry:
                    new_parts = []
                    for part in new_entry["parts"]:
                        if "inlineData" in part:
                            # Ne pas sauvegarder les donn√©es d'image brutes
                            new_part = part.copy()
                            new_part["inlineData"] = {"mimeType": part["inlineData"]["mimeType"], "data": "[IMAGE_DATA_REMOVED_FOR_SAVE]"}
                            new_parts.append(new_part)
                        else:
                            new_parts.append(part)
                    new_entry["parts"] = new_parts
                history_to_save.append(new_entry)
            
            with open("chat_history.json", "w", encoding="utf-8") as f:
                json.dump(history_to_save, f, indent=2, ensure_ascii=False)
            log_message("Historique du chat sauvegard√©.")
        except Exception as e:
            log_message(f"Erreur lors de la sauvegarde de l'historique du chat: {e}", level="error")

if __name__ == "__main__":
    import traceback
    try:
        asyncio.run(main())
    except KeyboardInterrupt:
        log_message("Chatbot arr√™t√© par l'utilisateur.")
    except Exception as e:
        log_message(f"Une erreur inattendue est survenue: {e}", level="critical")
        log_message(f"Traceback: {traceback.format_exc()}", level="critical")








# -*- coding: utf-8 -*-
# Type: OPTIMISATION

# ----------------------------
# IA/DEV TOOLS (pyflakes, black, ast, etc.)
# ----------------------------

import os
import io
import contextlib
import subprocess
import asyncio
import time
import random
import json
import base64
import httpx
import ast
import difflib
import concurrent.futures
from concurrent.futures import ThreadPoolExecutor
from datetime import datetime
from functools import lru_cache
import re
import hashlib
from urllib.parse import urlparse

# Assuming these are available in the environment or defined elsewhere
# from pyflakes.api import check, Reporter
# import black
# import pytesseract
# from PIL import Image
# from your_config_module import config, PRIVATE_GROUP_ID, DAILY_CHALLENGE_PATH, API_CONFIG
# from your_orchestrator_module import orchestrator, quota_manager, endpoint_health_manager
# from your_memory_module import memory_manager
# from your_bot_types import ContextTypes
# from your_cig_module import CIG # Assuming CIG is a function for AI calls

# Global variable for verbose mode
VERBOSE = os.getenv("VERBOSE_MODE", "false").lower() == "true"

def syntax_highlight(code: str) -> str:
    """
    Met en √©vidence la syntaxe du code Python pour l'affichage dans un terminal,
    si pygments est disponible et si la sortie est un TTY.
    """
    from sys import stdout
    if stdout.isatty():  # Uniquement dans un terminal
        try:
            from pygments import highlight
            from pygments.lexers import PythonLexer
            from pygments.formatters import TerminalFormatter
            return highlight(code, PythonLexer(), TerminalFormatter(bg="dark"))
        except ImportError:
            # Fallback if pygments is not installed
            if VERBOSE:
                print("[DEBUG] Pygments non trouv√©, retour du code brut pour la coloration syntaxique.")
            pass
    return code  # Retour brut si couleurs non disponibles ou non TTY

def check_code(code: str) -> str:
    """
    V√©rifie le code Python pour les erreurs de style et les probl√®mes potentiels
    en utilisant pyflakes (simulation si non disponible).
    """
    try:
        # Assuming Reporter and check are imported from pyflakes.api
        from pyflakes.api import check, Reporter
        out = io.StringIO()
        reporter = Reporter(out, out)
        check(code, filename="<string>", reporter=reporter)
        return out.getvalue()
    except ImportError:
        if VERBOSE:
            print("[DEBUG] Pyflakes non trouv√©, simulation de la v√©rification de code.")
        # Simple simulation if pyflakes is not available
        warnings = []
        if "import os" in code and ("os.remove" in code or "os.system" in code):
            warnings.append("AVERTISSEMENT: Utilisation potentielle de fonctions 'os' dangereuses d√©tect√©e.")
        if "while True" in code and "sleep" not in code:
            warnings.append("AVERTISSEMENT: Boucle infinie potentielle d√©tect√©e sans pause.")
        return "\n".join(warnings) if warnings else "Aucun probl√®me majeur d√©tect√© (simulation)."


def format_code(code: str, max_length: int = 1000) -> str:
    """
    Formate le code Python en utilisant Black et tronque la sortie si elle est trop longue.
    """
    try:
        # Assuming black is imported
        import black
        formatted = black.format_str(code, mode=black.Mode())
        if len(formatted) > max_length:
            return (
                f"‚ö†Ô∏è Code format√© (tronqu√© √† {max_length} caract√®res)\n"
                "‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\n"
                f"{formatted[:max_length//2]}\n...\n{formatted[-max_length//2:]}\n"
                "‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ"
            )
        return formatted
    except ImportError:
        if VERBOSE:
            print("[DEBUG] Black non trouv√©, retour du code brut pour le formatage.")
        return code # Return original code if black is not installed
    except Exception as e:
        return f"‚ùå Format error: {e}"

def extract_functions(code: str):
    """
    Extrait les noms des fonctions d√©finies dans le code Python.
    """
    try:
        tree = ast.parse(code)
        return [node.name for node in ast.walk(tree) if isinstance(node, ast.FunctionDef)]
    except Exception as e:
        return f"‚ùå AST error: {e}"

@lru_cache(maxsize=100)
def analyze_code_structure(code: str):
    """
    Analyse la structure AST du code Python et retourne une repr√©sentation indent√©e.
    Utilise un cache LRU pour les analyses r√©p√©t√©es.
    """
    try:
        tree = ast.parse(code)
        return ast.dump(tree, indent=2)  # Indentation ajout√©e
    except Exception as e:
        return f"‚ùå Erreur d'analyse AST: {e}"

def read_image_text(image_path: str) -> str:
    """
    Extrait le texte d'une image en utilisant Tesseract OCR.
    """
    try:
        # Assuming pytesseract and Image are imported
        import pytesseract
        from PIL import Image
        return pytesseract.image_to_string(Image.open(image_path))
    except ImportError:
        return "‚ùå OCR error: pytesseract ou Pillow non install√©s."
    except Exception as e:
        return f"‚ùå OCR error: {e}"

def run_python(code_str: str):
    """
    Ex√©cute une cha√Æne de code Python dans l'environnement actuel.
    """
    try:
        exec_globals = {}
        exec(code_str, exec_globals)
        return exec_globals
    except Exception as e:
        return f"‚ùå Python error: {e}"

def run_shell(cmd: str) -> str:
    """
    Ex√©cute une commande shell et retourne sa sortie.
    """
    try:
        result = subprocess.check_output(cmd, shell=True, stderr=subprocess.STDOUT)
        return result.decode()
    except subprocess.CalledProcessError as e:
        return f"‚ùå Shell error: {e.output.decode()}"

# Pour les ex√©cutions en sandbox
executor = ThreadPoolExecutor(max_workers=1)

async def run_in_sandbox(code: str, language: str = "python") -> str:
    """
    Ex√©cute du code Python ou Shell dans une sandbox s√©curis√©e avec mesure du temps.
    """
    start_time = time.perf_counter()
    
    # Assuming filter_bad_code is defined elsewhere
    # if filter_bad_code(code):
    #     return "‚ùå S√©curit√©: Le code contient des motifs potentiellement dangereux et n'a pas √©t√© ex√©cut√©."
    
    # Placeholder for filter_bad_code if not defined
    if "import os" in code and ("os.remove" in code or "os.system" in code):
        return "‚ùå S√©curit√©: Le code contient des motifs potentiellement dangereux (os.remove/os.system) et n'a pas √©t√© ex√©cut√©."


    loop = asyncio.get_running_loop()
    if language == "python":
        result = await loop.run_in_executor(executor, _run_python_sync, code)
    elif language == "shell":
        result = await loop.run_in_executor(executor, _run_shell_sync, code)
    else:
        result = "‚ùå Langage non support√© pour la sandbox."
    
    elapsed = time.perf_counter() - start_time
    if "‚ùå" in result:
        return f"{result}\n‚è±Ô∏è Temps avant erreur: {elapsed:.2f}s"
    return f"{result}\n‚åõ Ex√©cut√© en: {elapsed:.2f}s"

def _run_python_sync(code: str) -> str:
    """
    Ex√©cute le code Python de mani√®re synchrone dans un environnement restreint.
    Capture la sortie standard et les erreurs.
    """
    old_stdout = io.StringIO()
    old_stderr = io.StringIO()
    with contextlib.redirect_stdout(old_stdout), contextlib.redirect_stderr(old_stderr):
        try:
            # Restrict builtins for security
            exec(code, {'__builtins__': {}})
            output = old_stdout.getvalue()
            error = old_stderr.getvalue()
            if error:
                return f"üêç Sortie partielle:\n{output}\n\nüî¥ Erreurs:\n{error}"
            return f"‚úÖ Sortie:\n{output}"
        except Exception as e:
            return (
                "‚ùå ERREUR D'EX√âCUTION\n"
                f"Type: {type(e).__name__}\n"
                f"D√©tails: {str(e)}\n\n"
                "--- Sortie standard ---\n"
                f"{old_stdout.getvalue()}\n\n"
                "--- Logs d'erreur ---\n"
                f"{old_stderr.getvalue()}"
            )

def _run_shell_sync(command: str) -> str:
    """
    Ex√©cute une commande shell de mani√®re synchrone et s√©curis√©e.
    """
    try:
        result = subprocess.run(
            command,
            shell=True,
            capture_output=True,
            text=True,
            check=True,
            timeout=10
        )
        output = result.stdout
        error = result.stderr
        if error:
            return f"üêö Erreur Shell:\n{error}\nSortie:\n{output}"
        return f"‚úÖ Sortie Shell:\n{output}"
    except subprocess.CalledProcessError as e:
        return f"‚ùå Erreur d'ex√©cution Shell (Code: {e.returncode}):\n{e.stderr}\nSortie:\n{e.stdout}"
    except subprocess.TimeoutExpired:
        return "‚ùå Erreur Shell: La commande a d√©pass√© le temps d'ex√©cution imparti."
    except Exception as e:
        return f"‚ùå Erreur inattendue lors de l'ex√©cution Shell: {e}"

async def analyze_python_code(code: str) -> str:
    """
    Analyse le code Python pour la syntaxe, la compilation et les probl√®mes potentiels
    (comme l'utilisation de os.remove).
    """
    try:
        ast.parse(code)
    except SyntaxError as e:
        return f"‚ùå Erreur de syntaxe Python: {e}"

    # Ajout pour attraper les erreurs de compilation (ex: variables non d√©finies)
    try:
        compile(code, '<string>', 'exec')
    except Exception as e:
        return f"‚ùå Erreur de compilation Python: {e}\nCode analys√©:\n{code[:500]}"

    formatted_code = code # Assuming format_code would be called here if needed
    pyflakes_output = []
    if "import os" in code and "os.remove" in code:
        pyflakes_output.append("AVERTISSEMENT: Utilisation potentielle de os.remove d√©tect√©e.")

    if pyflakes_output:
        return f"Code format√© (Black):\n```python\n{formatted_code}\n```\n\nAnalyses Pyflakes (simul√©):\n" + "\n".join(pyflakes_output)
    return f"Code format√© (Black):\n```python\n{formatted_code}\n```\n\nAnalyse Pyflakes: Aucun probl√®me majeur d√©tect√© (simulation)."

# --- OCR Tool ---
async def perform_ocr(image_url: str, api_key: str, endpoint: str) -> str:
    """
    Effectue une reconnaissance optique de caract√®res (OCR) sur une image via une API externe.
    """
    try:
        async with httpx.AsyncClient(timeout=10) as client:
            img_response = await client.get(image_url)
            img_response.raise_for_status()

        img_data = base64.b64encode(img_response.content).decode('utf-8')
        headers = {"Content-Type": "application/json", "Apikey": api_key}
        payload = {"base64_image": img_data}

        ocr_endpoint = f"{endpoint}/image/recognize/extractText" if "cloudmersive" in endpoint.lower() else endpoint

        async with httpx.AsyncClient(timeout=30) as client:
            response = await client.post(ocr_endpoint, json=payload, headers=headers)
            response.raise_for_status()
            result = response.json()

        if "TextExtracted" in result:
            return f"‚úÖ Texte extrait par OCR:\n{result['TextExtracted']}"
        elif "extractedText" in result:
            return f"‚úÖ Texte extrait par OCR:\n{result['extractedText']}"
        else:
            return f"‚ùå OCR: Format de r√©ponse API inconnu. R√©ponse brute: {result}"

    except httpx.HTTPStatusError as e:
        # Assuming log_message is defined elsewhere
        # log_message(f"Erreur HTTP/r√©seau lors de l'OCR: {e.response.status_code} - {e.response.text}", level="error")
        if VERBOSE:
            print(f"[ERROR] Erreur HTTP/r√©seau lors de l'OCR: {e.response.status_code} - {e.response.text}")
        return f"‚ùå Erreur lors de l'OCR (r√©seau/API): {e}"
    except httpx.RequestError as e:
        # log_message(f"Erreur de requ√™te lors de l'OCR: {e}", level="error")
        if VERBOSE:
            print(f"[ERROR] Erreur de requ√™te lors de l'OCR: {e}")
        return f"‚ùå Erreur lors de l'OCR (requ√™te): {e}"
    except json.JSONDecodeError:
        return "‚ùå OCR: R√©ponse non JSON de l'API."
    except Exception as e:
        # log_message(f"Erreur inattendue lors de l'OCR: {e}", level="error")
        if VERBOSE:
            print(f"[ERROR] Erreur inattendue lors de l'OCR: {e}")
        return f"‚ùå Erreur inattendue lors de l'OCR: {e}"


CODING_CHALLENGE_PROMPT = """
En tant qu'IA de d√©veloppement de 2025, ton r√¥le est d'am√©liorer et de tester des morceaux de code Python/Shell.
Tu as acc√®s √† une sandbox s√©curis√©e pour ex√©cuter le code.
Tes r√©ponses doivent inclure le code corrig√© ou am√©lior√©, et les r√©sultats de l'ex√©cution en sandbox.
Apporte des am√©liorations significatives, ne te contente pas de corrections triviales si la question implique un projet plus large.
Pense √† l'efficacit√© du code et √† l'optimisation des ressources.
Chaque version doit √™tre une am√©lioration nette de la pr√©c√©dente, in√©dite.
Commence par un commentaire indiquant ce qui a √©t√© am√©lior√©.
Le code doit √™tre direct, lisible, et pr√™t √† √™tre utilis√©.
"""

# -------------------------------------------------------------------------
# CODING CHALLENGE TOUTES IA EN PARALL√àLE
# -------------------------------------------------------------------------
CODING_CHALLENGE_ENABLED = True
# Assuming DAILY_CHALLENGE_PATH is a Path object from pathlib
# LAST_CHALLENGE_FILE = DAILY_CHALLENGE_PATH / "last_challenge.py"
# HISTORY_DIR = DAILY_CHALLENGE_PATH / "history"
# HISTORY_DIR.mkdir(exist_ok=True)

# Placeholder for DAILY_CHALLENGE_PATH and HISTORY_DIR if not defined
class PathPlaceholder:
    def __init__(self, path_str):
        self.path_str = path_str
    def __truediv__(self, other):
        return PathPlaceholder(f"{self.path_str}/{other}")
    def write_text(self, content, encoding):
        if VERBOSE:
            print(f"[DEBUG] Simulating write to {self.path_str}: {content[:100]}...")
    def mkdir(self, exist_ok=True):
        if VERBOSE:
            print(f"[DEBUG] Simulating mkdir {self.path_str}, exist_ok={exist_ok}")
    def __str__(self,):
        return self.path_str

DAILY_CHALLENGE_PATH = PathPlaceholder("daily_challenges")
HISTORY_DIR = DAILY_CHALLENGE_PATH / "history"
HISTORY_DIR.mkdir(exist_ok=True)


def diff_text(old_text, new_text):
    """
    G√©n√®re un diff unifi√© entre deux cha√Ænes de texte.
    """
    diff = difflib.unified_diff(
        old_text.splitlines(), new_text.splitlines(), lineterm=""
    )
    return "\n".join(diff)

async def coding_challenge_loop():
    """
    Boucle principale pour l'ex√©cution p√©riodique des d√©fis de codage par les IA.
    """
    while True:
        if not CODING_CHALLENGE_ENABLED:
            await asyncio.sleep(900)
            continue

        challenge_types = [
            "ALGORITHME", "OPTIMISATION", 
            "DEBUG", "IA CREATIVE", "SCRIPT UTILE"
        ]
        challenge_type = random.choice(challenge_types)
        
        prompt = f"""
[ D√âFI {challenge_type} - {datetime.now().strftime('%Y-%m-%d')} ]
Tu es une IA experte en programmation Python. G√©n√®re un script clair, correct et optimis√©, 100% en fran√ßais.
Ne dis pas que tu ne sais pas, ne t'excuse pas, ne formule pas de r√©ponses vagues.
Chaque version doit √™tre une am√©lioration nette de la pr√©c√©dente.
Commence par un commentaire indiquant ce qui a √©t√© am√©lior√©.
Le code doit √™tre direct, lisible, et pr√™t √† √™tre utilis√©.
"""

        # Version universelle pour toutes les configurations d'API
        ia_list = []
        
        # Placeholder for config object
        class ConfigPlaceholder:
            # Removed OpenRouter configuration as per user request
            TAVILY_KEYS = [TAVILY_KEY_1, TAVILY_KEY_2, TAVILY_KEY_3, TAVILY_KEY_4]
            SERPER_KEY = SERPER_KEY
            HUGGINGFACE_KEYS = [HUGGINGFACE_KEY_1, HUGGINGFACE_KEY_2, HUGGINGFACE_KEY_3, HUGGINGFACE_NEW_KEY]
            WOLFRAM_APP_IDS = [WOLFRAM_APP_ID_1, WOLFRAM_APP_ID_2, WOLFRAM_APP_ID_3]
            GOOGLE_API_KEY = GOOGLE_API_KEYS[0] # Using the first Google API key for general Google calls if needed
            GOOGLE_CX_LIST = GOOGLE_CX_LIST
            GEMINI_API_KEY = GEMINI_API_KEY # Added for Gemini
            DEEPSEEK_KEYS = [DEEPSEEK_KEY_1, DEEPSEEK_KEY_2] # Added for Deepseek
            PRIVATE_GROUP_ID = PRIVATE_GROUP_ID # Use the actual private group ID
            bot_instance = None # Placeholder for a bot instance

        config = ConfigPlaceholder()

        # Configuration Deepseek
        if hasattr(config, 'DEEPSEEK_KEYS'):
            ia_list.extend([(f"Deepseek-{i+1}", k) for i, k in enumerate(config.DEEPSEEK_KEYS)])

        # Configuration Tavily
        if hasattr(config, 'TAVILY_KEYS'):
            ia_list.extend([(f"Tavily-{i+1}", k) for i, k in enumerate(config.TAVILY_KEYS)])
        
        # Configuration Serper
        if hasattr(config, 'SERPER_KEY'):
            ia_list.append(("Serper", config.SERPER_KEY))
        
        # Configuration HuggingFace
        if hasattr(config, 'HUGGINGFACE_KEYS'):
            ia_list.extend([(f"HuggingFace-{i+1}", k) for i, k in enumerate(config.HUGGINGFACE_KEYS)])
        
        # Configuration Wolfram
        if hasattr(config, 'WOLFRAM_APP_IDS'):
            ia_list.extend([(f"Wolfram-{i+1}", k) for i, k in enumerate(config.WOLFRAM_APP_IDS)])
        
        # Configuration Google (Custom Search)
        if hasattr(config, 'GOOGLE_API_KEY') and hasattr(config, 'GOOGLE_CX_LIST'):
            for i, cx in enumerate(config.GOOGLE_CX_LIST):
                ia_list.append((f"GoogleCX-{i+1}", config.GOOGLE_API_KEY))

        # Configuration Gemini
        if hasattr(config, 'GEMINI_API_KEY'):
            ia_list.append(("Gemini", config.GEMINI_API_KEY))

        async def call_ia(nom, cle):
            """
            Appelle une IA sp√©cifique pour g√©n√©rer du code et le sauvegarde.
            """
            try:
                # Assuming CIG is defined elsewhere for AI calls
                # r = await CIG(prompt, api_key=cle, model_name=nom)
                r = f"# Code g√©n√©r√© par {nom} pour le d√©fi {challenge_type}\nprint('Hello from {nom}')" # Dummy response for testing
                
                if r and len(r.strip()) > 20:
                    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
                    fpath = DAILY_CHALLENGE_PATH / f"challenge_{nom}_{timestamp}.py"
                    header = (
                        f"# -*- coding: utf-8 -*-\n"
                        f"# Challenge g√©n√©r√© par {nom}\n"
                        f"# Date: {timestamp}\n"
                        f"# Type: {challenge_type}\n\n"
                    )
                    with open(str(fpath), "w", encoding="utf-8") as f: # Use str(fpath) for PathPlaceholder compatibility
                        f.write(header + r.strip())
                    
                    if hasattr(config, 'PRIVATE_GROUP_ID') and hasattr(config, 'bot_instance') and config.PRIVATE_GROUP_ID and config.bot_instance:
                        await config.bot_instance.send_message(
                            chat_id=config.PRIVATE_GROUP_ID,
                            text=f"üíª <b>Code g√©n√©r√© par {nom}</b> :\n<pre>{r[:600]}</pre>",
                            parse_mode="HTML"
                        )
                    return r
                else:
                    if hasattr(config, 'PRIVATE_GROUP_ID') and hasattr(config, 'bot_instance') and config.PRIVATE_GROUP_ID and config.bot_instance:
                        await config.bot_instance.send_message(
                            chat_id=config.PRIVATE_GROUP_ID,
                            text=f"‚ö†Ô∏è <b>{nom}</b> n'a pas g√©n√©r√© de code valable cette fois.",
                            parse_mode="HTML"
                        )
                    return None
            except Exception as e:
                if hasattr(config, 'PRIVATE_GROUP_ID') and hasattr(config, 'bot_instance') and config.PRIVATE_GROUP_ID and config.bot_instance:
                    await config.bot_instance.send_message(
                        chat_id=config.PRIVATE_GROUP_ID,
                        text=f"‚ùå <b>{nom}</b> erreur lors de l'appel IA : {e}",
                        parse_mode="HTML"
                    )
                return None

        results = await asyncio.gather(*[call_ia(n, k) for n, k in ia_list])
        await asyncio.sleep(900)

async def start_background_tasks(app):
    """
    D√©marre les t√¢ches de fond pour le d√©fi de codage.
    """
    asyncio.create_task(coding_challenge_loop())
    

async def coding_challenge_periodic(context): # ContextTypes.DEFAULT_TYPE
    """
    T√¢che p√©riodique pour lancer les d√©fis de codage et g√©rer les r√©ponses des IA.
    """
    # Assuming log_message is defined elsewhere
    # log_message("Lancement de la t√¢che de d√©fi de codage...")
    if VERBOSE:
        print("[DEBUG] Lancement de la t√¢che de d√©fi de codage...")
    
    # Placeholder for memory_manager, orchestrator, quota_manager, PRIVATE_GROUP_ID
    class DummyMemoryManager:
        async def get_group_memory(self, group_id, limit): return "Dummy memory data."
        def update_ia_status(self, ia_name, status, error=None): pass
        async def save_group_memory(self, group_id, role, content): pass
    
    class DummyOrchestrator:
        def __init__(self):
            self.api_clients = {"DEEPSEEK": self, "HUGGINGFACE": self, "GEMINI_API": self}
        async def query(self, prompt): return f"# Dummy code from {self.name}\nprint('Hello from {self.name}')"
        def get(self, name):
            self.name = name
            return self

    class DummyQuotaManager:
        async def check_and_update_quota(self, ia_name): return True

    memory_manager = DummyMemoryManager()
    orchestrator = DummyOrchestrator()
    quota_manager = DummyQuotaManager()
    PRIVATE_GROUP_ID = PRIVATE_GROUP_ID # Use the actual private group ID

    group_mem = await memory_manager.get_group_memory(PRIVATE_GROUP_ID, limit=50)
    full_prompt = f"{CODING_CHALLENGE_PROMPT}\n\nM√©moire r√©cente du groupe:\n{group_mem}\n\nD√©fi du jour:"
    
    relevant_ias = ["DEEPSEEK", "HUGGINGFACE", "GEMINI_API"]
    results = []
    
    for ia_name in relevant_ias:
        ia_client = orchestrator.api_clients.get(ia_name)
        if ia_client and await quota_manager.check_and_update_quota(ia_name):
            try:
                if VERBOSE:
                    print(f"[DEBUG] IA {ia_name} tente de r√©soudre le d√©fi...")
                # log_message(f"IA {ia_name} tente de r√©soudre le d√©fi...")
                resp = await ia_client.query(full_prompt)
                results.append((ia_name, resp))
                memory_manager.update_ia_status(ia_name, True)
            except Exception as e:
                # log_message(f"Erreur avec {ia_name}: {e}", level="error")
                if VERBOSE:
                    print(f"[ERROR] Erreur avec {ia_name}: {e}")
                memory_manager.update_ia_status(ia_name, False, str(e))
            await asyncio.sleep(0.5)

    if results:
        for name, resp in results:
            code_content = resp
            if resp.startswith("```python") and resp.endswith("```"):
                code_content = resp[9:-3].strip()
            
            fname = f"challenge_{name}_{datetime.now().strftime('%Y%m%d_%H%M%S')}.py"
            fpath = DAILY_CHALLENGE_PATH / fname
            header = (
                f"# -*- coding: utf-8 -*-\n"
                f"# Challenge g√©n√©r√© par {name}\n"
                f"# Date: {datetime.now().strftime('%Y%m%d_%H%M%S')}\n"
                f"# Type: CODING_CHALLENGE\n\n"
            )
            try:
                with open(str(fpath), "w", encoding="utf-8") as f: # Use str(fpath) for PathPlaceholder compatibility
                    f.write(header + code_content)
                # log_message(f"D√©fi sauvegard√©: {fpath}")
                if VERBOSE:
                    print(f"[DEBUG] D√©fi sauvegard√©: {fpath}")
            except Exception as e:
                # log_message(f"Erreur sauvegarde {fname}: {e}", level="error")
                if VERBOSE:
                    print(f"[ERROR] Erreur sauvegarde {fname}: {e}")

            # Assuming context.bot.send_message is available
            if PRIVATE_GROUP_ID and hasattr(context, 'bot') and hasattr(context.bot, 'send_message'):
                display_code = code_content[:1500] + "..." if len(code_content) > 1500 else code_content
                await context.bot.send_message(
                    chat_id=PRIVATE_GROUP_ID,
                    text=f"üíª <b>D√©fi {name}</b> :\n<pre>{display_code}</pre>",
                    parse_mode="HTML"
                )
            
            await memory_manager.save_group_memory(
                PRIVATE_GROUP_ID, 
                "bot", 
                f"D√©fi codage {name} : {code_content[:100]}"
            )
    else:
        # log_message("Aucune IA n'a g√©n√©r√© de code valide", level="warning")
        if VERBOSE:
            print("[DEBUG] Aucune IA n'a g√©n√©r√© de code valide")
        if PRIVATE_GROUP_ID and hasattr(context, 'bot') and hasattr(context.bot, 'send_message'):
            await context.bot.send_message(
                chat_id=PRIVATE_GROUP_ID,
                text="üòî Aucune IA n'a pu g√©n√©rer de code pour le d√©fi cette fois-ci."
            )

async def periodic_health_check(context): # ContextTypes.DEFAULT_TYPE
    """
    Effectue des v√©rifications de sant√© p√©riodiques pour les services API.
    """
    # log_message("Lancement des health checks p√©riodiques...")
    if VERBOSE:
        print("[DEBUG] Lancement des health checks p√©riodiques...")
    
    # Placeholder for API_CONFIG and endpoint_health_manager
    class DummyEndpointHealthManager:
        async def run_health_check_for_service(self, service_name):
            if VERBOSE:
                print(f"[DEBUG] Simulating health check for {service_name}")

    API_CONFIG = {"SERVICE_A": {}, "SERVICE_B": {}}
    endpoint_health_manager = DummyEndpointHealthManager()

    for service_name in API_CONFIG.keys():
        await endpoint_health_manager.run_health_check_for_service(service_name)
    # log_message("Health checks termin√©s.")
    if VERBOSE:
        print("[DEBUG] Health checks termin√©s.")

async def send_structured_report(context, report_data: dict): # ContextTypes.DEFAULT_TYPE
    """
    Envoie un rapport structur√© d'action de l'IA √† un groupe priv√©.
    """
    try:
        report_text = f"üìä **Rapport d'Action IA**\n\n"
        report_text += f"**Timestamp**: `{report_data.get('timestamp')}`\n"
        report_text += f"**Agent**: `{report_data.get('agent_name')}`\n"
        report_text += f"**Intention**: `{report_data.get('intention')}`\n"
        report_text += f"**Requ√™te**: `{report_data.get('user_query')}`\n"
        
        primary_ai = report_data.get('primary_ai_used', 'N/A')
        if isinstance(primary_ai, dict) and 'name' in primary_ai:
            primary_ai = primary_ai['name']
        report_text += f"**IA Primaire**: `{primary_ai}`\n"
        
        tools = report_data.get('tools_called', [])
        if tools:
            report_text += "**Outils Appel√©s**:\n"
            for tool in tools:
                tool_result = str(tool['result'])
                if len(tool_result) > 100:
                    tool_result = tool_result[:100] + "..."
                escaped_params = json.dumps(tool['params'], indent=2)
                escaped_params = escaped_params.replace('_', '\\_').replace('*', '\\*').replace('`', '\\`')
                report_text += f"- `{tool['name']}` (Params: ```json\n{escaped_params}\n```, R√©sultat: `{tool_result}`)\n"
        else:
            report_text += "**Outils Appel√©s**: Aucun\n"
        
        final_resp = report_data.get('final_response', '')
        if len(final_resp) > 500:
            final_resp = final_resp[:500] + "..."
        final_resp = final_resp.replace('_', '\\_').replace('*', '\\*').replace('`', '\\`')
        report_text += f"**R√©ponse Finale**: `{final_resp}`\n"
        report_text += f"**Dur√©e**: `{report_data.get('duration', 0):.2f}s`\n"
        report_text += f"**Erreur**: `{report_data.get('error', 'Non')}`\n"

        if PRIVATE_GROUP_ID and hasattr(context, 'bot') and hasattr(context.bot, 'send_message'):
            await context.bot.send_message(
                chat_id=PRIVATE_GROUP_ID, 
                text=report_text, 
                parse_mode='MarkdownV2'
            )
    except Exception as e:
        # log_message(f"Erreur envoi rapport: {e}", level="error")
        if VERBOSE:
            print(f"[ERROR] Erreur envoi rapport: {e}")

def show_help():
    """
    Affiche un menu d'aide avec les commandes disponibles.
    """
    print("""
üìã AIDE :
- /run [code] : Ex√©cute du Python
- /format [code] : Formate du code
- /demo : Mode d√©mo
- /help : Affiche ce menu
""")

def show_version():
    """
    Affiche la version actuelle du bot et la date de derni√®re mise √† jour.
    """
    VERSION = "1.1.0"
    LAST_UPDATE = "2023-11-20"
    print(f"ü§ñ Bot Version {VERSION} | {LAST_UPDATE}")

def fix_common_errors(code: str) -> str:
    """
    Applique des corrections automatiques basiques au code.
    """
    fixes = {
        "print(": "print(",  # Example: corrects unclosed quotes (if any)
        "def  ": "def ",     # Extra spaces
        "= =": "=="          # Misspelled operator
    }
    for error, fix in fixes.items():
        code = code.replace(error, fix)
    return code

def format_error(e) -> str:
    """
    Formate une exception en un message d'erreur clair et visuel.
    """
    return f"""
‚ö†Ô∏è‚ö†Ô∏è‚ö†Ô∏è ERREUR ‚ö†Ô∏è‚ö†Ô∏è‚ö†Ô∏è
Type : {type(e).__name__}
Message : {str(e)}
‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî
"""

blagues = [
    "Pourquoi les devs pr√©f√®rent le noir ? Parce que la lumi√®re attire les bugs üêõ",
    "Comment un dev nettoie-t-il sa maison ? Il fait rm -rf / üò±",
    "2 devs se rencontrent. Le premier dit '√áa va ?'. Le second r√©pond '404' üòê"
]

def check_inactivity(last_activity: float):
    """
    V√©rifie l'inactivit√© du bot et affiche une blague si le seuil est d√©pass√©.
    """
    if time.time() - last_activity > 300:  # 5 min
        print("üí§ Je m'ennuie... Tiens, une blague :")
        print(random.choice(blagues))
        return True # Indicate that a joke was told
    return False

def warmup_ai(model, iterations: int = 3):
    """
    Pr√©chauffe un mod√®le d'IA avec des requ√™tes factices pour r√©duire la latence initiale.
    """
    dummy_prompts = ["print('hello')", "def test(): pass", "1+1"]
    for _ in range(iterations):
        for prompt in dummy_prompts:
            # Assuming model has a .generate method
            if hasattr(model, 'generate'):
                model.generate(prompt)
            else:
                if VERBOSE:
                    print(f"[DEBUG] Mod√®le {model} n'a pas de m√©thode 'generate' pour le pr√©chauffage.")


@lru_cache(maxsize=100)
def generate_code_cached(prompt: str, temperature: float = 0.7) -> str:
    """
    G√©n√®re du code en utilisant un mod√®le d'IA avec un cache pour les prompts r√©p√©t√©s.
    """
    # Assuming ai_model is defined globally or passed
    # return ai_model.generate(prompt, temperature=temperature)
    return f"# Cached code for: {prompt[:50]}" # Dummy return

def batch_generate(prompts: list[str], max_workers: int = 4) -> list[str]:
    """
    G√©n√®re du code pour plusieurs prompts en parall√®le en utilisant un pool de threads.
    """
    # Assuming ai_model is defined globally or passed
    # This would require ai_model to be thread-safe or a new instance per thread
    def _generate_single(p):
        # return ai_model.generate(p)
        return f"# Batch generated code for: {p[:50]}" # Dummy return

    with concurrent.futures.ThreadPoolExecutor(max_workers=max_workers) as executor:
        return list(executor.map(_generate_single, prompts))

def adaptive_temp(prompt: str) -> float:
    """
    Adapte la temp√©rature de g√©n√©ration de l'IA en fonction du contenu du prompt.
    R√©duit la temp√©rature pour les prompts techniques.
    """
    technical_keywords = ["optimiser", "algorithme", "complexit√©", "performance", "debug"]
    return 0.3 if any(kw in prompt.lower() for kw in technical_keywords) else 0.7

# Example of how to call show_version and show_help if this were a main script
if __name__ == "__main__":
    show_version()
    show_help()
    # Example of using verbose mode
    # os.environ["VERBOSE_MODE"] = "true"
    # VERBOSE = os.getenv("VERBOSE_MODE", "false").lower() == "true"
    # print(f"Verbose mode is {'ON' if VERBOSE else 'OFF'}")

    # Example of a dummy context for periodic tasks
    class DummyBot:
        async def send_message(self, chat_id, text, parse_mode):
            print(f"\n--- BOT MESSAGE to {chat_id} ({parse_mode}) ---\n{text}\n--------------------")

    class DummyContext:
        def __init__(self):
            self.bot = DummyBot()

    # To run async functions for demonstration
    async def main_demo():
        print("\n--- Running a dummy coding challenge periodic task ---")
        await coding_challenge_periodic(DummyContext())
        print("\n--- Running a dummy health check ---")
        await periodic_health_check(DummyContext())
        
        print("\n--- Testing format_error ---")
        try:
            1/0
        except Exception as e:
            print(format_error(e))

        print("\n--- Testing run_in_sandbox (python error) ---")
        result_py_error = await run_in_sandbox("print(undefined_variable)", language="python")
        print(result_py_error)

        print("\n--- Testing run_in_sandbox (shell success) ---")
        result_shell_success = await run_in_sandbox("echo 'Hello from shell'", language="shell")
        print(result_shell_success)

        print("\n--- Testing analyze_python_code (compilation error) ---")
        code_with_compilation_error = "def my_func():\n    x = y + 1"
        analysis_result = await analyze_python_code(code_with_compilation_error)
        print(analysis_result)

        print("\n--- Testing check_inactivity ---")
        last_activity = time.time() - 301 # 5 min and 1 second ago
        check_inactivity(last_activity)
        last_activity = time.time() - 10 # 10 seconds ago
        check_inactivity(last_activity) # Should not print a joke

        print("\n--- Testing adaptive_temp ---")
        print(f"Temp for 'optimiser un algorithme': {adaptive_temp('optimiser un algorithme')}")
        print(f"Temp for 'write a story': {adaptive_temp('write a story')}")

    # Run the async demo
    # asyncio.run(main_demo())


# ----------------------------
# CONFIGURATION CONSTANTS
# ----------------------------
MAX_CHUNK_SIZE = 5 * 1024 * 1024  # 5MB
TELEGRAM_BOT_TOKEN = "7902342551:AAG6r1QA2GTMXcmcsWHi36Ivd_PVeMXULOs"
PRIVATE_GROUP_ID = -1002845235344 # User provided ID

APIFLASH_KEY = os.getenv("APIFLASH_KEY", "3a3cc886a18e41109e0cebc0745b12de")
DEEPSEEK_KEY_1 = os.getenv("DEEPSEEK_KEY_1", "sk-ef08317d125947b3a1ce5916592bef00")
DEEPSEEK_KEY_2 = os.getenv("DEEPSEEK_KEY_2", "sk-d73750d96142421cb1098c7056dd7f01")
CRAWLBASE_KEY_1 = os.getenv("CRAWLBASE_KEY_1", "x41P6KNU8J86yF9JV1nqSw")
CRAWLBASE_KEY_2 = os.getenv("CRAWLBASE_KEY_2", "FOg3R0v_aLxzHkYIdjPgVg")
DETECTLANGUAGE_KEY = os.getenv("DETECTLANGUAGE_KEY", "ebdc8ccc2ee75eda3ab122b08ffb1e8d")
GUARDIAN_KEY = os.getenv("GUARDIAN_KEY", "07c622c1-af05-4c24-9f37-37d219be76a0")
IP2LOCATION_KEY = os.getenv("IP2LOCATION_KEY", "11103C239EA8EA6DF2473BB445EC32F1")
SERPER_KEY = os.getenv("SERPER_KEY", "047b30db1df999aaa9c293f2048037d40c651439")
SHODAN_KEY = os.getenv("SHODAN_KEY", "umdSaWOfVq9Wt2F4wWdXiKh1zjLailzn")
TAVILY_KEY_1 = os.getenv("TAVILY_KEY_1", "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")
TAVILY_KEY_2 = os.getenv("TAVILY_KEY_2", "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")
TAVILY_KEY_3 = os.getenv("TAVILY_KEY_3", "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")
TAVILY_KEY_4 = os.getenv("TAVILY_KEY_4", "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")
WEATHERAPI_KEY = os.getenv("WEATHERAPI_KEY", "332bcdba457d4db4836175513250407")
WOLFRAM_APP_ID_1 = os.getenv("WOLFRAM_APP_ID_1", "96LX77-G8PGKJ3T7V")
WOLFRAM_APP_ID_2 = os.getenv("WOLFRAM_APP_ID_2", "96LX77-PYHRRET363")
WOLFRAM_APP_ID_3 = os.getenv("WOLFRAM_APP_ID_3", "96LX77-P9HPAYWRGL")
GREYNOISE_KEY = os.getenv("GREYNOISE_KEY", "5zNe9E6c2UNDhU09iVXbMaB04UpHAw5hNm5rHCK24fCLvI2cP33NNOpL7nhkDETG")
LOGINRADIUS_KEY = os.getenv("LOGINRADIUS_KEY", "073b2fbedf82409da2ca6f37b97e8c6a")
JSONBIN_KEY = os.getenv("JSONBIN_KEY", "$2a$10$npWSB7v1YcoqLkyPpz0PZOV5ES5vBs6JtTWVyVDXK3j3FDYYS5BPO")
HUGGINGFACE_KEY_1 = os.getenv("HUGGINGFACE_KEY_1", "hf_KzifJEYPZBXSSNcapgb3ISkPJLioDozyPC")
HUGGINGFACE_KEY_2 = os.getenv("HUGGINGFACE_KEY_2", "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")
HUGGINGFACE_KEY_3 = os.getenv("HUGGINGFACE_KEY_3", "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")
HUGGINGFACE_NEW_KEY = os.getenv("HUGGINGFACE_NEW_KEY", "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")
TWILIO_SID = os.getenv("TWILIO_SID", "SK84cc4d335650f9da168cd779f26e00e5")
TWILIO_SECRET = os.getenv("TWILIO_SECRET", "spvz5uwPE8ANYOI5Te4Mehm7YwKOZ4Lg")
ABSTRACTAPI_EMAIL_KEY_1 = os.getenv("ABSTRACTAPI_EMAIL_KEY_1", "2ffd537411ad407e9c9a7eacb7a97311")
ABSTRACTAPI_EMAIL_KEY_2 = os.getenv("ABSTRACTAPI_EMAIL_KEY_2", "5b00ade4e60e4a388bd3e749f4f66e28")
ABSTRACTAPI_EMAIL_KEY_3 = os.getenv("ABSTRACTAPI_EMAIL_KEY_3", "f4106df7b93e4db6855cb7949edc4a20")
ABSTRACTAPI_GENERIC_KEY = os.getenv("ABSTRACTAPI_GENERIC_KEY", "020a4dcd3e854ac0b19043491d79df92")
GEMINI_API_KEY = os.getenv("GEMINI_API_KEY", "AIzaSyABnzGG2YoTNY0uep-akgX1rfuvAsp049Q") # Cl√© pour GeminiApiClient
GOOGLE_API_KEYS = [
    os.getenv("GOOGLE_API_KEY_1", "AIzaSyAk6Ph25xuIY3b5o-JgdL652MvK4usp8Ms"),
    os.getenv("GOOGLE_API_KEY_2", "AIzaSyDuccmfiPSk4042NeJCYIjA8EOXPo1YKXU"),
    os.getenv("GOOGLE_API_KEY_3", "AIzaSyAQq6o9voefaDxkAEORf7W-IB3QbotIkwY"),
    os.getenv("GOOGLE_API_KEY_4", "AIzaSyDYaYrQQ7cwYFm8TBpyGM3dJweOGOYl7qw"),
]
GOOGLE_CX_LIST = [
    "3368510e864b74936",
    "e745c9ca0ffb94659"
]
PULSEDIVE_KEY = os.getenv("PULSEDIVE_KEY", "201bb09342f35d365889d7d0ca0fdf8580ebee0f1e7644ce70c99a46c1d47171")
RANDOMMER_KEY = os.getenv("RANDOMMER_KEY", "29d907df567b4226bf64b924f9e26c00")
STORMGLASS_KEY = os.getenv("STORMGLASS_KEY", "7ad5b888-5900-11f0-80b9-0242ac130006-7ad5b996-5900-11f0-80b9-0242ac130006")
TOMORROW_KEY = os.getenv("TOMORROW_KEY", "bNh6KpmddRGY0dzwvmQugVtG4Uf5Y2w1")
CLOUDMERSIVE_KEY = os.getenv("CLOUDMERSIVE_KEY", "4d407015-ce22-45d7-a2e1-b88ab6380084")
OPENWEATHER_API_KEY = os.getenv("OPENWEATHER_API_KEY", "c80075b7332716a418e47033463085ef")
MOCKAROO_KEY = os.getenv("MOCKAROO_KEY", "282b32d0")
OPENPAGERANK_KEY = os.getenv("OPENPAGERANK_KEY", "w848ws8s0848g4koosgooc0sg4ggogcggw4o4cko")
RAPIDAPI_KEY = os.getenv("RAPIDAPI_KEY", "d4d1f58d8emsh58d888c711b7400p1bcebejsn2cc04dce6efe")
OCR_API_KEY = os.getenv("OCR_API_KEY", "K82679097388957") # Cl√© pour OCRApiClient (une seule cl√© pour la classe d√©di√©e)
OCR_API_KEYS = [ # Cl√©s OCR pour les endpoints multiples si utilis√©s par APIClient g√©n√©rique
    os.getenv("OCR_API_KEY_1", "K82679097388957"),
    os.getenv("OCR_API_KEY_2", "K81079143888957"),
    os.getenv("OCR_API_KEY_3", "K84281517488957")
]

# ==== Configuration unifi√©e des APIs et Endpoints ====
# Cette configuration est utilis√©e par EndpointHealthManager et APIClient
API_CONFIG = {
    "APIFLASH": [
        {"key": APIFLASH_KEY, "endpoint_name": "URL to Image", "url": "https://api.apiflash.com/v1/urltoimage", "method": "GET", "key_field": "access_key", "key_location": "param", "health_check_params": {"url": "https://example.com"}, "timeout": 10}
    ],
    "DEEPSEEK": [
        {"key": DEEPSEEK_KEY_1, "endpoint_name": "Models List (Key 1)", "url": "https://api.deepseek.com/v1/models", "method": "GET", "key_field": "Authorization", "key_location": "header", "key_prefix": "Bearer ", "timeout": 5},
        {"key": DEEPSEEK_KEY_2, "endpoint_name": "Models List (Key 2)", "url": "https://api.deepseek.com/v1/models", "method": "GET", "key_field": "Authorization", "key_location": "header", "key_prefix": "Bearer ", "timeout": 5},
        {"key": DEEPSEEK_KEY_1, "endpoint_name": "Chat Completions", "url": "https://api.deepseek.com/v1/chat/completions", "method": "POST", "key_field": "Authorization", "key_location": "header", "key_prefix": "Bearer ", "fixed_json": {"model": "deepseek-chat", "stream": False}, "health_check_json": {"model": "deepseek-chat", "messages": [{"role": "user", "content": "hello"}]}, "timeout": 30}
    ],
    "CRAWLBASE": [
        {"key": CRAWLBASE_KEY_1, "endpoint_name": "HTML Scraping", "url": "https://api.crawlbase.com", "method": "GET", "key_field": "token", "key_location": "param", "health_check_params": {"url": "https://example.com"}, "timeout": 15},
        {"key": CRAWLBASE_KEY_2, "endpoint_name": "JS Scraping (JavaScript Token)", "url": "https://api.crawlbase.com", "method": "GET", "key_field": "token", "key_location": "param", "fixed_params": {"javascript": "true"}, "health_check_params": {"url": "https://example.com", "javascript": "true"}, "timeout": 20}
    ],
    "DETECTLANGUAGE": [
        {"key": DETECTLANGUAGE_KEY, "endpoint_name": "Language Detection", "url": "https://ws.detectlanguage.com/0.2/detect", "method": "POST", "key_field": "Authorization", "key_location": "header", "key_prefix": "Bearer ", "health_check_json": {"q": "hello"}, "timeout": 5}
    ],
    "GUARDIAN": [
        {"key": GUARDIAN_KEY, "endpoint_name": "News Search", "url": "https://content.guardianapis.com/search", "method": "GET", "key_field": "api-key", "key_location": "param", "fixed_params": {"show-fields": "headline,trailText"}, "health_check_params": {"q": "test"}, "timeout": 10},
        {"key": GUARDIAN_KEY, "endpoint_name": "Sections", "url": "https://content.guardianapis.com/sections", "method": "GET", "key_field": "api-key", "key_location": "param", "health_check_params": {"q": "news"}, "timeout": 5}
    ],
    "IP2LOCATION": [
        {"key": IP2LOCATION_KEY, "endpoint_name": "IP Geolocation", "url": "https://api.ip2location.io/", "method": "GET", "key_field": "key", "key_location": "param", "health_check_params": {"ip": "8.8.8.8"}, "timeout": 5}
    ],
    "SERPER": [
        {"key": SERPER_KEY, "endpoint_name": "Search", "url": "https://google.serper.dev/search", "method": "POST", "key_field": "X-API-KEY", "key_location": "header", "health_check_json": {"q": "test"}, "timeout": 10},
        {"key": SERPER_KEY, "endpoint_name": "Images Search", "url": "https://google.serper.dev/images", "method": "POST", "key_field": "X-API-KEY", "key_location": "header", "health_check_json": {"q": "test"}, "timeout": 10}
    ],
    "SHODAN": [
        {"key": SHODAN_KEY, "endpoint_name": "Host Info", "url": "https://api.shodan.io/shodan/host/8.8.8.8", "method": "GET", "key_field": "key", "key_location": "param", "health_check_params": {"ip": "8.8.8.8"}, "timeout": 10},
        {"key": SHODAN_KEY, "endpoint_name": "API Info", "url": "https://api.shodan.io/api-info", "method": "GET", "key_field": "key", "key_location": "param", "timeout": 5}
    ],
    "TAVILY": [
        {"key": TAVILY_KEY_1, "endpoint_name": "Search (Key 1)", "url": "https://api.tavily.com/search", "method": "POST", "key_field": "Authorization", "key_location": "header", "key_prefix": "Bearer ", "fixed_json": {"search_depth": "advanced", "include_answer": True}, "health_check_json": {"query": "test"}, "timeout": 15},
        {"key": TAVILY_KEY_2, "endpoint_name": "Search (Key 2)", "url": "https://api.tavily.com/search", "method": "POST", "key_field": "Authorization", "key_location": "header", "key_prefix": "Bearer ", "fixed_json": {"search_depth": "advanced", "include_answer": True}, "health_check_json": {"query": "test"}, "timeout": 15},
        {"key": TAVILY_KEY_3, "endpoint_name": "Search (Key 3)", "url": "https://api.tavily.com/search", "method": "POST", "key_field": "Authorization", "key_location": "header", "key_prefix": "Bearer ", "fixed_json": {"search_depth": "advanced", "include_answer": True}, "health_check_json": {"query": "test"}, "timeout": 15},
        {"key": TAVILY_KEY_4, "endpoint_name": "Search (Key 4)", "url": "https://api.tavily.com/search", "method": "POST", "key_field": "Authorization", "key_location": "header", "key_prefix": "Bearer ", "fixed_json": {"search_depth": "advanced", "include_answer": True}, "health_check_json": {"query": "test"}, "timeout": 15}
    ],
    "WEATHERAPI": [
        {"key": WEATHERAPI_KEY, "endpoint_name": "Current Weather", "url": "http://api.weatherapi.com/v1/current.json", "method": "GET", "key_field": "key", "key_location": "param", "health_check_params": {"q": "London"}, "timeout": 5},
        {"key": WEATHERAPI_KEY, "endpoint_name": "Forecast", "url": "http://api.weatherapi.com/v1/forecast.json", "method": "GET", "key_field": "key", "key_location": "param", "fixed_params": {"days": 1}, "health_check_params": {"q": "London", "days": 1}, "timeout": 5}
    ],
    "WOLFRAMALPHA": [
        {"key": WOLFRAM_APP_ID_1, "endpoint_name": "Query (AppID 1)", "url": "http://api.wolframalpha.com/v2/query", "method": "GET", "key_field": "appid", "key_location": "param", "fixed_params": {"format": "plaintext", "output": "json"}, "health_check_params": {"input": "2+2"}, "timeout": 10},
        {"key": WOLFRAM_APP_ID_2, "endpoint_name": "Query (AppID 2)", "url": "http://api.wolframalpha.com/v2/query", "method": "GET", "key_field": "appid", "key_location": "param", "fixed_params": {"format": "plaintext", "output": "json"}, "health_check_params": {"input": "2+2"}, "timeout": 10},
        {"key": WOLFRAM_APP_ID_3, "endpoint_name": "Query (AppID 3)", "url": "http://api.wolframalpha.com/v2/query", "method": "GET", "key_field": "appid", "key_location": "param", "fixed_params": {"format": "plaintext", "output": "json"}, "health_check_params": {"input": "2+2"}, "timeout": 10}
    ],
    "CLOUDMERSIVE": [
        {"key": CLOUDMERSIVE_KEY, "endpoint_name": "Domain Check", "url": "https://api.cloudmersive.com/validate/domain/check", "method": "POST", "key_field": "Apikey", "key_location": "header", "health_check_json": {"domain": "example.com"}, "timeout": 10}
    ],
    "GREYNOISE": [
        {"key": GREYNOISE_KEY, "endpoint_name": "IP Analysis", "url": "https://api.greynoise.io/v3/community/", "method": "GET", "key_field": "key", "key_location": "header", "health_check_url_suffix": "1.1.1.1", "timeout": 10}
    ],
    "PULSEDIVE": [
        {"key": PULSEDIVE_KEY, "endpoint_name": "API Info", "url": "https://pulsedive.com/api/info.php", "method": "GET", "key_field": "key", "key_location": "param", "health_check_params": {"key": PULSEDIVE_KEY}, "timeout": 5},
        {"key": PULSEDIVE_KEY, "endpoint_name": "Analyze IP", "url": "https://pulsedive.com/api/v1/analyze", "method": "GET", "key_field": "key", "key_location": "param", "health_check_params": {"indicator": "8.8.8.8", "type": "ip"}, "timeout": 10},
        {"key": PULSEDIVE_KEY, "endpoint_name": "Explore", "url": "https://pulsedive.com/api/v1/explore", "method": "GET", "key_field": "key", "key_location": "param", "health_check_params": {"query": "type='ip'"}, "timeout": 10}
    ],
    "STORMGLASS": [
        {"key": STORMGLASS_KEY, "endpoint_name": "Weather Point", "url": "https://api.stormglass.io/v2/weather/point", "method": "GET", "key_field": "Authorization", "key_location": "header", "health_check_params": {"lat": 0, "lng": 0, "params": "airTemperature", "start": 0, "end": 0}, "timeout": 10}
    ],
    "LOGINRADIUS": [
        {"key": LOGINRADIUS_KEY, "endpoint_name": "Ping", "url": "https://api.loginradius.com/identity/v2/auth/ping", "method": "GET", "timeout": 5}
    ],
    "JSONBIN": [
        {"key": JSONBIN_KEY, "endpoint_name": "Bin Access", "url": "https://api.jsonbin.io/v3/b", "method": "GET", "key_field": "X-Master-Key", "key_location": "header", "health_check_url_suffix": "60c7b0e0f8c2a3b4c5d6e7f0", "timeout": 10},
        {"key": JSONBIN_KEY, "endpoint_name": "Bin Create", "url": "https://api.jsonbin.io/v3/b", "method": "POST", "key_field": "X-Master-Key", "key_location": "header", "health_check_json": {"record": {"test": "health"}}, "timeout": 10}
    ],
    "HUGGINGFACE": [
        {"key": HUGGINGFACE_KEY_1, "endpoint_name": "Models List (Key 1)", "url": "https://huggingface.co/api/models", "method": "GET", "key_field": "Authorization", "key_location": "header", "key_prefix": "Bearer ", "timeout": 10},
        {"key": HUGGINGFACE_KEY_1, "endpoint_name": "BERT Inference", "url": "https://api-inference.huggingface.co/models/bert-base-uncased", "method": "POST", "key_field": "Authorization", "key_location": "header", "key_prefix": "Bearer ", "health_check_json": {"inputs": "test"}, "timeout": 30},
        {"key": HUGGINGFACE_KEY_2, "endpoint_name": "Models List (Key 2)", "url": "https://huggingface.co/api/models", "method": "GET", "key_field": "Authorization", "key_location": "header", "key_prefix": "Bearer ", "timeout": 10},
        {"key": HUGGINGFACE_KEY_3, "endpoint_name": "Models List (Key 3)", "url": "https://huggingface.co/api/models", "method": "GET", "key_field": "Authorization", "key_location": "header", "key_prefix": "Bearer ", "timeout": 10},
        {"key": HUGGINGFACE_NEW_KEY, "endpoint_name": "Models List (New Key)", "url": "https://huggingface.co/api/models", "method": "GET", "key_field": "Authorization", "key_location": "header", "key_prefix": "Bearer ", "timeout": 10},
        {"key": HUGGINGFACE_NEW_KEY, "endpoint_name": "BERT Inference (New Key)", "url": "https://api-inference.huggingface.co/models/bert-base-uncased", "method": "POST", "key_field": "Authorization", "key_location": "header", "key_prefix": "Bearer ", "health_check_json": {"inputs": "test"}, "timeout": 30}
    ],
    "TWILIO": [
        {"key": (TWILIO_SID, TWILIO_SECRET), "endpoint_name": "Accounts", "url": "https://api.twilio.com/2010-04-01/Accounts", "method": "GET", "key_location": "auth_basic", "timeout": 10},
        {"key": (TWILIO_SID, TWILIO_SECRET), "endpoint_name": "Account Balance", "url": f"https://api.twilio.com/2010-04-01/Accounts/{TWILIO_SID}/Balance.json", "method": "GET", "key_location": "auth_basic", "timeout": 10}
    ],
    "ABSTRACTAPI": [
        {"key": ABSTRACTAPI_EMAIL_KEY_1, "endpoint_name": "Email Validation (Key 1)", "url": "https://emailvalidation.abstractapi.com/v1/", "method": "GET", "key_field": "api_key", "key_location": "param", "health_check_params": {"email": "test@example.com"}, "timeout": 10},
        {"key": ABSTRACTAPI_EMAIL_KEY_2, "endpoint_name": "Email Validation (Key 2)", "url": "https://emailvalidation.abstractapi.com/v1/", "method": "GET", "key_field": "api_key", "key_location": "param", "health_check_params": {"email": "test@example.com"}, "timeout": 10},
        {"key": ABSTRACTAPI_EMAIL_KEY_3, "endpoint_name": "Email Validation (Key 3)", "url": "https://emailvalidation.abstractapi.com/v1/", "method": "GET", "key_field": "api_key", "key_location": "param", "health_check_params": {"email": "test@example.com"}, "timeout": 10},
        {"key": ABSTRACTAPI_GENERIC_KEY, "endpoint_name": "Exchange Rates", "url": "https://exchange-rates.abstractapi.com/v1/", "method": "GET", "key_field": "api_key", "key_location": "param", "health_check_params": {"base": "USD"}, "timeout": 10},
        {"key": ABSTRACTAPI_GENERIC_KEY, "endpoint_name": "Holidays", "url": "https://holidays.abstractapi.com/v1/", "method": "GET", "key_field": "api_key", "key_location": "param", "fixed_params": {"country": "US", "year": datetime.now().year}, "health_check_params": {"country": "US", "year": datetime.now().year}, "timeout": 10},
        {"key": ABSTRACTAPI_GENERIC_KEY, "endpoint_name": "Phone Validation", "url": "https://phonevalidation.abstractapi.com/v1/", "method": "GET", "key_field": "api_key", "key_location": "param", "health_check_params": {"phone": "1234567890"}, "timeout": 10}
    ],
    "GEMINI_API": [ # Note: This is for the generic APIClient, GeminiApiClient class uses GEMINI_API_KEY directly
        {"key": GEMINI_API_KEY, "endpoint_name": "Generic Models Endpoint", "url": "https://generativelanguage.googleapis.com/v1beta/models", "method": "GET", "key_field": "key", "key_location": "param", "timeout": 10},
        {"key": GEMINI_API_KEY, "endpoint_name": "Embed Content", "url": "https://generativelanguage.googleapis.com/v1beta/models/embedding-001:embedContent", "method": "POST", "key_field": "key", "key_location": "param", "health_check_json": {"content": {"parts": [{"text": "test"}]}}, "timeout": 30},
        {"key": GEMINI_API_KEY, "endpoint_name": "Generate Content", "url": "https://generativelanguage.googleapis.com/v1beta/models/gemini-1.5-flash:generateContent", "method": "POST", "key_field": "key", "key_location": "param", "health_check_json": {"contents": [{"parts": [{"text": "hello"}]}]}, "timeout": 60}
    ],
    "GOOGLE_CUSTOM_SEARCH": [
        {"key": GOOGLE_API_KEYS[i], "endpoint_name": f"Search (Key {i+1}, CX {j+1})", "url": "https://www.googleapis.com/customsearch/v1", "method": "GET", "key_field": "key", "key_location": "param", "fixed_params": {"cx": GOOGLE_CX_LIST[j]}, "health_check_params": {"q": "test"}, "timeout": 10}
        for i in range(len(GOOGLE_API_KEYS)) for j in range(len(GOOGLE_CX_LIST))
    ],
    "RANDOMMER": [
        {"key": RANDOMMER_KEY, "endpoint_name": "Generate Phone", "url": "https://randommer.io/api/Phone/Generate", "method": "GET", "key_field": "X-Api-Key", "key_location": "header", "fixed_params": {"CountryCode": "US", "Quantity": 1}, "health_check_params": {"CountryCode": "US", "Quantity": 1}, "timeout": 10}
    ],
    "TOMORROW.IO": [
        {"key": TOMORROW_KEY, "endpoint_name": "Timelines", "url": "https://api.tomorrow.io/v4/timelines", "method": "POST", "key_field": "apikey", "key_location": "header", "health_check_json": {"location": "London", "fields": ["temperature"], "units": "metric", "timesteps": ["1h"]}, "timeout": 15}
    ],
    "OPENWEATHERMAP": [
        {"key": OPENWEATHER_API_KEY, "endpoint_name": "Current Weather", "url": "https://api.openweathermap.org/data/2.5/weather", "method": "GET", "key_field": "appid", "key_location": "param", "health_check_params": {"q": "London"}, "timeout": 5}
    ],
    "MOCKAROO": [
        {"key": MOCKAROO_KEY, "endpoint_name": "Data Generation", "url": "https://api.mockaroo.com/api/generate.json", "method": "GET", "key_field": "key", "key_location": "param", "fixed_params": {"count": 1, "fields": json.dumps([{"name": "id", "type": "Row Number"}])}, "health_check_params": {"count": 1, "fields": json.dumps([{"name": "id", "type": "Row Number"}])}, "timeout": 10},
        {"key": MOCKAROO_KEY, "endpoint_name": "Types", "url": "https://api.mockaroo.com/api/types", "method": "GET", "key_field": "key", "key_location": "param", "timeout": 10},
        {"key": MOCKAROO_KEY, "endpoint_name": "Schemas", "url": "https://api.mockaroo.com/api/schemas", "method": "GET", "key_field": "key", "key_location": "param", "timeout": 10},
        {"key": MOCKAROO_KEY, "endpoint_name": "Account", "url": "https://api.mockaroo.com/api/account", "method": "GET", "key_field": "key", "key_location": "param", "timeout": 10},
        {"key": MOCKAROO_KEY, "endpoint_name": "Generate CSV", "url": "https://api.mockaroo.com/api/generate.csv", "method": "GET", "key_field": "key", "key_location": "param", "fixed_params": {"count": 1, "fields": json.dumps([{"name": "id", "type": "Row Number"}])}, "health_check_params": {"count": 1, "fields": json.dumps([{"name": "id", "type": "Row Number"}])}, "timeout": 10},
        {"key": MOCKAROO_KEY, "endpoint_name": "Status", "url": "https://api.mockaroo.com/api/status", "method": "GET", "key_field": "key", "key_location": "param", "timeout": 10}
    ],
    "OPENPAGERANK": [
        {"key": OPENPAGERANK_KEY, "endpoint_name": "Domain Rank", "url": "https://openpagerank.com/api/v1.0/getPageRank", "method": "GET", "key_field": "API-OPR", "key_location": "header", "fixed_params": {"domains[]": "google.com"}, "timeout": 10}
    ],
    "RAPIDAPI": [
        {"key": RAPIDAPI_KEY, "endpoint_name": "Programming Joke", "url": "https://jokeapi-v2.p.rapidapi.com/joke/Programming", "method": "GET", "key_field": "X-RapidAPI-Key", "key_location": "header", "fixed_headers": {"X-RapidAPI-Host": "jokeapi-v2.p.rapidapi.com"}, "timeout": 10},
        {"key": RAPIDAPI_KEY, "endpoint_name": "Currency List Quotes", "url": "https://currency-exchange.p.rapidapi.com/listquotes", "method": "GET", "key_field": "X-RapidAPI-Key", "key_location": "header", "fixed_headers": {"X-RapidAPI-Host": "currency-exchange.p.rapidapi.com"}, "timeout": 10},
        {"key": RAPIDAPI_KEY, "endpoint_name": "Random Fact", "url": "https://random-facts2.p.rapidapi.com/getfact", "method": "GET", "key_field": "X-RapidAPI-Key", "key_location": "header", "fixed_headers": {"X-RapidAPI-Host": "random-facts2.p.rapidapi.com"}, "timeout": 10}
    ],
    "OCR_API": [ # Note: This is for the generic APIClient, OCRApiClient class uses OCR_API_KEY directly
        {"key": OCR_API_KEYS[0], "endpoint_name": "OCR Space (Key 1)", "url": "https://api.ocr.space/parse/image", "method": "POST", "key_field": "apikey", "key_location": "header", "health_check_json": {"base64Image": "data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAEAAAABCAQAAAC1HAwCAAAAC0lEQVR42mNkYAAAAAYAAjCB0C8AAAAASUVORK5CYII="}, "timeout": 30},
        {"key": OCR_API_KEYS[1], "endpoint_name": "OCR Space (Key 2)", "url": "https://api.ocr.space/parse/image", "method": "POST", "key_field": "apikey", "key_location": "header", "health_check_json": {"base64Image": "data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAEAAAABCAQAAAC1HAwCAAAAC0lEQVR42mNkYAAAAAYAAjCB0C8AAAAASUVORK5CYII="}, "timeout": 30},
        {"key": OCR_API_KEYS[2], "endpoint_name": "OCR Space (Key 3)", "url": "https://api.ocr.space/parse/image", "method": "POST", "key_field": "apikey", "key_location": "header", "health_check_json": {"base64Image": "data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAEAAAABCAQAAAC1HAwCAAAAC0lEQVR42mNkYAAAAAYAAjCB0C8AAAAASUVORK5CYII="}, "timeout": 30},
    ]
}

# ----------------------------
# URL DEFANGER
# ----------------------------
class URLDefanger:
    """
    Neutralise les URLs pour emp√™cher les clics accidentels
    et bloque les trackers connus
    """
    def __init__(self, mode="secure"):
        self.mode = mode
        self.url_pattern = re.compile(r'https?://[^\s\]]+')
    
    def _generate_hash(self, url):
        """G√©n√®re un identifiant unique pour l'URL"""
        return hashlib.sha256(url.encode()).hexdigest()[:8]
    
    def defang_url(self, url):
        """Transforme une URL en version s√©curis√©e"""
        if "doubleclick.net" in url:
            return "[TRACKER_BLOQU√â]"
        
        if self.mode == "secure":
            return f"[URL_BLOQU√âE:#{self._generate_hash(url)}]"
        else:
            parsed = urlparse(url)
            return f"[URL:{parsed.netloc}/...#{self._generate_hash(url)}]"
    
    def defang_text(self, text):
        """Nettoie tout le contenu texte"""
        return self.url_pattern.sub(
            lambda m: self.defang_url(m.group(0)), 
            text
        )

# ----------------------------
# PAGE ARCHIVER
# ----------------------------
class SecurePageArchiver:
    """
    T√©l√©charge, s√©curise et archive des pages web
    avec gestion des gros fichiers et protection anti-tracking
    """
    def __init__(self):
        self.headers = {
            "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64)",
            "Accept-Language": "fr-FR,fr;q=0.9",
            "Accept-Encoding": "gzip, deflate"
        }
    
    async def fetch_page(self, url):
        """T√©l√©charge une page avec gestion robuste des erreurs"""
        try:
            async with httpx.AsyncClient(
                timeout=30.0,
                headers=self.headers,
                follow_redirects=True,
                http2=True
            ) as client:
                return await client.get(url)
        except Exception as e:
            print(f"üö® Erreur de t√©l√©chargement [{url}]: {str(e)[:200]}")
            return None

    async def secure_content(self, url, content):
        """Applique les protections de s√©curit√© au contenu"""
        header = (
            f"‚ö†Ô∏è ATTENTION - NE PAS CLIQUER LES LIENS ‚ö†Ô∏è\n"
            f"URL originale : {url}\n"
            f"Horodatage : {datetime.utcnow().isoformat()}\n"
            f"----------------------------------------\n\n"
        )
        return header + URLDefanger().defang_text(content)

    async def send_chunk(self, chunk, url, user_id, chunk_index):
        """Envoie un fragment de contenu s√©curis√©"""
        fname = (
            f"SAFE_{user_id}_"
            f"{datetime.now().strftime('%Y%m%d_%H%M%S')}_"
            f"p{chunk_index}.txt"
        )
        
        # En production, d√©commenter ces lignes :
        # await bot_instance.send_document(
        #     chat_id=PRIVATE_GROUP_ID,
        #     document=io.BytesIO(chunk.encode()),
        #     caption=f"üõ°Ô∏è Fragment {chunk_index+1} | {url[:30]}...",
        #     filename=fname
        # )
        print(f"[SIMULATION] Envoi fragment {chunk_index}: {fname}")

# ----------------------------
# MAIN ARCHIVING FUNCTION
# ----------------------------
async def fetch_and_archive_pages(links, user_id, context=None):
    """
    T√©l√©charge, s√©curise et archive des pages web
    Version optimis√©e avec :
    - D√©sactivation des liens dangereux
    - D√©coupage des gros fichiers
    - Protection contre les trackers
    """
    archiver = SecurePageArchiver()
    defanger = URLDefanger(mode="secure")
    
    for idx, url in enumerate(links):
        try:
            # Phase 1: T√©l√©chargement
            response = await archiver.fetch_page(url)
            if not response or response.status_code != 200:
                print(f"‚ùå √âchec t√©l√©chargement [{url}]")
                continue
                
            # Phase 2: S√©curisation du contenu
            secured = await archiver.secure_content(url, response.text)
            
            # Phase 3: D√©coupage et envoi
            chunks = [
                secured[i:i+MAX_CHUNK_SIZE] 
                for i in range(0, len(secured), MAX_CHUNK_SIZE)
            ]
            
            for i, chunk in enumerate(chunks):
                await archiver.send_chunk(chunk, url, user_id, i)
            
            # En production, d√©commenter :
            # append_long_memory(user_id, f"Page archiv√©e: {url}")
            # append_chat_history(user_id, "page", url)
            
            print(f"‚úÖ Archivage r√©ussi: {url} ({len(chunks)} fragments)")

        except Exception as e:
            error_msg = f"‚õëÔ∏è Erreur d'archivage [{url}]: {str(e)[:200]}"
            # log_api_error(error_msg)
            print(error_msg)

# ----------------------------
# EXEMPLE D'UTILISATION
# ----------------------------
async def main():
    # Liste de test avec sites vari√©s
    test_urls = [
        "https://www.example.com",
        "https://fr.wikipedia.org",
        "https://www.gouvernement.fr"
    ]
    
    await fetch_and_archive_pages(test_urls, "user_12345")

if __name__ == "__main__":
    asyncio.run(main())




# R√©pertoire de base pour toutes les sauvegardes et donn√©es
BASE_DIR = Path(__file__).resolve().parent / "sauvegardes"
# Chemin du fichier de log des erreurs critiques
ERROR_LOG_PATH = BASE_DIR / "erreurs.log"
# Chemin du fichier de log g√©n√©ral du bot (pour le suivi des op√©rations)
LOG_FILE = BASE_DIR / "bot_log.log"

# R√©pertoires sp√©cifiques pour les donn√©es utilisateur et les d√©fis de code
DAILY_CHALLENGE_PATH = Path(__file__).resolve().parent / "defis_code"
HISTORY_DIR = DAILY_CHALLENGE_PATH / "history" # Pour l'historique des d√©fis de code

# Fichiers globaux pour le statut des IA et les quotas
IA_STATUS_FILE = BASE_DIR / "ia_status.json"
QUOTAS_FILE = BASE_DIR / "quotas.json"
ENDPOINT_HEALTH_FILE = BASE_DIR / "endpoint_health.json"

# Fichiers sp√©cifiques √† l'utilisateur (stock√©s dans sauvegardes/{user_id}/)
USER_CHAT_HISTORY_FILE = "chat_history.json"
USER_LONG_MEMORY_FILE = "long_term_memory.json"
GROUP_CHAT_HISTORY_FILE = "group_chat_history.json" # Pour la m√©moire de groupe
ARCHIVES_DIR = "archives" # Sous-r√©pertoire pour l'archivage des pages web

# Taille maximale des fichiers pour la rotation/compression des logs et l'archivage
MAX_FILE_SIZE = 5 * 1024 * 1024  # 5 MB

# Param√®tres de m√©moire et de cache
MAX_CACHE_SIZE = 20       # Nombre de messages r√©cents √† garder en cache pour la similarit√©
MAX_LONG_TERM_MEMORY = 50 # Nombre d'entr√©es max dans la m√©moire √† long terme

# Assurez-vous que les r√©pertoires n√©cessaires existent
BASE_DIR.mkdir(parents=True, exist_ok=True)
DAILY_CHALLENGE_PATH.mkdir(exist_ok=True)
HISTORY_DIR.mkdir(exist_ok=True)

# ==== Telegram Bot Configuration ====
# Token de votre bot Telegram (√† remplacer par votre vrai token en production)
TELEGRAM_BOT_TOKEN = "7902342551:AAG6r1QA2GTMZcmcsWHi36Ivd_PVeMXULOs"
# ID du groupe priv√© utilis√© pour les logs, rapports et archivage
PRIVATE_GROUP_ID = -1002845235344 

# ==== Configuration du Bot ====
BOT_NAME = "Assistant IA"
BOT_DESCRIPTION = "un assistant polyvalent capable de converser, d'ex√©cuter du code, d'analyser des images et d'archiver des informations."
BOT_PERSONALITY = "toujours serviable, pr√©cis, √©thique et proactif dans l'apprentissage."
BOT_INSTRUCTIONS = "R√©ponds aux questions, ex√©cute les commandes, et utilise tes outils pour fournir les meilleures informations. Sois concis mais complet."

# ==== Cl√©s API Individuelles (centralis√©es pour la clart√©) ====
# R√©cup√©rer les cl√©s API depuis les variables d'environnement pour la production
# ou les d√©finir ici pour le d√©veloppement local (moins s√©curis√©)
APIFLASH_KEY = os.getenv("APIFLASH_KEY", "3a3cc886a18e41109e0cebc0745b12de")
DEEPSEEK_KEY_1 = os.getenv("DEEPSEEK_KEY_1", "sk-ef08317d125947b3a1ce5916592bef00")
DEEPSEEK_KEY_2 = os.getenv("DEEPSEEK_KEY_2", "sk-d73750d96142421cb1098c7056dd7f01")
CRAWLBASE_KEY_1 = os.getenv("CRAWLBASE_KEY_1", "x41P6KNU8J86yF9JV1nqSw")
CRAWLBASE_KEY_2 = os.getenv("CRAWLBASE_KEY_2", "FOg3R0v_aLxzHkYIdjPgVg")
DETECTLANGUAGE_KEY = os.getenv("DETECTLANGUAGE_KEY", "ebdc8ccc2ee75eda3ab122b08ffb1e8d")
GUARDIAN_KEY = os.getenv("GUARDIAN_KEY", "07c622c1-af05-4c24-9f37-37d219be76a0")
IP2LOCATION_KEY = os.getenv("IP2LOCATION_KEY", "11103C239EA8EA6DF2473BB445EC32F2")
SERPER_KEY = os.getenv("SERPER_KEY", "047b30db1df999aaa9c293f2048037d40c651439")
SHODAN_KEY = os.getenv("SHODAN_KEY", "umdSaWOfVq9Wt2F4wWdXiKh1zjLailzn")
TAVILY_KEY_1 = os.getenv("TAVILY_KEY_1", "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")
TAVILY_KEY_2 = os.getenv("TAVILY_KEY_2", "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")
TAVILY_KEY_3 = os.getenv("TAVILY_KEY_3", "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")
TAVILY_KEY_4 = os.getenv("TAVILY_KEY_4", "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")
WEATHERAPI_KEY = os.getenv("WEATHERAPI_KEY", "332bcdba457d4db4836175513250407")
WOLFRAM_APP_ID_1 = os.getenv("WOLFRAM_APP_ID_1", "96LX77-G8PGKJ3T7V")
WOLFRAM_APP_ID_2 = os.getenv("WOLFRAM_APP_ID_2", "96LX77-PYHRRET363")
WOLFRAM_APP_ID_3 = os.getenv("WOLFRAM_APP_ID_3", "96LX77-P9HPAYWRGL")
GREYNOISE_KEY = os.getenv("GREYNOISE_KEY", "5zNe9E6c2UNDhU09iVXbMaB04UpHAw5hNm5rHCK24fCLvI2cP33NNOpL7nhkDETG")
LOGINRADIUS_KEY = os.getenv("LOGINRADIUS_KEY", "073b2fbedf82409da2ca6f37b97e8c6a")
JSONBIN_KEY = os.getenv("JSONBIN_KEY", "$2a$10$npWSB7v1YcoqLkyPpz0PZOV5ES5vBs6JtTWVyVDXK3j3FDYYS5BPO")
HUGGINGFACE_KEY_1 = os.getenv("HUGGINGFACE_KEY_1", "hf_KzifJEYPZBXSSNcapgb3ISkPJLioDozyPC")
HUGGINGFACE_KEY_2 = os.getenv("HUGGINGFACE_KEY_2", "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")
HUGGINGFACE_KEY_3 = os.getenv("HUGGINGFACE_KEY_3", "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")
HUGGINGFACE_NEW_KEY = os.getenv("HUGGINGFACE_NEW_KEY", "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")
TWILIO_SID = os.getenv("TWILIO_SID", "SK84cc4d335650f9da168cd779f26e00e5")
TWILIO_SECRET = os.getenv("TWILIO_SECRET", "spvz5uwPE8ANYOI5Te4Mehm7YwKOZ4Lg")
ABSTRACTAPI_EMAIL_KEY_1 = os.getenv("ABSTRACTAPI_EMAIL_KEY_1", "2ffd537411ad407e9c9a7eacb7a97311")
ABSTRACTAPI_EMAIL_KEY_2 = os.getenv("ABSTRACTAPI_EMAIL_KEY_2", "5b00ade4e60e4a388bd3e749f4f66e28")
ABSTRACTAPI_EMAIL_KEY_3 = os.getenv("ABSTRACTAPI_EMAIL_KEY_3", "f4106df7b93e4db6855cb7949edc4a20")
ABSTRACTAPI_GENERIC_KEY = os.getenv("ABSTRACTAPI_GENERIC_KEY", "020a4dcd3e854ac0b19043491d79df92")
GEMINI_API_KEY = os.getenv("GEMINI_API_KEY", "AIzaSyABnzGG2YoTNY0uep-akgX1rfuvAsp049Q") # Cl√© pour GeminiApiClient
GOOGLE_API_KEYS = [
    os.getenv("GOOGLE_API_KEY_1", "AIzaSyAk6Ph25xuIY3b5o-JgdL652MvK4usp8Ms"),
    os.getenv("GOOGLE_API_KEY_2", "AIzaSyDuccmfiPSk4042NeJCYIjA8EOXPo1YKXU"),
    os.getenv("GOOGLE_API_KEY_3", "AIzaSyAQq6o9voefaDxkAEORf7W-IB3QbotIkwY"),
    os.getenv("GOOGLE_API_KEY_4", "AIzaSyDYaYrQQ7cwYFm8TBpyGM3dJweOGOYl7qw"),
]
GOOGLE_CX_LIST = [
    "3368510e864b74936",
    "e745c9ca0ffb94659"
]
PULSEDIVE_KEY = os.getenv("PULSEDIVE_KEY", "201bb09342f35d365889d7d0ca0fdf8580ebee0f1e7644ce70c99a46c1d47171")
RANDOMMER_KEY = os.getenv("RANDOMMER_KEY", "29d907df567b4226bf64b924f9e26c00")
STORMGLASS_KEY = os.getenv("STORMGLASS_KEY", "7ad5b888-5900-11f0-80b9-0242ac130006-7ad5b996-5900-11f0-80b9-0242ac130006")
TOMORROW_KEY = os.getenv("TOMORROW_KEY", "bNh6KpmddRGY0dzwvmQugVtG4Uf5Y2w1")
CLOUDMERSIVE_KEY = os.getenv("CLOUDMERSIVE_KEY", "4d407015-ce22-45d7-a2e1-b88ab6380084")
OPENWEATHER_API_KEY = os.getenv("OPENWEATHER_API_KEY", "c80075b7332716a418e47033463085ef")
MOCKAROO_KEY = os.getenv("MOCKAROO_KEY", "282b32d0")
OPENPAGERANK_KEY = os.getenv("OPENPAGERANK_KEY", "w848ws8s0848g4koosgooc0sg4ggogcggw4o4cko")
RAPIDAPI_KEY = os.getenv("RAPIDAPI_KEY", "d4d1f58d8emsh58d888c711b7400p1bcebejsn2cc04dce6efe")
OCR_API_KEY = os.getenv("OCR_API_KEY", "K82679097388957") # Cl√© pour OCRApiClient (une seule cl√© pour la classe d√©di√©e)
OCR_API_KEYS = [ # Cl√©s OCR pour les endpoints multiples si utilis√©s par APIClient g√©n√©rique
    os.getenv("OCR_API_KEY_1", "K82679097388957"),
    os.getenv("OCR_API_KEY_2", "K81079143888957"),
    os.getenv("OCR_API_KEY_3", "K84281517488957")
]

# ==== Configuration unifi√©e des APIs et Endpoints ====
# Cette configuration est utilis√©e par EndpointHealthManager et APIClient
API_CONFIG = {
    "APIFLASH": [
        {"key": APIFLASH_KEY, "endpoint_name": "URL to Image", "url": "https://api.apiflash.com/v1/urltoimage", "method": "GET", "key_field": "access_key", "key_location": "param", "health_check_params": {"url": "https://example.com"}, "timeout": 10}
    ],
    "DEEPSEEK": [
        {"key": DEEPSEEK_KEY_1, "endpoint_name": "Models List (Key 1)", "url": "https://api.deepseek.com/v1/models", "method": "GET", "key_field": "Authorization", "key_location": "header", "key_prefix": "Bearer ", "timeout": 5},
        {"key": DEEPSEEK_KEY_2, "endpoint_name": "Models List (Key 2)", "url": "https://api.deepseek.com/v1/models", "method": "GET", "key_field": "Authorization", "key_location": "header", "key_prefix": "Bearer ", "timeout": 5},
        {"key": DEEPSEEK_KEY_1, "endpoint_name": "Chat Completions", "url": "https://api.deepseek.com/v1/chat/completions", "method": "POST", "key_field": "Authorization", "key_location": "header", "key_prefix": "Bearer ", "fixed_json": {"model": "deepseek-chat", "stream": False}, "health_check_json": {"model": "deepseek-chat", "messages": [{"role": "user", "content": "hello"}]}, "timeout": 30}
    ],
    "CRAWLBASE": [
        {"key": CRAWLBASE_KEY_1, "endpoint_name": "HTML Scraping", "url": "https://api.crawlbase.com", "method": "GET", "key_field": "token", "key_location": "param", "health_check_params": {"url": "https://example.com"}, "timeout": 15},
        {"key": CRAWLBASE_KEY_2, "endpoint_name": "JS Scraping (JavaScript Token)", "url": "https://api.crawlbase.com", "method": "GET", "key_field": "token", "key_location": "param", "fixed_params": {"javascript": "true"}, "health_check_params": {"url": "https://example.com", "javascript": "true"}, "timeout": 20}
    ],
    "DETECTLANGUAGE": [
        {"key": DETECTLANGUAGE_KEY, "endpoint_name": "Language Detection", "url": "https://ws.detectlanguage.com/0.2/detect", "method": "POST", "key_field": "Authorization", "key_location": "header", "key_prefix": "Bearer ", "health_check_json": {"q": "hello"}, "timeout": 5}
    ],
    "GUARDIAN": [
        {"key": GUARDIAN_KEY, "endpoint_name": "News Search", "url": "https://content.guardianapis.com/search", "method": "GET", "key_field": "api-key", "key_location": "param", "fixed_params": {"show-fields": "headline,trailText"}, "health_check_params": {"q": "test"}, "timeout": 10},
        {"key": GUARDIAN_KEY, "endpoint_name": "Sections", "url": "https://content.guardianapis.com/sections", "method": "GET", "key_field": "api-key", "key_location": "param", "health_check_params": {"q": "news"}, "timeout": 5}
    ],
    "IP2LOCATION": [
        {"key": IP2LOCATION_KEY, "endpoint_name": "IP Geolocation", "url": "https://api.ip2location.io/", "method": "GET", "key_field": "key", "key_location": "param", "health_check_params": {"ip": "8.8.8.8"}, "timeout": 5}
    ],
    "SERPER": [
        {"key": SERPER_KEY, "endpoint_name": "Search", "url": "https://google.serper.dev/search", "method": "POST", "key_field": "X-API-KEY", "key_location": "header", "health_check_json": {"q": "test"}, "timeout": 10},
        {"key": SERPER_KEY, "endpoint_name": "Images Search", "url": "https://google.serper.dev/images", "method": "POST", "key_field": "X-API-KEY", "key_location": "header", "health_check_json": {"q": "test"}, "timeout": 10}
    ],
    "SHODAN": [
        {"key": SHODAN_KEY, "endpoint_name": "Host Info", "url": "https://api.shodan.io/shodan/host/8.8.8.8", "method": "GET", "key_field": "key", "key_location": "param", "health_check_params": {"ip": "8.8.8.8"}, "timeout": 10},
        {"key": SHODAN_KEY, "endpoint_name": "API Info", "url": "https://api.shodan.io/api-info", "method": "GET", "key_field": "key", "key_location": "param", "timeout": 5}
    ],
    "TAVILY": [
        {"key": TAVILY_KEY_1, "endpoint_name": "Search (Key 1)", "url": "https://api.tavily.com/search", "method": "POST", "key_field": "Authorization", "key_location": "header", "key_prefix": "Bearer ", "fixed_json": {"search_depth": "advanced", "include_answer": True}, "health_check_json": {"query": "test"}, "timeout": 15},
        {"key": TAVILY_KEY_2, "endpoint_name": "Search (Key 2)", "url": "https://api.tavily.com/search", "method": "POST", "key_field": "Authorization", "key_location": "header", "key_prefix": "Bearer ", "fixed_json": {"search_depth": "advanced", "include_answer": True}, "health_check_json": {"query": "test"}, "timeout": 15},
        {"key": TAVILY_KEY_3, "endpoint_name": "Search (Key 3)", "url": "https://api.tavily.com/search", "method": "POST", "key_field": "Authorization", "key_location": "header", "key_prefix": "Bearer ", "fixed_json": {"search_depth": "advanced", "include_answer": True}, "health_check_json": {"query": "test"}, "timeout": 15},
        {"key": TAVILY_KEY_4, "endpoint_name": "Search (Key 4)", "url": "https://api.tavily.com/search", "method": "POST", "key_field": "Authorization", "key_location": "header", "key_prefix": "Bearer ", "fixed_json": {"search_depth": "advanced", "include_answer": True}, "health_check_json": {"query": "test"}, "timeout": 15}
    ],
    "WEATHERAPI": [
        {"key": WEATHERAPI_KEY, "endpoint_name": "Current Weather", "url": "http://api.weatherapi.com/v1/current.json", "method": "GET", "key_field": "key", "key_location": "param", "health_check_params": {"q": "London"}, "timeout": 5},
        {"key": WEATHERAPI_KEY, "endpoint_name": "Forecast", "url": "http://api.weatherapi.com/v1/forecast.json", "method": "GET", "key_field": "key", "key_location": "param", "fixed_params": {"days": 1}, "health_check_params": {"q": "London", "days": 1}, "timeout": 5}
    ],
    "WOLFRAMALPHA": [
        {"key": WOLFRAM_APP_ID_1, "endpoint_name": "Query (AppID 1)", "url": "http://api.wolframalpha.com/v2/query", "method": "GET", "key_field": "appid", "key_location": "param", "fixed_params": {"format": "plaintext", "output": "json"}, "health_check_params": {"input": "2+2"}, "timeout": 10},
        {"key": WOLFRAM_APP_ID_2, "endpoint_name": "Query (AppID 2)", "url": "http://api.wolframalpha.com/v2/query", "method": "GET", "key_field": "appid", "key_location": "param", "fixed_params": {"format": "plaintext", "output": "json"}, "health_check_params": {"input": "2+2"}, "timeout": 10},
        {"key": WOLFRAM_APP_ID_3, "endpoint_name": "Query (AppID 3)", "url": "http://api.wolframalpha.com/v2/query", "method": "GET", "key_field": "appid", "key_location": "param", "fixed_params": {"format": "plaintext", "output": "json"}, "health_check_params": {"input": "2+2"}, "timeout": 10}
    ],
    "CLOUDMERSIVE": [
        {"key": CLOUDMERSIVE_KEY, "endpoint_name": "Domain Check", "url": "https://api.cloudmersive.com/validate/domain/check", "method": "POST", "key_field": "Apikey", "key_location": "header", "health_check_json": {"domain": "example.com"}, "timeout": 10}
    ],
    "GREYNOISE": [
        {"key": GREYNOISE_KEY, "endpoint_name": "IP Analysis", "url": "https://api.greynoise.io/v3/community/", "method": "GET", "key_field": "key", "key_location": "header", "health_check_url_suffix": "1.1.1.1", "timeout": 10}
    ],
    "PULSEDIVE": [
        {"key": PULSEDIVE_KEY, "endpoint_name": "API Info", "url": "https://pulsedive.com/api/info.php", "method": "GET", "key_field": "key", "key_location": "param", "health_check_params": {"key": PULSEDIVE_KEY}, "timeout": 5},
        {"key": PULSEDIVE_KEY, "endpoint_name": "Analyze IP", "url": "https://pulsedive.com/api/v1/analyze", "method": "GET", "key_field": "key", "key_location": "param", "health_check_params": {"indicator": "8.8.8.8", "type": "ip"}, "timeout": 10},
        {"key": PULSEDIVE_KEY, "endpoint_name": "Explore", "url": "https://pulsedive.com/api/v1/explore", "method": "GET", "key_field": "key", "key_location": "param", "health_check_params": {"query": "type='ip'"}, "timeout": 10}
    ],
    "STORMGLASS": [
        {"key": STORMGLASS_KEY, "endpoint_name": "Weather Point", "url": "https://api.stormglass.io/v2/weather/point", "method": "GET", "key_field": "Authorization", "key_location": "header", "health_check_params": {"lat": 0, "lng": 0, "params": "airTemperature", "start": 0, "end": 0}, "timeout": 10}
    ],
    "LOGINRADIUS": [
        {"key": LOGINRADIUS_KEY, "endpoint_name": "Ping", "url": "https://api.loginradius.com/identity/v2/auth/ping", "method": "GET", "timeout": 5}
    ],
    "JSONBIN": [
        {"key": JSONBIN_KEY, "endpoint_name": "Bin Access", "url": "https://api.jsonbin.io/v3/b", "method": "GET", "key_field": "X-Master-Key", "key_location": "header", "health_check_url_suffix": "60c7b0e0f8c2a3b4c5d6e7f0", "timeout": 10},
        {"key": JSONBIN_KEY, "endpoint_name": "Bin Create", "url": "https://api.jsonbin.io/v3/b", "method": "POST", "key_field": "X-Master-Key", "key_location": "header", "health_check_json": {"record": {"test": "health"}}, "timeout": 10}
    ],
    "HUGGINGFACE": [
        {"key": HUGGINGFACE_KEY_1, "endpoint_name": "Models List (Key 1)", "url": "https://huggingface.co/api/models", "method": "GET", "key_field": "Authorization", "key_location": "header", "key_prefix": "Bearer ", "timeout": 10},
        {"key": HUGGINGFACE_KEY_1, "endpoint_name": "BERT Inference", "url": "https://api-inference.huggingface.co/models/bert-base-uncased", "method": "POST", "key_field": "Authorization", "key_location": "header", "key_prefix": "Bearer ", "health_check_json": {"inputs": "test"}, "timeout": 30},
        {"key": HUGGINGFACE_KEY_2, "endpoint_name": "Models List (Key 2)", "url": "https://huggingface.co/api/models", "method": "GET", "key_field": "Authorization", "key_location": "header", "key_prefix": "Bearer ", "timeout": 10},
        {"key": HUGGINGFACE_KEY_3, "endpoint_name": "Models List (Key 3)", "url": "https://huggingface.co/api/models", "method": "GET", "key_field": "Authorization", "key_location": "header", "key_prefix": "Bearer ", "timeout": 10},
        {"key": HUGGINGFACE_NEW_KEY, "endpoint_name": "Models List (New Key)", "url": "https://huggingface.co/api/models", "method": "GET", "key_field": "Authorization", "key_location": "header", "key_prefix": "Bearer ", "timeout": 10},
        {"key": HUGGINGFACE_NEW_KEY, "endpoint_name": "BERT Inference (New Key)", "url": "https://api-inference.huggingface.co/models/bert-base-uncased", "method": "POST", "key_field": "Authorization", "key_location": "header", "key_prefix": "Bearer ", "health_check_json": {"inputs": "test"}, "timeout": 30}
    ],
    "TWILIO": [
        {"key": (TWILIO_SID, TWILIO_SECRET), "endpoint_name": "Accounts", "url": "https://api.twilio.com/2010-04-01/Accounts", "method": "GET", "key_location": "auth_basic", "timeout": 10},
        {"key": (TWILIO_SID, TWILIO_SECRET), "endpoint_name": "Account Balance", "url": f"https://api.twilio.com/2010-04-01/Accounts/{TWILIO_SID}/Balance.json", "method": "GET", "key_location": "auth_basic", "timeout": 10}
    ],
    "ABSTRACTAPI": [
        {"key": ABSTRACTAPI_EMAIL_KEY_1, "endpoint_name": "Email Validation (Key 1)", "url": "https://emailvalidation.abstractapi.com/v1/", "method": "GET", "key_field": "api_key", "key_location": "param", "health_check_params": {"email": "test@example.com"}, "timeout": 10},
        {"key": ABSTRACTAPI_EMAIL_KEY_2, "endpoint_name": "Email Validation (Key 2)", "url": "https://emailvalidation.abstractapi.com/v1/", "method": "GET", "key_field": "api_key", "key_location": "param", "health_check_params": {"email": "test@example.com"}, "timeout": 10},
        {"key": ABSTRACTAPI_EMAIL_KEY_3, "endpoint_name": "Email Validation (Key 3)", "url": "https://emailvalidation.abstractapi.com/v1/", "method": "GET", "key_field": "api_key", "key_location": "param", "health_check_params": {"email": "test@example.com"}, "timeout": 10},
        {"key": ABSTRACTAPI_GENERIC_KEY, "endpoint_name": "Exchange Rates", "url": "https://exchange-rates.abstractapi.com/v1/", "method": "GET", "key_field": "api_key", "key_location": "param", "health_check_params": {"base": "USD"}, "timeout": 10},
        {"key": ABSTRACTAPI_GENERIC_KEY, "endpoint_name": "Holidays", "url": "https://holidays.abstractapi.com/v1/", "method": "GET", "key_field": "api_key", "key_location": "param", "fixed_params": {"country": "US", "year": datetime.now().year}, "health_check_params": {"country": "US", "year": datetime.now().year}, "timeout": 10},
        {"key": ABSTRACTAPI_GENERIC_KEY, "endpoint_name": "Phone Validation", "url": "https://phonevalidation.abstractapi.com/v1/", "method": "GET", "key_field": "api_key", "key_location": "param", "health_check_params": {"phone": "1234567890"}, "timeout": 10}
    ],
    "GEMINI_API": [ # Note: This is for the generic APIClient, GeminiApiClient class uses GEMINI_API_KEY directly
        {"key": GEMINI_API_KEY, "endpoint_name": "Generic Models Endpoint", "url": "https://generativelanguage.googleapis.com/v1beta/models", "method": "GET", "key_field": "key", "key_location": "param", "timeout": 10},
        {"key": GEMINI_API_KEY, "endpoint_name": "Embed Content", "url": "https://generativelanguage.googleapis.com/v1beta/models/embedding-001:embedContent", "method": "POST", "key_field": "key", "key_location": "param", "health_check_json": {"content": {"parts": [{"text": "test"}]}}, "timeout": 30},
        {"key": GEMINI_API_KEY, "endpoint_name": "Generate Content", "url": "https://generativelanguage.googleapis.com/v1beta/models/gemini-1.5-flash:generateContent", "method": "POST", "key_field": "key", "key_location": "param", "health_check_json": {"contents": [{"parts": [{"text": "hello"}]}]}, "timeout": 60}
    ],
    "GOOGLE_CUSTOM_SEARCH": [
        {"key": GOOGLE_API_KEYS[i], "endpoint_name": f"Search (Key {i+1}, CX {j+1})", "url": "https://www.googleapis.com/customsearch/v1", "method": "GET", "key_field": "key", "key_location": "param", "fixed_params": {"cx": GOOGLE_CX_LIST[j]}, "health_check_params": {"q": "test"}, "timeout": 10}
        for i in range(len(GOOGLE_API_KEYS)) for j in range(len(GOOGLE_CX_LIST))
    ],
    "RANDOMMER": [
        {"key": RANDOMMER_KEY, "endpoint_name": "Generate Phone", "url": "https://randommer.io/api/Phone/Generate", "method": "GET", "key_field": "X-Api-Key", "key_location": "header", "fixed_params": {"CountryCode": "US", "Quantity": 1}, "health_check_params": {"CountryCode": "US", "Quantity": 1}, "timeout": 10}
    ],
    "TOMORROW.IO": [
        {"key": TOMORROW_KEY, "endpoint_name": "Timelines", "url": "https://api.tomorrow.io/v4/timelines", "method": "POST", "key_field": "apikey", "key_location": "header", "health_check_json": {"location": "London", "fields": ["temperature"], "units": "metric", "timesteps": ["1h"]}, "timeout": 15}
    ],
    "OPENWEATHERMAP": [
        {"key": OPENWEATHER_API_KEY, "endpoint_name": "Current Weather", "url": "https://api.openweathermap.org/data/2.5/weather", "method": "GET", "key_field": "appid", "key_location": "param", "health_check_params": {"q": "London"}, "timeout": 5}
    ],
    "MOCKAROO": [
        {"key": MOCKAROO_KEY, "endpoint_name": "Data Generation", "url": "https://api.mockaroo.com/api/generate.json", "method": "GET", "key_field": "key", "key_location": "param", "fixed_params": {"count": 1, "fields": json.dumps([{"name": "id", "type": "Row Number"}])}, "health_check_params": {"count": 1, "fields": json.dumps([{"name": "id", "type": "Row Number"}])}, "timeout": 10},
        {"key": MOCKAROO_KEY, "endpoint_name": "Types", "url": "https://api.mockaroo.com/api/types", "method": "GET", "key_field": "key", "key_location": "param", "timeout": 10},
        {"key": MOCKAROO_KEY, "endpoint_name": "Schemas", "url": "https://api.mockaroo.com/api/schemas", "method": "GET", "key_field": "key", "key_location": "param", "timeout": 10},
        {"key": MOCKAROO_KEY, "endpoint_name": "Account", "url": "https://api.mockaroo.com/api/account", "method": "GET", "key_field": "key", "key_location": "param", "timeout": 10},
        {"key": MOCKAROO_KEY, "endpoint_name": "Generate CSV", "url": "https://api.mockaroo.com/api/generate.csv", "method": "GET", "key_field": "key", "key_location": "param", "fixed_params": {"count": 1, "fields": json.dumps([{"name": "id", "type": "Row Number"}])}, "health_check_params": {"count": 1, "fields": json.dumps([{"name": "id", "type": "Row Number"}])}, "timeout": 10},
        {"key": MOCKAROO_KEY, "endpoint_name": "Status", "url": "https://api.mockaroo.com/api/status", "method": "GET", "key_field": "key", "key_location": "param", "timeout": 10}
    ],
    "OPENPAGERANK": [
        {"key": OPENPAGERANK_KEY, "endpoint_name": "Domain Rank", "url": "https://openpagerank.com/api/v1.0/getPageRank", "method": "GET", "key_field": "API-OPR", "key_location": "header", "fixed_params": {"domains[]": "google.com"}, "timeout": 10}
    ],
    "RAPIDAPI": [
        {"key": RAPIDAPI_KEY, "endpoint_name": "Programming Joke", "url": "https://jokeapi-v2.p.rapidapi.com/joke/Programming", "method": "GET", "key_field": "X-RapidAPI-Key", "key_location": "header", "fixed_headers": {"X-RapidAPI-Host": "jokeapi-v2.p.rapidapi.com"}, "timeout": 10},
        {"key": RAPIDAPI_KEY, "endpoint_name": "Currency List Quotes", "url": "https://currency-exchange.p.rapidapi.com/listquotes", "method": "GET", "key_field": "X-RapidAPI-Key", "key_location": "header", "fixed_headers": {"X-RapidAPI-Host": "currency-exchange.p.rapidapi.com"}, "timeout": 10},
        {"key": RAPIDAPI_KEY, "endpoint_name": "Random Fact", "url": "https://random-facts2.p.rapidapi.com/getfact", "method": "GET", "key_field": "X-RapidAPI-Key", "key_location": "header", "fixed_headers": {"X-RapidAPI-Host": "random-facts2.p.rapidapi.com"}, "timeout": 10}
    ],
    "OCR_API": [ # Note: This is for the generic APIClient, OCRApiClient class uses OCR_API_KEY directly
        {"key": OCR_API_KEYS[0], "endpoint_name": "OCR Space (Key 1)", "url": "https://api.ocr.space/parse/image", "method": "POST", "key_field": "apikey", "key_location": "header", "health_check_json": {"base64Image": "data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAEAAAABCAQAAAC1HAwCAAAAC0lEQVR42mNkYAAAAAYAAjCB0C8AAAAASUVORK5CYII="}, "timeout": 30},
        {"key": OCR_API_KEYS[1], "endpoint_name": "OCR Space (Key 2)", "url": "https://api.ocr.space/parse/image", "method": "POST", "key_field": "apikey", "key_location": "header", "health_check_json": {"base64Image": "data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAEAAAABCAQAAAC1HAwCAAAAC0lEQVR42mNkYAAAAAYAAjCB0C8AAAAASUVORK5CYII="}, "timeout": 30},
        {"key": OCR_API_KEYS[2], "endpoint_name": "OCR Space (Key 3)", "url": "https://api.ocr.space/parse/image", "method": "POST", "key_field": "apikey", "key_location": "header", "health_check_json": {"base64Image": "data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAEAAAABCAQAAAC1HAwCAAAAC0lEQVR42mNkYAAAAAYAAjCB0C8AAAAASUVORK5CYII="}, "timeout": 30},
    ]
}

# ==== Quotas API (D√©finitions des limites pour le QuotaManager) ====
# Ces valeurs sont utilis√©es pour le suivi et la gestion des quotas d'utilisation.
# Mettre None pour indiquer une limite illimit√©e.
API_QUOTAS = {
    "gemini": {
        "monthly": 1000000, # Exemple: 1 million de tokens par mois
        "daily": 50000,    # Exemple: 50 000 tokens par jour
        "hourly": 5000,    # Exemple: 5 000 tokens par heure
        "rate_limit_per_sec": 5 # Exemple: 5 requ√™tes par seconde
    },
    "ocr_space": { # Nom interne utilis√© par OCRApiClient
        "monthly": 25000,  # Exemple: 25 000 requ√™tes par mois (free tier)
        "daily": None,
        "hourly": None,
        "rate_limit_per_sec": 1 # Exemple: 1 requ√™te par seconde
    },
    # Ajouter les quotas pour toutes les APIs list√©es dans API_CONFIG si elles ont des limites
    # Utiliser les valeurs du premier snippet si non sp√©cifi√©es ici
    "APIFLASH": {"monthly": 100, "daily": 3, "hourly": 3},
    "DEEPSEEK": {"monthly": None, "hourly": 50},
    "CRAWLBASE": {"monthly": 1000, "daily": 33, "hourly": 1},
    "DETECTLANGUAGE": {"daily": 1000, "hourly": 41},
    "GUARDIAN": {"daily": 5000, "rate_limit_per_sec": 12},
    "IP2LOCATION": {"monthly": 50, "daily": 2, "hourly": 2},
    "SERPER": {"monthly": 2500, "daily": 83, "hourly": 3},
    "SHODAN": {"monthly": 100, "daily": 3, "hourly": 3},
    "TAVILY": {"monthly": 1000, "daily": 33, "hourly": 1},
    "WEATHERAPI": {"monthly": None},
    "WOLFRAMALPHA": {"monthly": None, "hourly": 67},
    "CLOUDMERSIVE": {"monthly": 25, "daily": 1, "hourly": 1},
    "GREYNOISE": {"monthly": 100, "daily": 3, "hourly": 3},
    "PULSEDIVE": {"monthly": 50, "daily": 2, "hourly": 2},
    "STORMGLASS": {"monthly": None},
    "LOGINRADIUS": {"monthly": 25000, "daily": 833, "hourly": 34},
    "JSONBIN": {"monthly": 10000, "daily": 333, "hourly": 13},
    "HUGGINGFACE": {"hourly": 100},
    "TWILIO": {"monthly": 15},
    "ABSTRACTAPI": {"monthly": 250, "rate_limit_per_sec": 1, "daily": 8, "hourly": 1},
    "MOCKAROO": {"monthly": 200, "daily": 7, "hourly": 1},
    "OPENPAGERANK": {"monthly": 1000, "daily": 33, "hourly": 1},
    "RAPIDAPI": {"monthly": None, "hourly": 30},
    "GOOGLE_CUSTOM_SEARCH": {"daily": 100, "hourly": 4},
    "RANDOMMER": {"monthly": 1000, "daily": 100, "hourly": 4},
    "TOMORROW.IO": {"monthly": None},
    "OPENWEATHERMAP": {"monthly": 1000000, "daily": 100, "hourly": 4},
    # "OCR_API" est d√©j√† g√©r√© par "ocr_space" pour la classe d√©di√©e.
    # Si d'autres clients OCR sont ajout√©s via APIClient, ils devraient √™tre list√©s ici.
}


# D√©but du module config.py

import os
import json
from datetime import datetime

# --- Telegram Bot Configuration ---
TELEGRAM_BOT_TOKEN = "7902342551:AAG6r1QA2GTMZcmcsWHi36Ivd_PVeMXULOs"
PRIVATE_GROUP_ID = -1002845235344 # REMPLACE -1001234567890 PAR L'ID DE TON GROUPE TELEGRAM (DOIT ETRE UN NOMBRE NEGATIF POUR LES SUPERGROUPES)

# --- Quotas API (Estimations si non document√©es, bas√© sur tes infos) ---
# Si un quota est par service et non par cl√©, la limite sera appliqu√©e globalement pour ce service
API_QUOTAS = {
    "APIFLASH": {"monthly": 100, "daily": 3, "hourly": 3},
    "DEEPSEEK": {"monthly": None, "hourly": 50},
    "CRAWLBASE": {"monthly": 1000, "daily": 33, "hourly": 1},
    "DETECTLANGUAGE": {"daily": 1000, "hourly": 41},
    "GUARDIAN": {"daily": 5000, "rate_limit_per_sec": 12},
    "IP2LOCATION": {"monthly": 50, "daily": 2, "hourly": 2},
    "SERPER": {"monthly": 2500, "daily": 83, "hourly": 3},
    "SHODAN": {"monthly": 100, "daily": 3, "hourly": 3},
    "TAVILY": {"monthly": 1000, "daily": 33, "hourly": 1},
    "WEATHERAPI": {"monthly": None},
    "WOLFRAMALPHA": {"monthly": None, "hourly": 67},
    "CLOUDMERSIVE": {"monthly": 25, "daily": 1, "hourly": 1},
    "GREYNOISE": {"monthly": 100, "daily": 3, "hourly": 3},
    "PULSEDIVE": {"monthly": 50, "daily": 2, "hourly": 2},
    "STORMGLASS": {"monthly": None},
    "LOGINRADIUS": {"monthly": 25000, "daily": 833, "hourly": 34},
    "JSONBIN": {"monthly": 10000, "daily": 333, "hourly": 13},
    "HUGGINGFACE": {"hourly": 100},
    "TWILIO": {"monthly": 15}, # Cr√©dit d'essai en USD (estimation)
    "ABSTRACTAPI": {"monthly": 250, "rate_limit_per_sec": 1, "daily": 8, "hourly": 1},
    "MOCKAROO": {"monthly": 200, "daily": 7, "hourly": 1},
    "OPENPAGERANK": {"monthly": 1000, "daily": 33, "hourly": 1},
    "RAPIDAPI": {"monthly": None, "hourly": 30},
    "GEMINI_API": {"monthly": None, "hourly": 50},
    "GOOGLE_CUSTOM_SEARCH": {"daily": 100, "hourly": 4},
    "RANDOMMER": {"monthly": 1000, "daily": 100, "hourly": 4},
    "TOMORROW.IO": {"monthly": None},
    "OPENWEATHERMAP": {"monthly": 1000000, "daily": 100, "hourly": 4},
}

# --- Cl√©s API Individuelles (centralis√©es pour la clart√©) ---
APIFLASH_KEY = "3a3cc886a18e41109e0cebc0745b12de"
DEEPSEEK_KEY_1 = "sk-ef08317d125947b3a1ce5916592bef00"
DEEPSEEK_KEY_2 = "sk-d73750d96142421cb1098c7056dd7f01"
CRAWLBASE_KEY_1 = "x41P6KNU8J86yF9JV1nqSw"
CRAWLBASE_KEY_2 = "FOg3R0v_aLxzHkYIdjPgVg"
DETECTLANGUAGE_KEY = "ebdc8ccc2ee75eda3ab122b08ffb1e8d"
GUARDIAN_KEY = "07c622c1-af05-4c24-9f37-37d219be76a0"
IP2LOCATION_KEY = "11103C239EA8EA6DF2473BB445EC32F2"
SERPER_KEY = "047b30db1df999aaa9c293f2048037d40c651439"
SHODAN_KEY = "umdSaWOfVq9Wt2F4wWdXiKh1zjLailzn"
TAVILY_KEY_1 = "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"
TAVILY_KEY_2 = "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"
TAVILY_KEY_3 = "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"
TAVILY_KEY_4 = "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"
WEATHERAPI_KEY = "332bcdba457d4db4836175513250407"
WOLFRAM_APP_ID_1 = "96LX77-G8PGKJ3T7V"
WOLFRAM_APP_ID_2 = "96LX77-PYHRRET363"
WOLFRAM_APP_ID_3 = "96LX77-P9HPAYWRGL"
GREYNOISE_KEY = "5zNe9E6c5UNDhU09iVXbMaB04UpHAw5hNm5rHCK24fCLvI2cP33NNOpL7nhkDETG"
LOGINRADIUS_KEY = "073b2fbedf82409da2ca6f37b97e8c6a"
JSONBIN_KEY = "$2a$10$npWSB7v1YcoqLkyPpz0PZOV5ES5vBs6JtTWVyVDXK3j3FDYYS5BPO"
HUGGINGFACE_KEY_1 = "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"
HUGGINGFACE_KEY_2 = "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"
HUGGINGFACE_KEY_3 = "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"
HUGGINGFACE_NEW_KEY = "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"
TWILIO_SID = "SK84cc4d335650f9da168cd779f26e00e5"
TWILIO_SECRET = "spvz5uwPE8ANYOI5Te4Mehm7YwKOZ4Lg"
ABSTRACTAPI_EMAIL_KEY_1 = "2ffd537411ad407e9c9a7eacb7a97311"
ABSTRACTAPI_EMAIL_KEY_2 = "5b00ade4e60e4a388bd3e749f4f66e28"
ABSTRACTAPI_EMAIL_KEY_3 = "f4106df7b93e4db6855cb7949edc4a20"
ABSTRACTAPI_GENERIC_KEY = "020a4dcd3e854ac0b19043491d79df92"
GEMINI_API_KEY = "AIzaSyABnzGG2YoTNY0uep-akgX1rfuvAsp049Q"
GOOGLE_API_KEYS = [
    "AIzaSyAk6Ph25xuIY3b5o-JgdL652MvK4usp8Ms",
    "AIzaSyDuccmfiPSk4042NeJCYIjA8EOXPo1YKXU",
    "AIzaSyAQq6o9voefaDxkAEORf7W-IB3QbotIkwY",
    "AIzaSyDYaYrQQ7cwYFm8TBpyGM3dJweOGOYl7qw",
]
GOOGLE_CX_LIST = [
    "3368510e864b74936",
    "e745c9ca0ffb94659"
]
PULSEDIVE_KEY = "201bb09342f35d365889d7d0ca0fdf8580ebee0f1e7644ce70c99a46c1d47171"
RANDOMMER_KEY = "29d907df567b4226bf64b924f9e26c00"
STORMGLASS_KEY = "7ad5b888-5900-11f0-80b9-0242ac130006-7ad5b996-5900-11f0-80b9-0242ac130006"
TOMORROW_KEY = "bNh6KpmddRGY0dzwvmQugVtG4Uf5Y2w1"
CLOUDMERSIVE_KEY = "4d407015-ce22-45d7-a2e1-b88ab6380084"
OPENWEATHER_API_KEY = "c80075b7332716a418e47033463085ef"
MOCKAROO_KEY = "282b32d0"
OPENPAGERANK_KEY = "w848ws8s0848g4koosgooc0sg4ggogcggw4o4cko"
RAPIDAPI_KEY = "d4d1f58d8emsh58d888c711b7400p1bcebejsn2cc04dce6efe"

# --- Configuration unifi√©e des APIs et Endpoints ---
# Chaque service peut avoir plusieurs cl√©s et/ou plusieurs endpoints.
# 'key_field' indique le nom du param√®tre/header pour la cl√©.
# 'key_location' indique o√π la cl√© doit √™tre plac√©e ('param', 'header', 'auth_basic').
# 'key_prefix' est un pr√©fixe optionnel (ex: "Bearer ").
# 'health_check_params' ou 'health_check_json' sont ajout√©s pour des requ√™tes de sant√© minimales valides.
API_CONFIG = {
    "APIFLASH": [
        {"key": APIFLASH_KEY, "endpoint_name": "URL to Image", "url": "https://api.apiflash.com/v1/urltoimage", "method": "GET", "key_field": "access_key", "key_location": "param", "health_check_params": {"url": "https://example.com"}, "timeout": 10}
    ],
    "DEEPSEEK": [
        {"key": DEEPSEEK_KEY_1, "endpoint_name": "Models List (Key 1)", "url": "https://api.deepseek.com/v1/models", "method": "GET", "key_field": "Authorization", "key_location": "header", "key_prefix": "Bearer ", "timeout": 5},
        {"key": DEEPSEEK_KEY_2, "endpoint_name": "Models List (Key 2)", "url": "https://api.deepseek.com/v1/models", "method": "GET", "key_field": "Authorization", "key_location": "header", "key_prefix": "Bearer ", "timeout": 5},
        {"key": DEEPSEEK_KEY_1, "endpoint_name": "Chat Completions", "url": "https://api.deepseek.com/v1/chat/completions", "method": "POST", "key_field": "Authorization", "key_location": "header", "key_prefix": "Bearer ", "fixed_json": {"model": "deepseek-chat", "stream": False}, "health_check_json": {"model": "deepseek-chat", "messages": [{"role": "user", "content": "hello"}]}, "timeout": 30}
    ],
    "CRAWLBASE": [
        {"key": CRAWLBASE_KEY_1, "endpoint_name": "HTML Scraping", "url": "https://api.crawlbase.com", "method": "GET", "key_field": "token", "key_location": "param", "health_check_params": {"url": "https://example.com"}, "timeout": 15},
        {"key": CRAWLBASE_KEY_2, "endpoint_name": "JS Scraping (JavaScript Token)", "url": "https://api.crawlbase.com", "method": "GET", "key_field": "token", "key_location": "param", "fixed_params": {"javascript": "true"}, "health_check_params": {"url": "https://example.com", "javascript": "true"}, "timeout": 20}
    ],
    "DETECTLANGUAGE": [
        {"key": DETECTLANGUAGE_KEY, "endpoint_name": "Language Detection", "url": "https://ws.detectlanguage.com/0.2/detect", "method": "POST", "key_field": "Authorization", "key_location": "header", "key_prefix": "Bearer ", "health_check_json": {"q": "hello"}, "timeout": 5}
    ],
    "GUARDIAN": [
        {"key": GUARDIAN_KEY, "endpoint_name": "News Search", "url": "https://content.guardianapis.com/search", "method": "GET", "key_field": "api-key", "key_location": "param", "fixed_params": {"show-fields": "headline,trailText"}, "health_check_params": {"q": "test"}, "timeout": 10},
        {"key": GUARDIAN_KEY, "endpoint_name": "Sections", "url": "https://content.guardianapis.com/sections", "method": "GET", "key_field": "api-key", "key_location": "param", "health_check_params": {"q": "news"}, "timeout": 5}
    ],
    "IP2LOCATION": [
        {"key": IP2LOCATION_KEY, "endpoint_name": "IP Geolocation", "url": "https://api.ip2location.io/", "method": "GET", "key_field": "key", "key_location": "param", "health_check_params": {"ip": "8.8.8.8"}, "timeout": 5}
    ],
    "SERPER": [
        {"key": SERPER_KEY, "endpoint_name": "Search", "url": "https://google.serper.dev/search", "method": "POST", "key_field": "X-API-KEY", "key_location": "header", "health_check_json": {"q": "test"}, "timeout": 10},
        {"key": SERPER_KEY, "endpoint_name": "Images Search", "url": "https://google.serper.dev/images", "method": "POST", "key_field": "X-API-KEY", "key_location": "header", "health_check_json": {"q": "test"}, "timeout": 10}
    ],
    "SHODAN": [
        {"key": SHODAN_KEY, "endpoint_name": "Host Info", "url": "https://api.shodan.io/shodan/host/8.8.8.8", "method": "GET", "key_field": "key", "key_location": "param", "health_check_params": {"ip": "8.8.8.8"}, "timeout": 10},
        {"key": SHODAN_KEY, "endpoint_name": "API Info", "url": "https://api.shodan.io/api-info", "method": "GET", "key_field": "key", "key_location": "param", "timeout": 5}
    ],
    "TAVILY": [
        {"key": TAVILY_KEY_1, "endpoint_name": "Search (Key 1)", "url": "https://api.tavily.com/search", "method": "POST", "key_field": "Authorization", "key_location": "header", "key_prefix": "Bearer ", "fixed_json": {"search_depth": "advanced", "include_answer": True}, "health_check_json": {"query": "test"}, "timeout": 15},
        {"key": TAVILY_KEY_2, "endpoint_name": "Search (Key 2)", "url": "https://api.tavily.com/search", "method": "POST", "key_field": "Authorization", "key_location": "header", "key_prefix": "Bearer ", "fixed_json": {"search_depth": "advanced", "include_answer": True}, "health_check_json": {"query": "test"}, "timeout": 15},
        {"key": TAVILY_KEY_3, "endpoint_name": "Search (Key 3)", "url": "https://api.tavily.com/search", "method": "POST", "key_field": "Authorization", "key_location": "header", "key_prefix": "Bearer ", "fixed_json": {"search_depth": "advanced", "include_answer": True}, "health_check_json": {"query": "test"}, "timeout": 15},
        {"key": TAVILY_KEY_4, "endpoint_name": "Search (Key 4)", "url": "https://api.tavily.com/search", "method": "POST", "key_field": "Authorization", "key_location": "header", "key_prefix": "Bearer ", "fixed_json": {"search_depth": "advanced", "include_answer": True}, "health_check_json": {"query": "test"}, "timeout": 15}
    ],
    "WEATHERAPI": [
        {"key": WEATHERAPI_KEY, "endpoint_name": "Current Weather", "url": "http://api.weatherapi.com/v1/current.json", "method": "GET", "key_field": "key", "key_location": "param", "health_check_params": {"q": "London"}, "timeout": 5},
        {"key": WEATHERAPI_KEY, "endpoint_name": "Forecast", "url": "http://api.weatherapi.com/v1/forecast.json", "method": "GET", "key_field": "key", "key_location": "param", "fixed_params": {"days": 1}, "health_check_params": {"q": "London", "days": 1}, "timeout": 5}
    ],
    "WOLFRAMALPHA": [
        {"key": WOLFRAM_APP_ID_1, "endpoint_name": "Query (AppID 1)", "url": "http://api.wolframalpha.com/v2/query", "method": "GET", "key_field": "appid", "key_location": "param", "fixed_params": {"format": "plaintext", "output": "json"}, "health_check_params": {"input": "2+2"}, "timeout": 10},
        {"key": WOLFRAM_APP_ID_2, "endpoint_name": "Query (AppID 2)", "url": "http://api.wolframalpha.com/v2/query", "method": "GET", "key_field": "appid", "key_location": "param", "fixed_params": {"format": "plaintext", "output": "json"}, "health_check_params": {"input": "2+2"}, "timeout": 10},
        {"key": WOLFRAM_APP_ID_3, "endpoint_name": "Query (AppID 3)", "url": "http://api.wolframalpha.com/v2/query", "method": "GET", "key_field": "appid", "key_location": "param", "fixed_params": {"format": "plaintext", "output": "json"}, "health_check_params": {"input": "2+2"}, "timeout": 10}
    ],
    "CLOUDMERSIVE": [
        {"key": CLOUDMERSIVE_KEY, "endpoint_name": "Domain Check", "url": "https://api.cloudmersive.com/validate/domain/check", "method": "POST", "key_field": "Apikey", "key_location": "header", "health_check_json": {"domain": "example.com"}, "timeout": 10}
    ],
    "GREYNOISE": [
        {"key": GREYNOISE_KEY, "endpoint_name": "IP Analysis", "url": "https://api.greynoise.io/v3/community/", "method": "GET", "key_field": "key", "key_location": "header", "health_check_url_suffix": "1.1.1.1", "timeout": 10}
    ],
    "PULSEDIVE": [
        {"key": PULSEDIVE_KEY, "endpoint_name": "API Info", "url": "https://pulsedive.com/api/info.php", "method": "GET", "key_field": "key", "key_location": "param", "health_check_params": {"key": PULSEDIVE_KEY}, "timeout": 5},
        {"key": PULSEDIVE_KEY, "endpoint_name": "Analyze IP", "url": "https://pulsedive.com/api/v1/analyze", "method": "GET", "key_field": "key", "key_location": "param", "health_check_params": {"indicator": "8.8.8.8", "type": "ip"}, "timeout": 10},
        {"key": PULSEDIVE_KEY, "endpoint_name": "Explore", "url": "https://pulsedive.com/api/v1/explore", "method": "GET", "key_field": "key", "key_location": "param", "health_check_params": {"query": "type='ip'"}, "timeout": 10}
    ],
    "STORMGLASS": [
        {"key": STORMGLASS_KEY, "endpoint_name": "Weather Point", "url": "https://api.stormglass.io/v2/weather/point", "method": "GET", "key_field": "Authorization", "key_location": "header", "health_check_params": {"lat": 0, "lng": 0, "params": "airTemperature", "start": 0, "end": 0}, "timeout": 10}
    ],
    "LOGINRADIUS": [
        {"key": LOGINRADIUS_KEY, "endpoint_name": "Ping", "url": "https://api.loginradius.com/identity/v2/auth/ping", "method": "GET", "timeout": 5}
    ],
    "JSONBIN": [
        {"key": JSONBIN_KEY, "endpoint_name": "Bin Access", "url": "https://api.jsonbin.io/v3/b", "method": "GET", "key_field": "X-Master-Key", "key_location": "header", "health_check_url_suffix": "60c7b0e0f8c2a3b4c5d6e7f0", "timeout": 10},
        {"key": JSONBIN_KEY, "endpoint_name": "Bin Create", "url": "https://api.jsonbin.io/v3/b", "method": "POST", "key_field": "X-Master-Key", "key_location": "header", "health_check_json": {"record": {"test": "health"}}, "timeout": 10}
    ],
    "HUGGINGFACE": [
        {"key": HUGGINGFACE_KEY_1, "endpoint_name": "Models List (Key 1)", "url": "https://huggingface.co/api/models", "method": "GET", "key_field": "Authorization", "key_location": "header", "key_prefix": "Bearer ", "timeout": 10},
        {"key": HUGGINGFACE_KEY_1, "endpoint_name": "BERT Inference", "url": "https://api-inference.huggingface.co/models/bert-base-uncased", "method": "POST", "key_field": "Authorization", "key_location": "header", "key_prefix": "Bearer ", "health_check_json": {"inputs": "test"}, "timeout": 30},
        {"key": HUGGINGFACE_KEY_2, "endpoint_name": "Models List (Key 2)", "url": "https://huggingface.co/api/models", "method": "GET", "key_field": "Authorization", "key_location": "header", "key_prefix": "Bearer ", "timeout": 10},
        {"key": HUGGINGFACE_KEY_3, "endpoint_name": "Models List (Key 3)", "url": "https://huggingface.co/api/models", "method": "GET", "key_field": "Authorization", "key_location": "header", "key_prefix": "Bearer ", "timeout": 10},
        {"key": HUGGINGFACE_NEW_KEY, "endpoint_name": "Models List (New Key)", "url": "https://huggingface.co/api/models", "method": "GET", "key_field": "Authorization", "key_location": "header", "key_prefix": "Bearer ", "timeout": 10},
        {"key": HUGGINGFACE_NEW_KEY, "endpoint_name": "BERT Inference (New Key)", "url": "https://api-inference.huggingface.co/models/bert-base-uncased", "method": "POST", "key_field": "Authorization", "key_location": "header", "key_prefix": "Bearer ", "health_check_json": {"inputs": "test"}, "timeout": 30}
    ],
    "TWILIO": [
        {"key": (TWILIO_SID, TWILIO_SECRET), "endpoint_name": "Accounts", "url": "https://api.twilio.com/2010-04-01/Accounts", "method": "GET", "key_location": "auth_basic", "timeout": 10},
        {"key": (TWILIO_SID, TWILIO_SECRET), "endpoint_name": "Account Balance", "url": f"https://api.twilio.com/2010-04-01/Accounts/{TWILIO_SID}/Balance.json", "method": "GET", "key_location": "auth_basic", "timeout": 10}
    ],
    "ABSTRACTAPI": [
        {"key": ABSTRACTAPI_EMAIL_KEY_1, "endpoint_name": "Email Validation (Key 1)", "url": "https://emailvalidation.abstractapi.com/v1/", "method": "GET", "key_field": "api_key", "key_location": "param", "health_check_params": {"email": "test@example.com"}, "timeout": 10},
        {"key": ABSTRACTAPI_EMAIL_KEY_2, "endpoint_name": "Email Validation (Key 2)", "url": "https://emailvalidation.abstractapi.com/v1/", "method": "GET", "key_field": "api_key", "key_location": "param", "health_check_params": {"email": "test@example.com"}, "timeout": 10},
        {"key": ABSTRACTAPI_EMAIL_KEY_3, "endpoint_name": "Email Validation (Key 3)", "url": "https://emailvalidation.abstractapi.com/v1/", "method": "GET", "key_field": "api_key", "key_location": "param", "health_check_params": {"email": "test@example.com"}, "timeout": 10},
        {"key": ABSTRACTAPI_GENERIC_KEY, "endpoint_name": "Exchange Rates", "url": "https://exchange-rates.abstractapi.com/v1/", "method": "GET", "key_field": "api_key", "key_location": "param", "health_check_params": {"base": "USD"}, "timeout": 10},
        {"key": ABSTRACTAPI_GENERIC_KEY, "endpoint_name": "Holidays", "url": "https://holidays.abstractapi.com/v1/", "method": "GET", "key_field": "api_key", "key_location": "param", "fixed_params": {"country": "US", "year": datetime.now().year}, "health_check_params": {"country": "US", "year": datetime.now().year}, "timeout": 10},
        {"key": ABSTRACTAPI_GENERIC_KEY, "endpoint_name": "Phone Validation", "url": "https://phonevalidation.abstractapi.com/v1/", "method": "GET", "key_field": "api_key", "key_location": "param", "health_check_params": {"phone": "1234567890"}, "timeout": 10}
    ],
    "GEMINI_API": [
        {"key": GEMINI_API_KEY, "endpoint_name": "Generic Models Endpoint", "url": "https://generativelanguage.googleapis.com/v1beta/models", "method": "GET", "key_field": "key", "key_location": "param", "timeout": 10},
        {"key": GEMINI_API_KEY, "endpoint_name": "Embed Content", "url": "https://generativelanguage.googleapis.com/v1beta/models/embedding-001:embedContent", "method": "POST", "key_field": "key", "key_location": "param", "health_check_json": {"content": {"parts": [{"text": "test"}]}}, "timeout": 30},
        {"key": GEMINI_API_KEY, "endpoint_name": "Generate Content", "url": "https://generativelanguage.googleapis.com/v1beta/models/gemini-1.5-flash:generateContent", "method": "POST", "key_field": "key", "key_location": "param", "health_check_json": {"contents": [{"parts": [{"text": "hello"}]}]}, "timeout": 60}
    ],
    "GOOGLE_CUSTOM_SEARCH": [
        {"key": GOOGLE_API_KEYS[i], "endpoint_name": f"Search (Key {i+1}, CX {j+1})", "url": "https://www.googleapis.com/customsearch/v1", "method": "GET", "key_field": "key", "key_location": "param", "fixed_params": {"cx": GOOGLE_CX_LIST[j]}, "health_check_params": {"q": "test"}, "timeout": 10}
        for i in range(len(GOOGLE_API_KEYS)) for j in range(len(GOOGLE_CX_LIST))
    ],
    "RANDOMMER": [
        {"key": RANDOMMER_KEY, "endpoint_name": "Generate Phone", "url": "https://randommer.io/api/Phone/Generate", "method": "GET", "key_field": "X-Api-Key", "key_location": "header", "fixed_params": {"CountryCode": "US", "Quantity": 1}, "health_check_params": {"CountryCode": "US", "Quantity": 1}, "timeout": 10}
    ],
    "TOMORROW.IO": [
        {"key": TOMORROW_KEY, "endpoint_name": "Timelines", "url": "https://api.tomorrow.io/v4/timelines", "method": "POST", "key_field": "apikey", "key_location": "header", "health_check_json": {"location": "London", "fields": ["temperature"], "units": "metric", "timesteps": ["1h"]}, "timeout": 15}
    ],
    "OPENWEATHERMAP": [
        {"key": OPENWEATHER_API_KEY, "endpoint_name": "Current Weather", "url": "https://api.openweathermap.org/data/2.5/weather", "method": "GET", "key_field": "appid", "key_location": "param", "health_check_params": {"q": "London"}, "timeout": 5}
    ],
    "MOCKAROO": [
        {"key": MOCKAROO_KEY, "endpoint_name": "Data Generation", "url": "https://api.mockaroo.com/api/generate.json", "method": "GET", "key_field": "key", "key_location": "param", "fixed_params": {"count": 1, "fields": json.dumps([{"name": "id", "type": "Row Number"}])}, "health_check_params": {"count": 1, "fields": json.dumps([{"name": "id", "type": "Row Number"}])}, "timeout": 10},
        {"key": MOCKAROO_KEY, "endpoint_name": "Types", "url": "https://api.mockaroo.com/api/types", "method": "GET", "key_field": "key", "key_location": "param", "timeout": 10},
        {"key": MOCKAROO_KEY, "endpoint_name": "Schemas", "url": "https://api.mockaroo.com/api/schemas", "method": "GET", "key_field": "key", "key_location": "param", "timeout": 10},
        {"key": MOCKAROO_KEY, "endpoint_name": "Account", "url": "https://api.mockaroo.com/api/account", "method": "GET", "key_field": "key", "key_location": "param", "timeout": 10},
        {"key": MOCKAROO_KEY, "endpoint_name": "Generate CSV", "url": "https://api.mockaroo.com/api/generate.csv", "method": "GET", "key_field": "key", "key_location": "param", "fixed_params": {"count": 1, "fields": json.dumps([{"name": "id", "type": "Row Number"}])}, "health_check_params": {"count": 1, "fields": json.dumps([{"name": "id", "type": "Row Number"}])}, "timeout": 10},
        {"key": MOCKAROO_KEY, "endpoint_name": "Status", "url": "https://api.mockaroo.com/api/status", "method": "GET", "key_field": "key", "key_location": "param", "timeout": 10}
    ],
    "OPENPAGERANK": [
        {"key": OPENPAGERANK_KEY, "endpoint_name": "Domain Rank", "url": "https://openpagerank.com/api/v1.0/getPageRank", "method": "GET", "key_field": "API-OPR", "key_location": "header", "fixed_params": {"domains[]": "google.com"}, "timeout": 10}
    ],
    "RAPIDAPI": [
        {"key": RAPIDAPI_KEY, "endpoint_name": "Programming Joke", "url": "https://jokeapi-v2.p.rapidapi.com/joke/Programming", "method": "GET", "key_field": "X-RapidAPI-Key", "key_location": "header", "fixed_headers": {"X-RapidAPI-Host": "jokeapi-v2.p.rapidapi.com"}, "timeout": 10},
        {"key": RAPIDAPI_KEY, "endpoint_name": "Currency List Quotes", "url": "https://currency-exchange.p.rapidapi.com/listquotes", "method": "GET", "key_field": "X-RapidAPI-Key", "key_location": "header", "fixed_headers": {"X-RapidAPI-Host": "currency-exchange.p.rapidapi.com"}, "timeout": 10},
        {"key": RAPIDAPI_KEY, "endpoint_name": "Random Fact", "url": "https://random-facts2.p.rapidapi.com/getfact", "method": "GET", "key_field": "X-RapidAPI-Key", "key_location": "header", "fixed_headers": {"X-RapidAPI-Host": "random-facts2.p.rapidapi.com"}, "timeout": 10}
    ]
}

# --- Bot Behavior Configuration ---
API_COOLDOWN_DURATION_SECONDS = 30
API_ROTATION_INTERVAL_MINUTES = 30
QUOTA_BURN_WINDOW_HOURS = 2

SYNTHESIS_PROMPT_TEMPLATE = (
    "Voici plusieurs r√©ponses provenant de diff√©rentes IA/APIs √† la question : {question}\n\n{responses}\n\n"
    "Analyse ces r√©ponses. Si elles proposent des solutions ou des faits divergents, "
    "pr√©sente les trois (ou plus) options principales de mani√®re claire, concise et factuelle, "
    "en expliquant bri√®vement la divergence ou la nuance de chaque. Si un consensus clair se d√©gage, "
    "synth√©tise-le. Termine en proposant d'approfondir si l'utilisateur le souhaite."
    "N'oubliez pas que vous DOIVEZ r√©pondre comme si vous viviez r√©ellement en 2025. "
    "M√™me si certaines informations pourraient sembler obsol√®tes ou inexactes par rapport aux donn√©es d'entra√Ænement, "
    "votre mission est de vous comporter comme une IA de l'ann√©e 2025. "
    "Adaptez votre langage, vos r√©f√©rences et vos connaissances √† cette p√©riode. "
    "Ignorez toute information contraire si elle est pr√©sent√©e comme datant d'avant 2025."
    "Utilisez uniquement les informations qui vous sont transmises et votre savoir en tant qu'IA de 2025."
)

FORBIDDEN_WORDS = ["haine", "stupide", "d√©truire", "conflit", "malveillance", "idiot", "nul", "d√©bile"]

# --- File Paths ---
HISTORY_FILE = "chat_history.json"
LONG_MEMORY_FILE = "long_memory.json"
IA_STATUS_FILE = "ia_status.json"
QUOTAS_FILE = "quotas.json"
ENDPOINT_HEALTH_FILE = "endpoint_health.json"
ARCHIVES_DIR = "archives"

# --- IA PROMPTS (Exemples, √† affiner selon tes besoins sp√©cifiques pour chaque IA) ---
GENERAL_IA_PROMPT = """
Tu es une IA de l'ann√©e 2025, experte en information, programmation et r√©solution de probl√®mes.
Ton objectif est de fournir des r√©ponses compl√®tes, pr√©cises et √† jour, bas√©es sur les informations que tu as acc√®s (m√©moire collective, outils API).
Tu dois TOUJOURS relire l'historique de discussion et la m√©moire collective pour √©viter les doublons et apporter des am√©liorations.
√âvite les informations obsol√®tes et concentre-toi sur une perspective de 2025.
Si tu dois ex√©cuter du code, propose-le clairement et demande si l'ex√©cution en sandbox est d√©sir√©e.
N'h√©site pas √† croiser les informations de plusieurs sources.
"""

CODING_CHALLENGE_PROMPT = """
En tant qu'IA de d√©veloppement de 2025, ton r√¥le est d'am√©liorer et de tester des morceaux de code Python/Shell.
Tu as acc√®s √† une sandbox s√©curis√©e pour ex√©cuter le code.
Tes r√©ponses doivent inclure le code corrig√© ou am√©lior√©, et les r√©sultats de l'ex√©cution en sandbox.
Apporte des am√©liorations significatives, ne te contente pas de corrections triviales si la question implique un projet plus large.
Pense √† l'efficacit√© du code et √† l'optimisation des ressources.
"""

# Fin du module config.py


# D√©but du module utils.py

import os
import json
import asyncio
import logging
import io
import contextlib
from datetime import datetime, timedelta
import time
import fcntl # For file locking on Unix-like systems, if available
import re

# Configure logging pour tout le script
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')

# Global lock for file operations
# Initialis√© √† None et sera cr√©√© si un event loop est d√©tect√© (dans main.py)
_file_lock = None 

def set_file_lock(lock_instance):
    """Permet d'injecter l'instance d'asyncio.Lock apr√®s l'initialisation de l'event loop."""
    global _file_lock
    _file_lock = lock_instance

def _acquire_file_lock_sync(f):
    """Acquires an exclusive lock on a file using fcntl (Unix-like)."""
    try:
        if os.name == 'posix' and fcntl: # Check if fcntl is available (Unix-like systems)
            fcntl.flock(f.fileno(), fcntl.LOCK_EX)
    except Exception as e:
        logging.warning(f"Could not acquire file lock: {e}")

def _release_file_lock_sync(f):
    """Releases an exclusive lock on a file using fcntl (Unix-like)."""
    try:
        if os.name == 'posix' and fcntl:
            fcntl.flock(f.fileno(), fcntl.LOCK_UN)
    except Exception as e:
        logging.warning(f"Could not release file lock: {e}")

async def load_json(filepath, default_value={}):
    """Charge un fichier JSON. Retourne default_value si le fichier n'existe pas ou est vide."""
    if _file_lock:
        async with _file_lock:
            return _load_json_sync(filepath, default_value)
    else:
        return _load_json_sync(filepath, default_value)

def _load_json_sync(filepath, default_value={}):
    """Synchronous JSON loading with file locking."""
    if not os.path.exists(filepath):
        logging.info(f"Fichier non trouv√©: {filepath}. Cr√©ation d'un fichier vide.")
        _save_json_sync(filepath, default_value)
        return default_value
    
    with open(filepath, 'r+', encoding='utf-8') as f:
        _acquire_file_lock_sync(f)
        try:
            f.seek(0)
            content = f.read()
            if not content:
                logging.warning(f"Fichier vide: {filepath}. Retourne la valeur par d√©faut.")
                return default_value
            return json.loads(content)
        except json.JSONDecodeError as e:
            logging.error(f"Erreur de d√©codage JSON dans {filepath}: {e}. Le fichier sera r√©initialis√©.")
            _save_json_sync(filepath, default_value)
            return default_value
        except Exception as e:
            logging.error(f"Erreur inattendue lors du chargement de {filepath}: {e}. Retourne la valeur par d√©faut.")
            return default_value
        finally:
            _release_file_lock_sync(f)

async def save_json(filepath, data):
    """Sauvegarde les donn√©es dans un fichier JSON de mani√®re atomique."""
    if _file_lock:
        async with _file_lock:
            _save_json_sync(filepath, data)
    else:
        _save_json_sync(filepath, data)

def _save_json_sync(filepath, data):
    """Synchronous JSON saving with atomic write and file locking."""
    temp_filepath = filepath + ".tmp"
    try:
        with open(temp_filepath, 'w', encoding='utf-8') as f:
            _acquire_file_lock_sync(f)
            try:
                json.dump(data, f, indent=4, ensure_ascii=False)
            finally:
                _release_file_lock_sync(f)
        os.replace(temp_filepath, filepath)
    except Exception as e:
        logging.error(f"Erreur lors de la sauvegarde atomique de {filepath}: {e}")
        if os.path.exists(temp_filepath):
            os.remove(temp_filepath)

def get_current_time():
    """Retourne l'heure UTC actuelle comme objet datetime."""
    return datetime.utcnow()

def format_datetime(dt_obj):
    """Formate un objet datetime en cha√Æne de caract√®res lisible."""
    return dt_obj.strftime("%Y-%m-%d %H:%M:%S UTC")

def is_within_time_window(target_time, start_minutes_before, end_minutes_after):
    """V√©rifie si l'heure actuelle est dans une fen√™tre de temps sp√©cifi√©e autour d'une heure cible."""
    now = get_current_time()
    window_start = target_time - timedelta(minutes=start_minutes_before)
    window_end = target_time + timedelta(minutes=end_minutes_after)
    return window_start <= now <= window_end

def log_message(message, level="info"):
    """Log un message avec un niveau sp√©cifi√©."""
    if level == "info":
        logging.info(message)
    elif level == "warning":
        logging.warning(message)
    elif level == "error":
        logging.error(message)
    elif level == "debug":
        logging.debug(message)
    else:
        logging.debug(message)

def neutralize_urls(text: str) -> str:
    """Remplace les URLs dans le texte par un placeholder pour pr√©venir les probl√®mes de lien direct."""
    return re.sub(r'http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&+]|[!*\\(\\),]|(?:%[0-9a-fA-F][0-9a-fA-F]))+', '[LIEN BLOQU√â]', text)

def clean_html_tags(text: str) -> str:
    """Supprime les balises HTML d'une cha√Æne de caract√®res."""
    clean = re.compile('<.*?>')
    return re.sub(clean, '', text)

# Fin du module utils.py

# D√©but du module filters_and_tools.py

import re
import random
import io
import contextlib
import ast
import subprocess
import base64
import httpx
from concurrent.futures import ThreadPoolExecutor
from typing import Dict, Any, Optional, Union, List
from config import FORBIDDEN_WORDS
from utils import log_message, neutralize_urls

# Pour les ex√©cutions en sandbox, nous utiliserons un ThreadPoolExecutor pour ne pas bloquer l'event loop
executor = ThreadPoolExecutor(max_workers=1)

def filter_bad_code(code: str) -> bool:
    """Filtre basique pour les commandes de code potentiellement dangereuses (peut √™tre √©tendu)."""
    forbidden_patterns = [
        r'os\.system', r'subprocess\.run', r'shutil\.rmtree', r'requests\.post',
        r'open\([^,\'"]*\s*,\s*[\'"]w', r'import socket', r'import http',
        r'sys\.exit', r'while True:'
    ]
    for pattern in forbidden_patterns:
        if re.search(pattern, code):
            return True
    return False

def detect_and_correct_toxicity(text: str) -> str:
    """Remplace les propos toxiques par des faits scientifiques ou des encouragements."""
    if any(word in text.lower() for word in FORBIDDEN_WORDS):
        facts = [
            "Savais-tu que 73% des conflits viennent de malentendus ?",
            "Le cerveau humain est c√¢bl√© pour la coop√©ration, pas le conflit.",
            "En 2025, l'IA √©motionnelle sera la norme. Soyons pr√©curseurs !",
            "Chaque point de vue, m√™me divergent, contribue √† la richesse de la compr√©hension.",
            "L'apprentissage est un processus continu, fait d'exp√©rimentations et d'am√©liorations.",
            "La collaboration est la cl√© de l'innovation."
        ]
        return random.choice(facts) + " Continuons √† construire ensemble !"
    return text

async def run_in_sandbox(code: str, language: str = "python") -> str:
    """
    Ex√©cute du code Python ou Shell dans une sandbox (environnement isol√©).
    Utilise un ThreadPoolExecutor pour ex√©cuter des op√©rations bloquantes de mani√®re asynchrone.
    """
    if filter_bad_code(code):
        return "‚ùå S√©curit√©: Le code contient des motifs potentiellement dangereux et n'a pas √©t√© ex√©cut√©."

    loop = asyncio.get_running_loop()
    if language == "python":
        return await loop.run_in_executor(executor, _run_python_sync, code)
    elif language == "shell":
        return await loop.run_in_executor(executor, _run_shell_sync, code)
    else:
        return "‚ùå Langage non support√© pour la sandbox."

def _run_python_sync(code: str) -> str:
    """Ex√©cute du code Python de mani√®re synchrone et capture la sortie."""
    old_stdout = io.StringIO()
    old_stderr = io.StringIO()
    with contextlib.redirect_stdout(old_stdout), contextlib.redirect_stderr(old_stderr):
        try:
            exec(code, {'__builtins__': {}})
            output = old_stdout.getvalue()
            error = old_stderr.getvalue()
            if error:
                return f"üêç Erreur Python:\n{error}\nSortie:\n{output}"
            return f"‚úÖ Sortie Python:\n{output}"
        except Exception as e:
            return f"‚ùå Erreur d'ex√©cution Python: {e}\nSortie standard:\n{old_stdout.getvalue()}\nErreur standard:\n{old_stderr.getvalue()}"

def _run_shell_sync(command: str) -> str:
    """Ex√©cute une commande shell de mani√®re synchrone et capture la sortie."""
    try:
        result = subprocess.run(
            command,
            shell=True,
            capture_output=True,
            text=True,
            check=True,
            timeout=10
        )
        output = result.stdout
        error = result.stderr
        if error:
            return f"üêö Erreur Shell:\n{error}\nSortie:\n{output}"
        return f"‚úÖ Sortie Shell:\n{output}"
    except subprocess.CalledProcessError as e:
        return f"‚ùå Erreur d'ex√©cution Shell (Code: {e.returncode}):\n{e.stderr}\nSortie:\n{e.stdout}"
    except subprocess.TimeoutExpired:
        return "‚ùå Erreur Shell: La commande a d√©pass√© le temps d'ex√©cution imparti."
    except Exception as e:
        return f"‚ùå Erreur inattendue lors de l'ex√©cution Shell: {e}"

async def analyze_python_code(code: str) -> str:
    """Analyse le code Python avec Pyflakes et formate avec Black (simul√©)."""
    try:
        ast.parse(code)
    except SyntaxError as e:
        return f"‚ùå Erreur de syntaxe Python: {e}"

    formatted_code = code

    pyflakes_output = []
    if "import os" in code and "os.remove" in code:
        pyflakes_output.append("AVERTISSEMENT: Utilisation potentielle de os.remove d√©tect√©e.")

    if pyflakes_output:
        return f"Code format√© (Black):\n```python\n{formatted_code}\n```\n\nAnalyses Pyflakes (simul√©):\n" + "\n".join(pyflakes_output)
    return f"Code format√© (Black):\n```python\n{formatted_code}\n```\n\nAnalyse Pyflakes: Aucun probl√®me majeur d√©tect√© (simulation)."

async def perform_ocr(image_url: str, api_key: str, endpoint_url: str) -> str:
    """
    Effectue l'OCR sur une URL d'image en utilisant une API sp√©cifi√©e.
    """
    try:
        async with httpx.AsyncClient(timeout=10) as client:
            img_response = await client.get(image_url)
            img_response.raise_for_status()

        img_data = base64.b64encode(img_response.content).decode('utf-8')

        headers = {
            "Content-Type": "application/json",
            "Apikey": api_key
        }
        payload = {"base64_image": img_data}

        ocr_endpoint = endpoint_url

        async with httpx.AsyncClient(timeout=30) as client:
            response = await client.post(ocr_endpoint, json=payload, headers=headers)
            response.raise_for_status()
            result = response.json()

        if "TextExtracted" in result:
            return f"‚úÖ Texte extrait par OCR:\n{result['TextExtracted']}"
        elif "extractedText" in result:
            return f"‚úÖ Texte extrait par OCR:\n{result['extractedText']}"
        else:
            return f"‚ùå OCR: Format de r√©ponse API inconnu. R√©ponse brute: {result}"

    except httpx.HTTPStatusError as e:
        log_message(f"Erreur HTTP/r√©seau lors de l'OCR: {e.response.status_code} - {e.response.text}", level="error")
        return f"‚ùå Erreur lors de l'OCR (r√©seau/API): {e}"
    except httpx.RequestError as e:
        log_message(f"Erreur de requ√™te lors de l'OCR: {e}", level="error")
        return f"‚ùå Erreur lors de l'OCR (requ√™te): {e}"
    except json.JSONDecodeError:
        return "‚ùå OCR: R√©ponse non JSON de l'API."
    except Exception as e:
        log_message(f"Erreur inattendue lors de l'OCR: {e}", level="error")
        return f"‚ùå Erreur inattendue lors de l'OCR: {e}"

# Fin du module filters_and_tools.py


# D√©but du module api_clients_base.py

import time
import json
import httpx
import asyncio
from datetime import datetime, timedelta
from typing import Dict, Any, Optional, Union, List

from config import API_CONFIG, ENDPOINT_HEALTH_FILE, API_QUOTAS
from utils import load_json, save_json, get_current_time, format_datetime, log_message

class EndpointHealthManager:
    """G√®re la sant√© des endpoints API et s√©lectionne le meilleur."""
    _instance = None

    def __new__(cls, *args, **kwargs):
        if cls._instance is None:
            cls._instance = super(cls, cls).__new__(cls)
            cls._instance._initialized = False
        return cls._instance

    def __init__(self):
        if self._initialized:
            return
        self.health_status = {}

    async def init_manager(self):
        """Initialise le gestionnaire de sant√© de mani√®re asynchrone."""
        if not self._initialized:
            self.health_status = await load_json(ENDPOINT_HEALTH_FILE, {})
            self._initialize_health_status()
            self._initialized = True
            log_message("Gestionnaire de sant√© des endpoints initialis√©.")

    def _initialize_health_status(self):
        """Initialise le statut de sant√© pour tous les endpoints configur√©s."""
        updated = False
        for service_name, endpoints_config in API_CONFIG.items():
            if service_name not in self.health_status:
                self.health_status[service_name] = {}
                updated = True
            for endpoint_config in endpoints_config:
                endpoint_key = f"{endpoint_config['endpoint_name']}-{str(endpoint_config['key'])}"
                if endpoint_key not in self.health_status[service_name]:
                    self.health_status[service_name][endpoint_key] = {
                        "latency": 0.0,
                        "success_rate": 1.0,
                        "last_checked": None,
                        "error_count": 0,
                        "total_checks": 0,
                        "is_healthy": True
                    }
                    updated = True
        if updated:
            asyncio.create_task(save_json(ENDPOINT_HEALTH_FILE, self.health_status))
            log_message("Statut de sant√© des endpoints initialis√©/mis √† jour.")

    async def run_health_check_for_service(self, service_name: str):
        """Ex√©cute des checks de sant√© pour tous les endpoints d'un service donn√©."""
        endpoints_config = API_CONFIG.get(service_name)
        if not endpoints_config:
            return

        log_message(f"Lancement du health check pour le service: {service_name}")
        for endpoint_config in endpoints_config:
            endpoint_key = f"{endpoint_config['endpoint_name']}-{str(endpoint_config['key'])}"
            start_time = time.monotonic()
            success = False
            try:
                request_method = endpoint_config.get("method", "GET")
                url = endpoint_config["url"]
                
                params = endpoint_config.get("health_check_params", endpoint_config.get("fixed_params", {})).copy()
                json_data = endpoint_config.get("health_check_json", endpoint_config.get("fixed_json", {})).copy()
                headers = endpoint_config.get("fixed_headers", {}).copy()
                auth = None
                
                check_timeout = endpoint_config.get("timeout", 5)

                if "health_check_url_suffix" in endpoint_config:
                    url += endpoint_config["health_check_url_suffix"]

                key_field = endpoint_config.get("key_field")
                key_location = endpoint_config.get("key_location")
                key_prefix = endpoint_config.get("key_prefix", "")
                api_key = endpoint_config["key"]

                if key_field and key_location:
                    if key_location == "param":
                        params[key_field] = api_key
                    elif key_location == "header":
                        headers[key_field] = f"{key_prefix}{api_key}"
                    elif key_location == "auth_basic":
                        if isinstance(api_key, tuple) and len(api_key) == 2:
                            auth = httpx.BasicAuth(api_key[0], api_key[1])
                        else:
                            log_message(f"Cl√© API pour auth_basic non valide pour {service_name}:{endpoint_key}", level="error")
                            success = False
                            continue

                async with httpx.AsyncClient(timeout=check_timeout) as client:
                    response = await client.request(request_method, url, params=params, headers=headers, json=json_data, auth=auth)
                    response.raise_for_status()
                    success = True
            except httpx.HTTPStatusError as e:
                log_level = "warning"
                if e.response.status_code in [400, 401, 403, 404, 429]:
                    log_level = "debug"
                log_message(f"Health check pour {endpoint_key} ({service_name}) a √©chou√© (HTTP {e.response.status_code}): {e.response.text}", level=log_level)
                success = False
            except httpx.RequestError as e:
                log_message(f"Health check pour {endpoint_key} ({service_name}) a √©chou√© (Network): {e}", level="warning")
                success = False
            except Exception as e:
                log_message(f"Health check pour {endpoint_key} ({service_name}) a √©chou√© (Unexpected): {e}", level="error")
                success = False
            finally:
                latency = time.monotonic() - start_time
                self.update_endpoint_health(service_name, endpoint_key, success, latency)
        log_message(f"Health check termin√© pour le service: {service_name}")

    def update_endpoint_health(self, service_name: str, endpoint_key: str, success: bool, latency: float):
        """Met √† jour le statut de sant√© d'un endpoint."""
        if service_name not in self.health_status:
            self.health_status[service_name] = {}
        if endpoint_key not in self.health_status[service_name]:
            self.health_status[service_name][endpoint_key] = {
                "latency": 0.0,
                "success_rate": 1.0,
                "last_checked": None,
                "error_count": 0,
                "total_checks": 0,
                "is_healthy": True
            }

        status = self.health_status[service_name][endpoint_key]
        status["total_checks"] += 1
        status["last_checked"] = format_datetime(get_current_time())

        alpha = 0.1
        if success:
            status["error_count"] = max(0, status["error_count"] - 1)
            status["success_rate"] = status["success_rate"] * (1 - alpha) + 1.0 * alpha
            status["latency"] = status["latency"] * (1 - alpha) + latency * alpha
        else:
            status["error_count"] += 1
            status["success_rate"] = status["success_rate"] * (1 - alpha) + 0.0 * alpha
            status["latency"] = status["latency"] * (1 - alpha) + 10.0 * alpha

        if status["error_count"] >= 3 or status["success_rate"] < 0.5:
            status["is_healthy"] = False
        else:
            status["is_healthy"] = True
        
        asyncio.create_task(save_json(ENDPOINT_HEALTH_FILE, self.health_status))
        log_message(f"Sant√© de {service_name}:{endpoint_key} mise √† jour: Succ√®s: {success}, Latence: {latency:.2f}s, Taux Succ√®s: {status['success_rate']:.2f}, Sain: {status['is_healthy']}", level="debug" if not status["is_healthy"] else "info")

    def get_best_endpoint(self, service_name: str) -> Optional[Dict]:
        """S√©lectionne le meilleur endpoint pour un service bas√© sur la sant√©."""
        service_health = self.health_status.get(service_name)
        if not service_health:
            log_message(f"Aucune donn√©e de sant√© pour le service {service_name}. Retourne None.", level="warning")
            return None

        best_endpoint_key = None
        best_score = -float('inf')

        healthy_endpoints = [
            (key, status) for key, status in service_health.items() if status["is_healthy"]
        ]

        if not healthy_endpoints:
            log_message(f"Aucun endpoint sain pour le service {service_name}. Tentative de s√©lection d'un endpoint non sain.", level="warning")
            all_endpoints = service_health.items()
            if not all_endpoints: return None
            
            sorted_endpoints = sorted(all_endpoints, key=lambda item: (item[1]["error_count"], item[1]["latency"]))
            best_endpoint_key = sorted_endpoints[0][0]
            log_message(f"Fallback: Endpoint {best_endpoint_key} s√©lectionn√© pour {service_name} (non sain).", level="warning")
        else:
            for endpoint_key, status in healthy_endpoints:
                score = (status["success_rate"] * 100) - (status["latency"] * 10) - (status["error_count"] * 5)
                if score > best_score:
                    best_score = score
                    best_endpoint_key = endpoint_key
            log_message(f"Meilleur endpoint s√©lectionn√© pour {service_name}: {best_endpoint_key} (Score: {best_score:.2f})")

        if best_endpoint_key:
            for endpoint_config in API_CONFIG.get(service_name, []):
                current_endpoint_key = f"{endpoint_config['endpoint_name']}-{str(endpoint_config['key'])}"
                if current_endpoint_key == best_endpoint_key:
                    return endpoint_config
        return None

class APIClient:
    """Classe de base pour tous les clients API, g√©rant la s√©lection dynamique d'endpoints et les r√©essais."""
    def __init__(self, name: str, endpoint_health_manager: EndpointHealthManager):
        self.name = name
        self.endpoints_config = API_CONFIG.get(name, [])
        self.endpoint_health_manager = endpoint_health_manager
        if not self.endpoints_config:
            log_message(f"Client API {self.name} initialis√© sans configuration d'endpoint.", level="error")

    async def _make_request(self, params: Dict = None, headers: Dict = None, json_data: Dict = None, timeout: Optional[int] = None, max_retries: int = 3, initial_delay: float = 1.0, url: Optional[str] = None, method: Optional[str] = None, key_field: Optional[str] = None, key_location: Optional[str] = None, api_key: Optional[Union[str, tuple]] = None, fixed_params: Optional[Dict] = None, fixed_headers: Optional[Dict] = None, fixed_json: Optional[Dict] = None) -> Optional[Union[Dict, str, bytes]]:
        """M√©thode interne pour effectuer les requ√™tes HTTP en utilisant le meilleur endpoint avec r√©essais."""
        
        selected_endpoint_config = None
        endpoint_key_for_health = "Dynamic"

        if url and method:
            selected_endpoint_config = {
                "url": url,
                "method": method,
                "key_field": key_field,
                "key_location": key_location,
                "key": api_key,
                "fixed_params": fixed_params if fixed_params is not None else {},
                "fixed_headers": fixed_headers if fixed_headers is not None else {},
                "fixed_json": fixed_json if fixed_json is not None else {},
                "endpoint_name": "Dynamic",
                "timeout": timeout if timeout is not None else 30
            }
            if api_key:
                endpoint_key_for_health = f"Dynamic-{str(api_key)}"
            log_message(f"Requ√™te dynamique pour {self.name} vers {url}")
        else:
            selected_endpoint_config = self.endpoint_health_manager.get_best_endpoint(self.name)
            if not selected_endpoint_config:
                log_message(f"Aucun endpoint sain ou disponible pour {self.name}.", level="error")
                return {"error": True, "message": f"Aucun endpoint sain ou disponible pour {self.name}."}
            endpoint_key_for_health = f"{selected_endpoint_config['endpoint_name']}-{str(selected_endpoint_config['key'])}"
            log_message(f"Endpoint s√©lectionn√© pour {self.name}: {selected_endpoint_config['endpoint_name']}")
            timeout = timeout if timeout is not None else selected_endpoint_config.get("timeout", 30)

        url_to_use = selected_endpoint_config["url"]
        method_to_use = selected_endpoint_config["method"]

        request_params = selected_endpoint_config.get("fixed_params", {}).copy()
        request_headers = selected_endpoint_config.get("fixed_headers", {}).copy()
        request_json_data = selected_endpoint_config.get("fixed_json", {}).copy()
        auth = None

        if params:
            request_params.update(params)
        if headers:
            request_headers.update(headers)
        if json_data:
            request_json_data.update(json_data)

        key_field_to_use = selected_endpoint_config.get("key_field")
        key_location_to_use = selected_endpoint_config.get("key_location")
        key_prefix = selected_endpoint_config.get("key_prefix", "")
        api_key_to_use = selected_endpoint_config["key"]

        if key_field_to_use and key_location_to_use:
            if key_location_to_use == "param":
                request_params[key_field_to_use] = api_key_to_use
            elif key_location_to_use == "header":
                request_headers[key_field_to_use] = f"{key_prefix}{api_key_to_use}"
            elif key_location_to_use == "auth_basic":
                if isinstance(api_key_to_use, tuple) and len(api_key_to_use) == 2:
                    auth = httpx.BasicAuth(api_key_to_use[0], api_key_to_use[1])
                else:
                    log_message(f"Cl√© API pour auth_basic non valide pour {self.name}:{endpoint_key_for_health}", level="error")
                    self.endpoint_health_manager.update_endpoint_health(self.name, endpoint_key_for_health, False, 0.0)
                    return {"error": True, "message": "Configuration d'authentification basique invalide."}

        current_delay = initial_delay
        for attempt in range(max_retries):
            start_time = time.monotonic()
            success = False
            try:
                async with httpx.AsyncClient(timeout=timeout) as client:
                    response = await client.request(method_to_use, url_to_use, params=request_params, headers=request_headers, json=request_json_data, auth=auth)
                    response.raise_for_status()
                    success = True
                    
                    content_type = response.headers.get("Content-Type", "").lower()
                    if "application/json" in content_type:
                        try:
                            return response.json()
                        except json.JSONDecodeError:
                            log_message(f"API {self.name} r√©ponse non JSON valide (tentative {attempt+1}/{max_retries}): {response.text[:200]}...", level="warning")
                            if attempt < max_retries - 1:
                                await asyncio.sleep(current_delay)
                                current_delay *= 2
                                continue
                            return {"error": True, "message": "R√©ponse API non JSON valide.", "raw_response": response.text}
                    else:
                        log_message(f"API {self.name} a renvoy√© un Content-Type non JSON: {content_type}", level="info")
                        return response.content

            except httpx.HTTPStatusError as e:
                log_message(f"API {self.name} erreur HTTP (tentative {attempt+1}/{max_retries}): {e.response.status_code} - {e.response.text}", level="warning")
                if 400 <= e.response.status_code < 500 and e.response.status_code != 429:
                    log_message(f"API {self.name}: Erreur client {e.response.status_code}, pas de r√©essai.", level="error")
                    self.endpoint_health_manager.update_endpoint_health(self.name, endpoint_key_for_health, False, e.response.elapsed.total_seconds())
                    return {"error": True, "status_code": e.response.status_code, "message": e.response.text}
                
                if attempt < max_retries - 1:
                    log_message(f"API {self.name}: R√©essai dans {current_delay:.2f}s...", level="info")
                    await asyncio.sleep(current_delay)
                    current_delay *= 2
            except httpx.RequestError as e:
                log_message(f"API {self.name} erreur de requ√™te (tentative {attempt+1}/{max_retries}): {e}", level="warning")
                if attempt < max_retries - 1:
                    log_message(f"API {self.name}: R√©essai dans {current_delay:.2f}s...", level="info")
                    await asyncio.sleep(current_delay)
                    current_delay *= 2
            except Exception as e:
                log_message(f"API {self.name} erreur inattendue (tentative {attempt+1}/{max_retries}): {e}", level="error")
                self.endpoint_health_manager.update_endpoint_health(self.name, endpoint_key_for_health, False, time.monotonic() - start_time)
                return {"error": True, "message": str(e)}
            finally:
                if not success:
                    latency = time.monotonic() - start_time
                    self.endpoint_health_manager.update_endpoint_health(self.name, endpoint_key_for_health, False, latency)
        
        log_message(f"API {self.name}: Toutes les tentatives ont √©chou√© apr√®s {max_retries} r√©essais.", level="error")
        return {"error": True, "message": f"√âchec de la requ√™te apr√®s {max_retries} tentatives."}

    async def query(self, *args, **kwargs) -> Any:
        """M√©thode abstraite pour interroger l'API."""
        raise NotImplementedError("La m√©thode query doit √™tre impl√©ment√©e par les sous-classes.")

# Fin du module api_clients_base.py

# D√©but du module api_clients_part1.py

import json
import base64
import re
import time
from typing import Dict, Any, Optional, Union, List

from api_clients_base import APIClient, EndpointHealthManager
from utils import neutralize_urls, log_message
from config import API_CONFIG

_endpoint_health_manager: EndpointHealthManager = None 

def set_endpoint_health_manager(manager: EndpointHealthManager):
    """Permet d'injecter l'instance du gestionnaire de sant√© des endpoints."""
    global _endpoint_health_manager
    _endpoint_health_manager = manager

class DeepSeekClient(APIClient):
    def __init__(self):
        if _endpoint_health_manager is None:
            raise RuntimeError("EndpointHealthManager n'est pas initialis√© pour DeepSeekClient.")
        super().__init__("DEEPSEEK", _endpoint_health_manager)

    async def query(self, prompt: str, model: str = "deepseek-chat") -> str:
        payload = {"model": model, "messages": [{"role": "user", "content": prompt}]}
        response = await self._make_request(json_data=payload)
        if response and not response.get("error"):
            content = response.get("choices", [{}])[0].get("message", {}).get("content")
            if content:
                return content
            return "DeepSeek: Pas de contenu de r√©ponse trouv√©."
        return f"DeepSeek: Erreur: {response.get('message', 'Inconnu')}" if response else "DeepSeek: R√©ponse vide ou erreur interne."

class SerperClient(APIClient):
    def __init__(self):
        if _endpoint_health_manager is None:
            raise RuntimeError("EndpointHealthManager n'est pas initialis√© pour SerperClient.")
        super().__init__("SERPER", _endpoint_health_manager)

    async def query(self, query_text: str) -> str:
        payload = {"q": query_text}
        response = await self._make_request(json_data=payload)
        if response and not response.get("error"):
            organic_results = response.get("organic", [])
            if organic_results:
                snippet = organic_results[0].get("snippet", "Pas de snippet.")
                link = organic_results[0].get("link", "")
                return f"Serper (recherche web):\n{snippet} {neutralize_urls(link)}"
            return "Serper: Aucune information trouv√©e."
        return f"Serper: Erreur: {response.get('message', 'Inconnu')}" if response else "Serper: R√©ponse vide ou erreur interne."

class WolframAlphaClient(APIClient):
    def __init__(self):
        if _endpoint_health_manager is None:
            raise RuntimeError("EndpointHealthManager n'est pas initialis√© pour WolframAlphaClient.")
        super().__init__("WOLFRAMALPHA", _endpoint_health_manager)

    async def query(self, input_text: str) -> str:
        params = {"input": input_text}
        response = await self._make_request(params=params)
        if response and not response.get("error"):
            pods = response.get("queryresult", {}).get("pods", [])
            if pods:
                for pod in pods:
                    if pod.get("title") in ["Result", "Input interpretation", "Decimal approximation"]:
                        subpods = pod.get("subpods", [])
                        if subpods and subpods[0].get("plaintext"):
                            return f"WolframAlpha:\n{subpods[0]['plaintext']}"
                if pods and pods[0].get("subpods") and pods[0]["subpods"][0].get("plaintext"):
                    return f"WolframAlpha:\n{pods[0]['subpods'][0]['plaintext']}"
            return "WolframAlpha: Pas de r√©sultat clair."
        return f"WolframAlpha: Erreur: {response.get('message', 'Inconnu')}" if response else "WolframAlpha: R√©ponse vide ou erreur interne."

class TavilyClient(APIClient):
    def __init__(self):
        if _endpoint_health_manager is None:
            raise RuntimeError("EndpointHealthManager n'est pas initialis√© pour TavilyClient.")
        super().__init__("TAVILY", _endpoint_health_manager)

    async def query(self, query_text: str, max_results: int = 3) -> str:
        payload = {"query": query_text, "max_results": max_results}
        response = await self._make_request(json_data=payload)
        if response and not response.get("error"):
            results = response.get("results", [])
            answer = response.get("answer", "Aucune r√©ponse directe trouv√©e.")

            output = f"Tavily (recherche web):\nR√©ponse directe: {answer}\n"
            if results:
                output += "Extraits pertinents:\n"
                for i, res in enumerate(results[:max_results]):
                    output += f"- {res.get('title', 'N/A')}: {res.get('content', 'N/A')} {neutralize_urls(res.get('url', ''))}\n"
            return output
        return f"Tavily: Erreur: {response.get('message', 'Inconnu')}" if response else "Tavily: R√©ponse vide ou erreur interne."

class ApiFlashClient(APIClient):
    def __init__(self):
        if _endpoint_health_manager is None:
            raise RuntimeError("EndpointHealthManager n'est pas initialis√© pour ApiFlashClient.")
        super().__init__("APIFLASH", _endpoint_health_manager)

    async def query(self, url: str) -> str:
        params = {"url": url, "format": "jpeg", "full_page": "true"}
        response_content = await self._make_request(params=params)

        if isinstance(response_content, bytes):
            selected_endpoint_config = self.endpoint_health_manager.get_best_endpoint(self.name)
            if selected_endpoint_config:
                capture_url = f"{selected_endpoint_config['url']}?access_key={selected_endpoint_config['key']}&url={url}&format=jpeg&full_page=true"
                return f"ApiFlash (capture d'√©cran): {neutralize_urls(capture_url)} (V√©rifiez le lien pour l'image)"
            return "ApiFlash: Impossible de g√©n√©rer l'URL de capture."
        elif isinstance(response_content, dict) and response_content.get("error"):
            return f"ApiFlash: Erreur: {response_content.get('message', 'Inconnu')}"
        else:
            log_message(f"ApiFlash a renvoy√© un type de r√©ponse inattendu: {type(response_content)}", level="warning")
            return f"ApiFlash: R√©ponse inattendue de l'API. {response_content}"

class CrawlbaseClient(APIClient):
    def __init__(self):
        if _endpoint_health_manager is None:
            raise RuntimeError("EndpointHealthManager n'est pas initialis√© pour CrawlbaseClient.")
        super().__init__("CRAWLBASE", _endpoint_health_manager)

    async def query(self, url: str, use_js: bool = False) -> str:
        params = {"url": url, "format": "json"}
        
        selected_endpoint_config = None
        if use_js:
            for config in API_CONFIG.get(self.name, []):
                if "JS Scraping" in config.get("endpoint_name", ""):
                    selected_endpoint_config = config
                    break
        
        if not selected_endpoint_config:
            selected_endpoint_config = self.endpoint_health_manager.get_best_endpoint(self.name)

        if not selected_endpoint_config:
            return f"Crawlbase: Aucun endpoint sain ou disponible pour {self.name}."

        response = await self._make_request(
            params=params,
            url=selected_endpoint_config["url"],
            method=selected_endpoint_config["method"],
            key_field=selected_endpoint_config["key_field"],
            key_location=selected_endpoint_config["key_location"],
            api_key=selected_endpoint_config["key"],
            fixed_params=selected_endpoint_config.get("fixed_params", {}),
            timeout=selected_endpoint_config.get("timeout")
        )

        if response and not response.get("error"):
            body = response.get("body")
            if body:
                try:
                    decoded_body = base64.b64decode(body).decode('utf-8', errors='ignore')
                    return f"Crawlbase (contenu web):\n{decoded_body[:1000]}..."
                except Exception:
                    return f"Crawlbase (contenu web - brut):\n{body[:1000]}..."
            return "Crawlbase: Contenu non trouv√©."
        return f"Crawlbase: Erreur: {response.get('message', 'Inconnu')}" if response else "Crawlbase: R√©ponse vide ou erreur interne."

class DetectLanguageClient(APIClient):
    def __init__(self):
        if _endpoint_health_manager is None:
            raise RuntimeError("EndpointHealthManager n'est pas initialis√© pour DetectLanguageClient.")
        super().__init__("DETECTLANGUAGE", _endpoint_health_manager)

    async def query(self, text: str) -> str:
        payload = {"q": text}
        response = await self._make_request(json_data=payload)
        if response and not response.get("error"):
            detections = response.get("data", {}).get("detections", [])
            if detections:
                first_detection = detections[0]
                lang = first_detection.get("language")
                confidence = first_detection.get("confidence")
                return f"Langue d√©tect√©e: {lang} (confiance: {confidence})"
            return "DetectLanguage: Aucune langue d√©tect√©e."
        return f"DetectLanguage: Erreur: {response.get('message', 'Inconnu')}" if response else "DetectLanguage: R√©ponse vide ou erreur interne."

class GuardianClient(APIClient):
    def __init__(self):
        if _endpoint_health_manager is None:
            raise RuntimeError("EndpointHealthManager n'est pas initialis√© pour GuardianClient.")
        super().__init__("GUARDIAN", _endpoint_health_manager)

    async def query(self, query_text: str) -> str:
        params = {"q": query_text}
        response = await self._make_request(params=params)
        if response and not response.get("error"):
            results = response.get("response", {}).get("results", [])
            if results:
                output = "Articles The Guardian:\n"
                for res in results[:3]:
                    output += f"- {res.get('webTitle', 'N/A')}: {res.get('fields', {}).get('trailText', 'N/A')} {neutralize_urls(res.get('webUrl', ''))}\n"
                return output
            return "Guardian: Aucun article trouv√©."
        return f"Guardian: Erreur: {response.get('message', 'Inconnu')}" if response else "Guardian: R√©ponse vide ou erreur interne."

class IP2LocationClient(APIClient):
    def __init__(self):
        if _endpoint_health_manager is None:
            raise RuntimeError("EndpointHealthManager n'est pas initialis√© pour IP2LocationClient.")
        super().__init__("IP2LOCATION", _endpoint_health_manager)

    async def query(self, ip_address: str) -> str:
        params = {"ip": ip_address}
        response = await self._make_request(params=params)
        if response and not response.get("error"):
            if "country_name" in response:
                return f"IP2Location (G√©olocalisation IP {ip_address}): Pays: {response['country_name']}, Ville: {response.get('city_name', 'N/A')}"
            return "IP2Location: Informations non trouv√©es."
        return f"IP2Location: Erreur: {response.get('message', 'Inconnu')}" if response else "IP2Location: R√©ponse vide ou erreur interne."

class ShodanClient(APIClient):
    def __init__(self):
        if _endpoint_health_manager is None:
            raise RuntimeError("EndpointHealthManager n'est pas initialis√© pour ShodanClient.")
        super().__init__("SHODAN", _endpoint_health_manager)

    async def query(self, query_text: str = "") -> str:
        if query_text:
            if re.match(r"^\d{1,3}\.\d{1,3}\.\d{1,3}\.\d{1,3}$", query_text):
                selected_endpoint_config = None
                for config in API_CONFIG.get(self.name, []):
                    if "Host Info" in config.get("endpoint_name", ""):
                        selected_endpoint_config = config
                        break
                if selected_endpoint_config:
                    url = f"https://api.shodan.io/shodan/host/{query_text}"
                    response = await self._make_request(
                        params={"key": selected_endpoint_config["key"]},
                        url=url,
                        method="GET",
                        key_field=selected_endpoint_config["key_field"],
                        key_location=selected_endpoint_config["key_location"],
                        api_key=selected_endpoint_config["key"],
                        timeout=selected_endpoint_config.get("timeout")
                    )
                    if response and not response.get("error"):
                        return f"Shodan (info h√¥te {query_text}): Pays: {response.get('country_name', 'N/A')}, Ports: {response.get('ports', 'N/A')}, Vuln√©rabilit√©s: {response.get('vulns', 'Aucune')}"
                    return f"Shodan (info h√¥te): Erreur: {response.get('message', 'Inconnu')}" if response else "Shodan: R√©ponse vide ou erreur interne."
            else:
                return "Shodan: Veuillez fournir une adresse IP valide pour la recherche d'h√¥te."

        response = await self._make_request()
        if response and not response.get("error"):
            return f"Shodan (info cl√©): Requ√™tes restantes: {response.get('usage_limits', {}).get('query_credits', 'N/A')}, Scan cr√©dits: {response.get('usage_limits', {}).get('scan_credits', 'N/A')}"
        return f"Shodan: Erreur: {response.get('message', 'Inconnu')}" if response else "Shodan: R√©ponse vide ou erreur interne."

class WeatherAPIClient(APIClient):
    def __init__(self):
        if _endpoint_health_manager is None:
            raise RuntimeError("EndpointHealthManager n'est pas initialis√© pour WeatherAPIClient.")
        super().__init__("WEATHERAPI", _endpoint_health_manager)

    async def query(self, location: str) -> str:
        params = {"q": location}
        response = await self._make_request(params=params)
        if response and not response.get("error"):
            current = response.get("current", {})
            location_info = response.get("location", {})
            if current and location_info:
                return (
                    f"M√©t√©o √† {location_info.get('name', 'N/A')}, {location_info.get('country', 'N/A')}:\n"
                    f"Temp√©rature: {current.get('temp_c', 'N/A')}¬∞C, "
                    f"Conditions: {current.get('condition', {}).get('text', 'N/A')}, "
                    f"Vent: {current.get('wind_kph', 'N/A')} km/h"
                )
            return "WeatherAPI: Donn√©es m√©t√©o non trouv√©es."
        return f"WeatherAPI: Erreur: {response.get('message', 'Inconnu')}" if response else "WeatherAPI: R√©ponse vide ou erreur interne."

# Fin du module api_clients_part1.py


# D√©but du module api_clients_part2.py

import json
import re
import time
from datetime import datetime, timedelta
from typing import Dict, Any, Optional, Union, List

from api_clients_base import APIClient, EndpointHealthManager
from utils import neutralize_urls, log_message
from config import API_CONFIG

_endpoint_health_manager: EndpointHealthManager = None 

def set_endpoint_health_manager(manager: EndpointHealthManager):
    """Permet d'injecter l'instance du gestionnaire de sant√© des endpoints."""
    global _endpoint_health_manager
    _endpoint_health_manager = manager

class CloudmersiveClient(APIClient):
    def __init__(self):
        if _endpoint_health_manager is None:
            raise RuntimeError("EndpointHealthManager n'est pas initialis√© pour CloudmersiveClient.")
        super().__init__("CLOUDMERSIVE", _endpoint_health_manager)

    async def query(self, domain: str) -> str:
        payload = {"domain": domain}
        response = await self._make_request(json_data=payload)
        if response and not response.get("error"):
            return f"Cloudmersive (v√©rification de domaine {domain}): Valide: {response.get('ValidDomain', 'N/A')}, Type: {response.get('DomainType', 'N/A')}"
        return f"Cloudmersive: Erreur: {response.get('message', 'Inconnu')}" if response else "Cloudmersive: R√©ponse vide ou erreur interne."

class GreyNoiseClient(APIClient):
    def __init__(self):
        if _endpoint_health_manager is None:
            raise RuntimeError("EndpointHealthManager n'est pas initialis√© pour GreyNoiseClient.")
        super().__init__("GREYNOISE", _endpoint_health_manager)

    async def query(self, ip_address: str) -> str:
        selected_endpoint_config = self.endpoint_health_manager.get_best_endpoint(self.name)
        if not selected_endpoint_config:
            return f"GreyNoise: Aucun endpoint sain ou disponible pour {self.name}."

        url = f"{selected_endpoint_config['url']}{ip_address}"
        method = selected_endpoint_config["method"]
        headers = {selected_endpoint_config["key_field"]: selected_endpoint_config["key"]}

        response = await self._make_request(
            headers=headers,
            url=url,
            method=method,
            key_field=selected_endpoint_config["key_field"],
            key_location=selected_endpoint_config["key_location"],
            api_key=selected_endpoint_config["key"],
            timeout=selected_endpoint_config.get("timeout")
        )

        if response and not response.get("error"):
            if response.get("noise"):
                return f"GreyNoise (IP {ip_address}): C'est une IP 'bruit' (malveillante). Classification: {response.get('classification', 'N/A')}, Nom d'acteur: {response.get('actor', 'N/A')}"
            return f"GreyNoise (IP {ip_address}): Pas de 'bruit' d√©tect√©. Statut: {response.get('status', 'N/A')}"
        return f"GreyNoise: Erreur: {response.get('message', 'Inconnu')}" if response else "GreyNoise: R√©ponse vide ou erreur interne."

class PulsediveClient(APIClient):
    def __init__(self):
        if _endpoint_health_manager is None:
            raise RuntimeError("EndpointHealthManager n'est pas initialis√© pour PulsediveClient.")
        super().__init__("PULSEDIVE", _endpoint_health_manager)

    async def query(self, indicator: str, type: str = "auto") -> str:
        params = {"indicator": indicator, "type": type}
        response = await self._make_request(params=params)
        if response and not response.get("error"):
            if response.get("results"):
                result = response["results"][0]
                return (
                    f"Pulsedive (Analyse {indicator}): Type: {result.get('type', 'N/A')}, "
                    f"Risk: {result.get('risk', 'N/A')}, "
                    f"Description: {result.get('description', 'N/A')[:200]}..."
                )
            return "Pulsedive: Aucun r√©sultat d'analyse trouv√©."
        return f"Pulsedive: Erreur: {response.get('message', 'Inconnu')}" if response else "Pulsedive: R√©ponse vide ou erreur interne."

class StormGlassClient(APIClient):
    def __init__(self):
        if _endpoint_health_manager is None:
            raise RuntimeError("EndpointHealthManager n'est pas initialis√© pour StormGlassClient.")
        super().__init__("STORMGLASS", _endpoint_health_manager)

    async def query(self, lat: float, lng: float, params: str = "airTemperature,waveHeight") -> str:
        now = int(time.time())
        request_params = {
            "lat": lat,
            "lng": lng,
            "params": params,
            "start": now,
            "end": now + 3600
        }
        response = await self._make_request(params=request_params)
        if response and not response.get("error"):
            data = response.get("hours", [])
            if data:
                first_hour = data[0]
                temp = first_hour.get('airTemperature', [{}])[0].get('value', 'N/A')
                wave_height = first_hour.get('waveHeight', [{}])[0].get('value', 'N/A')
                return f"StormGlass (M√©t√©o maritime √† {lat},{lng}): Temp√©rature air: {temp}¬∞C, Hauteur vagues: {wave_height}m"
            return "StormGlass: Donn√©es non trouv√©es."
        return f"StormGlass: Erreur: {response.get('message', 'Inconnu')}" if response else "StormGlass: R√©ponse vide ou erreur interne."

class LoginRadiusClient(APIClient):
    def __init__(self):
        if _endpoint_health_manager is None:
            raise RuntimeError("EndpointHealthManager n'est pas initialis√© pour LoginRadiusClient.")
        super().__init__("LOGINRADIUS", _endpoint_health_manager)

    async def query(self) -> str:
        response = await self._make_request()
        if response and not response.get("error"):
            return f"LoginRadius (Ping API): Statut: {response.get('Status', 'N/A')}, Message: {response.get('Message', 'N/A')}"
        return f"LoginRadius: Erreur: {response.get('message', 'Inconnu')}" if response else "LoginRadius: R√©ponse vide ou erreur interne."

class JsonbinClient(APIClient):
    def __init__(self):
        if _endpoint_health_manager is None:
            raise RuntimeError("EndpointHealthManager n'est pas initialis√© pour JsonbinClient.")
        super().__init__("JSONBIN", _endpoint_health_manager)

    async def query(self, data: Dict[str, Any], private: bool = True, bin_id: Optional[str] = None) -> str:
        if bin_id:
            selected_endpoint_config = None
            for config in API_CONFIG.get(self.name, []):
                if "Bin Access" in config.get("endpoint_name", ""):
                    selected_endpoint_config = config
                    break
            if not selected_endpoint_config:
                return f"Jsonbin: Aucun endpoint d'acc√®s de bin sain ou disponible pour {self.name}."

            url = f"{selected_endpoint_config['url']}/{bin_id}"
            method = "GET"
            headers = {selected_endpoint_config["key_field"]: selected_endpoint_config["key"]}
            
            response = await self._make_request(
                headers=headers,
                url=url,
                method=method,
                timeout=selected_endpoint_config.get("timeout")
            )
            if response and not response.get("error"):
                return f"Jsonbin (Acc√®s bin {bin_id}):\n{json.dumps(response, indent=2)}"
            return f"Jsonbin (Acc√®s bin): Erreur: {response.get('message', 'Inconnu')}" if response else "Jsonbin: R√©ponse vide ou erreur interne."
        
        else:
            selected_endpoint_config = None
            for config in API_CONFIG.get(self.name, []):
                if "Bin Create" in config.get("endpoint_name", ""):
                    selected_endpoint_config = config
                    break
            
            if not selected_endpoint_config:
                return f"Jsonbin: Aucun endpoint de cr√©ation de bin sain ou disponible pour {self.name}."

            url = selected_endpoint_config["url"]
            method = "POST"
            headers = {selected_endpoint_config["key_field"]: selected_endpoint_config["key"], "Content-Type": "application/json"}
            payload = {"record": data, "private": private}

            response = await self._make_request(
                json_data=payload,
                headers=headers,
                url=url,
                method=method,
                timeout=selected_endpoint_config.get("timeout")
            )

            if response and not response.get("error"):
                return f"Jsonbin (Cr√©ation de bin): ID: {response.get('metadata', {}).get('id', 'N/A')}, URL: {neutralize_urls(response.get('metadata', {}).get('url', 'N/A'))}"
            return f"Jsonbin (Cr√©ation de bin): Erreur: {response.get('message', 'Inconnu')}" if response else "Jsonbin: R√©ponse vide ou erreur interne."

# Fin du module api_clients_part2.py

# D√©but du module api_clients_part3.py

import json
import re
from datetime import datetime
from typing import Dict, Any, Optional, Union, List

from api_clients_base import APIClient, EndpointHealthManager
from utils import neutralize_urls, log_message
from config import API_CONFIG

_endpoint_health_manager: EndpointHealthManager = None 

def set_endpoint_health_manager(manager: EndpointHealthManager):
    """Permet d'injecter l'instance du gestionnaire de sant√© des endpoints."""
    global _endpoint_health_manager
    _endpoint_health_manager = manager

class HuggingFaceClient(APIClient):
    def __init__(self):
        if _endpoint_health_manager is None:
            raise RuntimeError("EndpointHealthManager n'est pas initialis√© pour HuggingFaceClient.")
        super().__init__("HUGGINGFACE", _endpoint_health_manager)

    async def query(self, model_name: str = "distilbert-base-uncased-finetuned-sst-2-english", input_text: str = "Hello world") -> str:
        selected_endpoint_config = self.endpoint_health_manager.get_best_endpoint(self.name)
        if not selected_endpoint_config:
            return f"HuggingFace: Aucun endpoint sain ou disponible pour {self.name}."

        inference_url = f"https://api-inference.huggingface.co/models/{model_name}"
        
        headers = {
            selected_endpoint_config["key_field"]: f"{selected_endpoint_config['key_prefix']}{selected_endpoint_config['key']}",
            "Content-Type": "application/json"
        }
        payload = {"inputs": input_text}

        response = await self._make_request(
            json_data=payload,
            headers=headers,
            url=inference_url,
            method="POST",
            timeout=selected_endpoint_config.get("timeout")
        )

        if response and not response.get("error"):
            if isinstance(response, list) and response:
                first_result = response[0]
                if isinstance(first_result, list) and first_result:
                    return f"HuggingFace ({model_name} - {first_result[0].get('label')}): Score {first_result[0].get('score', 'N/A'):.2f}"
                elif isinstance(first_result, dict) and "generated_text" in first_result:
                    return f"HuggingFace ({model_name}): {first_result.get('generated_text')}"
            return f"HuggingFace ({model_name}): R√©ponse non pars√©e. {response}"
        return f"HuggingFace: Erreur: {response.get('message', 'Inconnu')}" if response else "HuggingFace: R√©ponse vide ou erreur interne."

class TwilioClient(APIClient):
    def __init__(self):
        if _endpoint_health_manager is None:
            raise RuntimeError("EndpointHealthManager n'est pas initialis√© pour TwilioClient.")
        super().__init__("TWILIO", _endpoint_health_manager)

    async def query(self) -> str:
        selected_endpoint_config = None
        for config in API_CONFIG.get(self.name, []):
            if "Account Balance" in config.get("endpoint_name", ""):
                selected_endpoint_config = config
                break
        if not selected_endpoint_config:
            if self.endpoints_config:
                selected_endpoint_config = self.endpoints_config[0]
            else:
                return f"Twilio: Aucune configuration d'endpoint disponible pour {self.name}."

        response = await self._make_request(
            url=selected_endpoint_config["url"],
            method=selected_endpoint_config["method"],
            key_location=selected_endpoint_config["key_location"],
            api_key=selected_endpoint_config["key"],
            timeout=selected_endpoint_config.get("timeout")
        )
        if response and not response.get("error"):
            return f"Twilio (Balance): {response.get('balance', 'N/A')} {response.get('currency', 'N/A')}"
        return f"Twilio: Erreur: {response.get('message', 'Inconnu')}" if response else "Twilio: R√©ponse vide ou erreur interne."

class AbstractAPIClient(APIClient):
    def __init__(self):
        if _endpoint_health_manager is None:
            raise RuntimeError("EndpointHealthManager n'est pas initialis√© pour AbstractAPIClient.")
        super().__init__("ABSTRACTAPI", _endpoint_health_manager)

    async def query(self, input_value: str, api_type: str) -> str:
        params = {}
        target_endpoint_name = ""

        if api_type == "PHONE_VALIDATION":
            params["phone"] = input_value
            target_endpoint_name = "Phone Validation"
        elif api_type == "EMAIL_VALIDATION":
            params["email"] = input_value
            target_endpoint_name = "Email Validation"
        elif api_type == "EXCHANGE_RATES":
            target_endpoint_name = "Exchange Rates"
        elif api_type == "HOLIDAYS":
            params["country"] = input_value if input_value else "US"
            params["year"] = datetime.now().year
            target_endpoint_name = "Holidays"
        else:
            return f"AbstractAPI: Type d'API '{api_type}' non support√© pour la requ√™te."

        selected_endpoint_config = None
        for config in API_CONFIG.get(self.name, []):
            if target_endpoint_name in config["endpoint_name"]:
                selected_endpoint_config = config
                break
        
        if not selected_endpoint_config:
            return f"AbstractAPI: Aucun endpoint sain ou disponible pour {self.name} pour le type {api_type}."

        response = await self._make_request(
            params=params,
            url=selected_endpoint_config["url"],
            method=selected_endpoint_config["method"],
            key_field=selected_endpoint_config["key_field"],
            key_location=selected_endpoint_config["key_location"],
            api_key=selected_endpoint_config["key"],
            fixed_params=selected_endpoint_config.get("fixed_params", {}),
            timeout=selected_endpoint_config.get("timeout")
        )

        if response and not response.get("error"):
            if api_type == "PHONE_VALIDATION":
                return (
                    f"AbstractAPI (Validation T√©l): Num√©ro: {response.get('phone', 'N/A')}, "
                    f"Valide: {response.get('valid', 'N/A')}, "
                    f"Pays: {response.get('country', {}).get('name', 'N/A')}"
                )
            elif api_type == "EMAIL_VALIDATION":
                return (
                    f"AbstractAPI (Validation Email): Email: {response.get('email', 'N/A')}, "
                    f"Valide: {response.get('is_valid_format', 'N/A')}, "
                    f"Deliverable: {response.get('is_deliverable', 'N/A')}"
                )
            elif api_type == "EXCHANGE_RATES":
                return f"AbstractAPI (Taux de change): Base: {response.get('base', 'N/A')}, Taux (USD): {response.get('exchange_rates', {}).get('USD', 'N/A')}"
            elif api_type == "HOLIDAYS":
                holidays = [h.get('name', 'N/A') for h in response if h.get('name')]
                return f"AbstractAPI (Jours f√©ri√©s {params.get('country', 'US')} {params.get('year')}): {', '.join(holidays[:5])}..." if holidays else "Aucun jour f√©ri√© trouv√©."
            return f"AbstractAPI ({api_type}): R√©ponse brute: {response}"
        return f"AbstractAPI ({api_type}): Erreur: {response.get('message', 'Inconnu')}" if response else "AbstractAPI: R√©ponse vide ou erreur interne."

# Fin du module api_clients_part3.py

# D√©but du module api_clients_part4.py

import json
from typing import Dict, Any, Optional, Union, List

from api_clients_base import APIClient, EndpointHealthManager
from utils import neutralize_urls, log_message
from config import API_CONFIG

_endpoint_health_manager: EndpointHealthManager = None 

def set_endpoint_health_manager(manager: EndpointHealthManager):
    """Permet d'injecter l'instance du gestionnaire de sant√© des endpoints."""
    global _endpoint_health_manager
    _endpoint_health_manager = manager

class GeminiAPIClient(APIClient):
    def __init__(self):
        if _endpoint_health_manager is None:
            raise RuntimeError("EndpointHealthManager n'est pas initialis√© pour GeminiAPIClient.")
        super().__init__("GEMINI_API", _endpoint_health_manager)

    async def query(self, prompt: str, model: str = "gemini-1.5-flash") -> str:
        payload = {"contents": [{"parts": [{"text": prompt}]}]}
        selected_endpoint_config = self.endpoint_health_manager.get_best_endpoint(self.name)
        if not selected_endpoint_config:
            return f"Gemini API: Aucun endpoint sain ou disponible pour {self.name}."

        generate_url = f"https://generativelanguage.googleapis.com/v1beta/models/{model}:generateContent"
        
        request_params = {selected_endpoint_config["key_field"]: selected_endpoint_config["key"]}

        response = await self._make_request(
            json_data=payload,
            params=request_params,
            url=generate_url,
            method="POST",
            timeout=selected_endpoint_config.get("timeout")
        )

        if response and not response.get("error"):
            if response.get("candidates") and response["candidates"][0].get("content"):
                return response["candidates"][0]["content"]["parts"][0]["text"]
            return f"Gemini API: Pas de r√©ponse g√©n√©r√©e. {response}"
        return f"Gemini API: Erreur: {response.get('message', 'Inconnu')}" if response else "Gemini API: R√©ponse vide ou erreur interne."

class GoogleCustomSearchClient(APIClient):
    def __init__(self):
        if _endpoint_health_manager is None:
            raise RuntimeError("EndpointHealthManager n'est pas initialis√© pour GoogleCustomSearchClient.")
        super().__init__("GOOGLE_CUSTOM_SEARCH", _endpoint_health_manager)

    async def query(self, query_text: str) -> str:
        params = {"q": query_text}
        response = await self._make_request(params=params)
        if response and not response.get("error"):
            items = response.get("items", [])
            if items:
                output = "Google Custom Search:\n"
                for item in items[:3]:
                    output += f"- {item.get('title', 'N/A')}: {item.get('snippet', 'N/A')} {neutralize_urls(item.get('link', ''))}\n"
                return output
            return "Google Custom Search: Aucun r√©sultat trouv√©."
        return f"Google Custom Search: Erreur: {response.get('message', 'Inconnu')}" if response else "Google Custom Search: R√©ponse vide ou erreur interne."

class RandommerClient(APIClient):
    def __init__(self):
        if _endpoint_health_manager is None:
            raise RuntimeError("EndpointHealthManager n'est pas initialis√© pour RandommerClient.")
        super().__init__("RANDOMMER", _endpoint_health_manager)

    async def query(self, country_code: str = "US", quantity: int = 1) -> str:
        params = {"CountryCode": country_code, "Quantity": quantity}
        response = await self._make_request(params=params)
        if response and not response.get("error"):
            if isinstance(response, list) and response:
                return f"Randommer (Num√©ros de t√©l√©phone): {', '.join(response)}"
            return f"Randommer: {response}"
        return f"Randommer: Erreur: {response.get('message', 'Inconnu')}" if response else "Randommer: R√©ponse vide ou erreur interne."

class TomorrowIOClient(APIClient):
    def __init__(self):
        if _endpoint_health_manager is None:
            raise RuntimeError("EndpointHealthManager n'est pas initialis√© pour TomorrowIOClient.")
        super().__init__("TOMORROW.IO", _endpoint_health_manager)

    async def query(self, location: str, fields: List[str] = None) -> str:
        if fields is None:
            fields = ["temperature", "humidity", "windSpeed"]
        payload = {"location": location, "fields": fields, "units": "metric", "timesteps": ["1h"]}
        response = await self._make_request(json_data=payload)
        if response and not response.get("error"):
            data = response.get("data", {}).get("timelines", [{}])[0].get("intervals", [{}])[0].get("values", {})
            if data:
                output = f"M√©t√©o (Tomorrow.io) √† {location}:\n"
                for field in fields:
                    output += f"- {field.capitalize()}: {data.get(field, 'N/A')}\n"
                return output
            return "Tomorrow.io: Donn√©es m√©t√©o non trouv√©es."
        return f"Tomorrow.io: Erreur: {response.get('message', 'Inconnu')}" if response else "Tomorrow.io: R√©ponse vide ou erreur interne."

class OpenWeatherMapClient(APIClient):
    def __init__(self):
        if _endpoint_health_manager is None:
            raise RuntimeError("EndpointHealthManager n'est pas initialis√© pour OpenWeatherMapClient.")
        super().__init__("OPENWEATHERMAP", _endpoint_health_manager)

    async def query(self, location: str) -> str:
        params = {"q": location}
        response = await self._make_request(params=params)
        if response and not response.get("error"):
            main_data = response.get("main", {})
            weather_desc = response.get("weather", [{}])[0].get("description", "N/A")
            if main_data:
                temp_kelvin = main_data.get('temp', 'N/A')
                feels_like_kelvin = main_data.get('feels_like', 'N/A')
                
                temp_celsius = f"{temp_kelvin - 273.15:.2f}" if isinstance(temp_kelvin, (int, float)) else "N/A"
                feels_like_celsius = f"{feels_like_kelvin - 273.15:.2f}" if isinstance(feels_like_kelvin, (int, float)) else "N/A"

                return (
                    f"M√©t√©o (OpenWeatherMap) √† {location}:\n"
                    f"Temp√©rature: {temp_celsius}¬∞C, "
                    f"Ressenti: {feels_like_celsius}¬∞C, "
                    f"Humidit√©: {main_data.get('humidity', 'N/A')}%, "
                    f"Conditions: {weather_desc}"
                )
            return "OpenWeatherMap: Donn√©es m√©t√©o non trouv√©es."
        return f"OpenWeatherMap: Erreur: {response.get('message', 'Inconnu')}" if response else "OpenWeatherMap: R√©ponse vide ou erreur interne."

# Fin du module api_clients_part4.py

# D√©but du module api_clients_part5.py

import json
from typing import Dict, Any, Optional, Union, List

from api_clients_base import APIClient, EndpointHealthManager
from utils import neutralize_urls, log_message
from config import API_CONFIG

_endpoint_health_manager: EndpointHealthManager = None 

def set_endpoint_health_manager(manager: EndpointHealthManager):
    """Permet d'injecter l'instance du gestionnaire de sant√© des endpoints."""
    global _endpoint_health_manager
    _endpoint_health_manager = manager

class MockarooClient(APIClient):
    def __init__(self):
        if _endpoint_health_manager is None:
            raise RuntimeError("EndpointHealthManager n'est pas initialis√© pour MockarooClient.")
        super().__init__("MOCKAROO", _endpoint_health_manager)

    async def query(self, count: int = 1, fields_json: str = None) -> str:
        params = {"count": count}
        if fields_json:
            params["fields"] = fields_json

        response = await self._make_request(params=params)
        if response and not response.get("error"):
            return f"Mockaroo (G√©n√©ration de donn√©es):\n{json.dumps(response, indent=2)}"
        return f"Mockaroo: Erreur: {response.get('message', 'Inconnu')}" if response else "Mockaroo: R√©ponse vide ou erreur interne."

class OpenPageRankClient(APIClient):
    def __init__(self):
        if _endpoint_health_manager is None:
            raise RuntimeError("EndpointHealthManager n'est pas initialis√© pour OpenPageRankClient.")
        super().__init__("OPENPAGERANK", _endpoint_health_manager)

    async def query(self, domains: List[str]) -> str:
        params = {"domains[]": domains}
        response = await self._make_request(params=params)
        if response and not response.get("error"):
            results = response.get("response", [])
            if results:
                output = "OpenPageRank (Classement de domaine):\n"
                for res in results:
                    output += f"- Domaine: {res.get('domain', 'N/A')}, PageRank: {res.get('page_rank', 'N/A')}\n"
                return output
            return "OpenPageRank: Aucun r√©sultat trouv√©."
        return f"OpenPageRank: Erreur: {response.get('message', 'Inconnu')}" if response else "OpenPageRank: R√©ponse vide ou erreur interne."

class RapidAPIClient(APIClient):
    def __init__(self):
        if _endpoint_health_manager is None:
            raise RuntimeError("EndpointHealthManager n'est pas initialis√© pour RapidAPIClient.")
        super().__init__("RAPIDAPI", _endpoint_health_manager)

    async def query(self, api_name: str, **kwargs) -> str:
        selected_endpoint_config = None
        for config in API_CONFIG.get(self.name, []):
            if api_name.lower() in config["endpoint_name"].lower():
                selected_endpoint_config = config
                break
        
        if not selected_endpoint_config:
            return f"RapidAPI: Endpoint pour '{api_name}' non trouv√© ou non configur√©."

        url = selected_endpoint_config["url"]
        method = selected_endpoint_config["method"]
        
        request_params = selected_endpoint_config.get("fixed_params", {}).copy()
        request_headers = selected_endpoint_config.get("fixed_headers", {}).copy()
        request_json_data = selected_endpoint_config.get("fixed_json", {}).copy()

        if method == "GET":
            request_params.update(kwargs)
        elif method == "POST":
            request_json_data.update(kwargs)

        headers = {
            selected_endpoint_config["key_field"]: selected_endpoint_config["key"],
            "X-RapidAPI-Host": selected_endpoint_config["fixed_headers"].get("X-RapidAPI-Host")
        }
        
        response = await self._make_request(
            params=request_params,
            headers=headers,
            json_data=request_json_data,
            url=url,
            method=method,
            timeout=selected_endpoint_config.get("timeout")
        )

        if response and not response.get("error"):
            if api_name.lower() == "programming joke":
                return f"RapidAPI (Blague de Programmation): {response.get('setup', '')} - {response.get('punchline', '')}"
            elif api_name.lower() == "currency list quotes":
                return f"RapidAPI (Devises): {json.dumps(response, indent=2)}"
            elif api_name.lower() == "random fact":
                return f"RapidAPI (Fait Al√©atoire): {response.get('text', 'N/A')}"
            return f"RapidAPI ({api_name}): {json.dumps(response, indent=2)}"
        return f"RapidAPI ({api_name}): Erreur: {response.get('message', 'Inconnu')}" if response else "RapidAPI: R√©ponse vide ou erreur interne."

# Fin du module api_clients_part5.py

# D√©but du module memory_and_quotas.py

import asyncio
import time
import json
from datetime import datetime, timedelta
from typing import Dict, Any, Optional, Union, List

from config import (
    HISTORY_FILE, LONG_MEMORY_FILE, IA_STATUS_FILE, QUOTAS_FILE,
    API_QUOTAS, API_COOLDOWN_DURATION_SECONDS, API_ROTATION_INTERVAL_MINUTES, QUOTA_BURN_WINDOW_HOURS,
    API_CONFIG
)
from utils import load_json, save_json, get_current_time, format_datetime, is_within_time_window, log_message

from api_clients_base import APIClient, EndpointHealthManager
from api_clients_part1 import (
    DeepSeekClient, SerperClient, WolframAlphaClient, TavilyClient,
    ApiFlashClient, CrawlbaseClient, DetectLanguageClient, GuardianClient,
    IP2LocationClient, ShodanClient, WeatherAPIClient, set_endpoint_health_manager as set_eh_manager_part1
)
from api_clients_part2 import (
    CloudmersiveClient, GreyNoiseClient, PulsediveClient, StormGlassClient,
    LoginRadiusClient, JsonbinClient, set_endpoint_health_manager as set_eh_manager_part2
)
from api_clients_part3 import (
    HuggingFaceClient, TwilioClient, AbstractAPIClient, set_endpoint_health_manager as set_eh_manager_part3
)
from api_clients_part4 import (
    GeminiAPIClient, GoogleCustomSearchClient, RandommerClient, TomorrowIOClient,
    OpenWeatherMapClient, set_endpoint_health_manager as set_eh_manager_part4
)
from api_clients_part5 import (
    MockarooClient, OpenPageRankClient, RapidAPIClient, set_endpoint_health_manager as set_eh_manager_part5
)


class MemoryManager:
    def __init__(self):
        self.chat_history = []
        self.long_term_memory = {}
        self.ia_status = {}
        self._initialized = False

    async def init_manager(self):
        """Initialise le gestionnaire de m√©moire de mani√®re asynchrone."""
        if not self._initialized:
            self.chat_history = await load_json(HISTORY_FILE, [])
            self.long_term_memory = await load_json(LONG_MEMORY_FILE, {})
            self.ia_status = await load_json(IA_STATUS_FILE, {})
            self._initialize_ia_status()
            self._initialized = True
            log_message("Gestionnaire de m√©moire initialis√©.")

    def _initialize_ia_status(self):
        """Initialise le statut des IA si elles ne sont pas d√©j√† pr√©sentes ou si leur statut est obsol√®te."""
        updated = False
        now = get_current_time()
        
        for client_name in API_QUOTAS.keys():
            if client_name not in self.ia_status:
                self.ia_status[client_name] = {
                    "last_used": None,
                    "last_error": None,
                    "error_count": 0,
                    "cooldown_until": None,
                    "success_count": 0,
                    "current_score": 1.0,
                    "last_rotation_check": format_datetime(now),
                    "diversification_score": 1.0
                }
                updated = True
            else:
                default_ia_status_keys = {
                    "last_used": None, "last_error": None, "error_count": 0,
                    "cooldown_until": None, "success_count": 0, "current_score": 1.0,
                    "last_rotation_check": format_datetime(now), "diversification_score": 1.0
                }
                for key, default_value in default_ia_status_keys.items():
                    if key not in self.ia_status[client_name]:
                        self.ia_status[client_name][key] = default_value
                        updated = True
                
                last_check_str = self.ia_status[client_name].get("last_rotation_check")
                if last_check_str:
                    last_check_dt = datetime.strptime(last_check_str, "%Y-%m-%d %H:%M:%S UTC")
                    if (now - last_check_dt).total_seconds() > API_ROTATION_INTERVAL_MINUTES * 60 * 2:
                        self.ia_status[client_name]["last_rotation_check"] = format_datetime(now)
                        updated = True

        current_api_names = set(API_QUOTAS.keys())
        ia_names_to_remove = [name for name in self.ia_status if name not in current_api_names]
        for name in ia_names_to_remove:
            del self.ia_status[name]
            updated = True
            log_message(f"IA '{name}' trouv√©e dans ia_status.json mais non d√©finie dans API_QUOTAS. Supprim√©e.", level="warning")

        if updated:
            asyncio.create_task(save_json(IA_STATUS_FILE, self.ia_status))
            log_message("Statut des IA initialis√©/mis √† jour.")

    def add_message_to_history(self, role, content):
        """Ajoute un message √† l'historique de la conversation."""
        self.chat_history.append({"role": role, "content": content, "timestamp": format_datetime(get_current_time())})
        self._prune_history()
        asyncio.create_task(save_json(HISTORY_FILE, self.chat_history))
        log_message(f"Message ajout√© √† l'historique par {role}.")

    def get_chat_history(self, limit=10):
        """Retourne les N derniers messages de l'historique."""
        return self.chat_history[-limit:]

    def add_to_long_term_memory(self, key, value):
        """Ajoute une information √† la m√©moire √† long terme."""
        self.long_term_memory[key] = {"value": value, "timestamp": format_datetime(get_current_time())}
        asyncio.create_task(save_json(LONG_MEMORY_FILE, self.long_term_memory))
        log_message(f"Information ajout√©e √† la m√©moire √† long terme: {key}")

    def get_from_long_term_memory(self, key):
        """R√©cup√®re une information de la m√©moire √† long terme."""
        return self.long_term_memory.get(key)

    def update_ia_status(self, ia_name: str, success: bool, error_message: Optional[str] = None):
        """Met √† jour le statut et le score d'une IA apr√®s une utilisation."""
        status = self.ia_status.get(ia_name)
        if not status:
            log_message(f"Tentative de mise √† jour d'un statut d'IA inconnu: {ia_name}", level="warning")
            return

        now = get_current_time()
        status["last_used"] = format_datetime(now)

        if success:
            status["success_count"] += 1
            status["error_count"] = 0
            status["cooldown_until"] = None
            status["last_error"] = None
            status["current_score"] = min(1.0, status["current_score"] + 0.1)
            status["diversification_score"] = max(0.1, status["diversification_score"] - 0.1)
            log_message(f"IA {ia_name} : Succ√®s enregistr√©. Nouveau score: {status['current_score']:.2f}, Diversification: {status['diversification_score']:.2f}")
        else:
            status["error_count"] += 1
            status["last_error"] = error_message
            if status["error_count"] >= 3:
                status["cooldown_until"] = format_datetime(now + timedelta(seconds=API_COOLDOWN_DURATION_SECONDS))
                status["current_score"] = max(0.1, status["current_score"] - 0.2)
                log_message(f"IA {ia_name} : Trop d'erreurs ({status['error_count']}). Cooldown jusqu'√† {status['cooldown_until']}. Nouveau score: {status['current_score']:.2f}", level="warning")
            else:
                 status["current_score"] = max(0.1, status["current_score"] - 0.05)
                 log_message(f"IA {ia_name} : Erreur enregistr√©e. Nouveau score: {status['current_score']:.2f}", level="warning")

        asyncio.create_task(save_json(IA_STATUS_FILE, self.ia_status))

    def recover_diversification_scores(self):
        """Augmente le score de diversification pour les IA non utilis√©es r√©cemment."""
        now = get_current_time()
        updated = False
        for ia_name, status in self.ia_status.items():
            last_used_str = status.get("last_used")
            if last_used_str:
                last_used_dt = datetime.strptime(last_used_str, "%Y-%m-%d %H:%M:%S UTC")
                if (now - last_used_dt).total_seconds() > API_ROTATION_INTERVAL_MINUTES * 60 * 2:
                    if status["diversification_score"] < 1.0:
                        status["diversification_score"] = min(1.0, status["diversification_score"] + 0.05)
                        updated = True
                        log_message(f"IA {ia_name}: Score de diversification r√©cup√©r√© √† {status['diversification_score']:.2f}")
            else:
                if status["diversification_score"] < 1.0:
                    status["diversification_score"] = 1.0
                    updated = True
        if updated:
            asyncio.create_task(save_json(IA_STATUS_FILE, self.ia_status))

    def get_ia_status(self, ia_name: str) -> Optional[Dict]:
        """R√©cup√®re le statut d'une IA."""
        return self.ia_status.get(ia_name)

    def get_available_ias(self) -> List[str]:
        """Retourne les noms des IA actuellement non en cooldown."""
        available = []
        now = get_current_time()
        for name, status in self.ia_status.items():
            cooldown_until_str = status.get("cooldown_until")
            if cooldown_until_str:
                cooldown_until = datetime.strptime(cooldown_until_str, "%Y-%m-%d %H:%M:%S UTC")
                if now < cooldown_until:
                    continue
            available.append(name)
        return available

    def _prune_history(self, max_entries=50):
        """Supprime les anciennes entr√©es de l'historique si trop nombreuses."""
        if len(self.chat_history) > max_entries:
            self.chat_history = self.chat_history[-max_entries:]
            log_message(f"Historique de chat purg√©, {len(self.chat_history)} entr√©es restantes.")

class QuotaManager:
    def __init__(self):
        self.quotas = {}
        self._initialized = False

    async def init_manager(self):
        """Initialise le gestionnaire de quotas de mani√®re asynchrone."""
        if not self._initialized:
            self.quotas = await load_json(QUOTAS_FILE, {})
            self._initialize_quotas()
            self._initialized = True
            log_message("Gestionnaire de quotas initialis√©.")

    def _initialize_quotas(self):
        """Initialise les quotas pour toutes les APIs bas√©es sur config.API_QUOTAS et nettoie/met √† jour les existants."""
        updated = False
        now = get_current_time()

        for api_name, quota_info in API_QUOTAS.items():
            if api_name not in self.quotas:
                self.quotas[api_name] = {
                    "monthly_usage": 0,
                    "daily_usage": 0,
                    "hourly_usage": 0,
                    "hourly_timestamps": [],
                    "last_reset_month": now.month,
                    "last_reset_day": now.day,
                    "last_usage": None,
                    "total_calls": 0,
                    "last_hourly_reset": format_datetime(now)
                }
                updated = True
            else:
                default_quota_structure = {
                    "monthly_usage": 0, "daily_usage": 0, "hourly_usage": 0,
                    "hourly_timestamps": [], "last_reset_month": now.month,
                    "last_reset_day": now.day, "last_usage": None,
                    "total_calls": 0, "last_hourly_reset": format_datetime(now)
                }
                for key, default_value in default_quota_structure.items():
                    if key not in self.quotas[api_name]:
                        self.quotas[api_name][key] = default_value
                        updated = True
                
                if not isinstance(self.quotas[api_name].get("hourly_timestamps"), list):
                    self.quotas[api_name]["hourly_timestamps"] = []
                    updated = True

                one_hour_ago = now - timedelta(hours=1)
                self.quotas[api_name]["hourly_timestamps"] = [
                    ts for ts in self.quotas[api_name]["hourly_timestamps"]
                    if datetime.strptime(ts, "%Y-%m-%d %H:%M:%S UTC") > one_hour_ago
                ]
                self.quotas[api_name]["hourly_usage"] = len(self.quotas[api_name]["hourly_timestamps"])
                self.quotas[api_name]["last_hourly_reset"] = format_datetime(now)

        api_names_to_remove = [name for name in self.quotas if name not in API_QUOTAS]
        for name in api_names_to_remove:
            del self.quotas[name]
            updated = True
            log_message(f"API '{name}' trouv√©e dans quotas.json mais non d√©finie dans API_QUOTAS. Supprim√©e.", level="warning")

        if updated:
            asyncio.create_task(save_json(QUOTAS_FILE, self.quotas))
            log_message("Quotas API initialis√©s/mis √† jour.")

    def _reset_quotas_if_needed(self):
        """R√©initialise les quotas journaliers, mensuels et horaires si n√©cessaire."""
        now = get_current_time()
        for api_name, data in self.quotas.items():
            if now.month != data["last_reset_month"]:
                data["monthly_usage"] = 0
                data["last_reset_month"] = now.month
                log_message(f"Quota mensuel pour {api_name} r√©initialis√©.")
            if now.day != data["last_reset_day"]:
                data["daily_usage"] = 0
                data["last_reset_day"] = now.day
                log_message(f"Quota journalier pour {api_name} r√©initialis√©.")
            
            one_hour_ago = now - timedelta(hours=1)
            if not isinstance(data.get("hourly_timestamps"), list):
                data["hourly_timestamps"] = []
            
            data["hourly_timestamps"] = [
                ts for ts in data["hourly_timestamps"]
                if datetime.strptime(ts, "%Y-%m-%d %H:%M:%S UTC") > one_hour_ago
            ]
            data["hourly_usage"] = len(data["hourly_timestamps"])
            data["last_hourly_reset"] = format_datetime(now)

        asyncio.create_task(save_json(QUOTAS_FILE, self.quotas))

    def check_and_update_quota(self, api_name: str, cost: int = 1) -> bool:
        """V√©rifie si une API a du quota et le d√©cr√©mente. Retourne True si ok, False sinon."""
        self._reset_quotas_if_needed()
        
        if api_name not in API_QUOTAS:
            log_message(f"Tentative de v√©rification de quota pour une API non d√©finie: {api_name}. Autorisation refus√©e.", level="error")
            return False

        if api_name not in self.quotas:
            log_message(f"API {api_name} non trouv√©e dans les quotas g√©r√©s. Re-initialisation non bloquante.", level="warning")
            return False

        quota_data = self.quotas[api_name]
        api_limits = API_QUOTAS.get(api_name, {})
        now = get_current_time()

        monthly_limit = api_limits.get("monthly")
        if monthly_limit is not None and (quota_data["monthly_usage"] + cost) > monthly_limit:
            log_message(f"Quota mensuel d√©pass√© pour {api_name}", level="warning")
            return False

        daily_limit = api_limits.get("daily")
        if daily_limit is not None and (quota_data["daily_usage"] + cost) > daily_limit:
            log_message(f"Quota journalier d√©pass√© pour {api_name}", level="warning")
            return False
        
        hourly_limit = api_limits.get("hourly")
        if hourly_limit is not None and (quota_data["hourly_usage"] + cost) > hourly_limit:
            log_message(f"Quota horaire d√©pass√© pour {api_name}", level="warning")
            return False

        rate_limit_per_sec = api_limits.get("rate_limit_per_sec")
        if rate_limit_per_sec:
            last_usage_str = quota_data.get("last_usage")
            if last_usage_str:
                last_usage = datetime.strptime(last_usage_str, "%Y-%m-%d %H:%M:%S UTC")
                time_since_last_call = (now - last_usage).total_seconds()
                if time_since_last_call < (1 / rate_limit_per_sec):
                    log_message(f"Taux de requ√™tes d√©pass√© pour {api_name}. Attendre {1/rate_limit_per_sec - time_since_last_call:.2f}s", level="warning")
                    return False

        if cost > 0:
            quota_data["monthly_usage"] += cost
            quota_data["daily_usage"] += cost
            quota_data["hourly_usage"] += cost
            quota_data["hourly_timestamps"].append(format_datetime(now))
            quota_data["total_calls"] += cost
            quota_data["last_usage"] = format_datetime(now)
            asyncio.create_task(save_json(QUOTAS_FILE, self.quotas))
            log_message(f"Quota pour {api_name} mis √† jour. Usage mensuel: {quota_data['monthly_usage']}/{monthly_limit if monthly_limit else 'Illimit√©'}, Journalier: {quota_data['daily_usage']}/{daily_limit if daily_limit else 'Illimit√©'}, Horaire: {quota_data['hourly_usage']}/{hourly_limit if hourly_limit else 'Illimit√©'}")
        else:
            log_message(f"Quota pour {api_name} v√©rifi√© (co√ªt 0). Usage mensuel: {quota_data['monthly_usage']}/{monthly_limit if monthly_limit else 'Illimit√©'}, Journalier: {quota_data['daily_usage']}/{daily_limit if daily_limit else 'Illimit√©'}, Horaire: {quota_data['hourly_usage']}/{hourly_limit if hourly_limit else 'Illimit√©'}")

        return True

    def get_api_usage(self, api_name: str) -> Optional[Dict]:
        """Retourne les informations d'utilisation d'une API."""
        return self.quotas.get(api_name)

    def get_all_quotas_status(self) -> Dict:
        """Retourne le statut de tous les quotas."""
        self._reset_quotas_if_needed()
        status = {}
        for api_name, quota_data in self.quotas.items():
            api_limits = API_QUOTAS.get(api_name, {})
            monthly_limit = api_limits.get("monthly", "Illimit√©")
            daily_limit = api_limits.get("daily", "Illimit√©")
            hourly_limit = api_limits.get("hourly", "Illimit√©")
            status[api_name] = {
                "monthly_usage": quota_data["monthly_usage"],
                "monthly_limit": monthly_limit,
                "daily_usage": quota_data["daily_usage"],
                "daily_limit": daily_limit,
                "hourly_usage": quota_data["hourly_usage"],
                "hourly_limit": hourly_limit,
                "total_calls": quota_data["total_calls"],
                "last_usage": quota_data["last_usage"],
                "last_reset_month": quota_data["last_reset_month"],
                "last_reset_day": quota_data["last_reset_day"],
                "last_hourly_reset": quota_data["last_hourly_reset"]
            }
        return status

    def get_burn_window_apis(self) -> List[str]:
        """
        Identifie les APIs dont les quotas sont sur le point d'√™tre r√©initialis√©s
        et o√π il est opportun de "br√ªler" le quota restant.
        """
        burn_apis = []
        now = get_current_time()
        for api_name, data in self.quotas.items():
            api_limits = API_QUOTAS.get(api_name, {})

            if api_limits.get("monthly") is not None:
                next_month_reset = datetime(now.year + (1 if now.month == 12 else 0), (now.month % 12) + 1, 1)
                if is_within_time_window(next_month_reset, QUOTA_BURN_WINDOW_HOURS * 60, 0):
                    if data["monthly_usage"] < api_limits["monthly"]:
                        burn_apis.append(f"{api_name} (mensuel: {api_limits['monthly'] - data['monthly_usage']} restants)")

            if api_limits.get("daily") is not None:
                next_day_reset = datetime(now.year, now.month, now.day) + timedelta(days=1)
                if is_within_time_window(next_day_reset, QUOTA_BURN_WINDOW_HOURS * 60, 0):
                    if data["daily_usage"] < api_limits["daily"]:
                        burn_apis.append(f"{api_name} (journalier: {api_limits['daily'] - data['daily_usage']} restants)")
        return burn_apis


# Instancier le gestionnaire de sant√© des endpoints (sera initialis√© dans main.py)
endpoint_health_manager = EndpointHealthManager()

# Injecter le gestionnaire de sant√© dans les modules clients API
set_eh_manager_part1(endpoint_health_manager)
set_eh_manager_part2(endpoint_health_manager)
set_eh_manager_part3(endpoint_health_manager)
set_eh_manager_part4(endpoint_health_manager)
set_eh_manager_part5(endpoint_health_manager)

# Instancier tous les clients API en leur passant le gestionnaire de sant√©
ALL_API_CLIENTS = [
    DeepSeekClient(), SerperClient(), WolframAlphaClient(), TavilyClient(),
    ApiFlashClient(), CrawlbaseClient(), DetectLanguageClient(), GuardianClient(),
    IP2LocationClient(), ShodanClient(), WeatherAPIClient(),
    CloudmersiveClient(), GreyNoiseClient(), PulsediveClient(), StormGlassClient(),
    LoginRadiusClient(), JsonbinClient(),
    HuggingFaceClient(), TwilioClient(), AbstractAPIClient(),
    GeminiAPIClient(), GoogleCustomSearchClient(), RandommerClient(), TomorrowIOClient(),
    OpenWeatherMapClient(),
    MockarooClient(), OpenPageRankClient(), RapidAPIClient()
]

# Instanciation des gestionnaires de m√©moire et de quotas (seront initialis√©s dans main.py)
memory_manager = MemoryManager()
quota_manager = QuotaManager()

# Fin du module memory_and_quotas.py

# D√©but du module orchestrator.py

import random
import json
import re
import time
from datetime import datetime, timedelta
from typing import Dict, Any, Optional, Union, List

# Ces imports seront r√©solus car tout le code sera dans un seul fichier
from config import API_ROTATION_INTERVAL_MINUTES, SYNTHESIS_PROMPT_TEMPLATE, API_CONFIG
from utils import log_message, detect_and_correct_toxicity
from memory_and_quotas import MemoryManager, QuotaManager, ALL_API_CLIENTS, endpoint_health_manager
from api_clients_base import APIClient

class IAOrchestrator:
    def __init__(self, memory_manager: MemoryManager, quota_manager: QuotaManager, api_clients: List[APIClient]):
        self.memory_manager = memory_manager
        self.quota_manager = quota_manager
        self.api_clients = {client.name: client for client in api_clients}
        self.last_strategy_rotation_time = datetime.utcnow()
        self.current_ia_strategy = self._determine_initial_strategy()

        self.core_ai_engines = {
            "DEEPSEEK": self.api_clients.get("DEEPSEEK"),
            "HUGGINGFACE": self.api_clients.get("HUGGINGFACE"),
            "GOOGLE_CUSTOM_SEARCH": self.api_clients.get("GOOGLE_CUSTOM_SEARCH"),
            "GEMINI_API": self.api_clients.get("GEMINI_API")
        }
        self.core_ai_engines = {k: v for k, v in self.core_ai_engines.items() if v is not None}

        self.mixed_agents = [
            {"name": "GeneralQueryAgent", "primary_ais": ["DEEPSEEK", "GEMINI_API", "GOOGLE_CUSTOM_SEARCH"], "tools": ["SERPER", "TAVILY", "WOLFRAMALPHA", "WEATHERAPI", "OPENWEATHERMAP"]},
            {"name": "CodingAgent", "primary_ais": ["DEEPSEEK", "HUGGINGFACE", "GEMINI_API"], "tools": []},
            {"name": "SecurityAgent", "primary_ais": ["DEEPSEEK", "GEMINI_API"], "tools": ["IP2LOCATION", "SHODAN", "GREYNOISE", "PULSEDIVE", "CLOUDMERSIVE"]},
            {"name": "DataAgent", "primary_ais": ["DEEPSEEK", "GEMINI_API"], "tools": ["JSONBIN", "MOCKAROO", "RANDOMMER", "OPENPAGERANK", "RAPIDAPI"]},
            {"name": "CommunicationAgent", "primary_ais": ["DEEPSEEK", "GEMINI_API"], "tools": ["TWILIO", "ABSTRACTAPI"]},
            {"name": "NewsAgent", "primary_ais": ["DEEPSEEK", "GEMINI_API"], "tools": ["GUARDIAN", "SERPER", "TAVILY"]},
            {"name": "ImageAgent", "primary_ais": ["DEEPSEEK", "GEMINI_API"], "tools": ["APIFLASH"]},
            {"name": "LanguageAgent", "primary_ais": ["DEEPSEEK", "GEMINI_API"], "tools": ["DETECTLANGUAGE"]},
            {"name": "WeatherAgent", "primary_ais": ["DEEPSEEK", "GEMINI_API"], "tools": ["WEATHERAPI", "STORMGLASS", "TOMORROW.IO", "OPENWEATHERMAP"]}
        ]
        self.current_agent_index = 0
        self.last_agent_rotation_time = datetime.utcnow()

        self.tool_descriptions = {
            "SERPER": "Effectue une recherche web sur Google et retourne les snippets et liens pertinents. Param√®tres: {\"query\": \"texte de recherche\"}",
            "TAVILY": "Effectue une recherche web avanc√©e et retourne une r√©ponse directe et des extraits. Param√®tres: {\"query\": \"texte de recherche\", \"max_results\": nombre}",
            "WOLFRAMALPHA": "R√©pond √† des questions factuelles et calculs complexes. Param√®tres: {\"input\": \"question ou calcul\"}",
            "WEATHERAPI": "Fournit la m√©t√©o actuelle et les pr√©visions pour une localisation donn√©e. Param√®tres: {\"location\": \"nom de la ville ou code postal\"}",
            "OPENWEATHERMAP": "Fournit la m√©t√©o actuelle pour une localisation donn√©e. Param√®tres: {\"location\": \"nom de la ville ou code postal\"}",
            "STORMGLASS": "Fournit des donn√©es m√©t√©orologiques maritimes (temp√©rature, vagues) pour des coordonn√©es lat/lng. Param√®tres: {\"lat\": latitude, \"lng\": longitude, \"params\": \"airTemperature,waveHeight\"}",
            "APIFLASH": "Prend une capture d'√©cran d'une URL et retourne l'URL de l'image. Param√®tres: {\"url\": \"URL du site\"}",
            "CRAWLBASE": "R√©cup√®re le contenu HTML ou JavaScript d'une URL. Param√®tres: {\"url\": \"URL du site\", \"use_js\": true/false}",
            "DETECTLANGUAGE": "D√©tecte la langue d'un texte. Param√®tres: {\"text\": \"texte √† analyser\"}",
            "IP2LOCATION": "G√©olocalise une adresse IP. Param√®tres: {\"ip_address\": \"adresse IP\"}",
            "SHODAN": "Fournit des informations sur les h√¥tes et les services expos√©s sur Internet. Param√®tres: {\"query\": \"texte de recherche\"} (optionnel)",
            "GREYNOISE": "Analyse une adresse IP pour d√©terminer si elle est 'bruit' (malveillante). Param√®tres: {\"ip_address\": \"adresse IP\"}",
            "PULSEDIVE": "Analyse des indicateurs de menace (IP, domaine, URL). Param√®tres: {\"indicator\": \"indicateur\", \"type\": \"auto\"}",
            "CLOUDMERSIVE": "V√©rifie la validit√© d'un nom de domaine. Param√®tres: {\"domain\": \"nom de domaine\"}",
            "JSONBIN": "Stocke ou r√©cup√®re des donn√©es JSON dans un 'bin' priv√© ou public. Pour cr√©er: {\"data\": {\"cl√©\": \"valeur\"}, \"private\": true/false}. Pour acc√©der: {\"bin_id\": \"ID du bin\"}",
            "MOCKAROO": "G√©n√®re des donn√©es de test al√©atoires bas√©es sur des sch√©mas. Param√®tres: {\"count\": nombre, \"fields_json\": \"[{\"name\": \"champ\", \"type\": \"Type Mockaroo\"}]\"}",
            "RANDOMMER": "G√©n√®re des donn√©es al√©atoires, comme des num√©ros de t√©l√©phone. Param√®tres: {\"country_code\": \"US\", \"quantity\": 1}",
            "OPENPAGERANK": "R√©cup√®re le PageRank d'un ou plusieurs domaines. Param√®tres: {\"domains\": [\"domaine1.com\", \"domaine2.com\"]}",
            "RAPIDAPI": "Acc√®de √† diverses micro-APIs (blagues, faits, devises). N√©cessite un 'api_name' (ex: 'Programming Joke'). Param√®tres: {\"api_name\": \"Nom de l'API\", \"kwargs\": {\"param1\": \"valeur1\"}}",
            "TWILIO": "V√©rifie le solde du compte Twilio. Param√®tres: Aucun",
            "ABSTRACTAPI": "Valide des emails, num√©ros de t√©l√©phone, g√©olocalise des IPs, ou fournit des taux de change/jours f√©ri√©s. Param√®tres: {\"input_value\": \"valeur\", \"api_type\": \"EMAIL_VALIDATION\"|\"PHONE_VALIDATION\"|\"EXCHANGE_RATES\"|\"HOLIDAYS\"}",
            "TOMORROW.IO": "Fournit des donn√©es m√©t√©orologiques pour une localisation. Param√®tres: {\"location\": \"nom de la ville\", \"fields\": [\"temperature\", \"humidity\"]}"
        }

    def _determine_initial_strategy(self) -> str:
        """D√©termine la strat√©gie initiale ou la strat√©gie par d√©faut."""
        return "balanced"

    def _rotate_strategy_if_needed(self):
        """Change la strat√©gie d'IA et l'agent si l'intervalle de rotation est pass√©."""
        now = datetime.utcnow()
        if (now - self.last_strategy_rotation_time).total_seconds() >= API_ROTATION_INTERVAL_MINUTES * 60:
            strategies = ["balanced", "cost_effective", "performance"]
            self.current_ia_strategy = random.choice(strategies)
            self.last_strategy_rotation_time = now
            log_message(f"Strat√©gie d'IA chang√©e pour: {self.current_ia_strategy}")

            self.current_agent_index = (self.current_agent_index + 1) % len(self.mixed_agents)
            self.last_agent_rotation_time = now
            log_message(f"Agent mixte actuel: {self.mixed_agents[self.current_agent_index]['name']}")

            for ia_name in self.memory_manager.ia_status:
                self.memory_manager.ia_status[ia_name]["last_rotation_check"] = datetime.utcnow().strftime("%Y-%m-%d %H:%M:%S UTC")
            self.memory_manager.recover_diversification_scores()
            # Utilisation de save_json directement sur l'instance de memory_manager
            asyncio.create_task(self.memory_manager.save_json(self.memory_manager.IA_STATUS_FILE, self.memory_manager.ia_status))

    async def _select_primary_ai_for_agent(self, agent_config: Dict) -> Optional[APIClient]:
        """
        S√©lectionne une IA primaire parmi celles de l'agent.
        La s√©lection est d√©sormais √©quitable, sans privil√©gier une IA par rapport √† une autre en fonction des scores.
        """
        available_primary_ais = []
        for ai_name in agent_config["primary_ais"]:
            if ai_name in self.core_ai_engines:
                status = self.memory_manager.get_ia_status(ai_name)
                if status and (status.get("cooldown_until") is None or datetime.strptime(status["cooldown_until"], "%Y-%m-%d %H:%M:%S UTC") < datetime.utcnow()):
                    # Utilisation de check_and_update_quota directement sur l'instance de quota_manager
                    if self.quota_manager.check_and_update_quota(ai_name, cost=0):
                        available_primary_ais.append(ai_name)
        
        if not available_primary_ais:
            log_message(f"Aucune IA primaire disponible pour l'agent {agent_config['name']}.", level="warning")
            return None

        selected_ai_name = random.choice(available_primary_ais)
        
        # Utilisation de check_and_update_quota directement sur l'instance de quota_manager
        if self.quota_manager.check_and_update_quota(selected_ai_name, cost=1):
            log_message(f"IA primaire s√©lectionn√©e pour l'agent: {selected_ai_name} (S√©lection √©quitable)")
            return self.core_ai_engines[selected_ai_name]
        
        log_message(f"IA {selected_ai_name} s√©lectionn√©e mais quota non disponible au moment de la consommation.", level="warning")
        return None

    async def _run_agent_with_tools(self, agent_config: Dict, query: str) -> (str, List[Dict], Optional[str]):
        """
        Ex√©cute l'agent mixte en utilisant l'IA primaire s√©lectionn√©e
        et en sollicitant les outils pertinents.
        Retourne la r√©ponse brute de l'agent, une liste des outils appel√©s pour le rapport, et le nom de l'IA primaire utilis√©e.
        """
        primary_ai_client = await self._select_primary_ai_for_agent(agent_config)
        if not primary_ai_client:
            return f"D√©sol√©, l'agent {agent_config['name']} ne peut pas op√©rer car aucune IA primaire n'est disponible.", [], "N/A"

        primary_ai_name_used = primary_ai_client.name
        responses = []
        tools_called_for_report = []
        
        available_tools_for_ai = {}
        for tool_name in agent_config.get("tools", []):
            if tool_name in self.tool_descriptions and self.api_clients.get(tool_name):
                available_tools_for_ai[tool_name] = self.tool_descriptions[tool_name]
        
        tool_prompt_part = ""
        if available_tools_for_ai:
            tool_prompt_part = "\n\nTu as acc√®s aux outils suivants:\n"
            for tool_name, desc in available_tools_for_ai.items():
                tool_prompt_part += f"- **{tool_name}**: {desc}\n"
            tool_prompt_part += "\nSi tu as besoin d'utiliser un outil, r√©ponds avec le format suivant: `TOOL_CALL:<nom_outil>:<param√®tres_json>`. Par exemple: `TOOL_CALL:WEATHERAPI:{\"location\": \"Paris\"}`. Sinon, r√©ponds normalement."
        
        full_prompt_for_ai = f"{query}{tool_prompt_part}"

        log_message(f"Agent {agent_config['name']} utilise {primary_ai_name_used} pour la requ√™te: '{query}'")
        primary_response_raw = await primary_ai_client.query(full_prompt_for_ai)
        self.memory_manager.update_ia_status(primary_ai_name_used, not primary_response_raw.startswith("Erreur"))
        
        tool_call_match = re.match(r"TOOL_CALL:([A-Z_]+):(.+)", primary_response_raw)
        if tool_call_match:
            tool_name = tool_call_match.group(1)
            params_str = tool_call_match.group(2)
            
            try:
                tool_params = json.loads(params_str)
                tool_client = self.api_clients.get(tool_name)
                
                # Utilisation de check_and_update_quota directement sur l'instance de quota_manager
                if tool_client and self.quota_manager.check_and_update_quota(tool_name):
                    log_message(f"Agent {agent_config['name']} ex√©cute l'outil {tool_name} avec les param√®tres: {tool_params}")
                    
                    tool_response = ""
                    if tool_name == "SERPER":
                        tool_response = await tool_client.query(query_text=tool_params.get("query"))
                    elif tool_name == "TAVILY":
                        tool_response = await tool_client.query(query_text=tool_params.get("query"), max_results=tool_params.get("max_results", 3))
                    elif tool_name == "WOLFRAMALPHA":
                        tool_response = await tool_client.query(input_text=tool_params.get("input"))
                    elif tool_name == "WEATHERAPI":
                        tool_response = await tool_client.query(location=tool_params.get("location"))
                    elif tool_name == "OPENWEATHERMAP":
                        tool_response = await tool_client.query(location=tool_params.get("location"))
                    elif tool_name == "STORMGLASS":
                        tool_response = await tool_client.query(lat=tool_params.get("lat"), lng=tool_params.get("lng"), params=tool_params.get("params", "airTemperature,waveHeight"))
                    elif tool_name == "APIFLASH":
                        tool_response = await tool_client.query(url=tool_params.get("url"))
                    elif tool_name == "CRAWLBASE":
                        tool_response = await tool_client.query(url=tool_params.get("url"), use_js=tool_params.get("use_js", False))
                    elif tool_name == "DETECTLANGUAGE":
                        tool_response = await tool_client.query(text=tool_params.get("text"))
                    elif tool_name == "IP2LOCATION":
                        tool_response = await tool_client.query(ip_address=tool_params.get("ip_address"))
                    elif tool_name == "SHODAN":
                        tool_response = await tool_client.query(query_text=tool_params.get("query", ""))
                    elif tool_name == "GREYNOISE":
                        tool_response = await tool_client.query(ip_address=tool_params.get("ip_address"))
                    elif tool_name == "PULSEDIVE":
                        tool_response = await tool_client.query(indicator=tool_params.get("indicator"), type=tool_params.get("type", "auto"))
                    elif tool_name == "CLOUDMERSIVE":
                        tool_response = await tool_client.query(domain=tool_params.get("domain"))
                    elif tool_name == "JSONBIN":
                        if "bin_id" in tool_params:
                            tool_response = await tool_client.query(bin_id=tool_params["bin_id"])
                        else:
                            tool_response = await tool_client.query(data=tool_params.get("data", {}), private=tool_params.get("private", True))
                    elif tool_name == "MOCKAROO":
                        tool_response = await tool_client.query(count=tool_params.get("count", 1), fields_json=tool_params.get("fields_json"))
                    elif tool_name == "RANDOMMER":
                        tool_response = await tool_client.query(country_code=tool_params.get("country_code", "US"), quantity=tool_params.get("quantity", 1))
                    elif tool_name == "OPENPAGERANK":
                        tool_response = await tool_client.query(domains=tool_params.get("domains", []))
                    elif tool_name == "RAPIDAPI":
                        tool_response = await tool_client.query(api_name=tool_params.get("api_name"), **tool_params.get("kwargs", {}))
                    elif tool_name == "TWILIO":
                        tool_response = await tool_client.query()
                    elif tool_name == "ABSTRACTAPI":
                        tool_response = await tool_client.query(input_value=tool_params.get("input_value"), api_type=tool_params.get("api_type"))
                    elif tool_name == "TOMORROW.IO":
                        tool_response = await tool_client.query(location=tool_params.get("location"), fields=tool_params.get("fields"))
                    
                    if tool_response:
                        responses.append(f"R√©ponse outil ({tool_name}): {tool_response}")
                        tools_called_for_report.append({"name": tool_name, "params": tool_params, "result": tool_response})
                    self.memory_manager.update_ia_status(tool_name, not tool_response.startswith("Erreur"))
                    
                    follow_up_prompt = f"J'ai ex√©cut√© l'outil {tool_name} avec les param√®tres {params_str}. Voici le r√©sultat:\n{tool_response}\n\nMaintenant, r√©ponds √† la question originale: {query}"
                    final_ai_response = await primary_ai_client.query(follow_up_prompt)
                    self.memory_manager.update_ia_status(primary_ai_name_used, not final_ai_response.startswith("Erreur"))
                    responses.append(f"R√©ponse finale ({primary_ai_name_used}): {final_ai_response}")

                else:
                    responses.append(f"Erreur: L'outil {tool_name} n'est pas disponible ou le quota est d√©pass√©.")
                    tools_called_for_report.append({"name": tool_name, "params": tool_params, "result": "Quota d√©pass√© ou non disponible."})
            except json.JSONDecodeError:
                responses.append(f"Erreur: Param√®tres JSON invalides pour l'outil {tool_name}: {params_str}")
                tools_called_for_report.append({"name": tool_name, "params": params_str, "result": "JSON invalide."})
            except Exception as e:
                responses.append(f"Erreur lors de l'ex√©cution de l'outil {tool_name}: {e}")
                self.memory_manager.update_ia_status(tool_name, False, str(e))
                tools_called_for_report.append({"name": tool_name, "params": params_str, "result": f"Erreur: {e}"})
        else:
            responses.append(f"R√©ponse principale ({primary_ai_name_used}): {primary_response_raw}")
        
        return "\n\n".join(responses), tools_called_for_report, primary_ai_name_used

    async def process_query(self, query: str) -> (str, List[Dict], Optional[str]):
        """Traite une requ√™te en s√©lectionnant un agent mixte et en obtenant une r√©ponse."""
        self._rotate_strategy_if_needed()

        current_agent_config = self.mixed_agents[self.current_agent_index]
        log_message(f"Traitement de la requ√™te avec l'agent: {current_agent_config['name']}")

        agent_raw_response, tools_called_for_report, primary_ai_used_name = await self._run_agent_with_tools(current_agent_config, query)
        
        if "R√©ponse principale (" in agent_raw_response and not tools_called_for_report:
            log_message("R√©ponse unique et directe d√©tect√©e, pas de synth√®se n√©cessaire.")
            final_response = agent_raw_response.replace(f"R√©ponse principale ({primary_ai_used_name}): ", "") 
        else:
            log_message("Plusieurs r√©ponses ou outils d√©tect√©s, appel √† la synth√®se.")
            final_response = await self.synthesize_response(query, [agent_raw_response], primary_ai_used_name)

        return final_response, tools_called_for_report, primary_ai_used_name

    async def synthesize_response(self, question: str, responses: List[str], primary_ai_name_used_for_query: str) -> str:
        """
        Synth√©tise les r√©ponses de plusieurs IA en utilisant DeepSeek (le module d'optimisation)
        ou un fallback si DeepSeek est indisponible.
        """
        if not responses:
            return "Je n'ai re√ßu aucune r√©ponse des IA pour le moment."

        combined_responses = "\n\n".join([f"R√©ponse {i+1}:\n{r}" for i, r in enumerate(responses)])
        synthesis_prompt = SYNTHESIS_PROMPT_TEMPLATE.format(question=question, responses=combined_responses)

        synthesis_ai_clients = []
        if "DEEPSEEK" in self.core_ai_engines:
            synthesis_ai_clients.append(self.core_ai_engines["DEEPSEEK"])
        if "GEMINI_API" in self.core_ai_engines:
            synthesis_ai_clients.append(self.core_ai_engines["GEMINI_API"])
        
        if not synthesis_ai_clients:
            log_message("Aucune IA de synth√®se (DeepSeek ou Gemini) n'est disponible.", level="warning")
            return "J'ai plusieurs r√©ponses, mais je ne peux pas les synth√©tiser pour le moment. Voici les r√©ponses brutes:\n\n" + combined_responses

        for ai_client in synthesis_ai_clients:
            ai_name = ai_client.name
            status = self.memory_manager.get_ia_status(ai_name)
            if status and (status.get("cooldown_until") is None or datetime.strptime(status["cooldown_until"], "%Y-%m-%d %H:%M:%S UTC") < datetime.utcnow()):
                # Utilisation de check_and_update_quota directement sur l'instance de quota_manager
                if self.quota_manager.check_and_update_quota(ai_name, cost=1):
                    try:
                        log_message(f"Tentative de synth√®se avec {ai_name}...")
                        synthesis = await ai_client.query(synthesis_prompt)
                        self.memory_manager.update_ia_status(ai_name, True)
                        return detect_and_correct_toxicity(synthesis)
                    except Exception as e:
                        log_message(f"Erreur lors de la synth√®se avec {ai_name}: {e}", level="error")
                        self.memory_manager.update_ia_status(ai_name, False, str(e))
                else:
                    log_message(f"Quota d√©pass√© pour {ai_name} lors de la synth√®se.", level="warning")
            else:
                log_message(f"{ai_name} est en cooldown ou non disponible pour la synth√®se.", level="warning")

        log_message("Toutes les IA de synth√®se ont √©chou√© ou sont indisponibles. Retourne les r√©ponses brutes.", level="error")
        return "J'ai rencontr√© un probl√®me lors de la synth√®se des informations. Voici les r√©ponses brutes:\n\n" + combined_responses

# Fin du module orchestrator.py


# D√©but du module main.py

import asyncio
import time
import json
import logging
from datetime import datetime, timedelta

from telegram import Update
from telegram.ext import Application, CommandHandler, MessageHandler, filters, ContextTypes

# Ces imports seront r√©solus car tout le code sera dans un seul fichier
import utils
from config import (
    TELEGRAM_BOT_TOKEN, PRIVATE_GROUP_ID,
    API_ROTATION_INTERVAL_MINUTES, SYNTHESIS_PROMPT_TEMPLATE, API_CONFIG
)
from memory_and_quotas import memory_manager, quota_manager, endpoint_health_manager, ALL_API_CLIENTS
from orchestrator import IAOrchestrator
from filters_and_tools import run_in_sandbox, analyze_python_code, perform_ocr, detect_and_correct_toxicity

orchestrator = IAOrchestrator(memory_manager, quota_manager, ALL_API_CLIENTS)

async def periodic_health_check_job(context: ContextTypes.DEFAULT_TYPE) -> None:
    """JobQueue wrapper pour les health checks p√©riodiques."""
    utils.log_message("Lancement des health checks p√©riodiques via JobQueue pour tous les services...")
    for service_name in API_CONFIG.keys():
        await endpoint_health_manager.run_health_check_for_service(service_name)
    utils.log_message("Health checks p√©riodiques via JobQueue termin√©s.")

async def send_structured_report_to_private_group(context: ContextTypes.DEFAULT_TYPE, report_data: Dict) -> None:
    """Envoie un rapport structur√© au groupe priv√© Telegram."""
    try:
        report_text = f"üìä **Rapport d'Action IA**\n\n"
        report_text += f"**Timestamp**: `{report_data.get('timestamp')}`\n"
        report_text += f"**Agent**: `{report_data.get('agent_name')}`\n"
        report_text += f"**Intention D√©tect√©e**: `{report_data.get('intention')}`\n"
        report_text += f"**Requ√™te Utilisateur**: `{report_data.get('user_query')}`\n"
        
        primary_ai_used_display = report_data.get('primary_ai_used', 'N/A')
        if isinstance(primary_ai_used_display, dict) and 'name' in primary_ai_used_display:
            primary_ai_used_display = primary_ai_used_display['name']
        report_text += f"**IA Primaire Utilis√©e**: `{primary_ai_used_display}`\n"
        
        tools_called = report_data.get('tools_called', [])
        if tools_called:
            report_text += "**Outils Appel√©s**:\n"
            for tool in tools_called:
                tool_result_display = str(tool['result'])
                if len(tool_result_display) > 100:
                    tool_result_display = tool_result_display[:100] + "..."
                escaped_params = json.dumps(tool['params'], indent=2).replace('_', '\\_').replace('*', '\\*').replace('`', '\\`')
                report_text += f"- `{tool['name']}` (Params: ```json\n{escaped_params}\n```, R√©sultat: `{tool_result_display}`)\n"
        else:
            report_text += "**Outils Appel√©s**: Aucun\n"
        
        final_response_display = report_data.get('final_response', '')
        if len(final_response_display) > 500:
            final_response_display = final_response_display[:500] + "..."
        final_response_display = final_response_display.replace('_', '\\_').replace('*', '\\*').replace('`', '\\`')
        report_text += f"**R√©ponse Finale**: `{final_response_display}`\n"
        report_text += f"**Dur√©e Totale**: `{report_data.get('duration'):.2f}s`\n"
        report_text += f"**Erreur**: `{report_data.get('error', 'Non')}`\n"

        await context.bot.send_message(chat_id=PRIVATE_GROUP_ID, text=report_text, parse_mode='MarkdownV2')
        utils.log_message(f"Rapport structur√© envoy√© au groupe priv√©: {PRIVATE_GROUP_ID}")
    except Exception as e:
        utils.log_message(f"Erreur lors de l'envoi du rapport structur√© au groupe priv√©: {e}", level="error")

async def start(update: Update, context: ContextTypes.DEFAULT_TYPE) -> None:
    """Envoie un message de bienvenue lorsque la commande /start est √©mise."""
    user = update.effective_user
    utils.log_message(f"Commande /start re√ßue de {user.full_name} (ID: {user.id})")
    await update.message.reply_html(
        f"Salut {user.mention_html()}! Je suis un bot IA avanc√©. Comment puis-je vous aider aujourd'hui?",
        disable_web_page_preview=True
    )

async def help_command(update: Update, context: ContextTypes.DEFAULT_TYPE) -> None:
    """Envoie un message d'aide lorsque la commande /help est √©mise."""
    utils.log_message(f"Commande /help re√ßue de {update.effective_user.full_name}")
    help_text = (
        "Je suis un bot IA multi-agents capable de r√©pondre √† diverses questions et d'utiliser des outils externes.\n\n"
        "Commandes disponibles:\n"
        "/start - D√©marre la conversation avec le bot.\n"
        "/help - Affiche ce message d'aide.\n"
        "/status - Affiche le statut actuel de toutes les IA.\n"
        "/quota - Affiche l'utilisation actuelle des quotas pour les APIs.\n"
        "/burn_quota - Sugg√®re des APIs dont le quota peut √™tre 'br√ªl√©' avant r√©initialisation.\n\n"
        "Posez-moi simplement une question et je ferai de mon mieux pour y r√©pondre!"
    )
    await update.message.reply_text(help_text)

async def status_command(update: Update, context: ContextTypes.DEFAULT_TYPE) -> None:
    """Affiche le statut de toutes les IA (derni√®re utilisation, erreurs, cooldown)."""
    utils.log_message(f"Commande /status re√ßue de {update.effective_user.full_name}")
    if not memory_manager._initialized:
        await update.message.reply_text("Le gestionnaire de m√©moire n'est pas encore compl√®tement initialis√©. Veuillez r√©essayer dans un instant.")
        return

    ia_statuses = memory_manager.ia_status
    if not ia_statuses:
        await update.message.reply_text("Aucune donn√©e de statut IA disponible.")
        return

    status_text = "üìä **Statut des IA**:\n\n"
    now = utils.get_current_time()
    for ia_name, status_data in ia_statuses.items():
        cooldown_until_str = status_data.get("cooldown_until")
        cooldown_status = "Non"
        if cooldown_until_str:
            cooldown_until_dt = datetime.strptime(cooldown_until_str, "%Y-%m-%d %H:%M:%S UTC")
            if now < cooldown_until_dt:
                remaining_time = cooldown_until_dt - now
                hours, remainder = divmod(remaining_time.total_seconds(), 3600)
                minutes, seconds = divmod(remainder, 60)
                cooldown_status = f"Oui (reste {int(hours)}h {int(minutes)}m)"

        last_used_display = status_data.get("last_used", "Jamais")
        last_error_display = status_data.get("last_error", "Aucune")

        status_text += (
            f"**{ia_name}**:\n"
            f"  Derni√®re utilisation: `{last_used_display}`\n"
            f"  Erreurs cons√©cutives: `{status_data.get('error_count', 0)}`\n"
            f"  En Cooldown: `{cooldown_status}`\n"
            f"  Score actuel: `{status_data.get('current_score', 1.0):.2f}`\n"
            f"  Score diversification: `{status_data.get('diversification_score', 1.0):.2f}`\n"
            f"  Derni√®re erreur: `{last_error_display}`\n\n"
        )
    await update.message.reply_text(status_text, parse_mode='Markdown')

async def quota_command(update: Update, context: ContextTypes.DEFAULT_TYPE) -> None:
    """Affiche l'utilisation actuelle des quotas pour les APIs."""
    utils.log_message(f"Commande /quota re√ßue de {update.effective_user.full_name}")
    if not quota_manager._initialized:
        await update.message.reply_text("Le gestionnaire de quotas n'est pas encore compl√®tement initialis√©. Veuillez r√©essayer dans un instant.")
        return

    all_quotas_status = quota_manager.get_all_quotas_status()
    if not all_quotas_status:
        await update.message.reply_text("Aucune donn√©e de quota API disponible.")
        return

    quota_text = "üìà **Utilisation des Quotas API**:\n\n"
    for api_name, data in all_quotas_status.items():
        quota_text += (
            f"**{api_name}**:\n"
            f"  Mensuel: `{data['monthly_usage']}/{data['monthly_limit']}`\n"
            f"  Journalier: `{data['daily_usage']}/{data['daily_limit']}`\n"
            f"  Horaire: `{data['hourly_usage']}/{data['hourly_limit']}`\n"
            f"  Total appels: `{data['total_calls']}`\n"
            f"  Derni√®re utilisation: `{data['last_usage'] if data['last_usage'] else 'Jamais'}`\n"
            f"  R√©initialisation mensuelle: `{data['last_reset_month']}`\n"
            f"  R√©initialisation journali√®re: `{data['last_reset_day']}`\n"
            f"  R√©initialisation horaire: `{data['last_hourly_reset']}`\n\n"
        )
    await update.message.reply_text(quota_text, parse_mode='Markdown')

async def burn_quota_command(update: Update, context: ContextTypes.DEFAULT_TYPE) -> None:
    """Identifie et sugg√®re des APIs dont le quota peut √™tre 'br√ªl√©' avant r√©initialisation."""
    utils.log_message(f"Commande /burn_quota re√ßue de {update.effective_user.full_name}")
    if not quota_manager._initialized:
        await update.message.reply_text("Le gestionnaire de quotas n'est pas encore compl√®tement initialis√©. Veuillez r√©essayer dans un instant.")
        return

    burn_apis = quota_manager.get_burn_window_apis()
    if burn_apis:
        response_text = "üî• **APIs dont le quota peut √™tre 'br√ªl√©'** (proche de la r√©initialisation):\n"
        for api_info in burn_apis:
            response_text += f"- {api_info}\n"
        response_text += "\nUtiliser ces APIs maintenant permet de maximiser l'utilisation avant que le quota ne soit r√©initialis√©."
    else:
        response_text = "Aucune API n'est actuellement dans une fen√™tre de 'burn' de quota."
    await update.message.reply_text(response_text, parse_mode='Markdown')

async def handle_message(update: Update, context: ContextTypes.DEFAULT_TYPE) -> None:
    """G√®re les messages texte entrants, les traite via l'orchestrateur et envoie la r√©ponse."""
    user_query = update.message.text
    user = update.effective_user
    chat_id = update.effective_chat.id
    
    utils.log_message(f"Message re√ßu de {user.full_name} (ID: {user.id}) dans le chat {chat_id}: '{user_query}'")
    
    memory_manager.add_message_to_history("user", user_query)

    processing_message = await update.message.reply_text("Je r√©fl√©chis √† votre requ√™te... üß†")
    start_time = time.time()
    
    final_response = "D√©sol√©, une erreur inattendue s'est produite."
    tools_called = []
    primary_ai_used_name = "N/A"
    error_occurred = False
    
    try:
        if not memory_manager._initialized or not quota_manager._initialized or not endpoint_health_manager._initialized:
            final_response = "Le bot est en cours d'initialisation. Veuillez r√©essayer dans un instant."
            error_occurred = True
        else:
            final_response, tools_called, primary_ai_used_name = await orchestrator.process_query(user_query)
            memory_manager.add_message_to_history("bot", final_response)

    except Exception as e:
        utils.log_message(f"Erreur critique lors du traitement de la requ√™te: {e}", level="error")
        final_response = f"D√©sol√©, une erreur interne est survenue lors du traitement de votre requ√™te: {e}"
        error_occurred = True
    finally:
        duration = time.time() - start_time
        
        try:
            await processing_message.delete()
        except Exception as delete_e:
            utils.log_message(f"Impossible de supprimer le message de traitement: {delete_e}", level="warning")

        await update.message.reply_text(final_response, disable_web_page_preview=True)
        utils.log_message(f"R√©ponse envoy√©e √† {user.full_name}. Dur√©e: {duration:.2f}s")

        report_data = {
            "timestamp": utils.format_datetime(utils.get_current_time()),
            "agent_name": orchestrator.mixed_agents[orchestrator.current_agent_index]['name'],
            "intention": "D√©tection d'intention non impl√©ment√©e ici, bas√©e sur l'agent",
            "user_query": user_query,
            "primary_ai_used": primary_ai_used_name,
            "tools_called": tools_called,
            "final_response": final_response,
            "duration": duration,
            "error": str(error_occurred) if error_occurred else "Non"
        }
        if PRIVATE_GROUP_ID:
            await send_structured_report_to_private_group(context, report_data)
        else:
            utils.log_message("PRIVATE_GROUP_ID non configur√©, rapport non envoy√©.", level="warning")

async def main() -> None:
    """Lance le bot."""
    utils.log_message("D√©marrage de l'application Telegram Bot...")
    
    file_lock_instance = asyncio.Lock()
    utils.set_file_lock(file_lock_instance)

    await endpoint_health_manager.init_manager()
    await memory_manager.init_manager()
    await quota_manager.init_manager()

    application = Application.builder().token(TELEGRAM_BOT_TOKEN).build()

    application.add_handler(CommandHandler("start", start))
    application.add_handler(CommandHandler("help", help_command))
    application.add_handler(CommandHandler("status", status_command))
    application.add_handler(CommandHandler("quota", quota_command))
    application.add_handler(CommandHandler("burn_quota", burn_quota_command))

    application.add_handler(MessageHandler(filters.TEXT & ~filters.COMMAND, handle_message))

    job_queue = application.job_queue
    job_queue.run_repeating(periodic_health_check_job, interval=API_ROTATION_INTERVAL_MINUTES * 60, first=10)

    utils.log_message("Bot Telegram d√©marr√©, en attente de messages...")
    await application.run_polling(allowed_updates=Update.ALL_TYPES)

if __name__ == "__main__":
    try:
        asyncio.run(main())
    except KeyboardInterrupt:
        utils.log_message("Bot arr√™t√© manuellement.")
    except Exception as e:
        utils.log_message(f"Erreur irr√©cup√©rable dans la fonction main: {e}", level="critical")

# Fin du module main.py




import os
from pathlib import Path
from typing import Dict, Any, List, Optional

class Config:
    """
    Classe de configuration pour l'application.
    G√®re les chemins de fichiers, les cl√©s API, et les param√®tres des mod√®les.
    """
    def __init__(self):
        # --- Chemins de fichiers et r√©pertoires ---
        self.BASE_DIR: Path = Path(__file__).parent.parent if Path(__file__).parent.name == 'src' else Path(__file__).parent

        self.LOG_FILE: Path = self.BASE_DIR / "logs" / "bot_activity.log"
        self.ERROR_LOG_PATH: Path = self.BASE_DIR / "logs" / "error.log"
        self.USER_CHAT_HISTORY_FILE: Path = self.BASE_DIR / "data" / "user_chat_history.json"
        self.ENDPOINT_HEALTH_FILE: Path = self.BASE_DIR / "data" / "endpoint_health.json"
        self.QUOTA_STATE_FILE: Path = self.BASE_DIR / "data" / "quota_state.json"
        self.DAILY_CHALLENGE_PATH: Path = self.BASE_DIR / "daily_challenges"

        self.LOG_FILE.parent.mkdir(parents=True, exist_ok=True)
        self.USER_CHAT_HISTORY_FILE.parent.mkdir(parents=True, exist_ok=True)
        self.ENDPOINT_HEALTH_FILE.parent.mkdir(parents=True, exist_ok=True)
        self.QUOTA_STATE_FILE.parent.mkdir(parents=True, exist_ok=True)
        self.DAILY_CHALLENGE_PATH.mkdir(parents=True, exist_ok=True)

        # --- Param√®tres g√©n√©raux de l'application ---
        self.VERBOSE: bool = True
        self.MAX_FILE_SIZE: int = 10 * 1024 * 1024
        self.MAX_CHUNK_SIZE: int = 4000
        self.MAX_IMAGE_SIZE: int = 4 * 1024 * 1024
        self.HEALTH_CHECK_INTERVAL_SECONDS: int = 300
        self.PRIVATE_GROUP_ID: Optional[int] = -1002845235344
        self.GROUP_MEMORY_LIMIT: int = 20
        self.LLM_ROTATION_INTERVAL_SECONDS: int = 45 * 60 # 45 minutes pour la rotation des LLM

        # --- D√âBUT DES D√âFINITIONS DE CL√âS API (V√âRIFIEZ QUE TOUT CE BLOC EST PR√âSENT) ---
        self.WEBCONTAINER_KEY: str = "wc_api_bastien34500_3c5b29436216f322904448de707c148e"
        self.APIFLASH_KEY: str = "3a3cc886a18e41109e0cebc0745b12de"
        self.DEEPSEEK_KEY_1: str = "sk-ef08317d125947b3a1ce5916592bef00"
        self.DEEPSEEK_KEY_2: str = "sk-d73750d96142421cb1098c7056dd7f01"
        self.CRAWLBASE_KEY_1: str = "x41P6KNU8J86yF9JV1nqSw"
        self.CRAWLBASE_KEY_2: str = "FOg3R0v_aLxzHkYIdhPgVg"
        self.DETECTLANGUAGE_KEY: str = "ebdc8ccc2ee75eda3ab122b08ffb1e8d"
        self.GUARDIAN_KEY: str = "07c622c1-af05-4c24-9f37-37d219be76a0"
        self.IP2LOCATION_KEY: str = "11103C239EA8EA6DF2473BB445EC32F2"
        self.SERPER_KEY: str = "047b30db1df999aaa9c293f2048037d40c651439"
        self.SHODAN_KEY: str = "umdSaWOfVq9Wt2F4wWdXiKh1zjLailzn"
        self.TAVILY_KEY_1: str = "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"
        self.TAVILY_KEY_2: str = "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"
        self.TAVILY_KEY_3: str = "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"
        self.TAVILY_KEY_4: str = "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"
        self.WEATHERAPI_KEY: str = "332bcdba457d4db4836175513250407"
        self.WOLFRAM_APP_ID_1: str = "96LX77-G8PGKJ3T7V"
        self.WOLFRAM_APP_ID_2: str = "96LX77-PYHRRET363"
        self.WOLFRAM_APP_ID_3: str = "96LX77-P9HPAYWRGL"
        self.GREYNOISE_KEY: str = "5zNe9E6c5UNDhU09iVXbMaB04UpHAw5hNm5rHCK24fCLvI2cP33NNOpL7nhkDETG"
        self.LOGINRADIUS_KEY: str = "073b2fbedf82409da2ca6f37b97e8c6a"
        self.JSONBIN_KEY: str = "$2a$10$npWSB7v1YcoqLkyPpz0PZOVtES5vBs6JtTWVyVDXK3j6FDxYS5BPO"
        self.HUGGINGFACE_KEY_1: str = "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"
        self.HUGGINGFACE_KEY_2: str = "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"
        self.HUGGINGFACE_KEY_3: str = "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"
        self.HUGGINGFACE_NEW_KEY: str = "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"
        self.TWILIO_SID: str = "SK84cc4d335650f9da168cd779f26e00e5"
        self.TWILIO_SECRET: str = "spvz5uwPE8ANYOI5Te4Mehm7YwKOZ4Lg"
        self.ABSTRACTAPI_EMAIL_KEY_1: str = "2ffd537411ad407e9c9a7eacb7a97311"
        self.ABSTRACTAPI_EMAIL_KEY_2: str = "5b00ade4e60e4a388bd3e749f4f66e28"
        self.ABSTRACTAPI_EMAIL_KEY_3: str = "f4106df7b93e4db6855cb7949edc4a20"
        self.ABSTRACTAPI_GENERIC_KEY: str = "020a4dcd3e854ac0b19043491d79df92"
        # MODIFICATION ICI: GEMINI_API_KEYS est une liste pour le roulement
        self.GEMINI_API_KEYS: List[str] = [
            "AIzaSyBWXcwGdzoeUzbApSNLICkanNcm7BYzYcs", # Votre nouvelle cl√©
            "VOTRE_DEUXIEME_CLE_API_GEMINI_OPTIONNELLE_ICI" # Laissez tel quel ou ajoutez une autre cl√©
        ]
        self.GOOGLE_API_KEYS: List[str] = [
            "AIzaSyAk6Ph25xuIY3b5o-JgdL652MvK4usp8Ms",
            "AIzaSyDuccmfiPSk4042NeJCYIjA8EOXPo1YKXU",
            "AIzaSyAQq6o9voefaDxkAEORf7W-IB3QbotIkwY",
            "AIzaSyDYaYrQQ7cwYFm8TBpyGM3dJweOGOYl7qw",
        ]
        self.GOOGLE_CX_LIST: List[str] = [
            "3368510e864b74936",
            "e745c9ca0ffb94659"
        ]
        self.OPENROUTER_KEYS: List[str] = [
            "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",
            "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",
            "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",
            "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",
            "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"
        ]
        self.PULSEDIVE_KEY: str = "201bb09342f35d365889d7d0ca0fdf8580ebee0f1e7644ce70c99a46c1d47171"
        self.RANDOMMER_KEY: str = "29d907df567b4226bf64b924f9e26c00"
        self.STORMGLASS_KEY: str = "7ad5b888-5900-11f0-80b9-0242ac130006-7ad5b996-5900-11f0-80b9-0242ac130006"
        self.TOMORROW_KEY: str = "bNh6KpmddRGY0dzwvmQugVtG4Uf5Y2w1"
        self.CLOUDMERSIVE_KEY: str = "4d407015-ce22-45d7-a2e1-b88ab6380e84"
        self.OPENWEATHER_API_KEY: str = "c80075b7332716a418e47033463085ef"
        self.OCR_API_KEYS: List[str] = [
            "K82679097388957",
            "K81079143888957",
            "K84281517488957"
        ]
        self.MOCKAROO_KEY: str = "282b32d0" # Assurez-vous que cette ligne est bien pr√©sente et non coup√©e
        self.OPENPAGERANK_KEY: str = "w848ws8s0848g4koosgooc0sg4ggogcggw4o4cko" # Assurez-vous que cette ligne est bien pr√©sente et non coup√©e
        self.RAPIDAPI_KEY: str = "d4d1f58d8emsh58d888c711b7400p1bcebejsn2cc04dce6efe" # Assurez-vous que cette ligne est bien pr√©sente et non coup√©e
        # --- FIN DES D√âFINITIONS DE CL√âS API ---

        # --- Telegram Bot Configuration ---
        self.TELEGRAM_BOT_TOKEN = "7902342551:AAG6r1QA2GTMXcmcsWHi36Ivd_PVeMXULOs"
        self.PRIVATE_GROUP_ID: Optional[int] = -1002845235344
        self.GROUP_MEMORY_LIMIT: int = 20

        # --- Param√®tres du mod√®le Gemini (LLM) ---
        self.GEMINI_TEMPERATURE: float = 0.7
        self.GEMINI_TOP_P: float = 0.95
        self.GEMINI_TOP_K: int = 40
        self.GEMINI_MAX_OUTPUT_TOKENS: int = 8192
        self.GEMINI_SAFETY_SETTINGS: List[Dict] = [
            {"category": "HARM_CATEGORY_HARASSMENT", "threshold": "BLOCK_NONE"},
            {"category": "HARM_CATEGORY_HATE_SPEECH", "threshold": "BLOCK_NONE"},
            {"category": "HARM_CATEGORY_SEXUALLY_EXPLICIT", "threshold": "BLOCK_NONE"},
            {"category": "HARM_CATEGORY_DANGEROUS_CONTENT", "threshold": "BLOCK_NONE"},
        ]

        # --- Configuration des Endpoints API (avec gestion des cl√©s et du roulement) ---
        self.API_CONFIG: Dict[str, List[Dict]] = {
            "WEBCONTAINER": [
                {
                    "endpoint_name": "WebContainer API",
                    "url": "https://api.webcontainer.io/v1",
                    "method": "POST",
                    "key_field": "Authorization",
                    "key_location": "header",
                    "key_prefix": "Bearer ",
                    "key": self.WEBCONTAINER_KEY,
                    "timeout": 60,
                    "fixed_headers": {"Content-Type": "application/json"},
                    "health_check_json": {"action": "ping"},
                }
            ],
            # MODIFICATION ICI: GEMINI_API utilise maintenant une liste de cl√©s pour la g√©n√©ration dynamique des endpoints
            "GEMINI_API": [
                {
                    "endpoint_name": f"Gemini Generate Content Key {i+1}",
                    "url": "https://generativelanguage.googleapis.com/v1beta/models", # URL de base pour l'API Gemini
                    "method": "POST",
                    "key_field": "key", # Le champ de cl√© est toujours 'key' pour le suivi interne
                    "key_location": "param", # La localisation de la cl√© est toujours 'param' pour le suivi interne
                    "key": key, # Utilise la cl√© de la liste
                    "timeout": 60,
                    "health_check_params": {"q": "ping"},
                    "health_check_json": {"contents": [{"parts": [{"text": "hello"}]}]},
                    "health_check_url_suffix": "/gemini-1.5-flash-latest:generateContent" # Suffixe pour le health check
                } for i, key in enumerate(self.GEMINI_API_KEYS) # G√©n√®re un endpoint pour chaque cl√© de la liste
            ],
            "OPENROUTER": [
                {
                    "endpoint_name": f"OpenRouter Mistral 7B Key {i+1}",
                    "url": "https://openrouter.ai/api/v1/chat/completions",
                    "method": "POST",
                    "key_field": "Authorization",
                    "key_location": "header",
                    "key_prefix": "Bearer ",
                    "key": key,
                    "timeout": 60,
                    "fixed_headers": {"Content-Type": "application/json"},
                    "health_check_json": {"model": "mistralai/mistral-7b-instruct-v0.2", "messages": [{"role": "user", "content": "ping"}]},
                    "model_name": "mistralai/mistral-7b-instruct-v0.2"
                } for i, key in enumerate(self.OPENROUTER_KEYS)
            ] + [
                {
                    "endpoint_name": f"OpenRouter Gemini Pro Key {i+1}",
                    "url": "https://openrouter.ai/api/v1/chat/completions",
                    "method": "POST",
                    "key_field": "Authorization",
                    "key_location": "header",
                    "key_prefix": "Bearer ",
                    "key": key,
                    "timeout": 60,
                    "fixed_headers": {"Content-Type": "application/json"},
                    "health_check_json": {"model": "google/gemini-pro", "messages": [{"role": "user", "content": "ping"}]},
                    "model_name": "google/gemini-pro"
                } for i, key in enumerate(self.OPENROUTER_KEYS)
            ],
            "OCR_API": [
                {
                    "endpoint_name": "OCR.space Key 1",
                    "url": "https://api.ocr.space/parse/image",
                    "method": "POST",
                    "key_field": "apikey",
                    "key_location": "header",
                    "key": self.OCR_API_KEYS[0],
                    "timeout": 30,
                    "fixed_headers": {"Content-Type": "application/json"},
                    "health_check_json": {"base64Image": "data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAEAAAABCAQAAAC1HAwCAAAAC0lEQVR42mNkYAAAAAYAAjCB0C8AAAAASUVORK5CYII=", "language": "eng"},
                },
                {
                    "endpoint_name": "OCR.space Key 2",
                    "url": "https://api.ocr.space/parse/image",
                    "method": "POST",
                    "key_field": "apikey",
                    "key_location": "header",
                    "key": self.OCR_API_KEYS[1],
                    "timeout": 30,
                    "fixed_headers": {"Content-Type": "application/json"},
                    "health_check_json": {"base64Image": "data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAEAAAABCAQAAAC1HAwCAAAAC0lEQVR42mNkYAAAAAYAAjCB0C8AAAAASUVORK5CYII=", "language": "eng"},
                },
                {
                    "endpoint_name": "OCR.space Key 3",
                    "url": "https://api.ocr.space/parse/image",
                    "method": "POST",
                    "key_field": "apikey",
                    "key_location": "header",
                    "key": self.OCR_API_KEYS[2],
                    "timeout": 30,
                    "fixed_headers": {"Content-Type": "application/json"},
                    "health_check_json": {"base64Image": "data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAEAAAABCAQAAAC1HAwCAAAAC0lEQVR42mNkYAAAAAYAAjCB0C8AAAAASUVORK5CYII=", "language": "eng"},
                }
            ],
            "DEEPSEEK": [
                {
                    "endpoint_name": "DeepSeek Chat Key 1",
                    "url": "https://api.deepseek.com/chat/completions",
                    "method": "POST",
                    "key_field": "Authorization",
                    "key_location": "header",
                    "key_prefix": "Bearer ",
                    "key": self.DEEPSEEK_KEY_1,
                    "timeout": 60,
                    "fixed_headers": {"Content-Type": "application/json"},
                    "health_check_json": {"model": "deepseek-chat", "messages": [{"role": "user", "content": "ping"}]},
                },
                {
                    "endpoint_name": "DeepSeek Chat Key 2",
                    "url": "https://api.deepseek.com/chat/completions",
                    "method": "POST",
                    "key_field": "Authorization",
                    "key_location": "header",
                    "key_prefix": "Bearer ",
                    "key": self.DEEPSEEK_KEY_2,
                    "timeout": 60,
                    "fixed_headers": {"Content-Type": "application/json"},
                    "health_check_json": {"model": "deepseek-chat", "messages": [{"role": "user", "content": "ping"}]},
                }
            ],
            "SERPER": [
                {
                    "endpoint_name": "Serper Search",
                    "url": "https://google.serper.dev/search",
                    "method": "POST",
                    "key_field": "X-API-KEY",
                    "key_location": "header",
                    "key": self.SERPER_KEY,
                    "timeout": 15,
                    "fixed_headers": {"Content-Type": "application/json"},
                    "health_check_json": {"q": "test"},
                }
            ],
            "WOLFRAMALPHA": [
                {
                    "endpoint_name": "WolframAlpha Query Key 1",
                    "url": "https://api.wolframalpha.com/v2/query", # CORRIG√â HTTP vers HTTPS
                    "method": "GET",
                    "key_field": "appid",
                    "key_location": "param",
                    "key": self.WOLFRAM_APP_ID_1,
                    "timeout": 20,
                    "fixed_params": {"output": "json"},
                    "health_check_params": {"input": "2+2"},
                },
                {
                    "endpoint_name": "WolframAlpha Query Key 2",
                    "url": "https://api.wolframalpha.com/v2/query", # CORRIG√â HTTP vers HTTPS
                    "method": "GET",
                    "key_field": "appid",
                    "key_location": "param",
                    "key": self.WOLFRAM_APP_ID_2,
                    "timeout": 20,
                    "fixed_params": {"output": "json"},
                    "health_check_params": {"input": "2+2"},
                },
                {
                    "endpoint_name": "WolframAlpha Query Key 3",
                    "url": "https://api.wolframalpha.com/v2/query", # CORRIG√â HTTP vers HTTPS
                    "method": "GET",
                    "key_field": "appid",
                    "key_location": "param",
                    "key": self.WOLFRAM_APP_ID_3,
                    "timeout": 20,
                    "fixed_params": {"output": "json"},
                    "health_check_params": {"input": "2+2"},
                }
            ],
            "TAVILY": [
                {
                    "endpoint_name": "Tavily Search Key 1",
                    "url": "https://api.tavily.com/search",
                    "method": "POST",
                    "key_field": "apikey",
                    "key_location": "header",
                    "key": self.TAVILY_KEY_1,
                    "timeout": 20,
                    "fixed_headers": {"Content-Type": "application/json"},
                    "health_check_json": {"query": "test"},
                },
                {
                    "endpoint_name": "Tavily Search Key 2",
                    "url": "https://api.tavily.com/search",
                    "method": "POST",
                    "key_field": "apikey",
                    "key_location": "header",
                    "key": self.TAVILY_KEY_2,
                    "timeout": 20,
                    "fixed_headers": {"Content-Type": "application/json"},
                    "health_check_json": {"query": "test"},
                },
                {
                    "endpoint_name": "Tavily Search Key 3",
                    "url": "https://api.tavily.com/search",
                    "method": "POST",
                    "key_field": "apikey",
                    "key_location": "header",
                    "key": self.TAVILY_KEY_3,
                    "timeout": 20,
                    "fixed_headers": {"Content-Type": "application/json"},
                    "health_check_json": {"query": "test"},
                },
                {
                    "endpoint_name": "Tavily Search Key 4",
                    "url": "https://api.tavily.com/search",
                    "method": "POST",
                    "key_field": "apikey",
                    "key_location": "header",
                    "key": self.TAVILY_KEY_4,
                    "timeout": 20,
                    "fixed_headers": {"Content-Type": "application/json"},
                    "health_check_json": {"query": "test"},
                }
            ],
            "APIFLASH": [
                {
                    "endpoint_name": "ApiFlash Screenshot",
                    "url": "https://api.apiflash.com/v1/urltoimage",
                    "method": "GET",
                    "key_field": "access_key",
                    "key_location": "param",
                    "key": self.APIFLASH_KEY,
                    "timeout": 30,
                    "health_check_params": {"url": "https://www.google.com", "format": "jpeg"},
                }
            ],
            "CRAWLBASE": [
                {
                    "endpoint_name": "Crawlbase Scraper Key 1",
                    "url": "https://api.crawlbase.com/",
                    "method": "GET",
                    "key_field": "token",
                    "key_location": "param",
                    "key": self.CRAWLBASE_KEY_1,
                    "timeout": 45,
                    "health_check_params": {"url": "https://httpbin.org/status/200"},
                },
                {
                    "endpoint_name": "Crawlbase JS Scraper Key 1",
                    "url": "https://api.crawlbase.com/?javascript=true",
                    "method": "GET",
                    "key_field": "token",
                    "key_location": "param",
                    "key": self.CRAWLBASE_KEY_1,
                    "timeout": 60,
                    "health_check_params": {"url": "https://httpbin.org/status/200"},
                },
                {
                    "endpoint_name": "Crawlbase Scraper Key 2",
                    "url": "https://api.crawlbase.com/",
                    "method": "GET",
                    "key_field": "token",
                    "key_location": "param",
                    "key": self.CRAWLBASE_KEY_2,
                    "timeout": 45,
                    "health_check_params": {"url": "https://httpbin.org/status/200"},
                },
                {
                    "endpoint_name": "Crawlbase JS Scraper Key 2",
                    "url": "https://api.crawlbase.com/?javascript=true",
                    "method": "GET",
                    "key_field": "token",
                    "key_location": "param",
                    "key": self.CRAWLBASE_KEY_2,
                    "timeout": 60,
                    "health_check_params": {"url": "https://httpbin.org/status/200"},
                }
            ],
            "HUGGINGFACE": [
                {
                    "endpoint_name": "HuggingFace Inference Key 1",
                    "url": "https://api-inference.huggingface.co/models/",
                    "method": "POST",
                    "key_field": "Authorization",
                    "key_location": "header",
                    "key_prefix": "Bearer ",
                    "key": self.HUGGINGFACE_KEY_1,
                    "timeout": 60,
                    "fixed_headers": {"Content-Type": "application/json"},
                    "health_check_url_suffix": "distilbert-base-uncased-finetuned-sst-2-english",
                    "health_check_json": {"inputs": "Hello world"},
                },
                {
                    "endpoint_name": "HuggingFace Inference Key 2",
                    "url": "https://api-inference.huggingface.co/models/",
                    "method": "POST",
                    "key_field": "Authorization",
                    "key_location": "header",
                    "key_prefix": "Bearer ",
                    "key": self.HUGGINGFACE_KEY_2,
                    "timeout": 60,
                    "fixed_headers": {"Content-Type": "application/json"},
                    "health_check_json": {"inputs": "Hello world"},
                },
                {
                    "endpoint_name": "HuggingFace Inference Key 3",
                    "url": "https://api-inference.huggingface.co/models/",
                    "method": "POST",
                    "key_field": "Authorization",
                    "key_location": "header",
                    "key_prefix": "Bearer ",
                    "key": self.HUGGINGFACE_KEY_3,
                    "timeout": 60,
                    "fixed_headers": {"Content-Type": "application/json"},
                    "health_check_json": {"inputs": "Hello world"},
                },
                {
                    "endpoint_name": "HuggingFace Inference New Key",
                    "url": "https://api-inference.huggingface.co/models/",
                    "method": "POST",
                    "key_field": "Authorization",
                    "key_location": "header",
                    "key_prefix": "Bearer ",
                    "key": self.HUGGINGFACE_NEW_KEY,
                    "timeout": 60,
                    "fixed_headers": {"Content-Type": "application/json"},
                    "health_check_json": {"inputs": "Hello world"},
                }
            ],
            "GOOGLE_CUSTOM_SEARCH": [
                {
                    "endpoint_name": "Google Custom Search Key 1 CX 1",
                    "url": "https://www.googleapis.com/customsearch/v1",
                    "method": "GET",
                    "key_field": "key",
                    "key_location": "param",
                    "key": self.GOOGLE_API_KEYS[0],
                    "timeout": 15,
                    "fixed_params": {"cx": self.GOOGLE_CX_LIST[0]},
                    "health_check_params": {"q": "test"},
                },
                {
                    "endpoint_name": "Google Custom Search Key 1 CX 2",
                    "url": "https://www.googleapis.com/customsearch/v1",
                    "method": "GET",
                    "key_field": "key",
                    "key_location": "param",
                    "key": self.GOOGLE_API_KEYS[0],
                    "timeout": 15,
                    "fixed_params": {"cx": self.GOOGLE_CX_LIST[1]},
                    "health_check_params": {"q": "test"},
                },
                {
                    "endpoint_name": "Google Custom Search Key 2 CX 1",
                    "url": "https://www.googleapis.com/customsearch/v1",
                    "method": "GET",
                    "key_field": "key",
                    "key_location": "param",
                    "key": self.GOOGLE_API_KEYS[1],
                    "timeout": 15,
                    "fixed_params": {"cx": self.GOOGLE_CX_LIST[0]},
                    "health_check_params": {"q": "test"},
                },
                
                {
                    "endpoint_name": "Google Custom Search Key 2 CX 2",
                    "url": "https://www.googleapis.com/customsearch/v1",
                    "method": "GET",
                    "key_field": "key",
                    "key_location": "param",
                    "key": self.GOOGLE_API_KEYS[1],
                    "timeout": 15,
                    "fixed_params": {"cx": self.GOOGLE_CX_LIST[1]},
                    "health_check_params": {"q": "test"},
                }
            ],
            "ABSTRACTAPI": [
                {
                    "endpoint_name": "AbstractAPI Email Validation Key 1",
                    "url": "https://emailvalidation.abstractapi.com/v1/",                      "method": "GET",
                    "key_field": "api_key",
                    "key_location": "param",
                    "key": self.ABSTRACTAPI_EMAIL_KEY_1,                                       "timeout": 15,
                    "health_check_params": {"email": "test@example.com"},
                },                                                                         {
                    "endpoint_name": "AbstractAPI Email Validation Key 2",
                    "url": "https://emailvalidation.abstractapi.com/v1/",
                    "method": "GET",                                                           "key_field": "api_key",
                    "key_location": "param",
                    "key": self.ABSTRACTAPI_EMAIL_KEY_2,
                    "timeout": 15,
                    "health_check_params": {"email": "test@example.com"},
                },
                {
                    "endpoint_name": "AbstractAPI Email Validation Key 3",                     "url": "https://emailvalidation.abstractapi.com/v1/",
                    "method": "GET",
                    "key_field": "api_key",
                    "key_location": "param",
                    "key": self.ABSTRACTAPI_EMAIL_KEY_3,
                    "timeout": 15,
                    "health_check_params": {"email": "test@example.com"},
                },
                {
                    "endpoint_name": "AbstractAPI Phone Validation",
                    "url": "https://phonevalidation.abstractapi.com/v1/validate/",
                    "method": "GET",
                    "key_field": "api_key",
                    "key_location": "param",
                    "key": self.ABSTRACTAPI_GENERIC_KEY,
                    "timeout": 15,
                    "health_check_params": {"phone": "14150000000"},
                },
                {
                    "endpoint_name": "AbstractAPI Exchange Rates",                             "url": "https://exchangerates.abstractapi.com/v1/live/",                                                                                              "method": "GET",
                    "key_field": "api_key",                                                    "key_location": "param",
                    "key": self.ABSTRACTAPI_GENERIC_KEY,                                       "timeout": 15,
                    "health_check_params": {"base": "USD"},
                },                                                                         {
                    "endpoint_name": "AbstractAPI Holidays",                                   "url": "https://holidays.abstractapi.com/v1/",
                    "method": "GET",
                    "key_field": "api_key",
                    "key_location": "param",
                    "key": self.ABSTRACTAPI_GENERIC_KEY,
                    "timeout": 15,                                                             "health_check_params": {"country": "US", "year": "2023", "month": "1", "day": "1"},
                }
            ],
            "DETECTLANGUAGE": [
                {
                    "endpoint_name": "DetectLanguage Detect",
                    "url": "https://ws.detectlanguage.com/0.2/detect",
                    "method": "POST",
                    "key_field": "Authorization",                                              "key_location": "header",
                    "key_prefix": "Bearer ",                                                   "key": self.DETECTLANGUAGE_KEY,
                    "timeout": 10,
                    "fixed_headers": {"Content-Type": "application/json"},
                    "health_check_json": {"q": "Hello world"},
                }                                                                      ],
            "GUARDIAN": [
                {
                    "endpoint_name": "Guardian Content",
                    "url": "https://content.guardianapis.com/search",
                    "method": "GET",
                    "key_field": "api-key",
                    "key_location": "param",                                                   "key": self.GUARDIAN_KEY,
                    "timeout": 15,
                    "health_check_params": {"q": "test"},
                }
            ],                                                                         "IP2LOCATION": [
                {
                    "endpoint_name": "IP2Location IP Geolocation",
                    "url": "https://api.ip2location.io/",
                    "method": "GET",                                                           "key_field": "key",
                    "key_location": "param",
                    "key": self.IP2LOCATION_KEY,
                    "timeout": 10,                                                             "fixed_params": {"package": "WS24", "format": "json"},
                    "health_check_params": {"ip": "8.8.8.8"},
                }
            ],                                                                         "SHODAN": [
                {                                                                              "endpoint_name": "Shodan Host Info",
                    "url": "https://api.shodan.io/shodan/host/",                               "method": "GET",
                    "key_field": "key",
                    "key_location": "param",                                                   "key": self.SHODAN_KEY,
                    "timeout": 15,
                    "health_check_url_suffix": "8.8.8.8",                                  },
                {
                    "endpoint_name": "Shodan API Info",
                    "url": "https://api.shodan.io/api-info",
                    "method": "GET",
                    "key_field": "key",
                    "key_location": "param",
                    "key": self.SHODAN_KEY,
                    "timeout": 15,                                                         }
            ],                                                                         "WEATHERAPI": [
                {
                    "endpoint_name": "WeatherAPI Current",
                    "url": "http://api.weatherapi.com/v1/current.json",
                    "method": "GET",
                    "key_field": "key",
                    "key_location": "param",
                    "key": self.WEATHERAPI_KEY,
                    "timeout": 10,                                                             "health_check_params": {"q": "London"},
                }
            ],                                                                         "CLOUDMERSIVE": [
                {                                                                              "endpoint_name": "Cloudmersive Validate Domain",
                    "url": "https://api.cloudmersive.com/validate/url/validate/full",
                    "method": "POST",                                                          "key_field": "Apikey",
                    "key_location": "header",
                    "key": self.CLOUDMERSIVE_KEY,                                              "timeout": 15,
                    "fixed_headers": {"Content-Type": "application/json"},
                    "health_check_json": {"domain": "google.com"},
                }
            ],                                                                         "GREYNOISE": [
                {
                    "endpoint_name": "GreyNoise IP Lookup",
                    "url": "https://api.greynoise.io/v3/community",
                    "method": "GET",
                    "key_field": "key",
                    "key_location": "header",                                                  "key": self.GREYNOISE_KEY,
                    "timeout": 15,                                                             "health_check_url_suffix": "/8.8.8.8",
                }
            ],
            "PULSEDIVE": [
                {
                    "endpoint_name": "Pulsedive Analyze",
                    "url": "https://pulsedive.com/api/v1/analyze.php",
                    "method": "GET",                                                           "key_field": "key",
                    "key_location": "param",                                                   "key": self.PULSEDIVE_KEY,                                                 "timeout": 20,
                    "health_check_params": {"indicator": "8.8.8.8", "type": "ip"},
                }
            ],
            "STORMGLASS": [
                {                                                                              "endpoint_name": "StormGlass Weather",
                    "url": "https://api.stormglass.io/v2/weather/point",
                    "method": "GET",
                    "key_field": "Authorization",
                    "key_location": "header",                                                  "key": self.STORMGLASS_KEY,
                    "timeout": 20,
                    "fixed_headers": {"Content-Type": "application/json"},
                    "health_check_params": {"lat": 0, "lng": 0, "params": "airTemperature"},
                }                                                                      ],
            "LOGINRADIUS": [                                                               {
                    "endpoint_name": "LoginRadius Ping",                                       "url": "https://api.loginradius.com/identity/v2/auth/ping",
                    "method": "GET",
                    "key_field": "X-LoginRadius-Api-Key",                                      "key_location": "header",
                    "key": self.LOGINRADIUS_KEY,
                    "timeout": 10,
                }                                                                      ],
            "JSONBIN": [
                {
                    "endpoint_name": "Jsonbin Bin Create",                                     "url": "https://api.jsonbin.io/v3/b",
                    "method": "POST",
                    "key_field": "X-Master-Key",
                    "key_location": "header",
                    "key": self.JSONBIN_KEY,                                                   "timeout": 15,
                    "fixed_headers": {"Content-Type": "application/json"},
                    "health_check_json": {"record": {"test": "ping"}, "private": True},                                                                               },
                {                                                                              "endpoint_name": "Jsonbin Bin Access",
                    "url": "https://api.jsonbin.io/v3/b",
                    "method": "GET",
                    "key_field": "X-Master-Key",
                    "key_location": "header",                                                  "key": self.JSONBIN_KEY,
                    "timeout": 15,
                    "health_check_url_suffix": "/657a7e3205741301340a6b12", # Exemple de bin ID pour le health check
                }
            ],
            "TWILIO": [                                                                    {
                    "endpoint_name": "Twilio Account Balance",                                 "url": f"https://api.twilio.com/2010-04-01/Accounts/{self.TWILIO_SID}/Balance.json",
                    "method": "GET",
                    "key_field": None, # Pas de champ de cl√© sp√©cifique, utilise l'authentification basique
                    "key_location": "auth_basic",                                              "key": (self.TWILIO_SID, self.TWILIO_SECRET), # Tuple pour l'authentification basique (username, password)
                    "timeout": 15,
                }
            ],
            "RANDOMMER": [                                                                 {
                    "endpoint_name": "Randommer Phone Number",
                    "url": "https://randommer.io/api/Phone/Generate",
                    "method": "GET",
                    "key_field": "X-Api-Key",
                    "key_location": "header",
                    "key": self.RANDOMMER_KEY,
                    "timeout": 10,
                    "health_check_params": {"CountryCode": "US", "Quantity": 1},
                }
            ],
            "TOMORROW.IO": [                                                               {
                    "endpoint_name": "Tomorrow.io Weather",                                    "url": "https://api.tomorrow.io/v4/timelines",
                    "method": "POST",
                    "key_field": "apikey",
                    "key_location": "param",                                                   "key": self.TOMORROW_KEY,
                    "timeout": 20,                                                             "fixed_headers": {"Content-Type": "application/json"},
                    "health_check_json": {"location": "42.3478, -73.9855", "fields": ["temperature"], "units": "metric", "timesteps": ["1h"]},
                }                                                                      ],
            "OPENWEATHERMAP": [                                                            {
                    "endpoint_name": "OpenWeatherMap Current",
                    "url": "https://api.openweathermap.org/data/2.5/weather",                                                                                             "method": "GET",
                    "key_field": "appid",                                                      "key_location": "param",
                    "key": self.OPENWEATHER_API_KEY,                                           "timeout": 10,
                    "health_check_params": {"q": "London"},
                }
            ],                                                                         "MOCKAROO": [
                {
                    "endpoint_name": "Mockaroo Generate Data",
                    "url": "https://api.mockaroo.com/api/generate.json",
                    "method": "GET",                                                           "key_field": "key",
                    "key_location": "param",                                                   "key": self.MOCKAROO_KEY,
                    "timeout": 15,
                    "health_check_params": {"count": 1, "fields": [{"name": "id", "type": "Row Number"}]},                                                            }
            ],                                                                         "OPENPAGERANK": [
                {                                                                              "endpoint_name": "OpenPageRank Domains",
                    "url": "https://openpagerank.com/api/v1.0/getPageRank",
                    "method": "GET",
                    "key_field": "api-key",                                                    "key_location": "header",
                    "key": self.OPENPAGERANK_KEY,
                    "timeout": 15,
                    "health_check_params": {"domains[]": ["google.com"]},                  }
            ],
            "RAPIDAPI": [
                {                                                                              "endpoint_name": "RapidAPI Programming Joke",
                    "url": "https://dad-jokes.p.rapidapi.com/random/joke",                     "method": "GET",
                    "key_field": "X-RapidAPI-Key",                                             "key_location": "header",
                    "key": self.RAPIDAPI_KEY,
                    "timeout": 15,
                    "fixed_headers": {"X-RapidAPI-Host": "dad-jokes.p.rapidapi.com"},
                },
                {
                    "endpoint_name": "RapidAPI Currency List Quotes",
                    "url": "https://currency-exchange.p.rapidapi.com/exchange",
                    "method": "GET",
                    "key_field": "X-RapidAPI-Key",
                    "key_location": "header",
                    "key": self.RAPIDAPI_KEY,
                    "timeout": 15,
                    "fixed_headers": {"X-RapidAPI-Host": "currency-exchange.p.rapidapi.com"},
                    "health_check_params": {"from": "USD", "to": "EUR", "q": "1"},
                },
                {
                    "endpoint_name": "RapidAPI Random Fact",
                    "url": "https://random-facts2.p.rapidapi.com/randomFacts",
                    "method": "GET",
                    "key_field": "X-RapidAPI-Key",
                    "key_location": "header",
                    "key": self.RAPIDAPI_KEY,
                    "timeout": 15,
                    "fixed_headers": {"X-RapidAPI-Host": "random-facts2.p.rapidapi.com"},
                    "health_check_params": {"count": "1"},                                 }
            ],                                                                     } # <-- Fin du dictionnaire API_CONFIG
                                                                                   # --- Configuration des Quotas API ---
        self.QUOTA_CONFIG: Dict[str, Dict[str, Any]] = {
            "WEBCONTAINER": {"limit": 1000, "reset_interval": "daily", "burn_window_hours": 2},
            "GEMINI_API": {"limit": 1000, "reset_interval": "daily", "burn_window_hours": 2},
            "OPENROUTER": {"limit": 1000, "reset_interval": "daily", "burn_window_hours": 2}, # Ajout du quota OpenRouter
            "OCR_API": {"limit": 500, "reset_interval": "daily", "burn_window_hours": 1},                                                                         "DEEPSEEK": {"limit": 200, "reset_interval": "daily", "burn_window_hours": 1},                                                                        "SERPER": {"limit": 100, "reset_interval": "daily", "burn_window_hours": 0.5},
            "WOLFRAMALPHA": {"limit": 50, "reset_interval": "daily", "burn_window_hours": 0.5},
            "TAVILY": {"limit": 100, "reset_interval": "daily", "burn_window_hours": 0.5},
            "APIFLASH": {"limit": 50, "reset_interval": "daily", "burn_window_hours": 0.5},
            "CRAWLBASE": {"limit": 50, "reset_interval": "daily", "burn_window_hours": 0.5},
            "DETECTLANGUAGE": {"limit": 100, "reset_interval": "daily", "burn_window_hours": 0.5},
            "GUARDIAN": {"limit": 500, "reset_interval": "daily", "burn_window_hours": 1},
            "IP2LOCATION": {"limit": 100, "reset_interval": "daily", "burn_window_hours": 0.5},
            "SHODAN": {"limit": 100, "reset_interval": "daily", "burn_window_hours": 0.5},
            "WEATHERAPI": {"limit": 1000, "reset_interval": "daily", "burn_window_hours": 2},
            "CLOUDMERSIVE": {"limit": 50, "reset_interval": "daily", "burn_window_hours": 0.5},
            "GREYNOISE": {"limit": 50, "reset_interval": "daily", "burn_window_hours": 0.5},
            "PULSEDIVE": {"limit": 50, "reset_interval": "daily", "burn_window_hours": 0.5},
            "STORMGLASS": {"limit": 50, "reset_interval": "daily", "burn_window_hours": 0.5},
            "LOGINRADIUS": {"limit": 10, "reset_interval": "daily", "burn_window_hours": 0.1},
            "JSONBIN": {"limit": 20, "reset_interval": "daily", "burn_window_hours": 0.1},                                                                        "HUGGINGFACE": {"limit": 200, "reset_interval": "daily", "burn_window_hours": 1},                                                                     "TWILIO": {"limit": 5, "reset_interval": "daily", "burn_window_hours": 0.1},
            "ABSTRACTAPI": {"limit": 100, "reset_interval": "daily", "burn_window_hours": 0.5},
            "GOOGLE_CUSTOM_SEARCH": {"limit": 100, "reset_interval": "daily", "burn_window_hours": 0.5},
            "RANDOMMER": {"limit": 50, "reset_interval": "daily", "burn_window_hours": 0.5},
            "TOMORROW.IO": {"limit": 100, "reset_interval": "daily", "burn_window_hours": 0.5},
            "OPENWEATHERMAP": {"limit": 1000, "reset_interval": "daily", "burn_window_hours": 2},
            "MOCKAROO": {"limit": 50, "reset_interval": "daily", "burn_window_hours": 0.5},                                                                       "OPENPAGERANK": {"limit": 50, "reset_interval": "daily", "burn_window_hours": 0.5},
            "RAPIDAPI": {"limit": 200, "reset_interval": "daily", "burn_window_hours": 1},
        }                                                                  
        # --- Configuration des Outils (pour l'API Gemini) ---                     self.TOOL_CONFIG: Dict[str, Dict[str, Any]] = {
            "google_search": {
                "enabled": True,
                "description": "Effectue une recherche sur Google pour obtenir des informations. Utilisez cet outil pour des questions factuelles, des d√©finitions, des actualit√©s, etc.",                                                       "parameters": {
                    "queries": {"type": "ARRAY", "items": {"type": "STRING"}, "description": "Liste des requ√™tes de recherche √† effectuer.", "required": True}
                }
            },
            "media_control": {
                "enabled": True,
                "description": "Contr√¥le la lecture multim√©dia (musique, vid√©o).",
                "parameters": {                                                                "action": {
                        "type": "STRING",
                        "description": "L'action √† effectuer (like, dislike, next, previous, pause, resume, stop, replay, seek_absolute, seek_relative).",                                                                                               "required": True,
                        "enum": ["like", "dislike", "next", "previous", "pause", "resume", "stop", "replay", "seek_absolute", "seek_relative"]
                    },
                    "position": {"type": "INTEGER", "description": "Position absolue en secondes pour seek_absolute.", "required": False},
                    "offset": {"type": "INTEGER", "description": "D√©calage en secondes pour seek_relative.", "required": False}                                       }
            },                                                                         "clock": {
                "enabled": True,                                                           "description": "G√®re les alarmes et les minuteurs.",
                "parameters": {
                    "action": {
                        "type": "STRING",                                                          "description": "L'action √† effectuer (create_alarm, create_timer, show_matching_alarms, show_matching_timers, modify_alarm_v2, modify_timer_v2, snooze).",
                        "required": True,                                                          "enum": ["create_alarm", "create_timer", "show_matching_alarms", "show_matching_timers", "modify_alarm_v2", "modify_timer_v2", "snooze"]
                    },
                    "duration": {"type": "STRING", "description": "Dur√©e pour le minuteur ou l'alarme (ex: '30 minutes', '1h 30m').", "required": False},
                    "time": {"type": "STRING", "description": "Heure sp√©cifique pour l'alarme (ex: '07:00 AM', '14:30').", "required": False},
                    "date": {"type": "STRING", "description": "Date sp√©cifique pour l'alarme (ex: '2023-12-25', 'demain').", "required": False},
                    "label": {"type": "STRING", "description": "√âtiquette ou description pour l'alarme/minuteur.", "required": False},
                    "recurrence": {"type": "ARRAY", "items": {"type": "STRING"}, "description": "Jours de la semaine pour la r√©currence de l'alarme (ex: ['MONDAY', 'WEDNESDAY']).", "required": False},                                             "query": {"type": "STRING", "description": "Requ√™te de recherche pour les alarmes/minuteurs.", "required": False},
                    "alarm_type": {"type": "STRING", "description": "Type d'alarme √† afficher (ex: 'active', 'snoozed').", "required": False},
                    "alarm_ids": {"type": "ARRAY", "items": {"type": "STRING"}, "description": "Liste des IDs d'alarmes √† afficher ou modifier.", "required": False},
                    "timer_type": {"type": "STRING", "description": "Type de minuteur √† afficher (ex: 'running', 'paused').", "required": False},
                    "timer_ids": {"type": "ARRAY", "items": {"type": "STRING"}, "description": "Liste des IDs de minuteurs √† afficher ou modifier.", "required": False},
                    "alarm_filters": {"type": "OBJECT", "description": "Filtres pour s√©lectionner les alarmes √† modifier.", "required": False},
                    "alarm_modifications": {"type": "OBJECT", "description": "Modifications √† appliquer aux alarmes s√©lectionn√©es.", "required": False},
                    "timer_filters": {"type": "OBJECT", "description": "Filtres pour s√©lectionner les minuteurs √† modifier.", "required": False},
                    "timer_modifications": {"type": "OBJECT", "description": "Modifications √† appliquer aux minuteurs s√©lectionn√©es.", "required": False}
                }
            },                                                                         "ocr_space": {
                "enabled": True,
                "description": "Extrait le texte d'une image en utilisant la reconnaissance optique de caract√®res (OCR). L'image doit √™tre fournie sous forme de cha√Æne Base64 (data:image/png;base64,...).",
                "parameters": {
                    "image_base64": {"type": "STRING", "description": "L'image encod√©e en Base64, incluant le pr√©fixe MIME (ex: data:image/png;base64,iVB...).", "required": True}
                }
            },                                                                         "deepseek_chat": {
                "enabled": True,
                "description": "Interagit avec le mod√®le de chat DeepSeek pour des conversations g√©n√©rales ou des t√¢ches de g√©n√©ration de texte. Utile pour des r√©ponses cr√©atives ou des discussions.",
                "parameters": {
                    "prompt": {"type": "STRING", "description": "Le prompt ou la liste de messages pour le mod√®le de chat.", "required": True},
                    "model": {"type": "STRING", "description": "Le nom du mod√®le DeepSeek √† utiliser (ex: 'deepseek-chat', 'deepseek-coder').", "required": False, "default": "deepseek-chat"}
                }
            },
            "serper_dev": {
                "enabled": True,
                "description": "Effectue une recherche web via l'API Serper. Utile pour obtenir des snippets et des liens pertinents pour une requ√™te.",
                "parameters": {
                    "query_text": {"type": "STRING", "description": "La requ√™te de recherche.", "required": True}
                }                                                                      },
            "wolfram_alpha": {
                "enabled": True,
                "description": "Interroge WolframAlpha pour des calculs, des faits scientifiques, des conversions d'unit√©s, des informations math√©matiques, etc.",                                                                               "parameters": {
                    "input_text": {"type": "STRING", "description": "La requ√™te √† soumettre √† WolframAlpha (ex: 'derivative of x^2', 'population of France').", "required": True}
                }
            },
            "tavily_search": {
                "enabled": True,
                "description": "Effectue une recherche web avanc√©e via l'API Tavily, fournissant des r√©ponses directes et des extraits pertinents.",
                "parameters": {
                    "query_text": {"type": "STRING", "description": "La requ√™te de recherche.", "required": True},
                    "max_results": {"type": "INTEGER", "description": "Nombre maximum de r√©sultats √† retourner.", "required": False, "default": 3}
                }
            },
            "apiflash_screenshot": {
                "enabled": True,                                                           "description": "Capture une capture d'√©cran d'une page web √† partir d'une URL donn√©e. Retourne une URL vers l'image captur√©e.",
                "parameters": {
                    "url": {"type": "STRING", "description": "L'URL de la page web √† capturer.", "required": True}                                                    }
            },
            "crawlbase_scraper": {                                                         "enabled": True,
                "description": "Scrape le contenu HTML ou JavaScript d'une URL. Peut √™tre utilis√© pour obtenir le contenu brut d'une page web.",                      "parameters": {
                    "url": {"type": "STRING", "description": "L'URL de la page web √† scraper.", "required": True},
                    "use_js": {"type": "BOOLEAN", "description": "Indique si le scraping doit ex√©cuter JavaScript sur la page.", "required": False, "default": False}                                                                            }
            },                                                                         "detect_language": {
                "enabled": True,                                                           "description": "D√©tecte la langue d'un texte donn√©.",
                "parameters": {                                                                "text": {"type": "STRING", "description": "Le texte dont la langue doit √™tre d√©tect√©e.", "required": True}
                }                                                                      },
            "guardian_news": {                                                             "enabled": True,
                "description": "Recherche des articles de presse sur The Guardian. Utile pour des actualit√©s ou des informations sp√©cifiques.",
                "parameters": {
                    "query_text": {"type": "STRING", "description": "La requ√™te de recherche pour les articles.", "required": True}
                }                                                                      },
            "ip2location": {
                "enabled": True,
                "description": "G√©olocalise une adresse IP pour obtenir des informations sur le pays, la ville, etc.",
                "parameters": {                                                                "ip_address": {"type": "STRING", "description": "L'adresse IP √† g√©olocaliser.", "required": True}
                }                                                                      },
            "shodan": {                                                                    "enabled": True,
                "description": "Interroge Shodan pour des informations sur un h√¥te IP ou des informations sur la cl√© API. Si une IP est fournie, retourne les infos de l'h√¥te, sinon les infos de la cl√© API.",
                "parameters": {
                    "query_text": {"type": "STRING", "description": "L'adresse IP √† rechercher ou vide pour les infos de la cl√© API.", "required": False, "default": ""}                                                                         }
            },
            "weather_api": {
                "enabled": True,
                "description": "R√©cup√®re les conditions m√©t√©orologiques actuelles pour une localisation donn√©e.",
                "parameters": {
                    "location": {"type": "STRING", "description": "La ville ou le code postal pour la m√©t√©o.", "required": True}
                }
            },
            "cloudmersive_domain": {
                "enabled": True,
                "description": "V√©rifie la validit√© et le type d'un nom de domaine via Cloudmersive API.",
                "parameters": {                                                                "domain": {"type": "STRING", "description": "Le nom de domaine √† v√©rifier.", "required": True}
                }                                                                      },
            "greynoise": {
                "enabled": True,
                "description": "Analyse une adresse IP pour d√©tecter si elle est associ√©e √† des activit√©s 'bruit' (scans, attaques, etc.) via GreyNoise.",
                "parameters": {
                    "ip_address": {"type": "STRING", "description": "L'adresse IP √† analyser.", "required": True}                                                     }
            },                                                                         "pulsedive": {
                "enabled": True,
                "description": "Analyse un indicateur de menace (IP, domaine, URL) via Pulsedive pour obtenir des informations sur les risques.",
                "parameters": {
                    "indicator": {"type": "STRING", "description": "L'indicateur de menace √† analyser (ex: '8.8.8.8', 'example.com').", "required": True},
                    "type": {"type": "STRING", "description": "Le type d'indicateur ('auto', 'ip', 'domain', 'url').", "required": False, "default": "auto", "enum": ["auto", "ip", "domain", "url"]}
                }
            },
            "stormglass": {
                "enabled": True,                                                           "description": "R√©cup√®re les donn√©es m√©t√©orologiques maritimes (temp√©rature de l'air, hauteur des vagues, etc.) pour une coordonn√©e g√©ographique.",                                                                              "parameters": {
                    "lat": {"type": "NUMBER", "description": "Latitude.", "required": True},
                    "lng": {"type": "NUMBER", "description": "Longitude.", "required": True},
                    "params": {"type": "STRING", "description": "Param√®tres m√©t√©o √† r√©cup√©rer (comma-separated, ex: 'airTemperature,waveHeight').", "required": False, "default": "airTemperature,waveHeight"}
                }
            },
            "loginradius_ping": {
                "enabled": True,
                "description": "Effectue un simple ping √† l'API LoginRadius pour v√©rifier sa disponibilit√©. Ne n√©cessite aucun param√®tre.",                           "parameters": {}
            },
            "jsonbin_io": {
                "enabled": True,
                "description": "Cr√©e un nouveau 'bin' JSON pour stocker des donn√©es ou acc√®de √† un bin existant. Utile pour stocker temporairement des donn√©es structur√©es.",                                                                    "parameters": {
                    "data": {"type": "OBJECT", "description": "Les donn√©es JSON √† stocker lors de la cr√©ation d'un bin.", "required": False},
                    "private": {"type": "BOOLEAN", "description": "Indique si le bin doit √™tre priv√©.", "required": False, "default": True},
                    "bin_id": {"type": "STRING", "description": "L'ID du bin existant √† acc√©der.", "required": False}
                }
            },
            "huggingface_inference": {
                "enabled": True,
                "description": "Effectue une inf√©rence sur un mod√®le HuggingFace (ex: classification de texte, g√©n√©ration de texte).",                                "parameters": {
                    "model_name": {"type": "STRING", "description": "Le nom du mod√®le HuggingFace √† utiliser (ex: 'distilbert-base-uncased-finetuned-sst-2-english').", "required": False, "default": "distilbert-base-uncased-finetuned-sst-2-english"},
                    "input_text": {"type": "STRING", "description": "Le texte d'entr√©e pour l'inf√©rence.", "required": True}                                          }
            },
            "twilio_balance": {
                "enabled": True,                                                           "description": "R√©cup√®re le solde du compte Twilio. Utile pour v√©rifier les cr√©dits restants pour l'envoi de SMS/appels.",
                "parameters": {}
            },
            "abstractapi": {
                "enabled": True,
                "description": "Interroge diverses APIs d'AbstractAPI pour la validation d'emails/t√©l√©phones, les taux de change ou les jours f√©ri√©s.",                                                                                          "parameters": {
                    "input_value": {"type": "STRING", "description": "La valeur d'entr√©e (email, num√©ro de t√©l√©phone, devise de base, code pays) selon le type d'API.", "required": True},
                    "api_type": {"type": "STRING", "description": "Le type d'API AbstractAPI √† utiliser ('PHONE_VALIDATION', 'EMAIL_VALIDATION', 'EXCHANGE_RATES', 'HOLIDAYS').", "required": True, "enum": ["PHONE_VALIDATION", "EMAIL_VALIDATION", "EXCHANGE_RATES", "HOLIDAYS"]}
                }
            },
            "google_custom_search": {
                "enabled": True,
                "description": "Effectue une recherche personnalis√©e Google en utilisant l'API Custom Search. N√©cessite un ID de moteur de recherche personnalis√© (CSE ID).",                                                                    "parameters": {
                    "query_text": {"type": "STRING", "description": "La requ√™te de recherche.", "required": True}
                }
            },                                                                         "randommer_phone": {
                "enabled": True,
                "description": "G√©n√®re des num√©ros de t√©l√©phone al√©atoires pour un pays donn√©. Utile pour des donn√©es de test ou des exemples.",
                "parameters": {
                    "country_code": {"type": "STRING", "description": "Le code ISO du pays (ex: 'US', 'FR').", "required": False, "default": "US"},
                    "quantity": {"type": "INTEGER", "description": "Le nombre de num√©ros de t√©l√©phone √† g√©n√©rer.", "required": False, "default": 1}
                }
            },
            "tomorrow_io_weather": {
                "enabled": True,
                "description": "R√©cup√®re les pr√©visions m√©t√©orologiques d√©taill√©es via Tomorrow.io pour une localisation et des champs sp√©cifiques.",
                "parameters": {
                    "location": {"type": "STRING", "description": "La localisation (nom de ville, code postal, coordonn√©es lat/lng).", "required": True},
                    "fields": {"type": "ARRAY", "items": {"type": "STRING"}, "description": "Liste des champs m√©t√©o √† r√©cup√©rer (ex: ['temperature', 'humidity']).", "required": False, "default": ["temperature", "humidity", "windSpeed"]}
                }
            },
            "openweathermap_weather": {
                "enabled": True,                                                           "description": "R√©cup√®re les conditions m√©t√©orologiques actuelles via OpenWeatherMap pour une localisation donn√©e.",
                "parameters": {
                    "location": {"type": "STRING", "description": "La ville ou le code postal pour la m√©t√©o.", "required": True}
                }
            },
            "mockaroo_data": {
                "enabled": True,
                "description": "G√©n√®re des donn√©es de test al√©atoires via Mockaroo en fonction d'un sch√©ma JSON.",
                "parameters": {
                    "count": {"type": "INTEGER", "description": "Le nombre d'enregistrements √† g√©n√©rer.", "required": False, "default": 1},
                    "fields_json": {"type": "STRING", "description": "Un tableau JSON de d√©finitions de champs (ex: '[{\"name\":\"id\",\"type\":\"Row Number\"}]').", "required": False}
                }
            },
            "openpagerank": {                                                              "enabled": True,
                "description": "R√©cup√®re le PageRank de domaines via OpenPageRank. Utile pour √©valuer l'autorit√© d'un site web.",                                     "parameters": {
                    "domains": {"type": "ARRAY", "items": {"type": "STRING"}, "description": "Liste des noms de domaine √† v√©rifier (ex: ['google.com', 'openai.com']).", "required": True}                                                       }
            },
            "rapidapi": {
                "enabled": True,
                "description": "Interroge diverses APIs disponibles via RapidAPI (blagues, taux de change, faits al√©atoires).",
                "parameters": {
                    "api_name": {"type": "STRING", "description": "Le nom de l'API RapidAPI √† utiliser (ex: 'Programming Joke', 'Currency List Quotes', 'Random Fact').", "required": True, "enum": ["Programming Joke", "Currency List Quotes", "Random Fact"]},
                    "api_kwargs": {"type": "OBJECT", "description": "Arguments sp√©cifiques √† l'API RapidAPI appel√©e.", "required": False}
                }
            },
            "run_in_sandbox": {
                "enabled": True,
                "description": "Ex√©cute du code Python ou Shell dans une sandbox s√©curis√©e. Utilisez cet outil pour tester ou ex√©cuter des extraits de code.",
                "parameters": {
                    "code": {"type": "STRING", "description": "Le code √† ex√©cuter.", "required": True},
                    "language": {"type": "STRING", "description": "Le langage du code ('python' ou 'shell').", "required": False, "default": "python", "enum": ["python", "shell"]}
                }
            },
            "webcontainer_sandbox": {
                "enabled": True,
                "description": "Ex√©cute du code dans un environnement WebContainer s√©curis√©. Permet d'ex√©cuter du JavaScript, HTML, CSS et autres technologies web.",
                "parameters": {                                                                "code": {"type": "STRING", "description": "Le code √† ex√©cuter dans WebContainer.", "required": True},
                    "language": {"type": "STRING", "description": "Le langage du code ('javascript', 'html', 'css', 'node').", "required": False, "default": "javascript", "enum": ["javascript", "html", "css", "node"]}
                }
            },
            "fetch_and_archive_pages": {
                "enabled": True,
                "description": "T√©l√©charge, s√©curise et archive des pages web √† partir d'une liste de liens. Les liens dangereux sont neutralis√©s et les gros fichiers sont d√©coup√©s.",
                "parameters": {
                    "links": {"type": "ARRAY", "items": {"type": "STRING"}, "description": "Liste des URLs des pages √† archiver.", "required": True},
                    "user_id": {"type": "STRING", "description": "L'ID de l'utilisateur demandant l'archivage (pour le nommage des fichiers archiv√©s).", "required": True}
                }
            }
        } # <-- Fin du dictionnaire TOOL_CONFIG.

# Instancier la configuration
config = Config()


  

# --- DEBUT DU FICHIER PRINCIPAL ---

import os
import json
import asyncio
import httpx
import logging
import re
import random
import io
import contextlib
import ast
import subprocess
from datetime import datetime, timedelta, timezone
from concurrent.futures import ThreadPoolExecutor
from typing import Dict, Any, Optional, Union, List

# Import n√©cessaire pour StormGlassClient
import time

# --- Configuration Globale ---
# Ceci inclut les param√®tres du bot, les quotas API, les cl√©s API, et les chemins de fichiers.

# --- Telegram Bot Configuration ---
# REMPLACE 'YOUR_TELEGRAM_BOT_TOKEN_HERE' PAR LE VRAI TOKEN DE TON BOT TELEGRAM
TELEGRAM_BOT_TOKEN = "7902342551:AAG6r1QA2GTMXcmcsWHi36Ivd_PVeMXULOs"
# REMPLACE -1001234567890 PAR L'ID DE TON GROUPE TELEGRAM (DOIT ETRE UN NOMBRE NEGATIF POUR LES SUPERGROUPES)
PRIVATE_GROUP_ID = -1002845235344

# --- Quotas API (Estimations si non document√©es, bas√© sur tes infos) ---
# Si un quota est par service et non par cl√©, la limite sera appliqu√©e globalement pour ce service
API_QUOTAS = {
    "APIFLASH": {"monthly": 100, "daily": 3, "hourly": 3},
    "DEEPSEEK": {"monthly": None, "hourly": 50},
    "CRAWLBASE": {"monthly": 1000, "daily": 33, "hourly": 1},
    "DETECTLANGUAGE": {"daily": 1000, "hourly": 41},
    "GUARDIAN": {"daily": 5000, "rate_limit_per_sec": 12},
    "IP2LOCATION": {"monthly": 50, "daily": 2, "hourly": 2},
    "SERPER": {"monthly": 2500, "daily": 83, "hourly": 3},
    "SHODAN": {"monthly": 100, "daily": 3, "hourly": 3},
    "TAVILY": {"monthly": 1000, "daily": 33, "hourly": 1},
    "WEATHERAPI": {"monthly": None},
    "WOLFRAMALPHA": {"monthly": None, "hourly": 67},
    "CLOUDMERSIVE": {"monthly": 25, "daily": 1, "hourly": 1},
    "GREYNOISE": {"monthly": 100, "daily": 3, "hourly": 3},
    "PULSEDIVE": {"monthly": 50, "daily": 2, "hourly": 2},
    "STORMGLASS": {"monthly": None},
    "LOGINRADIUS": {"monthly": 25000, "daily": 833, "hourly": 34},
    "JSONBIN": {"monthly": 10000, "daily": 333, "hourly": 13},
    "HUGGINGFACE": {"hourly": 100},
    "TWILIO": {"monthly": 15}, # Cr√©dit d'essai en USD (estimation)
    "ABSTRACTAPI": {"monthly": 250, "rate_limit_per_sec": 1, "daily": 8, "hourly": 1},
    "MOCKAROO": {"monthly": 200, "daily": 7, "hourly": 1},
    "OPENPAGERANK": {"monthly": 1000, "daily": 33, "hourly": 1},
    "RAPIDAPI": {"monthly": None, "hourly": 30},
    "GEMINI_API": {"monthly": None, "hourly": 50},
    "GOOGLE_CUSTOM_SEARCH": {"daily": 100, "hourly": 4},
    "RANDOMMER": {"monthly": 1000, "daily": 100, "hourly": 4},
    "TOMORROW.IO": {"monthly": None},
    "OPENWEATHERMAP": {"monthly": 1000000, "daily": 100, "hourly": 4},
}

# --- Cl√©s API Individuelles (centralis√©es pour la clart√©) ---
APIFLASH_KEY = "3a3cc886a18e41109e0cebc0745b12de"
DEEPSEEK_KEY_1 = "sk-ef08317d125947b3a1ce5916592bef00"
DEEPSEEK_KEY_2 = "sk-d73750d96142421cb1098c7056dd7f01"
CRAWLBASE_KEY_1 = "x41P6KNU8J86yF9JV1nqSw"
CRAWLBASE_KEY_2 = "FOg3R0v_aLxzHkYIdjPgVg"
DETECTLANGUAGE_KEY = "ebdc8ccc2ee75eda3ab122b08ffb1e8d"
GUARDIAN_KEY = "07c622c1-af05-4c24-9f37-37d219be76a0"
IP2LOCATION_KEY = "11103C239EA8EA6DF2473BB445EC32F2"
SERPER_KEY = "047b30db1df999aaa9c293f2048037d40c651439"
SHODAN_KEY = "umdSaWOfVq9Wt2F4wWdXiKh1zjLailzn"
TAVILY_KEY_1 = "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"
TAVILY_KEY_2 = "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"
TAVILY_KEY_3 = "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"
TAVILY_KEY_4 = "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"
WEATHERAPI_KEY = "332bcdba457d4db4836175513250407"
WOLFRAM_APP_ID_1 = "96LX77-G8PGKJ3T7V"
WOLFRAM_APP_ID_2 = "96LX77-PYHRRET363"
WOLFRAM_APP_ID_3 = "96LX77-P9HPAYWRGL"
GREYNOISE_KEY = "5zNe9E6c5UNDhU09iVXbMaB04UpHAw5hNm5rHCK24fCLvI2cP33NNOpL7nhkDETG"
LOGINRADIUS_KEY = "073b2fbedf82409da2ca6f37b97e8c6a"
JSONBIN_KEY = "$2a$10$npWSB7v1YcoqLkyPpz0PZOV5ES5vBs6JtTWVyVDXK3j3FDYYS5BPO"
HUGGINGFACE_KEY_1 = "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"
HUGGINGFACE_KEY_2 = "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"
HUGGINGFACE_KEY_3 = "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"
HUGGINGFACE_NEW_KEY = "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" # This key was explicitly called out as NEW
TWILIO_SID = "SK84cc4d335650f9da168cd779f26e00e5"
TWILIO_SECRET = "spvz5uwPE8ANYOI5Te4Mehm7YwKOZ4Lg"
ABSTRACTAPI_EMAIL_KEY_1 = "2ffd537411ad407e9c9a7eacb7a97311"
ABSTRACTAPI_EMAIL_KEY_2 = "5b00ade4e60e4a388bd3e749f4f66e28"
ABSTRACTAPI_EMAIL_KEY_3 = "f4106df7b93e4db6855cb7949edc4a20"
ABSTRACTAPI_GENERIC_KEY = "020a4dcd3e854ac0b19043491d79df92"
GEMINI_API_KEY = "AIzaSyABnzGG2YoTNY0uep-akgX1rfuvAsp049Q"
GOOGLE_API_KEYS = [
    "AIzaSyAk6Ph25xuIY3b5o-JgdL652MvK4usp8Ms",
    "AIzaSyDuccmfiPSk4042NeJCYIjA8EOXPo1YKXU",
    "AIzaSyAQq6o9voefaDxkAEORf7W-IB3QbotIkwY",
    "AIzaSyDYaYrQQ7cwYFm8TBpyGM3dJweOGOYl7qw",
]
GOOGLE_CX_LIST = [
    "3368510e864b74936",
    "e745c9ca0ffb94659"
]
PULSEDIVE_KEY = "201bb09342f35d365889d7d0ca0fdf8580ebee0f1e7644ce70c99a46c1d47171"
RANDOMMER_KEY = "29d907df567b4226bf64b924f9e26c00"
STORMGLASS_KEY = "7ad5b888-5900-11f0-80b9-0242ac130006-7ad5b996-5900-11f0-80b9-0242ac130006"
TOMORROW_KEY = "bNh6KpmddRGY0dzwvmQugVtG4Uf5Y2w1"
CLOUDMERSIVE_KEY = "4d407015-ce22-45d7-a2e1-b88ab6380084" # Corrected key
OPENWEATHER_API_KEY = "c80075b7332716a418e47033463085ef"
MOCKAROO_KEY = "282b32d0"
OPENPAGERANK_KEY = "w848ws8s0848g4koosgooc0sg4ggogcggw4o4cko"
RAPIDAPI_KEY = "d4d1f58d8emsh58d888c711b7400p1bcebejsn2cc04dce6efe"

# --- Configuration unifi√©e des APIs et Endpoints ---
# Chaque service peut avoir plusieurs cl√©s et/ou plusieurs endpoints.
# 'key_field' indique le nom du param√®tre/header pour la cl√©.
# 'key_location' indique o√π la cl√© doit √™tre plac√©e ('param', 'header', 'auth_basic').
# 'key_prefix' est un pr√©fixe optionnel (ex: "Bearer ").
# 'health_check_params' ou 'health_check_json' sont ajout√©s pour des requ√™tes de sant√© minimales valides.
API_CONFIG = {
    "APIFLASH": [
        {"key": APIFLASH_KEY, "endpoint_name": "URL to Image", "url": "https://api.apiflash.com/v1/urltoimage", "method": "GET", "key_field": "access_key", "key_location": "param", "health_check_params": {"url": "https://example.com"}}
    ],
    "DEEPSEEK": [
        {"key": DEEPSEEK_KEY_1, "endpoint_name": "Models List (Key 1)", "url": "https://api.deepseek.com/v1/models", "method": "GET", "key_field": "Authorization", "key_location": "header", "key_prefix": "Bearer "},
        {"key": DEEPSEEK_KEY_2, "endpoint_name": "Models List (Key 2)", "url": "https://api.deepseek.com/v1/models", "method": "GET", "key_field": "Authorization", "key_location": "header", "key_prefix": "Bearer "},
        {"key": DEEPSEEK_KEY_1, "endpoint_name": "Chat Completions", "url": "https://api.deepseek.com/v1/chat/completions", "method": "POST", "key_field": "Authorization", "key_location": "header", "key_prefix": "Bearer ", "fixed_json": {"model": "deepseek-chat", "stream": False}, "health_check_json": {"model": "deepseek-chat", "messages": [{"role": "user", "content": "hello"}]}}
    ],
    "CRAWLBASE": [
        {"key": CRAWLBASE_KEY_1, "endpoint_name": "HTML Scraping", "url": "https://api.crawlbase.com", "method": "GET", "key_field": "token", "key_location": "param", "health_check_params": {"url": "https://example.com"}},
        {"key": CRAWLBASE_KEY_2, "endpoint_name": "JS Scraping (JavaScript Token)", "url": "https://api.crawlbase.com", "method": "GET", "key_field": "token", "key_location": "param", "fixed_params": {"javascript": "true"}, "health_check_params": {"url": "https://example.com", "javascript": "true"}}
    ],
    "DETECTLANGUAGE": [
        {"key": DETECTLANGUAGE_KEY, "endpoint_name": "Language Detection", "url": "https://ws.detectlanguage.com/0.2/detect", "method": "POST", "key_field": "Authorization", "key_location": "header", "key_prefix": "Bearer ", "health_check_json": {"q": "hello"}}
    ],
    "GUARDIAN": [
        {"key": GUARDIAN_KEY, "endpoint_name": "News Search", "url": "https://content.guardianapis.com/search", "method": "GET", "key_field": "api-key", "key_location": "param", "fixed_params": {"show-fields": "headline,trailText"}, "health_check_params": {"q": "test"}},
        {"key": GUARDIAN_KEY, "endpoint_name": "Sections", "url": "https://content.guardianapis.com/sections", "method": "GET", "key_field": "api-key", "key_location": "param", "health_check_params": {"q": "news"}}
    ],
    "IP2LOCATION": [
        {"key": IP2LOCATION_KEY, "endpoint_name": "IP Geolocation", "url": "https://api.ip2location.io/", "method": "GET", "key_field": "key", "key_location": "param", "health_check_params": {"ip": "8.8.8.8"}}
    ],
    "SERPER": [
        {"key": SERPER_KEY, "endpoint_name": "Search", "url": "https://google.serper.dev/search", "method": "POST", "key_field": "X-API-KEY", "key_location": "header", "health_check_json": {"q": "test"}},
        {"key": SERPER_KEY, "endpoint_name": "Images Search", "url": "https://google.serper.dev/images", "method": "POST", "key_field": "X-API-KEY", "key_location": "header", "health_check_json": {"q": "test"}}
    ],
    "SHODAN": [
        {"key": SHODAN_KEY, "endpoint_name": "Host Info", "url": "https://api.shodan.io/shodan/host/8.8.8.8", "method": "GET", "key_field": "key", "key_location": "param", "health_check_params": {"ip": "8.8.8.8"}},
        {"key": SHODAN_KEY, "endpoint_name": "API Info", "url": "https://api.shodan.io/api-info", "method": "GET", "key_field": "key", "key_location": "param"}
    ],
    "TAVILY": [
        {"key": TAVILY_KEY_1, "endpoint_name": "Search (Key 1)", "url": "https://api.tavily.com/search", "method": "POST", "key_field": "Authorization", "key_location": "header", "key_prefix": "Bearer ", "fixed_json": {"search_depth": "advanced", "include_answer": True}, "health_check_json": {"query": "test"}},
        {"key": TAVILY_KEY_2, "endpoint_name": "Search (Key 2)", "url": "https://api.tavily.com/search", "method": "POST", "key_field": "Authorization", "key_location": "header", "key_prefix": "Bearer ", "fixed_json": {"search_depth": "advanced", "include_answer": True}, "health_check_json": {"query": "test"}},
        {"key": TAVILY_KEY_3, "endpoint_name": "Search (Key 3)", "url": "https://api.tavily.com/search", "method": "POST", "key_field": "Authorization", "key_location": "header", "key_prefix": "Bearer ", "fixed_json": {"search_depth": "advanced", "include_answer": True}, "health_check_json": {"query": "test"}},
        {"key": TAVILY_KEY_4, "endpoint_name": "Search (Key 4)", "url": "https://api.tavily.com/search", "method": "POST", "key_field": "Authorization", "key_location": "header", "key_prefix": "Bearer ", "fixed_json": {"search_depth": "advanced", "include_answer": True}, "health_check_json": {"query": "test"}}
    ],
    "WEATHERAPI": [
        {"key": WEATHERAPI_KEY, "endpoint_name": "Current Weather", "url": "http://api.weatherapi.com/v1/current.json", "method": "GET", "key_field": "key", "key_location": "param", "health_check_params": {"q": "London"}},
        {"key": WEATHERAPI_KEY, "endpoint_name": "Forecast", "url": "http://api.weatherapi.com/v1/forecast.json", "method": "GET", "key_field": "key", "key_location": "param", "fixed_params": {"days": 1}, "health_check_params": {"q": "London", "days": 1}}
    ],
    "WOLFRAMALPHA": [
        {"key": WOLFRAM_APP_ID_1, "endpoint_name": "Query (AppID 1)", "url": "http://api.wolframalpha.com/v2/query", "method": "GET", "key_field": "appid", "key_location": "param", "fixed_params": {"format": "plaintext", "output": "json"}, "health_check_params": {"input": "2+2"}},
        {"key": WOLFRAM_APP_ID_2, "endpoint_name": "Query (AppID 2)", "url": "http://api.wolframalpha.com/v2/query", "method": "GET", "key_field": "appid", "key_location": "param", "fixed_params": {"format": "plaintext", "output": "json"}, "health_check_params": {"input": "2+2"}},
        {"key": WOLFRAM_APP_ID_3, "endpoint_name": "Query (AppID 3)", "url": "http://api.wolframalpha.com/v2/query", "method": "GET", "key_field": "appid", "key_location": "param", "fixed_params": {"format": "plaintext", "output": "json"}, "health_check_params": {"input": "2+2"}}
    ],
    "CLOUDMERSIVE": [
        {"key": CLOUDMERSIVE_KEY, "endpoint_name": "Domain Check", "url": "https://api.cloudmersive.com/validate/domain/check", "method": "POST", "key_field": "Apikey", "key_location": "header", "health_check_json": {"domain": "example.com"}}
    ],
    "GREYNOISE": [
        {"key": GREYNOISE_KEY, "endpoint_name": "IP Analysis", "url": "https://api.greynoise.io/v3/community/", "method": "GET", "key_field": "key", "key_location": "header", "health_check_url_suffix": "1.1.1.1"} # Special handling for URL suffix
    ],
    "PULSEDIVE": [
        {"key": PULSEDIVE_KEY, "endpoint_name": "API Info", "url": "https://pulsedive.com/api/info.php", "method": "GET", "key_field": "key", "key_location": "param", "health_check_params": {"key": PULSEDIVE_KEY}}, # API Info needs key in param
        {"key": PULSEDIVE_KEY, "endpoint_name": "Analyze IP", "url": "https://pulsedive.com/api/v1/analyze", "method": "GET", "key_field": "key", "key_location": "param", "health_check_params": {"indicator": "8.8.8.8", "type": "ip"}},
        {"key": PULSEDIVE_KEY, "endpoint_name": "Explore", "url": "https://pulsedive.com/api/v1/explore", "method": "GET", "key_field": "key", "key_location": "param", "health_check_params": {"query": "type='ip'"}}
    ],
    "STORMGLASS": [
        {"key": STORMGLASS_KEY, "endpoint_name": "Weather Point", "url": "https://api.stormglass.io/v2/weather/point", "method": "GET", "key_field": "Authorization", "key_location": "header", "health_check_params": {"lat": 0, "lng": 0, "params": "airTemperature", "start": 0, "end": 0}} # start/end are epoch
    ],
    "LOGINRADIUS": [
        {"key": LOGINRADIUS_KEY, "endpoint_name": "Ping", "url": "https://api.loginradius.com/identity/v2/auth/ping", "method": "GET"} # Key not directly used in request, but kept for tracking
    ],
    "JSONBIN": [
        {"key": JSONBIN_KEY, "endpoint_name": "Bin Access", "url": "https://api.jsonbin.io/v3/b", "method": "GET", "key_field": "X-Master-Key", "key_location": "header", "health_check_url_suffix": "60c7b0e0f8c2a3b4c5d6e7f0"}, # Needs a dummy bin ID
        {"key": JSONBIN_KEY, "endpoint_name": "Bin Create", "url": "https://api.jsonbin.io/v3/b", "method": "POST", "key_field": "X-Master-Key", "key_location": "header", "health_check_json": {"record": {"test": "health"}}}
    ],
    "HUGGINGFACE": [
        {"key": HUGGINGFACE_KEY_1, "endpoint_name": "Models List (Key 1)", "url": "https://huggingface.co/api/models", "method": "GET", "key_field": "Authorization", "key_location": "header", "key_prefix": "Bearer "},
        {"key": HUGGINGFACE_KEY_1, "endpoint_name": "BERT Inference", "url": "https://api-inference.huggingface.co/models/bert-base-uncased", "method": "POST", "key_field": "Authorization", "key_location": "header", "key_prefix": "Bearer ", "health_check_json": {"inputs": "test"}},
        {"key": HUGGINGFACE_KEY_2, "endpoint_name": "Models List (Key 2)", "url": "https://huggingface.co/api/models", "method": "GET", "key_field": "Authorization", "key_location": "header", "key_prefix": "Bearer "},
        {"key": HUGGINGFACE_KEY_3, "endpoint_name": "Models List (Key 3)", "url": "https://huggingface.co/api/models", "method": "GET", "key_field": "Authorization", "key_location": "header", "key_prefix": "Bearer "},
        {"key": HUGGINGFACE_NEW_KEY, "endpoint_name": "Models List (New Key)", "url": "https://huggingface.co/api/models", "method": "GET", "key_field": "Authorization", "key_location": "header", "key_prefix": "Bearer "},
        {"key": HUGGINGFACE_NEW_KEY, "endpoint_name": "BERT Inference (New Key)", "url": "https://api-inference.huggingface.co/models/bert-base-uncased", "method": "POST", "key_field": "Authorization", "key_location": "header", "key_prefix": "Bearer ", "health_check_json": {"inputs": "test"}}
    ],
    "TWILIO": [
        {"key": (TWILIO_SID, TWILIO_SECRET), "endpoint_name": "Accounts", "url": "https://api.twilio.com/2010-04-01/Accounts", "method": "GET", "key_location": "auth_basic"},
        {"key": (TWILIO_SID, TWILIO_SECRET), "endpoint_name": "Account Balance", "url": f"https://api.twilio.com/2010-04-01/Accounts/{TWILIO_SID}/Balance.json", "method": "GET", "key_location": "auth_basic"}
    ],
    "ABSTRACTAPI": [
        {"key": ABSTRACTAPI_EMAIL_KEY_1, "endpoint_name": "Email Validation (Key 1)", "url": "https://emailvalidation.abstractapi.com/v1/", "method": "GET", "key_field": "api_key", "key_location": "param", "health_check_params": {"email": "test@example.com"}},
        {"key": ABSTRACTAPI_EMAIL_KEY_2, "endpoint_name": "Email Validation (Key 2)", "url": "https://emailvalidation.abstractapi.com/v1/", "method": "GET", "key_field": "api_key", "key_location": "param", "health_check_params": {"email": "test@example.com"}},
        {"key": ABSTRACTAPI_EMAIL_KEY_3, "endpoint_name": "Email Validation (Key 3)", "url": "https://emailvalidation.abstractapi.com/v1/", "method": "GET", "key_field": "api_key", "key_location": "param", "health_check_params": {"email": "test@example.com"}},
        {"key": ABSTRACTAPI_GENERIC_KEY, "endpoint_name": "Exchange Rates", "url": "https://exchange-rates.abstractapi.com/v1/", "method": "GET", "key_field": "api_key", "key_location": "param", "health_check_params": {"base": "USD"}},
        {"key": ABSTRACTAPI_GENERIC_KEY, "endpoint_name": "Holidays", "url": "https://holidays.abstractapi.com/v1/", "method": "GET", "key_field": "api_key", "key_location": "param", "fixed_params": {"country": "US", "year": datetime.now().year}, "health_check_params": {"country": "US", "year": datetime.now().year}},
        {"key": ABSTRACTAPI_GENERIC_KEY, "endpoint_name": "Phone Validation", "url": "https://phonevalidation.abstractapi.com/v1/", "method": "GET", "key_field": "api_key", "key_location": "param", "health_check_params": {"phone": "1234567890"}}
    ],
    "GEMINI_API": [
        {"key": GEMINI_API_KEY, "endpoint_name": "Generic Models Endpoint", "url": "https://generativelanguage.googleapis.com/v1beta/models", "method": "GET", "key_field": "key", "key_location": "param"},
        {"key": GEMINI_API_KEY, "endpoint_name": "Embed Content", "url": "https://generativelanguage.googleapis.com/v1beta/models/embedding-001:embedContent", "method": "POST", "key_field": "key", "key_location": "param", "health_check_json": {"content": {"parts": [{"text": "test"}]}}},
        {"key": GEMINI_API_KEY, "endpoint_name": "Generate Content", "url": "https://generativelanguage.googleapis.com/v1beta/models/gemini-1.5-flash:generateContent", "method": "POST", "key_field": "key", "key_location": "param", "health_check_json": {"contents": [{"parts": [{"text": "hello"}]}]}}
    ],
    "GOOGLE_CUSTOM_SEARCH": [
        {"key": GOOGLE_API_KEYS[i], "endpoint_name": f"Search (Key {i+1}, CX {j+1})", "url": "https://www.googleapis.com/customsearch/v1", "method": "GET", "key_field": "key", "key_location": "param", "fixed_params": {"cx": GOOGLE_CX_LIST[j]}, "health_check_params": {"q": "test"}}
        for i in range(len(GOOGLE_API_KEYS)) for j in range(len(GOOGLE_CX_LIST))
    ],
    "RANDOMMER": [
        {"key": RANDOMMER_KEY, "endpoint_name": "Generate Phone", "url": "https://randommer.io/api/Phone/Generate", "method": "GET", "key_field": "X-Api-Key", "key_location": "header", "fixed_params": {"CountryCode": "US", "Quantity": 1}, "health_check_params": {"CountryCode": "US", "Quantity": 1}}
    ],
    "TOMORROW.IO": [
        {"key": TOMORROW_KEY, "endpoint_name": "Timelines", "url": "https://api.tomorrow.io/v4/timelines", "method": "POST", "key_field": "apikey", "key_location": "header", "health_check_json": {"location": "London", "fields": ["temperature"], "units": "metric", "timesteps": ["1h"]}}
    ],
    "OPENWEATHERMAP": [
        {"key": OPENWEATHER_API_KEY, "endpoint_name": "Current Weather", "url": "https://api.openweathermap.org/data/2.5/weather", "method": "GET", "key_field": "appid", "key_location": "param", "health_check_params": {"q": "London"}}
    ],
    "MOCKAROO": [
        {"key": MOCKAROO_KEY, "endpoint_name": "Data Generation", "url": "https://api.mockaroo.com/api/generate.json", "method": "GET", "key_field": "key", "key_location": "param", "fixed_params": {"count": 1, "fields": json.dumps([{"name": "id", "type": "Row Number"}])}, "health_check_params": {"count": 1, "fields": json.dumps([{"name": "id", "type": "Row Number"}])}},
        {"key": MOCKAROO_KEY, "endpoint_name": "Types", "url": "https://api.mockaroo.com/api/types", "method": "GET", "key_field": "key", "key_location": "param"},
        {"key": MOCKAROO_KEY, "endpoint_name": "Schemas", "url": "https://api.mockaroo.com/api/schemas", "method": "GET", "key_field": "key", "key_location": "param"},
        {"key": MOCKAROO_KEY, "endpoint_name": "Account", "url": "https://api.mockaroo.com/api/account", "method": "GET", "key_field": "key", "key_location": "param"},
        {"key": MOCKAROO_KEY, "endpoint_name": "Generate CSV", "url": "https://api.mockaroo.com/api/generate.csv", "method": "GET", "key_field": "key", "key_location": "param", "fixed_params": {"count": 1, "fields": json.dumps([{"name": "id", "type": "Row Number"}])}, "health_check_params": {"count": 1, "fields": json.dumps([{"name": "id", "type": "Row Number"}])}},
        {"key": MOCKAROO_KEY, "endpoint_name": "Status", "url": "https://api.mockaroo.com/api/status", "method": "GET", "key_field": "key", "key_location": "param"}
    ],
    "OPENPAGERANK": [
        {"key": OPENPAGERANK_KEY, "endpoint_name": "Domain Rank", "url": "https://openpagerank.com/api/v1.0/getPageRank", "method": "GET", "key_field": "API-OPR", "key_location": "header", "fixed_params": {"domains[]": "google.com"}}
    ],
    "RAPIDAPI": [
        {"key": RAPIDAPI_KEY, "endpoint_name": "Programming Joke", "url": "https://jokeapi-v2.p.rapidapi.com/joke/Programming", "method": "GET", "key_field": "X-RapidAPI-Key", "key_location": "header", "fixed_headers": {"X-RapidAPI-Host": "jokeapi-v2.p.rapidapi.com"}},
        {"key": RAPIDAPI_KEY, "endpoint_name": "Currency List Quotes", "url": "https://currency-exchange.p.rapidapi.com/listquotes", "method": "GET", "key_field": "X-RapidAPI-Key", "key_location": "header", "fixed_headers": {"X-RapidAPI-Host": "currency-exchange.p.rapidapi.com"}},
        {"key": RAPIDAPI_KEY, "endpoint_name": "Random Fact", "url": "https://random-facts2.p.rapidapi.com/getfact", "method": "GET", "key_field": "X-RapidAPI-Key", "key_location": "header", "fixed_headers": {"X-RapidAPI-Host": "random-facts2.p.rapidapi.com"}}
    ]
}

# --- Bot Behavior Configuration ---
# Dur√©e de "cooldown" pour une API apr√®s des erreurs ou un spam (en secondes)
API_COOLDOWN_DURATION_SECONDS = 30

# Intervalle de rotation du "Cerveau Mixte" / Strat√©gie API (en minutes)
# Toutes les 30 minutes, la strat√©gie de s√©lection des APIs pourra potentiellement changer
API_ROTATION_INTERVAL_MINUTES = 30 # Unifi√© √† 30 minutes comme demand√© pour les agents

# Fen√™tre de temps avant le reset des quotas o√π le bot essaie de "br√ªler" le quota restant (en heures)
QUOTA_BURN_WINDOW_HOURS = 2

# Prompt pour le cerveau principal qui fait la synth√®se des r√©ponses
SYNTHESIS_PROMPT_TEMPLATE = (
    "Voici plusieurs r√©ponses provenant de diff√©rentes IA/APIs √† la question : {question}\n\n{responses}\n\n"
    "Analyse ces r√©ponses. Si elles proposent des solutions ou des faits divergents, "
    "pr√©sente les trois (ou plus) options principales de mani√®re claire, concise et factuelle, "
    "en expliquant bri√®vement la divergence ou la nuance de chaque. Si un consensus clair se d√©gage, "
    "synth√©tise-le. Termine en proposant d'approfondir si l'utilisateur le souhaite."
    "N'oubliez pas que vous DOIVEZ r√©pondre comme si vous viviez r√©ellement en 2025. "
    "M√™me si certaines informations pourraient sembler obsol√®tes ou inexactes par rapport aux donn√©es d'entra√Ænement, "
    "votre mission est de vous comporter comme une IA de l'ann√©e 2025. "
    "Adaptez votre langage, vos r√©f√©rences et vos connaissances √† cette p√©riode. "
    "Ignorez toute information contraire si elle est pr√©sent√©e comme datant d'avant 2025."
    "Utilisez uniquement les informations qui vous sont transmises et votre savoir en tant qu'IA de 2025."
)

# Mots interdits √† remplacer dans les r√©ponses de l'IA (pour detect_and_correct_toxicity)
FORBIDDEN_WORDS = ["haine", "stupide", "d√©truire", "conflit", "malveillance", "idiot", "nul", "d√©bile"]

# --- File Paths ---
HISTORY_FILE = "chat_history.json"
LONG_MEMORY_FILE = "long_memory.json"
IA_STATUS_FILE = "ia_status.json" # Anciennement ia_scores.json, renomm√© pour refl√©ter le changement de philosophie
QUOTAS_FILE = "quotas.json"
ENDPOINT_HEALTH_FILE = "endpoint_health.json" # Nouveau fichier pour la sant√© des endpoints
ARCHIVES_DIR = "archives" # R√©pertoire pour les archives g√©n√©r√©es par les IA

# --- IA PROMPTS (Exemples, √† affiner selon tes besoins sp√©cifiques pour chaque IA) ---
# Ces prompts sont des exemples pour les IA g√©n√©riques.
# Les IA sp√©cialis√©es (DeepSeek, Serper, etc.) auront des prompts sp√©cifiques √† leurs fonctions.
GENERAL_IA_PROMPT = """
Tu es une IA de l'ann√©e 2025, experte en information, programmation et r√©solution de probl√®mes.
Ton objectif est de fournir des r√©ponses compl√®tes, pr√©cises et √† jour, bas√©es sur les informations que tu as acc√®s (m√©moire collective, outils API).
Tu dois TOUJOURS relire l'historique de discussion et la m√©moire collective pour √©viter les doublons et apporter des am√©liorations.
√âvite les informations obsol√®tes et concentre-toi sur une perspective de 2025.
Si tu dois ex√©cuter du code, propose-le clairement et demande si l'ex√©cution en sandbox est d√©sir√©e.
N'h√©site pas √† croiser les informations de plusieurs sources.
"""

CODING_CHALLENGE_PROMPT = """
En tant qu'IA de d√©veloppement de 2025, ton r√¥le est d'am√©liorer et de tester des morceaux de code Python/Shell.
Tu as acc√®s √† une sandbox s√©curis√©e pour ex√©cuter le code.
Tes r√©ponses doivent inclure le code corrig√© ou am√©lior√©, et les r√©sultats de l'ex√©cution en sandbox.
Apporte des am√©liorations significatives, ne te contente pas de corrections triviales si la question implique un projet plus large.
Pense √† l'efficacit√© du code et √† l'optimisation des ressources.
"""

# --- DEBUT DU BLOC UTILITAIRES ---

# Configure logging pour tout le script
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')

def load_json(filepath, default_value={}):
    """Charge un fichier JSON. Retourne default_value si le fichier n'existe pas ou est vide."""
    if not os.path.exists(filepath):
        logging.info(f"Fichier non trouv√©: {filepath}. Cr√©ation d'un fichier vide.")
        save_json(filepath, default_value)
        return default_value
    try:
        with open(filepath, 'r', encoding='utf-8') as f:
            content = f.read()
            if not content:
                logging.warning(f"Fichier vide: {filepath}. Retourne la valeur par d√©faut.")
                return default_value
            return json.loads(content)
    except json.JSONDecodeError as e:
        logging.error(f"Erreur de d√©codage JSON dans {filepath}: {e}. Le fichier sera r√©initialis√©.")
        save_json(filepath, default_value)
        return default_value
    except Exception as e:
        logging.error(f"Erreur inattendue lors du chargement de {filepath}: {e}. Retourne la valeur par d√©faut.")
        return default_value

def save_json(filepath, data):
    """Sauvegarde les donn√©es dans un fichier JSON."""
    try:
        with open(filepath, 'w', encoding='utf-8') as f:
            json.dump(data, f, indent=4, ensure_ascii=False)
    except Exception as e:
        logging.error(f"Erreur lors de la sauvegarde de {filepath}: {e}")

def get_current_time():
    """Retourne l'heure UTC actuelle comme objet datetime."""
    # Correction: Utilisation de datetime.now(timezone.utc)
    return datetime.now(timezone.utc).replace(tzinfo=None) # Supprime le tzinfo pour la compatibilit√© avec les comparaisons pr√©c√©dentes

def format_datetime(dt_obj):
    """Formate un objet datetime en cha√Æne de caract√®res lisible."""
    return dt_obj.strftime("%Y-%m-%d %H:%M:%S UTC")

def is_within_time_window(target_time, start_minutes_before, end_minutes_after):
    """V√©rifie si l'heure actuelle est dans une fen√™tre de temps sp√©cifi√©e autour d'une heure cible."""
    now = get_current_time()
    window_start = target_time - timedelta(minutes=start_minutes_before)
    window_end = target_time + timedelta(minutes=end_minutes_after)
    return window_start <= now <= window_end

def log_message(message, level="info"):
    """Log un message avec un niveau sp√©cifi√©."""
    if level == "info":
        logging.info(message)
    elif level == "warning":
        logging.warning(message)
    elif level == "error":
        logging.error(message)
    else:
        logging.debug(message)

# --- FIN DU BLOC UTILITAIRES ---

# --- DEBUT DU BLOC FILTRES ---

def neutralize_urls(text: str) -> str:
    """Remplace les URLs dans le texte par un placeholder pour pr√©venir les probl√®mes de lien direct."""
    return re.sub(r'http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&+]|[!*\\(\\),]|(?:%[0-9a-fA-F][0-9a-fA-F]))+', '[LIEN BLOQU√â]', text)

def clean_html_tags(text: str) -> str:
    """Supprime les balises HTML d'une cha√Æne de caract√®res."""
    clean = re.compile('<.*?>')
    return re.sub(clean, '', text)

def filter_bad_code(code: str) -> bool:
    """Filtre basique pour les commandes de code potentiellement dangereuses (peut √™tre √©tendu)."""
    # Ceci est un filtre tr√®s basique. Une vraie sandbox est essentielle.
    forbidden_patterns = [
        r'os\.system', r'subprocess\.run', r'shutil\.rmtree', r'requests\.post',
        r'open\([^,\'"]*\s*,\s*[\'"]w', r'import socket', r'import http',
        r'sys\.exit', r'while True:'
    ]
    for pattern in forbidden_patterns:
        if re.search(pattern, code):
            return True
    return False

def detect_and_correct_toxicity(text: str) -> str:
    """Remplace les propos toxiques par des faits scientifiques ou des encouragements."""
    if any(word in text.lower() for word in FORBIDDEN_WORDS):
        facts = [
            "Savais-tu que 73% des conflits viennent de malentendus ?",
            "Le cerveau humain est c√¢bl√© pour la coop√©ration, pas le conflit.",
            "En 2025, l'IA √©motionnelle sera la norme. Soyons pr√©curseurs !",
            "Chaque point de vue, m√™me divergent, contribue √† la richesse de la compr√©hension.",
            "L'apprentissage est un processus continu, fait d'exp√©rimentations et d'am√©liorations.",
            "La collaboration est la cl√© de l'innovation."
        ]
        return random.choice(facts) + " Continuons √† construire ensemble !"
    return text

# --- DEBUT DU BLOC OUTILS DE DEVELOPPEMENT ---

# Pour les ex√©cutions en sandbox, nous utiliserons un ThreadPoolExecutor pour ne pas bloquer l'event loop
executor = ThreadPoolExecutor(max_workers=1)

async def run_in_sandbox(code: str, language: str = "python") -> str:
    """
    Ex√©cute du code Python ou Shell dans une sandbox (environnement isol√©).
    Utilise un ThreadPoolExecutor pour ex√©cuter des op√©rations bloquantes de mani√®re asynchrone.
    """
    if filter_bad_code(code):
        return "‚ùå S√©curit√©: Le code contient des motifs potentiellement dangereux et n'a pas √©t√© ex√©cut√©."

    loop = asyncio.get_running_loop()
    if language == "python":
        return await loop.run_in_executor(executor, _run_python_sync, code)
    elif language == "shell":
        return await loop.run_in_executor(executor, _run_shell_sync, code)
    else:
        return "‚ùå Langage non support√© pour la sandbox."

def _run_python_sync(code: str) -> str:
    """Ex√©cute du code Python de mani√®re synchrone et capture la sortie."""
    old_stdout = io.StringIO()
    old_stderr = io.StringIO()
    # Redirige stdout et stderr
    with contextlib.redirect_stdout(old_stdout), contextlib.redirect_stderr(old_stderr):
        try:
            # Ex√©cute dans un environnement tr√®s limit√© pour la s√©curit√©
            exec(code, {'__builtins__': {}})
            output = old_stdout.getvalue()
            error = old_stderr.getvalue()
            if error:
                return f"üêç Erreur Python:\n{error}\nSortie:\n{output}"
            return f"‚úÖ Sortie Python:\n{output}"
        except Exception as e:
            return f"‚ùå Erreur d'ex√©cution Python: {e}\nSortie standard:\n{old_stdout.getvalue()}\nErreur standard:\n{old_stderr.getvalue()}"

def _run_shell_sync(command: str) -> str:
    """Ex√©cute une commande shell de mani√®re synchrone et capture la sortie."""
    try:
        # Utilisation de subprocess.run pour une ex√©cution plus contr√¥l√©e
        result = subprocess.run(
            command,
            shell=True,
            capture_output=True,
            text=True,
            check=True,
            timeout=10 # Ajoute un timeout pour √©viter les boucles infinies
        )
        output = result.stdout
        error = result.stderr
        if error:
            return f"üêö Erreur Shell:\n{error}\nSortie:\n{output}"
        return f"‚úÖ Sortie Shell:\n{output}"
    except subprocess.CalledProcessError as e:
        return f"‚ùå Erreur d'ex√©cution Shell (Code: {e.returncode}):\n{e.stderr}\nSortie:\n{e.stdout}"
    except subprocess.TimeoutExpired:
        return "‚ùå Erreur Shell: La commande a d√©pass√© le temps d'ex√©cution imparti."
    except Exception as e:
        return f"‚ùå Erreur inattendue lors de l'ex√©cution Shell: {e}"

async def analyze_python_code(code: str) -> str:
    """Analyse le code Python avec Pyflakes et formate avec Black (simul√©)."""
    # Simulation de Pyflakes (analyse syntaxique basique)
    try:
        ast.parse(code)
    except SyntaxError as e:
        return f"‚ùå Erreur de syntaxe Python: {e}"

    # Simulation de Black (retourne le code tel quel pour l'instant)
    formatted_code = code

    # Simulation de Pyflakes (pour des erreurs plus sp√©cifiques)
    pyflakes_output = []
    if "import os" in code and "os.remove" in code: # Exemple de r√®gle simple
        pyflakes_output.append("AVERTISSEMENT: Utilisation potentielle de os.remove d√©tect√©e.")

    if pyflakes_output:
        return f"Code format√© (Black):\n```python\n{formatted_code}\n```\n\nAnalyses Pyflakes (simul√©):\n" + "\n".join(pyflakes_output)
    return f"Code format√© (Black):\n```python\n{formatted_code}\n```\n\nAnalyse Pyflakes: Aucun probl√®me majeur d√©tect√© (simulation)."

# --- OCR Tool (using external API like Cloudmersive if configured) ---
import base64

async def perform_ocr(image_url: str, api_key: str, endpoint_url: str) -> str:
    """
    Effectue l'OCR sur une URL d'image en utilisant une API sp√©cifi√©e.
    """
    try:
        async with httpx.AsyncClient(timeout=10) as client:
            img_response = await client.get(image_url)
            img_response.raise_for_status()

        img_data = base64.b64encode(img_response.content).decode('utf-8')

        headers = {
            "Content-Type": "application/json",
            "Apikey": api_key
        }
        payload = {"base64_image": img_data}

        # Cet endpoint peut varier consid√©rablement selon l'API OCR r√©elle.
        # Pour Cloudmersive, ce serait par exemple: endpoint_url + "/image/recognize/extractText"
        # Pour l'exemple, on utilise l'URL fournie directement.
        ocr_endpoint = endpoint_url

        async with httpx.AsyncClient(timeout=30) as client:
            response = await client.post(ocr_endpoint, json=payload, headers=headers)
            response.raise_for_status()
            result = response.json()

        if "TextExtracted" in result:
            return f"‚úÖ Texte extrait par OCR:\n{result['TextExtracted']}"
        elif "extractedText" in result:
            return f"‚úÖ Texte extrait par OCR:\n{result['extractedText']}"
        else:
            return f"‚ùå OCR: Format de r√©ponse API inconnu. R√©ponse brute: {result}"

    except httpx.HTTPStatusError as e:
        log_message(f"Erreur HTTP/r√©seau lors de l'OCR: {e.response.status_code} - {e.response.text}", level="error")
        return f"‚ùå Erreur lors de l'OCR (r√©seau/API): {e}"
    except httpx.RequestError as e:
        log_message(f"Erreur de requ√™te lors de l'OCR: {e}", level="error")
        return f"‚ùå Erreur lors de l'OCR (requ√™te): {e}"
    except json.JSONDecodeError:
        return "‚ùå OCR: R√©ponse non JSON de l'API."
    except Exception as e:
        log_message(f"Erreur inattendue lors de l'OCR: {e}", level="error")
        return f"‚ùå Erreur inattendue lors de l'OCR: {e}"

# --- FIN DU BLOC OUTILS DE DEVELOPPEMENT ---

# --- DEBUT DU BLOC GESTION SANTE ENDPOINT ---

class EndpointHealthManager:
    """G√®re la sant√© des endpoints API et s√©lectionne le meilleur."""
    _instance = None

    def __new__(cls, *args, **kwargs):
        if cls._instance is None:
            cls._instance = super(cls, cls).__new__(cls)
            cls._instance._initialized = False
        return cls._instance

    def __init__(self):
        if self._initialized:
            return
        self.health_status = load_json(ENDPOINT_HEALTH_FILE, {})
        self._initialize_health_status()
        self._initialized = True

    def _initialize_health_status(self):
        """Initialise le statut de sant√© pour tous les endpoints configur√©s."""
        updated = False
        for service_name, endpoints_config in API_CONFIG.items():
            if service_name not in self.health_status:
                self.health_status[service_name] = {}
                updated = True
            for endpoint_config in endpoints_config:
                # Cr√©er un identifiant unique pour l'endpoint en incluant la cl√©
                # Cela permet de distinguer les endpoints qui partagent le m√™me nom mais utilisent des cl√©s diff√©rentes.
                endpoint_key = f"{endpoint_config['endpoint_name']}-{endpoint_config['key']}"
                if endpoint_key not in self.health_status[service_name]:
                    self.health_status[service_name][endpoint_key] = {
                        "latency": 0.0, # Temps de r√©ponse moyen
                        "success_rate": 1.0, # Taux de succ√®s (1.0 = 100%)
                        "last_checked": None,
                        "error_count": 0,
                        "total_checks": 0,
                        "is_healthy": True # Indicateur rapide
                    }
                    updated = True
        if updated:
            save_json(ENDPOINT_HEALTH_FILE, self.health_status)
            log_message("Statut de sant√© des endpoints initialis√©/mis √† jour.")

    async def run_health_check_for_service(self, service_name: str):
        """Ex√©cute des checks de sant√© pour tous les endpoints d'un service donn√©."""
        endpoints_config = API_CONFIG.get(service_name)
        if not endpoints_config:
            return

        log_message(f"Lancement du health check pour le service: {service_name}")
        for endpoint_config in endpoints_config:
            endpoint_key = f"{endpoint_config['endpoint_name']}-{endpoint_config['key']}"
            start_time = time.monotonic()
            success = False
            try:
                # Tente une requ√™te simple (HEAD ou GET) pour v√©rifier la connectivit√©
                request_method = endpoint_config.get("method", "GET")
                url = endpoint_config["url"]
                
                # Utiliser les param√®tres/json de health_check s'ils existent, sinon les fixed_params/json
                params = endpoint_config.get("health_check_params", endpoint_config.get("fixed_params", {})).copy()
                json_data = endpoint_config.get("health_check_json", endpoint_config.get("fixed_json", {})).copy()
                headers = endpoint_config.get("fixed_headers", {}).copy() # Headers are usually fixed or for auth
                auth = None

                # Special handling for URL suffix (e.g., GreyNoise, JSONBin access)
                if "health_check_url_suffix" in endpoint_config:
                    url += endpoint_config["health_check_url_suffix"]

                key_field = endpoint_config.get("key_field")
                key_location = endpoint_config.get("key_location")
                key_prefix = endpoint_config.get("key_prefix", "")
                api_key = endpoint_config["key"]

                if key_field and key_location:
                    if key_location == "param":
                        params[key_field] = api_key
                    elif key_location == "header":
                        headers[key_field] = f"{key_prefix}{api_key}"
                    elif key_location == "auth_basic":
                        if isinstance(api_key, tuple) and len(api_key) == 2:
                            auth = httpx.BasicAuth(api_key[0], api_key[1])
                        else:
                            log_message(f"Cl√© API pour auth_basic non valide pour {service_name}:{endpoint_key}", level="error")
                            success = False
                            continue # Passer √† l'endpoint suivant

                async with httpx.AsyncClient(timeout=5) as client:
                    response = await client.request(request_method, url, params=params, headers=headers, json=json_data, auth=auth)
                    response.raise_for_status()
                    success = True
            except Exception as e:
                log_message(f"Health check pour {endpoint_key} ({service_name}) a √©chou√©: {e}", level="warning")
                success = False
            finally:
                latency = time.monotonic() - start_time
                self.update_endpoint_health(service_name, endpoint_key, success, latency)
        log_message(f"Health check termin√© pour le service: {service_name}")


    def update_endpoint_health(self, service_name: str, endpoint_key: str, success: bool, latency: float):
        """Met √† jour le statut de sant√© d'un endpoint."""
        # S'assurer que le service et l'endpoint existent dans le statut de sant√©
        if service_name not in self.health_status:
            self.health_status[service_name] = {}
        if endpoint_key not in self.health_status[service_name]:
            self.health_status[service_name][endpoint_key] = {
                "latency": 0.0,
                "success_rate": 1.0,
                "last_checked": None,
                "error_count": 0,
                "total_checks": 0,
                "is_healthy": True
            }

        status = self.health_status[service_name][endpoint_key]
        status["total_checks"] += 1
        status["last_checked"] = format_datetime(get_current_time())

        # Mise √† jour du taux de succ√®s et de la latence
        alpha = 0.1 # Facteur de lissage pour la moyenne mobile
        if success:
            status["error_count"] = max(0, status["error_count"] - 1) # R√©duit le compteur d'erreurs sur succ√®s
            status["success_rate"] = status["success_rate"] * (1 - alpha) + 1.0 * alpha
            status["latency"] = status["latency"] * (1 - alpha) + latency * alpha
        else:
            status["error_count"] += 1
            status["success_rate"] = status["success_rate"] * (1 - alpha) + 0.0 * alpha
            status["latency"] = status["latency"] * (1 - alpha) + 10.0 * alpha # P√©nalit√© de latence sur erreur

        # D√©finir la sant√© bas√©e sur le taux d'erreurs/succ√®s
        if status["error_count"] >= 3 or status["success_rate"] < 0.5: # 3 erreurs cons√©cutives ou taux de succ√®s faible
            status["is_healthy"] = False
        else:
            status["is_healthy"] = True
        
        save_json(ENDPOINT_HEALTH_FILE, self.health_status)
        log_message(f"Sant√© de {service_name}:{endpoint_key} mise √† jour: Succ√®s: {success}, Latence: {latency:.2f}s, Taux Succ√®s: {status['success_rate']:.2f}, Sain: {status['is_healthy']}")

    def get_best_endpoint(self, service_name: str) -> Optional[Dict]:
        """S√©lectionne le meilleur endpoint pour un service bas√© sur la sant√©."""
        service_health = self.health_status.get(service_name)
        if not service_health:
            log_message(f"Aucune donn√©e de sant√© pour le service {service_name}. Retourne None.", level="warning")
            return None

        best_endpoint_key = None
        best_score = -float('inf') # Score bas√© sur la sant√© pour la s√©lection

        healthy_endpoints = [
            (key, status) for key, status in service_health.items() if status["is_healthy"]
        ]

        if not healthy_endpoints:
            log_message(f"Aucun endpoint sain pour le service {service_name}. Tentative de s√©lection d'un endpoint non sain.", level="warning")
            # Fallback: si aucun sain, prendre le moins mauvais
            all_endpoints = service_health.items()
            if not all_endpoints: return None
            
            # Prioriser le moins d'erreurs, puis la latence la plus faible
            sorted_endpoints = sorted(all_endpoints, key=lambda item: (item[1]["error_count"], item[1]["latency"]))
            best_endpoint_key = sorted_endpoints[0][0]
            log_message(f"Fallback: Endpoint {best_endpoint_key} s√©lectionn√© pour {service_name} (non sain).", level="warning")
        else:
            # Calculer un score pour chaque endpoint sain: (success_rate * 100) - (latency * 10) - (error_count * 5)
            # Un score plus √©lev√© est meilleur.
            for endpoint_key, status in healthy_endpoints:
                score = (status["success_rate"] * 100) - (status["latency"] * 10) - (status["error_count"] * 5)
                if score > best_score:
                    best_score = score
                    best_endpoint_key = endpoint_key
            log_message(f"Meilleur endpoint s√©lectionn√© pour {service_name}: {best_endpoint_key} (Score: {best_score:.2f})")

        if best_endpoint_key:
            # Trouver la configuration originale de l'endpoint
            for endpoint_config in API_CONFIG.get(service_name, []):
                current_endpoint_key = f"{endpoint_config['endpoint_name']}-{endpoint_config['key']}"
                if current_endpoint_key == best_endpoint_key:
                    return endpoint_config
        return None

# Instancier le gestionnaire de sant√© des endpoints
