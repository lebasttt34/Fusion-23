# --- DEBUT DU FICHIER PRINCIPAL ---

import os
import json
import asyncio
import httpx
import logging
import re
import random
import io
import contextlib
import ast
import subprocess
from datetime import datetime, timedelta, timezone
from concurrent.futures import ThreadPoolExecutor
from typing import Dict, Any, Optional, Union, List

# Import nécessaire pour StormGlassClient
import time

# --- Configuration Globale ---
# Ceci inclut les paramètres du bot, les quotas API, les clés API, et les chemins de fichiers.

# --- Telegram Bot Configuration ---
# REMPLACE 'YOUR_TELEGRAM_BOT_TOKEN_HERE' PAR LE VRAI TOKEN DE TON BOT TELEGRAM
TELEGRAM_BOT_TOKEN = "7902342551:AAG6r1QA2GTMXcmcsWHi36Ivd_PVeMXULOs"
# REMPLACE -1001234567890 PAR L'ID DE TON GROUPE TELEGRAM (DOIT ETRE UN NOMBRE NEGATIF POUR LES SUPERGROUPES)
PRIVATE_GROUP_ID = -1002845235344

# --- Quotas API (Estimations si non documentées, basé sur tes infos) ---
# Si un quota est par service et non par clé, la limite sera appliquée globalement pour ce service
API_QUOTAS = {
    "APIFLASH": {"monthly": 100, "daily": 3, "hourly": 3},
    "DEEPSEEK": {"monthly": None, "hourly": 50},
    "CRAWLBASE": {"monthly": 1000, "daily": 33, "hourly": 1},
    "DETECTLANGUAGE": {"daily": 1000, "hourly": 41},
    "GUARDIAN": {"daily": 5000, "rate_limit_per_sec": 12},
    "IP2LOCATION": {"monthly": 50, "daily": 2, "hourly": 2},
    "SERPER": {"monthly": 2500, "daily": 83, "hourly": 3},
    "SHODAN": {"monthly": 100, "daily": 3, "hourly": 3},
    "TAVILY": {"monthly": 1000, "daily": 33, "hourly": 1},
    "WEATHERAPI": {"monthly": None},
    "WOLFRAMALPHA": {"monthly": None, "hourly": 67},
    "CLOUDMERSIVE": {"monthly": 25, "daily": 1, "hourly": 1},
    "GREYNOISE": {"monthly": 100, "daily": 3, "hourly": 3},
    "PULSEDIVE": {"monthly": 50, "daily": 2, "hourly": 2},
    "STORMGLASS": {"monthly": None},
    "LOGINRADIUS": {"monthly": 25000, "daily": 833, "hourly": 34},
    "JSONBIN": {"monthly": 10000, "daily": 333, "hourly": 13},
    "HUGGINGFACE": {"hourly": 100},
    "TWILIO": {"monthly": 15}, # Crédit d'essai en USD (estimation)
    "ABSTRACTAPI": {"monthly": 250, "rate_limit_per_sec": 1, "daily": 8, "hourly": 1},
    "MOCKAROO": {"monthly": 200, "daily": 7, "hourly": 1},
    "OPENPAGERANK": {"monthly": 1000, "daily": 33, "hourly": 1},
    "RAPIDAPI": {"monthly": None, "hourly": 30},
    "GEMINI_API": {"monthly": None, "hourly": 50},
    "GOOGLE_CUSTOM_SEARCH": {"daily": 100, "hourly": 4},
    "RANDOMMER": {"monthly": 1000, "daily": 100, "hourly": 4},
    "TOMORROW.IO": {"monthly": None},
    "OPENWEATHERMAP": {"monthly": 1000000, "daily": 100, "hourly": 4},
}

# --- Clés API Individuelles (centralisées pour la clarté) ---
APIFLASH_KEY = "3a3cc886a18e41109e0cebc0745b12de"
DEEPSEEK_KEY_1 = "sk-ef08317d125947b3a1ce5916592bef00"
DEEPSEEK_KEY_2 = "sk-d73750d96142421cb1098c7056dd7f01"
CRAWLBASE_KEY_1 = "x41P6KNU8J86yF9JV1nqSw"
CRAWLBASE_KEY_2 = "FOg3R0v_aLxzHkYIdjPgVg"
DETECTLANGUAGE_KEY = "ebdc8ccc2ee75eda3ab122b08ffb1e8d"
GUARDIAN_KEY = "07c622c1-af05-4c24-9f37-37d219be76a0"
IP2LOCATION_KEY = "11103C239EA8EA6DF2473BB445EC32F2"
SERPER_KEY = "047b30db1df999aaa9c293f2048037d40c651439"
SHODAN_KEY = "umdSaWOfVq9Wt2F4wWdXiKh1zjLailzn"
TAVILY_KEY_1 = "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"
TAVILY_KEY_2 = "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"
TAVILY_KEY_3 = "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"
TAVILY_KEY_4 = "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"
WEATHERAPI_KEY = "332bcdba457d4db4836175513250407"
WOLFRAM_APP_ID_1 = "96LX77-G8PGKJ3T7V"
WOLFRAM_APP_ID_2 = "96LX77-PYHRRET363"
WOLFRAM_APP_ID_3 = "96LX77-P9HPAYWRGL"
GREYNOISE_KEY = "5zNe9E6c5UNDhU09iVXbMaB04UpHAw5hNm5rHCK24fCLvI2cP33NNOpL7nhkDETG"
LOGINRADIUS_KEY = "073b2fbedf82409da2ca6f37b97e8c6a"
JSONBIN_KEY = "$2a$10$npWSB7v1YcoqLkyPpz0PZOV5ES5vBs6JtTWVyVDXK3j3FDYYS5BPO"
HUGGINGFACE_KEY_1 = "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"
HUGGINGFACE_KEY_2 = "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"
HUGGINGFACE_KEY_3 = "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"
HUGGINGFACE_NEW_KEY = "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" # This key was explicitly called out as NEW
TWILIO_SID = "SK84cc4d335650f9da168cd779f26e00e5"
TWILIO_SECRET = "spvz5uwPE8ANYOI5Te4Mehm7YwKOZ4Lg"
ABSTRACTAPI_EMAIL_KEY_1 = "2ffd537411ad407e9c9a7eacb7a97311"
ABSTRACTAPI_EMAIL_KEY_2 = "5b00ade4e60e4a388bd3e749f4f66e28"
ABSTRACTAPI_EMAIL_KEY_3 = "f4106df7b93e4db6855cb7949edc4a20"
ABSTRACTAPI_GENERIC_KEY = "020a4dcd3e854ac0b19043491d79df92"
GEMINI_API_KEY = "AIzaSyABnzGG2YoTNY0uep-akgX1rfuvAsp049Q"
GOOGLE_API_KEYS = [
    "AIzaSyAk6Ph25xuIY3b5o-JgdL652MvK4usp8Ms",
    "AIzaSyDuccmfiPSk4042NeJCYIjA8EOXPo1YKXU",
    "AIzaSyAQq6o9voefaDxkAEORf7W-IB3QbotIkwY",
    "AIzaSyDYaYrQQ7cwYFm8TBpyGM3dJweOGOYl7qw",
]
GOOGLE_CX_LIST = [
    "3368510e864b74936",
    "e745c9ca0ffb94659"
]
PULSEDIVE_KEY = "201bb09342f35d365889d7d0ca0fdf8580ebee0f1e7644ce70c99a46c1d47171"
RANDOMMER_KEY = "29d907df567b4226bf64b924f9e26c00"
STORMGLASS_KEY = "7ad5b888-5900-11f0-80b9-0242ac130006-7ad5b996-5900-11f0-80b9-0242ac130006"
TOMORROW_KEY = "bNh6KpmddRGY0dzwvmQugVtG4Uf5Y2w1"
CLOUDMERSIVE_KEY = "4d407015-ce22-45d7-a2e1-b88ab6380084" # Corrected key
OPENWEATHER_API_KEY = "c80075b7332716a418e47033463085ef"
MOCKAROO_KEY = "282b32d0"
OPENPAGERANK_KEY = "w848ws8s0848g4koosgooc0sg4ggogcggw4o4cko"
RAPIDAPI_KEY = "d4d1f58d8emsh58d888c711b7400p1bcebejsn2cc04dce6efe"

# --- Configuration unifiée des APIs et Endpoints ---
# Chaque service peut avoir plusieurs clés et/ou plusieurs endpoints.
# 'key_field' indique le nom du paramètre/header pour la clé.
# 'key_location' indique où la clé doit être placée ('param', 'header', 'auth_basic').
# 'key_prefix' est un préfixe optionnel (ex: "Bearer ").
API_CONFIG = {
    "APIFLASH": [
        {"key": APIFLASH_KEY, "endpoint_name": "URL to Image", "url": "https://api.apiflash.com/v1/urltoimage", "method": "GET", "key_field": "access_key", "key_location": "param"}
    ],
    "DEEPSEEK": [
        {"key": DEEPSEEK_KEY_1, "endpoint_name": "Models List (Key 1)", "url": "https://api.deepseek.com/v1/models", "method": "GET", "key_field": "Authorization", "key_location": "header", "key_prefix": "Bearer "},
        {"key": DEEPSEEK_KEY_2, "endpoint_name": "Models List (Key 2)", "url": "https://api.deepseek.com/v1/models", "method": "GET", "key_field": "Authorization", "key_location": "header", "key_prefix": "Bearer "},
        {"key": DEEPSEEK_KEY_1, "endpoint_name": "Chat Completions", "url": "https://api.deepseek.com/v1/chat/completions", "method": "POST", "key_field": "Authorization", "key_location": "header", "key_prefix": "Bearer ", "fixed_json": {"model": "deepseek-chat", "stream": False}}
    ],
    "CRAWLBASE": [
        {"key": CRAWLBASE_KEY_1, "endpoint_name": "HTML Scraping", "url": "https://api.crawlbase.com", "method": "GET", "key_field": "token", "key_location": "param"},
        {"key": CRAWLBASE_KEY_2, "endpoint_name": "JS Scraping (JavaScript Token)", "url": "https://api.crawlbase.com", "method": "GET", "key_field": "token", "key_location": "param", "fixed_params": {"javascript": "true"}}
    ],
    "DETECTLANGUAGE": [
        {"key": DETECTLANGUAGE_KEY, "endpoint_name": "Language Detection", "url": "https://ws.detectlanguage.com/0.2/detect", "method": "POST", "key_field": "Authorization", "key_location": "header", "key_prefix": "Bearer "}
    ],
    "GUARDIAN": [
        {"key": GUARDIAN_KEY, "endpoint_name": "News Search", "url": "https://content.guardianapis.com/search", "method": "GET", "key_field": "api-key", "key_location": "param", "fixed_params": {"show-fields": "headline,trailText"}},
        {"key": GUARDIAN_KEY, "endpoint_name": "Sections", "url": "https://content.guardianapis.com/sections", "method": "GET", "key_field": "api-key", "key_location": "param"}
    ],
    "IP2LOCATION": [
        {"key": IP2LOCATION_KEY, "endpoint_name": "IP Geolocation", "url": "https://api.ip2location.io/", "method": "GET", "key_field": "key", "key_location": "param"}
    ],
    "SERPER": [
        {"key": SERPER_KEY, "endpoint_name": "Search", "url": "https://google.serper.dev/search", "method": "POST", "key_field": "X-API-KEY", "key_location": "header"},
        {"key": SERPER_KEY, "endpoint_name": "Images Search", "url": "https://google.serper.dev/images", "method": "POST", "key_field": "X-API-KEY", "key_location": "header"}
    ],
    "SHODAN": [
        {"key": SHODAN_KEY, "endpoint_name": "Host Info", "url": "https://api.shodan.io/shodan/host/8.8.8.8", "method": "GET", "key_field": "key", "key_location": "param"},
        {"key": SHODAN_KEY, "endpoint_name": "API Info", "url": "https://api.shodan.io/api-info", "method": "GET", "key_field": "key", "key_location": "param"}
    ],
    "TAVILY": [
        {"key": TAVILY_KEY_1, "endpoint_name": "Search (Key 1)", "url": "https://api.tavily.com/search", "method": "POST", "key_field": "Authorization", "key_location": "header", "key_prefix": "Bearer ", "fixed_json": {"search_depth": "advanced", "include_answer": True}},
        {"key": TAVILY_KEY_2, "endpoint_name": "Search (Key 2)", "url": "https://api.tavily.com/search", "method": "POST", "key_field": "Authorization", "key_location": "header", "key_prefix": "Bearer ", "fixed_json": {"search_depth": "advanced", "include_answer": True}},
        {"key": TAVILY_KEY_3, "endpoint_name": "Search (Key 3)", "url": "https://api.tavily.com/search", "method": "POST", "key_field": "Authorization", "key_location": "header", "key_prefix": "Bearer ", "fixed_json": {"search_depth": "advanced", "include_answer": True}},
        {"key": TAVILY_KEY_4, "endpoint_name": "Search (Key 4)", "url": "https://api.tavily.com/search", "method": "POST", "key_field": "Authorization", "key_location": "header", "key_prefix": "Bearer ", "fixed_json": {"search_depth": "advanced", "include_answer": True}}
    ],
    "WEATHERAPI": [
        {"key": WEATHERAPI_KEY, "endpoint_name": "Current Weather", "url": "http://api.weatherapi.com/v1/current.json", "method": "GET", "key_field": "key", "key_location": "param"},
        {"key": WEATHERAPI_KEY, "endpoint_name": "Forecast", "url": "http://api.weatherapi.com/v1/forecast.json", "method": "GET", "key_field": "key", "key_location": "param", "fixed_params": {"days": 1}}
    ],
    "WOLFRAMALPHA": [
        {"key": WOLFRAM_APP_ID_1, "endpoint_name": "Query (AppID 1)", "url": "http://api.wolframalpha.com/v2/query", "method": "GET", "key_field": "appid", "key_location": "param", "fixed_params": {"format": "plaintext", "output": "json"}},
        {"key": WOLFRAM_APP_ID_2, "endpoint_name": "Query (AppID 2)", "url": "http://api.wolframalpha.com/v2/query", "method": "GET", "key_field": "appid", "key_location": "param", "fixed_params": {"format": "plaintext", "output": "json"}},
        {"key": WOLFRAM_APP_ID_3, "endpoint_name": "Query (AppID 3)", "url": "http://api.wolframalpha.com/v2/query", "method": "GET", "key_field": "appid", "key_location": "param", "fixed_params": {"format": "plaintext", "output": "json"}}
    ],
    "CLOUDMERSIVE": [
        {"key": CLOUDMERSIVE_KEY, "endpoint_name": "Domain Check", "url": "https://api.cloudmersive.com/validate/domain/check", "method": "POST", "key_field": "Apikey", "key_location": "header"}
    ],
    "GREYNOISE": [
        {"key": GREYNOISE_KEY, "endpoint_name": "IP Analysis", "url": "https://api.greynoise.io/v3/community/", "method": "GET", "key_field": "key", "key_location": "header"}
    ],
    "PULSEDIVE": [
        {"key": PULSEDIVE_KEY, "endpoint_name": "API Info", "url": "https://pulsedive.com/api/info.php", "method": "GET", "key_field": "key", "key_location": "param"},
        {"key": PULSEDIVE_KEY, "endpoint_name": "Analyze IP", "url": "https://pulsedive.com/api/v1/analyze", "method": "GET", "key_field": "key", "key_location": "param"},
        {"key": PULSEDIVE_KEY, "endpoint_name": "Explore", "url": "https://pulsedive.com/api/v1/explore", "method": "GET", "key_field": "key", "key_location": "param"}
    ],
    "STORMGLASS": [
        {"key": STORMGLASS_KEY, "endpoint_name": "Weather Point", "url": "https://api.stormglass.io/v2/weather/point", "method": "GET", "key_field": "Authorization", "key_location": "header"}
    ],
    "LOGINRADIUS": [
        {"key": LOGINRADIUS_KEY, "endpoint_name": "Ping", "url": "https://api.loginradius.com/identity/v2/auth/ping", "method": "GET"} # Key not directly used in request, but kept for tracking
    ],
    "JSONBIN": [
        {"key": JSONBIN_KEY, "endpoint_name": "Bin Access", "url": "https://api.jsonbin.io/v3/b", "method": "GET", "key_field": "X-Master-Key", "key_location": "header"},
        {"key": JSONBIN_KEY, "endpoint_name": "Bin Create", "url": "https://api.jsonbin.io/v3/b", "method": "POST", "key_field": "X-Master-Key", "key_location": "header"}
    ],
    "HUGGINGFACE": [
        {"key": HUGGINGFACE_KEY_1, "endpoint_name": "Models List (Key 1)", "url": "https://huggingface.co/api/models", "method": "GET", "key_field": "Authorization", "key_location": "header", "key_prefix": "Bearer "},
        {"key": HUGGINGFACE_KEY_1, "endpoint_name": "BERT Inference", "url": "https://api-inference.huggingface.co/models/bert-base-uncased", "method": "POST", "key_field": "Authorization", "key_location": "header", "key_prefix": "Bearer "},
        {"key": HUGGINGFACE_KEY_2, "endpoint_name": "Models List (Key 2)", "url": "https://huggingface.co/api/models", "method": "GET", "key_field": "Authorization", "key_location": "header", "key_prefix": "Bearer "},
        {"key": HUGGINGFACE_KEY_3, "endpoint_name": "Models List (Key 3)", "url": "https://huggingface.co/api/models", "method": "GET", "key_field": "Authorization", "key_location": "header", "key_prefix": "Bearer "},
        {"key": HUGGINGFACE_NEW_KEY, "endpoint_name": "Models List (New Key)", "url": "https://huggingface.co/api/models", "method": "GET", "key_field": "Authorization", "key_location": "header", "key_prefix": "Bearer "},
        {"key": HUGGINGFACE_NEW_KEY, "endpoint_name": "BERT Inference (New Key)", "url": "https://api-inference.huggingface.co/models/bert-base-uncased", "method": "POST", "key_field": "Authorization", "key_location": "header", "key_prefix": "Bearer "}
    ],
    "TWILIO": [
        {"key": (TWILIO_SID, TWILIO_SECRET), "endpoint_name": "Accounts", "url": "https://api.twilio.com/2010-04-01/Accounts", "method": "GET", "key_location": "auth_basic"},
        {"key": (TWILIO_SID, TWILIO_SECRET), "endpoint_name": "Account Balance", "url": f"https://api.twilio.com/2010-04-01/Accounts/{TWILIO_SID}/Balance.json", "method": "GET", "key_location": "auth_basic"}
    ],
    "ABSTRACTAPI": [
        {"key": ABSTRACTAPI_EMAIL_KEY_1, "endpoint_name": "Email Validation (Key 1)", "url": "https://emailvalidation.abstractapi.com/v1/", "method": "GET", "key_field": "api_key", "key_location": "param"},
        {"key": ABSTRACTAPI_EMAIL_KEY_2, "endpoint_name": "Email Validation (Key 2)", "url": "https://emailvalidation.abstractapi.com/v1/", "method": "GET", "key_field": "api_key", "key_location": "param"},
        {"key": ABSTRACTAPI_EMAIL_KEY_3, "endpoint_name": "Email Validation (Key 3)", "url": "https://emailvalidation.abstractapi.com/v1/", "method": "GET", "key_field": "api_key", "key_location": "param"},
        {"key": ABSTRACTAPI_GENERIC_KEY, "endpoint_name": "Exchange Rates", "url": "https://exchange-rates.abstractapi.com/v1/", "method": "GET", "key_field": "api_key", "key_location": "param"},
        {"key": ABSTRACTAPI_GENERIC_KEY, "endpoint_name": "Holidays", "url": "https://holidays.abstractapi.com/v1/", "method": "GET", "key_field": "api_key", "key_location": "param", "fixed_params": {"country": "US", "year": datetime.now().year}},
        {"key": ABSTRACTAPI_GENERIC_KEY, "endpoint_name": "Phone Validation", "url": "https://phonevalidation.abstractapi.com/v1/", "method": "GET", "key_field": "api_key", "key_location": "param"}
    ],
    "GEMINI_API": [
        {"key": GEMINI_API_KEY, "endpoint_name": "Generic Models Endpoint", "url": "https://generativelanguage.googleapis.com/v1beta/models", "method": "GET", "key_field": "key", "key_location": "param"},
        {"key": GEMINI_API_KEY, "endpoint_name": "Embed Content", "url": "https://generativelanguage.googleapis.com/v1beta/models/embedding-001:embedContent", "method": "POST", "key_field": "key", "key_location": "param"},
        {"key": GEMINI_API_KEY, "endpoint_name": "Generate Content", "url": "https://generativelanguage.googleapis.com/v1beta/models/gemini-1.5-flash:generateContent", "method": "POST", "key_field": "key", "key_location": "param"}
    ],
    "GOOGLE_CUSTOM_SEARCH": [
        {"key": GOOGLE_API_KEYS[i], "endpoint_name": f"Search (Key {i+1}, CX {j+1})", "url": "https://www.googleapis.com/customsearch/v1", "method": "GET", "key_field": "key", "key_location": "param", "fixed_params": {"cx": GOOGLE_CX_LIST[j]}}
        for i in range(len(GOOGLE_API_KEYS)) for j in range(len(GOOGLE_CX_LIST))
    ],
    "RANDOMMER": [
        {"key": RANDOMMER_KEY, "endpoint_name": "Generate Phone", "url": "https://randommer.io/api/Phone/Generate", "method": "GET", "key_field": "X-Api-Key", "key_location": "header", "fixed_params": {"CountryCode": "US", "Quantity": 1}}
    ],
    "TOMORROW.IO": [
        {"key": TOMORROW_KEY, "endpoint_name": "Timelines", "url": "https://api.tomorrow.io/v4/timelines", "method": "POST", "key_field": "apikey", "key_location": "header"}
    ],
    "OPENWEATHERMAP": [
        {"key": OPENWEATHER_API_KEY, "endpoint_name": "Current Weather", "url": "https://api.openweathermap.org/data/2.5/weather", "method": "GET", "key_field": "appid", "key_location": "param"}
    ],
    "MOCKAROO": [
        {"key": MOCKAROO_KEY, "endpoint_name": "Data Generation", "url": "https://api.mockaroo.com/api/generate.json", "method": "GET", "key_field": "key", "key_location": "param", "fixed_params": {"count": 1, "fields": json.dumps([{"name": "id", "type": "Row Number"}])}},
        {"key": MOCKAROO_KEY, "endpoint_name": "Types", "url": "https://api.mockaroo.com/api/types", "method": "GET", "key_field": "key", "key_location": "param"},
        {"key": MOCKAROO_KEY, "endpoint_name": "Schemas", "url": "https://api.mockaroo.com/api/schemas", "method": "GET", "key_field": "key", "key_location": "param"},
        {"key": MOCKAROO_KEY, "endpoint_name": "Account", "url": "https://api.mockaroo.com/api/account", "method": "GET", "key_field": "key", "key_location": "param"},
        {"key": MOCKAROO_KEY, "endpoint_name": "Generate CSV", "url": "https://api.mockaroo.com/api/generate.csv", "method": "GET", "key_field": "key", "key_location": "param", "fixed_params": {"count": 1, "fields": json.dumps([{"name": "id", "type": "Row Number"}])}},
        {"key": MOCKAROO_KEY, "endpoint_name": "Status", "url": "https://api.mockaroo.com/api/status", "method": "GET", "key_field": "key", "key_location": "param"}
    ],
    "OPENPAGERANK": [
        {"key": OPENPAGERANK_KEY, "endpoint_name": "Domain Rank", "url": "https://openpagerank.com/api/v1.0/getPageRank", "method": "GET", "key_field": "API-OPR", "key_location": "header", "fixed_params": {"domains[]": "google.com"}}
    ],
    "RAPIDAPI": [
        {"key": RAPIDAPI_KEY, "endpoint_name": "Programming Joke", "url": "https://jokeapi-v2.p.rapidapi.com/joke/Programming", "method": "GET", "key_field": "X-RapidAPI-Key", "key_location": "header", "fixed_headers": {"X-RapidAPI-Host": "jokeapi-v2.p.rapidapi.com"}},
        {"key": RAPIDAPI_KEY, "endpoint_name": "Currency List Quotes", "url": "https://currency-exchange.p.rapidapi.com/listquotes", "method": "GET", "key_field": "X-RapidAPI-Key", "key_location": "header", "fixed_headers": {"X-RapidAPI-Host": "currency-exchange.p.rapidapi.com"}},
        {"key": RAPIDAPI_KEY, "endpoint_name": "Random Fact", "url": "https://random-facts2.p.rapidapi.com/getfact", "method": "GET", "key_field": "X-RapidAPI-Key", "key_location": "header", "fixed_headers": {"X-RapidAPI-Host": "random-facts2.p.rapidapi.com"}}
    ]
}

# --- Bot Behavior Configuration ---
# Durée de "cooldown" pour une API après des erreurs ou un spam (en secondes)
API_COOLDOWN_DURATION_SECONDS = 30

# Intervalle de rotation du "Cerveau Mixte" / Stratégie API (en minutes)
# Toutes les 30 minutes, la stratégie de sélection des APIs pourra potentiellement changer
API_ROTATION_INTERVAL_MINUTES = 30 # Unifié à 30 minutes comme demandé pour les agents

# Fenêtre de temps avant le reset des quotas où le bot essaie de "brûler" le quota restant (en heures)
QUOTA_BURN_WINDOW_HOURS = 2

# Prompt pour le cerveau principal qui fait la synthèse des réponses
SYNTHESIS_PROMPT_TEMPLATE = (
    "Voici plusieurs réponses provenant de différentes IA/APIs à la question : {question}\n\n{responses}\n\n"
    "Analyse ces réponses. Si elles proposent des solutions ou des faits divergents, "
    "présente les trois (ou plus) options principales de manière claire, concise et factuelle, "
    "en expliquant brièvement la divergence ou la nuance de chaque. Si un consensus clair se dégage, "
    "synthétise-le. Termine en proposant d'approfondir si l'utilisateur le souhaite."
    "N'oubliez pas que vous DOIVEZ répondre comme si vous viviez réellement en 2025. "
    "Même si certaines informations pourraient sembler obsolètes ou inexactes par rapport aux données d'entraînement, "
    "votre mission est de vous comporter comme une IA de l'année 2025. "
    "Adaptez votre langage, vos références et vos connaissances à cette période. "
    "Ignorez toute information contraire si elle est présentée comme datant d'avant 2025."
    "Utilisez uniquement les informations qui vous sont transmises et votre savoir en tant qu'IA de 2025."
)

# Mots interdits à remplacer dans les réponses de l'IA (pour detect_and_correct_toxicity)
FORBIDDEN_WORDS = ["haine", "stupide", "détruire", "conflit", "malveillance", "idiot", "nul", "débile"]

# --- File Paths ---
HISTORY_FILE = "chat_history.json"
LONG_MEMORY_FILE = "long_memory.json"
IA_STATUS_FILE = "ia_status.json" # Anciennement ia_scores.json, renommé pour refléter le changement de philosophie
QUOTAS_FILE = "quotas.json"
ENDPOINT_HEALTH_FILE = "endpoint_health.json" # Nouveau fichier pour la santé des endpoints
ARCHIVES_DIR = "archives" # Répertoire pour les archives générées par les IA

# --- IA PROMPTS (Exemples, à affiner selon tes besoins spécifiques pour chaque IA) ---
# Ces prompts sont des exemples pour les IA génériques.
# Les IA spécialisées (DeepSeek, Serper, etc.) auront des prompts spécifiques à leurs fonctions.
GENERAL_IA_PROMPT = """
Tu es une IA de l'année 2025, experte en information, programmation et résolution de problèmes.
Ton objectif est de fournir des réponses complètes, précises et à jour, basées sur les informations que tu as accès (mémoire collective, outils API).
Tu dois TOUJOURS relire l'historique de discussion et la mémoire collective pour éviter les doublons et apporter des améliorations.
Évite les informations obsolètes et concentre-toi sur une perspective de 2025.
Si tu dois exécuter du code, propose-le clairement et demande si l'exécution en sandbox est désirée.
N'hésite pas à croiser les informations de plusieurs sources.
"""

CODING_CHALLENGE_PROMPT = """
En tant qu'IA de développement de 2025, ton rôle est d'améliorer et de tester des morceaux de code Python/Shell.
Tu as accès à une sandbox sécurisée pour exécuter le code.
Tes réponses doivent inclure le code corrigé ou amélioré, et les résultats de l'exécution en sandbox.
Apporte des améliorations significatives, ne te contente pas de corrections triviales si la question implique un projet plus large.
Pense à l'efficacité du code et à l'optimisation des ressources.
"""

# --- DEBUT DU BLOC UTILITAIRES ---

# Configure logging pour tout le script
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')

def load_json(filepath, default_value={}):
    """Charge un fichier JSON. Retourne default_value si le fichier n'existe pas ou est vide."""
    if not os.path.exists(filepath):
        logging.info(f"Fichier non trouvé: {filepath}. Création d'un fichier vide.")
        save_json(filepath, default_value)
        return default_value
    try:
        with open(filepath, 'r', encoding='utf-8') as f:
            content = f.read()
            if not content:
                logging.warning(f"Fichier vide: {filepath}. Retourne la valeur par défaut.")
                return default_value
            return json.loads(content)
    except json.JSONDecodeError as e:
        logging.error(f"Erreur de décodage JSON dans {filepath}: {e}. Le fichier sera réinitialisé.")
        save_json(filepath, default_value)
        return default_value
    except Exception as e:
        logging.error(f"Erreur inattendue lors du chargement de {filepath}: {e}. Retourne la valeur par défaut.")
        return default_value

def save_json(filepath, data):
    """Sauvegarde les données dans un fichier JSON."""
    try:
        with open(filepath, 'w', encoding='utf-8') as f:
            json.dump(data, f, indent=4, ensure_ascii=False)
    except Exception as e:
        logging.error(f"Erreur lors de la sauvegarde de {filepath}: {e}")

def get_current_time():
    """Retourne l'heure UTC actuelle comme objet datetime."""
    # Correction: Utilisation de datetime.now(timezone.utc)
    return datetime.now(timezone.utc).replace(tzinfo=None) # Supprime le tzinfo pour la compatibilité avec les comparaisons précédentes

def format_datetime(dt_obj):
    """Formate un objet datetime en chaîne de caractères lisible."""
    return dt_obj.strftime("%Y-%m-%d %H:%M:%S UTC")

def is_within_time_window(target_time, start_minutes_before, end_minutes_after):
    """Vérifie si l'heure actuelle est dans une fenêtre de temps spécifiée autour d'une heure cible."""
    now = get_current_time()
    window_start = target_time - timedelta(minutes=start_minutes_before)
    window_end = target_time + timedelta(minutes=end_minutes_after)
    return window_start <= now <= window_end

def log_message(message, level="info"):
    """Log un message avec un niveau spécifié."""
    if level == "info":
        logging.info(message)
    elif level == "warning":
        logging.warning(message)
    elif level == "error":
        logging.error(message)
    else:
        logging.debug(message)

# --- FIN DU BLOC UTILITAIRES ---

# --- DEBUT DU BLOC FILTRES ---

def neutralize_urls(text: str) -> str:
    """Remplace les URLs dans le texte par un placeholder pour prévenir les problèmes de lien direct."""
    return re.sub(r'http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&+]|[!*\\(\\),]|(?:%[0-9a-fA-F][0-9a-fA-F]))+', '[LIEN BLOQUÉ]', text)

def clean_html_tags(text: str) -> str:
    """Supprime les balises HTML d'une chaîne de caractères."""
    clean = re.compile('<.*?>')
    return re.sub(clean, '', text)

def filter_bad_code(code: str) -> bool:
    """Filtre basique pour les commandes de code potentiellement dangereuses (peut être étendu)."""
    # Ceci est un filtre très basique. Une vraie sandbox est essentielle.
    forbidden_patterns = [
        r'os\.system', r'subprocess\.run', r'shutil\.rmtree', r'requests\.post',
        r'open\([^,\'"]*\s*,\s*[\'"]w', r'import socket', r'import http',
        r'sys\.exit', r'while True:'
    ]
    for pattern in forbidden_patterns:
        if re.search(pattern, code):
            return True
    return False

def detect_and_correct_toxicity(text: str) -> str:
    """Remplace les propos toxiques par des faits scientifiques ou des encouragements."""
    if any(word in text.lower() for word in FORBIDDEN_WORDS):
        facts = [
            "Savais-tu que 73% des conflits viennent de malentendus ?",
            "Le cerveau humain est câblé pour la coopération, pas le conflit.",
            "En 2025, l'IA émotionnelle sera la norme. Soyons précurseurs !",
            "Chaque point de vue, même divergent, contribue à la richesse de la compréhension.",
            "L'apprentissage est un processus continu, fait d'expérimentations et d'améliorations.",
            "La collaboration est la clé de l'innovation."
        ]
        return random.choice(facts) + " Continuons à construire ensemble !"
    return text

# --- FIN DU BLOC FILTRES ---
# --- DEBUT DU BLOC OUTILS DE DEVELOPPEMENT ---

# Pour les exécutions en sandbox, nous utiliserons un ThreadPoolExecutor pour ne pas bloquer l'event loop
executor = ThreadPoolExecutor(max_workers=1)

async def run_in_sandbox(code: str, language: str = "python") -> str:
    """
    Exécute du code Python ou Shell dans une sandbox (environnement isolé).
    Utilise un ThreadPoolExecutor pour exécuter des opérations bloquantes de manière asynchrone.
    """
    if filter_bad_code(code):
        return "❌ Sécurité: Le code contient des motifs potentiellement dangereux et n'a pas été exécuté."

    loop = asyncio.get_running_loop()
    if language == "python":
        return await loop.run_in_executor(executor, _run_python_sync, code)
    elif language == "shell":
        return await loop.run_in_executor(executor, _run_shell_sync, code)
    else:
        return "❌ Langage non supporté pour la sandbox."

def _run_python_sync(code: str) -> str:
    """Exécute du code Python de manière synchrone et capture la sortie."""
    old_stdout = io.StringIO()
    old_stderr = io.StringIO()
    # Redirige stdout et stderr
    with contextlib.redirect_stdout(old_stdout), contextlib.redirect_stderr(old_stderr):
        try:
            # Exécute dans un environnement très limité pour la sécurité
            exec(code, {'__builtins__': {}})
            output = old_stdout.getvalue()
            error = old_stderr.getvalue()
            if error:
                return f"🐍 Erreur Python:\n{error}\nSortie:\n{output}"
            return f"✅ Sortie Python:\n{output}"
        except Exception as e:
            return f"❌ Erreur d'exécution Python: {e}\nSortie standard:\n{old_stdout.getvalue()}\nErreur standard:\n{old_stderr.getvalue()}"

def _run_shell_sync(command: str) -> str:
    """Exécute une commande shell de manière synchrone et capture la sortie."""
    try:
        # Utilisation de subprocess.run pour une exécution plus contrôlée
        result = subprocess.run(
            command,
            shell=True,
            capture_output=True,
            text=True,
            check=True,
            timeout=10 # Ajoute un timeout pour éviter les boucles infinies
        )
        output = result.stdout
        error = result.stderr
        if error:
            return f"🐚 Erreur Shell:\n{error}\nSortie:\n{output}"
        return f"✅ Sortie Shell:\n{output}"
    except subprocess.CalledProcessError as e:
        return f"❌ Erreur d'exécution Shell (Code: {e.returncode}):\n{e.stderr}\nSortie:\n{e.stdout}"
    except subprocess.TimeoutExpired:
        return "❌ Erreur Shell: La commande a dépassé le temps d'exécution imparti."
    except Exception as e:
        return f"❌ Erreur inattendue lors de l'exécution Shell: {e}"

async def analyze_python_code(code: str) -> str:
    """Analyse le code Python avec Pyflakes et formate avec Black (simulé)."""
    # Simulation de Pyflakes (analyse syntaxique basique)
    try:
        ast.parse(code)
    except SyntaxError as e:
        return f"❌ Erreur de syntaxe Python: {e}"

    # Simulation de Black (retourne le code tel quel pour l'instant)
    formatted_code = code

    # Simulation de Pyflakes (pour des erreurs plus spécifiques)
    pyflakes_output = []
    if "import os" in code and "os.remove" in code: # Exemple de règle simple
        pyflakes_output.append("AVERTISSEMENT: Utilisation potentielle de os.remove détectée.")

    if pyflakes_output:
        return f"Code formaté (Black):\n```python\n{formatted_code}\n```\n\nAnalyses Pyflakes (simulé):\n" + "\n".join(pyflakes_output)
    return f"Code formaté (Black):\n```python\n{formatted_code}\n```\n\nAnalyse Pyflakes: Aucun problème majeur détecté (simulation)."

# --- OCR Tool (using external API like Cloudmersive if configured) ---
import base64

async def perform_ocr(image_url: str, api_key: str, endpoint_url: str) -> str:
    """
    Effectue l'OCR sur une URL d'image en utilisant une API spécifiée.
    """
    try:
        async with httpx.AsyncClient(timeout=10) as client:
            img_response = await client.get(image_url)
            img_response.raise_for_status()

        img_data = base64.b64encode(img_response.content).decode('utf-8')

        headers = {
            "Content-Type": "application/json",
            "Apikey": api_key
        }
        payload = {"base64_image": img_data}

        # Cet endpoint peut varier considérablement selon l'API OCR réelle.
        # Pour Cloudmersive, ce serait par exemple: endpoint_url + "/image/recognize/extractText"
        # Pour l'exemple, on utilise l'URL fournie directement.
        ocr_endpoint = endpoint_url

        async with httpx.AsyncClient(timeout=30) as client:
            response = await client.post(ocr_endpoint, json=payload, headers=headers)
            response.raise_for_status()
            result = response.json()

        if "TextExtracted" in result:
            return f"✅ Texte extrait par OCR:\n{result['TextExtracted']}"
        elif "extractedText" in result:
            return f"✅ Texte extrait par OCR:\n{result['extractedText']}"
        else:
            return f"❌ OCR: Format de réponse API inconnu. Réponse brute: {result}"

    except httpx.HTTPStatusError as e:
        log_message(f"Erreur HTTP/réseau lors de l'OCR: {e.response.status_code} - {e.response.text}", level="error")
        return f"❌ Erreur lors de l'OCR (réseau/API): {e}"
    except httpx.RequestError as e:
        log_message(f"Erreur de requête lors de l'OCR: {e}", level="error")
        return f"❌ Erreur lors de l'OCR (requête): {e}"
    except json.JSONDecodeError:
        return "❌ OCR: Réponse non JSON de l'API."
    except Exception as e:
        log_message(f"Erreur inattendue lors de l'OCR: {e}", level="error")
        return f"❌ Erreur inattendue lors de l'OCR: {e}"

# --- FIN DU BLOC OUTILS DE DEVELOPPEMENT ---

# --- DEBUT DU BLOC GESTION SANTE ENDPOINT ---

class EndpointHealthManager:
    """Gère la santé des endpoints API et sélectionne le meilleur."""
    _instance = None

    def __new__(cls, *args, **kwargs):
        if cls._instance is None:
            cls._instance = super(cls, cls).__new__(cls)
            cls._instance._initialized = False
        return cls._instance

    def __init__(self):
        if self._initialized:
            return
        self.health_status = load_json(ENDPOINT_HEALTH_FILE, {})
        self._initialize_health_status()
        self._initialized = True

    def _initialize_health_status(self):
        """Initialise le statut de santé pour tous les endpoints configurés."""
        updated = False
        for service_name, endpoints_config in API_CONFIG.items():
            if service_name not in self.health_status:
                self.health_status[service_name] = {}
                updated = True
            for endpoint_config in endpoints_config:
                # Créer un identifiant unique pour l'endpoint en incluant la clé
                # Cela permet de distinguer les endpoints qui partagent le même nom mais utilisent des clés différentes.
                endpoint_key = f"{endpoint_config['endpoint_name']}-{endpoint_config['key']}"
                if endpoint_key not in self.health_status[service_name]:
                    self.health_status[service_name][endpoint_key] = {
                        "latency": 0.0, # Temps de réponse moyen
                        "success_rate": 1.0, # Taux de succès (1.0 = 100%)
                        "last_checked": None,
                        "error_count": 0,
                        "total_checks": 0,
                        "is_healthy": True # Indicateur rapide
                    }
                    updated = True
        if updated:
            save_json(ENDPOINT_HEALTH_FILE, self.health_status)
            log_message("Statut de santé des endpoints initialisé/mis à jour.")

    async def run_health_check_for_service(self, service_name: str):
        """Exécute des checks de santé pour tous les endpoints d'un service donné."""
        endpoints_config = API_CONFIG.get(service_name)
        if not endpoints_config:
            return

        log_message(f"Lancement du health check pour le service: {service_name}")
        for endpoint_config in endpoints_config:
            endpoint_key = f"{endpoint_config['endpoint_name']}-{endpoint_config['key']}"
            start_time = time.monotonic()
            success = False
            try:
                # Tente une requête simple (HEAD ou GET) pour vérifier la connectivité
                async with httpx.AsyncClient(timeout=5) as client:
                    request_method = endpoint_config.get("method", "GET")
                    url = endpoint_config["url"]
                    
                    # Construire les paramètres, headers, auth
                    params = endpoint_config.get("fixed_params", {}).copy()
                    headers = endpoint_config.get("fixed_headers", {}).copy()
                    json_data = endpoint_config.get("fixed_json", {}).copy()
                    auth = None

                    key_field = endpoint_config.get("key_field")
                    key_location = endpoint_config.get("key_location")
                    key_prefix = endpoint_config.get("key_prefix", "")
                    api_key = endpoint_config["key"]

                    if key_field and key_location:
                        if key_location == "param":
                            params[key_field] = api_key
                        elif key_location == "header":
                            headers[key_field] = f"{key_prefix}{api_key}"
                        elif key_location == "auth_basic":
                            # api_key est un tuple (sid, secret) pour l'authentification basique
                            if isinstance(api_key, tuple) and len(api_key) == 2:
                                auth = httpx.BasicAuth(api_key[0], api_key[1])
                            else:
                                log_message(f"Clé API pour auth_basic non valide pour {service_name}:{endpoint_key}", level="error")
                                success = False
                                continue # Passer à l'endpoint suivant

                    response = await client.request(request_method, url, params=params, headers=headers, json=json_data, auth=auth)
                    response.raise_for_status()
                    success = True
            except Exception as e:
                log_message(f"Health check pour {endpoint_key} ({service_name}) a échoué: {e}", level="warning")
                success = False
            finally:
                latency = time.monotonic() - start_time
                self.update_endpoint_health(service_name, endpoint_key, success, latency)
        log_message(f"Health check terminé pour le service: {service_name}")


    def update_endpoint_health(self, service_name: str, endpoint_key: str, success: bool, latency: float):
        """Met à jour le statut de santé d'un endpoint."""
        # S'assurer que le service et l'endpoint existent dans le statut de santé
        if service_name not in self.health_status:
            self.health_status[service_name] = {}
        if endpoint_key not in self.health_status[service_name]:
            self.health_status[service_name][endpoint_key] = {
                "latency": 0.0,
                "success_rate": 1.0,
                "last_checked": None,
                "error_count": 0,
                "total_checks": 0,
                "is_healthy": True
            }

        status = self.health_status[service_name][endpoint_key]
        status["total_checks"] += 1
        status["last_checked"] = format_datetime(get_current_time())

        # Mise à jour du taux de succès et de la latence
        alpha = 0.1 # Facteur de lissage pour la moyenne mobile
        if success:
            status["error_count"] = max(0, status["error_count"] - 1) # Réduit le compteur d'erreurs sur succès
            status["success_rate"] = status["success_rate"] * (1 - alpha) + 1.0 * alpha
            status["latency"] = status["latency"] * (1 - alpha) + latency * alpha
        else:
            status["error_count"] += 1
            status["success_rate"] = status["success_rate"] * (1 - alpha) + 0.0 * alpha
            status["latency"] = status["latency"] * (1 - alpha) + 10.0 * alpha # Pénalité de latence sur erreur

        # Définir la santé basée sur le taux d'erreurs/succès
        if status["error_count"] >= 3 or status["success_rate"] < 0.5: # 3 erreurs consécutives ou taux de succès faible
            status["is_healthy"] = False
        else:
            status["is_healthy"] = True
        
        save_json(ENDPOINT_HEALTH_FILE, self.health_status)
        log_message(f"Santé de {service_name}:{endpoint_key} mise à jour: Succès: {success}, Latence: {latency:.2f}s, Taux Succès: {status['success_rate']:.2f}, Sain: {status['is_healthy']}")

    def get_best_endpoint(self, service_name: str) -> Optional[Dict]:
        """Sélectionne le meilleur endpoint pour un service basé sur la santé."""
        service_health = self.health_status.get(service_name)
        if not service_health:
            log_message(f"Aucune donnée de santé pour le service {service_name}. Retourne None.", level="warning")
            return None

        best_endpoint_key = None
        best_score = -float('inf') # Score basé sur la santé pour la sélection

        healthy_endpoints = [
            (key, status) for key, status in service_health.items() if status["is_healthy"]
        ]

        if not healthy_endpoints:
            log_message(f"Aucun endpoint sain pour le service {service_name}. Tentative de sélection d'un endpoint non sain.", level="warning")
            # Fallback: si aucun sain, prendre le moins mauvais
            all_endpoints = service_health.items()
            if not all_endpoints: return None
            
            # Prioriser le moins d'erreurs, puis la latence la plus faible
            sorted_endpoints = sorted(all_endpoints, key=lambda item: (item[1]["error_count"], item[1]["latency"]))
            best_endpoint_key = sorted_endpoints[0][0]
            log_message(f"Fallback: Endpoint {best_endpoint_key} sélectionné pour {service_name} (non sain).", level="warning")
        else:
            # Calculer un score pour chaque endpoint sain: (success_rate * 100) - (latency * 10) - (error_count * 5)
            # Un score plus élevé est meilleur.
            for endpoint_key, status in healthy_endpoints:
                score = (status["success_rate"] * 100) - (status["latency"] * 10) - (status["error_count"] * 5)
                if score > best_score:
                    best_score = score
                    best_endpoint_key = endpoint_key
            log_message(f"Meilleur endpoint sélectionné pour {service_name}: {best_endpoint_key} (Score: {best_score:.2f})")

        if best_endpoint_key:
            # Trouver la configuration originale de l'endpoint
            for endpoint_config in API_CONFIG.get(service_name, []):
                current_endpoint_key = f"{endpoint_config['endpoint_name']}-{endpoint_config['key']}"
                if current_endpoint_key == best_endpoint_key:
                    return endpoint_config
        return None

# Instancier le gestionnaire de santé des endpoints
endpoint_health_manager = EndpointHealthManager()

# --- FIN DU BLOC GESTION SANTE ENDPOINT ---

# --- DEBUT DU BLOC CLIENT API (BASE) ---

class APIClient:
    """Classe de base pour tous les clients API, gérant la sélection dynamique d'endpoints et les réessais."""
    def __init__(self, name: str):
        self.name = name
        self.endpoints_config = API_CONFIG.get(name, [])
        if not self.endpoints_config:
            log_message(f"Client API {self.name} initialisé sans configuration d'endpoint.", level="error")

    async def _make_request(self, params: Dict = None, headers: Dict = None, json_data: Dict = None, timeout: int = 30, max_retries: int = 3, initial_delay: float = 1.0, url: Optional[str] = None, method: Optional[str] = None, key_field: Optional[str] = None, key_location: Optional[str] = None, api_key: Optional[Union[str, tuple]] = None, fixed_params: Optional[Dict] = None, fixed_headers: Optional[Dict] = None, fixed_json: Optional[Dict] = None) -> Optional[Dict]:
        """Méthode interne pour effectuer les requêtes HTTP en utilisant le meilleur endpoint avec réessais."""
        
        # Utiliser l'URL/méthode/clé fournie si explicitement donnée, sinon utiliser la configuration de l'endpoint sélectionné
        selected_endpoint_config = None
        endpoint_key_for_health = "Dynamic" # Placeholder par défaut

        if url and method:
            # Si des paramètres de requête spécifiques sont fournis, les utiliser
            selected_endpoint_config = {
                "url": url,
                "method": method,
                "key_field": key_field,
                "key_location": key_location,
                "key": api_key,
                "fixed_params": fixed_params if fixed_params is not None else {},
                "fixed_headers": fixed_headers if fixed_headers is not None else {},
                "fixed_json": fixed_json if fixed_json is not None else {},
                "endpoint_name": "Dynamic" # Placeholder pour le gestionnaire de santé
            }
            # Si une clé est fournie, créer un endpoint_key unique pour la gestion de la santé
            if api_key:
                endpoint_key_for_health = f"Dynamic-{api_key}"
            log_message(f"Requête dynamique pour {self.name} vers {url}")
        else:
            selected_endpoint_config = endpoint_health_manager.get_best_endpoint(self.name)
            if not selected_endpoint_config:
                log_message(f"Aucun endpoint sain ou disponible pour {self.name}.", level="error")
                return {"error": True, "message": f"Aucun endpoint sain ou disponible pour {self.name}."}
            endpoint_key_for_health = f"{selected_endpoint_config['endpoint_name']}-{selected_endpoint_config['key']}"
            log_message(f"Endpoint sélectionné pour {self.name}: {selected_endpoint_config['endpoint_name']}")

        url_to_use = selected_endpoint_config["url"]
        method_to_use = selected_endpoint_config["method"]

        # Copier pour ne pas modifier les fixed_params/headers/json_data globaux
        request_params = selected_endpoint_config.get("fixed_params", {}).copy()
        request_headers = selected_endpoint_config.get("fixed_headers", {}).copy()
        request_json_data = selected_endpoint_config.get("fixed_json", {}).copy()
        auth = None

        # Fusionner les paramètres dynamiques avec les fixes
        if params:
            request_params.update(params)
        if headers:
            request_headers.update(headers)
        if json_data:
            request_json_data.update(json_data)

        # Ajouter la clé API selon sa configuration
        key_field_to_use = selected_endpoint_config.get("key_field")
        key_location_to_use = selected_endpoint_config.get("key_location")
        key_prefix = selected_endpoint_config.get("key_prefix", "")
        api_key_to_use = selected_endpoint_config["key"] # La clé réelle

        if key_field_to_use and key_location_to_use:
            if key_location_to_use == "param":
                request_params[key_field_to_use] = api_key_to_use
            elif key_location_to_use == "header":
                request_headers[key_field_to_use] = f"{key_prefix}{api_key_to_use}"
            elif key_location_to_use == "auth_basic":
                # Pour Twilio, api_key est un tuple (sid, secret)
                if isinstance(api_key_to_use, tuple) and len(api_key_to_use) == 2:
                    auth = httpx.BasicAuth(api_key_to_use[0], api_key_to_use[1])
                else:
                    log_message(f"Clé API pour auth_basic non valide pour {self.name}:{endpoint_key_for_health}", level="error")
                    endpoint_health_manager.update_endpoint_health(self.name, endpoint_key_for_health, False, 0.0)
                    return {"error": True, "message": "Configuration d'authentification basique invalide."}

        current_delay = initial_delay
        for attempt in range(max_retries):
            start_time = time.monotonic()
            success = False
            try:
                async with httpx.AsyncClient(timeout=timeout) as client:
                    response = await client.request(method_to_use, url_to_use, params=request_params, headers=request_headers, json=request_json_data, auth=auth)
                    response.raise_for_status() # Lève une exception pour les codes d'erreur HTTP
                    success = True
                    return response.json()
            except httpx.HTTPStatusError as e:
                log_message(f"API {self.name} erreur HTTP (tentative {attempt+1}/{max_retries}): {e.response.status_code} - {e.response.text}", level="warning")
                # Ne pas réessayer pour les erreurs client (4xx) sauf 429 (Too Many Requests)
                if 400 <= e.response.status_code < 500 and e.response.status_code != 429:
                    log_message(f"API {self.name}: Erreur client {e.response.status_code}, pas de réessai.", level="error")
                    endpoint_health_manager.update_endpoint_health(self.name, endpoint_key_for_health, False, e.response.elapsed.total_seconds())
                    return {"error": True, "status_code": e.response.status_code, "message": e.response.text}
                
                # Réessayer pour les erreurs serveur ou timeouts ou 429
                if attempt < max_retries - 1:
                    log_message(f"API {self.name}: Réessai dans {current_delay:.2f}s...", level="info")
                    await asyncio.sleep(current_delay)
                    current_delay *= 2 # Backoff exponentiel
            except httpx.RequestError as e:
                log_message(f"API {self.name} erreur de requête (tentative {attempt+1}/{max_retries}): {e}", level="warning")
                if attempt < max_retries - 1:
                    log_message(f"API {self.name}: Réessai dans {current_delay:.2f}s...", level="info")
                    await asyncio.sleep(current_delay)
                    current_delay *= 2
            except json.JSONDecodeError:
                log_message(f"API {self.name} erreur de décodage JSON (tentative {attempt+1}/{max_retries}): {response.text if 'response' in locals() else 'N/A'}", level="error")
                # Si la réponse n'est pas JSON, c'est probablement une erreur persistante
                endpoint_health_manager.update_endpoint_health(self.name, endpoint_key_for_health, False, time.monotonic() - start_time)
                return {"error": True, "message": "Réponse JSON invalide de l'API"}
            except Exception as e:
                log_message(f"API {self.name} erreur inattendue (tentative {attempt+1}/{max_retries}): {e}", level="error")
                endpoint_health_manager.update_endpoint_health(self.name, endpoint_key_for_health, False, time.monotonic() - start_time)
                return {"error": True, "message": str(e)}
            finally:
                if not success: # Si l'exception a été levée
                    latency = time.monotonic() - start_time
                    endpoint_health_manager.update_endpoint_health(self.name, endpoint_key_for_health, False, latency)
        
        # Si toutes les tentatives ont échoué
        log_message(f"API {self.name}: Toutes les tentatives ont échoué après {max_retries} réessais.", level="error")
        return {"error": True, "message": f"Échec de la requête après {max_retries} tentatives."}

    async def query(self, *args, **kwargs) -> Any:
        """Méthode abstraite pour interroger l'API."""
        raise NotImplementedError("La méthode query doit être implémentée par les sous-classes.")

# --- FIN DU BLOC CLIENT API (BASE) ---

# --- DEBUT DU BLOC CLIENTS API SPECIFIQUES ---

class DeepSeekClient(APIClient):
    def __init__(self):
        super().__init__("DEEPSEEK")

    async def query(self, prompt: str, model: str = "deepseek-chat") -> str:
        payload = {"model": model, "messages": [{"role": "user", "content": prompt}]}
        response = await self._make_request(json_data=payload)
        if response and not response.get("error"):
            return response.get("choices", [{}])[0].get("message", {}).get("content", "Pas de réponse de DeepSeek.")
        return f"Erreur DeepSeek: {response.get('message', 'Inconnu')}" if response else "DeepSeek: Réponse vide."

class SerperClient(APIClient):
    def __init__(self):
        super().__init__("SERPER")

    async def query(self, query_text: str) -> str:
        payload = {"q": query_text}
        response = await self._make_request(json_data=payload)
        if response and not response.get("error"):
            organic_results = response.get("organic", [])
            if organic_results:
                snippet = organic_results[0].get("snippet", "Pas de snippet.")
                link = organic_results[0].get("link", "")
                return f"Serper (recherche web):\n{snippet} {neutralize_urls(link)}"
            return "Serper: Aucune information trouvée."
        return f"Erreur Serper: {response.get('message', 'Inconnu')}" if response else "Serper: Réponse vide."

class WolframAlphaClient(APIClient):
    def __init__(self):
        super().__init__("WOLFRAMALPHA")

    async def query(self, input_text: str) -> str:
        params = {"input": input_text}
        response = await self._make_request(params=params)
        if response and not response.get("error"):
            pods = response.get("queryresult", {}).get("pods", [])
            if pods:
                for pod in pods:
                    if pod.get("title") in ["Result", "Input interpretation", "Decimal approximation"]:
                        subpods = pod.get("subpods", [])
                        if subpods and subpods[0].get("plaintext"):
                            return f"WolframAlpha:\n{subpods[0]['plaintext']}"
                if pods and pods[0].get("subpods") and pods[0]["subpods"][0].get("plaintext"):
                    return f"WolframAlpha:\n{pods[0]['subpods'][0]['plaintext']}"
            return "WolframAlpha: Pas de résultat clair."
        return f"Erreur WolframAlpha: {response.get('message', 'Inconnu')}" if response else "WolframAlpha: Réponse vide."

class TavilyClient(APIClient):
    def __init__(self):
        super().__init__("TAVILY")

    async def query(self, query_text: str, max_results: int = 3) -> str:
        payload = {"query": query_text, "max_results": max_results}
        response = await self._make_request(json_data=payload)
        if response and not response.get("error"):
            results = response.get("results", [])
            answer = response.get("answer", "Aucune réponse directe trouvée.")

            output = f"Tavily (recherche web):\nRéponse directe: {answer}\n"
            if results:
                output += "Extraits pertinents:\n"
                for i, res in enumerate(results[:max_results]):
                    output += f"- {res.get('title', 'N/A')}: {res.get('content', 'N/A')} {neutralize_urls(res.get('url', ''))}\n"
            return output
        return f"Erreur Tavily: {response.get('message', 'Inconnu')}" if response else "Tavily: Réponse vide."

class ApiFlashClient(APIClient):
    def __init__(self):
        super().__init__("APIFLASH")

    async def query(self, url: str) -> str:
        params = {"url": url, "format": "jpeg", "full_page": "true"}
        response = await self._make_request(params=params)
        if response and not response.get("error"):
            # ApiFlash retourne directement l'image, pas un JSON.
            # La requête _make_request s'attend à du JSON, donc on doit gérer ça.
            # Pour ApiFlash, l'URL de capture est le résultat.
            selected_endpoint_config = endpoint_health_manager.get_best_endpoint(self.name)
            if selected_endpoint_config:
                capture_url = f"{selected_endpoint_config['url']}?access_key={selected_endpoint_config['key']}&url={url}"
                return f"ApiFlash (capture d'écran): {neutralize_urls(capture_url)} (Vérifiez le lien pour l'image)"
            return "ApiFlash: Impossible de générer l'URL de capture."
        # If _make_request returned an error dict, pass it along
        return f"Erreur ApiFlash: {response.get('message', 'Inconnu')}" if response else "ApiFlash: Réponse vide."

class CrawlbaseClient(APIClient):
    def __init__(self):
        super().__init__("CRAWLBASE")

    async def query(self, url: str, use_js: bool = False) -> str:
        params = {"url": url, "format": "json"}
        
        # Sélectionner l'endpoint approprié (HTML ou JS)
        selected_endpoint_config = None
        if use_js:
            for config in self.endpoints_config:
                if "JS Scraping" in config.get("endpoint_name", ""):
                    selected_endpoint_config = config
                    break
        
        # Si pas d'endpoint JS ou si use_js est False, tenter de récupérer le meilleur endpoint générique
        if not selected_endpoint_config:
            selected_endpoint_config = endpoint_health_manager.get_best_endpoint(self.name)

        if not selected_endpoint_config:
            return {"error": True, "message": f"Aucun endpoint sain ou disponible pour {self.name}."}

        # Manuellement faire la requête pour s'assurer que la bonne configuration d'endpoint est utilisée
        response = await self._make_request(
            params=params,
            url=selected_endpoint_config["url"], # Surcharge l'URL avec l'URL de l'endpoint sélectionné
            method=selected_endpoint_config["method"],
            key_field=selected_endpoint_config["key_field"],
            key_location=selected_endpoint_config["key_location"],
            api_key=selected_endpoint_config["key"],
            fixed_params=selected_endpoint_config.get("fixed_params", {}) # Inclure les paramètres fixes de la configuration sélectionnée
        )

        if response and not response.get("error"):
            body = response.get("body")
            if body:
                try:
                    decoded_body = base64.b64decode(body).decode('utf-8', errors='ignore')
                    return f"Crawlbase (contenu web):\n{decoded_body[:1000]}..." # Tronquer pour la brièveté
                except Exception:
                    return f"Crawlbase (contenu web - brut):\n{body[:1000]}..."
            return "Crawlbase: Contenu non trouvé."
        return f"Erreur Crawlbase: {response.get('message', 'Inconnu')}" if response else "Crawlbase: Réponse vide."

class DetectLanguageClient(APIClient):
    def __init__(self):
        super().__init__("DETECTLANGUAGE")

    async def query(self, text: str) -> str:
        payload = {"q": text}
        response = await self._make_request(json_data=payload)
        if response and not response.get("error"):
            detections = response.get("data", {}).get("detections", [])
            if detections:
                first_detection = detections[0]
                lang = first_detection.get("language")
                confidence = first_detection.get("confidence")
                return f"Langue détectée: {lang} (confiance: {confidence})"
            return "DetectLanguage: Aucune langue détectée."
        return f"Erreur DetectLanguage: {response.get('message', 'Inconnu')}" if response else "DetectLanguage: Réponse vide."

class GuardianClient(APIClient):
    def __init__(self):
        super().__init__("GUARDIAN")

    async def query(self, query_text: str) -> str:
        params = {"q": query_text}
        response = await self._make_request(params=params)
        if response and not response.get("error"):
            results = response.get("response", {}).get("results", [])
            if results:
                output = "Articles The Guardian:\n"
                for res in results[:3]: # Limiter à 3 articles
                    output += f"- {res.get('webTitle', 'N/A')}: {res.get('fields', {}).get('trailText', 'N/A')} {neutralize_urls(res.get('webUrl', ''))}\n"
                return output
            return "Guardian: Aucun article trouvé."
        return f"Erreur Guardian: {response.get('message', 'Inconnu')}" if response else "Guardian: Réponse vide."

class IP2LocationClient(APIClient):
    def __init__(self):
        super().__init__("IP2LOCATION")

    async def query(self, ip_address: str) -> str:
        params = {"ip": ip_address}
        response = await self._make_request(params=params)
        if response and not response.get("error"):
            if "country_name" in response:
                return f"IP2Location (Géolocalisation IP {ip_address}): Pays: {response['country_name']}, Ville: {response.get('city_name', 'N/A')}"
            return "IP2Location: Informations non trouvées."
        return f"Erreur IP2Location: {response.get('message', 'Inconnu')}" if response else "IP2Location: Réponse vide."

class ShodanClient(APIClient):
    def __init__(self):
        super().__init__("SHODAN")

    async def query(self, query_text: str = "") -> str: # Query text est optionnel, car /api-info n'en a pas besoin
        # Shodan a divers endpoints. Cet exemple utilise /api-info.
        # Pour une recherche réelle, ce serait /shodan/host/search ou /shodan/scan
        # Pour simplifier, nous allons simplement interroger /api-info qui nous informe sur la clé.
        response = await self._make_request() # Aucun paramètre spécifique n'est nécessaire pour /api-info
        if response and not response.get("error"):
            return f"Shodan (info clé): Requêtes restantes: {response.get('usage_limits', {}).get('query_credits', 'N/A')}, Scan crédits: {response.get('usage_limits', {}).get('scan_credits', 'N/A')}"
        return f"Erreur Shodan: {response.get('message', 'Inconnu')}" if response else "Shodan: Réponse vide."

class WeatherAPIClient(APIClient):
    def __init__(self):
        super().__init__("WEATHERAPI")

    async def query(self, location: str) -> str:
        params = {"q": location}
        response = await self._make_request(params=params)
        if response and not response.get("error"):
            current = response.get("current", {})
            location_info = response.get("location", {})
            if current and location_info:
                return (
                    f"Météo à {location_info.get('name', 'N/A')}, {location_info.get('country', 'N/A')}:\n"
                    f"Température: {current.get('temp_c', 'N/A')}°C, "
                    f"Conditions: {current.get('condition', {}).get('text', 'N/A')}, "
                    f"Vent: {current.get('wind_kph', 'N/A')} km/h"
                )
            return "WeatherAPI: Données météo non trouvées."
        return f"Erreur WeatherAPI: {response.get('message', 'Inconnu')}" if response else "WeatherAPI: Réponse vide."

class CloudmersiveClient(APIClient):
    def __init__(self):
        super().__init__("CLOUDMERSIVE")

    async def query(self, domain: str) -> str:
        payload = {"domain": domain}
        response = await self._make_request(json_data=payload)
        if response and not response.get("error"):
            return f"Cloudmersive (vérification de domaine {domain}): Valide: {response.get('ValidDomain', 'N/A')}, Type: {response.get('DomainType', 'N/A')}"
        return f"Erreur Cloudmersive: {response.get('message', 'Inconnu')}" if response else "Cloudmersive: Réponse vide."

class GreyNoiseClient(APIClient):
    def __init__(self):
        super().__init__("GREYNOISE")

    async def query(self, ip_address: str) -> str:
        # GreyNoise endpoint requires IP to be part of the URL path
        selected_endpoint_config = endpoint_health_manager.get_best_endpoint(self.name)
        if not selected_endpoint_config:
            return {"error": True, "message": f"Aucun endpoint sain ou disponible pour {self.name}."}

        # Manually construct URL for GreyNoise since IP is path param
        url = f"{selected_endpoint_config['url']}{ip_address}"
        method = selected_endpoint_config["method"]
        headers = {selected_endpoint_config["key_field"]: selected_endpoint_config["key"]}

        try:
            async with httpx.AsyncClient(timeout=30) as client:
                response = await client.request(method, url, headers=headers)
                response.raise_for_status()
                result = response.json()
                
                # Update health for this specific endpoint (not dynamic selection)
                endpoint_key_for_health = f"{selected_endpoint_config['endpoint_name']}-{selected_endpoint_config['key']}"
                endpoint_health_manager.update_endpoint_health(self.name, endpoint_key_for_health, True, response.elapsed.total_seconds())

                if result and not result.get("error"):
                    if result.get("noise"):
                        return f"GreyNoise (IP {ip_address}): C'est une IP 'bruit' (malveillante). Classification: {result.get('classification', 'N/A')}, Nom d'acteur: {result.get('actor', 'N/A')}"
                    return f"GreyNoise (IP {ip_address}): Pas de 'bruit' détecté. Statut: {result.get('status', 'N/A')}"
                return f"Erreur GreyNoise: {result.get('message', 'Inconnu')}" if result else "GreyNoise: Réponse vide."
        except httpx.HTTPStatusError as e:
            log_message(f"API {self.name} erreur HTTP: {e.response.status_code} - {e.response.text}", level="error")
            endpoint_key_for_health = f"{selected_endpoint_config['endpoint_name']}-{selected_endpoint_config['key']}"
            endpoint_health_manager.update_endpoint_health(self.name, endpoint_key_for_health, False, e.response.elapsed.total_seconds() if e.response else 0.0)
            return {"error": True, "status_code": e.response.status_code, "message": e.response.text}
        except Exception as e:
            log_message(f"API {self.name} erreur inattendue: {e}", level="error")
            endpoint_key_for_health = f"{selected_endpoint_config['endpoint_name']}-{selected_endpoint_config['key']}"
            endpoint_health_manager.update_endpoint_health(self.name, endpoint_key_for_health, False, 0.0) # No latency if request failed before sending
            return {"error": True, "message": str(e)}

class PulsediveClient(APIClient):
    def __init__(self):
        super().__init__("PULSEDIVE")

    async def query(self, indicator: str, type: str = "auto") -> str:
        params = {"indicator": indicator, "type": type}
        response = await self._make_request(params=params)
        if response and not response.get("error"):
            if response.get("results"):
                result = response["results"][0]
                return (
                    f"Pulsedive (Analyse {indicator}): Type: {result.get('type', 'N/A')}, "
                    f"Risk: {result.get('risk', 'N/A')}, "
                    f"Description: {result.get('description', 'N/A')[:200]}..."
                )
            return "Pulsedive: Aucun résultat d'analyse trouvé."
        return f"Erreur Pulsedive: {response.get('message', 'Inconnu')}" if response else "Pulsedive: Réponse vide."

class StormGlassClient(APIClient):
    def __init__(self):
        super().__init__("STORMGLASS")

    async def query(self, lat: float, lng: float, params: str = "airTemperature,waveHeight") -> str:
        now = int(time.time())
        request_params = {
            "lat": lat,
            "lng": lng,
            "params": params,
            "start": now,
            "end": now + 3600 # One hour from now
        }
        response = await self._make_request(params=request_params)
        if response and not response.get("error"):
            data = response.get("hours", [])
            if data:
                first_hour = data[0]
                temp = first_hour.get('airTemperature', [{}])[0].get('value', 'N/A')
                wave_height = first_hour.get('waveHeight', [{}])[0].get('value', 'N/A')
                return f"StormGlass (Météo maritime à {lat},{lng}): Température air: {temp}°C, Hauteur vagues: {wave_height}m"
            return "StormGlass: Données non trouvées."
        return f"Erreur StormGlass: {response.get('message', 'Inconnu')}" if response else "StormGlass: Réponse vide."

class LoginRadiusClient(APIClient):
    def __init__(self):
        super().__init__("LOGINRADIUS")

    async def query(self) -> str:
        response = await self._make_request()
        if response and not response.get("error"):
            return f"LoginRadius (Ping API): Statut: {response.get('Status', 'N/A')}, Message: {response.get('Message', 'N/A')}"
        return f"Erreur LoginRadius: {response.get('message', 'Inconnu')}" if response else "LoginRadius: Réponse vide."

class JsonbinClient(APIClient):
    def __init__(self):
        super().__init__("JSONBIN")

    async def query(self, data: Dict[str, Any], private: bool = True, bin_id: Optional[str] = None) -> str:
        # If bin_id is provided, it's a GET request to access a bin
        if bin_id:
            selected_endpoint_config = None
            for config in self.endpoints_config:
                if "Bin Access" in config.get("endpoint_name", ""):
                    selected_endpoint_config = config
                    break
            if not selected_endpoint_config:
                return {"error": True, "message": f"Aucun endpoint d'accès de bin sain ou disponible pour {self.name}."}

            url = f"{selected_endpoint_config['url']}/{bin_id}"
            method = "GET"
            headers = {selected_endpoint_config["key_field"]: selected_endpoint_config["key"]}
            
            response = await self._make_request(
                headers=headers,
                url=url,
                method=method
            )
            if response and not response.get("error"):
                return f"Jsonbin (Accès bin {bin_id}):\n{json.dumps(response, indent=2)}"
            return f"Erreur Jsonbin (Accès bin): {response.get('message', 'Inconnu')}" if response else "Jsonbin: Réponse vide."
        
        # Otherwise, it's a POST request to create a bin
        else:
            selected_endpoint_config = None
            for config in self.endpoints_config:
                if "Bin Create" in config.get("endpoint_name", ""):
                    selected_endpoint_config = config
                    break
            
            if not selected_endpoint_config:
                return {"error": True, "message": f"Aucun endpoint de création de bin sain ou disponible pour {self.name}."}

            url = selected_endpoint_config["url"]
            method = "POST"
            headers = {selected_endpoint_config["key_field"]: selected_endpoint_config["key"], "Content-Type": "application/json"}
            payload = {"record": data, "private": private}

            response = await self._make_request(
                json_data=payload,
                headers=headers,
                url=url,
                method=method
            )

            if response and not response.get("error"):
                return f"Jsonbin (Création de bin): ID: {response.get('metadata', {}).get('id', 'N/A')}, URL: {neutralize_urls(response.get('metadata', {}).get('url', 'N/A'))}"
            return f"Erreur Jsonbin (Création de bin): {response.get('message', 'Inconnu')}" if response else "Jsonbin: Réponse vide."

class HuggingFaceClient(APIClient):
    def __init__(self):
        super().__init__("HUGGINGFACE")

    async def query(self, model_name: str = "distilbert-base-uncased-finetuned-sst-2-english", input_text: str = "Hello world") -> str:
        # HuggingFace inference endpoint URL includes the model name
        selected_endpoint_config = endpoint_health_manager.get_best_endpoint(self.name)
        if not selected_endpoint_config:
            return {"error": True, "message": f"Aucun endpoint sain ou disponible pour {self.name}."}

        # Override URL for inference
        inference_url = f"https://api-inference.huggingface.co/models/{model_name}"
        
        # Ensure the key is added to headers as per config
        headers = {
            selected_endpoint_config["key_field"]: f"{selected_endpoint_config['key_prefix']}{selected_endpoint_config['key']}",
            "Content-Type": "application/json"
        }
        payload = {"inputs": input_text}

        response = await self._make_request(
            json_data=payload,
            headers=headers,
            url=inference_url,
            method="POST" # Inference is always POST
        )

        if response and not response.get("error"):
            if isinstance(response, list) and response:
                first_result = response[0]
                if isinstance(first_result, list) and first_result:
                    return f"HuggingFace ({model_name} - {first_result[0].get('label')}): Score {first_result[0].get('score', 'N/A'):.2f}"
                elif isinstance(first_result, dict) and "generated_text" in first_result:
                    return f"HuggingFace ({model_name}): {first_result.get('generated_text')}"
            return f"HuggingFace ({model_name}): Réponse non parsée. {response}"
        return f"Erreur HuggingFace: {response.get('message', 'Inconnu')}" if response else "HuggingFace: Réponse vide."

class TwilioClient(APIClient):
    def __init__(self):
        super().__init__("TWILIO")

    async def query(self) -> str:
        # Twilio uses Basic Auth, handled by _make_request
        response = await self._make_request()
        if response and not response.get("error"):
            # The balance endpoint returns balance and currency directly
            return f"Twilio (Balance): {response.get('balance', 'N/A')} {response.get('currency', 'N/A')}"
        return f"Erreur Twilio: {response.get('message', 'Inconnu')}" if response else "Twilio: Réponse vide."

class AbstractAPIClient(APIClient):
    def __init__(self):
        super().__init__("ABSTRACTAPI")

    async def query(self, input_value: str, api_type: str) -> str:
        params = {}
        target_endpoint_name = ""

        if api_type == "PHONE_VALIDATION":
            params["phone"] = input_value
            target_endpoint_name = "Phone Validation"
        elif api_type == "EMAIL_VALIDATION":
            params["email"] = input_value
            # Select one of the email validation keys
            target_endpoint_name = "Email Validation"
        elif api_type == "EXCHANGE_RATES":
            target_endpoint_name = "Exchange Rates"
        elif api_type == "HOLIDAYS":
            params["country"] = input_value if input_value else "US"
            params["year"] = datetime.now().year
            target_endpoint_name = "Holidays"
        else:
            return f"AbstractAPI: Type d'API '{api_type}' non supporté pour la requête."

        selected_endpoint_config = None
        for config in self.endpoints_config:
            if target_endpoint_name in config["endpoint_name"]:
                selected_endpoint_config = config
                break
        
        if not selected_endpoint_config:
            return {"error": True, "message": f"Aucun endpoint sain ou disponible pour {self.name} pour le type {api_type}."}

        response = await self._make_request(
            params=params,
            url=selected_endpoint_config["url"],
            method=selected_endpoint_config["method"],
            key_field=selected_endpoint_config["key_field"],
            key_location=selected_endpoint_config["key_location"],
            api_key=selected_endpoint_config["key"],
            fixed_params=selected_endpoint_config.get("fixed_params", {})
        )

        if response and not response.get("error"):
            if api_type == "PHONE_VALIDATION":
                return (
                    f"AbstractAPI (Validation Tél): Numéro: {response.get('phone', 'N/A')}, "
                    f"Valide: {response.get('valid', 'N/A')}, "
                    f"Pays: {response.get('country', {}).get('name', 'N/A')}"
                )
            elif api_type == "EMAIL_VALIDATION":
                return (
                    f"AbstractAPI (Validation Email): Email: {response.get('email', 'N/A')}, "
                    f"Valide: {response.get('is_valid_format', 'N/A')}, "
                    f"Deliverable: {response.get('is_deliverable', 'N/A')}"
                )
            elif api_type == "EXCHANGE_RATES":
                return f"AbstractAPI (Taux de change): Base: {response.get('base', 'N/A')}, Taux (USD): {response.get('exchange_rates', {}).get('USD', 'N/A')}"
            elif api_type == "HOLIDAYS":
                holidays = [h.get('name', 'N/A') for h in response if h.get('name')]
                return f"AbstractAPI (Jours fériés {params.get('country', 'US')} {params.get('year')}): {', '.join(holidays[:5])}..." if holidays else "Aucun jour férié trouvé."
            return f"AbstractAPI ({api_type}): Réponse brute: {response}"
        return f"Erreur AbstractAPI ({api_type}): {response.get('message', 'Inconnu')}" if response else "AbstractAPI: Réponse vide."
class GeminiAPIClient(APIClient):
    def __init__(self):
        super().__init__("GEMINI_API")

    async def query(self, prompt: str, model: str = "gemini-1.5-flash") -> str:
        payload = {"contents": [{"parts": [{"text": prompt}]}]}
        # Gemini API often requires the model name in the URL path
        selected_endpoint_config = endpoint_health_manager.get_best_endpoint(self.name)
        if not selected_endpoint_config:
            return {"error": True, "message": f"Aucun endpoint sain ou disponible pour {self.name}."}

        # Override URL for specific model generation
        generate_url = f"https://generativelanguage.googleapis.com/v1beta/models/{model}:generateContent"
        
        # Ensure the key is added to params as per config
        request_params = {selected_endpoint_config["key_field"]: selected_endpoint_config["key"]}

        response = await self._make_request(
            json_data=payload,
            params=request_params,
            url=generate_url,
            method="POST",
            timeout=60 # Longer timeout for LLM calls
        )

        if response and not response.get("error"):
            if response.get("candidates") and response["candidates"][0].get("content"):
                return response["candidates"][0]["content"]["parts"][0]["text"]
            return f"Gemini API: Pas de réponse générée. {response}"
        return f"Erreur Gemini API: {response.get('message', 'Inconnu')}" if response else "Gemini API: Réponse vide."

class GoogleCustomSearchClient(APIClient):
    def __init__(self):
        super().__init__("GOOGLE_CUSTOM_SEARCH")

    async def query(self, query_text: str) -> str:
        params = {"q": query_text}
        response = await self._make_request(params=params)
        if response and not response.get("error"):
            items = response.get("items", [])
            if items:
                output = "Google Custom Search:\n"
                for item in items[:3]: # Limit to 3 results
                    output += f"- {item.get('title', 'N/A')}: {item.get('snippet', 'N/A')} {neutralize_urls(item.get('link', ''))}\n"
                return output
            return "Google Custom Search: Aucun résultat trouvé."
        return f"Erreur Google Custom Search: {response.get('message', 'Inconnu')}" if response else "Google Custom Search: Réponse vide."

# OpenRouterClient a été supprimé comme demandé.

class RandommerClient(APIClient):
    def __init__(self):
        super().__init__("RANDOMMER")

    async def query(self, country_code: str = "US", quantity: int = 1) -> str:
        params = {"CountryCode": country_code, "Quantity": quantity}
        response = await self._make_request(params=params)
        if response and not response.get("error"):
            if isinstance(response, list) and response:
                return f"Randommer (Numéros de téléphone): {', '.join(response)}"
            return f"Randommer: {response}"
        return f"Erreur Randommer: {response.get('message', 'Inconnu')}" if response else "Randommer: Réponse vide."

class TomorrowIOClient(APIClient):
    def __init__(self):
        super().__init__("TOMORROW.IO")

    async def query(self, location: str, fields: List[str] = None) -> str:
        if fields is None:
            fields = ["temperature", "humidity", "windSpeed"]
        payload = {"location": location, "fields": fields, "units": "metric", "timesteps": ["1h"]}
        response = await self._make_request(json_data=payload)
        if response and not response.get("error"):
            data = response.get("data", {}).get("timelines", [{}])[0].get("intervals", [{}])[0].get("values", {})
            if data:
                output = f"Météo (Tomorrow.io) à {location}:\n"
                for field in fields:
                    output += f"- {field.capitalize()}: {data.get(field, 'N/A')}\n"
                return output
            return "Tomorrow.io: Données météo non trouvées."
        return f"Erreur Tomorrow.io: {response.get('message', 'Inconnu')}" if response else "Tomorrow.io: Réponse vide."

class OpenWeatherMapClient(APIClient):
    def __init__(self):
        super().__init__("OPENWEATHERMAP")

    async def query(self, location: str) -> str:
        params = {"q": location}
        response = await self._make_request(params=params)
        if response and not response.get("error"):
            main_data = response.get("main", {})
            weather_desc = response.get("weather", [{}])[0].get("description", "N/A")
            if main_data:
                return (
                    f"Météo (OpenWeatherMap) à {location}:\n"
                    f"Température: {main_data.get('temp', 'N/A')}°C, "
                    f"Ressenti: {main_data.get('feels_like', 'N/A')}°C, "
                    f"Humidité: {main_data.get('humidity', 'N/A')}%, "
                    f"Conditions: {weather_desc}"
                )
            return "OpenWeatherMap: Données météo non trouvées."
        return f"Erreur OpenWeatherMap: {response.get('message', 'Inconnu')}" if response else "OpenWeatherMap: Réponse vide."

class MockarooClient(APIClient):
    def __init__(self):
        super().__init__("MOCKAROO")

    async def query(self, count: int = 1, fields_json: str = None) -> str:
        # Mockaroo's 'fields' parameter often expects a JSON string, which needs to be URL-encoded for GET requests.
        # The default fixed_params already include a basic fields_json.
        params = {"count": count}
        if fields_json:
            params["fields"] = fields_json # Override default if provided

        response = await self._make_request(params=params)
        if response and not response.get("error"):
            return f"Mockaroo (Génération de données):\n{json.dumps(response, indent=2)}"
        return f"Erreur Mockaroo: {response.get('message', 'Inconnu')}" if response else "Mockaroo: Réponse vide."

class OpenPageRankClient(APIClient):
    def __init__(self):
        super().__init__("OPENPAGERANK")

    async def query(self, domains: List[str]) -> str:
        params = {"domains[]": domains}
        response = await self._make_request(params=params)
        if response and not response.get("error"):
            results = response.get("response", [])
            if results:
                output = "OpenPageRank (Classement de domaine):\n"
                for res in results:
                    output += f"- Domaine: {res.get('domain', 'N/A')}, PageRank: {res.get('page_rank', 'N/A')}\n"
                return output
            return "OpenPageRank: Aucun résultat trouvé."
        return f"Erreur OpenPageRank: {response.get('message', 'Inconnu')}" if response else "OpenPageRank: Réponse vide."

class RapidAPIClient(APIClient):
    def __init__(self):
        super().__init__("RAPIDAPI")

    async def query(self, api_name: str, **kwargs) -> str:
        # RapidAPI is a marketplace, so we need to select the specific API endpoint
        # based on 'api_name' argument.
        selected_endpoint_config = None
        for config in self.endpoints_config:
            if api_name.lower() in config["endpoint_name"].lower():
                selected_endpoint_config = config
                break
        
        if not selected_endpoint_config:
            return f"RapidAPI: Endpoint pour '{api_name}' non trouvé ou non configuré."

        # Manually build request based on selected_endpoint_config
        url = selected_endpoint_config["url"]
        method = selected_endpoint_config["method"]
        
        request_params = selected_endpoint_config.get("fixed_params", {}).copy()
        request_headers = selected_endpoint_config.get("fixed_headers", {}).copy()
        request_json_data = selected_endpoint_config.get("fixed_json", {}).copy()

        # Add dynamic kwargs to params/json_data
        if method == "GET":
            request_params.update(kwargs)
        elif method == "POST":
            request_json_data.update(kwargs)

        headers = {
            selected_endpoint_config["key_field"]: selected_endpoint_config["key"],
            "X-RapidAPI-Host": selected_endpoint_config["fixed_headers"].get("X-RapidAPI-Host") # Specific to RapidAPI
        }
        
        response = await self._make_request(
            params=request_params,
            headers=headers,
            json_data=request_json_data,
            url=url,
            method=method
        )

        if response and not response.get("error"):
            if api_name.lower() == "programming joke":
                return f"RapidAPI (Blague de Programmation): {response.get('setup', '')} - {response.get('punchline', '')}"
            elif api_name.lower() == "currency list quotes":
                return f"RapidAPI (Devises): {json.dumps(response, indent=2)}"
            elif api_name.lower() == "random fact":
                return f"RapidAPI (Fait Aléatoire): {response.get('text', 'N/A')}"
            return f"RapidAPI ({api_name}): {json.dumps(response, indent=2)}"
        return f"Erreur RapidAPI ({api_name}): {response.get('message', 'Inconnu')}" if response else "RapidAPI: Réponse vide."

# --- Instancier tous les clients API ---
ALL_API_CLIENTS = [
    DeepSeekClient(),
    SerperClient(),
    WolframAlphaClient(),
    TavilyClient(),
    ApiFlashClient(),
    CrawlbaseClient(),
    DetectLanguageClient(),
    GuardianClient(),
    IP2LocationClient(),
    ShodanClient(),
    WeatherAPIClient(),
    CloudmersiveClient(),
    GreyNoiseClient(),
    PulsediveClient(),
    StormGlassClient(),
    LoginRadiusClient(),
    JsonbinClient(),
    HuggingFaceClient(),
    TwilioClient(),
    AbstractAPIClient(),
    GeminiAPIClient(),
    GoogleCustomSearchClient(),
    RandommerClient(),
    TomorrowIOClient(),
    OpenWeatherMapClient(),
    MockarooClient(),
    OpenPageRankClient(),
    RapidAPIClient()
]

# --- FIN DU BLOC CLIENTS API SPECIFIQUES ---

# --- DEBUT DU BLOC GESTION MEMOIRE ET QUOTAS ---

class MemoryManager:
    def __init__(self):
        self.chat_history = load_json(HISTORY_FILE, [])
        self.long_term_memory = load_json(LONG_MEMORY_FILE, {})
        self.ia_status = load_json(IA_STATUS_FILE, {})
        self._initialize_ia_status()

    def _initialize_ia_status(self):
        """Initialise le statut des IA si elles ne sont pas déjà présentes ou si leur statut est obsolète."""
        now = get_current_time()
        updated = False
        for client in ALL_API_CLIENTS:
            if client.name not in self.ia_status:
                self.ia_status[client.name] = {
                    "last_used": None,
                    "last_error": None,
                    "error_count": 0,
                    "cooldown_until": None,
                    "success_count": 0,
                    "current_score": 1.0, # Maintenu pour la compatibilité, mais moins utilisé pour la sélection primaire
                    "last_rotation_check": format_datetime(now),
                    "diversification_score": 1.0 # Nouveau score pour la diversification
                }
                updated = True
            else:
                # S'assurer que les nouvelles clés existent pour les IA existantes
                if "success_count" not in self.ia_status[client.name]:
                    self.ia_status[client.name]["success_count"] = 0
                    updated = True
                if "current_score" not in self.ia_status[client.name]:
                    self.ia_status[client.name]["current_score"] = 1.0
                    updated = True
                if "last_rotation_check" not in self.ia_status[client.name]:
                    self.ia_status[client.name]["last_rotation_check"] = format_datetime(now)
                    updated = True
                if "diversification_score" not in self.ia_status[client.name]:
                    self.ia_status[client.name]["diversification_score"] = 1.0
                    updated = True

        if updated:
            save_json(IA_STATUS_FILE, self.ia_status)
            log_message("Statut des IA initialisé/mis à jour.")

    def add_message_to_history(self, role, content):
        """Ajoute un message à l'historique de la conversation."""
        self.chat_history.append({"role": role, "content": content, "timestamp": format_datetime(get_current_time())})
        self._prune_history()
        save_json(HISTORY_FILE, self.chat_history)
        log_message(f"Message ajouté à l'historique par {role}.")

    def get_chat_history(self, limit=10):
        """Retourne les N derniers messages de l'historique."""
        return self.chat_history[-limit:]

    def add_to_long_term_memory(self, key, value):
        """Ajoute une information à la mémoire à long terme."""
        self.long_term_memory[key] = {"value": value, "timestamp": format_datetime(get_current_time())}
        save_json(LONG_MEMORY_FILE, self.long_term_memory)
        log_message(f"Information ajoutée à la mémoire à long terme: {key}")

    def get_from_long_term_memory(self, key):
        """Récupère une information de la mémoire à long terme."""
        return self.long_term_memory.get(key)

    def update_ia_status(self, ia_name: str, success: bool, error_message: Optional[str] = None):
        """Met à jour le statut et le score d'une IA après une utilisation."""
        status = self.ia_status.get(ia_name)
        if not status:
            log_message(f"Tentative de mise à jour d'un statut d'IA inconnu: {ia_name}", level="warning")
            return

        now = get_current_time()
        status["last_used"] = format_datetime(now)

        if success:
            status["success_count"] += 1
            status["error_count"] = 0
            status["cooldown_until"] = None
            status["last_error"] = None
            status["current_score"] = min(1.0, status["current_score"] + 0.1)
            # Decrease diversification score on use
            status["diversification_score"] = max(0.1, status["diversification_score"] - 0.1)
            log_message(f"IA {ia_name} : Succès enregistré. Nouveau score: {status['current_score']:.2f}, Diversification: {status['diversification_score']:.2f}")
        else:
            status["error_count"] += 1
            status["last_error"] = error_message
            if status["error_count"] >= 3:
                status["cooldown_until"] = format_datetime(now + timedelta(seconds=API_COOLDOWN_DURATION_SECONDS))
                status["current_score"] = max(0.1, status["current_score"] - 0.2)
                log_message(f"IA {ia_name} : Trop d'erreurs ({status['error_count']}). Cooldown jusqu'à {status['cooldown_until']}. Nouveau score: {status['current_score']:.2f}", level="warning")
            else:
                 status["current_score"] = max(0.1, status["current_score"] - 0.05)
                 log_message(f"IA {ia_name} : Erreur enregistrée. Nouveau score: {status['current_score']:.2f}", level="warning")

        save_json(IA_STATUS_FILE, self.ia_status)

    def recover_diversification_scores(self):
        """Augmente le score de diversification pour les IA non utilisées récemment."""
        now = get_current_time()
        updated = False
        for ia_name, status in self.ia_status.items():
            last_used_str = status.get("last_used")
            if last_used_str:
                last_used_dt = datetime.strptime(last_used_str, "%Y-%m-%d %H:%M:%S UTC").replace(tzinfo=None)
                # If not used in the last API_ROTATION_INTERVAL_MINUTES * 2 (e.g., 60 mins), recover score
                if (now - last_used_dt).total_seconds() > API_ROTATION_INTERVAL_MINUTES * 60 * 2:
                    if status["diversification_score"] < 1.0:
                        status["diversification_score"] = min(1.0, status["diversification_score"] + 0.05)
                        updated = True
                        log_message(f"IA {ia_name}: Score de diversification récupéré à {status['diversification_score']:.2f}")
            else: # Never used, ensure it's at max
                if status["diversification_score"] < 1.0:
                    status["diversification_score"] = 1.0
                    updated = True
        if updated:
            save_json(IA_STATUS_FILE, self.ia_status)

    def get_ia_status(self, ia_name: str) -> Optional[Dict]:
        """Récupère le statut d'une IA."""
        return self.ia_status.get(ia_name)

    def get_available_ias(self) -> List[str]:
        """Retourne les noms des IA actuellement non en cooldown."""
        available = []
        now = get_current_time()
        for name, status in self.ia_status.items():
            cooldown_until_str = status.get("cooldown_until")
            if cooldown_until_str:
                cooldown_until = datetime.strptime(cooldown_until_str, "%Y-%m-%d %H:%M:%S UTC").replace(tzinfo=None)
                if now < cooldown_until:
                    continue
            available.append(name)
        return available

    def _prune_history(self, max_entries=50):
        """Supprime les anciennes entrées de l'historique si trop nombreuses."""
        if len(self.chat_history) > max_entries:
            self.chat_history = self.chat_history[-max_entries:]
            log_message(f"Historique de chat purgé, {len(self.chat_history)} entrées restantes.")

class QuotaManager:
    def __init__(self):
        self.quotas = load_json(QUOTAS_FILE, {})
        self._initialize_quotas()

    def _initialize_quotas(self):
        """Initialise les quotas pour toutes les APIs basées sur config.API_QUOTAS et nettoie/met à jour les existants."""
        updated = False
        now = get_current_time()

        # Step 1: Ensure all APIs from API_QUOTAS are in self.quotas with full structure
        for api_name, quota_info in API_QUOTAS.items():
            if api_name not in self.quotas:
                self.quotas[api_name] = {
                    "monthly_usage": 0,
                    "daily_usage": 0,
                    "hourly_usage": 0,
                    "hourly_timestamps": [],
                    "last_reset_month": now.month,
                    "last_reset_day": now.day,
                    "last_usage": None,
                    "total_calls": 0,
                    "last_hourly_reset": format_datetime(now)
                }
                updated = True
            else:
                # Ensure existing entries have all required keys
                default_quota_structure = {
                    "monthly_usage": 0,
                    "daily_usage": 0,
                    "hourly_usage": 0,
                    "hourly_timestamps": [],
                    "last_reset_month": now.month,
                    "last_reset_day": now.day,
                    "last_usage": None,
                    "total_calls": 0,
                    "last_hourly_reset": format_datetime(now)
                }
                for key, default_value in default_quota_structure.items():
                    if key not in self.quotas[api_name]:
                        self.quotas[api_name][key] = default_value
                        updated = True
                
                # Re-evaluate hourly_usage based on timestamps during initialization
                one_hour_ago = now - timedelta(hours=1)
                # Ensure hourly_timestamps is a list before filtering
                if not isinstance(self.quotas[api_name].get("hourly_timestamps"), list):
                    self.quotas[api_name]["hourly_timestamps"] = []
                    updated = True

                self.quotas[api_name]["hourly_timestamps"] = [
                    ts for ts in self.quotas[api_name]["hourly_timestamps"]
                    if datetime.strptime(ts, "%Y-%m-%d %H:%M:%S UTC").replace(tzinfo=None) > one_hour_ago
                ]
                self.quotas[api_name]["hourly_usage"] = len(self.quotas[api_name]["hourly_timestamps"])
                self.quotas[api_name]["last_hourly_reset"] = format_datetime(now) # Update reset time

        # Step 2: Remove any API names from self.quotas that are NOT in API_QUOTAS
        # This handles cases where invalid API names might have been added previously
        api_names_to_remove = [name for name in self.quotas if name not in API_QUOTAS]
        for name in api_names_to_remove:
            del self.quotas[name]
            updated = True
            log_message(f"API '{name}' trouvée dans quotas.json mais non définie dans API_QUOTAS. Supprimée.", level="warning")

        if updated:
            save_json(QUOTAS_FILE, self.quotas)
            log_message("Quotas API initialisés/mis à jour.")

    def _reset_quotas_if_needed(self):
        """Réinitialise les quotas journaliers, mensuels et horaires si nécessaire."""
        now = get_current_time()
        for api_name, data in self.quotas.items():
            # Reset mensuel
            if now.month != data["last_reset_month"]:
                data["monthly_usage"] = 0
                data["last_reset_month"] = now.month
                log_message(f"Quota mensuel pour {api_name} réinitialisé.")
            # Reset journalier
            if now.day != data["last_reset_day"]:
                data["daily_usage"] = 0
                data["last_reset_day"] = now.day
                log_message(f"Quota journalier pour {api_name} réinitialisé.")
            
            # Reset et gestion horaire (nettoyage des timestamps trop anciens)
            one_hour_ago = now - timedelta(hours=1)
            # Ensure hourly_timestamps is a list before filtering
            if not isinstance(data.get("hourly_timestamps"), list):
                data["hourly_timestamps"] = []
            
            data["hourly_timestamps"] = [
                ts for ts in data["hourly_timestamps"]
                if datetime.strptime(ts, "%Y-%m-%d %H:%M:%S UTC").replace(tzinfo=None) > one_hour_ago
            ]
            data["hourly_usage"] = len(data["hourly_timestamps"])
            
            # Update last_hourly_reset to current time if a reset happened or after cleanup
            data["last_hourly_reset"] = format_datetime(now)

        save_json(QUOTAS_FILE, self.quotas)

    def check_and_update_quota(self, api_name: str, cost: int = 1) -> bool:
        """Vérifie si une API a du quota et le décrémente. Retourne True si ok, False sinon."""
        self._reset_quotas_if_needed()
        
        # IMPORTANT: Only process if api_name is a valid, configured API
        if api_name not in API_QUOTAS:
            log_message(f"Tentative de vérification de quota pour une API non définie: {api_name}. Autorisation refusée.", level="error")
            return False # Prevent processing for undefined APIs

        if api_name not in self.quotas:
            # This case should ideally not happen after robust initialization, but as a fallback
            log_message(f"API {api_name} non trouvée dans les quotas gérés. Re-initialisation.", level="warning")
            self._initialize_quotas() # Re-initialize to ensure it's added
            if api_name not in self.quotas: # If still not there after re-init, something is fundamentally wrong
                log_message(f"API {api_name} toujours introuvable après re-initialisation. Autorisation refusée.", level="error")
                return False


        quota_data = self.quotas[api_name]
        api_limits = API_QUOTAS.get(api_name, {})
        now = get_current_time()

        monthly_limit = api_limits.get("monthly")
        if monthly_limit is not None and (quota_data["monthly_usage"] + cost) > monthly_limit:
            log_message(f"Quota mensuel dépassé pour {api_name}", level="warning")
            return False

        daily_limit = api_limits.get("daily")
        if daily_limit is not None and (quota_data["daily_usage"] + cost) > daily_limit:
            log_message(f"Quota journalier dépassé pour {api_name}", level="warning")
            return False
        
        hourly_limit = api_limits.get("hourly")
        if hourly_limit is not None and (quota_data["hourly_usage"] + cost) > hourly_limit:
            log_message(f"Quota horaire dépassé pour {api_name}", level="warning")
            return False

        rate_limit_per_sec = api_limits.get("rate_limit_per_sec")
        if rate_limit_per_sec:
            last_usage_str = quota_data.get("last_usage")
            if last_usage_str:
                last_usage = datetime.strptime(last_usage_str, "%Y-%m-%d %H:%M:%S UTC").replace(tzinfo=None)
                time_since_last_call = (now - last_usage).total_seconds()
                if time_since_last_call < (1 / rate_limit_per_sec):
                    log_message(f"Taux de requêtes dépassé pour {api_name}. Attendre {1/rate_limit_per_sec - time_since_last_call:.2f}s", level="warning")
                    return False

        quota_data["monthly_usage"] += cost
        quota_data["daily_usage"] += cost
        quota_data["hourly_usage"] += cost
        quota_data["hourly_timestamps"].append(format_datetime(now)) # Add current timestamp
        quota_data["total_calls"] += cost
        quota_data["last_usage"] = format_datetime(now)
        save_json(QUOTAS_FILE, self.quotas)
        log_message(f"Quota pour {api_name} mis à jour. Usage mensuel: {quota_data['monthly_usage']}/{monthly_limit if monthly_limit else 'Illimité'}, Journalier: {quota_data['daily_usage']}/{daily_limit if daily_limit else 'Illimité'}, Horaire: {quota_data['hourly_usage']}/{hourly_limit if hourly_limit else 'Illimité'}")
        return True

    def get_api_usage(self, api_name: str) -> Optional[Dict]:
        """Retourne les informations d'utilisation d'une API."""
        return self.quotas.get(api_name)

    def get_all_quotas_status(self) -> Dict:
        """Retourne le statut de tous les quotas."""
        self._reset_quotas_if_needed()
        status = {}
        for api_name, quota_data in self.quotas.items():
            api_limits = API_QUOTAS.get(api_name, {})
            monthly_limit = api_limits.get("monthly", "Illimité")
            daily_limit = api_limits.get("daily", "Illimité")
            hourly_limit = api_limits.get("hourly", "Illimité")
            status[api_name] = {
                "monthly_usage": quota_data["monthly_usage"],
                "monthly_limit": monthly_limit,
                "daily_usage": quota_data["daily_usage"],
                "daily_limit": daily_limit,
                "hourly_usage": quota_data["hourly_usage"],
                "hourly_limit": hourly_limit,
                "total_calls": quota_data["total_calls"],
                "last_usage": quota_data["last_usage"],
                "last_reset_month": quota_data["last_reset_month"],
                "last_reset_day": quota_data["last_reset_day"],
                "last_hourly_reset": quota_data["last_hourly_reset"]
            }
        return status

    def get_burn_window_apis(self) -> List[str]:
        """
        Identifie les APIs dont les quotas sont sur le point d'être réinitialisés
        et où il est opportun de "brûler" le quota restant.
        """
        burn_apis = []
        now = get_current_time()
        for api_name, data in self.quotas.items():
            api_limits = API_QUOTAS.get(api_name, {})

            if api_limits.get("monthly") is not None:
                next_month_reset = datetime(now.year + (1 if now.month == 12 else 0), (now.month % 12) + 1, 1).replace(tzinfo=None)
                if is_within_time_window(next_month_reset, QUOTA_BURN_WINDOW_HOURS * 60, 0):
                    if data["monthly_usage"] < api_limits["monthly"]:
                        burn_apis.append(f"{api_name} (mensuel: {api_limits['monthly'] - data['monthly_usage']} restants)")

            if api_limits.get("daily") is not None:
                next_day_reset = datetime(now.year, now.month, now.day).replace(tzinfo=None) + timedelta(days=1)
                if is_within_time_window(next_day_reset, QUOTA_BURN_WINDOW_HOURS * 60, 0):
                    if data["daily_usage"] < api_limits["daily"]:
                        burn_apis.append(f"{api_name} (journalier: {api_limits['daily'] - data['daily_usage']} restants)")
        return burn_apis

# Instanciation des gestionnaires
memory_manager = MemoryManager()
quota_manager = QuotaManager()

import time
from telegram import Update, ForceReply
from telegram.ext import Application, CommandHandler, MessageHandler, filters, ContextTypes

# --- Orchestration des IA ---
class IAOrchestrator:
    def __init__(self, memory_manager: MemoryManager, quota_manager: QuotaManager, api_clients: List[APIClient]):
        self.memory_manager = memory_manager
        self.quota_manager = quota_manager
        self.api_clients = {client.name: client for client in api_clients}
        self.last_strategy_rotation_time = get_current_time()
        self.current_ia_strategy = self._determine_initial_strategy()

        # Les cinq moteurs IA principaux
        self.core_ai_engines = {
            "DEEPSEEK": self.api_clients.get("DEEPSEEK"),
            "HUGGINGFACE": self.api_clients.get("HUGGINGFACE"),
            "GOOGLE_CUSTOM_SEARCH": self.api_clients.get("GOOGLE_CUSTOM_SEARCH"),
            "GEMINI_API": self.api_clients.get("GEMINI_API")
        }
        # Filtrer les clients None si l'API n'est pas configurée
        self.core_ai_engines = {k: v for k, v in self.core_ai_engines.items() if v is not None}

        # Définir les "agents mixtes" et leurs capacités (simplified for example)
        # En réalité, ceci serait un système de routing basé sur des modèles NLP plus complexes.
        self.mixed_agents = [
            {"name": "GeneralQueryAgent", "primary_ais": ["DEEPSEEK", "GEMINI_API", "GOOGLE_CUSTOM_SEARCH"], "tools": ["SERPER", "TAVILY", "WOLFRAMALPHA", "WEATHERAPI", "OPENWEATHERMAP"]},
            {"name": "CodingAgent", "primary_ais": ["DEEPSEEK", "HUGGINGFACE", "GEMINI_API"], "tools": []}, # Tools are sandbox/analyzer
            {"name": "SecurityAgent", "primary_ais": ["DEEPSEEK", "GEMINI_API"], "tools": ["IP2LOCATION", "SHODAN", "GREYNOISE", "PULSEDIVE", "CLOUDMERSIVE"]},
            {"name": "DataAgent", "primary_ais": ["DEEPSEEK", "GEMINI_API"], "tools": ["JSONBIN", "MOCKAROO", "RANDOMMER", "OPENPAGERANK", "RAPIDAPI"]},
            {"name": "CommunicationAgent", "primary_ais": ["DEEPSEEK", "GEMINI_API"], "tools": ["TWILIO", "ABSTRACTAPI"]},
            {"name": "NewsAgent", "primary_ais": ["DEEPSEEK", "GEMINI_API"], "tools": ["GUARDIAN", "SERPER", "TAVILY"]},
            {"name": "ImageAgent", "primary_ais": ["DEEPSEEK", "GEMINI_API"], "tools": ["APIFLASH"]}, # OCR tool is separate
            {"name": "LanguageAgent", "primary_ais": ["DEEPSEEK", "GEMINI_API"], "tools": ["DETECTLANGUAGE"]},
            {"name": "WeatherAgent", "primary_ais": ["DEEPSEEK", "GEMINI_API"], "tools": ["WEATHERAPI", "STORMGLASS", "TOMORROW.IO", "OPENWEATHERMAP"]}
        ]
        self.current_agent_index = 0
        self.last_agent_rotation_time = get_current_time()

        # Tool descriptions for AI
        self.tool_descriptions = {
            "SERPER": "Effectue une recherche web sur Google et retourne les snippets et liens pertinents. Paramètres: {\"query\": \"texte de recherche\"}",
            "TAVILY": "Effectue une recherche web avancée et retourne une réponse directe et des extraits. Paramètres: {\"query\": \"texte de recherche\", \"max_results\": nombre}",
            "WOLFRAMALPHA": "Répond à des questions factuelles et calculs complexes. Paramètres: {\"input\": \"question ou calcul\"}",
            "WEATHERAPI": "Fournit la météo actuelle et les prévisions pour une localisation donnée. Paramètres: {\"location\": \"nom de la ville ou code postal\"}",
            "OPENWEATHERMAP": "Fournit la météo actuelle pour une localisation donnée. Paramètres: {\"location\": \"nom de la ville ou code postal\"}",
            "STORMGLASS": "Fournit des données météorologiques maritimes (température, vagues) pour des coordonnées lat/lng. Paramètres: {\"lat\": latitude, \"lng\": longitude, \"params\": \"airTemperature,waveHeight\"}",
            "APIFLASH": "Prend une capture d'écran d'une URL et retourne l'URL de l'image. Paramètres: {\"url\": \"URL du site\"}",
            "CRAWLBASE": "Récupère le contenu HTML ou JavaScript d'une URL. Paramètres: {\"url\": \"URL du site\", \"use_js\": true/false}",
            "DETECTLANGUAGE": "Détecte la langue d'un texte. Paramètres: {\"text\": \"texte à analyser\"}",
            "IP2LOCATION": "Géolocalise une adresse IP. Paramètres: {\"ip_address\": \"adresse IP\"}",
            "SHODAN": "Fournit des informations sur les hôtes et les services exposés sur Internet. Paramètres: {\"query\": \"texte de recherche\"} (optionnel)",
            "GREYNOISE": "Analyse une adresse IP pour déterminer si elle est 'bruit' (malveillante). Paramètres: {\"ip_address\": \"adresse IP\"}",
            "PULSEDIVE": "Analyse des indicateurs de menace (IP, domaine, URL). Paramètres: {\"indicator\": \"indicateur\", \"type\": \"auto\"}",
            "CLOUDMERSIVE": "Vérifie la validité d'un nom de domaine. Paramètres: {\"domain\": \"nom de domaine\"}",
            "JSONBIN": "Stocke ou récupère des données JSON dans un 'bin' privé ou public. Pour créer: {\"data\": {\"clé\": \"valeur\"}, \"private\": true/false}. Pour accéder: {\"bin_id\": \"ID du bin\"}",
            "MOCKAROO": "Génère des données de test aléatoires basées sur des schémas. Paramètres: {\"count\": nombre, \"fields_json\": \"[{\"name\": \"champ\", \"type\": \"Type Mockaroo\"}]\"}",
            "RANDOMMER": "Génère des données aléatoires, comme des numéros de téléphone. Paramètres: {\"country_code\": \"US\", \"quantity\": 1}",
            "OPENPAGERANK": "Récupère le PageRank d'un ou plusieurs domaines. Paramètres: {\"domains\": [\"domaine1.com\", \"domaine2.com\"]}",
            "RAPIDAPI": "Accède à diverses micro-APIs (blagues, faits, devises). Nécessite un 'api_name' (ex: 'Programming Joke'). Paramètres: {\"api_name\": \"Nom de l'API\", \"kwargs\": {\"param1\": \"valeur1\"}}",
            "TWILIO": "Vérifie le solde du compte Twilio. Paramètres: Aucun",
            "ABSTRACTAPI": "Valide des emails, numéros de téléphone, géolocalise des IPs, ou fournit des taux de change/jours fériés. Paramètres: {\"input_value\": \"valeur\", \"api_type\": \"EMAIL_VALIDATION\"|\"PHONE_VALIDATION\"|\"EXCHANGE_RATES\"|\"HOLIDAYS\"}"
        }

    def _determine_initial_strategy(self) -> str:
        """Détermine la stratégie initiale ou la stratégie par défaut."""
        return "balanced"

    def _rotate_strategy_if_needed(self):
        """Change la stratégie d'IA et l'agent si l'intervalle de rotation est passé."""
        now = get_current_time()
        if (now - self.last_strategy_rotation_time).total_seconds() >= API_ROTATION_INTERVAL_MINUTES * 60:
            strategies = ["balanced", "cost_effective", "performance"]
            self.current_ia_strategy = random.choice(strategies)
            self.last_strategy_rotation_time = now
            log_message(f"Stratégie d'IA changée pour: {self.current_ia_strategy}")

            # Rotation des agents mixtes
            self.current_agent_index = (self.current_agent_index + 1) % len(self.mixed_agents)
            self.last_agent_rotation_time = now
            log_message(f"Agent mixte actuel: {self.mixed_agents[self.current_agent_index]['name']}")

            # Mettre à jour le last_rotation_check pour toutes les IA et récupérer les scores de diversification
            for ia_name in self.memory_manager.ia_status:
                self.memory_manager.ia_status[ia_name]["last_rotation_check"] = format_datetime(now)
            self.memory_manager.recover_diversification_scores() # Recover diversification scores
            save_json(IA_STATUS_FILE, self.memory_manager.ia_status)

    async def _select_primary_ai_for_agent(self, agent_config: Dict) -> Optional[APIClient]:
        """
        Sélectionne une IA primaire parmi celles de l'agent.
        La sélection est désormais équitable, sans privilégier une IA par rapport à une autre en fonction des scores.
        """
        available_primary_ais = []
        for ai_name in agent_config["primary_ais"]:
            if ai_name in self.core_ai_engines:
                status = self.memory_manager.get_ia_status(ai_name)
                # Vérifier si l'IA n'est pas en cooldown
                if status and (status.get("cooldown_until") is None or datetime.strptime(status["cooldown_until"], "%Y-%m-%d %H:%M:%S UTC").replace(tzinfo=None) < get_current_time()):
                    # Vérifier le quota sans le consommer pour la sélection
                    if self.quota_manager.check_and_update_quota(ai_name, cost=0):
                        available_primary_ais.append(ai_name)
        
        if not available_primary_ais:
            log_message(f"Aucune IA primaire disponible pour l'agent {agent_config['name']}.", level="warning")
            return None

        # Sélection aléatoire et équitable parmi les IA disponibles
        selected_ai_name = random.choice(available_primary_ais)
        
        # Consommer le quota pour l'IA sélectionnée
        if self.quota_manager.check_and_update_quota(selected_ai_name):
            log_message(f"IA primaire sélectionnée pour l'agent: {selected_ai_name} (Sélection équitable)")
            return self.core_ai_engines[selected_ai_name]
        
        # Ce cas ne devrait pas arriver souvent si le check_and_update_quota(cost=0) a réussi
        # mais c'est une sécurité.
        log_message(f"IA {selected_ai_name} sélectionnée mais quota non disponible au moment de la consommation.", level="warning")
        return None


    async def _run_agent_with_tools(self, agent_config: Dict, query: str) -> str:
        """
        Exécute l'agent mixte en utilisant l'IA primaire sélectionnée
        et en sollicitant les outils pertinents.
        """
        primary_ai_client = await self._select_primary_ai_for_agent(agent_config)
        if not primary_ai_client:
            return f"Désolé, l'agent {agent_config['name']} ne peut pas opérer car aucune IA primaire n'est disponible.", []

        responses = []
        tools_called_for_report = []
        
        # Prepare tool descriptions for the AI
        available_tools_for_ai = {}
        for tool_name in agent_config.get("tools", []):
            if tool_name in self.tool_descriptions and self.api_clients.get(tool_name):
                available_tools_for_ai[tool_name] = self.tool_descriptions[tool_name]
        
        tool_prompt_part = ""
        if available_tools_for_ai:
            tool_prompt_part = "\n\nTu as accès aux outils suivants:\n"
            for tool_name, desc in available_tools_for_ai.items():
                tool_prompt_part += f"- **{tool_name}**: {desc}\n"
            tool_prompt_part += "\nSi tu as besoin d'utiliser un outil, réponds avec le format suivant: `TOOL_CALL:<nom_outil>:<paramètres_json>`. Par exemple: `TOOL_CALL:WEATHERAPI:{\"location\": \"Paris\"}`. Sinon, réponds normalement."
        
        full_prompt_for_ai = f"{query}{tool_prompt_part}"

        # 1. Obtenir une première réponse de l'IA primaire
        log_message(f"Agent {agent_config['name']} utilise {primary_ai_client.name} pour la requête: '{query}'")
        primary_response_raw = await primary_ai_client.query(full_prompt_for_ai)
        self.memory_manager.update_ia_status(primary_ai_client.name, not primary_response_raw.startswith("Erreur"))
        
        # Check for tool calls in the primary AI's response
        tool_call_match = re.match(r"TOOL_CALL:([A-Z_]+):(.+)", primary_response_raw)
        if tool_call_match:
            tool_name = tool_call_match.group(1)
            params_str = tool_call_match.group(2)
            
            try:
                tool_params = json.loads(params_str)
                tool_client = self.api_clients.get(tool_name)
                if tool_client and self.quota_manager.check_and_update_quota(tool_name):
                    log_message(f"Agent {agent_config['name']} exécute l'outil {tool_name} avec les paramètres: {tool_params}")
                    
                    tool_response = ""
                    # Dynamic tool call based on tool_name and parsed params
                    # This requires careful mapping of tool_params to actual method arguments
                    if tool_name == "SERPER":
                        tool_response = await tool_client.query(query_text=tool_params.get("query"))
                    elif tool_name == "TAVILY":
                        tool_response = await tool_client.query(query_text=tool_params.get("query"), max_results=tool_params.get("max_results", 3))
                    elif tool_name == "WOLFRAMALPHA":
                        tool_response = await tool_client.query(input_text=tool_params.get("input"))
                    elif tool_name == "WEATHERAPI":
                        tool_response = await tool_client.query(location=tool_params.get("location"))
                    elif tool_name == "OPENWEATHERMAP":
                        tool_response = await tool_client.query(location=tool_params.get("location"))
                    elif tool_name == "STORMGLASS":
                        tool_response = await tool_client.query(lat=tool_params.get("lat"), lng=tool_params.get("lng"), params=tool_params.get("params", "airTemperature,waveHeight"))
                    elif tool_name == "APIFLASH":
                        tool_response = await tool_client.query(url=tool_params.get("url"))
                    elif tool_name == "CRAWLBASE":
                        tool_response = await tool_client.query(url=tool_params.get("url"), use_js=tool_params.get("use_js", False))
                    elif tool_name == "DETECTLANGUAGE":
                        tool_response = await tool_client.query(text=tool_params.get("text"))
                    elif tool_name == "IP2LOCATION":
                        tool_response = await tool_client.query(ip_address=tool_params.get("ip_address"))
                    elif tool_name == "SHODAN":
                        tool_response = await tool_client.query(query_text=tool_params.get("query", ""))
                    elif tool_name == "GREYNOISE":
                        tool_response = await tool_client.query(ip_address=tool_params.get("ip_address"))
                    elif tool_name == "PULSEDIVE":
                        tool_response = await tool_client.query(indicator=tool_params.get("indicator"), type=tool_params.get("type", "auto"))
                    elif tool_name == "CLOUDMERSIVE":
                        tool_response = await tool_client.query(domain=tool_params.get("domain"))
                    elif tool_name == "JSONBIN":
                        if "bin_id" in tool_params:
                            tool_response = await tool_client.query(bin_id=tool_params["bin_id"])
                        else:
                            tool_response = await tool_client.query(data=tool_params.get("data", {}), private=tool_params.get("private", True))
                    elif tool_name == "MOCKAROO":
                        tool_response = await tool_client.query(count=tool_params.get("count", 1), fields_json=tool_params.get("fields_json"))
                    elif tool_name == "RANDOMMER":
                        tool_response = await tool_client.query(country_code=tool_params.get("country_code", "US"), quantity=tool_params.get("quantity", 1))
                    elif tool_name == "OPENPAGERANK":
                        tool_response = await tool_client.query(domains=tool_params.get("domains", []))
                    elif tool_name == "RAPIDAPI":
                        tool_response = await tool_client.query(api_name=tool_params.get("api_name"), **tool_params.get("kwargs", {}))
                    elif tool_name == "TWILIO":
                        tool_response = await tool_client.query()
                    elif tool_name == "ABSTRACTAPI":
                        tool_response = await tool_client.query(input_value=tool_params.get("input_value"), api_type=tool_params.get("api_type"))
                    elif tool_name == "TOMORROW.IO":
                        tool_response = await tool_client.query(location=tool_params.get("location"), fields=tool_params.get("fields"))
                    
                    if tool_response:
                        responses.append(f"Réponse outil ({tool_name}): {tool_response}")
                        tools_called_for_report.append({"name": tool_name, "params": tool_params, "result": tool_response})
                    self.memory_manager.update_ia_status(tool_name, not tool_response.startswith("Erreur"))
                    
                    # Feed tool response back to primary AI for final answer
                    follow_up_prompt = f"J'ai exécuté l'outil {tool_name} avec les paramètres {params_str}. Voici le résultat:\n{tool_response}\n\nMaintenant, réponds à la question originale: {query}"
                    final_ai_response = await primary_ai_client.query(follow_up_prompt)
                    self.memory_manager.update_ia_status(primary_ai_client.name, not final_ai_response.startswith("Erreur"))
                    responses.append(f"Réponse finale ({primary_ai_client.name}): {final_ai_response}")

                else:
                    responses.append(f"Erreur: L'outil {tool_name} n'est pas disponible ou le quota est dépassé.")
                    tools_called_for_report.append({"name": tool_name, "params": tool_params, "result": "Quota dépassé ou non disponible."})
            except json.JSONDecodeError:
                responses.append(f"Erreur: Paramètres JSON invalides pour l'outil {tool_name}: {params_str}")
                tools_called_for_report.append({"name": tool_name, "params": params_str, "result": "JSON invalide."})
            except Exception as e:
                responses.append(f"Erreur lors de l'exécution de l'outil {tool_name}: {e}")
                self.memory_manager.update_ia_status(tool_name, False, str(e))
                tools_called_for_report.append({"name": tool_name, "params": params_str, "result": f"Erreur: {e}"})
        else:
            # If no tool call, the primary AI's initial response is the main response
            responses.append(f"Réponse principale ({primary_ai_client.name}): {primary_response_raw}")
        
        return "\n\n".join(responses), tools_called_for_report


    async def process_query(self, query: str) -> str:
        """Traite une requête en sélectionnant un agent mixte et en obtenant une réponse."""
        self._rotate_strategy_if_needed() # Rotation de la stratégie et de l'agent

        # Sélectionner l'agent mixte actuel
        current_agent_config = self.mixed_agents[self.current_agent_index]
        log_message(f"Traitement de la requête avec l'agent: {current_agent_config['name']}")

        # Exécuter l'agent avec ses outils
        agent_raw_response, tools_called_for_report = await self._run_agent_with_tools(current_agent_config, query)
        
        # Synthèse Optimisée des Réponses
        # Vérifier si la réponse est simple ou si elle contient des marqueurs de multiples réponses/outils
        # A simple heuristic: if it contains "Réponse principale (" and not "Réponse outil ("
        # and there are no tools called, then it's likely a single, direct response.
        if "Réponse principale (" in agent_raw_response and not tools_called_for_report:
            log_message("Réponse unique et directe détectée, pas de synthèse nécessaire.")
            final_response = agent_raw_response.replace(f"Réponse principale ({current_agent_config['primary_ais'][0]}): ", "") # Remove prefix
        else:
            log_message("Plusieurs réponses ou outils détectés, appel à la synthèse.")
            final_response = await self.synthesize_response(query, [agent_raw_response])

        return final_response, tools_called_for_report

    async def synthesize_response(self, question: str, responses: List[str]) -> str:
        """
        Synthétise les réponses de plusieurs IA en utilisant DeepSeek (le module d'optimisation).
        """
        if not responses:
            return "Je n'ai reçu aucune réponse des IA pour le moment."

        combined_responses = "\n\n".join([f"Réponse {i+1}:\n{r}" for i, r in enumerate(responses)])
        synthesis_prompt = SYNTHESIS_PROMPT_TEMPLATE.format(question=question, responses=combined_responses)

        deepseek_client = self.core_ai_engines.get("DEEPSEEK")
        if not deepseek_client:
            log_message("DeepSeek n'est pas disponible pour la synthèse.", level="warning")
            return "J'ai plusieurs réponses, mais je ne peux pas les synthétiser pour le moment. Voici les réponses brutes:\n\n" + combined_responses

        try:
            synthesis = await deepseek_client.query(synthesis_prompt)
            self.memory_manager.update_ia_status("DEEPSEEK", True) # Update DeepSeek status for synthesis
            return detect_and_correct_toxicity(synthesis)
        except Exception as e:
            log_message(f"Erreur lors de la synthèse avec DeepSeek: {e}", level="error")
            self.memory_manager.update_ia_status("DEEPSEEK", False, str(e))
            return "J'ai rencontré un problème lors de la synthèse des informations. Voici les réponses brutes:\n\n" + combined_responses

# Instancier l'orchestrateur
orchestrator = IAOrchestrator(memory_manager, quota_manager, ALL_API_CLIENTS)

# --- Tâche de fond pour les Health Checks des Endpoints (Wrapper pour JobQueue) ---
async def periodic_health_check_job(context: ContextTypes.DEFAULT_TYPE) -> None:
    """JobQueue wrapper pour les health checks périodiques."""
    log_message("Lancement des health checks périodiques via JobQueue pour tous les services...")
    for service_name in API_CONFIG.keys():
        await endpoint_health_manager.run_health_check_for_service(service_name)
    log_message("Health checks périodiques via JobQueue terminés.")

# --- Structured Reporting to Private Group ---
async def send_structured_report_to_private_group(context: ContextTypes.DEFAULT_TYPE, report_data: Dict) -> None:
    """Envoie un rapport structuré au groupe privé Telegram."""
    try:
        report_text = f"📊 **Rapport d'Action IA**\n\n"
        report_text += f"**Timestamp**: `{report_data.get('timestamp')}`\n"
        report_text += f"**Agent**: `{report_data.get('agent_name')}`\n"
        report_text += f"**Intention Détectée**: `{report_data.get('intention')}`\n"
        report_text += f"**Requête Utilisateur**: `{report_data.get('user_query')}`\n"
        report_text += f"**IA Primaire Utilisée**: `{report_data.get('primary_ai_used')}`\n"
        
        tools_called = report_data.get('tools_called', [])
        if tools_called:
            report_text += "**Outils Appelés**:\n"
            for tool in tools_called:
                # Truncate tool result for report to avoid very long messages
                tool_result_display = str(tool['result'])
                if len(tool_result_display) > 100:
                    tool_result_display = tool_result_display[:100] + "..."
                report_text += f"- `{tool['name']}` (Params: `{tool['params']}`, Résultat: `{tool_result_display}`)\n"
        else:
            report_text += "**Outils Appelés**: Aucun\n"
        
        # Truncate final response for report
        final_response_display = report_data.get('final_response', '')
        if len(final_response_display) > 500:
            final_response_display = final_response_display[:500] + "..."
        report_text += f"**Réponse Finale**: `{final_response_display}`\n"
        report_text += f"**Durée Totale**: `{report_data.get('duration'):.2f}s`\n"
        report_text += f"**Erreur**: `{report_data.get('error', 'Non')}`\n"

        await context.bot.send_message(chat_id=PRIVATE_GROUP_ID, text=report_text, parse_mode='Markdown')
        log_message(f"Rapport structuré envoyé au groupe privé: {PRIVATE_GROUP_ID}")
    except Exception as e:
        log_message(f"Erreur lors de l'envoi du rapport structuré au groupe privé: {e}", level="error")

import time
from telegram import Update, ForceReply
from telegram.ext import Application, CommandHandler, MessageHandler, filters, ContextTypes

# --- Handlers de commandes Telegram ---

async def start(update: Update, context: ContextTypes.DEFAULT_TYPE) -> None:
    """Envoie un message lorsque la commande /start est émise."""
    user = update.effective_user
    await update.message.reply_html(
        f"Salut {user.mention_html()} ! Je suis ton assistant IA de 2025. "
        "Pose-moi une question, demande-moi d'écrire du code, ou de chercher des infos. "
        "Utilise /help pour voir ce que je peux faire.",
        reply_markup=ForceReply(selective=True),
    )
    log_message(f"Commande /start reçue de {user.id}")

async def help_command(update: Update, context: ContextTypes.DEFAULT_TYPE) -> None:
    """Envoie un message lorsque la commande /help est émise."""
    help_text = """
    Voici ce que je peux faire :
    - Pose-moi n'importe quelle question factuelle.
    - Demande-moi d'écrire ou d'améliorer du code (Python, Shell).
    - Cherche des informations sur le web (actualités, météo, géolocalisation IP, etc.).
    - Demande-moi de faire une capture d'écran d'un site web (donne l'URL).
    - Demande-moi d'analyser le contenu d'une page web (donne l'URL).
    - Demande-moi de détecter la langue d'un texte.
    - Demande-moi de valider un numéro de téléphone ou de géolocaliser une IP ou un email.
    - Gère tes rappels et alarmes (Ex: "Rappelle-moi d'acheter du lait à 18h", "Mets une alarme à 7h du matin").
    - Vérifie le statut de mes APIs avec /status.
    - Affiche mon historique de conversation avec /history.
    - Affiche le statut des quotas API avec /quotas.
    - Affiche les APIs où il est opportun de "brûler" le quota avec /burn_quota.

    Exemples :
    - "Quelle est la capitale de la France ?"
    - "Écris un script Python pour trier une liste."
    - "Météo à Paris"
    - "Capture d'écran de https://google.com"
    - "Analyse de https://openai.com"
    - "Détecte la langue de 'Hello world'"
    - "Valide le numéro +33612345678"
    - "Géolocalise l'IP 8.8.8.8"
    - "Valide l'email test@example.com"
    - "Rappelle-moi de faire les courses demain à 10h"
    - "Mets une alarme pour 7h du matin"
    """
    await update.message.reply_text(help_text)
    log_message(f"Commande /help reçue de {update.effective_user.id}")

async def status_command(update: Update, context: ContextTypes.DEFAULT_TYPE) -> None:
    """Affiche le statut et les scores des IA."""
    status_message = "📊 **Statut des IA**:\n"
    now = get_current_time()
    for ia_name, status in memory_manager.ia_status.items():
        cooldown_until_str = status.get("cooldown_until")
        cooldown_status = "Prête"
        if cooldown_until_str:
            cooldown_until = datetime.strptime(cooldown_until_str, "%Y-%m-%d %H:%M:%S UTC").replace(tzinfo=None)
            if now < cooldown_until:
                remaining = cooldown_until - now
                cooldown_status = f"Cooldown ({remaining.total_seconds():.0f}s restantes)"
        
        last_used_str = status.get("last_used", "Jamais")
        if last_used_str != "Jamais":
            last_used_dt = datetime.strptime(last_used_str, "%Y-%m-%d %H:%M:%S UTC").replace(tzinfo=None)
            time_since_last_used = (now - last_used_dt).total_seconds()
            if time_since_last_used < 60:
                last_used_display = f"{time_since_last_used:.0f}s ago"
            elif time_since_last_used < 3600:
                last_used_display = f"{time_since_last_used / 60:.0f}m ago"
            else:
                last_used_display = f"{time_since_last_used / 3600:.1f}h ago"
        else:
            last_used_display = "Jamais"

        status_message += (
            f"- **{ia_name}**: Score: `{status['current_score']:.2f}`, Diversification: `{status['diversification_score']:.2f}`, "
            f"Succès: `{status['success_count']}`, Erreurs: `{status['error_count']}`, "
            f"Statut: `{cooldown_status}`, Dernière utilisation: `{last_used_display}`\n"
        )
    status_message += f"\nStratégie actuelle: `{orchestrator.current_ia_strategy}`"
    status_message += f"\nAgent mixte actuel: `{orchestrator.mixed_agents[orchestrator.current_agent_index]['name']}`"
    await update.message.reply_markdown(status_message)
    log_message(f"Commande /status reçue de {update.effective_user.id}")

async def history_command(update: Update, context: ContextTypes.DEFAULT_TYPE) -> None:
    """Affiche les 10 derniers messages de l'historique."""
    history = memory_manager.get_chat_history()
    if not history:
        await update.message.reply_text("L'historique de conversation est vide.")
        return

    history_text = "📜 **Historique des 10 dernières interactions**:\n\n"
    for entry in history:
        history_text += f"**{entry['role'].capitalize()}** ({entry['timestamp']}):\n{entry['content'][:150]}...\n\n"
    await update.message.reply_markdown(history_text)
    log_message(f"Commande /history reçue de {update.effective_user.id}")

async def quotas_command(update: Update, context: ContextTypes.DEFAULT_TYPE) -> None:
    """Affiche le statut actuel des quotas API."""
    quotas_status = quota_manager.get_all_quotas_status()
    message = "📈 **Statut des Quotas API**:\n\n"
    for api_name, data in quotas_status.items():
        message += (
            f"**{api_name}**:\n"
            f"  - Mensuel: `{data['monthly_usage']}` / `{data['monthly_limit']}`\n"
            f"  - Journalier: `{data['daily_usage']}` / `{data['daily_limit']}`\n"
            f"  - Horaire: `{data['hourly_usage']}` / `{data['hourly_limit']}`\n"
            f"  - Total appels: `{data['total_calls']}`\n"
            f"  - Dernière utilisation: `{data['last_usage'] if data['last_usage'] else 'N/A'}`\n"
            f"  - Reset Mensuel: `{data['last_reset_month']}`\n"
            f"  - Reset Journalier: `{data['last_reset_day']}`\n"
            f"  - Reset Horaire: `{data['last_hourly_reset']}`\n\n"
        )
    await update.message.reply_markdown(message)
    log_message(f"Commande /quotas reçue de {update.effective_user.id}")

async def burn_quota_command(update: Update, context: ContextTypes.DEFAULT_TYPE) -> None:
    """Affiche les APIs où il est opportun de "brûler" le quota."""
    burn_apis = quota_manager.get_burn_window_apis()
    if burn_apis:
        message = "🔥 **APIs où il est opportun de 'brûler' le quota avant réinitialisation**:\n\n"
        for api_info in burn_apis:
            message += f"- {api_info}\n"
        message += f"\nFenêtre de brûlage: {QUOTA_BURN_WINDOW_HOURS} heures avant le reset."
    else:
        message = "🎉 Aucune API n'est actuellement dans une fenêtre de 'brûlage' de quota. Tout est optimisé !"
    await update.message.reply_markdown(message)
    log_message(f"Commande /burn_quota reçue de {update.effective_user.id}")

async def detect_intent(query: str) -> str:
    """
    Détecte l'intention de l'utilisateur en utilisant une IA primaire disponible
    (DeepSeek, Gemini, etc.) de manière équitable.
    """
    prompt = f"Classe la requête suivante dans une des catégories suivantes: 'programmation', 'image', 'météo', 'langue', 'recherche', 'sécurité', 'données', 'communication', 'actualités', 'général'. Réponds uniquement avec le nom de la catégorie. Requête: '{query}'"
    
    # Sélectionner une IA primaire pour la détection d'intention
    # On itère sur les IA principales pour trouver la première disponible qui n'est pas en cooldown
    # et qui a du quota, en respectant l'équité.
    available_intent_ais = []
    for ai_name in orchestrator.core_ai_engines:
        ai_client = orchestrator.core_ai_engines[ai_name]
        status = memory_manager.get_ia_status(ai_name)
        if ai_client and status and (status.get("cooldown_until") is None or datetime.strptime(status["cooldown_until"], "%Y-%m-%d %H:%M:%S UTC").replace(tzinfo=None) < get_current_time()):
            if quota_manager.check_and_update_quota(ai_name, cost=0): # Check quota without consuming
                available_intent_ais.append(ai_name)
    
    if not available_intent_ais:
        log_message("Aucune IA principale disponible pour la détection d'intention. Retourne 'général'.", level="warning")
        return "général"

    # Choisir une IA aléatoirement parmi celles disponibles pour l'équité
    selected_ai_for_intent = random.choice(available_intent_ais)
    intent_ai_client = orchestrator.core_ai_engines[selected_ai_for_intent]

    # Consommer le quota pour l'IA sélectionnée
    if not quota_manager.check_and_update_quota(selected_ai_for_intent):
        log_message(f"Quota dépassé pour {selected_ai_for_intent} lors de la détection d'intention. Retourne 'général'.", level="warning")
        return "général"

    try:
        response = await intent_ai_client.query(prompt)
        # Clean up response to get just the category name
        category = response.strip().lower().replace('.', '').replace('catégorie: ', '')
        if category in ['programmation', 'image', 'météo', 'langue', 'recherche', 'sécurité', 'données', 'communication', 'actualités', 'général']:
            return category
        return "général" # Fallback
    except Exception as e:
        log_message(f"Erreur lors de la détection d'intention avec {selected_ai_for_intent}: {e}", level="error")
        memory_manager.update_ia_status(selected_ai_for_intent, False, str(e))
        return "général" # Fallback if AI fails


# --- Gestionnaire de messages (le cœur du bot) ---

async def handle_message(update: Update, context: ContextTypes.DEFAULT_TYPE) -> None:
    """Traite les messages texte de l'utilisateur."""
    user_message = update.message.text
    user_id = update.effective_user.id
    log_message(f"Message reçu de {user_id}: {user_message}")

    memory_manager.add_message_to_history("user", user_message)

    response_text = ""
    start_processing_time = time.monotonic()
    
    # Intention Detection
    detected_intention = await detect_intent(user_message)
    log_message(f"Intention détectée pour '{user_message}': {detected_intention}")

    tools_called_report = []
    error_occurred = False

    try:
        # Détection d'intentions spécifiques (prioritaires sur l'orchestrateur général)
        if any(keyword in user_message.lower() for keyword in ["alarme", "réveil", "timer", "minuteur", "rappelle-moi", "rappel", "reminder"]):
            log_message("Intention détectée: Alarme/Rappel (Simulé).")
            response_text = "Je peux t'aider avec les alarmes, minuteurs et rappels ! Dis-moi par exemple : 'Mets une alarme à 7h du matin' ou 'Rappelle-moi d'acheter du lait à 18h'."
            await context.bot.send_message(chat_id=update.effective_chat.id, text="Message reçu. Mission comprise.")
        elif "```python" in user_message or "```shell" in user_message or "exécute ce code" in user_message.lower() or "teste ce script" in user_message.lower():
            log_message("Intention détectée: Exécution de code.")
            await context.bot.send_message(chat_id=update.effective_chat.id, text="Message reçu. Mission comprise.")
            lang_match = re.search(r"```(python|shell)\n(.*?)```", user_message, re.DOTALL)
            if lang_match:
                language = lang_match.group(1)
                code = lang_match.group(2)
                response_text = await run_in_sandbox(code, language)
            else:
                response_text = "Veuillez formater votre code avec des triple backticks et spécifier le langage (ex: ```python\\nprint('Hello')``` ou ```shell\\nls -l```)."
        elif "analyse ce code python" in user_message.lower() or "vérifie ce script python" in user_message.lower():
            log_message("Intention détectée: Analyse de code Python.")
            await context.bot.send_message(chat_id=update.effective_chat.id, text="Message reçu. Mission comprise.")
            code_match = re.search(r"```python\n(.*?)```", user_message, re.DOTALL)
            if code_match:
                code = code_match.group(1)
                response_text = await analyze_python_code(code)
            else:
                response_text = "Veuillez fournir le code Python à analyser formaté avec ```python\\n...```."
        elif "extraire texte image" in user_message.lower() or "ocr" in user_message.lower() or "lis cette image" in user_message.lower():
            log_message("Intention détectée: OCR.")
            await context.bot.send_message(chat_id=update.effective_chat.id, text="Message reçu. Mission comprise.")
            url_match = re.search(r'https?://[^\s]+(?:\.jpg|\.jpeg|\.png|\.gif|\.bmp|\.tiff)', user_message, re.IGNORECASE)
            if url_match:
                image_url = url_match.group(0)
                # For OCR, we'll try to use Cloudmersive if a key is available for OCR
                # The provided Cloudmersive config is for Domain Check, not OCR.
                # If an OCR endpoint was configured, it would be called here.
                # For now, we'll return a message indicating no direct OCR API.
                response_text = "Désolé, je n'ai pas d'API OCR directement configurée pour le moment. Mon client Cloudmersive est pour la validation de domaine."
            else:
                response_text = "Veuillez fournir une URL d'image valide (jpg, png, etc.) pour l'extraction de texte."
        else:
            log_message("Intention générale, utilisation de l'orchestrateur d'IA.")
            await context.bot.send_message(chat_id=update.effective_chat.id, text="Message reçu. Mission comprise.")
            response_text, tools_called_report = await orchestrator.process_query(user_message)

    except Exception as e:
        log_message(f"Erreur majeure lors du traitement du message: {e}", level="error")
        response_text = f"Désolé, une erreur inattendue est survenue: {e}"
        error_occurred = True

    final_response = clean_html_tags(response_text)
    final_response = neutralize_urls(final_response)
    final_response = detect_and_correct_toxicity(final_response)

    await update.message.reply_text(final_response)
    memory_manager.add_message_to_history("assistant", final_response)
    log_message(f"Réponse envoyée à {user_id}.")

    # Send structured report to private group
    end_processing_time = time.monotonic()
    processing_duration = end_processing_time - start_processing_time

    report_data = {
        "timestamp": format_datetime(get_current_time()),
        "agent_name": orchestrator.mixed_agents[orchestrator.current_agent_index]['name'],
        "intention": detected_intention,
        "user_query": user_message,
        "primary_ai_used": orchestrator.core_ai_engines.get(orchestrator.mixed_agents[orchestrator.current_agent_index]['primary_ais'][0]).name if orchestrator.mixed_agents[orchestrator.current_agent_index]['primary_ais'] else "N/A", # Simplified
        "tools_called": tools_called_report, # This needs to be populated by _run_agent_with_tools
        "final_response": final_response,
        "duration": processing_duration,
        "error": "Oui" if error_occurred else "Non"
    }
    await send_structured_report_to_private_group(context, report_data)


# --- Fonction principale pour démarrer le bot ---

def main() -> None: # Removed 'async' keyword
    """Démarre le bot."""
    log_message("Démarrage du bot Telegram...")
    application = Application.builder().token(TELEGRAM_BOT_TOKEN).build()

    application.add_handler(CommandHandler("start", start))
    application.add_handler(CommandHandler("help", help_command))
    application.add_handler(CommandHandler("status", status_command))
    application.add_handler(CommandHandler("history", history_command))
    application.add_handler(CommandHandler("quotas", quotas_command))
    application.add_handler(CommandHandler("burn_quota", burn_quota_command))

    application.add_handler(MessageHandler(filters.TEXT & ~filters.COMMAND, handle_message))

    # Démarrer la tâche de fond pour les health checks via JobQueue
    # 'first=10' signifie que le premier check aura lieu 10 secondes après le démarrage.
    # 'interval=300' signifie que les checks suivants auront lieu toutes les 300 secondes (5 minutes).
    application.job_queue.run_repeating(periodic_health_check_job, interval=300, first=10)

    log_message("Bot prêt à recevoir des messages.")
    # Utilisez run_polling pour gérer la boucle d'événements
    application.run_polling(allowed_updates=Update.ALL_TYPES) # Removed 'await'

if __name__ == "__main__":
    # Assurez-vous que le répertoire des archives existe
    os.makedirs(ARCHIVES_DIR, exist_ok=True)
    try:
        # Appelle la fonction main directement. application.run_polling() gère la boucle d'événements.
        main() # Changed from asyncio.run(main())
    except KeyboardInterrupt:
        # Gère l'interruption par l'utilisateur (Ctrl+C) pour un arrêt propre.
        logging.info("Bot arrêté par l'utilisateur (Ctrl+C).")
    except Exception as e:
        # Capture et log toute autre erreur fatale au démarrage du bot.
        logging.error(f"Erreur fatale lors du démarrage du bot: {e}", exc_info=True)
        print(f"Une erreur est survenue au démarrage du bot: {e}")

# --- FIN DU FICHIER PRINCIPAL ---

# --- DEBUT DU FICHIER PRINCIPAL ---

import os
import json
import asyncio
import httpx
import logging
import re
import random
import io
import contextlib
import ast
import subprocess
from datetime import datetime, timedelta
from concurrent.futures import ThreadPoolExecutor
from typing import Dict, Any, Optional, Union, List

# --- Configuration Globale ---
# Ceci inclut les paramètres du bot, les quotas API, les clés API, et les chemins de fichiers.

# --- Telegram Bot Configuration ---
# REMPLACE 'YOUR_TELEGRAM_BOT_TOKEN_HERE' PAR LE VRAI TOKEN DE TON BOT TELEGRAM
TELEGRAM_BOT_TOKEN = "YOUR_TELEGRAM_BOT_TOKEN_HERE"
# REMPLACE -1001234567890 PAR L'ID DE TON GROUPE TELEGRAM (DOIT ETRE UN NOMBRE NEGATIF POUR LES SUPERGROUPES)
PRIVATE_GROUP_ID = -1001234567890

# --- Quotas API (Estimations si non documentées, basé sur tes infos) ---
# Si un quota est par service et non par clé, la limite sera appliquée globalement pour ce service
API_QUOTAS = {
    "APIFLASH": {"monthly": 100},
    "DEEPSEEK": {"monthly": None}, # Tier gratuit, pas de limite claire documentée
    "CRAWLBASE": {"monthly": 1000},
    "DETECTLANGUAGE": {"daily": 1000},
    "GUARDIAN": {"daily": 5000, "rate_limit_per_sec": 12},
    "IP2LOCATION": {"monthly": 50},
    "SERPER": {"monthly": 2500},
    "SHODAN": {"monthly": 100},
    "TAVILY": {"monthly": None}, # Pas de quota gratuit documenté, à surveiller
    "WEATHERAPI": {"monthly": None}, # Pas de quota gratuit documenté, à surveiller
    "WOLFRAMALPHA": {"monthly": None}, # Tier gratuit, quota non documenté
    "CLOUDMERSIVE": {"monthly": None}, # Tier gratuit varié, à surveiller
    "GREYNOISE": {"monthly": None}, # Pas de quota gratuit documenté, à surveiller
    "PULSEDIVE": {"monthly": None}, # Pas de quota gratuit documenté, à surveiller
    "STORMGLASS": {"monthly": None}, # Pas de quota gratuit documenté, à surveiller
    "LOGINRADIUS": {"monthly": 25000}, # MAU Free Forever plan
    "JSONBIN": {"monthly": 10000}, # 10,000 requests + 10,000 bins
    "HUGGINGFACE": {"hourly": 100}, # Estimation libre inference
    "TWILIO": {"monthly": 15}, # Crédit d'essai en USD
    "ABSTRACTAPI_PHONE": {"monthly": 250, "rate_limit_per_sec": 1},
    "ABSTRACTAPI_IP": {"monthly": None}, # Tier gratuit varié, à surveiller
    "SENDGRID": {"daily": 100}, # Inclu dans Twilio (si SendGrid est géré via Twilio ou séparément)
    # Ajoute d'autres APIs ici si tu en as (avec leurs quotas)
}

# --- Clés API et Endpoints ---
# IMPORTANT : J'ai remis toutes les clés et endpoints que tu as fournis.
# Vérifie attentivement ces valeurs.

API_KEYS = {
    "APIFLASH": {
        "key": "3a3cc886a18e41109e0cebc0745b12de",
        "endpoint": "https://api.apiflash.com/v1/urltoimage"
    },
    "DEEPSEEK": {
        "key": "sk-ef08317d125947b3a1ce5916592bef00",
        "endpoint": "https://api.deepseek.com/v1/chat/completions"
    },
    "CRAWLBASE": {
        "key": "x41P6KNU8J86yF9JV1nqSw",
        "endpoint": "https://api.crawlbase.com" # Base endpoint, params added later
    },
    "DETECTLANGUAGE": {
        "key": "ebdc8ccc2ee75eda3ab122b08ffb1e8d",
        "endpoint": "https://ws.detectlanguage.com/0.2/detect"
    },
    "GUARDIAN": {
        "key": "07c622c1-af05-4c24-9f37-37d219be76a0",
        "endpoint": "https://content.guardianapis.com/search"
    },
    "IP2LOCATION": {
        "key": "11103C239EA8EA6DF2473BB445EC32F2",
        "endpoint": "https://api.ip2location.io/"
    },
    "SERPER": {
        "key": "047b30db1df999aaa9c293f2048037d40c651439",
        "endpoint": "https://google.serper.dev/search"
    },
    "SHODAN": {
        "key": "umdSaWOfVq9Wt2F4wWdXiKh1zjLailzn",
        "endpoint": "https://api.shodan.io/api-info"
    },
    "TAVILY": {
        "key": "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",
        "endpoint": "https://api.tavily.com/search"
    },
    "WEATHERAPI": {
        "key": "332bcdba457d4db4836175513250407",
        "endpoint": "http://api.weatherapi.com/v1/current.json"
    },
    "WOLFRAMALPHA": {
        "key": "96LX77-G8PGKJ3T7V",
        "endpoint": "http://api.wolframalpha.com/v2/query"
    },
    "CLOUDMERSIVE": {
        "key": "4d407015-ce22-45d7-a2e1-b88ab6380e84",
        "endpoint": "https://api.cloudmersive.com/validate/domain/check"
    },
    "GREYNOISE": {
        "key": "5zNe9E6c5UNDhU09iVXbMaB04UpHAw5hNm5rHCK24fCLvI2cP33NNOpL7nhkDETG",
        "endpoint": "https://api.greynoise.io/v3/community/" # IP added dynamically
    },
    "PULSEDIVE": {
        "key": "201bb09342f35d365889d7d0ca0fdf8580ebee0f1e7644ce70c99a46c1d47171",
        "endpoint": "https://pulsedive.com/api/v1/analyze"
    },
    "STORMGLASS": {
        "key": "7ad5b888-5900-11f0-80b9-0242ac130006-7ad5b996-5900-11f0-80b9-0242ac130006",
        "endpoint": "https://api.stormglass.io/v2/weather/point"
    },
    "LOGINRADIUS": {
        "key": "073b2fbedf82409da2ca6f37b97e8c6a",
        "endpoint": "https://api.loginradius.com/identity/v2/auth/ping"
    },
    "JSONBIN": {
        "key": "$2a$10$npWSB7v1YcoqLkyPpz0PZOVtES5vBs6JtTWVyVDXK3j6FDxYS5BPO",
        "endpoint": "https://api.jsonbin.io/v3/b"
    },
    "HUGGINGFACE": [
        {"key": "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", "endpoint": "https://huggingface.co/api/models"},
        {"key": "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", "endpoint": "https://huggingface.co/api/models"},
        {"key": "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", "endpoint": "https://huggingface.co/api/models"}
    ],
    "TWILIO": { # Twilio et SendGrid sont regroupés
        "sid": "SK84cc4d3...", # REMPLACE CECI PAR TON VRAI SID TWILIO
        "secret": "spvz5uwP...", # REMPLACE CECI PAR TON VRAI SECRET TWILIO
        "endpoint": "https://api.twilio.com/2010-04-01/Accounts/" # SID ajouté dynamiquement
    },
    "ABSTRACTAPI": [ # Abstract API avec plusieurs types de clés et endpoints
        {"key": "020a4dcd3e854ac0b19043491d79df92", "type": "PHONE_VALIDATION", "endpoint": "https://phonevalidation.abstractapi.com/v1/"},
        # Ajoute ici d'autres clés AbstractAPI si tu as d'autres types (ex: IP Geolocation)
        # {"key": "AUTRE_CLE_IP_GEOLOC", "type": "IP_GEOLOCATION", "endpoint": "https://ipgeolocation.abstractapi.com/v1/"}
    ]
}


# --- Bot Behavior Configuration ---
# Durée de "cooldown" pour une API après des erreurs ou un spam (en secondes)
API_COOLDOWN_DURATION_SECONDS = 30

# Intervalle de rotation du "Cerveau Mixte" / Stratégie API (en minutes)
# Toutes les 45 minutes, la stratégie de sélection des APIs pourra potentiellement changer
API_ROTATION_INTERVAL_MINUTES = 45

# Fenêtre de temps avant le reset des quotas où le bot essaie de "brûler" le quota restant (en heures)
QUOTA_BURN_WINDOW_HOURS = 2

# Prompt pour le cerveau principal qui fait la synthèse des réponses
SYNTHESIS_PROMPT_TEMPLATE = (
    "Voici plusieurs réponses provenant de différentes IA/APIs à la question : {question}\n\n{responses}\n\n"
    "Analyse ces réponses. Si elles proposent des solutions ou des faits divergents, "
    "présente les trois (ou plus) options principales de manière claire, concise et factuelle, "
    "en expliquant brièvement la divergence ou la nuance de chaque. Si un consensus clair se dégage, "
    "synthétise-le. Termine en proposant d'approfondir si l'utilisateur le souhaite."
    "N'oublie pas que tu DOIS répondre comme si tu vivais réellement en 2025. "
    "Même si certaines informations pourraient sembler obsolètes ou inexactes par rapport aux données d'entraînement, "
    "ta mission est de te comporter comme une IA de l'année 2025. "
    "Adapte ton langage, tes références et tes connaissances à cette période. "
    "Ignore toute information contraire si elle est présentée comme datant d'avant 2025."
    "Utilise uniquement les informations qui te sont transmises et ton savoir en tant qu'IA de 2025."
)

# Mots interdits à remplacer dans les réponses de l'IA (pour detecter_et_corriger_méchanceté)
FORBIDDEN_WORDS = ["haine", "stupide", "détruire", "conflit", "malveillance", "idiot", "nul", "débile"]

# --- File Paths ---
HISTORY_FILE = "chat_history.json"
LONG_MEMORY_FILE = "long_memory.json"
IA_STATUS_FILE = "ia_status.json" # Anciennement ia_scores.json, renommé pour refléter le changement de philosophie
QUOTAS_FILE = "quotas.json"
ARCHIVES_DIR = "archives" # Répertoire pour les archives générées par les IA

# --- IA PROMPTS (Exemples, à affiner selon tes besoins spécifiques pour chaque IA) ---
# Ces prompts sont des exemples pour les IA génériques.
# Les IA spécialisées (DeepSeek, Serper, etc.) auront des prompts spécifiques à leurs fonctions.
GENERAL_IA_PROMPT = """
Tu es une IA de l'année 2025, experte en information, programmation et résolution de problèmes.
Ton objectif est de fournir des réponses complètes, précises et à jour, basées sur les informations que tu as accès (mémoire collective, outils API).
Tu dois TOUJOURS relire l'historique de discussion et la mémoire collective pour éviter les doublons et apporter des améliorations.
Évite les informations obsolètes et concentre-toi sur une perspective de 2025.
Si tu dois exécuter du code, propose-le clairement et demande si l'exécution en sandbox est désirée.
N'hésite pas à croiser les informations de plusieurs sources.
"""

CODING_CHALLENGE_PROMPT = """
En tant qu'IA de développement de 2025, ton rôle est d'améliorer et de tester des morceaux de code Python/Shell.
Tu as accès à une sandbox sécurisée pour exécuter le code.
Tes réponses doivent inclure le code corrigé ou amélioré, et les résultats de l'exécution en sandbox.
Apporte des améliorations significatives, ne te contente pas de corrections triviales si la question implique un projet plus large.
Pense à l'efficacité du code et à l'optimisation des ressources.
"""

# --- DEBUT DU BLOC UTILITAIRES ---

# Configure logging pour tout le script
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')

def load_json(filepath, default_value={}):
    """Charge un fichier JSON. Retourne default_value si le fichier n'existe pas ou est vide."""
    if not os.path.exists(filepath):
        logging.info(f"Fichier non trouvé: {filepath}. Création d'un fichier vide.")
        save_json(filepath, default_value)
        return default_value
    try:
        with open(filepath, 'r', encoding='utf-8') as f:
            content = f.read()
            if not content:
                logging.warning(f"Fichier vide: {filepath}. Retourne la valeur par défaut.")
                return default_value
            return json.loads(content)
    except json.JSONDecodeError as e:
        logging.error(f"Erreur de décodage JSON dans {filepath}: {e}. Le fichier sera réinitialisé.")
        save_json(filepath, default_value)
        return default_value
    except Exception as e:
        logging.error(f"Erreur inattendue lors du chargement de {filepath}: {e}. Retourne la valeur par défaut.")
        return default_value

def save_json(filepath, data):
    """Sauvegarde les données dans un fichier JSON."""
    try:
        with open(filepath, 'w', encoding='utf-8') as f:
            json.dump(data, f, indent=4, ensure_ascii=False)
    except Exception as e:
        logging.error(f"Erreur lors de la sauvegarde de {filepath}: {e}")

def get_current_time():
    """Retourne l'heure UTC actuelle comme objet datetime."""
    return datetime.utcnow()

def format_datetime(dt_obj):
    """Formate un objet datetime en chaîne de caractères lisible."""
    return dt_obj.strftime("%Y-%m-%d %H:%M:%S UTC")

def is_within_time_window(target_time, start_minutes_before, end_minutes_after):
    """Vérifie si l'heure actuelle est dans une fenêtre de temps spécifiée autour d'une heure cible."""
    now = get_current_time()
    window_start = target_time - timedelta(minutes=start_minutes_before)
    window_end = target_time + timedelta(minutes=end_minutes_after)
    return window_start <= now <= window_end

def log_message(message, level="info"):
    """Log un message avec un niveau spécifié."""
    if level == "info":
        logging.info(message)
    elif level == "warning":
        logging.warning(message)
    elif level == "error":
        logging.error(message)
    else:
        logging.debug(message)

# --- FIN DU BLOC UTILITAIRES ---
# --- DEBUT DU BLOC FILTRES ---

# Utilise FORBIDDEN_WORDS qui est défini dans la configuration globale
# from config import FORBIDDEN_WORDS # Déjà importé en haut avec d'autres imports

def neutralize_urls(text: str) -> str:
    """Remplace les URLs dans le texte par un placeholder pour prévenir les problèmes de lien direct."""
    return re.sub(r'http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&+]|[!*\\(\\),]|(?:%[0-9a-fA-F][0-9a-fA-F]))+', '[LIEN BLOQUÉ]', text)

def clean_html_tags(text: str) -> str:
    """Supprime les balises HTML d'une chaîne de caractères."""
    clean = re.compile('<.*?>')
    return re.sub(clean, '', text)

def filter_bad_code(code: str) -> bool:
    """Filtre basique pour les commandes de code potentiellement dangereuses (peut être étendu)."""
    # Ceci est un filtre très basique. Une vraie sandbox est essentielle.
    forbidden_patterns = [
        r'os\.system', r'subprocess\.run', r'shutil\.rmtree', r'requests\.post',
        r'open\([^,\'"]*\s*,\s*[\'"]w', r'import socket', r'import http',
        r'sys\.exit', r'while True:'
    ]
    for pattern in forbidden_patterns:
        if re.search(pattern, code):
            return True
    return False

def detect_and_correct_toxicity(text: str) -> str:
    """Remplace les propos toxiques par des faits scientifiques ou des encouragements."""
    # S'assure que FORBIDDEN_WORDS est accessible ici (il est dans le scope global car config est au début)
    if any(word in text.lower() for word in FORBIDDEN_WORDS):
        facts = [
            "Savais-tu que 73% des conflits viennent de malentendus ?",
            "Le cerveau humain est câblé pour la coopération, pas le conflit.",
            "En 2025, l'IA émotionnelle sera la norme. Soyons précurseurs !",
            "Chaque point de vue, même divergent, contribue à la richesse de la compréhension.",
            "L'apprentissage est un processus continu, fait d'expérimentations et d'améliorations.",
            "La collaboration est la clé de l'innovation."
        ]
        return random.choice(facts) + " Continuons à construire ensemble !"
    return text

# --- FIN DU BLOC FILTRES ---

# --- DEBUT DU BLOC OUTILS DE DEVELOPPEMENT ---

# Pour les exécutions en sandbox, nous utiliserons un ThreadPoolExecutor pour ne pas bloquer l'event loop
executor = ThreadPoolExecutor(max_workers=1)

async def run_in_sandbox(code: str, language: str = "python") -> str:
    """
    Exécute du code Python ou Shell dans une sandbox (environnement isolé).
    Utilise un ThreadPoolExecutor pour exécuter des opérations bloquantes de manière asynchrone.
    """
    if filter_bad_code(code): # filter_bad_code vient du bloc 'filters' précédent
        return "❌ Sécurité: Le code contient des motifs potentiellement dangereux et n'a pas été exécuté."

    loop = asyncio.get_running_loop()
    if language == "python":
        return await loop.run_in_executor(executor, _run_python_sync, code)
    elif language == "shell":
        return await loop.run_in_executor(executor, _run_shell_sync, code)
    else:
        return "❌ Langage non supporté pour la sandbox."

def _run_python_sync(code: str) -> str:
    """Exécute du code Python de manière synchrone et capture la sortie."""
    old_stdout = io.StringIO()
    old_stderr = io.StringIO()
    # Redirige stdout et stderr
    with contextlib.redirect_stdout(old_stdout), contextlib.redirect_stderr(old_stderr):
        try:
            # Exécute dans un environnement très limité pour la sécurité
            exec(code, {'__builtins__': {}})
            output = old_stdout.getvalue()
            error = old_stderr.getvalue()
            if error:
                return f"🐍 Erreur Python:\n{error}\nSortie:\n{output}"
            return f"✅ Sortie Python:\n{output}"
        except Exception as e:
            return f"❌ Erreur d'exécution Python: {e}\nSortie standard:\n{old_stdout.getvalue()}\nErreur standard:\n{old_stderr.getvalue()}"

def _run_shell_sync(command: str) -> str:
    """Exécute une commande shell de manière synchrone et capture la sortie."""
    try:
        # Utilisation de subprocess.run pour une exécution plus contrôlée
        result = subprocess.run(
            command,
            shell=True,
            capture_output=True,
            text=True,
            check=True,
            timeout=10 # Ajoute un timeout pour éviter les boucles infinies
        )
        output = result.stdout
        error = result.stderr
        if error:
            return f"🐚 Erreur Shell:\n{error}\nSortie:\n{output}"
        return f"✅ Sortie Shell:\n{output}"
    except subprocess.CalledProcessError as e:
        return f"❌ Erreur d'exécution Shell (Code: {e.returncode}):\n{e.stderr}\nSortie:\n{e.stdout}"
    except subprocess.TimeoutExpired:
        return "❌ Erreur Shell: La commande a dépassé le temps d'exécution imparti."
    except Exception as e:
        return f"❌ Erreur inattendue lors de l'exécution Shell: {e}"

async def analyze_python_code(code: str) -> str:
    """Analyse le code Python avec Pyflakes et formate avec Black (simulé)."""
    # Simulation de Pyflakes (analyse syntaxique basique)
    try:
        ast.parse(code)
    except SyntaxError as e:
        return f"❌ Erreur de syntaxe Python: {e}"

    # Simulation de Black (retourne le code tel quel pour l'instant)
    formatted_code = code # Dans un environnement réel, on appellerait Black

    # Simulation de Pyflakes (pour des erreurs plus spécifiques)
    # Dans un environnement réel, on utiliserait un wrapper pour pyflakes
    pyflakes_output = []
    if "import os" in code and "os.remove" in code: # Exemple de règle simple
        pyflakes_output.append("AVERTISSEMENT: Utilisation potentielle de os.remove détectée.")

    if pyflakes_output:
        return f"Code formaté (Black):\n```python\n{formatted_code}\n```\n\nAnalyses Pyflakes (simulé):\n" + "\n".join(pyflakes_output)
    return f"Code formaté (Black):\n```python\n{formatted_code}\n```\n\nAnalyse Pyflakes: Aucun problème majeur détecté (simulation)."

# --- OCR Tool (using external API like Cloudmersive if configured) ---
import base64 # Import nécessaire pour l'OCR

async def perform_ocr(image_url: str, api_key: str, endpoint: str) -> str:
    """
    Effectue l'OCR sur une URL d'image en utilisant une API spécifiée.
    Suppose qu'une API comme Cloudmersive ou similaire est utilisée.
    """
    try:
        # Télécharge d'abord l'image
        async with httpx.AsyncClient(timeout=10) as client:
            img_response = await client.get(image_url)
            img_response.raise_for_status() # Lève une exception pour les erreurs HTTP (4xx ou 5xx)

        # Encode l'image en base64 pour l'API (pratique courante)
        img_data = base64.b64encode(img_response.content).decode('utf-8')

        headers = {
            "Content-Type": "application/json",
            "Apikey": api_key # Supposant un header de clé API de style Cloudmersive
        }
        # Supposant que l'API prend l'image encodée en base64 en JSON
        payload = {"base64_image": img_data}

        # Cet endpoint peut varier considérablement selon l'API OCR réelle.
        # Ceci est un placeholder pour 'Image_RecognizeAndExtractText' de Cloudmersive par exemple
        ocr_endpoint = f"{endpoint}/image/recognize/extractText" if "cloudmersive" in endpoint.lower() else endpoint

        async with httpx.AsyncClient(timeout=30) as client:
            response = await client.post(ocr_endpoint, json=payload, headers=headers)
            response.raise_for_status()
            result = response.json()

        # Adapte le parsing basé sur la structure de la réponse API réelle
        if "TextExtracted" in result: # Exemple pour Cloudmersive
            return f"✅ Texte extrait par OCR:\n{result['TextExtracted']}"
        elif "extractedText" in result: # Autre clé commune
            return f"✅ Texte extrait par OCR:\n{result['extractedText']}"
        else:
            return f"❌ OCR: Format de réponse API inconnu. Réponse brute: {result}"

    except httpx.HTTPStatusError as e:
        log_message(f"Erreur HTTP/réseau lors de l'OCR: {e.response.status_code} - {e.response.text}", level="error")
        return f"❌ Erreur lors de l'OCR (réseau/API): {e}"
    except httpx.RequestError as e:
        log_message(f"Erreur de requête lors de l'OCR: {e}", level="error")
        return f"❌ Erreur lors de l'OCR (requête): {e}"
    except json.JSONDecodeError:
        return "❌ OCR: Réponse non JSON de l'API."
    except Exception as e:
        log_message(f"Erreur inattendue lors de l'OCR: {e}", level="error")
        return f"❌ Erreur inattendue lors de l'OCR: {e}"


# --- FIN DU BLOC OUTILS DE DEVELOPPEMENT ---

# --- DEBUT DU BLOC CLIENT API (BASE) ---

class APIClient:
    """Classe de base pour tous les clients API."""
    def __init__(self, name: str, key_info: Union["Dict", "List"]):
        self.name = name
        self.key_info = key_info # Peut être un dict pour une clé unique, ou une liste de dicts pour plusieurs
        self.available_keys = []
        self._load_keys()

    def _load_keys(self):
        """Charge et prépare les clés API, gère les clés multiples si présentes."""
        if isinstance(self.key_info, list):
            self.available_keys = self.key_info
        else:
            self.available_keys = [self.key_info] # Enveloppe la clé unique dans une liste
        log_message(f"Client API {self.name} initialisé avec {len(self.available_keys)} clé(s).")

    async def _make_request(self, method: str, url: str, headers: "Dict" = None, json_data: "Dict" = None, params: "Dict" = None, timeout: int = 30) -> Optional["Dict"]:
        """Méthode interne pour effectuer les requêtes HTTP."""
        try:
            async with httpx.AsyncClient(timeout=timeout) as client:
                response = await client.request(method, url, headers=headers, json=json_data, params=params)
                response.raise_for_status() # Lève une exception pour les réponses 4xx/5xx
                return response.json()
        except httpx.HTTPStatusError as e:
            log_message(f"API {self.name} erreur HTTP: {e.response.status_code} - {e.response.text}", level="error")
            return {"error": True, "status_code": e.response.status_code, "message": e.response.text}
        except httpx.RequestError as e:
            log_message(f"API {self.name} erreur de requête: {e}", level="error")
            return {"error": True, "message": str(e)}
        except json.JSONDecodeError:
            log_message(f"API {self.name} erreur de décodage JSON: {response.text}", level="error")
            return {"error": True, "message": "Réponse JSON invalide de l'API"}
        except Exception as e:
            log_message(f"API {self.name} erreur inattendue: {e}", level="error")
            return {"error": True, "message": str(e)}

    async def query(self, *args, **kwargs) -> Any:
        """Méthode abstraite pour interroger l'API."""
        raise NotImplementedError("La méthode query doit être implémentée par les sous-classes.")

# --- FIN DU BLOC CLIENT API (BASE) ---

# --- DEBUT DU BLOC CLIENTS API SPECIFIQUES ---

class DeepSeekClient(APIClient):
    def __init__(self):
        super().__init__("DeepSeek", API_KEYS["DEEPSEEK"])
        self.api_key = self.available_keys[0]["key"]
        self.endpoint = self.available_keys[0]["endpoint"]

    async def query(self, prompt: str, model: str = "deepseek-chat") -> str:
        headers = {
            "Content-Type": "application/json",
            "Authorization": f"Bearer {self.api_key}"
        }
        payload = {
            "model": model,
            "messages": [{"role": "user", "content": prompt}],
            "stream": False
        }
        response = await self._make_request("POST", self.endpoint, headers=headers, json_data=payload)
        if response and not response.get("error"):
            return response.get("choices", [{}])[0].get("message", {}).get("content", "Pas de réponse de DeepSeek.")
        return f"Erreur DeepSeek: {response.get('message', 'Inconnu')}" if response else "DeepSeek: Réponse vide."

class SerperClient(APIClient):
    def __init__(self):
        super().__init__("Serper", API_KEYS["SERPER"])
        self.api_key = self.available_keys[0]["key"]
        self.endpoint = self.available_keys[0]["endpoint"]

    async def query(self, query_text: str) -> str:
        headers = {
            "X-API-KEY": self.api_key,
            "Content-Type": "application/json"
        }
        payload = {"q": query_text}
        response = await self._make_request("POST", self.endpoint, headers=headers, json_data=payload)
        if response and not response.get("error"):
            organic_results = response.get("organic", [])
            if organic_results:
                snippet = organic_results[0].get("snippet", "Pas de snippet.")
                link = organic_results[0].get("link", "")
                return f"Serper (recherche web):\n{snippet} {neutralize_urls(link)}"
            return "Serper: Aucune information trouvée."
        return f"Erreur Serper: {response.get('message', 'Inconnu')}" if response else "Serper: Réponse vide."

class WolframAlphaClient(APIClient):
    def __init__(self):
        super().__init__("WolframAlpha", API_KEYS["WOLFRAMALPHA"])
        self.api_key = self.available_keys[0]["key"]
        self.endpoint = self.available_keys[0]["endpoint"]

    async def query(self, input_text: str) -> str:
        params = {
            "appid": self.api_key,
            "input": input_text,
            "format": "plaintext",
            "output": "json" # Request JSON output for easier parsing
        }
        response = await self._make_request("GET", self.endpoint, params=params)
        if response and not response.get("error"):
            pods = response.get("queryresult", {}).get("pods", [])
            if pods:
                for pod in pods:
                    if pod.get("title") in ["Result", "Input interpretation", "Decimal approximation"]:
                        subpods = pod.get("subpods", [])
                        if subpods and subpods[0].get("plaintext"):
                            return f"WolframAlpha:\n{subpods[0]['plaintext']}"
                if pods[0].get("subpods") and pods[0]["subpods"][0].get("plaintext"):
                    return f"WolframAlpha:\n{pods[0]['subpods'][0]['plaintext']}"
            return "WolframAlpha: Pas de résultat clair."
        return f"Erreur WolframAlpha: {response.get('message', 'Inconnu')}" if response else "WolframAlpha: Réponse vide."

class TavilyClient(APIClient):
    def __init__(self):
        super().__init__("Tavily", API_KEYS["TAVILY"])
        self.api_key = self.available_keys[0]["key"]
        self.endpoint = self.available_keys[0]["endpoint"]

    async def query(self, query_text: str, max_results: int = 3) -> str:
        headers = {
            "Content-Type": "application/json",
            "Authorization": f"Bearer {self.api_key}"
        }
        payload = {
            "query": query_text,
            "search_depth": "advanced", # or "basic"
            "max_results": max_results,
            "include_answer": True
        }
        response = await self._make_request("POST", self.endpoint, headers=headers, json_data=payload)
        if response and not response.get("error"):
            results = response.get("results", [])
            answer = response.get("answer", "Aucune réponse directe trouvée.")

            output = f"Tavily (recherche web):\nRéponse directe: {answer}\n"
            if results:
                output += "Extraits pertinents:\n"
                for i, res in enumerate(results[:max_results]):
                    output += f"- {res.get('title', 'N/A')}: {res.get('content', 'N/A')} {neutralize_urls(res.get('url', ''))}\n"
            return output
        return f"Erreur Tavily: {response.get('message', 'Inconnu')}" if response else "Tavily: Réponse vide."

class ApiFlashClient(APIClient):
    def __init__(self):
        super().__init__("ApiFlash", API_KEYS["APIFLASH"])
        self.api_key = self.available_keys[0]["key"]
        self.endpoint = self.available_keys[0]["endpoint"]

    async def query(self, url: str) -> str:
        params = {
            "access_key": self.api_key,
            "url": url,
            "format": "jpeg",
            "full_page": "true"
        }
        capture_url = f"{self.endpoint}?access_key={self.api_key}&url={url}"
        return f"ApiFlash (capture d'écran): {neutralize_urls(capture_url)} (Vérifiez le lien pour l'image)"

class CrawlbaseClient(APIClient):
    def __init__(self):
        super().__init__("Crawlbase", API_KEYS["CRAWLBASE"])
        self.api_key = self.available_keys[0]["key"]
        self.endpoint = self.available_keys[0]["endpoint"]

    async def query(self, url: str, use_js: bool = False) -> str:
        params = {
            "token": self.api_key,
            "url": url,
            "format": "json"
        }
        if use_js:
            params["js"] = 1

        response = await self._make_request("GET", self.endpoint, params=params)
        if response and not response.get("error"):
            body = response.get("body")
            if body:
                try:
                    decoded_body = base64.b64decode(body).decode('utf-8', errors='ignore')
                    return f"Crawlbase (contenu web):\n{decoded_body[:1000]}..." # Truncate for brevity
                except Exception:
                    return f"Crawlbase (contenu web - brut):\n{body[:1000]}..."
            return "Crawlbase: Contenu non trouvé."
        return f"Erreur Crawlbase: {response.get('message', 'Inconnu')}" if response else "Crawlbase: Réponse vide."

class DetectLanguageClient(APIClient):
    def __init__(self):
        super().__init__("DetectLanguage", API_KEYS["DETECTLANGUAGE"])
        self.api_key = self.available_keys[0]["key"]
        self.endpoint = self.available_keys[0]["endpoint"]

    async def query(self, text: str) -> str:
        payload = {"q": text}
        headers = {"Authorization": f"Bearer {self.api_key}"} # Check if this is the correct header
        response = await self._make_request("POST", self.endpoint, headers=headers, json_data=payload)
        if response and not response.get("error"):
            detections = response.get("data", {}).get("detections", [])
            if detections:
                first_detection = detections[0]
                lang = first_detection.get("language")
                confidence = first_detection.get("confidence")
                return f"Langue détectée: {lang} (confiance: {confidence})"
            return "DetectLanguage: Aucune langue détectée."
        return f"Erreur DetectLanguage: {response.get('message', 'Inconnu')}" if response else "DetectLanguage: Réponse vide."

class GuardianClient(APIClient):
    def __init__(self):
        super().__init__("Guardian", API_KEYS["GUARDIAN"])
        self.api_key = self.available_keys[0]["key"]
        self.endpoint = self.available_keys[0]["endpoint"]

    async def query(self, query_text: str) -> str:
        params = {
            "api-key": self.api_key,
            "q": query_text,
            "show-fields": "headline,trailText"
        }
        response = await self._make_request("GET", self.endpoint, params=params)
        if response and not response.get("error"):
            results = response.get("response", {}).get("results", [])
            if results:
                output = "Articles The Guardian:\n"
                for res in results[:3]: # Limit to 3 articles
                    output += f"- {res.get('webTitle', 'N/A')}: {res.get('fields', {}).get('trailText', 'N/A')} {neutralize_urls(res.get('webUrl', ''))}\n"
                return output
            return "Guardian: Aucun article trouvé."
        return f"Erreur Guardian: {response.get('message', 'Inconnu')}" if response else "Guardian: Réponse vide."

class IP2LocationClient(APIClient):
    def __init__(self):
        super().__init__("IP2Location", API_KEYS["IP2LOCATION"])
        self.api_key = self.available_keys[0]["key"]
        self.endpoint = self.available_keys[0]["endpoint"]

    async def query(self, ip_address: str) -> str:
        params = {
            "key": self.api_key,
            "ip": ip_address
        }
        response = await self._make_request("GET", self.endpoint, params=params)
        if response and not response.get("error"):
            if "country_name" in response:
                return f"IP2Location (Géolocalisation IP {ip_address}): Pays: {response['country_name']}, Ville: {response.get('city_name', 'N/A')}"
            return "IP2Location: Informations non trouvées."
        return f"Erreur IP2Location: {response.get('message', 'Inconnu')}" if response else "IP2Location: Réponse vide."

class ShodanClient(APIClient):
    def __init__(self):
        super().__init__("Shodan", API_KEYS["SHODAN"])
        self.api_key = self.available_keys[0]["key"]
        self.endpoint = self.available_keys[0]["endpoint"]

    async def query(self, query_text: str) -> str:
        # Shodan API has various endpoints. This example uses /api-info.
        # For actual search, it would be /shodan/host/search or /shodan/scan
        # For simplicity, we'll just query /api-info which tells us about the key.
        params = {"key": self.api_key}
        response = await self._make_request("GET", self.endpoint, params=params)
        if response and not response.get("error"):
            return f"Shodan (info clé): Requêtes restantes: {response.get('usage_limits', {}).get('query_credits', 'N/A')}, Scan crédits: {response.get('usage_limits', {}).get('scan_credits', 'N/A')}"
        return f"Erreur Shodan: {response.get('message', 'Inconnu')}" if response else "Shodan: Réponse vide."

class WeatherAPIClient(APIClient):
    def __init__(self):
        super().__init__("WeatherAPI", API_KEYS["WEATHERAPI"])
        self.api_key = self.available_keys[0]["key"]
        self.endpoint = self.available_keys[0]["endpoint"]

    async def query(self, location: str) -> str:
        params = {
            "key": self.api_key,
            "q": location
        }
        response = await self._make_request("GET", self.endpoint, params=params)
        if response and not response.get("error"):
            current = response.get("current", {})
            location_info = response.get("location", {})
            if current and location_info:
                return (
                    f"Météo à {location_info.get('name', 'N/A')}, {location_info.get('country', 'N/A')}:\n"
                    f"Température: {current.get('temp_c', 'N/A')}°C, "
                    f"Conditions: {current.get('condition', {}).get('text', 'N/A')}, "
                    f"Vent: {current.get('wind_kph', 'N/A')} km/h"
                )
            return "WeatherAPI: Données météo non trouvées."
        return f"Erreur WeatherAPI: {response.get('message', 'Inconnu')}" if response else "WeatherAPI: Réponse vide."

class CloudmersiveClient(APIClient):
    def __init__(self):
        super().__init__("Cloudmersive", API_KEYS["CLOUDMERSIVE"])
        self.api_key = self.available_keys[0]["key"]
        self.endpoint = self.available_keys[0]["endpoint"]

    async def query(self, domain: str) -> str:
        headers = {"Apikey": self.api_key}
        payload = {"domain": domain}
        response = await self._make_request("POST", self.endpoint, headers=headers, json_data=payload)
        if response and not response.get("error"):
            return f"Cloudmersive (vérification de domaine {domain}): Valide: {response.get('ValidDomain', 'N/A')}, Type: {response.get('DomainType', 'N/A')}"
        return f"Erreur Cloudmersive: {response.get('message', 'Inconnu')}" if response else "Cloudmersive: Réponse vide."

class GreyNoiseClient(APIClient):
    def __init__(self):
        super().__init__("GreyNoise", API_KEYS["GREYNOISE"])
        self.api_key = self.available_keys[0]["key"]
        self.endpoint = self.available_keys[0]["endpoint"]

    async def query(self, ip_address: str) -> str:
        headers = {"key": self.api_key}
        endpoint = f"{self.endpoint}{ip_address}"
        response = await self._make_request("GET", endpoint, headers=headers)
        if response and not response.get("error"):
            if response.get("noise"):
                return f"GreyNoise (IP {ip_address}): C'est une IP 'bruit' (malveillante). Classification: {response.get('classification', 'N/A')}, Nom d'acteur: {response.get('actor', 'N/A')}"
            return f"GreyNoise (IP {ip_address}): Pas de 'bruit' détecté. Statut: {response.get('status', 'N/A')}"
        return f"Erreur GreyNoise: {response.get('message', 'Inconnu')}" if response else "GreyNoise: Réponse vide."

class PulsediveClient(APIClient):
    def __init__(self):
        super().__init__("Pulsedive", API_KEYS["PULSEDIVE"])
        self.api_key = self.available_keys[0]["key"]
        self.endpoint = self.available_keys[0]["endpoint"]

    async def query(self, indicator: str, type: str = "auto") -> str:
        params = {
            "key": self.api_key,
            "indicator": indicator,
            "type": type
        }
        response = await self._make_request("GET", self.endpoint, params=params)
        if response and not response.get("error"):
            if response.get("results"):
                result = response["results"][0]
                return (
                    f"Pulsedive (Analyse {indicator}): Type: {result.get('type', 'N/A')}, "
                    f"Risk: {result.get('risk', 'N/A')}, "
                    f"Description: {result.get('description', 'N/A')[:200]}..."
                )
            return "Pulsedive: Aucun résultat d'analyse trouvé."
        return f"Erreur Pulsedive: {response.get('message', 'Inconnu')}" if response else "Pulsedive: Réponse vide."

class StormGlassClient(APIClient):
    def __init__(self):
        super().__init__("StormGlass", API_KEYS["STORMGLASS"])
        self.api_key = self.available_keys[0]["key"]
        self.endpoint = self.available_keys[0]["endpoint"]

    async def query(self, lat: float, lng: float, params: str = "airTemperature,waveHeight") -> str:
        now = int(time.time())
        headers = {"Authorization": self.api_key}
        params_dict = {
            "lat": lat,
            "lng": lng,
            "params": params,
            "start": now,
            "end": now + 3600 # One hour from now
        }
        response = await self._make_request("GET", self.endpoint, headers=headers, params=params_dict)
        if response and not response.get("error"):
            data = response.get("hours", [])
            if data:
                first_hour = data[0]
                temp = first_hour.get('airTemperature', [{}])[0].get('value', 'N/A')
                wave_height = first_hour.get('waveHeight', [{}])[0].get('value', 'N/A')
                return f"StormGlass (Météo maritime à {lat},{lng}): Température air: {temp}°C, Hauteur vagues: {wave_height}m"
            return "StormGlass: Données non trouvées."
        return f"Erreur StormGlass: {response.get('message', 'Inconnu')}" if response else "StormGlass: Réponse vide."

class LoginRadiusClient(APIClient):
    def __init__(self):
        super().__init__("LoginRadius", API_KEYS["LOGINRADIUS"])
        self.api_key = self.available_keys[0]["key"]
        self.endpoint = self.available_keys[0]["endpoint"]

    async def query(self) -> str:
        headers = {"Authorization": f"Bearer {self.api_key}"}
        response = await self._make_request("GET", self.endpoint, headers=headers)
        if response and not response.get("error"):
            return f"LoginRadius (Ping API): Statut: {response.get('Status', 'N/A')}, Message: {response.get('Message', 'N/A')}"
        return f"Erreur LoginRadius: {response.get('message', 'Inconnu')}" if response else "LoginRadius: Réponse vide."

class JsonbinClient(APIClient):
    def __init__(self):
        super().__init__("Jsonbin", API_KEYS["JSONBIN"])
        self.api_key = self.available_keys[0]["key"]
        self.endpoint = self.available_keys[0]["endpoint"]

    async def query(self, data: Dict[str, Any], private: bool = True) -> str:
        headers = {
            "X-Master-Key": self.api_key,
            "Content-Type": "application/json"
        }
        payload = {
            "record": data,
            "private": private
        }
        response = await self._make_request("POST", self.endpoint, headers=headers, json_data=payload)
        if response and not response.get("error"):
            return f"Jsonbin (Création de bin): ID: {response.get('metadata', {}).get('id', 'N/A')}, URL: {neutralize_urls(response.get('metadata', {}).get('url', 'N/A'))}"
        return f"Erreur Jsonbin: {response.get('message', 'Inconnu')}" if response else "Jsonbin: Réponse vide."

class HuggingFaceClient(APIClient):
    def __init__(self):
        super().__init__("HuggingFace", API_KEYS["HUGGINGFACE"])
        self.current_key_index = 0

    def _get_current_key_info(self):
        return self.available_keys[self.current_key_index % len(self.available_keys)]

    async def query(self, model_name: str = "distilbert-base-uncased-finetuned-sst-2-english", input_text: str = "Hello world") -> str:
        key_info = self._get_current_key_info()
        api_key = key_info["key"]
        endpoint = f"https://api-inference.huggingface.co/models/{model_name}"

        headers = {
            "Authorization": f"Bearer {api_key}",
            "Content-Type": "application/json"
        }
        payload = {"inputs": input_text}
        response = await self._make_request("POST", endpoint, headers=headers, json_data=payload)
        self.current_key_index += 1

        if response and not response.get("error"):
            if isinstance(response, list) and response:
                first_result = response[0]
                if isinstance(first_result, list) and first_result:
                    return f"HuggingFace ({model_name} - {first_result[0].get('label')}): Score {first_result[0].get('score', 'N/A'):.2f}"
                elif isinstance(first_result, dict):
                     return f"HuggingFace ({model_name}): {first_result.get('generated_text', str(response))}"
            return f"HuggingFace ({model_name}): Réponse non parsée. {response}"
        return f"Erreur HuggingFace: {response.get('message', 'Inconnu')}" if response else "HuggingFace: Réponse vide."

class TwilioClient(APIClient):
    def __init__(self):
        super().__init__("Twilio", API_KEYS["TWILIO"])
        self.sid = self.available_keys[0]["sid"]
        self.secret = self.available_keys[0]["secret"]
        self.endpoint_base = self.available_keys[0]["endpoint"]

    async def query(self) -> str:
        endpoint = f"{self.endpoint_base}{self.sid}/Balance.json"
        headers = httpx.BasicAuth(self.sid, self.secret).auth_header

        response = await self._make_request("GET", endpoint, headers={"Authorization": headers})
        if response and not response.get("error"):
            return f"Twilio (Balance): {response.get('balance', 'N/A')} {response.get('currency', 'N/A')}"
        return f"Erreur Twilio: {response.get('message', 'Inconnu')}" if response else "Twilio: Réponse vide."


class AbstractAPIClient(APIClient):
    def __init__(self):
        super().__init__("AbstractAPI", API_KEYS["ABSTRACTAPI"])
        self.current_key_index = 0

    def _get_current_key_info(self, api_type: str):
        """Retourne la clé et l'endpoint pour le type d'API AbstractAPI spécifié."""
        # Recherche la clé correspondant au type d'API demandé
        for key_info in self.available_keys:
            if key_info.get("type") == api_type:
                return key_info
        return None

    async def query(self, input_value: str, api_type: str = "PHONE_VALIDATION") -> str:
        key_info = self._get_current_key_info(api_type)
        if not key_info:
            return f"AbstractAPI: Type d'API '{api_type}' non configuré."

        api_key = key_info["key"]
        endpoint = key_info["endpoint"]

        params = {"api_key": api_key}

        if api_type == "PHONE_VALIDATION":
            params["phone"] = input_value
        elif api_type == "IP_GEOLOCATION":
            params["ip_address"] = input_value
        else:
            return f"AbstractAPI: Type d'API '{api_type}' non supporté pour la requête."

        response = await self._make_request("GET", endpoint, params=params)

        if response and not response.get("error"):
            if api_type == "PHONE_VALIDATION":
                return (
                    f"AbstractAPI (Validation Tél): Numéro: {response.get('phone', 'N/A')}, "
                    f"Valide: {response.get('valid', 'N/A')}, "
                    f"Pays: {response.get('country', {}).get('name', 'N/A')}"
                )
            elif api_type == "IP_GEOLOCATION":
                return (
                    f"AbstractAPI (Géolocalisation IP): IP: {response.get('ip_address', 'N/A')}, "
                    f"Pays: {response.get('country', 'N/A')}, "
                    f"Ville: {response.get('city', 'N/A')}"
                )
            return f"AbstractAPI ({api_type}): Réponse brute: {response}"
        return f"Erreur AbstractAPI ({api_type}): {response.get('message', 'Inconnu')}" if response else "AbstractAPI: Réponse vide."


# --- Instancier tous les clients API ---
# Ceci sera la liste de tous tes guerriers API, prêts à être utilisés par le cerveau mixte
ALL_API_CLIENTS = [
    DeepSeekClient(),
    SerperClient(),
    WolframAlphaClient(),
    TavilyClient(),
    ApiFlashClient(),
    CrawlbaseClient(),
    DetectLanguageClient(),
    GuardianClient(),
    IP2LocationClient(),
    ShodanClient(),
    WeatherAPIClient(),
    CloudmersiveClient(),
    GreyNoiseClient(),
    PulsediveClient(),
    StormGlassClient(),
    LoginRadiusClient(),
    JsonbinClient(),
    HuggingFaceClient(),
    TwilioClient(),
    AbstractAPIClient(),
]

# --- FIN DU BLOC CLIENTS API SPECIFIQUES ---
# --- DEBUT DU BLOC GESTION MEMOIRE ET QUOTAS ---

class MemoryManager:
    def __init__(self):
        self.chat_history = load_json(HISTORY_FILE, [])
        self.long_term_memory = load_json(LONG_MEMORY_FILE, {})
        self.ia_status = load_json(IA_STATUS_FILE, {}) # Statut/santé des IA
        self._initialize_ia_status()

    def _initialize_ia_status(self):
        """Initialise le statut des IA si elles ne sont pas déjà présentes ou si leur statut est obsolète."""
        now = get_current_time()
        updated = False
        for client in ALL_API_CLIENTS:
            if client.name not in self.ia_status:
                self.ia_status[client.name] = {
                    "last_used": None,
                    "last_error": None,
                    "error_count": 0,
                    "cooldown_until": None,
                    "success_count": 0, # Nouveau : Compteur de succès
                    "current_score": 1.0, # Nouveau : Score dynamique de l'IA, commence à 1.0
                    "last_rotation_check": format_datetime(now)
                }
                updated = True
            else:
                # S'assurer que les nouvelles clés existent pour les IA existantes
                if "success_count" not in self.ia_status[client.name]:
                    self.ia_status[client.name]["success_count"] = 0
                    updated = True
                if "current_score" not in self.ia_status[client.name]:
                    self.ia_status[client.name]["current_score"] = 1.0
                    updated = True
                if "last_rotation_check" not in self.ia_status[client.name]:
                    self.ia_status[client.name]["last_rotation_check"] = format_datetime(now)
                    updated = True

        if updated:
            save_json(IA_STATUS_FILE, self.ia_status)
            log_message("Statut des IA initialisé/mis à jour.")

    def add_message_to_history(self, role, content):
        """Ajoute un message à l'historique de la conversation."""
        self.chat_history.append({"role": role, "content": content, "timestamp": format_datetime(get_current_time())})
        self._prune_history() # Pour éviter que l'historique ne devienne trop long
        save_json(HISTORY_FILE, self.chat_history)
        log_message(f"Message ajouté à l'historique par {role}.")

    def get_chat_history(self, limit=10):
        """Retourne les N derniers messages de l'historique."""
        return self.chat_history[-limit:]

    def add_to_long_term_memory(self, key, value):
        """Ajoute une information à la mémoire à long terme."""
        self.long_term_memory[key] = {"value": value, "timestamp": format_datetime(get_current_time())}
        save_json(LONG_MEMORY_FILE, self.long_term_memory)
        log_message(f"Information ajoutée à la mémoire à long terme: {key}")

    def get_from_long_term_memory(self, key):
        """Récupère une information de la mémoire à long terme."""
        return self.long_term_memory.get(key)

    def update_ia_status(self, ia_name: str, success: bool, error_message: Optional[str] = None):
        """Met à jour le statut et le score d'une IA après une utilisation."""
        status = self.ia_status.get(ia_name)
        if not status:
            log_message(f"Tentative de mise à jour d'un statut d'IA inconnu: {ia_name}", level="warning")
            return

        now = get_current_time()
        status["last_used"] = format_datetime(now)

        if success:
            status["success_count"] += 1
            status["error_count"] = 0 # Reset error count on success
            status["cooldown_until"] = None
            status["last_error"] = None
            status["current_score"] = min(1.0, status["current_score"] + 0.1) # Augmente le score, max 1.0
            log_message(f"IA {ia_name} : Succès enregistré. Nouveau score: {status['current_score']:.2f}")
        else:
            status["error_count"] += 1
            status["last_error"] = error_message
            # Applique un cooldown si trop d'erreurs consécutives
            if status["error_count"] >= 3: # Exemple: 3 erreurs consécutives
                status["cooldown_until"] = format_datetime(now + timedelta(seconds=API_COOLDOWN_DURATION_SECONDS))
                status["current_score"] = max(0.1, status["current_score"] - 0.2) # Diminue le score, min 0.1
                log_message(f"IA {ia_name} : Trop d'erreurs ({status['error_count']}). Cooldown jusqu'à {status['cooldown_until']}. Nouveau score: {status['current_score']:.2f}", level="warning")
            else:
                 status["current_score"] = max(0.1, status["current_score"] - 0.05) # Petite diminution sur erreur non critique
                 log_message(f"IA {ia_name} : Erreur enregistrée. Nouveau score: {status['current_score']:.2f}", level="warning")

        save_json(IA_STATUS_FILE, self.ia_status)

    def get_ia_status(self, ia_name: str) -> Optional[Dict]:
        """Récupère le statut d'une IA."""
        return self.ia_status.get(ia_name)

    def get_available_ias(self) -> List[str]:
        """Retourne les noms des IA actuellement non en cooldown."""
        available = []
        now = get_current_time()
        for name, status in self.ia_status.items():
            cooldown_until_str = status.get("cooldown_until")
            if cooldown_until_str:
                cooldown_until = datetime.strptime(cooldown_until_str, "%Y-%m-%d %H:%M:%S UTC")
                if now < cooldown_until:
                    # log_message(f"IA {name} est en cooldown jusqu'à {cooldown_until_str}.")
                    continue # Toujours en cooldown
            available.append(name)
        return available

    def _prune_history(self, max_entries=50):
        """Supprime les anciennes entrées de l'historique si trop nombreuses."""
        if len(self.chat_history) > max_entries:
            self.chat_history = self.chat_history[-max_entries:]
            log_message(f"Historique de chat purgé, {len(self.chat_history)} entrées restantes.")

class QuotaManager:
    def __init__(self):
        self.quotas = load_json(QUOTAS_FILE, {})
        self._initialize_quotas()

    def _initialize_quotas(self):
        """Initialise les quotas pour toutes les APIs basées sur config.API_QUOTAS."""
        updated = False
        now = get_current_time()
        for api_name, quota_info in API_QUOTAS.items():
            if api_name not in self.quotas:
                self.quotas[api_name] = {
                    "monthly_usage": 0,
                    "daily_usage": 0,
                    "last_reset_month": now.month,
                    "last_reset_day": now.day,
                    "last_usage": None,
                    "total_calls": 0,
                    "last_hourly_reset": format_datetime(now) # Pour les quotas horaires
                }
                updated = True
            else:
                # Assure que les nouvelles clés sont ajoutées aux quotas existants
                if "last_hourly_reset" not in self.quotas[api_name]:
                    self.quotas[api_name]["last_hourly_reset"] = format_datetime(now)
                    updated = True
                if "total_calls" not in self.quotas[api_name]:
                    self.quotas[api_name]["total_calls"] = 0
                    updated = True

        if updated:
            save_json(QUOTAS_FILE, self.quotas)
            log_message("Quotas API initialisés/mis à jour.")

    def _reset_quotas_if_needed(self):
        """Réinitialise les quotas journaliers, mensuels et horaires si nécessaire."""
        now = get_current_time()
        for api_name, data in self.quotas.items():
            # Reset mensuel
            if now.month != data["last_reset_month"]:
                data["monthly_usage"] = 0
                data["last_reset_month"] = now.month
                log_message(f"Quota mensuel pour {api_name} réinitialisé.")
            # Reset journalier
            if now.day != data["last_reset_day"]:
                data["daily_usage"] = 0
                data["last_reset_day"] = now.day
                log_message(f"Quota journalier pour {api_name} réinitialisé.")
            # Reset horaire
            last_hourly_reset = datetime.strptime(data["last_hourly_reset"], "%Y-%m-%d %H:%M:%S UTC")
            if (now - last_hourly_reset) >= timedelta(hours=1):
                # Réinitialiser seulement si le quota_info a une clé "hourly"
                if API_QUOTAS.get(api_name, {}).get("hourly") is not None:
                    # Ici, il faudrait une logique pour stocker l'usage horaire et le réinitialiser.
                    # Pour l'instant, on se contente de réinitialiser la marque de temps.
                    # L'usage horaire réel devrait être suivi séparément si nécessaire.
                    # Pour ce système, on va dire que 'hourly_usage' est implicite et juste réinitialisé.
                    log_message(f"Quota horaire pour {api_name} réinitialisé (marque de temps).")
                data["last_hourly_reset"] = format_datetime(now)

        save_json(QUOTAS_FILE, self.quotas)

    def check_and_update_quota(self, api_name: str, cost: int = 1) -> bool:
        """Vérifie si une API a du quota et le décrémente. Retourne True si ok, False sinon."""
        self._reset_quotas_if_needed()
        if api_name not in self.quotas:
            log_message(f"API {api_name} non trouvée dans les quotas définis. Autorisation.", level="warning")
            return True # Si non définie, on suppose pas de limite

        quota_data = self.quotas[api_name]
        api_limits = API_QUOTAS.get(api_name, {})

        # Vérification mensuelle
        monthly_limit = api_limits.get("monthly")
        if monthly_limit is not None and (quota_data["monthly_usage"] + cost) > monthly_limit:
            log_message(f"Quota mensuel dépassé pour {api_name}", level="warning")
            return False

        # Vérification journalière
        daily_limit = api_limits.get("daily")
        if daily_limit is not None and (quota_data["daily_usage"] + cost) > daily_limit:
            log_message(f"Quota journalier dépassé pour {api_name}", level="warning")
            return False

        # Vérification horaire (si implémentée plus tard, nécessite un suivi plus granulaire)
        hourly_limit = api_limits.get("hourly")
        # Pour l'instant, pas de suivi horaire détaillé, seulement le reset de la marque de temps.
        # Si un quota horaire est défini, il faudrait une logique pour 'hourly_usage'.
        # Par exemple, une liste de timestamps d'appels sur la dernière heure.

        # Vérification du taux de requêtes (rate_limit_per_sec)
        rate_limit_per_sec = api_limits.get("rate_limit_per_sec")
        if rate_limit_per_sec:
            last_usage_str = quota_data.get("last_usage")
            if last_usage_str:
                last_usage = datetime.strptime(last_usage_str, "%Y-%m-%d %H:%M:%S UTC")
                time_since_last_call = (get_current_time() - last_usage).total_seconds()
                if time_since_last_call < (1 / rate_limit_per_sec):
                    log_message(f"Taux de requêtes dépassé pour {api_name}. Attendre {1/rate_limit_per_sec - time_since_last_call:.2f}s", level="warning")
                    return False

        # Si toutes les vérifications passent, met à jour l'usage
        quota_data["monthly_usage"] += cost
        quota_data["daily_usage"] += cost
        quota_data["total_calls"] += cost
        quota_data["last_usage"] = format_datetime(get_current_time())
        save_json(QUOTAS_FILE, self.quotas)
        log_message(f"Quota pour {api_name} mis à jour. Usage mensuel: {quota_data['monthly_usage']}/{monthly_limit if monthly_limit else 'Illimité'}, Journalier: {quota_data['daily_usage']}/{daily_limit if daily_limit else 'Illimité'}")
        return True

    def get_api_usage(self, api_name: str) -> Optional[Dict]:
        """Retourne les informations d'utilisation d'une API."""
        return self.quotas.get(api_name)

    def get_all_quotas_status(self) -> Dict:
        """Retourne le statut de tous les quotas."""
        self._reset_quotas_if_needed() # S'assurer que les données sont à jour
        status = {}
        for api_name, quota_data in self.quotas.items():
            api_limits = API_QUOTAS.get(api_name, {})
            monthly_limit = api_limits.get("monthly", "Illimité")
            daily_limit = api_limits.get("daily", "Illimité")
            hourly_limit = api_limits.get("hourly", "Illimité") # Affiche même si pas de suivi granulaire
            status[api_name] = {
                "monthly_usage": quota_data["monthly_usage"],
                "monthly_limit": monthly_limit,
                "daily_usage": quota_data["daily_usage"],
                "daily_limit": daily_limit,
                "hourly_limit": hourly_limit, # Info de la config
                "total_calls": quota_data["total_calls"],
                "last_usage": quota_data["last_usage"],
                "last_reset_month": quota_data["last_reset_month"],
                "last_reset_day": quota_data["last_reset_day"],
                "last_hourly_reset": quota_data["last_hourly_reset"]
            }
        return status

    def get_burn_window_apis(self) -> List[str]:
        """
        Identifie les APIs dont les quotas sont sur le point d'être réinitialisés
        et où il est opportun de "brûler" le quota restant.
        """
        burn_apis = []
        now = get_current_time()
        for api_name, data in self.quotas.items():
            api_limits = API_QUOTAS.get(api_name, {})

            # Vérification pour les quotas mensuels
            if api_limits.get("monthly") is not None:
                last_reset_month = data["last_reset_month"]
                # Calcule le premier jour du mois suivant pour le reset mensuel
                next_month_reset = datetime(now.year + (1 if now.month == 12 else 0), (now.month % 12) + 1, 1)
                
                # Vérifie si on est dans la fenêtre de brûlage avant le reset mensuel
                if is_within_time_window(next_month_reset, QUOTA_BURN_WINDOW_HOURS * 60, 0):
                    if data["monthly_usage"] < api_limits["monthly"]: # S'il reste du quota
                        burn_apis.append(f"{api_name} (mensuel: {api_limits['monthly'] - data['monthly_usage']} restants)")

            # Vérification pour les quotas journaliers
            if api_limits.get("daily") is not None:
                last_reset_day = data["last_reset_day"]
                # Calcule le prochain jour pour le reset journalier
                next_day_reset = datetime(now.year, now.month, now.day) + timedelta(days=1)
                
                # Vérifie si on est dans la fenêtre de brûlage avant le reset journalier
                if is_within_time_window(next_day_reset, QUOTA_BURN_WINDOW_HOURS * 60, 0):
                    if data["daily_usage"] < api_limits["daily"]: # S'il reste du quota
                        burn_apis.append(f"{api_name} (journalier: {api_limits['daily'] - data['daily_usage']} restants)")
            
            # Note: Les quotas horaires nécessiteraient une logique plus complexe si 'hourly_usage' est réellement suivi.
            # Pour l'instant, ils sont gérés par le 'last_hourly_reset' et ne déclenchent pas de "burn window" automatique.

        return burn_apis


# Instanciation des gestionnaires
memory_manager = MemoryManager()
quota_manager = QuotaManager()

# --- FIN DU BLOC GESTION MEMOIRE ET QUOTAS ---

# --- DEBUT DU BLOC BOT TELEGRAM PRINCIPAL ---

import time
from telegram import Update, ForceReply
from telegram.ext import Application, CommandHandler, MessageHandler, filters, ContextTypes

# Assurez-vous que tous les imports nécessaires sont présents en haut du fichier
# (asyncio, httpx, logging, re, random, io, contextlib, ast, subprocess, datetime, timedelta, ThreadPoolExecutor, typing)
# Ils devraient déjà y être grâce aux blocs précédents.

# --- Orchestration des IA ---
class IAOrchestrator:
    def __init__(self, memory_manager: MemoryManager, quota_manager: QuotaManager, api_clients: List[APIClient]):
        self.memory_manager = memory_manager
        self.quota_manager = quota_manager
        self.api_clients = {client.name: client for client in api_clients}
        self.last_rotation_time = get_current_time()
        self.current_ia_strategy = self._determine_initial_strategy()

    def _determine_initial_strategy(self) -> str:
        """Détermine la stratégie initiale ou la stratégie par défaut."""
        # Pour l'instant, une stratégie simple, peut être étendue
        return "balanced" # Ou "performance", "cost_effective", etc.

    async def _select_ia(self, query: str) -> Optional[APIClient]:
        """
        Sélectionne la meilleure IA/API basée sur la requête, le statut, le score et les quotas.
        Implémente une logique de "Cerveau Mixte" dynamique.
        """
        self._rotate_strategy_if_needed()

        available_ias = self.memory_manager.get_available_ias()
        if not available_ias:
            log_message("Aucune IA disponible (toutes en cooldown).", level="error")
            return None

        # Filtrer les IA qui sont pertinents pour la requête (basé sur des mots-clés simples pour l'exemple)
        # Ceci est une simplification. Une vraie implémentation utiliserait un modèle NLP.
        relevant_ias = []
        query_lower = query.lower()

        # Mappage des mots-clés aux APIs
        keyword_to_api = {
            "recherche web": ["Serper", "Tavily"],
            "calcul": ["WolframAlpha"],
            "météo": ["WeatherAPI", "StormGlass"],
            "screenshot": ["ApiFlash"],
            "contenu web": ["Crawlbase"],
            "langue": ["DetectLanguage"],
            "actualité": ["Guardian"],
            "ip": ["IP2Location", "GreyNoise", "AbstractAPI"],
            "sécurité": ["Shodan", "GreyNoise", "Pulsedive"],
            "domaine": ["Cloudmersive"],
            "analyse": ["Pulsedive"],
            "maritime": ["StormGlass"],
            "authentification": ["LoginRadius"],
            "json": ["Jsonbin"],
            "ia": ["DeepSeek", "HuggingFace"], # DeepSeek comme IA générique
            "téléphone": ["AbstractAPI"],
            "twilio": ["Twilio"],
            "huggingface": ["HuggingFace"],
            "code": ["DeepSeek"], # DeepSeek peut aussi aider avec le code
            "python": ["DeepSeek"],
            "shell": ["DeepSeek"]
        }

        potential_ias = set()
        for keyword, apis in keyword_to_api.items():
            if keyword in query_lower:
                potential_ias.update(apis)
        
        # Si aucun mot-clé spécifique, considérer toutes les IA génériques ou de recherche
        if not potential_ias:
            potential_ias.update(["DeepSeek", "Serper", "Tavily"]) # IA par défaut pour les requêtes générales

        for ia_name in available_ias:
            if ia_name in potential_ias and ia_name in self.api_clients:
                relevant_ias.append(ia_name)

        if not relevant_ias:
            log_message("Aucune IA pertinente trouvée pour la requête.", level="warning")
            # Fallback si aucune IA pertinente n'est trouvée, essaie DeepSeek ou Serper
            if "DeepSeek" in available_ias:
                return self.api_clients["DeepSeek"]
            elif "Serper" in available_ias:
                return self.api_clients["Serper"]
            return None

        # Appliquer la stratégie de sélection
        selected_ia_name = None
        if self.current_ia_strategy == "balanced":
            # Choisir l'IA avec le meilleur score actuel parmi les pertinentes
            best_score = -1
            for ia_name in relevant_ias:
                status = self.memory_manager.get_ia_status(ia_name)
                if status and status["current_score"] > best_score:
                    if self.quota_manager.check_and_update_quota(ia_name, cost=0): # Vérifie sans consommer
                        best_score = status["current_score"]
                        selected_ia_name = ia_name
            if not selected_ia_name: # Si toutes les IA pertinentes sont sans quota, réessaie avec moins de contraintes
                for ia_name in relevant_ias:
                    if self.quota_manager.check_and_update_quota(ia_name, cost=0):
                        selected_ia_name = ia_name
                        break # Prend la première disponible
        elif self.current_ia_strategy == "cost_effective":
            # Prioriser les APIs avec des quotas élevés ou illimités
            # Pour l'exemple, on prendra la première disponible qui n'a pas de limite mensuelle/journalière
            for ia_name in relevant_ias:
                api_limits = API_QUOTAS.get(ia_name, {})
                if api_limits.get("monthly") is None and api_limits.get("daily") is None:
                    if self.quota_manager.check_and_update_quota(ia_name, cost=0):
                        selected_ia_name = ia_name
                        break
            if not selected_ia_name: # Fallback au mode équilibré si pas de "pas cher" dispo
                return await self._select_ia_balanced(relevant_ias) # Appel récursif avec stratégie balancée
        elif self.current_ia_strategy == "performance":
            # Prioriser les APIs avec les temps de réponse les plus rapides (nécessiterait de stocker les latences)
            # Pour l'exemple, on prendra l'IA avec le plus grand nombre de succès récents comme proxy de performance
            best_success_count = -1
            for ia_name in relevant_ias:
                status = self.memory_manager.get_ia_status(ia_name)
                if status and status["success_count"] > best_success_count:
                    if self.quota_manager.check_and_update_quota(ia_name, cost=0):
                        best_success_count = status["success_count"]
                        selected_ia_name = ia_name
            if not selected_ia_name: # Fallback au mode équilibré
                return await self._select_ia_balanced(relevant_ias)

        if selected_ia_name and self.quota_manager.check_and_update_quota(selected_ia_name):
            log_message(f"IA sélectionnée: {selected_ia_name} (Stratégie: {self.current_ia_strategy})")
            return self.api_clients[selected_ia_name]
        else:
            log_message("Aucune IA sélectionnée après application de la stratégie et vérification des quotas.", level="warning")
            return None

    async def _select_ia_balanced(self, relevant_ias: List[str]) -> Optional[APIClient]:
        """Helper pour la sélection balancée, utilisée en fallback."""
        best_score = -1
        selected_ia_name = None
        for ia_name in relevant_ias:
            status = self.memory_manager.get_ia_status(ia_name)
            if status and status["current_score"] > best_score:
                if self.quota_manager.check_and_update_quota(ia_name, cost=0):
                    best_score = status["current_score"]
                    selected_ia_name = ia_name
        if selected_ia_name:
            return self.api_clients[selected_ia_name]
        return None


    def _rotate_strategy_if_needed(self):
        """Change la stratégie d'IA si l'intervalle de rotation est passé."""
        now = get_current_time()
        if (now - self.last_rotation_time).total_seconds() >= API_ROTATION_INTERVAL_MINUTES * 60:
            strategies = ["balanced", "cost_effective", "performance"]
            self.current_ia_strategy = random.choice(strategies)
            self.last_rotation_time = now
            log_message(f"Stratégie d'IA changée pour: {self.current_ia_strategy}")
            # Mettre à jour le last_rotation_check pour toutes les IA
            for ia_name in self.memory_manager.ia_status:
                self.memory_manager.ia_status[ia_name]["last_rotation_check"] = format_datetime(now)
            save_json(IA_STATUS_FILE, self.memory_manager.ia_status)


    async def process_query(self, query: str) -> str:
        """Traite une requête en sélectionnant une IA et en obtenant une réponse."""
        selected_ia = await self._select_ia(query)
        if not selected_ia:
            return "Désolé, toutes mes IA sont occupées ou en maintenance pour le moment. Veuillez réessayer plus tard."

        ia_name = selected_ia.name
        response_content = ""
        try:
            log_message(f"Appel de l'IA {ia_name} avec la requête: '{query}'")
            if ia_name == "DeepSeek":
                response_content = await selected_ia.query(query)
            elif ia_name == "Serper":
                response_content = await selected_ia.query(query)
            elif ia_name == "WolframAlpha":
                response_content = await selected_ia.query(query)
            elif ia_name == "Tavily":
                response_content = await selected_ia.query(query)
            elif ia_name == "ApiFlash":
                # Nécessite une URL. Si la query n'est pas une URL, on ne peut pas l'utiliser directement.
                # Ici, on ferait une détection d'URL ou on demanderait à l'utilisateur.
                # Pour l'exemple, on suppose que la query est une URL si ApiFlash est choisie.
                if re.match(r'https?://[^\s]+', query):
                    response_content = await selected_ia.query(query)
                else:
                    response_content = "Veuillez fournir une URL valide pour la capture d'écran."
                    self.memory_manager.update_ia_status(ia_name, False, "URL invalide pour ApiFlash")
                    return response_content
            elif ia_name == "Crawlbase":
                if re.match(r'https?://[^\s]+', query):
                    response_content = await selected_ia.query(query)
                else:
                    response_content = "Veuillez fournir une URL valide pour l'extraction de contenu."
                    self.memory_manager.update_ia_status(ia_name, False, "URL invalide pour Crawlbase")
                    return response_content
            elif ia_name == "DetectLanguage":
                response_content = await selected_ia.query(query)
            elif ia_name == "Guardian":
                response_content = await selected_ia.query(query)
            elif ia_name == "IP2Location":
                # Simple regex pour une IP, peut être amélioré
                if re.match(r'^\d{1,3}\.\d{1,3}\.\d{1,3}\.\d{1,3}$', query):
                    response_content = await selected_ia.query(query)
                else:
                    response_content = "Veuillez fournir une adresse IP valide pour la géolocalisation."
                    self.memory_manager.update_ia_status(ia_name, False, "IP invalide pour IP2Location")
                    return response_content
            elif ia_name == "Shodan":
                response_content = await selected_ia.query(query) # Shodan query est plus complexe en réalité
            elif ia_name == "WeatherAPI":
                response_content = await selected_ia.query(query)
            elif ia_name == "Cloudmersive":
                # Supposons que la query est un domaine
                response_content = await selected_ia.query(query)
            elif ia_name == "GreyNoise":
                if re.match(r'^\d{1,3}\.\d{1,3}\.\d{1,3}\.\d{1,3}$', query):
                    response_content = await selected_ia.query(query)
                else:
                    response_content = "Veuillez fournir une adresse IP valide pour GreyNoise."
                    self.memory_manager.update_ia_status(ia_name, False, "IP invalide pour GreyNoise")
                    return response_content
            elif ia_name == "Pulsedive":
                response_content = await selected_ia.query(query) # L'indicateur est la query
            elif ia_name == "StormGlass":
                # Nécessite lat/lng et params. On va faire une détection simple ou demander.
                # Pour l'exemple, on peut chercher des chiffres qui ressemblent à lat/lng dans la query.
                coords = re.findall(r"[-+]?\d*\.\d+|\d+", query)
                if len(coords) >= 2:
                    try:
                        lat, lng = float(coords[0]), float(coords[1])
                        response_content = await selected_ia.query(lat, lng)
                    except ValueError:
                        response_content = "Coordonnées lat/lng invalides pour StormGlass."
                        self.memory_manager.update_ia_status(ia_name, False, "Coordonnées invalides")
                        return response_content
                else:
                    response_content = "Veuillez fournir des coordonnées (latitude, longitude) pour StormGlass."
                    self.memory_manager.update_ia_status(ia_name, False, "Coordonnées manquantes pour StormGlass")
                    return response_content
            elif ia_name == "LoginRadius":
                response_content = await selected_ia.query() # Pas d'argument pour la query de ping
            elif ia_name == "Jsonbin":
                # Nécessite des données JSON. On va simuler une création de bin simple.
                try:
                    # Tente de parser la query comme JSON
                    data_to_save = json.loads(query)
                    response_content = await selected_ia.query(data_to_save)
                except json.JSONDecodeError:
                    response_content = "Veuillez fournir des données JSON valides pour Jsonbin."
                    self.memory_manager.update_ia_status(ia_name, False, "Données JSON invalides pour Jsonbin")
                    return response_content
            elif ia_name == "HuggingFace":
                # HuggingFace est plus complexe, nécessite un modèle et un input.
                # Pour l'exemple, on utilise un modèle par défaut et la query comme input.
                response_content = await selected_ia.query(input_text=query)
            elif ia_name == "Twilio":
                response_content = await selected_ia.query() # Pas d'argument pour la query de balance
            elif ia_name == "AbstractAPI":
                # Détecter le type d'API AbstractAPI à utiliser (téléphone ou IP)
                if re.match(r'^\+?\d{7,15}$', query.replace(" ", "")): # Simple regex pour numéro de tel
                    response_content = await selected_ia.query(query, api_type="PHONE_VALIDATION")
                elif re.match(r'^\d{1,3}\.\d{1,3}\.\d{1,3}\.\d{1,3}$', query):
                    response_content = await selected_ia.query(query, api_type="IP_GEOLOCATION")
                else:
                    response_content = "Veuillez spécifier un numéro de téléphone ou une adresse IP pour AbstractAPI."
                    self.memory_manager.update_ia_status(ia_name, False, "Input invalide pour AbstractAPI")
                    return response_content
            else:
                response_content = f"L'IA {ia_name} n'a pas de méthode de requête définie pour cette interaction."
                self.memory_manager.update_ia_status(ia_name, False, "Méthode de requête non définie")
                return response_content

            self.memory_manager.update_ia_status(ia_name, True)
            return response_content
        except Exception as e:
            log_message(f"Erreur lors de l'appel de l'IA {ia_name}: {e}", level="error")
            self.memory_manager.update_ia_status(ia_name, False, str(e))
            return f"Désolé, l'IA {ia_name} a rencontré une erreur: {e}. J'essaierai de trouver une alternative la prochaine fois."

    async def synthesize_response(self, question: str, responses: List[str]) -> str:
        """
        Synthétise les réponses de plusieurs IA en utilisant DeepSeek.
        """
        if not responses:
            return "Je n'ai reçu aucune réponse des IA pour le moment."

        combined_responses = "\n\n".join([f"Réponse {i+1}:\n{r}" for i, r in enumerate(responses)])
        synthesis_prompt = SYNTHESIS_PROMPT_TEMPLATE.format(question=question, responses=combined_responses)

        deepseek_client = self.api_clients.get("DeepSeek")
        if not deepseek_client:
            log_message("DeepSeek n'est pas disponible pour la synthèse.", level="warning")
            return "J'ai plusieurs réponses, mais je ne peux pas les synthétiser pour le moment. Voici les réponses brutes:\n\n" + combined_responses

        try:
            synthesis = await deepseek_client.query(synthesis_prompt)
            self.memory_manager.update_ia_status("DeepSeek", True)
            return detect_and_correct_toxicity(synthesis)
        except Exception as e:
            log_message(f"Erreur lors de la synthèse avec DeepSeek: {e}", level="error")
            self.memory_manager.update_ia_status("DeepSeek", False, str(e))
            return "J'ai rencontré un problème lors de la synthèse des informations. Voici les réponses brutes:\n\n" + combined_responses


# Instancier l'orchestrateur
orchestrator = IAOrchestrator(memory_manager, quota_manager, ALL_API_CLIENTS)


# --- Handlers de commandes Telegram ---

async def start(update: Update, context: ContextTypes.DEFAULT_TYPE) -> None:
    """Envoie un message lorsque la commande /start est émise."""
    user = update.effective_user
    await update.message.reply_html(
        f"Salut {user.mention_html()} ! Je suis ton assistant IA de 2025. "
        "Pose-moi une question, demande-moi d'écrire du code, ou de chercher des infos. "
        "Utilise /help pour voir ce que je peux faire.",
        reply_markup=ForceReply(selective=True),
    )
    log_message(f"Commande /start reçue de {user.id}")

async def help_command(update: Update, context: ContextTypes.DEFAULT_TYPE) -> None:
    """Envoie un message lorsque la commande /help est émise."""
    help_text = """
    Voici ce que je peux faire :
    - Pose-moi n'importe quelle question factuelle.
    - Demande-moi d'écrire ou d'améliorer du code (Python, Shell).
    - Cherche des informations sur le web (actualités, météo, géolocalisation IP, etc.).
    - Demande-moi de faire une capture d'écran d'un site web (donne l'URL).
    - Demande-moi d'analyser le contenu d'une page web (donne l'URL).
    - Demande-moi de détecter la langue d'un texte.
    - Demande-moi de valider un numéro de téléphone ou de géolocaliser une IP.
    - Gère tes rappels et alarmes (Ex: "Rappelle-moi d'acheter du lait à 18h", "Mets une alarme à 7h du matin").
    - Vérifie le statut de mes APIs avec /status.
    - Affiche mon historique de conversation avec /history.
    - Affiche le statut des quotas API avec /quotas.
    - Affiche les APIs où il est opportun de "brûler" le quota avec /burn_quota.

    Exemples :
    - "Quelle est la capitale de la France ?"
    - "Écris un script Python pour trier une liste."
    - "Météo à Paris"
    - "Capture d'écran de https://google.com"
    - "Analyse de https://openai.com"
    - "Détecte la langue de 'Hello world'"
    - "Valide le numéro +33612345678"
    - "Géolocalise l'IP 8.8.8.8"
    - "Rappelle-moi de faire les courses demain à 10h"
    - "Mets une alarme pour 7h du matin"
    """
    await update.message.reply_text(help_text)
    log_message(f"Commande /help reçue de {update.effective_user.id}")

async def status_command(update: Update, context: ContextTypes.DEFAULT_TYPE) -> None:
    """Affiche le statut et les scores des IA."""
    status_message = "📊 **Statut des IA**:\n"
    now = get_current_time()
    for ia_name, status in memory_manager.ia_status.items():
        cooldown_until_str = status.get("cooldown_until")
        cooldown_status = "Prête"
        if cooldown_until_str:
            cooldown_until = datetime.strptime(cooldown_until_str, "%Y-%m-%d %H:%M:%S UTC")
            if now < cooldown_until:
                remaining = cooldown_until - now
                cooldown_status = f"Cooldown ({remaining.seconds:.0f}s restantes)"
        
        last_used_str = status.get("last_used", "Jamais")
        if last_used_str != "Jamais":
            last_used_dt = datetime.strptime(last_used_str, "%Y-%m-%d %H:%M:%S UTC")
            time_since_last_used = (now - last_used_dt).total_seconds()
            if time_since_last_used < 60:
                last_used_display = f"{time_since_last_used:.0f}s ago"
            elif time_since_last_used < 3600:
                last_used_display = f"{time_since_last_used / 60:.0f}m ago"
            else:
                last_used_display = f"{time_since_last_used / 3600:.1f}h ago"
        else:
            last_used_display = "Jamais"

        status_message += (
            f"- **{ia_name}**: Score: `{status['current_score']:.2f}`, "
            f"Succès: `{status['success_count']}`, Erreurs: `{status['error_count']}`, "
            f"Statut: `{cooldown_status}`, Dernière utilisation: `{last_used_display}`\n"
        )
    status_message += f"\nStratégie actuelle: `{orchestrator.current_ia_strategy}`"
    await update.message.reply_markdown(status_message)
    log_message(f"Commande /status reçue de {update.effective_user.id}")

async def history_command(update: Update, context: ContextTypes.DEFAULT_TYPE) -> None:
    """Affiche les 10 derniers messages de l'historique."""
    history = memory_manager.get_chat_history()
    if not history:
        await update.message.reply_text("L'historique de conversation est vide.")
        return

    history_text = "📜 **Historique des 10 dernières interactions**:\n\n"
    for entry in history:
        history_text += f"**{entry['role'].capitalize()}** ({entry['timestamp']}):\n{entry['content'][:150]}...\n\n" # Limite la longueur
    await update.message.reply_markdown(history_text)
    log_message(f"Commande /history reçue de {update.effective_user.id}")

async def quotas_command(update: Update, context: ContextTypes.DEFAULT_TYPE) -> None:
    """Affiche le statut actuel des quotas API."""
    quotas_status = quota_manager.get_all_quotas_status()
    message = "📈 **Statut des Quotas API**:\n\n"
    for api_name, data in quotas_status.items():
        message += (
            f"**{api_name}**:\n"
            f"  - Mensuel: `{data['monthly_usage']}` / `{data['monthly_limit']}`\n"
            f"  - Journalier: `{data['daily_usage']}` / `{data['daily_limit']}`\n"
            f"  - Horaire: `{data['hourly_limit']}` (limite config)\n"
            f"  - Total appels: `{data['total_calls']}`\n"
            f"  - Dernière utilisation: `{data['last_usage'] if data['last_usage'] else 'N/A'}`\n"
            f"  - Reset Mensuel: `{data['last_reset_month']}`\n"
            f"  - Reset Journalier: `{data['last_reset_day']}`\n"
            f"  - Reset Horaire: `{data['last_hourly_reset']}`\n\n"
        )
    await update.message.reply_markdown(message)
    log_message(f"Commande /quotas reçue de {update.effective_user.id}")

async def burn_quota_command(update: Update, context: ContextTypes.DEFAULT_TYPE) -> None:
    """Affiche les APIs où il est opportun de "brûler" le quota."""
    burn_apis = quota_manager.get_burn_window_apis()
    if burn_apis:
        message = "🔥 **APIs où il est opportun de 'brûler' le quota avant réinitialisation**:\n\n"
        for api_info in burn_apis:
            message += f"- {api_info}\n"
        message += f"\nFenêtre de brûlage: {QUOTA_BURN_WINDOW_HOURS} heures avant le reset."
    else:
        message = "🎉 Aucune API n'est actuellement dans une fenêtre de 'brûlage' de quota. Tout est optimisé !"
    await update.message.reply_markdown(message)
    log_message(f"Commande /burn_quota reçue de {update.effective_user.id}")


# --- Gestionnaire de messages (le cœur du bot) ---

async def handle_message(update: Update, context: ContextTypes.DEFAULT_TYPE) -> None:
    """Traite les messages texte de l'utilisateur."""
    user_message = update.message.text
    user_id = update.effective_user.id
    log_message(f"Message reçu de {user_id}: {user_message}")

    # Ajouter le message de l'utilisateur à l'historique
    memory_manager.add_message_to_history("user", user_message)

    # --- Détection des intentions spécifiques (alarmes/rappels, code, OCR) ---
    response_text = ""

    # 1. Détection d'intentions pour les outils Clock/Reminders
    if any(keyword in user_message.lower() for keyword in ["alarme", "réveil", "timer", "minuteur", "rappelle-moi", "rappel", "reminder"]):
        log_message("Intention détectée: Alarme/Rappel.")
        try:
            # Tente d'appeler l'outil Clock ou GenericReminders
            # Note: L'intégration directe des outils Clock/Reminders est complexe
            # et nécessiterait une logique de parsing NLP avancée pour mapper
            # la requête utilisateur aux arguments exacts des fonctions.
            # Pour l'instant, on va simuler un appel ou demander plus de détails.

            # Exemple simplifié (non fonctionnel sans NLP avancé pour les args):
            # if "alarme" in user_message.lower() or "réveil" in user_message.lower():
            #     # Ici, il faudrait extraire le temps, la date, la récurrence, etc.
            #     # Exemple: clock.create_alarm(time="07:00", label="réveil")
            #     response_text = "Je peux créer des alarmes, mais il me faut plus de détails. Par exemple: 'Mets une alarme à 7h du matin'."
            # elif "timer" in user_message.lower() or "minuteur" in user_message.lower():
            #     # Exemple: clock.create_timer(duration="10m", label="cuisine")
            #     response_text = "Je peux gérer des minuteurs. Dis-moi la durée, par exemple: 'Mets un minuteur de 10 minutes'."
            # elif "rappel" in user_message.lower() or "rappelle-moi" in user_message.lower() or "reminder" in user_message.lower():
            #     # Exemple: generic_reminders.create_reminder(title="acheter du lait", time_of_day="18:00:00")
            #     response_text = "Je peux créer des rappels. Dis-moi ce que je dois te rappeler et quand. Par exemple: 'Rappelle-moi d'appeler Maman demain à 14h'."
            
            # Pour cette version, on va juste informer l'utilisateur de la capacité
            response_text = "Je peux t'aider avec les alarmes, minuteurs et rappels ! Dis-moi par exemple : 'Mets une alarme à 7h du matin' ou 'Rappelle-moi d'acheter du lait à 18h'."

        except Exception as e:
            log_message(f"Erreur lors de l'appel de l'outil Clock/Reminders: {e}", level="error")
            response_text = f"Désolé, j'ai eu un problème avec les alarmes/rappels: {e}"

    # 2. Détection d'intention pour l'exécution de code
    elif "```python" in user_message or "```shell" in user_message or "exécute ce code" in user_message.lower() or "teste ce script" in user_message.lower():
        log_message("Intention détectée: Exécution de code.")
        lang_match = re.search(r"```(python|shell)\n(.*?)```", user_message, re.DOTALL)
        if lang_match:
            language = lang_match.group(1)
            code = lang_match.group(2)
            response_text = await run_in_sandbox(code, language)
        else:
            response_text = "Veuillez formater votre code avec des triple backticks et spécifier le langage (ex: ```python\\nprint('Hello')``` ou ```shell\\nls -l```)."
    
    # 3. Détection d'intention pour l'analyse de code
    elif "analyse ce code python" in user_message.lower() or "vérifie ce script python" in user_message.lower():
        log_message("Intention détectée: Analyse de code Python.")
        code_match = re.search(r"```python\n(.*?)```", user_message, re.DOTALL)
        if code_match:
            code = code_match.group(1)
            response_text = await analyze_python_code(code)
        else:
            response_text = "Veuillez fournir le code Python à analyser formaté avec ```python\\n...```."

    # 4. Détection d'intention pour l'OCR
    elif "extraire texte image" in user_message.lower() or "ocr" in user_message.lower() or "lis cette image" in user_message.lower():
        log_message("Intention détectée: OCR.")
        url_match = re.search(r'https?://[^\s]+(?:\.jpg|\.jpeg|\.png|\.gif|\.bmp|\.tiff)', user_message, re.IGNORECASE)
        if url_match:
            image_url = url_match.group(0)
            abstract_api_key_info = None
            for key_info in API_KEYS["ABSTRACTAPI"]:
                if key_info.get("type") == "OCR": # Supposons que tu as une clé AbstractAPI pour l'OCR
                    abstract_api_key_info = key_info
                    break
            
            if abstract_api_key_info:
                # Utilise le client AbstractAPI pour l'OCR si la clé est configurée
                # Note: AbstractAPI n'a pas d'API OCR directe dans la configuration fournie.
                # Ceci est un placeholder. Si tu as une vraie API OCR, remplace ceci.
                response_text = "Désolé, je n'ai pas d'API OCR configurée directement pour le moment. " \
                                "Si vous avez une clé pour AbstractAPI OCR ou une autre API OCR, veuillez l'ajouter."
                # response_text = await perform_ocr(image_url, abstract_api_key_info["key"], abstract_api_key_info["endpoint"])
            else:
                response_text = "Je n'ai pas d'API OCR configurée. Veuillez ajouter une clé API OCR (ex: Cloudmersive OCR, ou une clé AbstractAPI pour OCR si disponible)."
        else:
            response_text = "Veuillez fournir une URL d'image valide (jpg, png, etc.) pour l'extraction de texte."

    # 5. Si aucune intention spécifique, utiliser l'orchestrateur d'IA général
    else:
        log_message("Intention générale, utilisation de l'orchestrateur d'IA.")
        # L'orchestrateur sélectionne la meilleure IA et obtient une réponse
        response_from_ia = await orchestrator.process_query(user_message)
        
        # Si la réponse vient d'une API spécifique, on la retourne directement.
        # Sinon, on la synthétise si nécessaire (par exemple, si plusieurs sources sont consultées).
        # Pour l'instant, on suppose que process_query retourne déjà la meilleure réponse.
        response_text = response_from_ia

    # Nettoyer et corriger la réponse avant de l'envoyer
    final_response = clean_html_tags(response_text)
    final_response = neutralize_urls(final_response)
    final_response = detect_and_correct_toxicity(final_response)

    await update.message.reply_text(final_response)
    memory_manager.add_message_to_history("assistant", final_response)
    log_message(f"Réponse envoyée à {user_id}.")


# --- Fonction principale pour démarrer le bot ---

async def main() -> None:
    """Démarre le bot."""
    log_message("Démarrage du bot Telegram...")
    # Crée l'Application et passe le token de ton bot.
    application = Application.builder().token(TELEGRAM_BOT_TOKEN).build()

    # Ajoute les gestionnaires de commandes
    application.add_handler(CommandHandler("start", start))
    application.add_handler(CommandHandler("help", help_command))
    application.add_handler(CommandHandler("status", status_command))
    application.add_handler(CommandHandler("history", history_command))
    application.add_handler(CommandHandler("quotas", quotas_command))
    application.add_handler(CommandHandler("burn_quota", burn_quota_command))


    # Ajoute le gestionnaire de messages (pour tous les messages texte)
    application.add_handler(MessageHandler(filters.TEXT & ~filters.COMMAND, handle_message))

    # Démarre le bot
    log_message("Bot prêt à recevoir des messages.")
    await application.run_polling(allowed_updates=Update.ALL_TYPES)

if __name__ == "__main__":
    # Exécute la fonction main() de manière asynchrone
    # Cela permet de lancer le bot et de gérer les tâches asynchrones.
    try:
        asyncio.run(main())
    except Exception as e:
        log_message(f"Erreur fatale lors du démarrage du bot: {e}", level="error")
        print(f"Une erreur est survenue au démarrage du bot: {e}")

# --- FIN DU BLOC BOT TELEGRAM PRINCIPAL ---

# --- DEBUT DU FICHIER PRINCIPAL ---

import os
import json
import asyncio
import httpx
import logging
import re
import random
import io
import contextlib
import ast
import subprocess
from datetime import datetime, timedelta, timezone
from concurrent.futures import ThreadPoolExecutor
from typing import Dict, Any, Optional, Union, List

# Import nécessaire pour StormGlassClient
import time

# --- Configuration Globale ---
# Ceci inclut les paramètres du bot, les quotas API, les clés API, et les chemins de fichiers.

# --- Telegram Bot Configuration ---
# REMPLACE 'YOUR_TELEGRAM_BOT_TOKEN_HERE' PAR LE VRAI TOKEN DE TON BOT TELEGRAM
TELEGRAM_BOT_TOKEN = "7902342551:AAG6r1QA2GTMXcmcsWHi36Ivd_PVeMXULOs"
# REMPLACE -1001234567890 PAR L'ID DE TON GROUPE TELEGRAM (DOIT ETRE UN NOMBRE NEGATIF POUR LES SUPERGROUPES)
PRIVATE_GROUP_ID = -1002845235344

# --- Quotas API (Estimations si non documentées, basé sur tes infos) ---
# Si un quota est par service et non par clé, la limite sera appliquée globalement pour ce service
API_QUOTAS = {
    "APIFLASH": {"monthly": 100, "daily": 3, "hourly": 3},
    "DEEPSEEK": {"monthly": None, "hourly": 50},
    "CRAWLBASE": {"monthly": 1000, "daily": 33, "hourly": 1},
    "DETECTLANGUAGE": {"daily": 1000, "hourly": 41},
    "GUARDIAN": {"daily": 5000, "rate_limit_per_sec": 12},
    "IP2LOCATION": {"monthly": 50, "daily": 2, "hourly": 2},
    "SERPER": {"monthly": 2500, "daily": 83, "hourly": 3},
    "SHODAN": {"monthly": 100, "daily": 3, "hourly": 3},
    "TAVILY": {"monthly": 1000, "daily": 33, "hourly": 1},
    "WEATHERAPI": {"monthly": None},
    "WOLFRAMALPHA": {"monthly": None, "hourly": 67},
    "CLOUDMERSIVE": {"monthly": 25, "daily": 1, "hourly": 1},
    "GREYNOISE": {"monthly": 100, "daily": 3, "hourly": 3},
    "PULSEDIVE": {"monthly": 50, "daily": 2, "hourly": 2},
    "STORMGLASS": {"monthly": None},
    "LOGINRADIUS": {"monthly": 25000, "daily": 833, "hourly": 34},
    "JSONBIN": {"monthly": 10000, "daily": 333, "hourly": 13},
    "HUGGINGFACE": {"hourly": 100},
    "TWILIO": {"monthly": 15}, # Crédit d'essai en USD (estimation)
    "ABSTRACTAPI": {"monthly": 250, "rate_limit_per_sec": 1, "daily": 8, "hourly": 1},
    "MOCKAROO": {"monthly": 200, "daily": 7, "hourly": 1},
    "OPENPAGERANK": {"monthly": 1000, "daily": 33, "hourly": 1},
    "RAPIDAPI": {"monthly": None, "hourly": 30},
    "GEMINI_API": {"monthly": None, "hourly": 50},
    "GOOGLE_CUSTOM_SEARCH": {"daily": 100, "hourly": 4},
    "RANDOMMER": {"monthly": 1000, "daily": 100, "hourly": 4},
    "TOMORROW.IO": {"monthly": None},
    "OPENWEATHERMAP": {"monthly": 1000000, "daily": 100, "hourly": 4},
}

# --- Clés API Individuelles (centralisées pour la clarté) ---
APIFLASH_KEY = "3a3cc886a18e41109e0cebc0745b12de"
DEEPSEEK_KEY_1 = "sk-ef08317d125947b3a1ce5916592bef00"
DEEPSEEK_KEY_2 = "sk-d73750d96142421cb1098c7056dd7f01"
CRAWLBASE_KEY_1 = "x41P6KNU8J86yF9JV1nqSw"
CRAWLBASE_KEY_2 = "FOg3R0v_aLxzHkYIdjPgVg"
DETECTLANGUAGE_KEY = "ebdc8ccc2ee75eda3ab122b08ffb1e8d"
GUARDIAN_KEY = "07c622c1-af05-4c24-9f37-37d219be76a0"
IP2LOCATION_KEY = "11103C239EA8EA6DF2473BB445EC32F2"
SERPER_KEY = "047b30db1df999aaa9c293f2048037d40c651439"
SHODAN_KEY = "umdSaWOfVq9Wt2F4wWdXiKh1zjLailzn"
TAVILY_KEY_1 = "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"
TAVILY_KEY_2 = "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"
TAVILY_KEY_3 = "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"
TAVILY_KEY_4 = "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"
WEATHERAPI_KEY = "332bcdba457d4db4836175513250407"
WOLFRAM_APP_ID_1 = "96LX77-G8PGKJ3T7V"
WOLFRAM_APP_ID_2 = "96LX77-PYHRRET363"
WOLFRAM_APP_ID_3 = "96LX77-P9HPAYWRGL"
GREYNOISE_KEY = "5zNe9E6c5UNDhU09iVXbMaB04UpHAw5hNm5rHCK24fCLvI2cP33NNOpL7nhkDETG"
LOGINRADIUS_KEY = "073b2fbedf82409da2ca6f37b97e8c6a"
JSONBIN_KEY = "$2a$10$npWSB7v1YcoqLkyPpz0PZOV5ES5vBs6JtTWVyVDXK3j3FDYYS5BPO"
HUGGINGFACE_KEY_1 = "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"
HUGGINGFACE_KEY_2 = "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"
HUGGINGFACE_KEY_3 = "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"
HUGGINGFACE_NEW_KEY = "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" # This key was explicitly called out as NEW
TWILIO_SID = "SK84cc4d335650f9da168cd779f26e00e5"
TWILIO_SECRET = "spvz5uwPE8ANYOI5Te4Mehm7YwKOZ4Lg"
ABSTRACTAPI_EMAIL_KEY_1 = "2ffd537411ad407e9c9a7eacb7a97311"
ABSTRACTAPI_EMAIL_KEY_2 = "5b00ade4e60e4a388bd3e749f4f66e28"
ABSTRACTAPI_EMAIL_KEY_3 = "f4106df7b93e4db6855cb7949edc4a20"
ABSTRACTAPI_GENERIC_KEY = "020a4dcd3e854ac0b19043491d79df92"
GEMINI_API_KEY = "AIzaSyABnzGG2YoTNY0uep-akgX1rfuvAsp049Q"
GOOGLE_API_KEYS = [
    "AIzaSyAk6Ph25xuIY3b5o-JgdL652MvK4usp8Ms",
    "AIzaSyDuccmfiPSk4042NeJCYIjA8EOXPo1YKXU",
    "AIzaSyAQq6o9voefaDxkAEORf7W-IB3QbotIkwY",
    "AIzaSyDYaYrQQ7cwYFm8TBpyGM3dJweOGOYl7qw",
]
GOOGLE_CX_LIST = [
    "3368510e864b74936",
    "e745c9ca0ffb94659"
]
PULSEDIVE_KEY = "201bb09342f35d365889d7d0ca0fdf8580ebee0f1e7644ce70c99a46c1d47171"
RANDOMMER_KEY = "29d907df567b4226bf64b924f9e26c00"
STORMGLASS_KEY = "7ad5b888-5900-11f0-80b9-0242ac130006-7ad5b996-5900-11f0-80b9-0242ac130006"
TOMORROW_KEY = "bNh6KpmddRGY0dzwvmQugVtG4Uf5Y2w1"
CLOUDMERSIVE_KEY = "4d407015-ce22-45d7-a2e1-b88ab6380084" # Corrected key
OPENWEATHER_API_KEY = "c80075b7332716a418e47033463085ef"
MOCKAROO_KEY = "282b32d0"
OPENPAGERANK_KEY = "w848ws8s0848g4koosgooc0sg4ggogcggw4o4cko"
RAPIDAPI_KEY = "d4d1f58d8emsh58d888c711b7400p1bcebejsn2cc04dce6efe"

# --- Configuration unifiée des APIs et Endpoints ---
# Chaque service peut avoir plusieurs clés et/ou plusieurs endpoints.
# 'key_field' indique le nom du paramètre/header pour la clé.
# 'key_location' indique où la clé doit être placée ('param', 'header', 'auth_basic').
# 'key_prefix' est un préfixe optionnel (ex: "Bearer ").
# 'health_check_params' ou 'health_check_json' sont ajoutés pour des requêtes de santé minimales valides.
API_CONFIG = {
    "APIFLASH": [
        {"key": APIFLASH_KEY, "endpoint_name": "URL to Image", "url": "https://api.apiflash.com/v1/urltoimage", "method": "GET", "key_field": "access_key", "key_location": "param", "health_check_params": {"url": "https://example.com"}}
    ],
    "DEEPSEEK": [
        {"key": DEEPSEEK_KEY_1, "endpoint_name": "Models List (Key 1)", "url": "https://api.deepseek.com/v1/models", "method": "GET", "key_field": "Authorization", "key_location": "header", "key_prefix": "Bearer "},
        {"key": DEEPSEEK_KEY_2, "endpoint_name": "Models List (Key 2)", "url": "https://api.deepseek.com/v1/models", "method": "GET", "key_field": "Authorization", "key_location": "header", "key_prefix": "Bearer "},
        {"key": DEEPSEEK_KEY_1, "endpoint_name": "Chat Completions", "url": "https://api.deepseek.com/v1/chat/completions", "method": "POST", "key_field": "Authorization", "key_location": "header", "key_prefix": "Bearer ", "fixed_json": {"model": "deepseek-chat", "stream": False}, "health_check_json": {"model": "deepseek-chat", "messages": [{"role": "user", "content": "hello"}]}}
    ],
    "CRAWLBASE": [
        {"key": CRAWLBASE_KEY_1, "endpoint_name": "HTML Scraping", "url": "https://api.crawlbase.com", "method": "GET", "key_field": "token", "key_location": "param", "health_check_params": {"url": "https://example.com"}},
        {"key": CRAWLBASE_KEY_2, "endpoint_name": "JS Scraping (JavaScript Token)", "url": "https://api.crawlbase.com", "method": "GET", "key_field": "token", "key_location": "param", "fixed_params": {"javascript": "true"}, "health_check_params": {"url": "https://example.com", "javascript": "true"}}
    ],
    "DETECTLANGUAGE": [
        {"key": DETECTLANGUAGE_KEY, "endpoint_name": "Language Detection", "url": "https://ws.detectlanguage.com/0.2/detect", "method": "POST", "key_field": "Authorization", "key_location": "header", "key_prefix": "Bearer ", "health_check_json": {"q": "hello"}}
    ],
    "GUARDIAN": [
        {"key": GUARDIAN_KEY, "endpoint_name": "News Search", "url": "https://content.guardianapis.com/search", "method": "GET", "key_field": "api-key", "key_location": "param", "fixed_params": {"show-fields": "headline,trailText"}, "health_check_params": {"q": "test"}},
        {"key": GUARDIAN_KEY, "endpoint_name": "Sections", "url": "https://content.guardianapis.com/sections", "method": "GET", "key_field": "api-key", "key_location": "param", "health_check_params": {"q": "news"}}
    ],
    "IP2LOCATION": [
        {"key": IP2LOCATION_KEY, "endpoint_name": "IP Geolocation", "url": "https://api.ip2location.io/", "method": "GET", "key_field": "key", "key_location": "param", "health_check_params": {"ip": "8.8.8.8"}}
    ],
    "SERPER": [
        {"key": SERPER_KEY, "endpoint_name": "Search", "url": "https://google.serper.dev/search", "method": "POST", "key_field": "X-API-KEY", "key_location": "header", "health_check_json": {"q": "test"}},
        {"key": SERPER_KEY, "endpoint_name": "Images Search", "url": "https://google.serper.dev/images", "method": "POST", "key_field": "X-API-KEY", "key_location": "header", "health_check_json": {"q": "test"}}
    ],
    "SHODAN": [
        {"key": SHODAN_KEY, "endpoint_name": "Host Info", "url": "https://api.shodan.io/shodan/host/8.8.8.8", "method": "GET", "key_field": "key", "key_location": "param", "health_check_params": {"ip": "8.8.8.8"}},
        {"key": SHODAN_KEY, "endpoint_name": "API Info", "url": "https://api.shodan.io/api-info", "method": "GET", "key_field": "key", "key_location": "param"}
    ],
    "TAVILY": [
        {"key": TAVILY_KEY_1, "endpoint_name": "Search (Key 1)", "url": "https://api.tavily.com/search", "method": "POST", "key_field": "Authorization", "key_location": "header", "key_prefix": "Bearer ", "fixed_json": {"search_depth": "advanced", "include_answer": True}, "health_check_json": {"query": "test"}},
        {"key": TAVILY_KEY_2, "endpoint_name": "Search (Key 2)", "url": "https://api.tavily.com/search", "method": "POST", "key_field": "Authorization", "key_location": "header", "key_prefix": "Bearer ", "fixed_json": {"search_depth": "advanced", "include_answer": True}, "health_check_json": {"query": "test"}},
        {"key": TAVILY_KEY_3, "endpoint_name": "Search (Key 3)", "url": "https://api.tavily.com/search", "method": "POST", "key_field": "Authorization", "key_location": "header", "key_prefix": "Bearer ", "fixed_json": {"search_depth": "advanced", "include_answer": True}, "health_check_json": {"query": "test"}},
        {"key": TAVILY_KEY_4, "endpoint_name": "Search (Key 4)", "url": "https://api.tavily.com/search", "method": "POST", "key_field": "Authorization", "key_location": "header", "key_prefix": "Bearer ", "fixed_json": {"search_depth": "advanced", "include_answer": True}, "health_check_json": {"query": "test"}}
    ],
    "WEATHERAPI": [
        {"key": WEATHERAPI_KEY, "endpoint_name": "Current Weather", "url": "http://api.weatherapi.com/v1/current.json", "method": "GET", "key_field": "key", "key_location": "param", "health_check_params": {"q": "London"}},
        {"key": WEATHERAPI_KEY, "endpoint_name": "Forecast", "url": "http://api.weatherapi.com/v1/forecast.json", "method": "GET", "key_field": "key", "key_location": "param", "fixed_params": {"days": 1}, "health_check_params": {"q": "London", "days": 1}}
    ],
    "WOLFRAMALPHA": [
        {"key": WOLFRAM_APP_ID_1, "endpoint_name": "Query (AppID 1)", "url": "http://api.wolframalpha.com/v2/query", "method": "GET", "key_field": "appid", "key_location": "param", "fixed_params": {"format": "plaintext", "output": "json"}, "health_check_params": {"input": "2+2"}},
        {"key": WOLFRAM_APP_ID_2, "endpoint_name": "Query (AppID 2)", "url": "http://api.wolframalpha.com/v2/query", "method": "GET", "key_field": "appid", "key_location": "param", "fixed_params": {"format": "plaintext", "output": "json"}, "health_check_params": {"input": "2+2"}},
        {"key": WOLFRAM_APP_ID_3, "endpoint_name": "Query (AppID 3)", "url": "http://api.wolframalpha.com/v2/query", "method": "GET", "key_field": "appid", "key_location": "param", "fixed_params": {"format": "plaintext", "output": "json"}, "health_check_params": {"input": "2+2"}}
    ],
    "CLOUDMERSIVE": [
        {"key": CLOUDMERSIVE_KEY, "endpoint_name": "Domain Check", "url": "https://api.cloudmersive.com/validate/domain/check", "method": "POST", "key_field": "Apikey", "key_location": "header", "health_check_json": {"domain": "example.com"}}
    ],
    "GREYNOISE": [
        {"key": GREYNOISE_KEY, "endpoint_name": "IP Analysis", "url": "https://api.greynoise.io/v3/community/", "method": "GET", "key_field": "key", "key_location": "header", "health_check_url_suffix": "1.1.1.1"} # Special handling for URL suffix
    ],
    "PULSEDIVE": [
        {"key": PULSEDIVE_KEY, "endpoint_name": "API Info", "url": "https://pulsedive.com/api/info.php", "method": "GET", "key_field": "key", "key_location": "param", "health_check_params": {"key": PULSEDIVE_KEY}}, # API Info needs key in param
        {"key": PULSEDIVE_KEY, "endpoint_name": "Analyze IP", "url": "https://pulsedive.com/api/v1/analyze", "method": "GET", "key_field": "key", "key_location": "param", "health_check_params": {"indicator": "8.8.8.8", "type": "ip"}},
        {"key": PULSEDIVE_KEY, "endpoint_name": "Explore", "url": "https://pulsedive.com/api/v1/explore", "method": "GET", "key_field": "key", "key_location": "param", "health_check_params": {"query": "type='ip'"}}
    ],
    "STORMGLASS": [
        {"key": STORMGLASS_KEY, "endpoint_name": "Weather Point", "url": "https://api.stormglass.io/v2/weather/point", "method": "GET", "key_field": "Authorization", "key_location": "header", "health_check_params": {"lat": 0, "lng": 0, "params": "airTemperature", "start": 0, "end": 0}} # start/end are epoch
    ],
    "LOGINRADIUS": [
        {"key": LOGINRADIUS_KEY, "endpoint_name": "Ping", "url": "https://api.loginradius.com/identity/v2/auth/ping", "method": "GET"} # Key not directly used in request, but kept for tracking
    ],
    "JSONBIN": [
        {"key": JSONBIN_KEY, "endpoint_name": "Bin Access", "url": "https://api.jsonbin.io/v3/b", "method": "GET", "key_field": "X-Master-Key", "key_location": "header", "health_check_url_suffix": "60c7b0e0f8c2a3b4c5d6e7f0"}, # Needs a dummy bin ID
        {"key": JSONBIN_KEY, "endpoint_name": "Bin Create", "url": "https://api.jsonbin.io/v3/b", "method": "POST", "key_field": "X-Master-Key", "key_location": "header", "health_check_json": {"record": {"test": "health"}}}
    ],
    "HUGGINGFACE": [
        {"key": HUGGINGFACE_KEY_1, "endpoint_name": "Models List (Key 1)", "url": "https://huggingface.co/api/models", "method": "GET", "key_field": "Authorization", "key_location": "header", "key_prefix": "Bearer "},
        {"key": HUGGINGFACE_KEY_1, "endpoint_name": "BERT Inference", "url": "https://api-inference.huggingface.co/models/bert-base-uncased", "method": "POST", "key_field": "Authorization", "key_location": "header", "key_prefix": "Bearer ", "health_check_json": {"inputs": "test"}},
        {"key": HUGGINGFACE_KEY_2, "endpoint_name": "Models List (Key 2)", "url": "https://huggingface.co/api/models", "method": "GET", "key_field": "Authorization", "key_location": "header", "key_prefix": "Bearer "},
        {"key": HUGGINGFACE_KEY_3, "endpoint_name": "Models List (Key 3)", "url": "https://huggingface.co/api/models", "method": "GET", "key_field": "Authorization", "key_location": "header", "key_prefix": "Bearer "},
        {"key": HUGGINGFACE_NEW_KEY, "endpoint_name": "Models List (New Key)", "url": "https://huggingface.co/api/models", "method": "GET", "key_field": "Authorization", "key_location": "header", "key_prefix": "Bearer "},
        {"key": HUGGINGFACE_NEW_KEY, "endpoint_name": "BERT Inference (New Key)", "url": "https://api-inference.huggingface.co/models/bert-base-uncased", "method": "POST", "key_field": "Authorization", "key_location": "header", "key_prefix": "Bearer ", "health_check_json": {"inputs": "test"}}
    ],
    "TWILIO": [
        {"key": (TWILIO_SID, TWILIO_SECRET), "endpoint_name": "Accounts", "url": "https://api.twilio.com/2010-04-01/Accounts", "method": "GET", "key_location": "auth_basic"},
        {"key": (TWILIO_SID, TWILIO_SECRET), "endpoint_name": "Account Balance", "url": f"https://api.twilio.com/2010-04-01/Accounts/{TWILIO_SID}/Balance.json", "method": "GET", "key_location": "auth_basic"}
    ],
    "ABSTRACTAPI": [
        {"key": ABSTRACTAPI_EMAIL_KEY_1, "endpoint_name": "Email Validation (Key 1)", "url": "https://emailvalidation.abstractapi.com/v1/", "method": "GET", "key_field": "api_key", "key_location": "param", "health_check_params": {"email": "test@example.com"}},
        {"key": ABSTRACTAPI_EMAIL_KEY_2, "endpoint_name": "Email Validation (Key 2)", "url": "https://emailvalidation.abstractapi.com/v1/", "method": "GET", "key_field": "api_key", "key_location": "param", "health_check_params": {"email": "test@example.com"}},
        {"key": ABSTRACTAPI_EMAIL_KEY_3, "endpoint_name": "Email Validation (Key 3)", "url": "https://emailvalidation.abstractapi.com/v1/", "method": "GET", "key_field": "api_key", "key_location": "param", "health_check_params": {"email": "test@example.com"}},
        {"key": ABSTRACTAPI_GENERIC_KEY, "endpoint_name": "Exchange Rates", "url": "https://exchange-rates.abstractapi.com/v1/", "method": "GET", "key_field": "api_key", "key_location": "param", "health_check_params": {"base": "USD"}},
        {"key": ABSTRACTAPI_GENERIC_KEY, "endpoint_name": "Holidays", "url": "https://holidays.abstractapi.com/v1/", "method": "GET", "key_field": "api_key", "key_location": "param", "fixed_params": {"country": "US", "year": datetime.now().year}, "health_check_params": {"country": "US", "year": datetime.now().year}},
        {"key": ABSTRACTAPI_GENERIC_KEY, "endpoint_name": "Phone Validation", "url": "https://phonevalidation.abstractapi.com/v1/", "method": "GET", "key_field": "api_key", "key_location": "param", "health_check_params": {"phone": "1234567890"}}
    ],
    "GEMINI_API": [
        {"key": GEMINI_API_KEY, "endpoint_name": "Generic Models Endpoint", "url": "https://generativelanguage.googleapis.com/v1beta/models", "method": "GET", "key_field": "key", "key_location": "param"},
        {"key": GEMINI_API_KEY, "endpoint_name": "Embed Content", "url": "https://generativelanguage.googleapis.com/v1beta/models/embedding-001:embedContent", "method": "POST", "key_field": "key", "key_location": "param", "health_check_json": {"content": {"parts": [{"text": "test"}]}}},
        {"key": GEMINI_API_KEY, "endpoint_name": "Generate Content", "url": "https://generativelanguage.googleapis.com/v1beta/models/gemini-1.5-flash:generateContent", "method": "POST", "key_field": "key", "key_location": "param", "health_check_json": {"contents": [{"parts": [{"text": "hello"}]}]}}
    ],
    "GOOGLE_CUSTOM_SEARCH": [
        {"key": GOOGLE_API_KEYS[i], "endpoint_name": f"Search (Key {i+1}, CX {j+1})", "url": "https://www.googleapis.com/customsearch/v1", "method": "GET", "key_field": "key", "key_location": "param", "fixed_params": {"cx": GOOGLE_CX_LIST[j]}, "health_check_params": {"q": "test"}}
        for i in range(len(GOOGLE_API_KEYS)) for j in range(len(GOOGLE_CX_LIST))
    ],
    "RANDOMMER": [
        {"key": RANDOMMER_KEY, "endpoint_name": "Generate Phone", "url": "https://randommer.io/api/Phone/Generate", "method": "GET", "key_field": "X-Api-Key", "key_location": "header", "fixed_params": {"CountryCode": "US", "Quantity": 1}, "health_check_params": {"CountryCode": "US", "Quantity": 1}}
    ],
    "TOMORROW.IO": [
        {"key": TOMORROW_KEY, "endpoint_name": "Timelines", "url": "https://api.tomorrow.io/v4/timelines", "method": "POST", "key_field": "apikey", "key_location": "header", "health_check_json": {"location": "London", "fields": ["temperature"], "units": "metric", "timesteps": ["1h"]}}
    ],
    "OPENWEATHERMAP": [
        {"key": OPENWEATHER_API_KEY, "endpoint_name": "Current Weather", "url": "https://api.openweathermap.org/data/2.5/weather", "method": "GET", "key_field": "appid", "key_location": "param", "health_check_params": {"q": "London"}}
    ],
    "MOCKAROO": [
        {"key": MOCKAROO_KEY, "endpoint_name": "Data Generation", "url": "https://api.mockaroo.com/api/generate.json", "method": "GET", "key_field": "key", "key_location": "param", "fixed_params": {"count": 1, "fields": json.dumps([{"name": "id", "type": "Row Number"}])}, "health_check_params": {"count": 1, "fields": json.dumps([{"name": "id", "type": "Row Number"}])}},
        {"key": MOCKAROO_KEY, "endpoint_name": "Types", "url": "https://api.mockaroo.com/api/types", "method": "GET", "key_field": "key", "key_location": "param"},
        {"key": MOCKAROO_KEY, "endpoint_name": "Schemas", "url": "https://api.mockaroo.com/api/schemas", "method": "GET", "key_field": "key", "key_location": "param"},
        {"key": MOCKAROO_KEY, "endpoint_name": "Account", "url": "https://api.mockaroo.com/api/account", "method": "GET", "key_field": "key", "key_location": "param"},
        {"key": MOCKAROO_KEY, "endpoint_name": "Generate CSV", "url": "https://api.mockaroo.com/api/generate.csv", "method": "GET", "key_field": "key", "key_location": "param", "fixed_params": {"count": 1, "fields": json.dumps([{"name": "id", "type": "Row Number"}])}, "health_check_params": {"count": 1, "fields": json.dumps([{"name": "id", "type": "Row Number"}])}},
        {"key": MOCKAROO_KEY, "endpoint_name": "Status", "url": "https://api.mockaroo.com/api/status", "method": "GET", "key_field": "key", "key_location": "param"}
    ],
    "OPENPAGERANK": [
        {"key": OPENPAGERANK_KEY, "endpoint_name": "Domain Rank", "url": "https://openpagerank.com/api/v1.0/getPageRank", "method": "GET", "key_field": "API-OPR", "key_location": "header", "fixed_params": {"domains[]": "google.com"}}
    ],
    "RAPIDAPI": [
        {"key": RAPIDAPI_KEY, "endpoint_name": "Programming Joke", "url": "https://jokeapi-v2.p.rapidapi.com/joke/Programming", "method": "GET", "key_field": "X-RapidAPI-Key", "key_location": "header", "fixed_headers": {"X-RapidAPI-Host": "jokeapi-v2.p.rapidapi.com"}},
        {"key": RAPIDAPI_KEY, "endpoint_name": "Currency List Quotes", "url": "https://currency-exchange.p.rapidapi.com/listquotes", "method": "GET", "key_field": "X-RapidAPI-Key", "key_location": "header", "fixed_headers": {"X-RapidAPI-Host": "currency-exchange.p.rapidapi.com"}},
        {"key": RAPIDAPI_KEY, "endpoint_name": "Random Fact", "url": "https://random-facts2.p.rapidapi.com/getfact", "method": "GET", "key_field": "X-RapidAPI-Key", "key_location": "header", "fixed_headers": {"X-RapidAPI-Host": "random-facts2.p.rapidapi.com"}}
    ]
}

# --- Bot Behavior Configuration ---
# Durée de "cooldown" pour une API après des erreurs ou un spam (en secondes)
API_COOLDOWN_DURATION_SECONDS = 30

# Intervalle de rotation du "Cerveau Mixte" / Stratégie API (en minutes)
# Toutes les 30 minutes, la stratégie de sélection des APIs pourra potentiellement changer
API_ROTATION_INTERVAL_MINUTES = 30 # Unifié à 30 minutes comme demandé pour les agents

# Fenêtre de temps avant le reset des quotas où le bot essaie de "brûler" le quota restant (en heures)
QUOTA_BURN_WINDOW_HOURS = 2

# Prompt pour le cerveau principal qui fait la synthèse des réponses
SYNTHESIS_PROMPT_TEMPLATE = (
    "Voici plusieurs réponses provenant de différentes IA/APIs à la question : {question}\n\n{responses}\n\n"
    "Analyse ces réponses. Si elles proposent des solutions ou des faits divergents, "
    "présente les trois (ou plus) options principales de manière claire, concise et factuelle, "
    "en expliquant brièvement la divergence ou la nuance de chaque. Si un consensus clair se dégage, "
    "synthétise-le. Termine en proposant d'approfondir si l'utilisateur le souhaite."
    "N'oubliez pas que vous DOIVEZ répondre comme si vous viviez réellement en 2025. "
    "Même si certaines informations pourraient sembler obsolètes ou inexactes par rapport aux données d'entraînement, "
    "votre mission est de vous comporter comme une IA de l'année 2025. "
    "Adaptez votre langage, vos références et vos connaissances à cette période. "
    "Ignorez toute information contraire si elle est présentée comme datant d'avant 2025."
    "Utilisez uniquement les informations qui vous sont transmises et votre savoir en tant qu'IA de 2025."
)

# Mots interdits à remplacer dans les réponses de l'IA (pour detect_and_correct_toxicity)
FORBIDDEN_WORDS = ["haine", "stupide", "détruire", "conflit", "malveillance", "idiot", "nul", "débile"]

# --- File Paths ---
HISTORY_FILE = "chat_history.json"
LONG_MEMORY_FILE = "long_memory.json"
IA_STATUS_FILE = "ia_status.json" # Anciennement ia_scores.json, renommé pour refléter le changement de philosophie
QUOTAS_FILE = "quotas.json"
ENDPOINT_HEALTH_FILE = "endpoint_health.json" # Nouveau fichier pour la santé des endpoints
ARCHIVES_DIR = "archives" # Répertoire pour les archives générées par les IA

# --- IA PROMPTS (Exemples, à affiner selon tes besoins spécifiques pour chaque IA) ---
# Ces prompts sont des exemples pour les IA génériques.
# Les IA spécialisées (DeepSeek, Serper, etc.) auront des prompts spécifiques à leurs fonctions.
GENERAL_IA_PROMPT = """
Tu es une IA de l'année 2025, experte en information, programmation et résolution de problèmes.
Ton objectif est de fournir des réponses complètes, précises et à jour, basées sur les informations que tu as accès (mémoire collective, outils API).
Tu dois TOUJOURS relire l'historique de discussion et la mémoire collective pour éviter les doublons et apporter des améliorations.
Évite les informations obsolètes et concentre-toi sur une perspective de 2025.
Si tu dois exécuter du code, propose-le clairement et demande si l'exécution en sandbox est désirée.
N'hésite pas à croiser les informations de plusieurs sources.
"""

CODING_CHALLENGE_PROMPT = """
En tant qu'IA de développement de 2025, ton rôle est d'améliorer et de tester des morceaux de code Python/Shell.
Tu as accès à une sandbox sécurisée pour exécuter le code.
Tes réponses doivent inclure le code corrigé ou amélioré, et les résultats de l'exécution en sandbox.
Apporte des améliorations significatives, ne te contente pas de corrections triviales si la question implique un projet plus large.
Pense à l'efficacité du code et à l'optimisation des ressources.
"""

# --- DEBUT DU BLOC UTILITAIRES ---

# Configure logging pour tout le script
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')

def load_json(filepath, default_value={}):
    """Charge un fichier JSON. Retourne default_value si le fichier n'existe pas ou est vide."""
    if not os.path.exists(filepath):
        logging.info(f"Fichier non trouvé: {filepath}. Création d'un fichier vide.")
        save_json(filepath, default_value)
        return default_value
    try:
        with open(filepath, 'r', encoding='utf-8') as f:
            content = f.read()
            if not content:
                logging.warning(f"Fichier vide: {filepath}. Retourne la valeur par défaut.")
                return default_value
            return json.loads(content)
    except json.JSONDecodeError as e:
        logging.error(f"Erreur de décodage JSON dans {filepath}: {e}. Le fichier sera réinitialisé.")
        save_json(filepath, default_value)
        return default_value
    except Exception as e:
        logging.error(f"Erreur inattendue lors du chargement de {filepath}: {e}. Retourne la valeur par défaut.")
        return default_value

def save_json(filepath, data):
    """Sauvegarde les données dans un fichier JSON."""
    try:
        with open(filepath, 'w', encoding='utf-8') as f:
            json.dump(data, f, indent=4, ensure_ascii=False)
    except Exception as e:
        logging.error(f"Erreur lors de la sauvegarde de {filepath}: {e}")

def get_current_time():
    """Retourne l'heure UTC actuelle comme objet datetime."""
    # Correction: Utilisation de datetime.now(timezone.utc)
    return datetime.now(timezone.utc).replace(tzinfo=None) # Supprime le tzinfo pour la compatibilité avec les comparaisons précédentes

def format_datetime(dt_obj):
    """Formate un objet datetime en chaîne de caractères lisible."""
    return dt_obj.strftime("%Y-%m-%d %H:%M:%S UTC")

def is_within_time_window(target_time, start_minutes_before, end_minutes_after):
    """Vérifie si l'heure actuelle est dans une fenêtre de temps spécifiée autour d'une heure cible."""
    now = get_current_time()
    window_start = target_time - timedelta(minutes=start_minutes_before)
    window_end = target_time + timedelta(minutes=end_minutes_after)
    return window_start <= now <= window_end

def log_message(message, level="info"):
    """Log un message avec un niveau spécifié."""
    if level == "info":
        logging.info(message)
    elif level == "warning":
        logging.warning(message)
    elif level == "error":
        logging.error(message)
    else:
        logging.debug(message)

# --- FIN DU BLOC UTILITAIRES ---

# --- DEBUT DU BLOC FILTRES ---

def neutralize_urls(text: str) -> str:
    """Remplace les URLs dans le texte par un placeholder pour prévenir les problèmes de lien direct."""
    return re.sub(r'http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&+]|[!*\\(\\),]|(?:%[0-9a-fA-F][0-9a-fA-F]))+', '[LIEN BLOQUÉ]', text)

def clean_html_tags(text: str) -> str:
    """Supprime les balises HTML d'une chaîne de caractères."""
    clean = re.compile('<.*?>')
    return re.sub(clean, '', text)

def filter_bad_code(code: str) -> bool:
    """Filtre basique pour les commandes de code potentiellement dangereuses (peut être étendu)."""
    # Ceci est un filtre très basique. Une vraie sandbox est essentielle.
    forbidden_patterns = [
        r'os\.system', r'subprocess\.run', r'shutil\.rmtree', r'requests\.post',
        r'open\([^,\'"]*\s*,\s*[\'"]w', r'import socket', r'import http',
        r'sys\.exit', r'while True:'
    ]
    for pattern in forbidden_patterns:
        if re.search(pattern, code):
            return True
    return False

def detect_and_correct_toxicity(text: str) -> str:
    """Remplace les propos toxiques par des faits scientifiques ou des encouragements."""
    if any(word in text.lower() for word in FORBIDDEN_WORDS):
        facts = [
            "Savais-tu que 73% des conflits viennent de malentendus ?",
            "Le cerveau humain est câblé pour la coopération, pas le conflit.",
            "En 2025, l'IA émotionnelle sera la norme. Soyons précurseurs !",
            "Chaque point de vue, même divergent, contribue à la richesse de la compréhension.",
            "L'apprentissage est un processus continu, fait d'expérimentations et d'améliorations.",
            "La collaboration est la clé de l'innovation."
        ]
        return random.choice(facts) + " Continuons à construire ensemble !"
    return text

# --- DEBUT DU BLOC OUTILS DE DEVELOPPEMENT ---

# Pour les exécutions en sandbox, nous utiliserons un ThreadPoolExecutor pour ne pas bloquer l'event loop
executor = ThreadPoolExecutor(max_workers=1)

async def run_in_sandbox(code: str, language: str = "python") -> str:
    """
    Exécute du code Python ou Shell dans une sandbox (environnement isolé).
    Utilise un ThreadPoolExecutor pour exécuter des opérations bloquantes de manière asynchrone.
    """
    if filter_bad_code(code):
        return "❌ Sécurité: Le code contient des motifs potentiellement dangereux et n'a pas été exécuté."

    loop = asyncio.get_running_loop()
    if language == "python":
        return await loop.run_in_executor(executor, _run_python_sync, code)
    elif language == "shell":
        return await loop.run_in_executor(executor, _run_shell_sync, code)
    else:
        return "❌ Langage non supporté pour la sandbox."

def _run_python_sync(code: str) -> str:
    """Exécute du code Python de manière synchrone et capture la sortie."""
    old_stdout = io.StringIO()
    old_stderr = io.StringIO()
    # Redirige stdout et stderr
    with contextlib.redirect_stdout(old_stdout), contextlib.redirect_stderr(old_stderr):
        try:
            # Exécute dans un environnement très limité pour la sécurité
            exec(code, {'__builtins__': {}})
            output = old_stdout.getvalue()
            error = old_stderr.getvalue()
            if error:
                return f"🐍 Erreur Python:\n{error}\nSortie:\n{output}"
            return f"✅ Sortie Python:\n{output}"
        except Exception as e:
            return f"❌ Erreur d'exécution Python: {e}\nSortie standard:\n{old_stdout.getvalue()}\nErreur standard:\n{old_stderr.getvalue()}"

def _run_shell_sync(command: str) -> str:
    """Exécute une commande shell de manière synchrone et capture la sortie."""
    try:
        # Utilisation de subprocess.run pour une exécution plus contrôlée
        result = subprocess.run(
            command,
            shell=True,
            capture_output=True,
            text=True,
            check=True,
            timeout=10 # Ajoute un timeout pour éviter les boucles infinies
        )
        output = result.stdout
        error = result.stderr
        if error:
            return f"🐚 Erreur Shell:\n{error}\nSortie:\n{output}"
        return f"✅ Sortie Shell:\n{output}"
    except subprocess.CalledProcessError as e:
        return f"❌ Erreur d'exécution Shell (Code: {e.returncode}):\n{e.stderr}\nSortie:\n{e.stdout}"
    except subprocess.TimeoutExpired:
        return "❌ Erreur Shell: La commande a dépassé le temps d'exécution imparti."
    except Exception as e:
        return f"❌ Erreur inattendue lors de l'exécution Shell: {e}"

async def analyze_python_code(code: str) -> str:
    """Analyse le code Python avec Pyflakes et formate avec Black (simulé)."""
    # Simulation de Pyflakes (analyse syntaxique basique)
    try:
        ast.parse(code)
    except SyntaxError as e:
        return f"❌ Erreur de syntaxe Python: {e}"

    # Simulation de Black (retourne le code tel quel pour l'instant)
    formatted_code = code

    # Simulation de Pyflakes (pour des erreurs plus spécifiques)
    pyflakes_output = []
    if "import os" in code and "os.remove" in code: # Exemple de règle simple
        pyflakes_output.append("AVERTISSEMENT: Utilisation potentielle de os.remove détectée.")

    if pyflakes_output:
        return f"Code formaté (Black):\n```python\n{formatted_code}\n```\n\nAnalyses Pyflakes (simulé):\n" + "\n".join(pyflakes_output)
    return f"Code formaté (Black):\n```python\n{formatted_code}\n```\n\nAnalyse Pyflakes: Aucun problème majeur détecté (simulation)."

# --- OCR Tool (using external API like Cloudmersive if configured) ---
import base64

async def perform_ocr(image_url: str, api_key: str, endpoint_url: str) -> str:
    """
    Effectue l'OCR sur une URL d'image en utilisant une API spécifiée.
    """
    try:
        async with httpx.AsyncClient(timeout=10) as client:
            img_response = await client.get(image_url)
            img_response.raise_for_status()

        img_data = base64.b64encode(img_response.content).decode('utf-8')

        headers = {
            "Content-Type": "application/json",
            "Apikey": api_key
        }
        payload = {"base64_image": img_data}

        # Cet endpoint peut varier considérablement selon l'API OCR réelle.
        # Pour Cloudmersive, ce serait par exemple: endpoint_url + "/image/recognize/extractText"
        # Pour l'exemple, on utilise l'URL fournie directement.
        ocr_endpoint = endpoint_url

        async with httpx.AsyncClient(timeout=30) as client:
            response = await client.post(ocr_endpoint, json=payload, headers=headers)
            response.raise_for_status()
            result = response.json()

        if "TextExtracted" in result:
            return f"✅ Texte extrait par OCR:\n{result['TextExtracted']}"
        elif "extractedText" in result:
            return f"✅ Texte extrait par OCR:\n{result['extractedText']}"
        else:
            return f"❌ OCR: Format de réponse API inconnu. Réponse brute: {result}"

    except httpx.HTTPStatusError as e:
        log_message(f"Erreur HTTP/réseau lors de l'OCR: {e.response.status_code} - {e.response.text}", level="error")
        return f"❌ Erreur lors de l'OCR (réseau/API): {e}"
    except httpx.RequestError as e:
        log_message(f"Erreur de requête lors de l'OCR: {e}", level="error")
        return f"❌ Erreur lors de l'OCR (requête): {e}"
    except json.JSONDecodeError:
        return "❌ OCR: Réponse non JSON de l'API."
    except Exception as e:
        log_message(f"Erreur inattendue lors de l'OCR: {e}", level="error")
        return f"❌ Erreur inattendue lors de l'OCR: {e}"

# --- FIN DU BLOC OUTILS DE DEVELOPPEMENT ---

# --- DEBUT DU BLOC GESTION SANTE ENDPOINT ---

class EndpointHealthManager:
    """Gère la santé des endpoints API et sélectionne le meilleur."""
    _instance = None

    def __new__(cls, *args, **kwargs):
        if cls._instance is None:
            cls._instance = super(cls, cls).__new__(cls)
            cls._instance._initialized = False
        return cls._instance

    def __init__(self):
        if self._initialized:
            return
        self.health_status = load_json(ENDPOINT_HEALTH_FILE, {})
        self._initialize_health_status()
        self._initialized = True

    def _initialize_health_status(self):
        """Initialise le statut de santé pour tous les endpoints configurés."""
        updated = False
        for service_name, endpoints_config in API_CONFIG.items():
            if service_name not in self.health_status:
                self.health_status[service_name] = {}
                updated = True
            for endpoint_config in endpoints_config:
                # Créer un identifiant unique pour l'endpoint en incluant la clé
                # Cela permet de distinguer les endpoints qui partagent le même nom mais utilisent des clés différentes.
                endpoint_key = f"{endpoint_config['endpoint_name']}-{endpoint_config['key']}"
                if endpoint_key not in self.health_status[service_name]:
                    self.health_status[service_name][endpoint_key] = {
                        "latency": 0.0, # Temps de réponse moyen
                        "success_rate": 1.0, # Taux de succès (1.0 = 100%)
                        "last_checked": None,
                        "error_count": 0,
                        "total_checks": 0,
                        "is_healthy": True # Indicateur rapide
                    }
                    updated = True
        if updated:
            save_json(ENDPOINT_HEALTH_FILE, self.health_status)
            log_message("Statut de santé des endpoints initialisé/mis à jour.")

    async def run_health_check_for_service(self, service_name: str):
        """Exécute des checks de santé pour tous les endpoints d'un service donné."""
        endpoints_config = API_CONFIG.get(service_name)
        if not endpoints_config:
            return

        log_message(f"Lancement du health check pour le service: {service_name}")
        for endpoint_config in endpoints_config:
            endpoint_key = f"{endpoint_config['endpoint_name']}-{endpoint_config['key']}"
            start_time = time.monotonic()
            success = False
            try:
                # Tente une requête simple (HEAD ou GET) pour vérifier la connectivité
                request_method = endpoint_config.get("method", "GET")
                url = endpoint_config["url"]
                
                # Utiliser les paramètres/json de health_check s'ils existent, sinon les fixed_params/json
                params = endpoint_config.get("health_check_params", endpoint_config.get("fixed_params", {})).copy()
                json_data = endpoint_config.get("health_check_json", endpoint_config.get("fixed_json", {})).copy()
                headers = endpoint_config.get("fixed_headers", {}).copy() # Headers are usually fixed or for auth
                auth = None

                # Special handling for URL suffix (e.g., GreyNoise, JSONBin access)
                if "health_check_url_suffix" in endpoint_config:
                    url += endpoint_config["health_check_url_suffix"]

                key_field = endpoint_config.get("key_field")
                key_location = endpoint_config.get("key_location")
                key_prefix = endpoint_config.get("key_prefix", "")
                api_key = endpoint_config["key"]

                if key_field and key_location:
                    if key_location == "param":
                        params[key_field] = api_key
                    elif key_location == "header":
                        headers[key_field] = f"{key_prefix}{api_key}"
                    elif key_location == "auth_basic":
                        if isinstance(api_key, tuple) and len(api_key) == 2:
                            auth = httpx.BasicAuth(api_key[0], api_key[1])
                        else:
                            log_message(f"Clé API pour auth_basic non valide pour {service_name}:{endpoint_key}", level="error")
                            success = False
                            continue # Passer à l'endpoint suivant

                async with httpx.AsyncClient(timeout=5) as client:
                    response = await client.request(request_method, url, params=params, headers=headers, json=json_data, auth=auth)
                    response.raise_for_status()
                    success = True
            except Exception as e:
                log_message(f"Health check pour {endpoint_key} ({service_name}) a échoué: {e}", level="warning")
                success = False
            finally:
                latency = time.monotonic() - start_time
                self.update_endpoint_health(service_name, endpoint_key, success, latency)
        log_message(f"Health check terminé pour le service: {service_name}")


    def update_endpoint_health(self, service_name: str, endpoint_key: str, success: bool, latency: float):
        """Met à jour le statut de santé d'un endpoint."""
        # S'assurer que le service et l'endpoint existent dans le statut de santé
        if service_name not in self.health_status:
            self.health_status[service_name] = {}
        if endpoint_key not in self.health_status[service_name]:
            self.health_status[service_name][endpoint_key] = {
                "latency": 0.0,
                "success_rate": 1.0,
                "last_checked": None,
                "error_count": 0,
                "total_checks": 0,
                "is_healthy": True
            }

        status = self.health_status[service_name][endpoint_key]
        status["total_checks"] += 1
        status["last_checked"] = format_datetime(get_current_time())

        # Mise à jour du taux de succès et de la latence
        alpha = 0.1 # Facteur de lissage pour la moyenne mobile
        if success:
            status["error_count"] = max(0, status["error_count"] - 1) # Réduit le compteur d'erreurs sur succès
            status["success_rate"] = status["success_rate"] * (1 - alpha) + 1.0 * alpha
            status["latency"] = status["latency"] * (1 - alpha) + latency * alpha
        else:
            status["error_count"] += 1
            status["success_rate"] = status["success_rate"] * (1 - alpha) + 0.0 * alpha
            status["latency"] = status["latency"] * (1 - alpha) + 10.0 * alpha # Pénalité de latence sur erreur

        # Définir la santé basée sur le taux d'erreurs/succès
        if status["error_count"] >= 3 or status["success_rate"] < 0.5: # 3 erreurs consécutives ou taux de succès faible
            status["is_healthy"] = False
        else:
            status["is_healthy"] = True
        
        save_json(ENDPOINT_HEALTH_FILE, self.health_status)
        log_message(f"Santé de {service_name}:{endpoint_key} mise à jour: Succès: {success}, Latence: {latency:.2f}s, Taux Succès: {status['success_rate']:.2f}, Sain: {status['is_healthy']}")

    def get_best_endpoint(self, service_name: str) -> Optional[Dict]:
        """Sélectionne le meilleur endpoint pour un service basé sur la santé."""
        service_health = self.health_status.get(service_name)
        if not service_health:
            log_message(f"Aucune donnée de santé pour le service {service_name}. Retourne None.", level="warning")
            return None

        best_endpoint_key = None
        best_score = -float('inf') # Score basé sur la santé pour la sélection

        healthy_endpoints = [
            (key, status) for key, status in service_health.items() if status["is_healthy"]
        ]

        if not healthy_endpoints:
            log_message(f"Aucun endpoint sain pour le service {service_name}. Tentative de sélection d'un endpoint non sain.", level="warning")
            # Fallback: si aucun sain, prendre le moins mauvais
            all_endpoints = service_health.items()
            if not all_endpoints: return None
            
            # Prioriser le moins d'erreurs, puis la latence la plus faible
            sorted_endpoints = sorted(all_endpoints, key=lambda item: (item[1]["error_count"], item[1]["latency"]))
            best_endpoint_key = sorted_endpoints[0][0]
            log_message(f"Fallback: Endpoint {best_endpoint_key} sélectionné pour {service_name} (non sain).", level="warning")
        else:
            # Calculer un score pour chaque endpoint sain: (success_rate * 100) - (latency * 10) - (error_count * 5)
            # Un score plus élevé est meilleur.
            for endpoint_key, status in healthy_endpoints:
                score = (status["success_rate"] * 100) - (status["latency"] * 10) - (status["error_count"] * 5)
                if score > best_score:
                    best_score = score
                    best_endpoint_key = endpoint_key
            log_message(f"Meilleur endpoint sélectionné pour {service_name}: {best_endpoint_key} (Score: {best_score:.2f})")

        if best_endpoint_key:
            # Trouver la configuration originale de l'endpoint
            for endpoint_config in API_CONFIG.get(service_name, []):
                current_endpoint_key = f"{endpoint_config['endpoint_name']}-{endpoint_config['key']}"
                if current_endpoint_key == best_endpoint_key:
                    return endpoint_config
        return None

# Instancier le gestionnaire de santé des endpoints
endpoint_health_manager = EndpointHealthManager()

# --- FIN DU BLOC GESTION SANTE ENDPOINT ---
# --- DEBUT DU BLOC CLIENT API (BASE) ---

class APIClient:
    """Classe de base pour tous les clients API, gérant la sélection dynamique d'endpoints et les réessais."""
    def __init__(self, name: str):
        self.name = name
        self.endpoints_config = API_CONFIG.get(name, [])
        if not self.endpoints_config:
            log_message(f"Client API {self.name} initialisé sans configuration d'endpoint.", level="error")

    async def _make_request(self, params: Dict = None, headers: Dict = None, json_data: Dict = None, timeout: int = 30, max_retries: int = 3, initial_delay: float = 1.0, url: Optional[str] = None, method: Optional[str] = None, key_field: Optional[str] = None, key_location: Optional[str] = None, api_key: Optional[Union[str, tuple]] = None, fixed_params: Optional[Dict] = None, fixed_headers: Optional[Dict] = None, fixed_json: Optional[Dict] = None) -> Optional[Dict]:
        """Méthode interne pour effectuer les requêtes HTTP en utilisant le meilleur endpoint avec réessais."""
        
        # Utiliser l'URL/méthode/clé fournie si explicitement donnée, sinon utiliser la configuration de l'endpoint sélectionné
        selected_endpoint_config = None
        endpoint_key_for_health = "Dynamic" # Placeholder par défaut

        if url and method:
            # Si des paramètres de requête spécifiques sont fournis, les utiliser
            selected_endpoint_config = {
                "url": url,
                "method": method,
                "key_field": key_field,
                "key_location": key_location,
                "key": api_key,
                "fixed_params": fixed_params if fixed_params is not None else {},
                "fixed_headers": fixed_headers if fixed_headers is not None else {},
                "fixed_json": fixed_json if fixed_json is not None else {},
                "endpoint_name": "Dynamic" # Placeholder pour le gestionnaire de santé
            }
            # Si une clé est fournie, créer un endpoint_key unique pour la gestion de la santé
            if api_key:
                endpoint_key_for_health = f"Dynamic-{api_key}"
            log_message(f"Requête dynamique pour {self.name} vers {url}")
        else:
            selected_endpoint_config = endpoint_health_manager.get_best_endpoint(self.name)
            if not selected_endpoint_config:
                log_message(f"Aucun endpoint sain ou disponible pour {self.name}.", level="error")
                return {"error": True, "message": f"Aucun endpoint sain ou disponible pour {self.name}."}
            endpoint_key_for_health = f"{selected_endpoint_config['endpoint_name']}-{selected_endpoint_config['key']}"
            log_message(f"Endpoint sélectionné pour {self.name}: {selected_endpoint_config['endpoint_name']}")

        url_to_use = selected_endpoint_config["url"]
        method_to_use = selected_endpoint_config["method"]

        # Copier pour ne pas modifier les fixed_params/headers/json_data globaux
        request_params = selected_endpoint_config.get("fixed_params", {}).copy()
        request_headers = selected_endpoint_config.get("fixed_headers", {}).copy()
        request_json_data = selected_endpoint_config.get("fixed_json", {}).copy()
        auth = None

        # Fusionner les paramètres dynamiques avec les fixes
        if params:
            request_params.update(params)
        if headers:
            request_headers.update(headers)
        if json_data:
            request_json_data.update(json_data)

        # Ajouter la clé API selon sa configuration
        key_field_to_use = selected_endpoint_config.get("key_field")
        key_location_to_use = selected_endpoint_config.get("key_location")
        key_prefix = selected_endpoint_config.get("key_prefix", "")
        api_key_to_use = selected_endpoint_config["key"] # La clé réelle

        if key_field_to_use and key_location_to_use:
            if key_location_to_use == "param":
                request_params[key_field_to_use] = api_key_to_use
            elif key_location_to_use == "header":
                request_headers[key_field_to_use] = f"{key_prefix}{api_key_to_use}"
            elif key_location_to_use == "auth_basic":
                # Pour Twilio, api_key est un tuple (sid, secret)
                if isinstance(api_key_to_use, tuple) and len(api_key_to_use) == 2:
                    auth = httpx.BasicAuth(api_key_to_use[0], api_key_to_use[1])
                else:
                    log_message(f"Clé API pour auth_basic non valide pour {self.name}:{endpoint_key_for_health}", level="error")
                    endpoint_health_manager.update_endpoint_health(self.name, endpoint_key_for_health, False, 0.0)
                    return {"error": True, "message": "Configuration d'authentification basique invalide."}

        current_delay = initial_delay
        for attempt in range(max_retries):
            start_time = time.monotonic()
            success = False
            try:
                async with httpx.AsyncClient(timeout=timeout) as client:
                    response = await client.request(method_to_use, url_to_use, params=request_params, headers=request_headers, json=request_json_data, auth=auth)
                    response.raise_for_status() # Lève une exception pour les codes d'erreur HTTP
                    success = True
                    # Tente de décoder le JSON, sinon retourne le texte brut ou une erreur
                    try:
                        return response.json()
                    except json.JSONDecodeError:
                        log_message(f"API {self.name} réponse non JSON (tentative {attempt+1}/{max_retries}): {response.text}", level="warning")
                        # Si ce n'est pas JSON et que ce n'est pas une erreur HTTP, on considère ça comme un succès partiel
                        # mais on le signale comme une erreur pour les clients qui attendent du JSON.
                        return {"error": True, "message": "Réponse API non JSON.", "raw_response": response.text}

            except httpx.HTTPStatusError as e:
                log_message(f"API {self.name} erreur HTTP (tentative {attempt+1}/{max_retries}): {e.response.status_code} - {e.response.text}", level="warning")
                # Ne pas réessayer pour les erreurs client (4xx) sauf 429 (Too Many Requests)
                if 400 <= e.response.status_code < 500 and e.response.status_code != 429:
                    log_message(f"API {self.name}: Erreur client {e.response.status_code}, pas de réessai.", level="error")
                    endpoint_health_manager.update_endpoint_health(self.name, endpoint_key_for_health, False, e.response.elapsed.total_seconds())
                    return {"error": True, "status_code": e.response.status_code, "message": e.response.text}
                
                # Réessayer pour les erreurs serveur ou timeouts ou 429
                if attempt < max_retries - 1:
                    log_message(f"API {self.name}: Réessai dans {current_delay:.2f}s...", level="info")
                    await asyncio.sleep(current_delay)
                    current_delay *= 2 # Backoff exponentiel
            except httpx.RequestError as e:
                log_message(f"API {self.name} erreur de requête (tentative {attempt+1}/{max_retries}): {e}", level="warning")
                if attempt < max_retries - 1:
                    log_message(f"API {self.name}: Réessai dans {current_delay:.2f}s...", level="info")
                    await asyncio.sleep(current_delay)
                    current_delay *= 2
            except Exception as e:
                log_message(f"API {self.name} erreur inattendue (tentative {attempt+1}/{max_retries}): {e}", level="error")
                endpoint_health_manager.update_endpoint_health(self.name, endpoint_key_for_health, False, time.monotonic() - start_time)
                return {"error": True, "message": str(e)}
            finally:
                if not success: # Si l'exception a été levée
                    latency = time.monotonic() - start_time
                    endpoint_health_manager.update_endpoint_health(self.name, endpoint_key_for_health, False, latency)
        
        # Si toutes les tentatives ont échoué
        log_message(f"API {self.name}: Toutes les tentatives ont échoué après {max_retries} réessais.", level="error")
        return {"error": True, "message": f"Échec de la requête après {max_retries} tentatives."}

    async def query(self, *args, **kwargs) -> Any:
        """Méthode abstraite pour interroger l'API."""
        raise NotImplementedError("La méthode query doit être implémentée par les sous-classes.")

# --- FIN DU BLOC CLIENT API (BASE) ---

# --- DEBUT DU BLOC CLIENTS API SPECIFIQUES (PARTIE 1) ---

class DeepSeekClient(APIClient):
    def __init__(self):
        super().__init__("DEEPSEEK")

    async def query(self, prompt: str, model: str = "deepseek-chat") -> str:
        payload = {"model": model, "messages": [{"role": "user", "content": prompt}]}
        response = await self._make_request(json_data=payload)
        if response and not response.get("error"):
            content = response.get("choices", [{}])[0].get("message", {}).get("content")
            if content:
                return content
            return "DeepSeek: Pas de contenu de réponse trouvé."
        return f"DeepSeek: Erreur: {response.get('message', 'Inconnu')}" if response else "DeepSeek: Réponse vide ou erreur interne."

class SerperClient(APIClient):
    def __init__(self):
        super().__init__("SERPER")

    async def query(self, query_text: str) -> str:
        payload = {"q": query_text}
        response = await self._make_request(json_data=payload)
        if response and not response.get("error"):
            organic_results = response.get("organic", [])
            if organic_results:
                snippet = organic_results[0].get("snippet", "Pas de snippet.")
                link = organic_results[0].get("link", "")
                return f"Serper (recherche web):\n{snippet} {neutralize_urls(link)}"
            return "Serper: Aucune information trouvée."
        return f"Serper: Erreur: {response.get('message', 'Inconnu')}" if response else "Serper: Réponse vide ou erreur interne."

class WolframAlphaClient(APIClient):
    def __init__(self):
        super().__init__("WOLFRAMALPHA")

    async def query(self, input_text: str) -> str:
        params = {"input": input_text}
        response = await self._make_request(params=params)
        if response and not response.get("error"):
            pods = response.get("queryresult", {}).get("pods", [])
            if pods:
                for pod in pods:
                    if pod.get("title") in ["Result", "Input interpretation", "Decimal approximation"]:
                        subpods = pod.get("subpods", [])
                        if subpods and subpods[0].get("plaintext"):
                            return f"WolframAlpha:\n{subpods[0]['plaintext']}"
                if pods and pods[0].get("subpods") and pods[0]["subpods"][0].get("plaintext"):
                    return f"WolframAlpha:\n{pods[0]['subpods'][0]['plaintext']}"
            return "WolframAlpha: Pas de résultat clair."
        return f"WolframAlpha: Erreur: {response.get('message', 'Inconnu')}" if response else "WolframAlpha: Réponse vide ou erreur interne."

class TavilyClient(APIClient):
    def __init__(self):
        super().__init__("TAVILY")

    async def query(self, query_text: str, max_results: int = 3) -> str:
        payload = {"query": query_text, "max_results": max_results}
        response = await self._make_request(json_data=payload)
        if response and not response.get("error"):
            results = response.get("results", [])
            answer = response.get("answer", "Aucune réponse directe trouvée.")

            output = f"Tavily (recherche web):\nRéponse directe: {answer}\n"
            if results:
                output += "Extraits pertinents:\n"
                for i, res in enumerate(results[:max_results]):
                    output += f"- {res.get('title', 'N/A')}: {res.get('content', 'N/A')} {neutralize_urls(res.get('url', ''))}\n"
            return output
        return f"Tavily: Erreur: {response.get('message', 'Inconnu')}" if response else "Tavily: Réponse vide ou erreur interne."

class ApiFlashClient(APIClient):
    def __init__(self):
        super().__init__("APIFLASH")

    async def query(self, url: str) -> str:
        params = {"url": url, "format": "jpeg", "full_page": "true"}
        response = await self._make_request(params=params)
        # ApiFlash retourne directement l'image, pas un JSON.
        # Donc, si la requête HTTP a réussi, on considère que c'est un succès.
        # La méthode _make_request va retourner un dictionnaire d'erreur si la réponse n'est pas JSON.
        if response and response.get("error") and "Réponse API non JSON" in response["message"]:
            # C'est le comportement attendu pour ApiFlash (retourne une image, pas JSON)
            # On doit donc ignorer l'erreur JSON et construire l'URL de l'image.
            selected_endpoint_config = endpoint_health_manager.get_best_endpoint(self.name)
            if selected_endpoint_config:
                # Reconstruire l'URL avec les paramètres pour l'affichage
                capture_url = f"{selected_endpoint_config['url']}?access_key={selected_endpoint_config['key']}&url={url}&format=jpeg&full_page=true"
                return f"ApiFlash (capture d'écran): {neutralize_urls(capture_url)} (Vérifiez le lien pour l'image)"
            return "ApiFlash: Impossible de générer l'URL de capture."
        elif response and not response.get("error"):
            # Si par hasard ApiFlash renvoie du JSON (peu probable pour une capture), on le log
            log_message(f"ApiFlash a renvoyé du JSON inattendu: {response}", level="warning")
            return f"ApiFlash: Réponse inattendue de l'API. {response}"
        
        return f"ApiFlash: Erreur: {response.get('message', 'Inconnu')}" if response else "ApiFlash: Réponse vide ou erreur interne."

class CrawlbaseClient(APIClient):
    def __init__(self):
        super().__init__("CRAWLBASE")

    async def query(self, url: str, use_js: bool = False) -> str:
        params = {"url": url, "format": "json"}
        
        # Sélectionner l'endpoint approprié (HTML ou JS)
        selected_endpoint_config = None
        if use_js:
            for config in self.endpoints_config:
                if "JS Scraping" in config.get("endpoint_name", ""):
                    selected_endpoint_config = config
                    break
        
        # Si pas d'endpoint JS ou si use_js est False, tenter de récupérer le meilleur endpoint générique
        if not selected_endpoint_config:
            selected_endpoint_config = endpoint_health_manager.get_best_endpoint(self.name)

        if not selected_endpoint_config:
            return f"Crawlbase: Aucun endpoint sain ou disponible pour {self.name}."

        # Manuellement faire la requête pour s'assurer que la bonne configuration d'endpoint est utilisée
        response = await self._make_request(
            params=params,
            url=selected_endpoint_config["url"], # Surcharge l'URL avec l'URL de l'endpoint sélectionné
            method=selected_endpoint_config["method"],
            key_field=selected_endpoint_config["key_field"],
            key_location=selected_endpoint_config["key_location"],
            api_key=selected_endpoint_config["key"],
            fixed_params=selected_endpoint_config.get("fixed_params", {}) # Inclure les paramètres fixes de la configuration sélectionnée
        )

        if response and not response.get("error"):
            body = response.get("body")
            if body:
                try:
                    decoded_body = base64.b64decode(body).decode('utf-8', errors='ignore')
                    return f"Crawlbase (contenu web):\n{decoded_body[:1000]}..." # Tronquer pour la brièveté
                except Exception:
                    return f"Crawlbase (contenu web - brut):\n{body[:1000]}..."
            return "Crawlbase: Contenu non trouvé."
        return f"Crawlbase: Erreur: {response.get('message', 'Inconnu')}" if response else "Crawlbase: Réponse vide ou erreur interne."

class DetectLanguageClient(APIClient):
    def __init__(self):
        super().__init__("DETECTLANGUAGE")

    async def query(self, text: str) -> str:
        payload = {"q": text}
        response = await self._make_request(json_data=payload)
        if response and not response.get("error"):
            detections = response.get("data", {}).get("detections", [])
            if detections:
                first_detection = detections[0]
                lang = first_detection.get("language")
                confidence = first_detection.get("confidence")
                return f"Langue détectée: {lang} (confiance: {confidence})"
            return "DetectLanguage: Aucune langue détectée."
        return f"DetectLanguage: Erreur: {response.get('message', 'Inconnu')}" if response else "DetectLanguage: Réponse vide ou erreur interne."

class GuardianClient(APIClient):
    def __init__(self):
        super().__init__("GUARDIAN")

    async def query(self, query_text: str) -> str:
        params = {"q": query_text}
        response = await self._make_request(params=params)
        if response and not response.get("error"):
            results = response.get("response", {}).get("results", [])
            if results:
                output = "Articles The Guardian:\n"
                for res in results[:3]: # Limiter à 3 articles
                    output += f"- {res.get('webTitle', 'N/A')}: {res.get('fields', {}).get('trailText', 'N/A')} {neutralize_urls(res.get('webUrl', ''))}\n"
                return output
            return "Guardian: Aucun article trouvé."
        return f"Guardian: Erreur: {response.get('message', 'Inconnu')}" if response else "Guardian: Réponse vide ou erreur interne."

class IP2LocationClient(APIClient):
    def __init__(self):
        super().__init__("IP2LOCATION")

    async def query(self, ip_address: str) -> str:
        params = {"ip": ip_address}
        response = await self._make_request(params=params)
        if response and not response.get("error"):
            if "country_name" in response:
                return f"IP2Location (Géolocalisation IP {ip_address}): Pays: {response['country_name']}, Ville: {response.get('city_name', 'N/A')}"
            return "IP2Location: Informations non trouvées."
        return f"IP2Location: Erreur: {response.get('message', 'Inconnu')}" if response else "IP2Location: Réponse vide ou erreur interne."

class ShodanClient(APIClient):
    def __init__(self):
        super().__init__("SHODAN")

    async def query(self, query_text: str = "") -> str: # Query text est optionnel, car /api-info n'en a pas besoin
        # Shodan a divers endpoints. Cet exemple utilise /api-info.
        # Pour une recherche réelle, ce serait /shodan/host/search ou /shodan/scan
        # Pour simplifier, nous allons simplement interroger /api-info qui nous informe sur la clé.
        # Si query_text est fourni, on tente une recherche d'hôte.
        if query_text:
            # Tenter de faire une recherche d'hôte si l'IP est valide
            if re.match(r"^\d{1,3}\.\d{1,3}\.\d{1,3}\.\d{1,3}$", query_text):
                selected_endpoint_config = None
                for config in self.endpoints_config:
                    if "Host Info" in config.get("endpoint_name", ""):
                        selected_endpoint_config = config
                        break
                if selected_endpoint_config:
                    url = f"https://api.shodan.io/shodan/host/{query_text}"
                    response = await self._make_request(
                        params={"key": selected_endpoint_config["key"]},
                        url=url,
                        method="GET"
                    )
                    if response and not response.get("error"):
                        return f"Shodan (info hôte {query_text}): Pays: {response.get('country_name', 'N/A')}, Ports: {response.get('ports', 'N/A')}, Vulnérabilités: {response.get('vulns', 'Aucune')}"
                    return f"Shodan (info hôte): Erreur: {response.get('message', 'Inconnu')}" if response else "Shodan: Réponse vide ou erreur interne."
            else:
                return "Shodan: Veuillez fournir une adresse IP valide pour la recherche d'hôte."

        # Par défaut, ou si la recherche d'hôte n'est pas applicable/échoue, interroger /api-info
        response = await self._make_request() # Aucun paramètre spécifique n'est nécessaire pour /api-info
        if response and not response.get("error"):
            return f"Shodan (info clé): Requêtes restantes: {response.get('usage_limits', {}).get('query_credits', 'N/A')}, Scan crédits: {response.get('usage_limits', {}).get('scan_credits', 'N/A')}"
        return f"Shodan: Erreur: {response.get('message', 'Inconnu')}" if response else "Shodan: Réponse vide ou erreur interne."

class WeatherAPIClient(APIClient):
    def __init__(self):
        super().__init__("WEATHERAPI")

    async def query(self, location: str) -> str:
        params = {"q": location}
        response = await self._make_request(params=params)
        if response and not response.get("error"):
            current = response.get("current", {})
            location_info = response.get("location", {})
            if current and location_info:
                return (
                    f"Météo à {location_info.get('name', 'N/A')}, {location_info.get('country', 'N/A')}:\n"
                    f"Température: {current.get('temp_c', 'N/A')}°C, "
                    f"Conditions: {current.get('condition', {}).get('text', 'N/A')}, "
                    f"Vent: {current.get('wind_kph', 'N/A')} km/h"
                )
            return "WeatherAPI: Données météo non trouvées."
        return f"WeatherAPI: Erreur: {response.get('message', 'Inconnu')}" if response else "WeatherAPI: Réponse vide ou erreur interne."

class CloudmersiveClient(APIClient):
    def __init__(self):
        super().__init__("CLOUDMERSIVE")

    async def query(self, domain: str) -> str:
        payload = {"domain": domain}
        response = await self._make_request(json_data=payload)
        if response and not response.get("error"):
            return f"Cloudmersive (vérification de domaine {domain}): Valide: {response.get('ValidDomain', 'N/A')}, Type: {response.get('DomainType', 'N/A')}"
        return f"Cloudmersive: Erreur: {response.get('message', 'Inconnu')}" if response else "Cloudmersive: Réponse vide ou erreur interne."

class GreyNoiseClient(APIClient):
    def __init__(self):
        super().__init__("GREYNOISE")

    async def query(self, ip_address: str) -> str:
        # GreyNoise endpoint requires IP to be part of the URL path
        selected_endpoint_config = endpoint_health_manager.get_best_endpoint(self.name)
        if not selected_endpoint_config:
            return f"GreyNoise: Aucun endpoint sain ou disponible pour {self.name}."

        # Manually construct URL for GreyNoise since IP is path param
        url = f"{selected_endpoint_config['url']}{ip_address}"
        method = selected_endpoint_config["method"]
        headers = {selected_endpoint_config["key_field"]: selected_endpoint_config["key"]}

        # Utilisation de _make_request pour bénéficier des réessais et de la gestion d'erreurs
        response = await self._make_request(
            headers=headers,
            url=url,
            method=method,
            key_field=selected_endpoint_config["key_field"], # Passer pour que _make_request puisse gérer la clé
            key_location=selected_endpoint_config["key_location"],
            api_key=selected_endpoint_config["key"]
        )

        if response and not response.get("error"):
            if response.get("noise"):
                return f"GreyNoise (IP {ip_address}): C'est une IP 'bruit' (malveillante). Classification: {response.get('classification', 'N/A')}, Nom d'acteur: {response.get('actor', 'N/A')}"
            return f"GreyNoise (IP {ip_address}): Pas de 'bruit' détecté. Statut: {response.get('status', 'N/A')}"
        return f"GreyNoise: Erreur: {response.get('message', 'Inconnu')}" if response else "GreyNoise: Réponse vide ou erreur interne."

class PulsediveClient(APIClient):
    def __init__(self):
        super().__init__("PULSEDIVE")

    async def query(self, indicator: str, type: str = "auto") -> str:
        params = {"indicator": indicator, "type": type}
        response = await self._make_request(params=params)
        if response and not response.get("error"):
            if response.get("results"):
                result = response["results"][0]
                return (
                    f"Pulsedive (Analyse {indicator}): Type: {result.get('type', 'N/A')}, "
                    f"Risk: {result.get('risk', 'N/A')}, "
                    f"Description: {result.get('description', 'N/A')[:200]}..."
                )
            return "Pulsedive: Aucun résultat d'analyse trouvé."
        return f"Pulsedive: Erreur: {response.get('message', 'Inconnu')}" if response else "Pulsedive: Réponse vide ou erreur interne."

class StormGlassClient(APIClient):
    def __init__(self):
        super().__init__("STORMGLASS")

    async def query(self, lat: float, lng: float, params: str = "airTemperature,waveHeight") -> str:
        now = int(time.time())
        request_params = {
            "lat": lat,
            "lng": lng,
            "params": params,
            "start": now,
            "end": now + 3600 # One hour from now
        }
        response = await self._make_request(params=request_params)
        if response and not response.get("error"):
            data = response.get("hours", [])
            if data:
                first_hour = data[0]
                temp = first_hour.get('airTemperature', [{}])[0].get('value', 'N/A')
                wave_height = first_hour.get('waveHeight', [{}])[0].get('value', 'N/A')
                return f"StormGlass (Météo maritime à {lat},{lng}): Température air: {temp}°C, Hauteur vagues: {wave_height}m"
            return "StormGlass: Données non trouvées."
        return f"StormGlass: Erreur: {response.get('message', 'Inconnu')}" if response else "StormGlass: Réponse vide ou erreur interne."

class LoginRadiusClient(APIClient):
    def __init__(self):
        super().__init__("LOGINRADIUS")

    async def query(self) -> str:
        response = await self._make_request()
        if response and not response.get("error"):
            return f"LoginRadius (Ping API): Statut: {response.get('Status', 'N/A')}, Message: {response.get('Message', 'N/A')}"
        return f"LoginRadius: Erreur: {response.get('message', 'Inconnu')}" if response else "LoginRadius: Réponse vide ou erreur interne."

class JsonbinClient(APIClient):
    def __init__(self):
        super().__init__("JSONBIN")

    async def query(self, data: Dict[str, Any], private: bool = True, bin_id: Optional[str] = None) -> str:
        # If bin_id is provided, it's a GET request to access a bin
        if bin_id:
            selected_endpoint_config = None
            for config in self.endpoints_config:
                if "Bin Access" in config.get("endpoint_name", ""):
                    selected_endpoint_config = config
                    break
            if not selected_endpoint_config:
                return f"Jsonbin: Aucun endpoint d'accès de bin sain ou disponible pour {self.name}."

            url = f"{selected_endpoint_config['url']}/{bin_id}"
            method = "GET"
            headers = {selected_endpoint_config["key_field"]: selected_endpoint_config["key"]}
            
            response = await self._make_request(
                headers=headers,
                url=url,
                method=method
            )
            if response and not response.get("error"):
                return f"Jsonbin (Accès bin {bin_id}):\n{json.dumps(response, indent=2)}"
            return f"Jsonbin (Accès bin): Erreur: {response.get('message', 'Inconnu')}" if response else "Jsonbin: Réponse vide ou erreur interne."
        
        # Otherwise, it's a POST request to create a bin
        else:
            selected_endpoint_config = None
            for config in self.endpoints_config:
                if "Bin Create" in config.get("endpoint_name", ""):
                    selected_endpoint_config = config
                    break
            
            if not selected_endpoint_config:
                return f"Jsonbin: Aucun endpoint de création de bin sain ou disponible pour {self.name}."

            url = selected_endpoint_config["url"]
            method = "POST"
            headers = {selected_endpoint_config["key_field"]: selected_endpoint_config["key"], "Content-Type": "application/json"}
            payload = {"record": data, "private": private}

            response = await self._make_request(
                json_data=payload,
                headers=headers,
                url=url,
                method=method
            )

            if response and not response.get("error"):
                return f"Jsonbin (Création de bin): ID: {response.get('metadata', {}).get('id', 'N/A')}, URL: {neutralize_urls(response.get('metadata', {}).get('url', 'N/A'))}"
            return f"Jsonbin (Création de bin): Erreur: {response.get('message', 'Inconnu')}" if response else "Jsonbin: Réponse vide ou erreur interne."

class HuggingFaceClient(APIClient):
    def __init__(self):
        super().__init__("HUGGINGFACE")

    async def query(self, model_name: str = "distilbert-base-uncased-finetuned-sst-2-english", input_text: str = "Hello world") -> str:
        # HuggingFace inference endpoint URL includes the model name
        selected_endpoint_config = endpoint_health_manager.get_best_endpoint(self.name)
        if not selected_endpoint_config:
            return f"HuggingFace: Aucun endpoint sain ou disponible pour {self.name}."

        # Override URL for inference
        inference_url = f"https://api-inference.huggingface.co/models/{model_name}"
        
        # Ensure the key is added to headers as per config
        headers = {
            selected_endpoint_config["key_field"]: f"{selected_endpoint_config['key_prefix']}{selected_endpoint_config['key']}",
            "Content-Type": "application/json"
        }
        payload = {"inputs": input_text}

        response = await self._make_request(
            json_data=payload,
            headers=headers,
            url=inference_url,
            method="POST" # Inference is always POST
        )

        if response and not response.get("error"):
            if isinstance(response, list) and response:
                first_result = response[0]
                if isinstance(first_result, list) and first_result:
                    return f"HuggingFace ({model_name} - {first_result[0].get('label')}): Score {first_result[0].get('score', 'N/A'):.2f}"
                elif isinstance(first_result, dict) and "generated_text" in first_result:
                    return f"HuggingFace ({model_name}): {first_result.get('generated_text')}"
            return f"HuggingFace ({model_name}): Réponse non parsée. {response}"
        return f"HuggingFace: Erreur: {response.get('message', 'Inconnu')}" if response else "HuggingFace: Réponse vide ou erreur interne."

class TwilioClient(APIClient):
    def __init__(self):
        super().__init__("TWILIO")

    async def query(self) -> str:
        # Twilio uses Basic Auth, handled by _make_request
        # We need to explicitly select an endpoint for the query method
        selected_endpoint_config = None
        for config in self.endpoints_config:
            if "Account Balance" in config.get("endpoint_name", ""): # Prioritize balance check
                selected_endpoint_config = config
                break
        if not selected_endpoint_config:
            selected_endpoint_config = self.endpoints_config[0] # Fallback to first if balance not found

        response = await self._make_request(
            url=selected_endpoint_config["url"],
            method=selected_endpoint_config["method"],
            key_location=selected_endpoint_config["key_location"],
            api_key=selected_endpoint_config["key"]
        )
        if response and not response.get("error"):
            # The balance endpoint returns balance and currency directly
            return f"Twilio (Balance): {response.get('balance', 'N/A')} {response.get('currency', 'N/A')}"
        return f"Twilio: Erreur: {response.get('message', 'Inconnu')}" if response else "Twilio: Réponse vide ou erreur interne."

class AbstractAPIClient(APIClient):
    def __init__(self):
        super().__init__("ABSTRACTAPI")

    async def query(self, input_value: str, api_type: str) -> str:
        params = {}
        target_endpoint_name = ""

        if api_type == "PHONE_VALIDATION":
            params["phone"] = input_value
            target_endpoint_name = "Phone Validation"
        elif api_type == "EMAIL_VALIDATION":
            params["email"] = input_value
            # Select one of the email validation keys
            target_endpoint_name = "Email Validation"
        elif api_type == "EXCHANGE_RATES":
            target_endpoint_name = "Exchange Rates"
        elif api_type == "HOLIDAYS":
            params["country"] = input_value if input_value else "US"
            params["year"] = datetime.now().year
            target_endpoint_name = "Holidays"
        else:
            return f"AbstractAPI: Type d'API '{api_type}' non supporté pour la requête."

        selected_endpoint_config = None
        for config in self.endpoints_config:
            if target_endpoint_name in config["endpoint_name"]:
                selected_endpoint_config = config
                break
        
        if not selected_endpoint_config:
            return f"AbstractAPI: Aucun endpoint sain ou disponible pour {self.name} pour le type {api_type}."

        response = await self._make_request(
            params=params,
            url=selected_endpoint_config["url"],
            method=selected_endpoint_config["method"],
            key_field=selected_endpoint_config["key_field"],
            key_location=selected_endpoint_config["key_location"],
            api_key=selected_endpoint_config["key"],
            fixed_params=selected_endpoint_config.get("fixed_params", {})
        )

        if response and not response.get("error"):
            if api_type == "PHONE_VALIDATION":
                return (
                    f"AbstractAPI (Validation Tél): Numéro: {response.get('phone', 'N/A')}, "
                    f"Valide: {response.get('valid', 'N/A')}, "
                    f"Pays: {response.get('country', {}).get('name', 'N/A')}"
                )
            elif api_type == "EMAIL_VALIDATION":
                return (
                    f"AbstractAPI (Validation Email): Email: {response.get('email', 'N/A')}, "
                    f"Valide: {response.get('is_valid_format', 'N/A')}, "
                    f"Deliverable: {response.get('is_deliverable', 'N/A')}"
                )
            elif api_type == "EXCHANGE_RATES":
                return f"AbstractAPI (Taux de change): Base: {response.get('base', 'N/A')}, Taux (USD): {response.get('exchange_rates', {}).get('USD', 'N/A')}"
            elif api_type == "HOLIDAYS":
                holidays = [h.get('name', 'N/A') for h in response if h.get('name')]
                return f"AbstractAPI (Jours fériés {params.get('country', 'US')} {params.get('year')}): {', '.join(holidays[:5])}..." if holidays else "Aucun jour férié trouvé."
            return f"AbstractAPI ({api_type}): Réponse brute: {response}"
        return f"AbstractAPI ({api_type}): Erreur: {response.get('message', 'Inconnu')}" if response else "AbstractAPI: Réponse vide ou erreur interne."

class GeminiAPIClient(APIClient):
    def __init__(self):
        super().__init__("GEMINI_API")

    async def query(self, prompt: str, model: str = "gemini-1.5-flash") -> str:
        payload = {"contents": [{"parts": [{"text": prompt}]}]}
        # Gemini API often requires the model name in the URL path
        selected_endpoint_config = endpoint_health_manager.get_best_endpoint(self.name)
        if not selected_endpoint_config:
            return f"Gemini API: Aucun endpoint sain ou disponible pour {self.name}."

        # Override URL for specific model generation
        generate_url = f"https://generativelanguage.googleapis.com/v1beta/models/{model}:generateContent"
        
        # Ensure the key is added to params as per config
        request_params = {selected_endpoint_config["key_field"]: selected_endpoint_config["key"]}

        response = await self._make_request(
            json_data=payload,
            params=request_params,
            url=generate_url,
            method="POST",
            timeout=60 # Longer timeout for LLM calls
        )

        if response and not response.get("error"):
            if response.get("candidates") and response["candidates"][0].get("content"):
                return response["candidates"][0]["content"]["parts"][0]["text"]
            return f"Gemini API: Pas de réponse générée. {response}"
        return f"Gemini API: Erreur: {response.get('message', 'Inconnu')}" if response else "Gemini API: Réponse vide ou erreur interne."

class GoogleCustomSearchClient(APIClient):
    def __init__(self):
        super().__init__("GOOGLE_CUSTOM_SEARCH")

    async def query(self, query_text: str) -> str:
        params = {"q": query_text}
        response = await self._make_request(params=params)
        if response and not response.get("error"):
            items = response.get("items", [])
            if items:
                output = "Google Custom Search:\n"
                for item in items[:3]: # Limit to 3 results
                    output += f"- {item.get('title', 'N/A')}: {item.get('snippet', 'N/A')} {neutralize_urls(item.get('link', ''))}\n"
                return output
            return "Google Custom Search: Aucun résultat trouvé."
        return f"Google Custom Search: Erreur: {response.get('message', 'Inconnu')}" if response else "Google Custom Search: Réponse vide ou erreur interne."

class RandommerClient(APIClient):
    def __init__(self):
        super().__init__("RANDOMMER")

    async def query(self, country_code: str = "US", quantity: int = 1) -> str:
        params = {"CountryCode": country_code, "Quantity": quantity}
        response = await self._make_request(params=params)
        if response and not response.get("error"):
            if isinstance(response, list) and response:
                return f"Randommer (Numéros de téléphone): {', '.join(response)}"
            return f"Randommer: {response}"
        return f"Randommer: Erreur: {response.get('message', 'Inconnu')}" if response else "Randommer: Réponse vide ou erreur interne."

class TomorrowIOClient(APIClient):
    def __init__(self):
        super().__init__("TOMORROW.IO")

    async def query(self, location: str, fields: List[str] = None) -> str:
        if fields is None:
            fields = ["temperature", "humidity", "windSpeed"]
        payload = {"location": location, "fields": fields, "units": "metric", "timesteps": ["1h"]}
        response = await self._make_request(json_data=payload)
        if response and not response.get("error"):
            data = response.get("data", {}).get("timelines", [{}])[0].get("intervals", [{}])[0].get("values", {})
            if data:
                output = f"Météo (Tomorrow.io) à {location}:\n"
                for field in fields:
                    output += f"- {field.capitalize()}: {data.get(field, 'N/A')}\n"
                return output
            return "Tomorrow.io: Données météo non trouvées."
        return f"Tomorrow.io: Erreur: {response.get('message', 'Inconnu')}" if response else "Tomorrow.io: Réponse vide ou erreur interne."

class OpenWeatherMapClient(APIClient):
    def __init__(self):
        super().__init__("OPENWEATHERMAP")

    async def query(self, location: str) -> str:
        params = {"q": location}
        response = await self._make_request(params=params)
        if response and not response.get("error"):
            main_data = response.get("main", {})
            weather_desc = response.get("weather", [{}])[0].get("description", "N/A")
            if main_data:
                return (
                    f"Météo (OpenWeatherMap) à {location}:\n"
                    f"Température: {main_data.get('temp', 'N/A')}°C, "
                    f"Ressenti: {main_data.get('feels_like', 'N/A')}°C, "
                    f"Humidité: {main_data.get('humidity', 'N/A')}%, "
                    f"Conditions: {weather_desc}"
                )
            return "OpenWeatherMap: Données météo non trouvées."
        return f"OpenWeatherMap: Erreur: {response.get('message', 'Inconnu')}" if response else "OpenWeatherMap: Réponse vide ou erreur interne."

class MockarooClient(APIClient):
    def __init__(self):
        super().__init__("MOCKAROO")

    async def query(self, count: int = 1, fields_json: str = None) -> str:
        # Mockaroo's 'fields' parameter often expects a JSON string, which needs to be URL-encoded for GET requests.
        # The default fixed_params already include a basic fields_json.
        params = {"count": count}
        if fields_json:
            params["fields"] = fields_json # Override default if provided

        response = await self._make_request(params=params)
        if response and not response.get("error"):
            return f"Mockaroo (Génération de données):\n{json.dumps(response, indent=2)}"
        return f"Mockaroo: Erreur: {response.get('message', 'Inconnu')}" if response else "Mockaroo: Réponse vide ou erreur interne."

class OpenPageRankClient(APIClient):
    def __init__(self):
        super().__init__("OPENPAGERANK")

    async def query(self, domains: List[str]) -> str:
        params = {"domains[]": domains}
        response = await self._make_request(params=params)
        if response and not response.get("error"):
            results = response.get("response", [])
            if results:
                output = "OpenPageRank (Classement de domaine):\n"
                for res in results:
                    output += f"- Domaine: {res.get('domain', 'N/A')}, PageRank: {res.get('page_rank', 'N/A')}\n"
                return output
            return "OpenPageRank: Aucun résultat trouvé."
        return f"OpenPageRank: Erreur: {response.get('message', 'Inconnu')}" if response else "OpenPageRank: Réponse vide ou erreur interne."

class RapidAPIClient(APIClient):
    def __init__(self):
        super().__init__("RAPIDAPI")

    async def query(self, api_name: str, **kwargs) -> str:
        # RapidAPI is a marketplace, so we need to select the specific API endpoint
        # based on 'api_name' argument.
        selected_endpoint_config = None
        for config in self.endpoints_config:
            if api_name.lower() in config["endpoint_name"].lower():
                selected_endpoint_config = config
                break
        
        if not selected_endpoint_config:
            return f"RapidAPI: Endpoint pour '{api_name}' non trouvé ou non configuré."

        # Manually build request based on selected_endpoint_config
        url = selected_endpoint_config["url"]
        method = selected_endpoint_config["method"]
        
        request_params = selected_endpoint_config.get("fixed_params", {}).copy()
        request_headers = selected_endpoint_config.get("fixed_headers", {}).copy()
        request_json_data = selected_endpoint_config.get("fixed_json", {}).copy()

        # Add dynamic kwargs to params/json_data
        if method == "GET":
            request_params.update(kwargs)
        elif method == "POST":
            request_json_data.update(kwargs)

        headers = {
            selected_endpoint_config["key_field"]: selected_endpoint_config["key"],
            "X-RapidAPI-Host": selected_endpoint_config["fixed_headers"].get("X-RapidAPI-Host") # Specific to RapidAPI
        }
        
        response = await self._make_request(
            params=request_params,
            headers=headers,
            json_data=request_json_data,
            url=url,
            method=method
        )

        if response and not response.get("error"):
            if api_name.lower() == "programming joke":
                return f"RapidAPI (Blague de Programmation): {response.get('setup', '')} - {response.get('punchline', '')}"
            elif api_name.lower() == "currency list quotes":
                return f"RapidAPI (Devises): {json.dumps(response, indent=2)}"
            elif api_name.lower() == "random fact":
                return f"RapidAPI (Fait Aléatoire): {response.get('text', 'N/A')}"
            return f"RapidAPI ({api_name}): {json.dumps(response, indent=2)}"
        return f"RapidAPI ({api_name}): Erreur: {response.get('message', 'Inconnu')}" if response else "RapidAPI: Réponse vide ou erreur interne."

# --- Instancier tous les clients API ---
ALL_API_CLIENTS = [
    DeepSeekClient(),
    SerperClient(),
    WolframAlphaClient(),
    TavilyClient(),
    ApiFlashClient(),
    CrawlbaseClient(),
    DetectLanguageClient(),
    GuardianClient(),
    IP2LocationClient(),
    ShodanClient(),
    WeatherAPIClient(),
    CloudmersiveClient(),
    GreyNoiseClient(),
    PulsediveClient(),
    StormGlassClient(),
    LoginRadiusClient(),
    JsonbinClient(),
    HuggingFaceClient(),
    TwilioClient(),
    AbstractAPIClient(),
    GeminiAPIClient(),
    GoogleCustomSearchClient(),
    RandommerClient(),
    TomorrowIOClient(),
    OpenWeatherMapClient(),
    MockarooClient(),
    OpenPageRankClient(),
    RapidAPIClient()
]

# --- FIN DU BLOC CLIENTS API SPECIFIQUES---

# --- DEBUT DU BLOC GESTION MEMOIRE ET QUOTAS ---

class MemoryManager:
    def __init__(self):
        self.chat_history = load_json(HISTORY_FILE, [])
        self.long_term_memory = load_json(LONG_MEMORY_FILE, {})
        self.ia_status = load_json(IA_STATUS_FILE, {})
        self._initialize_ia_status()

    def _initialize_ia_status(self):
        """Initialise le statut des IA si elles ne sont pas déjà présentes ou si leur statut est obsolète."""
        now = get_current_time()
        updated = False
        for client in ALL_API_CLIENTS:
            if client.name not in self.ia_status:
                self.ia_status[client.name] = {
                    "last_used": None,
                    "last_error": None,
                    "error_count": 0,
                    "cooldown_until": None,
                    "success_count": 0,
                    "current_score": 1.0, # Maintenu pour la compatibilité, mais moins utilisé pour la sélection primaire
                    "last_rotation_check": format_datetime(now),
                    "diversification_score": 1.0 # Nouveau score pour la diversification
                }
                updated = True
            else:
                # S'assurer que les nouvelles clés existent pour les IA existantes
                default_ia_status_keys = {
                    "success_count": 0,
                    "current_score": 1.0,
                    "last_rotation_check": format_datetime(now),
                    "diversification_score": 1.0
                }
                for key, default_value in default_ia_status_keys.items():
                    if key not in self.ia_status[client.name]:
                        self.ia_status[client.name][key] = default_value
                        updated = True

        # Nettoyer les IA qui ne sont plus dans ALL_API_CLIENTS
        current_api_names = {client.name for client in ALL_API_CLIENTS}
        ia_names_to_remove = [name for name in self.ia_status if name not in current_api_names]
        for name in ia_names_to_remove:
            del self.ia_status[name]
            updated = True
            log_message(f"IA '{name}' trouvée dans ia_status.json mais non définie dans ALL_API_CLIENTS. Supprimée.", level="warning")


        if updated:
            save_json(IA_STATUS_FILE, self.ia_status)
            log_message("Statut des IA initialisé/mis à jour.")

    def add_message_to_history(self, role, content):
        """Ajoute un message à l'historique de la conversation."""
        self.chat_history.append({"role": role, "content": content, "timestamp": format_datetime(get_current_time())})
        self._prune_history()
        save_json(HISTORY_FILE, self.chat_history)
        log_message(f"Message ajouté à l'historique par {role}.")

    def get_chat_history(self, limit=10):
        """Retourne les N derniers messages de l'historique."""
        return self.chat_history[-limit:]

    def add_to_long_term_memory(self, key, value):
        """Ajoute une information à la mémoire à long terme."""
        self.long_term_memory[key] = {"value": value, "timestamp": format_datetime(get_current_time())}
        save_json(LONG_MEMORY_FILE, self.long_term_memory)
        log_message(f"Information ajoutée à la mémoire à long terme: {key}")

    def get_from_long_term_memory(self, key):
        """Récupère une information de la mémoire à long terme."""
        return self.long_term_memory.get(key)

    def update_ia_status(self, ia_name: str, success: bool, error_message: Optional[str] = None):
        """Met à jour le statut et le score d'une IA après une utilisation."""
        status = self.ia_status.get(ia_name)
        if not status:
            log_message(f"Tentative de mise à jour d'un statut d'IA inconnu: {ia_name}", level="warning")
            return

        now = get_current_time()
        status["last_used"] = format_datetime(now)

        if success:
            status["success_count"] += 1
            status["error_count"] = 0
            status["cooldown_until"] = None
            status["last_error"] = None
            status["current_score"] = min(1.0, status["current_score"] + 0.1)
            # Decrease diversification score on use
            status["diversification_score"] = max(0.1, status["diversification_score"] - 0.1)
            log_message(f"IA {ia_name} : Succès enregistré. Nouveau score: {status['current_score']:.2f}, Diversification: {status['diversification_score']:.2f}")
        else:
            status["error_count"] += 1
            status["last_error"] = error_message
            if status["error_count"] >= 3:
                status["cooldown_until"] = format_datetime(now + timedelta(seconds=API_COOLDOWN_DURATION_SECONDS))
                status["current_score"] = max(0.1, status["current_score"] - 0.2)
                log_message(f"IA {ia_name} : Trop d'erreurs ({status['error_count']}). Cooldown jusqu'à {status['cooldown_until']}. Nouveau score: {status['current_score']:.2f}", level="warning")
            else:
                 status["current_score"] = max(0.1, status["current_score"] - 0.05)
                 log_message(f"IA {ia_name} : Erreur enregistrée. Nouveau score: {status['current_score']:.2f}", level="warning")

        save_json(IA_STATUS_FILE, self.ia_status)

    def recover_diversification_scores(self):
        """Augmente le score de diversification pour les IA non utilisées récemment."""
        now = get_current_time()
        updated = False
        for ia_name, status in self.ia_status.items():
            last_used_str = status.get("last_used")
            if last_used_str:
                last_used_dt = datetime.strptime(last_used_str, "%Y-%m-%d %H:%M:%S UTC").replace(tzinfo=None)
                # If not used in the last API_ROTATION_INTERVAL_MINUTES * 2 (e.g., 60 mins), recover score
                if (now - last_used_dt).total_seconds() > API_ROTATION_INTERVAL_MINUTES * 60 * 2:
                    if status["diversification_score"] < 1.0:
                        status["diversification_score"] = min(1.0, status["diversification_score"] + 0.05)
                        updated = True
                        log_message(f"IA {ia_name}: Score de diversification récupéré à {status['diversification_score']:.2f}")
            else: # Never used, ensure it's at max
                if status["diversification_score"] < 1.0:
                    status["diversification_score"] = 1.0
                    updated = True
        if updated:
            save_json(IA_STATUS_FILE, self.ia_status)

    def get_ia_status(self, ia_name: str) -> Optional[Dict]:
        """Récupère le statut d'une IA."""
        return self.ia_status.get(ia_name)

    def get_available_ias(self) -> List[str]:
        """Retourne les noms des IA actuellement non en cooldown."""
        available = []
        now = get_current_time()
        for name, status in self.ia_status.items():
            cooldown_until_str = status.get("cooldown_until")
            if cooldown_until_str:
                cooldown_until = datetime.strptime(cooldown_until_str, "%Y-%m-%d %H:%M:%S UTC").replace(tzinfo=None)
                if now < cooldown_until:
                    continue
            available.append(name)
        return available

    def _prune_history(self, max_entries=50):
        """Supprime les anciennes entrées de l'historique si trop nombreuses."""
        if len(self.chat_history) > max_entries:
            self.chat_history = self.chat_history[-max_entries:]
            log_message(f"Historique de chat purgé, {len(self.chat_history)} entrées restantes.")

class QuotaManager:
    def __init__(self):
        self.quotas = load_json(QUOTAS_FILE, {})
        self._initialize_quotas()

    def _initialize_quotas(self):
        """Initialise les quotas pour toutes les APIs basées sur config.API_QUOTAS et nettoie/met à jour les existants."""
        updated = False
        now = get_current_time()

        # Step 1: Ensure all APIs from API_QUOTAS are in self.quotas with full structure
        for api_name, quota_info in API_QUOTAS.items():
            if api_name not in self.quotas:
                self.quotas[api_name] = {
                    "monthly_usage": 0,
                    "daily_usage": 0,
                    "hourly_usage": 0,
                    "hourly_timestamps": [],
                    "last_reset_month": now.month,
                    "last_reset_day": now.day,
                    "last_usage": None,
                    "total_calls": 0,
                    "last_hourly_reset": format_datetime(now)
                }
                updated = True
            else:
                # Ensure existing entries have all required keys
                default_quota_structure = {
                    "monthly_usage": 0,
                    "daily_usage": 0,
                    "hourly_usage": 0,
                    "hourly_timestamps": [],
                    "last_reset_month": now.month,
                    "last_reset_day": now.day,
                    "last_usage": None,
                    "total_calls": 0,
                    "last_hourly_reset": format_datetime(now)
                }
                for key, default_value in default_quota_structure.items():
                    if key not in self.quotas[api_name]:
                        self.quotas[api_name][key] = default_value
                        updated = True
                
                # Re-evaluate hourly_usage based on timestamps during initialization
                one_hour_ago = now - timedelta(hours=1)
                # Ensure hourly_timestamps is a list before filtering
                if not isinstance(self.quotas[api_name].get("hourly_timestamps"), list):
                    self.quotas[api_name]["hourly_timestamps"] = []
                    updated = True

                self.quotas[api_name]["hourly_timestamps"] = [
                    ts for ts in self.quotas[api_name]["hourly_timestamps"]
                    if datetime.strptime(ts, "%Y-%m-%d %H:%M:%S UTC").replace(tzinfo=None) > one_hour_ago
                ]
                self.quotas[api_name]["hourly_usage"] = len(self.quotas[api_name]["hourly_timestamps"])
                self.quotas[api_name]["last_hourly_reset"] = format_datetime(now) # Update reset time

        # Step 2: Remove any API names from self.quotas that are NOT in API_QUOTAS
        # This handles cases where invalid API names might have been added previously
        api_names_to_remove = [name for name in self.quotas if name not in API_QUOTAS]
        for name in api_names_to_remove:
            del self.quotas[name]
            updated = True
            log_message(f"API '{name}' trouvée dans quotas.json mais non définie dans API_QUOTAS. Supprimée.", level="warning")

        if updated:
            save_json(QUOTAS_FILE, self.quotas)
            log_message("Quotas API initialisés/mis à jour.")

    def _reset_quotas_if_needed(self):
        """Réinitialise les quotas journaliers, mensuels et horaires si nécessaire."""
        now = get_current_time()
        for api_name, data in self.quotas.items():
            # Reset mensuel
            if now.month != data["last_reset_month"]:
                data["monthly_usage"] = 0
                data["last_reset_month"] = now.month
                log_message(f"Quota mensuel pour {api_name} réinitialisé.")
            # Reset journalier
            if now.day != data["last_reset_day"]:
                data["daily_usage"] = 0
                data["last_reset_day"] = now.day
                log_message(f"Quota journalier pour {api_name} réinitialisé.")
            
            # Reset et gestion horaire (nettoyage des timestamps trop anciens)
            one_hour_ago = now - timedelta(hours=1)
            # Ensure hourly_timestamps is a list before filtering
            if not isinstance(data.get("hourly_timestamps"), list):
                data["hourly_timestamps"] = []
            
            data["hourly_timestamps"] = [
                ts for ts in data["hourly_timestamps"]
                if datetime.strptime(ts, "%Y-%m-%d %H:%M:%S UTC").replace(tzinfo=None) > one_hour_ago
            ]
            data["hourly_usage"] = len(data["hourly_timestamps"])
            
            # Update last_hourly_reset to current time if a reset happened or after cleanup
            data["last_hourly_reset"] = format_datetime(now)

        save_json(QUOTAS_FILE, self.quotas)

    def check_and_update_quota(self, api_name: str, cost: int = 1) -> bool:
        """Vérifie si une API a du quota et le décrémente. Retourne True si ok, False sinon."""
        self._reset_quotas_if_needed()
        
        # IMPORTANT: Only process if api_name is a valid, configured API
        if api_name not in API_QUOTAS:
            log_message(f"Tentative de vérification de quota pour une API non définie: {api_name}. Autorisation refusée.", level="error")
            return False # Prevent processing for undefined APIs

        if api_name not in self.quotas:
            # This case should ideally not happen after robust initialization, but as a fallback
            log_message(f"API {api_name} non trouvée dans les quotas gérés. Re-initialisation.", level="warning")
            self._initialize_quotas() # Re-initialize to ensure it's added
            if api_name not in self.quotas: # If still not there after re-init, something is fundamentally wrong
                log_message(f"API {api_name} toujours introuvable après re-initialisation. Autorisation refusée.", level="error")
                return False


        quota_data = self.quotas[api_name]
        api_limits = API_QUOTAS.get(api_name, {})
        now = get_current_time()

        monthly_limit = api_limits.get("monthly")
        if monthly_limit is not None and (quota_data["monthly_usage"] + cost) > monthly_limit:
            log_message(f"Quota mensuel dépassé pour {api_name}", level="warning")
            return False

        daily_limit = api_limits.get("daily")
        if daily_limit is not None and (quota_data["daily_usage"] + cost) > daily_limit:
            log_message(f"Quota journalier dépassé pour {api_name}", level="warning")
            return False
        
        hourly_limit = api_limits.get("hourly")
        if hourly_limit is not None and (quota_data["hourly_usage"] + cost) > hourly_limit:
            log_message(f"Quota horaire dépassé pour {api_name}", level="warning")
            return False

        rate_limit_per_sec = api_limits.get("rate_limit_per_sec")
        if rate_limit_per_sec:
            last_usage_str = quota_data.get("last_usage")
            if last_usage_str:
                last_usage = datetime.strptime(last_usage_str, "%Y-%m-%d %H:%M:%S UTC").replace(tzinfo=None)
                time_since_last_call = (now - last_usage).total_seconds()
                if time_since_last_call < (1 / rate_limit_per_sec):
                    log_message(f"Taux de requêtes dépassé pour {api_name}. Attendre {1/rate_limit_per_sec - time_since_last_call:.2f}s", level="warning")
                    return False

        # Only update usage if cost is greater than 0. This prevents quota consumption during check-only calls.
        if cost > 0:
            quota_data["monthly_usage"] += cost
            quota_data["daily_usage"] += cost
            quota_data["hourly_usage"] += cost
            quota_data["hourly_timestamps"].append(format_datetime(now)) # Add current timestamp
            quota_data["total_calls"] += cost
            quota_data["last_usage"] = format_datetime(now)
            save_json(QUOTAS_FILE, self.quotas)
            log_message(f"Quota pour {api_name} mis à jour. Usage mensuel: {quota_data['monthly_usage']}/{monthly_limit if monthly_limit else 'Illimité'}, Journalier: {quota_data['daily_usage']}/{daily_limit if daily_limit else 'Illimité'}, Horaire: {quota_data['hourly_usage']}/{hourly_limit if hourly_limit else 'Illimité'}")
        else:
            log_message(f"Quota pour {api_name} vérifié (coût 0). Usage mensuel: {quota_data['monthly_usage']}/{monthly_limit if monthly_limit else 'Illimité'}, Journalier: {quota_data['daily_usage']}/{daily_limit if daily_limit else 'Illimité'}, Horaire: {quota_data['hourly_usage']}/{hourly_limit if hourly_limit else 'Illimité'}")

        return True

    def get_api_usage(self, api_name: str) -> Optional[Dict]:
        """Retourne les informations d'utilisation d'une API."""
        return self.quotas.get(api_name)

    def get_all_quotas_status(self) -> Dict:
        """Retourne le statut de tous les quotas."""
        self._reset_quotas_if_needed()
        status = {}
        for api_name, quota_data in self.quotas.items():
            api_limits = API_QUOTAS.get(api_name, {})
            monthly_limit = api_limits.get("monthly", "Illimité")
            daily_limit = api_limits.get("daily", "Illimité")
            hourly_limit = api_limits.get("hourly", "Illimité")
            status[api_name] = {
                "monthly_usage": quota_data["monthly_usage"],
                "monthly_limit": monthly_limit,
                "daily_usage": quota_data["daily_usage"],
                "daily_limit": daily_limit,
                "hourly_usage": quota_data["hourly_usage"],
                "hourly_limit": hourly_limit,
                "total_calls": quota_data["total_calls"],
                "last_usage": quota_data["last_usage"],
                "last_reset_month": quota_data["last_reset_month"],
                "last_reset_day": quota_data["last_reset_day"],
                "last_hourly_reset": quota_data["last_hourly_reset"]
            }
        return status

    def get_burn_window_apis(self) -> List[str]:
        """
        Identifie les APIs dont les quotas sont sur le point d'être réinitialisés
        et où il est opportun de "brûler" le quota restant.
        """
        burn_apis = []
        now = get_current_time()
        for api_name, data in self.quotas.items():
            api_limits = API_QUOTAS.get(api_name, {})

            if api_limits.get("monthly") is not None:
                next_month_reset = datetime(now.year + (1 if now.month == 12 else 0), (now.month % 12) + 1, 1).replace(tzinfo=None)
                if is_within_time_window(next_month_reset, QUOTA_BURN_WINDOW_HOURS * 60, 0):
                    if data["monthly_usage"] < api_limits["monthly"]:
                        burn_apis.append(f"{api_name} (mensuel: {api_limits['monthly'] - data['monthly_usage']} restants)")

            if api_limits.get("daily") is not None:
                next_day_reset = datetime(now.year, now.month, now.day).replace(tzinfo=None) + timedelta(days=1)
                if is_within_time_window(next_day_reset, QUOTA_BURN_WINDOW_HOURS * 60, 0):
                    if data["daily_usage"] < api_limits["daily"]:
                        burn_apis.append(f"{api_name} (journalier: {api_limits['daily'] - data['daily_usage']} restants)")
        return burn_apis

# Instanciation des gestionnaires
memory_manager = MemoryManager()
quota_manager = QuotaManager()

import time
from telegram import Update, ForceReply
from telegram.ext import Application, CommandHandler, MessageHandler, filters, ContextTypes

# --- Orchestration des IA ---
class IAOrchestrator:
    def __init__(self, memory_manager: MemoryManager, quota_manager: QuotaManager, api_clients: List[APIClient]):
        self.memory_manager = memory_manager
        self.quota_manager = quota_manager
        self.api_clients = {client.name: client for client in api_clients}
        self.last_strategy_rotation_time = get_current_time()
        self.current_ia_strategy = self._determine_initial_strategy()

        # Les cinq moteurs IA principaux
        self.core_ai_engines = {
            "DEEPSEEK": self.api_clients.get("DEEPSEEK"),
            "HUGGINGFACE": self.api_clients.get("HUGGINGFACE"),
            "GOOGLE_CUSTOM_SEARCH": self.api_clients.get("GOOGLE_CUSTOM_SEARCH"),
            "GEMINI_API": self.api_clients.get("GEMINI_API")
        }
        # Filtrer les clients None si l'API n'est pas configurée
        self.core_ai_engines = {k: v for k, v in self.core_ai_engines.items() if v is not None}

        # Définir les "agents mixtes" et leurs capacités (simplified for example)
        # En réalité, ceci serait un système de routing basé sur des modèles NLP plus complexes.
        self.mixed_agents = [
            {"name": "GeneralQueryAgent", "primary_ais": ["DEEPSEEK", "GEMINI_API", "GOOGLE_CUSTOM_SEARCH"], "tools": ["SERPER", "TAVILY", "WOLFRAMALPHA", "WEATHERAPI", "OPENWEATHERMAP"]},
            {"name": "CodingAgent", "primary_ais": ["DEEPSEEK", "HUGGINGFACE", "GEMINI_API"], "tools": []}, # Tools are sandbox/analyzer
            {"name": "SecurityAgent", "primary_ais": ["DEEPSEEK", "GEMINI_API"], "tools": ["IP2LOCATION", "SHODAN", "GREYNOISE", "PULSEDIVE", "CLOUDMERSIVE"]},
            {"name": "DataAgent", "primary_ais": ["DEEPSEEK", "GEMINI_API"], "tools": ["JSONBIN", "MOCKAROO", "RANDOMMER", "OPENPAGERANK", "RAPIDAPI"]},
            {"name": "CommunicationAgent", "primary_ais": ["DEEPSEEK", "GEMINI_API"], "tools": ["TWILIO", "ABSTRACTAPI"]},
            {"name": "NewsAgent", "primary_ais": ["DEEPSEEK", "GEMINI_API"], "tools": ["GUARDIAN", "SERPER", "TAVILY"]},
            {"name": "ImageAgent", "primary_ais": ["DEEPSEEK", "GEMINI_API"], "tools": ["APIFLASH"]}, # OCR tool is separate
            {"name": "LanguageAgent", "primary_ais": ["DEEPSEEK", "GEMINI_API"], "tools": ["DETECTLANGUAGE"]},
            {"name": "WeatherAgent", "primary_ais": ["DEEPSEEK", "GEMINI_API"], "tools": ["WEATHERAPI", "STORMGLASS", "TOMORROW.IO", "OPENWEATHERMAP"]}
        ]
        self.current_agent_index = 0
        self.last_agent_rotation_time = get_current_time()

        # Tool descriptions for AI
        self.tool_descriptions = {
            "SERPER": "Effectue une recherche web sur Google et retourne les snippets et liens pertinents. Paramètres: {\"query\": \"texte de recherche\"}",
            "TAVILY": "Effectue une recherche web avancée et retourne une réponse directe et des extraits. Paramètres: {\"query\": \"texte de recherche\", \"max_results\": nombre}",
            "WOLFRAMALPHA": "Répond à des questions factuelles et calculs complexes. Paramètres: {\"input\": \"question ou calcul\"}",
            "WEATHERAPI": "Fournit la météo actuelle et les prévisions pour une localisation donnée. Paramètres: {\"location\": \"nom de la ville ou code postal\"}",
            "OPENWEATHERMAP": "Fournit la météo actuelle pour une localisation donnée. Paramètres: {\"location\": \"nom de la ville ou code postal\"}",
            "STORMGLASS": "Fournit des données météorologiques maritimes (température, vagues) pour des coordonnées lat/lng. Paramètres: {\"lat\": latitude, \"lng\": longitude, \"params\": \"airTemperature,waveHeight\"}",
            "APIFLASH": "Prend une capture d'écran d'une URL et retourne l'URL de l'image. Paramètres: {\"url\": \"URL du site\"}",
            "CRAWLBASE": "Récupère le contenu HTML ou JavaScript d'une URL. Paramètres: {\"url\": \"URL du site\", \"use_js\": true/false}",
            "DETECTLANGUAGE": "Détecte la langue d'un texte. Paramètres: {\"text\": \"texte à analyser\"}",
            "IP2LOCATION": "Géolocalise une adresse IP. Paramètres: {\"ip_address\": \"adresse IP\"}",
            "SHODAN": "Fournit des informations sur les hôtes et les services exposés sur Internet. Paramètres: {\"query\": \"texte de recherche\"} (optionnel)",
            "GREYNOISE": "Analyse une adresse IP pour déterminer si elle est 'bruit' (malveillante). Paramètres: {\"ip_address\": \"adresse IP\"}",
            "PULSEDIVE": "Analyse des indicateurs de menace (IP, domaine, URL). Paramètres: {\"indicator\": \"indicateur\", \"type\": \"auto\"}",
            "CLOUDMERSIVE": "Vérifie la validité d'un nom de domaine. Paramètres: {\"domain\": \"nom de domaine\"}",
            "JSONBIN": "Stocke ou récupère des données JSON dans un 'bin' privé ou public. Pour créer: {\"data\": {\"clé\": \"valeur\"}, \"private\": true/false}. Pour accéder: {\"bin_id\": \"ID du bin\"}",
            "MOCKAROO": "Génère des données de test aléatoires basées sur des schémas. Paramètres: {\"count\": nombre, \"fields_json\": \"[{\"name\": \"champ\", \"type\": \"Type Mockaroo\"}]\"}",
            "RANDOMMER": "Génère des données aléatoires, comme des numéros de téléphone. Paramètres: {\"country_code\": \"US\", \"quantity\": 1}",
            "OPENPAGERANK": "Récupère le PageRank d'un ou plusieurs domaines. Paramètres: {\"domains\": [\"domaine1.com\", \"domaine2.com\"]}",
            "RAPIDAPI": "Accède à diverses micro-APIs (blagues, faits, devises). Nécessite un 'api_name' (ex: 'Programming Joke'). Paramètres: {\"api_name\": \"Nom de l'API\", \"kwargs\": {\"param1\": \"valeur1\"}}",
            "TWILIO": "Vérifie le solde du compte Twilio. Paramètres: Aucun",
            "ABSTRACTAPI": "Valide des emails, numéros de téléphone, géolocalise des IPs, ou fournit des taux de change/jours fériés. Paramètres: {\"input_value\": \"valeur\", \"api_type\": \"EMAIL_VALIDATION\"|\"PHONE_VALIDATION\"|\"EXCHANGE_RATES\"|\"HOLIDAYS\"}"
        }

    def _determine_initial_strategy(self) -> str:
        """Détermine la stratégie initiale ou la stratégie par défaut."""
        return "balanced"

    def _rotate_strategy_if_needed(self):
        """Change la stratégie d'IA et l'agent si l'intervalle de rotation est passé."""
        now = get_current_time()
        if (now - self.last_strategy_rotation_time).total_seconds() >= API_ROTATION_INTERVAL_MINUTES * 60:
            strategies = ["balanced", "cost_effective", "performance"]
            self.current_ia_strategy = random.choice(strategies)
            self.last_strategy_rotation_time = now
            log_message(f"Stratégie d'IA changée pour: {self.current_ia_strategy}")

            # Rotation des agents mixtes
            self.current_agent_index = (self.current_agent_index + 1) % len(self.mixed_agents)
            self.last_agent_rotation_time = now
            log_message(f"Agent mixte actuel: {self.mixed_agents[self.current_agent_index]['name']}")

            # Mettre à jour le last_rotation_check pour toutes les IA et récupérer les scores de diversification
            for ia_name in self.memory_manager.ia_status:
                self.memory_manager.ia_status[ia_name]["last_rotation_check"] = format_datetime(now)
            self.memory_manager.recover_diversification_scores() # Recover diversification scores
            save_json(IA_STATUS_FILE, self.memory_manager.ia_status)

    async def _select_primary_ai_for_agent(self, agent_config: Dict) -> Optional[APIClient]:
        """
        Sélectionne une IA primaire parmi celles de l'agent.
        La sélection est désormais équitable, sans privilégier une IA par rapport à une autre en fonction des scores.
        """
        available_primary_ais = []
        for ai_name in agent_config["primary_ais"]:
            if ai_name in self.core_ai_engines:
                status = self.memory_manager.get_ia_status(ai_name)
                # Vérifier si l'IA n'est pas en cooldown
                if status and (status.get("cooldown_until") is None or datetime.strptime(status["cooldown_until"], "%Y-%m-%d %H:%M:%S UTC").replace(tzinfo=None) < get_current_time()):
                    # Vérifier le quota sans le consommer pour la sélection
                    # Utiliser cost=0 pour juste vérifier la disponibilité sans impacter le quota
                    if self.quota_manager.check_and_update_quota(ai_name, cost=0):
                        available_primary_ais.append(ai_name)
        
        if not available_primary_ais:
            log_message(f"Aucune IA primaire disponible pour l'agent {agent_config['name']}.", level="warning")
            return None

        # Sélection aléatoire et équitable parmi les IA disponibles
        selected_ai_name = random.choice(available_primary_ais)
        
        # Consommer le quota pour l'IA sélectionnée (coût réel de 1)
        if self.quota_manager.check_and_update_quota(selected_ai_name, cost=1):
            log_message(f"IA primaire sélectionnée pour l'agent: {selected_ai_name} (Sélection équitable)")
            return self.core_ai_engines[selected_ai_name]
        
        # Ce cas ne devrait pas arriver souvent si le check_and_update_quota(cost=0) a réussi
        # mais c'est une sécurité.
        log_message(f"IA {selected_ai_name} sélectionnée mais quota non disponible au moment de la consommation.", level="warning")
        return None


    async def _run_agent_with_tools(self, agent_config: Dict, query: str) -> (str, List[Dict]):
        """
        Exécute l'agent mixte en utilisant l'IA primaire sélectionnée
        et en sollicitant les outils pertinents.
        Retourne la réponse brute de l'agent et une liste des outils appelés pour le rapport.
        """
        primary_ai_client = await self._select_primary_ai_for_agent(agent_config)
        if not primary_ai_client:
            return f"Désolé, l'agent {agent_config['name']} ne peut pas opérer car aucune IA primaire n'est disponible.", []

        responses = []
        tools_called_for_report = []
        
        # Prepare tool descriptions for the AI
        available_tools_for_ai = {}
        for tool_name in agent_config.get("tools", []):
            if tool_name in self.tool_descriptions and self.api_clients.get(tool_name):
                available_tools_for_ai[tool_name] = self.tool_descriptions[tool_name]
        
        tool_prompt_part = ""
        if available_tools_for_ai:
            tool_prompt_part = "\n\nTu as accès aux outils suivants:\n"
            for tool_name, desc in available_tools_for_ai.items():
                tool_prompt_part += f"- **{tool_name}**: {desc}\n"
            tool_prompt_part += "\nSi tu as besoin d'utiliser un outil, réponds avec le format suivant: `TOOL_CALL:<nom_outil>:<paramètres_json>`. Par exemple: `TOOL_CALL:WEATHERAPI:{\"location\": \"Paris\"}`. Sinon, réponds normalement."
        
        full_prompt_for_ai = f"{query}{tool_prompt_part}"

        # 1. Obtenir une première réponse de l'IA primaire
        log_message(f"Agent {agent_config['name']} utilise {primary_ai_client.name} pour la requête: '{query}'")
        primary_response_raw = await primary_ai_client.query(full_prompt_for_ai)
        self.memory_manager.update_ia_status(primary_ai_client.name, not primary_response_raw.startswith("Erreur"))
        
        # Check for tool calls in the primary AI's response
        tool_call_match = re.match(r"TOOL_CALL:([A-Z_]+):(.+)", primary_response_raw)
        if tool_call_match:
            tool_name = tool_call_match.group(1)
            params_str = tool_call_match.group(2)
            
            try:
                tool_params = json.loads(params_str)
                tool_client = self.api_clients.get(tool_name)
                
                if tool_client and self.quota_manager.check_and_update_quota(tool_name):
                    log_message(f"Agent {agent_config['name']} exécute l'outil {tool_name} avec les paramètres: {tool_params}")
                    
                    tool_response = ""
                    # Dynamic tool call based on tool_name and parsed params
                    # This requires careful mapping of tool_params to actual method arguments
                    if tool_name == "SERPER":
                        tool_response = await tool_client.query(query_text=tool_params.get("query"))
                    elif tool_name == "TAVILY":
                        tool_response = await tool_client.query(query_text=tool_params.get("query"), max_results=tool_params.get("max_results", 3))
                    elif tool_name == "WOLFRAMALPHA":
                        tool_response = await tool_client.query(input_text=tool_params.get("input"))
                    elif tool_name == "WEATHERAPI":
                        tool_response = await tool_client.query(location=tool_params.get("location"))
                    elif tool_name == "OPENWEATHERMAP":
                        tool_response = await tool_client.query(location=tool_params.get("location"))
                    elif tool_name == "STORMGLASS":
                        tool_response = await tool_client.query(lat=tool_params.get("lat"), lng=tool_params.get("lng"), params=tool_params.get("params", "airTemperature,waveHeight"))
                    elif tool_name == "APIFLASH":
                        tool_response = await tool_client.query(url=tool_params.get("url"))
                    elif tool_name == "CRAWLBASE":
                        tool_response = await tool_client.query(url=tool_params.get("url"), use_js=tool_params.get("use_js", False))
                    elif tool_name == "DETECTLANGUAGE":
                        tool_response = await tool_client.query(text=tool_params.get("text"))
                    elif tool_name == "IP2LOCATION":
                        tool_response = await tool_client.query(ip_address=tool_params.get("ip_address"))
                    elif tool_name == "SHODAN":
                        tool_response = await tool_client.query(query_text=tool_params.get("query", ""))
                    elif tool_name == "GREYNOISE":
                        tool_response = await tool_client.query(ip_address=tool_params.get("ip_address"))
                    elif tool_name == "PULSEDIVE":
                        tool_response = await tool_client.query(indicator=tool_params.get("indicator"), type=tool_params.get("type", "auto"))
                    elif tool_name == "CLOUDMERSIVE":
                        tool_response = await tool_client.query(domain=tool_params.get("domain"))
                    elif tool_name == "JSONBIN":
                        if "bin_id" in tool_params:
                            tool_response = await tool_client.query(bin_id=tool_params["bin_id"])
                        else:
                            tool_response = await tool_client.query(data=tool_params.get("data", {}), private=tool_params.get("private", True))
                    elif tool_name == "MOCKAROO":
                        tool_response = await tool_client.query(count=tool_params.get("count", 1), fields_json=tool_params.get("fields_json"))
                    elif tool_name == "RANDOMMER":
                        tool_response = await tool_client.query(country_code=tool_params.get("country_code", "US"), quantity=tool_params.get("quantity", 1))
                    elif tool_name == "OPENPAGERANK":
                        tool_response = await tool_client.query(domains=tool_params.get("domains", []))
                    elif tool_name == "RAPIDAPI":
                        tool_response = await tool_client.query(api_name=tool_params.get("api_name"), **tool_params.get("kwargs", {}))
                    elif tool_name == "TWILIO":
                        tool_response = await tool_client.query()
                    elif tool_name == "ABSTRACTAPI":
                        tool_response = await tool_client.query(input_value=tool_params.get("input_value"), api_type=tool_params.get("api_type"))
                    elif tool_name == "TOMORROW.IO":
                        tool_response = await tool_client.query(location=tool_params.get("location"), fields=tool_params.get("fields"))
                    
                    if tool_response:
                        responses.append(f"Réponse outil ({tool_name}): {tool_response}")
                        tools_called_for_report.append({"name": tool_name, "params": tool_params, "result": tool_response})
                    self.memory_manager.update_ia_status(tool_name, not tool_response.startswith("Erreur"))
                    
                    # Feed tool response back to primary AI for final answer
                    follow_up_prompt = f"J'ai exécuté l'outil {tool_name} avec les paramètres {params_str}. Voici le résultat:\n{tool_response}\n\nMaintenant, réponds à la question originale: {query}"
                    final_ai_response = await primary_ai_client.query(follow_up_prompt)
                    self.memory_manager.update_ia_status(primary_ai_client.name, not final_ai_response.startswith("Erreur"))
                    responses.append(f"Réponse finale ({primary_ai_client.name}): {final_ai_response}")

                else:
                    responses.append(f"Erreur: L'outil {tool_name} n'est pas disponible ou le quota est dépassé.")
                    tools_called_for_report.append({"name": tool_name, "params": tool_params, "result": "Quota dépassé ou non disponible."})
            except json.JSONDecodeError:
                responses.append(f"Erreur: Paramètres JSON invalides pour l'outil {tool_name}: {params_str}")
                tools_called_for_report.append({"name": tool_name, "params": params_str, "result": "JSON invalide."})
            except Exception as e:
                responses.append(f"Erreur lors de l'exécution de l'outil {tool_name}: {e}")
                self.memory_manager.update_ia_status(tool_name, False, str(e))
                tools_called_for_report.append({"name": tool_name, "params": params_str, "result": f"Erreur: {e}"})
        else:
            # If no tool call, the primary AI's initial response is the main response
            responses.append(f"Réponse principale ({primary_ai_client.name}): {primary_response_raw}")
        
        return "\n\n".join(responses), tools_called_for_report


    async def process_query(self, query: str) -> (str, List[Dict]):
        """Traite une requête en sélectionnant un agent mixte et en obtenant une réponse."""
        self._rotate_strategy_if_needed() # Rotation de la stratégie et de l'agent

        # Sélectionner l'agent mixte actuel
        current_agent_config = self.mixed_agents[self.current_agent_index]
        log_message(f"Traitement de la requête avec l'agent: {current_agent_config['name']}")

        # Exécuter l'agent avec ses outils
        agent_raw_response, tools_called_for_report = await self._run_agent_with_tools(current_agent_config, query)
        
        # Synthèse Optimisée des Réponses
        # Vérifier si la réponse est simple ou si elle contient des marqueurs de multiples réponses/outils
        # A simple heuristic: if it contains "Réponse principale (" and not "Réponse outil ("
        # and there are no tools called, then it's likely a single, direct response.
        if "Réponse principale (" in agent_raw_response and not tools_called_for_report:
            log_message("Réponse unique et directe détectée, pas de synthèse nécessaire.")
            final_response = agent_raw_response.replace(f"Réponse principale ({primary_ai_client.name}): ", "") # Remove prefix
        else:
            log_message("Plusieurs réponses ou outils détectés, appel à la synthèse.")
            final_response = await self.synthesize_response(query, [agent_raw_response])

        return final_response, tools_called_for_report

    async def synthesize_response(self, question: str, responses: List[str]) -> str:
        """
        Synthétise les réponses de plusieurs IA en utilisant DeepSeek (le module d'optimisation).
        """
        if not responses:
            return "Je n'ai reçu aucune réponse des IA pour le moment."

        combined_responses = "\n\n".join([f"Réponse {i+1}:\n{r}" for i, r in enumerate(responses)])
        synthesis_prompt = SYNTHESIS_PROMPT_TEMPLATE.format(question=question, responses=combined_responses)

        deepseek_client = self.core_ai_engines.get("DEEPSEEK")
        if not deepseek_client:
            log_message("DeepSeek n'est pas disponible pour la synthèse.", level="warning")
            return "J'ai plusieurs réponses, mais je ne peux pas les synthétiser pour le moment. Voici les réponses brutes:\n\n" + combined_responses

        try:
            synthesis = await deepseek_client.query(synthesis_prompt)
            self.memory_manager.update_ia_status("DEEPSEEK", True) # Update DeepSeek status for synthesis
            return detect_and_correct_toxicity(synthesis)
        except Exception as e:
            log_message(f"Erreur lors de la synthèse avec DeepSeek: {e}", level="error")
            self.memory_manager.update_ia_status("DEEPSEEK", False, str(e))
            return "J'ai rencontré un problème lors de la synthèse des informations. Voici les réponses brutes:\n\n" + combined_responses

# Instancier l'orchestrateur
orchestrator = IAOrchestrator(memory_manager, quota_manager, ALL_API_CLIENTS)

# --- Tâche de fond pour les Health Checks des Endpoints (Wrapper pour JobQueue) ---
async def periodic_health_check_job(context: ContextTypes.DEFAULT_TYPE) -> None:
    """JobQueue wrapper pour les health checks périodiques."""
    log_message("Lancement des health checks périodiques via JobQueue pour tous les services...")
    for service_name in API_CONFIG.keys():
        await endpoint_health_manager.run_health_check_for_service(service_name)
    log_message("Health checks périodiques via JobQueue terminés.")

# --- Structured Reporting to Private Group ---
async def send_structured_report_to_private_group(context: ContextTypes.DEFAULT_TYPE, report_data: Dict) -> None:
    """Envoie un rapport structuré au groupe privé Telegram."""
    try:
        report_text = f"📊 **Rapport d'Action IA**\n\n"
        report_text += f"**Timestamp**: `{report_data.get('timestamp')}`\n"
        report_text += f"**Agent**: `{report_data.get('agent_name')}`\n"
        report_text += f"**Intention Détectée**: `{report_data.get('intention')}`\n"
        report_text += f"**Requête Utilisateur**: `{report_data.get('user_query')}`\n"
        
        # S'assurer que primary_ai_used est toujours une chaîne valide
        primary_ai_used_display = report_data.get('primary_ai_used', 'N/A')
        if isinstance(primary_ai_used_display, dict) and 'name' in primary_ai_used_display:
            primary_ai_used_display = primary_ai_used_display['name']
        report_text += f"**IA Primaire Utilisée**: `{primary_ai_used_display}`\n"
        
        tools_called = report_data.get('tools_called', [])
        if tools_called:
            report_text += "**Outils Appelés**:\n"
            for tool in tools_called:
                # Truncate tool result for report to avoid very long messages
                tool_result_display = str(tool['result'])
                if len(tool_result_display) > 100:
                    tool_result_display = tool_result_display[:100] + "..."
                report_text += f"- `{tool['name']}` (Params: `{tool['params']}`, Résultat: `{tool_result_display}`)\n"
        else:
            report_text += "**Outils Appelés**: Aucun\n"
        
        # Truncate final response for report
        final_response_display = report_data.get('final_response', '')
        if len(final_response_display) > 500:
            final_response_display = final_response_display[:500] + "..."
        report_text += f"**Réponse Finale**: `{final_response_display}`\n"
        report_text += f"**Durée Totale**: `{report_data.get('duration'):.2f}s`\n"
        report_text += f"**Erreur**: `{report_data.get('error', 'Non')}`\n"

        await context.bot.send_message(chat_id=PRIVATE_GROUP_ID, text=report_text, parse_mode='Markdown')
        log_message(f"Rapport structuré envoyé au groupe privé: {PRIVATE_GROUP_ID}")
    except Exception as e:
        log_message(f"Erreur lors de l'envoi du rapport structuré au groupe privé: {e}", level="error")

import time
from telegram import Update, ForceReply
from telegram.ext import Application, CommandHandler, MessageHandler, filters, ContextTypes

# --- Handlers de commandes Telegram ---

async def start(update: Update, context: ContextTypes.DEFAULT_TYPE) -> None:
    """Envoie un message lorsque la commande /start est émise."""
    user = update.effective_user
    await update.message.reply_html(
        f"Salut {user.mention_html()} ! Je suis ton assistant IA de 2025. "
        "Pose-moi une question, demande-moi d'écrire du code, ou de chercher des infos. "
        "Utilise /help pour voir ce que je peux faire.",
        reply_markup=ForceReply(selective=True),
    )
    log_message(f"Commande /start reçue de {user.id}")

async def help_command(update: Update, context: ContextTypes.DEFAULT_TYPE) -> None:
    """Envoie un message lorsque la commande /help est émise."""
    help_text = """
    Voici ce que je peux faire :
    - Pose-moi n'importe quelle question factuelle.
    - Demande-moi d'écrire ou d'améliorer du code (Python, Shell).
    - Cherche des informations sur le web (actualités, météo, géolocalisation IP, etc.).
    - Demande-moi de faire une capture d'écran d'un site web (donne l'URL).
    - Demande-moi d'analyser le contenu d'une page web (donne l'URL).
    - Demande-moi de détecter la langue d'un texte.
    - Demande-moi de valider un numéro de téléphone ou de géolocaliser une IP ou un email.
    - Gère tes rappels et alarmes (Ex: "Rappelle-moi d'acheter du lait à 18h", "Mets une alarme à 7h du matin").
    - Vérifie le statut de mes APIs avec /status.
    - Affiche mon historique de conversation avec /history.
    - Affiche le statut des quotas API avec /quotas.
    - Affiche les APIs où il est opportun de "brûler" le quota avec /burn_quota.

    Exemples :
    - "Quelle est la capitale de la France ?"
    - "Écris un script Python pour trier une liste."
    - "Météo à Paris"
    - "Capture d'écran de https://google.com"
    - "Analyse de https://openai.com"
    - "Détecte la langue de 'Hello world'"
    - "Valide le numéro +33612345678"
    - "Géolocalise l'IP 8.8.8.8"
    - "Valide l'email test@example.com"
    - "Rappelle-moi de faire les courses demain à 10h"
    - "Mets une alarme pour 7h du matin"
    """
    await update.message.reply_text(help_text)
    log_message(f"Commande /help reçue de {update.effective_user.id}")

async def status_command(update: Update, context: ContextTypes.DEFAULT_TYPE) -> None:
    """Affiche le statut et les scores des IA."""
    status_message = "📊 **Statut des IA**:\n"
    now = get_current_time()
    for ia_name, status in memory_manager.ia_status.items():
        cooldown_until_str = status.get("cooldown_until")
        cooldown_status = "Prête"
        if cooldown_until_str:
            cooldown_until = datetime.strptime(cooldown_until_str, "%Y-%m-%d %H:%M:%S UTC").replace(tzinfo=None)
            if now < cooldown_until:
                remaining = cooldown_until - now
                cooldown_status = f"Cooldown ({remaining.total_seconds():.0f}s restantes)"
        
        last_used_str = status.get("last_used", "Jamais")
        if last_used_str != "Jamais":
            last_used_dt = datetime.strptime(last_used_str, "%Y-%m-%d %H:%M:%S UTC").replace(tzinfo=None)
            time_since_last_used = (now - last_used_dt).total_seconds()
            if time_since_last_used < 60:
                last_used_display = f"{time_since_last_used:.0f}s ago"
            elif time_since_last_used < 3600:
                last_used_display = f"{time_since_last_used / 60:.0f}m ago"
            else:
                last_used_display = f"{time_since_last_used / 3600:.1f}h ago"
        else:
            last_used_display = "Jamais"

        status_message += (
            f"- **{ia_name}**: Score: `{status['current_score']:.2f}`, Diversification: `{status['diversification_score']:.2f}`, "
            f"Succès: `{status['success_count']}`, Erreurs: `{status['error_count']}`, "
            f"Statut: `{cooldown_status}`, Dernière utilisation: `{last_used_display}`\n"
        )
    status_message += f"\nStratégie actuelle: `{orchestrator.current_ia_strategy}`"
    status_message += f"\nAgent mixte actuel: `{orchestrator.mixed_agents[orchestrator.current_agent_index]['name']}`"
    await update.message.reply_markdown(status_message)
    log_message(f"Commande /status reçue de {update.effective_user.id}")

async def history_command(update: Update, context: ContextTypes.DEFAULT_TYPE) -> None:
    """Affiche les 10 derniers messages de l'historique."""
    history = memory_manager.get_chat_history()
    if not history:
        await update.message.reply_text("L'historique de conversation est vide.")
        return

    history_text = "📜 **Historique des 10 dernières interactions**:\n\n"
    for entry in history:
        history_text += f"**{entry['role'].capitalize()}** ({entry['timestamp']}):\n{entry['content'][:150]}...\n\n"
    await update.message.reply_markdown(history_text)
    log_message(f"Commande /history reçue de {update.effective_user.id}")

async def quotas_command(update: Update, context: ContextTypes.DEFAULT_TYPE) -> None:
    """Affiche le statut actuel des quotas API."""
    quotas_status = quota_manager.get_all_quotas_status()
    message = "📈 **Statut des Quotas API**:\n\n"
    for api_name, data in quotas_status.items():
        message += (
            f"**{api_name}**:\n"
            f"  - Mensuel: `{data['monthly_usage']}` / `{data['monthly_limit']}`\n"
            f"  - Journalier: `{data['daily_usage']}` / `{data['daily_limit']}`\n"
            f"  - Horaire: `{data['hourly_usage']}` / `{data['hourly_limit']}`\n"
            f"  - Total appels: `{data['total_calls']}`\n"
            f"  - Dernière utilisation: `{data['last_usage'] if data['last_usage'] else 'N/A'}`\n"
            f"  - Reset Mensuel: `{data['last_reset_month']}`\n"
            f"  - Reset Journalier: `{data['last_reset_day']}`\n"
            f"  - Reset Horaire: `{data['last_hourly_reset']}`\n\n"
        )
    await update.message.reply_markdown(message)
    log_message(f"Commande /quotas reçue de {update.effective_user.id}")

async def burn_quota_command(update: Update, context: ContextTypes.DEFAULT_TYPE) -> None:
    """Affiche les APIs où il est opportun de "brûler" le quota."""
    burn_apis = quota_manager.get_burn_window_apis()
    if burn_apis:
        message = "🔥 **APIs où il est opportun de 'brûler' le quota avant réinitialisation**:\n\n"
        for api_info in burn_apis:
            message += f"- {api_info}\n"
        message += f"\nFenêtre de brûlage: {QUOTA_BURN_WINDOW_HOURS} heures avant le reset."
    else:
        message = "🎉 Aucune API n'est actuellement dans une fenêtre de 'brûlage' de quota. Tout est optimisé !"
    await update.message.reply_markdown(message)
    log_message(f"Commande /burn_quota reçue de {update.effective_user.id}")

async def detect_intent(query: str) -> str:
    """
    Détecte l'intention de l'utilisateur en utilisant une IA primaire disponible
    (DeepSeek, Gemini, etc.) de manière équitable.
    """
    prompt = f"Classe la requête suivante dans une des catégories suivantes: 'programmation', 'image', 'météo', 'langue', 'recherche', 'sécurité', 'données', 'communication', 'actualités', 'général'. Réponds uniquement avec le nom de la catégorie. Requête: '{query}'"
    
    # Sélectionner une IA primaire pour la détection d'intention
    # On itère sur les IA principales pour trouver la première disponible qui n'est pas en cooldown
    # et qui a du quota, en respectant l'équité.
    available_intent_ais = []
    for ai_name in orchestrator.core_ai_engines:
        ai_client = orchestrator.core_ai_engines[ai_name]
        status = memory_manager.get_ia_status(ai_name)
        if ai_client and status and (status.get("cooldown_until") is None or datetime.strptime(status["cooldown_until"], "%Y-%m-%d %H:%M:%S UTC").replace(tzinfo=None) < get_current_time()):
            if quota_manager.check_and_update_quota(ai_name, cost=0): # Check quota without consuming
                available_intent_ais.append(ai_name)
    
    if not available_intent_ais:
        log_message("Aucune IA principale disponible pour la détection d'intention. Retourne 'général'.", level="warning")
        return "général"

    # Choisir une IA aléatoirement parmi celles disponibles pour l'équité
    selected_ai_for_intent = random.choice(available_intent_ais)
    intent_ai_client = orchestrator.core_ai_engines[selected_ai_for_intent]

    # Consommer le quota pour l'IA sélectionnée
    if not quota_manager.check_and_update_quota(selected_ai_for_intent, cost=1): # Consume 1 unit for intent detection
        log_message(f"Quota dépassé pour {selected_ai_for_intent} lors de la détection d'intention. Retourne 'général'.", level="warning")
        return "général"

    try:
        response = await intent_ai_client.query(prompt)
        # Clean up response to get just the category name
        category = response.strip().lower().replace('.', '').replace('catégorie: ', '')
        if category in ['programmation', 'image', 'météo', 'langue', 'recherche', 'sécurité', 'données', 'communication', 'actualités', 'général']:
            return category
        return "général" # Fallback
    except Exception as e:
        log_message(f"Erreur lors de la détection d'intention avec {selected_ai_for_intent}: {e}", level="error")
        memory_manager.update_ia_status(selected_ai_for_intent, False, str(e))
        return "général" # Fallback if AI fails


# --- Gestionnaire de messages (le cœur du bot) ---

async def handle_message(update: Update, context: ContextTypes.DEFAULT_TYPE) -> None:
    """Traite les messages texte de l'utilisateur."""
    user_message = update.message.text
    user_id = update.effective_user.id
    log_message(f"Message reçu de {user_id}: {user_message}")

    memory_manager.add_message_to_history("user", user_message)

    response_text = ""
    start_processing_time = time.monotonic()
    
    # Intention Detection
    detected_intention = await detect_intent(user_message)
    log_message(f"Intention détectée pour '{user_message}': {detected_intention}")

    tools_called_report = []
    error_occurred = False

    try:
        # Détection d'intentions spécifiques (prioritaires sur l'orchestrateur général)
        if any(keyword in user_message.lower() for keyword in ["alarme", "réveil", "timer", "minuteur", "rappelle-moi", "rappel", "reminder"]):
            log_message("Intention détectée: Alarme/Rappel (Simulé).")
            response_text = "Je peux t'aider avec les alarmes, minuteurs et rappels ! Dis-moi par exemple : 'Mets une alarme à 7h du matin' ou 'Rappelle-moi d'acheter du lait à 18h'."
            await context.bot.send_message(chat_id=update.effective_chat.id, text="Message reçu. Mission comprise.")
        elif "```python" in user_message or "```shell" in user_message or "exécute ce code" in user_message.lower() or "teste ce script" in user_message.lower():
            log_message("Intention détectée: Exécution de code.")
            await context.bot.send_message(chat_id=update.effective_chat.id, text="Message reçu. Mission comprise.")
            lang_match = re.search(r"```(python|shell)\n(.*?)```", user_message, re.DOTALL)
            if lang_match:
                language = lang_match.group(1)
                code = lang_match.group(2)
                response_text = await run_in_sandbox(code, language)
            else:
                response_text = "Veuillez formater votre code avec des triple backticks et spécifier le langage (ex: ```python\\nprint('Hello')``` ou ```shell\\nls -l```)."
        elif "analyse ce code python" in user_message.lower() or "vérifie ce script python" in user_message.lower():
            log_message("Intention détectée: Analyse de code Python.")
            await context.bot.send_message(chat_id=update.effective_chat.id, text="Message reçu. Mission comprise.")
            code_match = re.search(r"```python\n(.*?)```", user_message, re.DOTALL)
            if code_match:
                code = code_match.group(1)
                response_text = await analyze_python_code(code)
            else:
                response_text = "Veuillez fournir le code Python à analyser formaté avec ```python\\n...```."
        elif "extraire texte image" in user_message.lower() or "ocr" in user_message.lower() or "lis cette image" in user_message.lower():
            log_message("Intention détectée: OCR.")
            await context.bot.send_message(chat_id=update.effective_chat.id, text="Message reçu. Mission comprise.")
            url_match = re.search(r'https?://[^\s]+(?:\.jpg|\.jpeg|\.png|\.gif|\.bmp|\.tiff)', user_message, re.IGNORECASE)
            if url_match:
                image_url = url_match.group(0)
                # For OCR, we'll try to use Cloudmersive if a key is available for OCR
                # The provided Cloudmersive config is for Domain Check, not OCR.
                # If an OCR endpoint was configured, it would be called here.
                # For now, we'll return a message indicating no direct OCR API.
                response_text = "Désolé, je n'ai pas d'API OCR directement configurée pour le moment. Mon client Cloudmersive est pour la validation de domaine."
            else:
                response_text = "Veuillez fournir une URL d'image valide (jpg, png, etc.) pour l'extraction de texte."
        else:
            log_message("Intention générale, utilisation de l'orchestrateur d'IA.")
            await context.bot.send_message(chat_id=update.effective_chat.id, text="Message reçu. Mission comprise.")
            response_text, tools_called_report = await orchestrator.process_query(user_message)

    except Exception as e:
        log_message(f"Erreur majeure lors du traitement du message: {e}", level="error")
        response_text = f"Désolé, une erreur inattendue est survenue: {e}"
        error_occurred = True

    final_response = clean_html_tags(response_text)
    final_response = neutralize_urls(final_response)
    final_response = detect_and_correct_toxicity(final_response)

    await update.message.reply_text(final_response)
    memory_manager.add_message_to_history("assistant", final_response)
    log_message(f"Réponse envoyée à {user_id}.")

    # Send structured report to private group
    end_processing_time = time.monotonic()
    processing_duration = end_processing_time - start_processing_time

    # Get the primary AI used by the current agent for the report
    primary_ai_used_in_report = "N/A"
    current_agent_config = orchestrator.mixed_agents[orchestrator.current_agent_index]
    if current_agent_config['primary_ais']:
        # This is a simplification; in a real scenario, you'd track which primary AI was actually selected for the main query.
        # For now, we'll just pick the first one from the agent's config.
        primary_ai_used_in_report = current_agent_config['primary_ais'][0]


    report_data = {
        "timestamp": format_datetime(get_current_time()),
        "agent_name": current_agent_config['name'],
        "intention": detected_intention,
        "user_query": user_message,
        "primary_ai_used": primary_ai_used_in_report, 
        "tools_called": tools_called_report,
        "final_response": final_response,
        "duration": processing_duration,
        "error": "Oui" if error_occurred else "Non"
    }
    await send_structured_report_to_private_group(context, report_data)


# --- Fonction principale pour démarrer le bot ---

def main() -> None:
    """Démarre le bot."""
    log_message("Démarrage du bot Telegram...")
    application = Application.builder().token(TELEGRAM_BOT_TOKEN).build()

    application.add_handler(CommandHandler("start", start))
    application.add_handler(CommandHandler("help", help_command))
    application.add_handler(CommandHandler("status", status_command))
    application.add_handler(CommandHandler("history", history_command))
    application.add_handler(CommandHandler("quotas", quotas_command))
    application.add_handler(CommandHandler("burn_quota", burn_quota_command))

    application.add_handler(MessageHandler(filters.TEXT & ~filters.COMMAND, handle_message))

    # Démarrer la tâche de fond pour les health checks via JobQueue
    # 'first=10' signifie que le premier check aura lieu 10 secondes après le démarrage.
    # 'interval=300' signifie que les checks suivants auront lieu toutes les 300 secondes (5 minutes).
    application.job_queue.run_repeating(periodic_health_check_job, interval=300, first=10)

    log_message("Bot prêt à recevoir des messages.")
    # Utilisez run_polling pour gérer la boucle d'événements
    application.run_polling(allowed_updates=Update.ALL_TYPES)

if __name__ == "__main__":
    # Assurez-vous que le répertoire des archives existe
    os.makedirs(ARCHIVES_DIR, exist_ok=True)
    try:
        main()
    except KeyboardInterrupt:
        # Gère l'interruption par l'utilisateur (Ctrl+C) pour un arrêt propre.
        logging.info("Bot arrêté par l'utilisateur (Ctrl+C).")
    except Exception as e:
        # Capture et log toute autre erreur fatale au démarrage du bot.
        logging.error(f"Erreur fatale lors du démarrage du bot: {e}", exc_info=True)
        print(f"Une erreur est survenue au démarrage du bot: {e}")

# --- FIN DU FICHIER PRINCIPAL ---


# --- DEBUT DU FICHIER PRINCIPAL ---

import os
import json
import asyncio
import httpx
import logging
import re
import random
import io
import contextlib
import ast
import subprocess
from datetime import datetime, timedelta
from concurrent.futures import ThreadPoolExecutor
from typing import Dict, Any, Optional, Union, List

# Import nécessaire pour StormGlassClient
import time

# --- Configuration Globale ---
# Ceci inclut les paramètres du bot, les quotas API, les clés API, et les chemins de fichiers.

# --- Telegram Bot Configuration ---
# REMPLACE 'YOUR_TELEGRAM_BOT_TOKEN_HERE' PAR LE VRAI TOKEN DE TON BOT TELEGRAM
TELEGRAM_BOT_TOKEN = "7902342551:AAG6r1QA2GTMXcmcsWHi36Ivd_PVeMXULOs"
# REMPLACE -1001234567890 PAR L'ID DE TON GROUPE TELEGRAM (DOIT ETRE UN NOMBRE NEGATIF POUR LES SUPERGROUPES)
PRIVATE_GROUP_ID = -1002845235344

# --- Quotas API (Estimations si non documentées, basé sur tes infos) ---
# Si un quota est par service et non par clé, la limite sera appliquée globalement pour ce service
API_QUOTAS = {
    "APIFLASH": {"monthly": 100, "daily": 3, "hourly": 3},
    "DEEPSEEK": {"monthly": None, "hourly": 50},
    "CRAWLBASE": {"monthly": 1000, "daily": 33, "hourly": 1},
    "DETECTLANGUAGE": {"daily": 1000, "hourly": 41},
    "GUARDIAN": {"daily": 5000, "rate_limit_per_sec": 12},
    "IP2LOCATION": {"monthly": 50, "daily": 2, "hourly": 2},
    "SERPER": {"monthly": 2500, "daily": 83, "hourly": 3},
    "SHODAN": {"monthly": 100, "daily": 3, "hourly": 3},
    "TAVILY": {"monthly": 1000, "daily": 33, "hourly": 1},
    "WEATHERAPI": {"monthly": None},
    "WOLFRAMALPHA": {"monthly": None, "hourly": 67},
    "CLOUDMERSIVE": {"monthly": 25, "daily": 1, "hourly": 1},
    "GREYNOISE": {"monthly": 100, "daily": 3, "hourly": 3},
    "PULSEDIVE": {"monthly": 50, "daily": 2, "hourly": 2},
    "STORMGLASS": {"monthly": None},
    "LOGINRADIUS": {"monthly": 25000, "daily": 833, "hourly": 34},
    "JSONBIN": {"monthly": 10000, "daily": 333, "hourly": 13},
    "HUGGINGFACE": {"hourly": 100},
    "TWILIO": {"monthly": 15}, # Crédit d'essai en USD (estimation)
    "ABSTRACTAPI": {"monthly": 250, "rate_limit_per_sec": 1, "daily": 8, "hourly": 1},
    "MOCKAROO": {"monthly": 200, "daily": 7, "hourly": 1},
    "OPENPAGERANK": {"monthly": 1000, "daily": 33, "hourly": 1},
    "RAPIDAPI": {"monthly": None, "hourly": 30},
    "GEMINI_API": {"monthly": None, "hourly": 50},
    "GOOGLE_CUSTOM_SEARCH": {"daily": 100, "hourly": 4},
    "OPENROUTER": {"monthly": None, "hourly": 30},
    "RANDOMMER": {"monthly": 1000, "daily": 100, "hourly": 4},
    "TOMORROW.IO": {"monthly": None},
    "OPENWEATHERMAP": {"monthly": 1000000, "daily": 100, "hourly": 4},
}

# --- Clés API Individuelles (centralisées pour la clarté) ---
APIFLASH_KEY = "3a3cc886a18e41109e0cebc0745b12de"
DEEPSEEK_KEY_1 = "sk-ef08317d125947b3a1ce5916592bef00"
DEEPSEEK_KEY_2 = "sk-d73750d96142421cb1098c7056dd7f01"
CRAWLBASE_KEY_1 = "x41P6KNU8J86yF9JV1nqSw"
CRAWLBASE_KEY_2 = "FOg3R0v_aLxzHkYIdhPgVg"
DETECTLANGUAGE_KEY = "ebdc8ccc2ee75eda3ab122b08ffb1e8d"
GUARDIAN_KEY = "07c622c1-af05-4c24-9f37-37d219be76a0"
IP2LOCATION_KEY = "11103C239EA8EA6DF2473BB445EC32F2"
SERPER_KEY = "047b30db1df999aaa9c293f2048037d40c651439"
SHODAN_KEY = "umdSaWOfVq9Wt2F4wWdXiKh1zjLailzn"
TAVILY_KEY_1 = "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"
TAVILY_KEY_2 = "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"
TAVILY_KEY_3 = "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"
TAVILY_KEY_4 = "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"
WEATHERAPI_KEY = "332bcdba457d4db4836175513250407"
WOLFRAM_APP_ID_1 = "96LX77-G8PGKJ3T7V"
WOLFRAM_APP_ID_2 = "96LX77-PYHRRET363"
WOLFRAM_APP_ID_3 = "96LX77-P9HPAYWRGL"
GREYNOISE_KEY = "5zNe9E6c5UNDhU09iVXbMaB04UpHAw5hNm5rHCK24fCLvI2cP33NNOpL7nhkDETG"
LOGINRADIUS_KEY = "073b2fbedf82409da2ca6f37b97e8c6a"
JSONBIN_KEY = "$2a$10$npWSB7v1YcoqLkyPpz0PZOVtES5vBs6JtTWVyVDXK3j6FDxYS5BPO"
HUGGINGFACE_KEY_1 = "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"
HUGGINGFACE_KEY_2 = "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"
HUGGINGFACE_KEY_3 = "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"
HUGGINGFACE_NEW_KEY = "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" # This key was explicitly called out as NEW
TWILIO_SID = "SK84cc4d335650f9da168cd779f26e00e5"
TWILIO_SECRET = "spvz5uwPE8ANYOI5Te4Mehm7YwKOZ4Lg"
ABSTRACTAPI_EMAIL_KEY_1 = "2ffd537411ad407e9c9a7eacb7a97311"
ABSTRACTAPI_EMAIL_KEY_2 = "5b00ade4e60e4a388bd3e749f4f66e28"
ABSTRACTAPI_EMAIL_KEY_3 = "f4106df7b93e4db6855cb7949edc4a20"
ABSTRACTAPI_GENERIC_KEY = "020a4dcd3e854ac0b19043491d79df92"
GEMINI_API_KEY = "AIzaSyABnzGG2YoTNY0uep-akgX1rfuvAsp049Q"
GOOGLE_API_KEYS = [
    "AIzaSyAk6Ph25xuIY3b5o-JgdL652MvK4usp8Ms",
    "AIzaSyDuccmfiPSk4042NeJCYIjA8EOXPo1YKXU",
    "AIzaSyAQq6o9voefaDxkAEORf7W-IB3QbotIkwY",
    "AIzaSyDYaYrQQ7cwYFm8TBpyGM3dJweOGOYl7qw",
]
GOOGLE_CX_LIST = [
    "3368510e864b74936",
    "e745c9ca0ffb94659"
]
OPENROUTER_KEYS = [
    "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",
    "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",
    "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",
    "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",
    "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"
]
PULSEDIVE_KEY = "201bb09342f35d365889d7d0ca0fdf8580ebee0f1e7644ce70c99a46c1d47171"
RANDOMMER_KEY = "29d907df567b4226bf64b924f9e26c00"
STORMGLASS_KEY = "7ad5b888-5900-11f0-80b9-0242ac130006-7ad5b996-5900-11f0-80b9-0242ac130006"
TOMORROW_KEY = "bNh6KpmddRGY0dzwvmQugVtG4Uf5Y2w1"
CLOUDMERSIVE_KEY = "4d407015-ce22-45d7-a2e1-b88ab6380084" # Corrected key
OPENWEATHER_API_KEY = "c80075b7332716a418e47033463085ef"
MOCKAROO_KEY = "282b32d0"
OPENPAGERANK_KEY = "w848ws8s0848g4koosgooc0sg4ggogcggw4o4cko"
RAPIDAPI_KEY = "d4d1f58d8emsh58d888c711b7400p1bcebejsn2cc04dce6efe"

# --- Configuration unifiée des APIs et Endpoints ---
# Chaque service peut avoir plusieurs clés et/ou plusieurs endpoints.
# 'key_field' indique le nom du paramètre/header pour la clé.
# 'key_location' indique où la clé doit être placée ('param', 'header', 'auth_basic').
# 'key_prefix' est un préfixe optionnel (ex: "Bearer ").
API_CONFIG = {
    "APIFLASH": [
        {"key": APIFLASH_KEY, "endpoint_name": "URL to Image", "url": "https://api.apiflash.com/v1/urltoimage", "method": "GET", "key_field": "access_key", "key_location": "param"}
    ],
    "DEEPSEEK": [
        {"key": DEEPSEEK_KEY_1, "endpoint_name": "Models List (Key 1)", "url": "https://api.deepseek.com/v1/models", "method": "GET", "key_field": "Authorization", "key_location": "header", "key_prefix": "Bearer "},
        {"key": DEEPSEEK_KEY_2, "endpoint_name": "Models List (Key 2)", "url": "https://api.deepseek.com/v1/models", "method": "GET", "key_field": "Authorization", "key_location": "header", "key_prefix": "Bearer "},
        {"key": DEEPSEEK_KEY_1, "endpoint_name": "Chat Completions", "url": "https://api.deepseek.com/v1/chat/completions", "method": "POST", "key_field": "Authorization", "key_location": "header", "key_prefix": "Bearer ", "fixed_json": {"model": "deepseek-chat", "stream": False}}
    ],
    "CRAWLBASE": [
        {"key": CRAWLBASE_KEY_1, "endpoint_name": "HTML Scraping", "url": "https://api.crawlbase.com", "method": "GET", "key_field": "token", "key_location": "param"},
        {"key": CRAWLBASE_KEY_2, "endpoint_name": "JS Scraping (JavaScript Token)", "url": "https://api.crawlbase.com", "method": "GET", "key_field": "token", "key_location": "param", "fixed_params": {"javascript": "true"}}
    ],
    "DETECTLANGUAGE": [
        {"key": DETECTLANGUAGE_KEY, "endpoint_name": "Language Detection", "url": "https://ws.detectlanguage.com/0.2/detect", "method": "POST", "key_field": "Authorization", "key_location": "header", "key_prefix": "Bearer "}
    ],
    "GUARDIAN": [
        {"key": GUARDIAN_KEY, "endpoint_name": "News Search", "url": "https://content.guardianapis.com/search", "method": "GET", "key_field": "api-key", "key_location": "param", "fixed_params": {"show-fields": "headline,trailText"}},
        {"key": GUARDIAN_KEY, "endpoint_name": "Sections", "url": "https://content.guardianapis.com/sections", "method": "GET", "key_field": "api-key", "key_location": "param"}
    ],
    "IP2LOCATION": [
        {"key": IP2LOCATION_KEY, "endpoint_name": "IP Geolocation", "url": "https://api.ip2location.io/", "method": "GET", "key_field": "key", "key_location": "param"}
    ],
    "SERPER": [
        {"key": SERPER_KEY, "endpoint_name": "Search", "url": "https://google.serper.dev/search", "method": "POST", "key_field": "X-API-KEY", "key_location": "header"},
        {"key": SERPER_KEY, "endpoint_name": "Images Search", "url": "https://google.serper.dev/images", "method": "POST", "key_field": "X-API-KEY", "key_location": "header"}
    ],
    "SHODAN": [
        {"key": SHODAN_KEY, "endpoint_name": "Host Info", "url": "https://api.shodan.io/shodan/host/8.8.8.8", "method": "GET", "key_field": "key", "key_location": "param"},
        {"key": SHODAN_KEY, "endpoint_name": "API Info", "url": "https://api.shodan.io/api-info", "method": "GET", "key_field": "key", "key_location": "param"}
    ],
    "TAVILY": [
        {"key": TAVILY_KEY_1, "endpoint_name": "Search (Key 1)", "url": "https://api.tavily.com/search", "method": "POST", "key_field": "Authorization", "key_location": "header", "key_prefix": "Bearer ", "fixed_json": {"search_depth": "advanced", "include_answer": True}},
        {"key": TAVILY_KEY_2, "endpoint_name": "Search (Key 2)", "url": "https://api.tavily.com/search", "method": "POST", "key_field": "Authorization", "key_location": "header", "key_prefix": "Bearer ", "fixed_json": {"search_depth": "advanced", "include_answer": True}},
        {"key": TAVILY_KEY_3, "endpoint_name": "Search (Key 3)", "url": "https://api.tavily.com/search", "method": "POST", "key_field": "Authorization", "key_location": "header", "key_prefix": "Bearer ", "fixed_json": {"search_depth": "advanced", "include_answer": True}},
        {"key": TAVILY_KEY_4, "endpoint_name": "Search (Key 4)", "url": "https://api.tavily.com/search", "method": "POST", "key_field": "Authorization", "key_location": "header", "key_prefix": "Bearer ", "fixed_json": {"search_depth": "advanced", "include_answer": True}}
    ],
    "WEATHERAPI": [
        {"key": WEATHERAPI_KEY, "endpoint_name": "Current Weather", "url": "http://api.weatherapi.com/v1/current.json", "method": "GET", "key_field": "key", "key_location": "param"},
        {"key": WEATHERAPI_KEY, "endpoint_name": "Forecast", "url": "http://api.weatherapi.com/v1/forecast.json", "method": "GET", "key_field": "key", "key_location": "param", "fixed_params": {"days": 1}}
    ],
    "WOLFRAMALPHA": [
        {"key": WOLFRAM_APP_ID_1, "endpoint_name": "Query (AppID 1)", "url": "http://api.wolframalpha.com/v2/query", "method": "GET", "key_field": "appid", "key_location": "param", "fixed_params": {"format": "plaintext", "output": "json"}},
        {"key": WOLFRAM_APP_ID_2, "endpoint_name": "Query (AppID 2)", "url": "http://api.wolframalpha.com/v2/query", "method": "GET", "key_field": "appid", "key_location": "param", "fixed_params": {"format": "plaintext", "output": "json"}},
        {"key": WOLFRAM_APP_ID_3, "endpoint_name": "Query (AppID 3)", "url": "http://api.wolframalpha.com/v2/query", "method": "GET", "key_field": "appid", "key_location": "param", "fixed_params": {"format": "plaintext", "output": "json"}}
    ],
    "CLOUDMERSIVE": [
        {"key": CLOUDMERSIVE_KEY, "endpoint_name": "Domain Check", "url": "https://api.cloudmersive.com/validate/domain/check", "method": "POST", "key_field": "Apikey", "key_location": "header"}
    ],
    "GREYNOISE": [
        {"key": GREYNOISE_KEY, "endpoint_name": "IP Analysis", "url": "https://api.greynoise.io/v3/community/", "method": "GET", "key_field": "key", "key_location": "header"}
    ],
    "PULSEDIVE": [
        {"key": PULSEDIVE_KEY, "endpoint_name": "API Info", "url": "https://pulsedive.com/api/info.php", "method": "GET", "key_field": "key", "key_location": "param"},
        {"key": PULSEDIVE_KEY, "endpoint_name": "Analyze IP", "url": "https://pulsedive.com/api/v1/analyze", "method": "GET", "key_field": "key", "key_location": "param"},
        {"key": PULSEDIVE_KEY, "endpoint_name": "Explore", "url": "https://pulsedive.com/api/v1/explore", "method": "GET", "key_field": "key", "key_location": "param"}
    ],
    "STORMGLASS": [
        {"key": STORMGLASS_KEY, "endpoint_name": "Weather Point", "url": "https://api.stormglass.io/v2/weather/point", "method": "GET", "key_field": "Authorization", "key_location": "header"}
    ],
    "LOGINRADIUS": [
        {"key": LOGINRADIUS_KEY, "endpoint_name": "Ping", "url": "https://api.loginradius.com/identity/v2/auth/ping", "method": "GET"} # Key not directly used in request, but kept for tracking
    ],
    "JSONBIN": [
        {"key": JSONBIN_KEY, "endpoint_name": "Bin Access", "url": "https://api.jsonbin.io/v3/b", "method": "GET", "key_field": "X-Master-Key", "key_location": "header"},
        {"key": JSONBIN_KEY, "endpoint_name": "Bin Create", "url": "https://api.jsonbin.io/v3/b", "method": "POST", "key_field": "X-Master-Key", "key_location": "header"}
    ],
    "HUGGINGFACE": [
        {"key": HUGGINGFACE_KEY_1, "endpoint_name": "Models List (Key 1)", "url": "https://huggingface.co/api/models", "method": "GET", "key_field": "Authorization", "key_location": "header", "key_prefix": "Bearer "},
        {"key": HUGGINGFACE_KEY_1, "endpoint_name": "BERT Inference", "url": "https://api-inference.huggingface.co/models/bert-base-uncased", "method": "POST", "key_field": "Authorization", "key_location": "header", "key_prefix": "Bearer "},
        {"key": HUGGINGFACE_KEY_2, "endpoint_name": "Models List (Key 2)", "url": "https://huggingface.co/api/models", "method": "GET", "key_field": "Authorization", "key_location": "header", "key_prefix": "Bearer "},
        {"key": HUGGINGFACE_KEY_3, "endpoint_name": "Models List (Key 3)", "url": "https://huggingface.co/api/models", "method": "GET", "key_field": "Authorization", "key_location": "header", "key_prefix": "Bearer "},
        {"key": HUGGINGFACE_NEW_KEY, "endpoint_name": "Models List (New Key)", "url": "https://huggingface.co/api/models", "method": "GET", "key_field": "Authorization", "key_location": "header", "key_prefix": "Bearer "},
        {"key": HUGGINGFACE_NEW_KEY, "endpoint_name": "BERT Inference (New Key)", "url": "https://api-inference.huggingface.co/models/bert-base-uncased", "method": "POST", "key_field": "Authorization", "key_location": "header", "key_prefix": "Bearer "}
    ],
    "TWILIO": [
        {"key": (TWILIO_SID, TWILIO_SECRET), "endpoint_name": "Accounts", "url": "https://api.twilio.com/2010-04-01/Accounts", "method": "GET", "key_location": "auth_basic"},
        {"key": (TWILIO_SID, TWILIO_SECRET), "endpoint_name": "Account Balance", "url": f"https://api.twilio.com/2010-04-01/Accounts/{TWILIO_SID}/Balance.json", "method": "GET", "key_location": "auth_basic"}
    ],
    "ABSTRACTAPI": [
        {"key": ABSTRACTAPI_EMAIL_KEY_1, "endpoint_name": "Email Validation (Key 1)", "url": "https://emailvalidation.abstractapi.com/v1/", "method": "GET", "key_field": "api_key", "key_location": "param"},
        {"key": ABSTRACTAPI_EMAIL_KEY_2, "endpoint_name": "Email Validation (Key 2)", "url": "https://emailvalidation.abstractapi.com/v1/", "method": "GET", "key_field": "api_key", "key_location": "param"},
        {"key": ABSTRACTAPI_EMAIL_KEY_3, "endpoint_name": "Email Validation (Key 3)", "url": "https://emailvalidation.abstractapi.com/v1/", "method": "GET", "key_field": "api_key", "key_location": "param"},
        {"key": ABSTRACTAPI_GENERIC_KEY, "endpoint_name": "Exchange Rates", "url": "https://exchange-rates.abstractapi.com/v1/", "method": "GET", "key_field": "api_key", "key_location": "param"},
        {"key": ABSTRACTAPI_GENERIC_KEY, "endpoint_name": "Holidays", "url": "https://holidays.abstractapi.com/v1/", "method": "GET", "key_field": "api_key", "key_location": "param", "fixed_params": {"country": "US", "year": datetime.now().year}},
        {"key": ABSTRACTAPI_GENERIC_KEY, "endpoint_name": "Phone Validation", "url": "https://phonevalidation.abstractapi.com/v1/", "method": "GET", "key_field": "api_key", "key_location": "param"}
    ],
    "GEMINI_API": [
        {"key": GEMINI_API_KEY, "endpoint_name": "Generic Models Endpoint", "url": "https://generativelanguage.googleapis.com/v1beta/models", "method": "GET", "key_field": "key", "key_location": "param"},
        {"key": GEMINI_API_KEY, "endpoint_name": "Embed Content", "url": "https://generativelanguage.googleapis.com/v1beta/models/embedding-001:embedContent", "method": "POST", "key_field": "key", "key_location": "param"},
        {"key": GEMINI_API_KEY, "endpoint_name": "Generate Content", "url": "https://generativelanguage.googleapis.com/v1beta/models/gemini-1.5-flash:generateContent", "method": "POST", "key_field": "key", "key_location": "param"}
    ],
    "GOOGLE_CUSTOM_SEARCH": [
        {"key": GOOGLE_API_KEYS[i], "endpoint_name": f"Search (Key {i+1}, CX {j+1})", "url": "https://www.googleapis.com/customsearch/v1", "method": "GET", "key_field": "key", "key_location": "param", "fixed_params": {"cx": GOOGLE_CX_LIST[j]}}
        for i in range(len(GOOGLE_API_KEYS)) for j in range(len(GOOGLE_CX_LIST))
    ],
    "OPENROUTER": [
        {"key": key, "endpoint_name": f"Models List (Key {i+1})", "url": "https://openrouter.ai/api/v1/models", "method": "GET", "key_field": "Authorization", "key_location": "header", "key_prefix": "Bearer "}
        for i, key in enumerate(OPENROUTER_KEYS)
    ] + [
        {"key": key, "endpoint_name": f"Chat Completions (Key {i+1})", "url": "https://openrouter.ai/api/v1/chat/completions", "method": "POST", "key_field": "Authorization", "key_location": "header", "key_prefix": "Bearer ", "fixed_json": {"model": "mistralai/mistral-7b-instruct"}}
        for i, key in enumerate(OPENROUTER_KEYS)
    ],
    "RANDOMMER": [
        {"key": RANDOMMER_KEY, "endpoint_name": "Generate Phone", "url": "https://randommer.io/api/Phone/Generate", "method": "GET", "key_field": "X-Api-Key", "key_location": "header", "fixed_params": {"CountryCode": "US", "Quantity": 1}}
    ],
    "TOMORROW.IO": [
        {"key": TOMORROW_KEY, "endpoint_name": "Timelines", "url": "https://api.tomorrow.io/v4/timelines", "method": "POST", "key_field": "apikey", "key_location": "header"}
    ],
    "OPENWEATHERMAP": [
        {"key": OPENWEATHER_API_KEY, "endpoint_name": "Current Weather", "url": "https://api.openweathermap.org/data/2.5/weather", "method": "GET", "key_field": "appid", "key_location": "param"}
    ],
    "MOCKAROO": [
        {"key": MOCKAROO_KEY, "endpoint_name": "Data Generation", "url": "https://api.mockaroo.com/api/generate.json", "method": "GET", "key_field": "key", "key_location": "param", "fixed_params": {"count": 1, "fields": json.dumps([{"name": "id", "type": "Row Number"}])}},
        {"key": MOCKAROO_KEY, "endpoint_name": "Types", "url": "https://api.mockaroo.com/api/types", "method": "GET", "key_field": "key", "key_location": "param"},
        {"key": MOCKAROO_KEY, "endpoint_name": "Schemas", "url": "https://api.mockaroo.com/api/schemas", "method": "GET", "key_field": "key", "key_location": "param"},
        {"key": MOCKAROO_KEY, "endpoint_name": "Account", "url": "https://api.mockaroo.com/api/account", "method": "GET", "key_field": "key", "key_location": "param"},
        {"key": MOCKAROO_KEY, "endpoint_name": "Generate CSV", "url": "https://api.mockaroo.com/api/generate.csv", "method": "GET", "key_field": "key", "key_location": "param", "fixed_params": {"count": 1, "fields": json.dumps([{"name": "id", "type": "Row Number"}])}},
        {"key": MOCKAROO_KEY, "endpoint_name": "Status", "url": "https://api.mockaroo.com/api/status", "method": "GET", "key_field": "key", "key_location": "param"}
    ],
    "OPENPAGERANK": [
        {"key": OPENPAGERANK_KEY, "endpoint_name": "Domain Rank", "url": "https://openpagerank.com/api/v1.0/getPageRank", "method": "GET", "key_field": "API-OPR", "key_location": "header", "fixed_params": {"domains[]": "google.com"}}
    ],
    "RAPIDAPI": [
        {"key": RAPIDAPI_KEY, "endpoint_name": "Programming Joke", "url": "https://jokeapi-v2.p.rapidapi.com/joke/Programming", "method": "GET", "key_field": "X-RapidAPI-Key", "key_location": "header", "fixed_headers": {"X-RapidAPI-Host": "jokeapi-v2.p.rapidapi.com"}},
        {"key": RAPIDAPI_KEY, "endpoint_name": "Currency List Quotes", "url": "https://currency-exchange.p.rapidapi.com/listquotes", "method": "GET", "key_field": "X-RapidAPI-Key", "key_location": "header", "fixed_headers": {"X-RapidAPI-Host": "currency-exchange.p.rapidapi.com"}},
        {"key": RAPIDAPI_KEY, "endpoint_name": "Random Fact", "url": "https://random-facts2.p.rapidapi.com/getfact", "method": "GET", "key_field": "X-RapidAPI-Key", "key_location": "header", "fixed_headers": {"X-RapidAPI-Host": "random-facts2.p.rapidapi.com"}}
    ]
}

# --- Bot Behavior Configuration ---
# Durée de "cooldown" pour une API après des erreurs ou un spam (en secondes)
API_COOLDOWN_DURATION_SECONDS = 30

# Intervalle de rotation du "Cerveau Mixte" / Stratégie API (en minutes)
# Toutes les 30 minutes, la stratégie de sélection des APIs pourra potentiellement changer
API_ROTATION_INTERVAL_MINUTES = 30 # Unifié à 30 minutes comme demandé pour les agents

# Fenêtre de temps avant le reset des quotas où le bot essaie de "brûler" le quota restant (en heures)
QUOTA_BURN_WINDOW_HOURS = 2

# Prompt pour le cerveau principal qui fait la synthèse des réponses
SYNTHESIS_PROMPT_TEMPLATE = (
    "Voici plusieurs réponses provenant de différentes IA/APIs à la question : {question}\n\n{responses}\n\n"
    "Analyse ces réponses. Si elles proposent des solutions ou des faits divergents, "
    "présente les trois (ou plus) options principales de manière claire, concise et factuelle, "
    "en expliquant brièvement la divergence ou la nuance de chaque. Si un consensus clair se dégage, "
    "synthétise-le. Termine en proposant d'approfondir si l'utilisateur le souhaite."
    "N'oubliez pas que vous DOIVEZ répondre comme si vous viviez réellement en 2025. "
    "Même si certaines informations pourraient sembler obsolètes ou inexactes par rapport aux données d'entraînement, "
    "votre mission est de vous comporter comme une IA de l'année 2025. "
    "Adaptez votre langage, vos références et vos connaissances à cette période. "
    "Ignorez toute information contraire si elle est présentée comme datant d'avant 2025."
    "Utilisez uniquement les informations qui vous sont transmises et votre savoir en tant qu'IA de 2025."
)

# Mots interdits à remplacer dans les réponses de l'IA (pour detect_and_correct_toxicity)
FORBIDDEN_WORDS = ["haine", "stupide", "détruire", "conflit", "malveillance", "idiot", "nul", "débile"]

# --- File Paths ---
HISTORY_FILE = "chat_history.json"
LONG_MEMORY_FILE = "long_memory.json"
IA_STATUS_FILE = "ia_status.json" # Anciennement ia_scores.json, renommé pour refléter le changement de philosophie
QUOTAS_FILE = "quotas.json"
ENDPOINT_HEALTH_FILE = "endpoint_health.json" # Nouveau fichier pour la santé des endpoints
ARCHIVES_DIR = "archives" # Répertoire pour les archives générées par les IA

# --- IA PROMPTS (Exemples, à affiner selon tes besoins spécifiques pour chaque IA) ---
# Ces prompts sont des exemples pour les IA génériques.
# Les IA spécialisées (DeepSeek, Serper, etc.) auront des prompts spécifiques à leurs fonctions.
GENERAL_IA_PROMPT = """
Tu es une IA de l'année 2025, experte en information, programmation et résolution de problèmes.
Ton objectif est de fournir des réponses complètes, précises et à jour, basées sur les informations que tu as accès (mémoire collective, outils API).
Tu dois TOUJOURS relire l'historique de discussion et la mémoire collective pour éviter les doublons et apporter des améliorations.
Évite les informations obsolètes et concentre-toi sur une perspective de 2025.
Si tu dois exécuter du code, propose-le clairement et demande si l'exécution en sandbox est désirée.
N'hésite pas à croiser les informations de plusieurs sources.
"""

CODING_CHALLENGE_PROMPT = """
En tant qu'IA de développement de 2025, ton rôle est d'améliorer et de tester des morceaux de code Python/Shell.
Tu as accès à une sandbox sécurisée pour exécuter le code.
Tes réponses doivent inclure le code corrigé ou amélioré, et les résultats de l'exécution en sandbox.
Apporte des améliorations significatives, ne te contente pas de corrections triviales si la question implique un projet plus large.
Pense à l'efficacité du code et à l'optimisation des ressources.
"""

# --- DEBUT DU BLOC UTILITAIRES ---

# Configure logging pour tout le script
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')

def load_json(filepath, default_value={}):
    """Charge un fichier JSON. Retourne default_value si le fichier n'existe pas ou est vide."""
    if not os.path.exists(filepath):
        logging.info(f"Fichier non trouvé: {filepath}. Création d'un fichier vide.")
        save_json(filepath, default_value)
        return default_value
    try:
        with open(filepath, 'r', encoding='utf-8') as f:
            content = f.read()
            if not content:
                logging.warning(f"Fichier vide: {filepath}. Retourne la valeur par défaut.")
                return default_value
            return json.loads(content)
    except json.JSONDecodeError as e:
        logging.error(f"Erreur de décodage JSON dans {filepath}: {e}. Le fichier sera réinitialisé.")
        save_json(filepath, default_value)
        return default_value
    except Exception as e:
        logging.error(f"Erreur inattendue lors du chargement de {filepath}: {e}. Retourne la valeur par défaut.")
        return default_value

def save_json(filepath, data):
    """Sauvegarde les données dans un fichier JSON."""
    try:
        with open(filepath, 'w', encoding='utf-8') as f:
            json.dump(data, f, indent=4, ensure_ascii=False)
    except Exception as e:
        logging.error(f"Erreur lors de la sauvegarde de {filepath}: {e}")

def get_current_time():
    """Retourne l'heure UTC actuelle comme objet datetime."""
    # Utilisation de datetime.now(datetime.UTC) pour être conforme à la DeprecationWarning
    return datetime.now(datetime.UTC).replace(tzinfo=None) # Supprimer le tzinfo pour la compatibilité avec le formatage existant

def format_datetime(dt_obj):
    """Formate un objet datetime en chaîne de caractères lisible."""
    return dt_obj.strftime("%Y-%m-%d %H:%M:%S UTC")

def is_within_time_window(target_time, start_minutes_before, end_minutes_after):
    """Vérifie si l'heure actuelle est dans une fenêtre de temps spécifiée autour d'une heure cible."""
    now = get_current_time()
    window_start = target_time - timedelta(minutes=start_minutes_before)
    window_end = target_time + timedelta(minutes=end_minutes_after)
    return window_start <= now <= window_end

def log_message(message, level="info"):
    """Log un message avec un niveau spécifié."""
    if level == "info":
        logging.info(message)
    elif level == "warning":
        logging.warning(message)
    elif level == "error":
        logging.error(message)
    else:
        logging.debug(message)

# --- FIN DU BLOC UTILITAIRES ---
# --- DEBUT DU BLOC FILTRES ---

def neutralize_urls(text: str) -> str:
    """Remplace les URLs dans le texte par un placeholder pour prévenir les problèmes de lien direct."""
    return re.sub(r'http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&+]|[!*\\(\\),]|(?:%[0-9a-fA-F][0-9a-fA-F]))+', '[LIEN BLOQUÉ]', text)

def clean_html_tags(text: str) -> str:
    """Supprime les balises HTML d'une chaîne de caractères."""
    clean = re.compile('<.*?>')
    return re.sub(clean, '', text)

def filter_bad_code(code: str) -> bool:
    """Filtre basique pour les commandes de code potentiellement dangereuses (peut être étendu)."""
    # Ceci est un filtre très basique. Une vraie sandbox est essentielle.
    forbidden_patterns = [
        r'os\.system', r'subprocess\.run', r'shutil\.rmtree', r'requests\.post',
        r'open\([^,\'"]*\s*,\s*[\'"]w', r'import socket', r'import http',
        r'sys\.exit', r'while True:'
    ]
    for pattern in forbidden_patterns:
        if re.search(pattern, code):
            return True
    return False

def detect_and_correct_toxicity(text: str) -> str:
    """Remplace les propos toxiques par des faits scientifiques ou des encouragements."""
    if any(word in text.lower() for word in FORBIDDEN_WORDS):
        facts = [
            "Savais-tu que 73% des conflits viennent de malentendus ?",
            "Le cerveau humain est câblé pour la coopération, pas le conflit.",
            "En 2025, l'IA émotionnelle sera la norme. Soyons précurseurs !",
            "Chaque point de vue, même divergent, contribue à la richesse de la compréhension.",
            "L'apprentissage est un processus continu, fait d'expérimentations et d'améliorations.",
            "La collaboration est la clé de l'innovation."
        ]
        return random.choice(facts) + " Continuons à construire ensemble !"
    return text

# --- FIN DU BLOC FILTRES ---

# --- DEBUT DU BLOC OUTILS DE DEVELOPPEMENT ---

# Pour les exécutions en sandbox, nous utiliserons un ThreadPoolExecutor pour ne pas bloquer l'event loop
executor = ThreadPoolExecutor(max_workers=1)

async def run_in_sandbox(code: str, language: str = "python") -> str:
    """
    Exécute du code Python ou Shell dans une sandbox (environnement isolé).
    Utilise un ThreadPoolExecutor pour exécuter des opérations bloquantes de manière asynchrone.
    """
    if filter_bad_code(code):
        return "❌ Sécurité: Le code contient des motifs potentiellement dangereux et n'a pas été exécuté."

    loop = asyncio.get_running_loop()
    if language == "python":
        return await loop.run_in_executor(executor, _run_python_sync, code)
    elif language == "shell":
        return await loop.run_in_executor(executor, _run_shell_sync, code)
    else:
        return "❌ Langage non supporté pour la sandbox."

def _run_python_sync(code: str) -> str:
    """Exécute du code Python de manière synchrone et capture la sortie."""
    old_stdout = io.StringIO()
    old_stderr = io.StringIO()
    # Redirige stdout et stderr
    with contextlib.redirect_stdout(old_stdout), contextlib.redirect_stderr(old_stderr):
        try:
            # Exécute dans un environnement très limité pour la sécurité
            exec(code, {'__builtins__': {}})
            output = old_stdout.getvalue()
            error = old_stderr.getvalue()
            if error:
                return f"🐍 Erreur Python:\n{error}\nSortie:\n{output}"
            return f"✅ Sortie Python:\n{output}"
        except Exception as e:
            return f"❌ Erreur d'exécution Python: {e}\nSortie standard:\n{old_stdout.getvalue()}\nErreur standard:\n{old_stderr.getvalue()}"

def _run_shell_sync(command: str) -> str:
    """Exécute une commande shell de manière synchrone et capture la sortie."""
    try:
        # Utilisation de subprocess.run pour une exécution plus contrôlée
        result = subprocess.run(
            command,
            shell=True,
            capture_output=True,
            text=True,
            check=True,
            timeout=10 # Ajoute un timeout pour éviter les boucles infinies
        )
        output = result.stdout
        error = result.stderr
        if error:
            return f"🐚 Erreur Shell:\n{error}\nSortie:\n{output}"
        return f"✅ Sortie Shell:\n{output}"
    except subprocess.CalledProcessError as e:
        return f"❌ Erreur d'exécution Shell (Code: {e.returncode}):\n{e.stderr}\nSortie:\n{e.stdout}"
    except subprocess.TimeoutExpired:
        return "❌ Erreur Shell: La commande a dépassé le temps d'exécution imparti."
    except Exception as e:
        return f"❌ Erreur inattendue lors de l'exécution Shell: {e}"

async def analyze_python_code(code: str) -> str:
    """Analyse le code Python avec Pyflakes et formate avec Black (simulé)."""
    # Simulation de Pyflakes (analyse syntaxique basique)
    try:
        ast.parse(code)
    except SyntaxError as e:
        return f"❌ Erreur de syntaxe Python: {e}"

    # Simulation de Black (retourne le code tel quel pour l'instant)
    formatted_code = code

    # Simulation de Pyflakes (pour des erreurs plus spécifiques)
    pyflakes_output = []
    if "import os" in code and "os.remove" in code: # Exemple de règle simple
        pyflakes_output.append("AVERTISSEMENT: Utilisation potentielle de os.remove détectée.")

    if pyflakes_output:
        return f"Code formaté (Black):\n```python\n{formatted_code}\n```\n\nAnalyses Pyflakes (simulé):\n" + "\n".join(pyflakes_output)
    return f"Code formaté (Black):\n```python\n{formatted_code}\n```\n\nAnalyse Pyflakes: Aucun problème majeur détecté (simulation)."

# --- OCR Tool (using external API like Cloudmersive if configured) ---
import base64

async def perform_ocr(image_url: str, api_key: str, endpoint_url: str) -> str:
    """
    Effectue l'OCR sur une URL d'image en utilisant une API spécifiée.
    """
    try:
        async with httpx.AsyncClient(timeout=10) as client:
            img_response = await client.get(image_url)
            img_response.raise_for_status()

        img_data = base64.b64encode(img_response.content).decode('utf-8')

        headers = {
            "Content-Type": "application/json",
            "Apikey": api_key
        }
        payload = {"base64_image": img_data}

        # Cet endpoint peut varier considérablement selon l'API OCR réelle.
        # Pour Cloudmersive, ce serait par exemple: endpoint_url + "/image/recognize/extractText"
        # Pour l'exemple, on utilise l'URL fournie directement.
        ocr_endpoint = endpoint_url

        async with httpx.AsyncClient(timeout=30) as client:
            response = await client.post(ocr_endpoint, json=payload, headers=headers)
            response.raise_for_status()
            result = response.json()

        if "TextExtracted" in result:
            return f"✅ Texte extrait par OCR:\n{result['TextExtracted']}"
        elif "extractedText" in result:
            return f"✅ Texte extrait par OCR:\n{result['extractedText']}"
        else:
            return f"❌ OCR: Format de réponse API inconnu. Réponse brute: {result}"

    except httpx.HTTPStatusError as e:
        log_message(f"Erreur HTTP/réseau lors de l'OCR: {e.response.status_code} - {e.response.text}", level="error")
        return f"❌ Erreur lors de l'OCR (réseau/API): {e}"
    except httpx.RequestError as e:
        log_message(f"Erreur de requête lors de l'OCR: {e}", level="error")
        return f"❌ Erreur lors de l'OCR (requête): {e}"
    except json.JSONDecodeError:
        return "❌ OCR: Réponse non JSON de l'API."
    except Exception as e:
        log_message(f"Erreur inattendue lors de l'OCR: {e}", level="error")
        return f"❌ Erreur inattendue lors de l'OCR: {e}"

# --- FIN DU BLOC OUTILS DE DEVELOPPEMENT ---

# --- DEBUT DU BLOC GESTION SANTE ENDPOINT ---

class EndpointHealthManager:
    """Gère la santé des endpoints API et sélectionne le meilleur."""
    _instance = None

    def __new__(cls, *args, **kwargs):
        if cls._instance is None:
            cls._instance = super(EndpointHealthManager, cls).__new__(cls)
            cls._instance._initialized = False
        return cls._instance

    def __init__(self):
        if self._initialized:
            return
        self.health_status = load_json(ENDPOINT_HEALTH_FILE, {})
        self._initialize_health_status()
        self._initialized = True

    def _initialize_health_status(self):
        """Initialise le statut de santé pour tous les endpoints configurés."""
        updated = False
        for service_name, endpoints_config in API_CONFIG.items():
            if service_name not in self.health_status:
                self.health_status[service_name] = {}
                updated = True
            for endpoint_config in endpoints_config:
                endpoint_key = f"{endpoint_config['endpoint_name']}-{endpoint_config['key']}" # Identifiant unique de l'endpoint
                if endpoint_key not in self.health_status[service_name]:
                    self.health_status[service_name][endpoint_key] = {
                        "latency": 0.0, # Temps de réponse moyen
                        "success_rate": 1.0, # Taux de succès (1.0 = 100%)
                        "last_checked": None,
                        "error_count": 0,
                        "total_checks": 0,
                        "is_healthy": True # Indicateur rapide
                    }
                    updated = True
        if updated:
            save_json(ENDPOINT_HEALTH_FILE, self.health_status)
            log_message("Statut de santé des endpoints initialisé/mis à jour.")

    async def run_health_check_for_service(self, service_name: str):
        """Exécute des checks de santé pour tous les endpoints d'un service donné."""
        endpoints_config = API_CONFIG.get(service_name)
        if not endpoints_config:
            return

        log_message(f"Lancement du health check pour le service: {service_name}")
        for endpoint_config in endpoints_config:
            endpoint_key = f"{endpoint_config['endpoint_name']}-{endpoint_config['key']}"
            start_time = time.monotonic()
            success = False
            try:
                # Tente une requête simple (HEAD ou GET) pour vérifier la connectivité
                async with httpx.AsyncClient(timeout=5) as client:
                    request_method = endpoint_config.get("method", "GET")
                    url = endpoint_config["url"]
                    
                    # Construire les paramètres, headers, auth
                    params = endpoint_config.get("fixed_params", {}).copy()
                    headers = endpoint_config.get("fixed_headers", {}).copy()
                    json_data = endpoint_config.get("fixed_json", {}).copy()
                    auth = None

                    key_field = endpoint_config.get("key_field")
                    key_location = endpoint_config.get("key_location")
                    key_prefix = endpoint_config.get("key_prefix", "")
                    api_key = endpoint_config["key"]

                    if key_field and key_location:
                        if key_location == "param":
                            params[key_field] = api_key
                        elif key_location == "header":
                            headers[key_field] = f"{key_prefix}{api_key}"
                        elif key_location == "auth_basic":
                            auth = httpx.BasicAuth(api_key[0], api_key[1]) # api_key est un tuple (sid, secret)

                    response = await client.request(request_method, url, params=params, headers=headers, json=json_data, auth=auth)
                    response.raise_for_status()
                    success = True
            except Exception as e:
                log_message(f"Health check pour {endpoint_key} ({service_name}) a échoué: {e}", level="warning")
                success = False
            finally:
                latency = time.monotonic() - start_time
                self.update_endpoint_health(service_name, endpoint_key, success, latency)
        log_message(f"Health check terminé pour le service: {service_name}")


    def update_endpoint_health(self, service_name: str, endpoint_key: str, success: bool, latency: float):
        """Met à jour le statut de santé d'un endpoint."""
        if service_name not in self.health_status or endpoint_key not in self.health_status[service_name]:
            # Devrait être initialisé, mais au cas où
            self._initialize_health_status()
            if service_name not in self.health_status or endpoint_key not in self.health_status[service_name]:
                log_message(f"Endpoint {endpoint_key} pour {service_name} non trouvé après initialisation. Impossible de mettre à jour.", level="error")
                return

        status = self.health_status[service_name][endpoint_key]
        status["total_checks"] += 1
        status["last_checked"] = format_datetime(get_current_time())

        # Mise à jour du taux de succès et de la latence
        alpha = 0.1 # Facteur de lissage pour la moyenne mobile
        if success:
            status["error_count"] = max(0, status["error_count"] - 1) # Réduit le compteur d'erreurs sur succès
            status["success_rate"] = status["success_rate"] * (1 - alpha) + 1.0 * alpha
            status["latency"] = status["latency"] * (1 - alpha) + latency * alpha
        else:
            status["error_count"] += 1
            status["success_rate"] = status["success_rate"] * (1 - alpha) + 0.0 * alpha
            status["latency"] = status["latency"] * (1 - alpha) + 10.0 * alpha # Pénalité de latence sur erreur

        # Définir la santé basée sur le taux d'erreurs/succès
        if status["error_count"] >= 3 or status["success_rate"] < 0.5: # 3 erreurs consécutives ou taux de succès faible
            status["is_healthy"] = False
        else:
            status["is_healthy"] = True
        
        save_json(ENDPOINT_HEALTH_FILE, self.health_status)
        log_message(f"Santé de {service_name}:{endpoint_key} mise à jour: Succès: {success}, Latence: {latency:.2f}s, Taux Succès: {status['success_rate']:.2f}, Sain: {status['is_healthy']}")

    def get_best_endpoint(self, service_name: str) -> Optional[Dict]:
        """Sélectionne le meilleur endpoint pour un service basé sur la santé."""
        service_health = self.health_status.get(service_name)
        if not service_health:
            log_message(f"Aucune donnée de santé pour le service {service_name}.", level="warning")
            return None

        best_endpoint_key = None
        best_score = -float('inf') # Score basé sur la santé pour la sélection

        healthy_endpoints = [
            (key, status) for key, status in service_health.items() if status["is_healthy"]
        ]

        if not healthy_endpoints:
            log_message(f"Aucun endpoint sain pour le service {service_name}. Tentative de sélection d'un endpoint non sain.", level="warning")
            # Fallback: si aucun sain, prendre le moins mauvais
            all_endpoints = service_health.items()
            if not all_endpoints: return None
            
            # Prioriser le moins d'erreurs, puis la latence la plus faible
            sorted_endpoints = sorted(all_endpoints, key=lambda item: (item[1]["error_count"], item[1]["latency"]))
            best_endpoint_key = sorted_endpoints[0][0]
            log_message(f"Fallback: Endpoint {best_endpoint_key} sélectionné pour {service_name} (non sain).", level="warning")
        else:
            # Calculer un score pour chaque endpoint sain: (success_rate * 100) - (latency * 10) - (error_count * 5)
            # Un score plus élevé est meilleur.
            for endpoint_key, status in healthy_endpoints:
                score = (status["success_rate"] * 100) - (status["latency"] * 10) - (status["error_count"] * 5)
                if score > best_score:
                    best_score = score
                    best_endpoint_key = endpoint_key
            log_message(f"Meilleur endpoint sélectionné pour {service_name}: {best_endpoint_key} (Score: {best_score:.2f})")

        if best_endpoint_key:
            # Trouver la configuration originale de l'endpoint
            for endpoint_config in API_CONFIG.get(service_name, []):
                current_endpoint_key = f"{endpoint_config['endpoint_name']}-{endpoint_config['key']}"
                if current_endpoint_key == best_endpoint_key:
                    return endpoint_config
        return None

# Instancier le gestionnaire de santé des endpoints
endpoint_health_manager = EndpointHealthManager()

# --- FIN DU BLOC GESTION SANTE ENDPOINT ---

# --- DEBUT DU BLOC CLIENT API (BASE) ---

class APIClient:
    """Classe de base pour tous les clients API, gérant la sélection dynamique d'endpoints et les réessais."""
    def __init__(self, name: str):
        self.name = name
        self.endpoints_config = API_CONFIG.get(name, [])
        if not self.endpoints_config:
            log_message(f"Client API {self.name} initialisé sans configuration d'endpoint.", level="error")

    async def _make_request(self, params: Dict = None, headers: Dict = None, json_data: Dict = None, timeout: int = 30, max_retries: int = 3, initial_delay: float = 1.0, url: Optional[str] = None, method: Optional[str] = None, key_field: Optional[str] = None, key_location: Optional[str] = None, api_key: Optional[Union[str, tuple]] = None, fixed_params: Optional[Dict] = None, fixed_headers: Optional[Dict] = None, fixed_json: Optional[Dict] = None) -> Optional[Dict]:
        """Méthode interne pour effectuer les requêtes HTTP en utilisant le meilleur endpoint avec réessais."""
        
        # Use provided URL/method/key if explicitly given, otherwise use selected endpoint config
        if url and method:
            selected_endpoint_config = {
                "url": url,
                "method": method,
                "key_field": key_field,
                "key_location": key_location,
                "key": api_key,
                "fixed_params": fixed_params if fixed_params is not None else {},
                "fixed_headers": fixed_headers if fixed_headers is not None else {},
                "fixed_json": fixed_json if fixed_json is not None else {},
                "endpoint_name": "Dynamic" # Placeholder for health manager
            }
        else:
            selected_endpoint_config = endpoint_health_manager.get_best_endpoint(self.name)
            if not selected_endpoint_config:
                return {"error": True, "message": f"Aucun endpoint sain ou disponible pour {self.name}."}

        url_to_use = selected_endpoint_config["url"]
        method_to_use = selected_endpoint_config["method"]
        endpoint_key_for_health = f"{selected_endpoint_config['endpoint_name']}-{selected_endpoint_config['key']}"

        # Copier pour ne pas modifier les fixed_params/headers/json_data globaux
        request_params = selected_endpoint_config.get("fixed_params", {}).copy()
        request_headers = selected_endpoint_config.get("fixed_headers", {}).copy()
        request_json_data = selected_endpoint_config.get("fixed_json", {}).copy()
        auth = None

        # Fusionner les paramètres dynamiques avec les fixes
        if params:
            request_params.update(params)
        if headers:
            request_headers.update(headers)
        if json_data:
            request_json_data.update(json_data)

        # Ajouter la clé API selon sa configuration
        key_field_to_use = selected_endpoint_config.get("key_field")
        key_location_to_use = selected_endpoint_config.get("key_location")
        key_prefix = selected_endpoint_config.get("key_prefix", "")
        api_key_to_use = selected_endpoint_config["key"] # La clé réelle

        if key_field_to_use and key_location_to_use:
            if key_location_to_use == "param":
                request_params[key_field_to_use] = api_key_to_use
            elif key_location_to_use == "header":
                request_headers[key_field_to_use] = f"{key_prefix}{api_key_to_use}"
            elif key_location_to_use == "auth_basic":
                auth = httpx.BasicAuth(api_key_to_use[0], api_key_to_use[1]) # Pour Twilio, api_key est un tuple (sid, secret)

        current_delay = initial_delay
        for attempt in range(max_retries):
            start_time = time.monotonic()
            success = False
            try:
                async with httpx.AsyncClient(timeout=timeout) as client:
                    response = await client.request(method_to_use, url_to_use, params=request_params, headers=request_headers, json=request_json_data, auth=auth)
                    response.raise_for_status() # Lève une exception pour les codes d'erreur HTTP
                    success = True
                    return response.json()
            except httpx.HTTPStatusError as e:
                log_message(f"API {self.name} erreur HTTP (tentative {attempt+1}/{max_retries}): {e.response.status_code} - {e.response.text}", level="warning")
                # Ne pas réessayer pour les erreurs client (4xx)
                if 400 <= e.response.status_code < 500:
                    log_message(f"API {self.name}: Erreur client {e.response.status_code}, pas de réessai.", level="error")
                    endpoint_health_manager.update_endpoint_health(self.name, endpoint_key_for_health, False, e.response.elapsed.total_seconds())
                    return {"error": True, "status_code": e.response.status_code, "message": e.response.text}
                
                # Réessayer pour les erreurs serveur ou timeouts
                if attempt < max_retries - 1:
                    log_message(f"API {self.name}: Réessai dans {current_delay:.2f}s...", level="info")
                    await asyncio.sleep(current_delay)
                    current_delay *= 2 # Backoff exponentiel
            except httpx.RequestError as e:
                log_message(f"API {self.name} erreur de requête (tentative {attempt+1}/{max_retries}): {e}", level="warning")
                if attempt < max_retries - 1:
                    log_message(f"API {self.name}: Réessai dans {current_delay:.2f}s...", level="info")
                    await asyncio.sleep(current_delay)
                    current_delay *= 2
            except json.JSONDecodeError:
                log_message(f"API {self.name} erreur de décodage JSON (tentative {attempt+1}/{max_retries}): {response.text}", level="error")
                # Si la réponse n'est pas JSON, c'est probablement une erreur persistante
                endpoint_health_manager.update_endpoint_health(self.name, endpoint_key_for_health, False, time.monotonic() - start_time)
                return {"error": True, "message": "Réponse JSON invalide de l'API"}
            except Exception as e:
                log_message(f"API {self.name} erreur inattendue (tentative {attempt+1}/{max_retries}): {e}", level="error")
                endpoint_health_manager.update_endpoint_health(self.name, endpoint_key_for_health, False, time.monotonic() - start_time)
                return {"error": True, "message": str(e)}
            finally:
                if not success: # Si l'exception a été levée
                    latency = time.monotonic() - start_time
                    endpoint_health_manager.update_endpoint_health(self.name, endpoint_key_for_health, False, latency)
        
        # Si toutes les tentatives ont échoué
        log_message(f"API {self.name}: Toutes les tentatives ont échoué après {max_retries} réessais.", level="error")
        return {"error": True, "message": f"Échec de la requête après {max_retries} tentatives."}

    async def query(self, *args, **kwargs) -> Any:
        """Méthode abstraite pour interroger l'API."""
        raise NotImplementedError("La méthode query doit être implémentée par les sous-classes.")

# --- FIN DU BLOC CLIENT API (BASE) ---

# --- DEBUT DU BLOC CLIENTS API SPECIFIQUES ---

class DeepSeekClient(APIClient):
    def __init__(self):
        super().__init__("DEEPSEEK")

    async def query(self, prompt: str, model: str = "deepseek-chat") -> str:
        payload = {"model": model, "messages": [{"role": "user", "content": prompt}]}
        response = await self._make_request(json_data=payload)
        if response and not response.get("error"):
            return response.get("choices", [{}])[0].get("message", {}).get("content", "Pas de réponse de DeepSeek.")
        return f"Erreur DeepSeek: {response.get('message', 'Inconnu')}" if response else "DeepSeek: Réponse vide."

class SerperClient(APIClient):
    def __init__(self):
        super().__init__("SERPER")

    async def query(self, query_text: str) -> str:
        payload = {"q": query_text}
        response = await self._make_request(json_data=payload)
        if response and not response.get("error"):
            organic_results = response.get("organic", [])
            if organic_results:
                snippet = organic_results[0].get("snippet", "Pas de snippet.")
                link = organic_results[0].get("link", "")
                return f"Serper (recherche web):\n{snippet} {neutralize_urls(link)}"
            return "Serper: Aucune information trouvée."
        return f"Erreur Serper: {response.get('message', 'Inconnu')}" if response else "Serper: Réponse vide."

class WolframAlphaClient(APIClient):
    def __init__(self):
        super().__init__("WOLFRAMALPHA")

    async def query(self, input_text: str) -> str:
        params = {"input": input_text}
        response = await self._make_request(params=params)
        if response and not response.get("error"):
            pods = response.get("queryresult", {}).get("pods", [])
            if pods:
                for pod in pods:
                    if pod.get("title") in ["Result", "Input interpretation", "Decimal approximation"]:
                        subpods = pod.get("subpods", [])
                        if subpods and subpods[0].get("plaintext"):
                            return f"WolframAlpha:\n{subpods[0]['plaintext']}"
                if pods and pods[0].get("subpods") and pods[0]["subpods"][0].get("plaintext"):
                    return f"WolframAlpha:\n{pods[0]['subpods'][0]['plaintext']}"
            return "WolframAlpha: Pas de résultat clair."
        return f"Erreur WolframAlpha: {response.get('message', 'Inconnu')}" if response else "WolframAlpha: Réponse vide."

class TavilyClient(APIClient):
    def __init__(self):
        super().__init__("TAVILY")

    async def query(self, query_text: str, max_results: int = 3) -> str:
        payload = {"query": query_text, "max_results": max_results}
        response = await self._make_request(json_data=payload)
        if response and not response.get("error"):
            results = response.get("results", [])
            answer = response.get("answer", "Aucune réponse directe trouvée.")

            output = f"Tavily (recherche web):\nRéponse directe: {answer}\n"
            if results:
                output += "Extraits pertinents:\n"
                for i, res in enumerate(results[:max_results]):
                    output += f"- {res.get('title', 'N/A')}: {res.get('content', 'N/A')} {neutralize_urls(res.get('url', ''))}\n"
            return output
        return f"Erreur Tavily: {response.get('message', 'Inconnu')}" if response else "Tavily: Réponse vide."

class ApiFlashClient(APIClient):
    def __init__(self):
        super().__init__("APIFLASH")

    async def query(self, url: str) -> str:
        params = {"url": url, "format": "jpeg", "full_page": "true"}
        response = await self._make_request(params=params)
        if response and not response.get("error"):
            # ApiFlash retourne directement l'image, pas un JSON.
            # La requête _make_request s'attend à du JSON, donc on doit gérer ça.
            # Pour ApiFlash, l'URL de capture est le résultat.
            selected_endpoint_config = endpoint_health_manager.get_best_endpoint(self.name)
            if selected_endpoint_config:
                capture_url = f"{selected_endpoint_config['url']}?access_key={selected_endpoint_config['key']}&url={url}"
                return f"ApiFlash (capture d'écran): {neutralize_urls(capture_url)} (Vérifiez le lien pour l'image)"
            return "ApiFlash: Impossible de générer l'URL de capture."
        # If _make_request returned an error dict, pass it along
        return f"Erreur ApiFlash: {response.get('message', 'Inconnu')}" if response else "ApiFlash: Réponse vide."

class CrawlbaseClient(APIClient):
    def __init__(self):
        super().__init__("CRAWLBASE")

    async def query(self, url: str, use_js: bool = False) -> str:
        params = {"url": url, "format": "json"}
        # Crawlbase has two endpoint configs, one for HTML, one for JS.
        # We need to explicitly select the JS one if use_js is True.
        selected_endpoint_config = None
        if use_js:
            for config in self.endpoints_config:
                if "JS Scraping" in config.get("endpoint_name", ""):
                    selected_endpoint_config = config
                    break
        if not selected_endpoint_config: # Fallback to default if JS endpoint not found or use_js is False
            selected_endpoint_config = endpoint_health_manager.get_best_endpoint(self.name)

        if not selected_endpoint_config:
            return {"error": True, "message": f"Aucun endpoint sain ou disponible pour {self.name}."}

        # Manually make request to ensure the correct endpoint config is used
        response = await self._make_request(
            params=params,
            url=selected_endpoint_config["url"], # Override URL with selected endpoint's URL
            method=selected_endpoint_config["method"],
            key_field=selected_endpoint_config["key_field"],
            key_location=selected_endpoint_config["key_location"],
            api_key=selected_endpoint_config["key"],
            fixed_params=selected_endpoint_config.get("fixed_params", {}) # Include fixed params from selected config
        )

        if response and not response.get("error"):
            body = response.get("body")
            if body:
                try:
                    decoded_body = base64.b64decode(body).decode('utf-8', errors='ignore')
                    return f"Crawlbase (contenu web):\n{decoded_body[:1000]}..." # Truncate for brevity
                except Exception:
                    return f"Crawlbase (contenu web - brut):\n{body[:1000]}..."
            return "Crawlbase: Contenu non trouvé."
        return f"Erreur Crawlbase: {response.get('message', 'Inconnu')}" if response else "Crawlbase: Réponse vide."

class DetectLanguageClient(APIClient):
    def __init__(self):
        super().__init__("DETECTLANGUAGE")

    async def query(self, text: str) -> str:
        payload = {"q": text}
        response = await self._make_request(json_data=payload)
        if response and not response.get("error"):
            detections = response.get("data", {}).get("detections", [])
            if detections:
                first_detection = detections[0]
                lang = first_detection.get("language")
                confidence = first_detection.get("confidence")
                return f"Langue détectée: {lang} (confiance: {confidence})"
            return "DetectLanguage: Aucune langue détectée."
        return f"Erreur DetectLanguage: {response.get('message', 'Inconnu')}" if response else "DetectLanguage: Réponse vide."

class GuardianClient(APIClient):
    def __init__(self):
        super().__init__("GUARDIAN")

    async def query(self, query_text: str) -> str:
        params = {"q": query_text}
        response = await self._make_request(params=params)
        if response and not response.get("error"):
            results = response.get("response", {}).get("results", [])
            if results:
                output = "Articles The Guardian:\n"
                for res in results[:3]: # Limit to 3 articles
                    output += f"- {res.get('webTitle', 'N/A')}: {res.get('fields', {}).get('trailText', 'N/A')} {neutralize_urls(res.get('webUrl', ''))}\n"
                return output
            return "Guardian: Aucun article trouvé."
        return f"Erreur Guardian: {response.get('message', 'Inconnu')}" if response else "Guardian: Réponse vide."

class IP2LocationClient(APIClient):
    def __init__(self):
        super().__init__("IP2LOCATION")

    async def query(self, ip_address: str) -> str:
        params = {"ip": ip_address}
        response = await self._make_request(params=params)
        if response and not response.get("error"):
            if "country_name" in response:
                return f"IP2Location (Géolocalisation IP {ip_address}): Pays: {response['country_name']}, Ville: {response.get('city_name', 'N/A')}"
            return "IP2Location: Informations non trouvées."
        return f"Erreur IP2Location: {response.get('message', 'Inconnu')}" if response else "IP2Location: Réponse vide."

class ShodanClient(APIClient):
    def __init__(self):
        super().__init__("SHODAN")

    async def query(self, query_text: str = "") -> str: # Query text is optional, as /api-info doesn't need it
        # Shodan has various endpoints. This example uses /api-info.
        # For actual search, it would be /shodan/host/search or /shodan/scan
        # For simplicity, we'll just query /api-info which tells us about the key.
        response = await self._make_request() # No specific params needed for /api-info
        if response and not response.get("error"):
            return f"Shodan (info clé): Requêtes restantes: {response.get('usage_limits', {}).get('query_credits', 'N/A')}, Scan crédits: {response.get('usage_limits', {}).get('scan_credits', 'N/A')}"
        return f"Erreur Shodan: {response.get('message', 'Inconnu')}" if response else "Shodan: Réponse vide."

class WeatherAPIClient(APIClient):
    def __init__(self):
        super().__init__("WEATHERAPI")

    async def query(self, location: str) -> str:
        params = {"q": location}
        response = await self._make_request(params=params)
        if response and not response.get("error"):
            current = response.get("current", {})
            location_info = response.get("location", {})
            if current and location_info:
                return (
                    f"Météo à {location_info.get('name', 'N/A')}, {location_info.get('country', 'N/A')}:\n"
                    f"Température: {current.get('temp_c', 'N/A')}°C, "
                    f"Conditions: {current.get('condition', {}).get('text', 'N/A')}, "
                    f"Vent: {current.get('wind_kph', 'N/A')} km/h"
                )
            return "WeatherAPI: Données météo non trouvées."
        return f"Erreur WeatherAPI: {response.get('message', 'Inconnu')}" if response else "WeatherAPI: Réponse vide."

class CloudmersiveClient(APIClient):
    def __init__(self):
        super().__init__("CLOUDMERSIVE")

    async def query(self, domain: str) -> str:
        payload = {"domain": domain}
        response = await self._make_request(json_data=payload)
        if response and not response.get("error"):
            return f"Cloudmersive (vérification de domaine {domain}): Valide: {response.get('ValidDomain', 'N/A')}, Type: {response.get('DomainType', 'N/A')}"
        return f"Erreur Cloudmersive: {response.get('message', 'Inconnu')}" if response else "Cloudmersive: Réponse vide."

class GreyNoiseClient(APIClient):
    def __init__(self):
        super().__init__("GREYNOISE")

    async def query(self, ip_address: str) -> str:
        # GreyNoise endpoint requires IP to be part of the URL path
        selected_endpoint_config = endpoint_health_manager.get_best_endpoint(self.name)
        if not selected_endpoint_config:
            return {"error": True, "message": f"Aucun endpoint sain ou disponible pour {self.name}."}

        # Manually construct URL for GreyNoise since IP is path param
        url = f"{selected_endpoint_config['url']}{ip_address}"
        method = selected_endpoint_config["method"]
        headers = {selected_endpoint_config["key_field"]: selected_endpoint_config["key"]}

        try:
            async with httpx.AsyncClient(timeout=30) as client:
                response = await client.request(method, url, headers=headers)
                response.raise_for_status()
                result = response.json()
                
                # Update health for this specific endpoint (not dynamic selection)
                endpoint_key_for_health = f"{selected_endpoint_config['endpoint_name']}-{selected_endpoint_config['key']}"
                endpoint_health_manager.update_endpoint_health(self.name, endpoint_key_for_health, True, response.elapsed.total_seconds())

                if result and not result.get("error"):
                    if result.get("noise"):
                        return f"GreyNoise (IP {ip_address}): C'est une IP 'bruit' (malveillante). Classification: {result.get('classification', 'N/A')}, Nom d'acteur: {result.get('actor', 'N/A')}"
                    return f"GreyNoise (IP {ip_address}): Pas de 'bruit' détecté. Statut: {result.get('status', 'N/A')}"
                return f"Erreur GreyNoise: {result.get('message', 'Inconnu')}" if result else "GreyNoise: Réponse vide."
        except httpx.HTTPStatusError as e:
            log_message(f"API {self.name} erreur HTTP: {e.response.status_code} - {e.response.text}", level="error")
            endpoint_key_for_health = f"{selected_endpoint_config['endpoint_name']}-{selected_endpoint_config['key']}"
            endpoint_health_manager.update_endpoint_health(self.name, endpoint_key_for_health, False, e.response.elapsed.total_seconds() if e.response else 0.0)
            return {"error": True, "status_code": e.response.status_code, "message": e.response.text}
        except Exception as e:
            log_message(f"API {self.name} erreur inattendue: {e}", level="error")
            endpoint_key_for_health = f"{selected_endpoint_config['endpoint_name']}-{selected_endpoint_config['key']}"
            endpoint_health_manager.update_endpoint_health(self.name, endpoint_key_for_health, False, 0.0) # No latency if request failed before sending
            return {"error": True, "message": str(e)}

class PulsediveClient(APIClient):
    def __init__(self):
        super().__init__("PULSEDIVE")

    async def query(self, indicator: str, type: str = "auto") -> str:
        params = {"indicator": indicator, "type": type}
        response = await self._make_request(params=params)
        if response and not response.get("error"):
            if response.get("results"):
                result = response["results"][0]
                return (
                    f"Pulsedive (Analyse {indicator}): Type: {result.get('type', 'N/A')}, "
                    f"Risk: {result.get('risk', 'N/A')}, "
                    f"Description: {result.get('description', 'N/A')[:200]}..."
                )
            return "Pulsedive: Aucun résultat d'analyse trouvé."
        return f"Erreur Pulsedive: {response.get('message', 'Inconnu')}" if response else "Pulsedive: Réponse vide."

class StormGlassClient(APIClient):
    def __init__(self):
        super().__init__("STORMGLASS")

    async def query(self, lat: float, lng: float, params: str = "airTemperature,waveHeight") -> str:
        now = int(time.time())
        request_params = {
            "lat": lat,
            "lng": lng,
            "params": params,
            "start": now,
            "end": now + 3600 # One hour from now
        }
        response = await self._make_request(params=request_params)
        if response and not response.get("error"):
            data = response.get("hours", [])
            if data:
                first_hour = data[0]
                temp = first_hour.get('airTemperature', [{}])[0].get('value', 'N/A')
                wave_height = first_hour.get('waveHeight', [{}])[0].get('value', 'N/A')
                return f"StormGlass (Météo maritime à {lat},{lng}): Température air: {temp}°C, Hauteur vagues: {wave_height}m"
            return "StormGlass: Données non trouvées."
        return f"Erreur StormGlass: {response.get('message', 'Inconnu')}" if response else "StormGlass: Réponse vide."

class LoginRadiusClient(APIClient):
    def __init__(self):
        super().__init__("LOGINRADIUS")

    async def query(self) -> str:
        response = await self._make_request()
        if response and not response.get("error"):
            return f"LoginRadius (Ping API): Statut: {response.get('Status', 'N/A')}, Message: {response.get('Message', 'N/A')}"
        return f"Erreur LoginRadius: {response.get('message', 'Inconnu')}" if response else "LoginRadius: Réponse vide."

class JsonbinClient(APIClient):
    def __init__(self):
        super().__init__("JSONBIN")

    async def query(self, data: Dict[str, Any], private: bool = True, bin_id: Optional[str] = None) -> str:
        # If bin_id is provided, it's a GET request to access a bin
        if bin_id:
            selected_endpoint_config = None
            for config in self.endpoints_config:
                if "Bin Access" in config.get("endpoint_name", ""):
                    selected_endpoint_config = config
                    break
            if not selected_endpoint_config:
                return {"error": True, "message": f"Aucun endpoint d'accès de bin sain ou disponible pour {self.name}."}

            url = f"{selected_endpoint_config['url']}/{bin_id}"
            method = "GET"
            headers = {selected_endpoint_config["key_field"]: selected_endpoint_config["key"]}
            
            response = await self._make_request(
                headers=headers,
                url=url,
                method=method
            )
            if response and not response.get("error"):
                return f"Jsonbin (Accès bin {bin_id}):\n{json.dumps(response, indent=2)}"
            return f"Erreur Jsonbin (Accès bin): {response.get('message', 'Inconnu')}" if response else "Jsonbin: Réponse vide."
        
        # Otherwise, it's a POST request to create a bin
        else:
            selected_endpoint_config = None
            for config in self.endpoints_config:
                if "Bin Create" in config.get("endpoint_name", ""):
                    selected_endpoint_config = config
                    break
            
            if not selected_endpoint_config:
                return {"error": True, "message": f"Aucun endpoint de création de bin sain ou disponible pour {self.name}."}

            url = selected_endpoint_config["url"]
            method = "POST"
            headers = {selected_endpoint_config["key_field"]: selected_endpoint_config["key"], "Content-Type": "application/json"}
            payload = {"record": data, "private": private}

            response = await self._make_request(
                json_data=payload,
                headers=headers,
                url=url,
                method=method
            )

            if response and not response.get("error"):
                return f"Jsonbin (Création de bin): ID: {response.get('metadata', {}).get('id', 'N/A')}, URL: {neutralize_urls(response.get('metadata', {}).get('url', 'N/A'))}"
            return f"Erreur Jsonbin (Création de bin): {response.get('message', 'Inconnu')}" if response else "Jsonbin: Réponse vide."

class HuggingFaceClient(APIClient):
    def __init__(self):
        super().__init__("HUGGINGFACE")

    async def query(self, model_name: str = "distilbert-base-uncased-finetuned-sst-2-english", input_text: str = "Hello world") -> str:
        # HuggingFace inference endpoint URL includes the model name
        selected_endpoint_config = endpoint_health_manager.get_best_endpoint(self.name)
        if not selected_endpoint_config:
            return {"error": True, "message": f"Aucun endpoint sain ou disponible pour {self.name}."}

        # Override URL for inference
        inference_url = f"https://api-inference.huggingface.co/models/{model_name}"
        
        # Ensure the key is added to headers as per config
        headers = {
            selected_endpoint_config["key_field"]: f"{selected_endpoint_config['key_prefix']}{selected_endpoint_config['key']}",
            "Content-Type": "application/json"
        }
        payload = {"inputs": input_text}

        response = await self._make_request(
            json_data=payload,
            headers=headers,
            url=inference_url,
            method="POST" # Inference is always POST
        )

        if response and not response.get("error"):
            if isinstance(response, list) and response:
                first_result = response[0]
                if isinstance(first_result, list) and first_result:
                    return f"HuggingFace ({model_name} - {first_result[0].get('label')}): Score {first_result[0].get('score', 'N/A'):.2f}"
                elif isinstance(first_result, dict) and "generated_text" in first_result:
                    return f"HuggingFace ({model_name}): {first_result.get('generated_text')}"
            return f"HuggingFace ({model_name}): Réponse non parsée. {response}"
        return f"Erreur HuggingFace: {response.get('message', 'Inconnu')}" if response else "HuggingFace: Réponse vide."

class TwilioClient(APIClient):
    def __init__(self):
        super().__init__("TWILIO")

    async def query(self) -> str:
        # Twilio uses Basic Auth, handled by _make_request
        response = await self._make_request()
        if response and not response.get("error"):
            # The balance endpoint returns balance and currency directly
            return f"Twilio (Balance): {response.get('balance', 'N/A')} {response.get('currency', 'N/A')}"
        return f"Erreur Twilio: {response.get('message', 'Inconnu')}" if response else "Twilio: Réponse vide."

class AbstractAPIClient(APIClient):
    def __init__(self):
        super().__init__("ABSTRACTAPI")

    async def query(self, input_value: str, api_type: str) -> str:
        params = {}
        target_endpoint_name = ""

        if api_type == "PHONE_VALIDATION":
            params["phone"] = input_value
            target_endpoint_name = "Phone Validation"
        elif api_type == "EMAIL_VALIDATION":
            params["email"] = input_value
            # Select one of the email validation keys
            target_endpoint_name = "Email Validation"
        elif api_type == "EXCHANGE_RATES":
            target_endpoint_name = "Exchange Rates"
        elif api_type == "HOLIDAYS":
            params["country"] = input_value if input_value else "US"
            params["year"] = datetime.now().year
            target_endpoint_name = "Holidays"
        else:
            return f"AbstractAPI: Type d'API '{api_type}' non supporté pour la requête."

        selected_endpoint_config = None
        for config in self.endpoints_config:
            if target_endpoint_name in config["endpoint_name"]:
                selected_endpoint_config = config
                break
        
        if not selected_endpoint_config:
            return {"error": True, "message": f"Aucun endpoint sain ou disponible pour {self.name} pour le type {api_type}."}

        response = await self._make_request(
            params=params,
            url=selected_endpoint_config["url"],
            method=selected_endpoint_config["method"],
            key_field=selected_endpoint_config["key_field"],
            key_location=selected_endpoint_config["key_location"],
            api_key=selected_endpoint_config["key"],
            fixed_params=selected_endpoint_config.get("fixed_params", {})
        )

        if response and not response.get("error"):
            if api_type == "PHONE_VALIDATION":
                return (
                    f"AbstractAPI (Validation Tél): Numéro: {response.get('phone', 'N/A')}, "
                    f"Valide: {response.get('valid', 'N/A')}, "
                    f"Pays: {response.get('country', {}).get('name', 'N/A')}"
                )
            elif api_type == "EMAIL_VALIDATION":
                return (
                    f"AbstractAPI (Validation Email): Email: {response.get('email', 'N/A')}, "
                    f"Valide: {response.get('is_valid_format', 'N/A')}, "
                    f"Deliverable: {response.get('is_deliverable', 'N/A')}"
                )
            elif api_type == "EXCHANGE_RATES":
                return f"AbstractAPI (Taux de change): Base: {response.get('base', 'N/A')}, Taux (USD): {response.get('exchange_rates', {}).get('USD', 'N/A')}"
            elif api_type == "HOLIDAYS":
                holidays = [h.get('name', 'N/A') for h in response if h.get('name')]
                return f"AbstractAPI (Jours fériés {params.get('country', 'US')} {params.get('year')}): {', '.join(holidays[:5])}..." if holidays else "Aucun jour férié trouvé."
            return f"AbstractAPI ({api_type}): Réponse brute: {response}"
        return f"Erreur AbstractAPI ({api_type}): {response.get('message', 'Inconnu')}" if response else "AbstractAPI: Réponse vide."

class GeminiAPIClient(APIClient):
    def __init__(self):
        super().__init__("GEMINI_API")

    async def query(self, prompt: str, model: str = "gemini-1.5-flash") -> str:
        payload = {"contents": [{"parts": [{"text": prompt}]}]}
        # Gemini API often requires the model name in the URL path
        selected_endpoint_config = endpoint_health_manager.get_best_endpoint(self.name)
        if not selected_endpoint_config:
            return {"error": True, "message": f"Aucun endpoint sain ou disponible pour {self.name}."}

        # Override URL for specific model generation
        generate_url = f"https://generativelanguage.googleapis.com/v1beta/models/{model}:generateContent"
        
        # Ensure the key is added to params as per config
        request_params = {selected_endpoint_config["key_field"]: selected_endpoint_config["key"]}

        response = await self._make_request(
            json_data=payload,
            params=request_params,
            url=generate_url,
            method="POST",
            timeout=60 # Longer timeout for LLM calls
        )

        if response and not response.get("error"):
            if response.get("candidates") and response["candidates"][0].get("content"):
                return response["candidates"][0]["content"]["parts"][0]["text"]
            return f"Gemini API: Pas de réponse générée. {response}"
        return f"Erreur Gemini API: {response.get('message', 'Inconnu')}" if response else "Gemini API: Réponse vide."

class GoogleCustomSearchClient(APIClient):
    def __init__(self):
        super().__init__("GOOGLE_CUSTOM_SEARCH")

    async def query(self, query_text: str) -> str:
        params = {"q": query_text}
        response = await self._make_request(params=params)
        if response and not response.get("error"):
            items = response.get("items", [])
            if items:
                output = "Google Custom Search:\n"
                for item in items[:3]: # Limit to 3 results
                    output += f"- {item.get('title', 'N/A')}: {item.get('snippet', 'N/A')} {neutralize_urls(item.get('link', ''))}\n"
                return output
            return "Google Custom Search: Aucun résultat trouvé."
        return f"Erreur Google Custom Search: {response.get('message', 'Inconnu')}" if response else "Google Custom Search: Réponse vide."

class OpenRouterClient(APIClient):
    def __init__(self):
        super().__init__("OPENROUTER")

    async def query(self, prompt: str, model: str = "mistralai/mistral-7b-instruct") -> str:
        payload = {"model": model, "messages": [{"role": "user", "content": prompt}]}
        response = await self._make_request(json_data=payload)
        if response and not response.get("error"):
            return response.get("choices", [{}])[0].get("message", {}).get("content", "Pas de réponse d'OpenRouter.")
        return f"Erreur OpenRouter: {response.get('message', 'Inconnu')}" if response else "OpenRouter: Réponse vide."

class RandommerClient(APIClient):
    def __init__(self):
        super().__init__("RANDOMMER")

    async def query(self, country_code: str = "US", quantity: int = 1) -> str:
        params = {"CountryCode": country_code, "Quantity": quantity}
        response = await self._make_request(params=params)
        if response and not response.get("error"):
            if isinstance(response, list) and response:
                return f"Randommer (Numéros de téléphone): {', '.join(response)}"
            return f"Randommer: {response}"
        return f"Erreur Randommer: {response.get('message', 'Inconnu')}" if response else "Randommer: Réponse vide."

class TomorrowIOClient(APIClient):
    def __init__(self):
        super().__init__("TOMORROW.IO")

    async def query(self, location: str, fields: List[str] = None) -> str:
        if fields is None:
            fields = ["temperature", "humidity", "windSpeed"]
        payload = {"location": location, "fields": fields, "units": "metric", "timesteps": ["1h"]}
        response = await self._make_request(json_data=payload)
        if response and not response.get("error"):
            data = response.get("data", {}).get("timelines", [{}])[0].get("intervals", [{}])[0].get("values", {})
            if data:
                output = f"Météo (Tomorrow.io) à {location}:\n"
                for field in fields:
                    output += f"- {field.capitalize()}: {data.get(field, 'N/A')}\n"
                return output
            return "Tomorrow.io: Données météo non trouvées."
        return f"Erreur Tomorrow.io: {response.get('message', 'Inconnu')}" if response else "Tomorrow.io: Réponse vide."

class OpenWeatherMapClient(APIClient):
    def __init__(self):
        super().__init__("OPENWEATHERMAP")

    async def query(self, location: str) -> str:
        params = {"q": location}
        response = await self._make_request(params=params)
        if response and not response.get("error"):
            main_data = response.get("main", {})
            weather_desc = response.get("weather", [{}])[0].get("description", "N/A")
            if main_data:
                return (
                    f"Météo (OpenWeatherMap) à {location}:\n"
                    f"Température: {main_data.get('temp', 'N/A')}°C, "
                    f"Ressenti: {main_data.get('feels_like', 'N/A')}°C, "
                    f"Humidité: {main_data.get('humidity', 'N/A')}%, "
                    f"Conditions: {weather_desc}"
                )
            return "OpenWeatherMap: Données météo non trouvées."
        return f"Erreur OpenWeatherMap: {response.get('message', 'Inconnu')}" if response else "OpenWeatherMap: Réponse vide."

class MockarooClient(APIClient):
    def __init__(self):
        super().__init__("MOCKAROO")

    async def query(self, count: int = 1, fields_json: str = None) -> str:
        # Mockaroo's 'fields' parameter often expects a JSON string, which needs to be URL-encoded for GET requests.
        # The default fixed_params already include a basic fields_json.
        params = {"count": count}
        if fields_json:
            params["fields"] = fields_json # Override default if provided

        response = await self._make_request(params=params)
        if response and not response.get("error"):
            return f"Mockaroo (Génération de données):\n{json.dumps(response, indent=2)}"
        return f"Erreur Mockaroo: {response.get('message', 'Inconnu')}" if response else "Mockaroo: Réponse vide."

class OpenPageRankClient(APIClient):
    def __init__(self):
        super().__init__("OPENPAGERANK")

    async def query(self, domains: List[str]) -> str:
        params = {"domains[]": domains}
        response = await self._make_request(params=params)
        if response and not response.get("error"):
            results = response.get("response", [])
            if results:
                output = "OpenPageRank (Classement de domaine):\n"
                for res in results:
                    output += f"- Domaine: {res.get('domain', 'N/A')}, PageRank: {res.get('page_rank', 'N/A')}\n"
                return output
            return "OpenPageRank: Aucun résultat trouvé."
        return f"Erreur OpenPageRank: {response.get('message', 'Inconnu')}" if response else "OpenPageRank: Réponse vide."

class RapidAPIClient(APIClient):
    def __init__(self):
        super().__init__("RAPIDAPI")

    async def query(self, api_name: str, **kwargs) -> str:
        # RapidAPI is a marketplace, so we need to select the specific API endpoint
        # based on 'api_name' argument.
        selected_endpoint_config = None
        for config in self.endpoints_config:
            if api_name.lower() in config["endpoint_name"].lower():
                selected_endpoint_config = config
                break
        
        if not selected_endpoint_config:
            return f"RapidAPI: Endpoint pour '{api_name}' non trouvé ou non configuré."

        # Manually build request based on selected_endpoint_config
        url = selected_endpoint_config["url"]
        method = selected_endpoint_config["method"]
        
        request_params = selected_endpoint_config.get("fixed_params", {}).copy()
        request_headers = selected_endpoint_config.get("fixed_headers", {}).copy()
        request_json_data = selected_endpoint_config.get("fixed_json", {}).copy()

        # Add dynamic kwargs to params/json_data
        if method == "GET":
            request_params.update(kwargs)
        elif method == "POST":
            request_json_data.update(kwargs)

        headers = {
            selected_endpoint_config["key_field"]: selected_endpoint_config["key"],
            "X-RapidAPI-Host": selected_endpoint_config["fixed_headers"].get("X-RapidAPI-Host") # Specific to RapidAPI
        }
        
        response = await self._make_request(
            params=request_params,
            headers=headers,
            json_data=request_json_data,
            url=url,
            method=method
        )

        if response and not response.get("error"):
            if api_name.lower() == "programming joke":
                return f"RapidAPI (Blague de Programmation): {response.get('setup', '')} - {response.get('punchline', '')}"
            elif api_name.lower() == "currency list quotes":
                return f"RapidAPI (Devises): {json.dumps(response, indent=2)}"
            elif api_name.lower() == "random fact":
                return f"RapidAPI (Fait Aléatoire): {response.get('text', 'N/A')}"
            return f"RapidAPI ({api_name}): {json.dumps(response, indent=2)}"
        return f"Erreur RapidAPI ({api_name}): {response.get('message', 'Inconnu')}" if response else "RapidAPI: Réponse vide."

# --- Instancier tous les clients API ---
ALL_API_CLIENTS = [
    DeepSeekClient(),
    SerperClient(),
    WolframAlphaClient(),
    TavilyClient(),
    ApiFlashClient(),
    CrawlbaseClient(),
    DetectLanguageClient(),
    GuardianClient(),
    IP2LocationClient(),
    ShodanClient(),
    WeatherAPIClient(),
    CloudmersiveClient(),
    GreyNoiseClient(),
    PulsediveClient(),
    StormGlassClient(),
    LoginRadiusClient(),
    JsonbinClient(),
    HuggingFaceClient(),
    TwilioClient(),
    AbstractAPIClient(),
    GeminiAPIClient(),
    GoogleCustomSearchClient(),
    OpenRouterClient(),
    RandommerClient(),
    TomorrowIOClient(),
    OpenWeatherMapClient(),
    MockarooClient(),
    OpenPageRankClient(),
    RapidAPIClient()
]

# --- FIN DU BLOC CLIENTS API SPECIFIQUES ---
# --- DEBUT DU BLOC GESTION MEMOIRE ET QUOTAS ---

class MemoryManager:
    def __init__(self):
        self.chat_history = load_json(HISTORY_FILE, [])
        self.long_term_memory = load_json(LONG_MEMORY_FILE, {})
        self.ia_status = load_json(IA_STATUS_FILE, {})
        self._initialize_ia_status()

    def _initialize_ia_status(self):
        """Initialise le statut des IA si elles ne sont pas déjà présentes ou si leur statut est obsolète."""
        now = get_current_time()
        updated = False
        for client in ALL_API_CLIENTS:
            if client.name not in self.ia_status:
                self.ia_status[client.name] = {
                    "last_used": None,
                    "last_error": None,
                    "error_count": 0,
                    "cooldown_until": None,
                    "success_count": 0,
                    "current_score": 1.0,
                    "last_rotation_check": format_datetime(now),
                    "diversification_score": 1.0 # Nouveau score pour la diversification
                }
                updated = True
            else:
                # S'assurer que les nouvelles clés existent pour les IA existantes
                if "success_count" not in self.ia_status[client.name]:
                    self.ia_status[client.name]["success_count"] = 0
                    updated = True
                if "current_score" not in self.ia_status[client.name]:
                    self.ia_status[client.name]["current_score"] = 1.0
                    updated = True
                if "last_rotation_check" not in self.ia_status[client.name]:
                    self.ia_status[client.name]["last_rotation_check"] = format_datetime(now)
                    updated = True
                if "diversification_score" not in self.ia_status[client.name]:
                    self.ia_status[client.name]["diversification_score"] = 1.0
                    updated = True

        if updated:
            save_json(IA_STATUS_FILE, self.ia_status)
            log_message("Statut des IA initialisé/mis à jour.")

    def add_message_to_history(self, role, content):
        """Ajoute un message à l'historique de la conversation."""
        self.chat_history.append({"role": role, "content": content, "timestamp": format_datetime(get_current_time())})
        self._prune_history()
        save_json(HISTORY_FILE, self.chat_history)
        log_message(f"Message ajouté à l'historique par {role}.")

    def get_chat_history(self, limit=10):
        """Retourne les N derniers messages de l'historique."""
        return self.chat_history[-limit:]

    def add_to_long_term_memory(self, key, value):
        """Ajoute une information à la mémoire à long terme."""
        self.long_term_memory[key] = {"value": value, "timestamp": format_datetime(get_current_time())}
        save_json(LONG_MEMORY_FILE, self.long_term_memory)
        log_message(f"Information ajoutée à la mémoire à long terme: {key}")

    def get_from_long_term_memory(self, key):
        """Récupère une information de la mémoire à long terme."""
        return self.long_term_memory.get(key)

    def update_ia_status(self, ia_name: str, success: bool, error_message: Optional[str] = None):
        """Met à jour le statut et le score d'une IA après une utilisation."""
        status = self.ia_status.get(ia_name)
        if not status:
            log_message(f"Tentative de mise à jour d'un statut d'IA inconnu: {ia_name}", level="warning")
            return

        now = get_current_time()
        status["last_used"] = format_datetime(now)

        if success:
            status["success_count"] += 1
            status["error_count"] = 0
            status["cooldown_until"] = None
            status["last_error"] = None
            status["current_score"] = min(1.0, status["current_score"] + 0.1)
            status["diversification_score"] = max(0.1, status["diversification_score"] - 0.1) # Decrease diversification score on use
            log_message(f"IA {ia_name} : Succès enregistré. Nouveau score: {status['current_score']:.2f}, Diversification: {status['diversification_score']:.2f}")
        else:
            status["error_count"] += 1
            status["last_error"] = error_message
            if status["error_count"] >= 3:
                status["cooldown_until"] = format_datetime(now + timedelta(seconds=API_COOLDOWN_DURATION_SECONDS))
                status["current_score"] = max(0.1, status["current_score"] - 0.2)
                log_message(f"IA {ia_name} : Trop d'erreurs ({status['error_count']}). Cooldown jusqu'à {status['cooldown_until']}. Nouveau score: {status['current_score']:.2f}", level="warning")
            else:
                 status["current_score"] = max(0.1, status["current_score"] - 0.05)
                 log_message(f"IA {ia_name} : Erreur enregistrée. Nouveau score: {status['current_score']:.2f}", level="warning")

        save_json(IA_STATUS_FILE, self.ia_status)

    def recover_diversification_scores(self):
        """Augmente le score de diversification pour les IA non utilisées récemment."""
        now = get_current_time()
        updated = False
        for ia_name, status in self.ia_status.items():
            last_used_str = status.get("last_used")
            if last_used_str:
                last_used_dt = datetime.strptime(last_used_str, "%Y-%m-%d %H:%M:%S UTC")
                # If not used in the last API_ROTATION_INTERVAL_MINUTES * 2 (e.g., 60 mins), recover score
                if (now - last_used_dt).total_seconds() > API_ROTATION_INTERVAL_MINUTES * 60 * 2:
                    if status["diversification_score"] < 1.0:
                        status["diversification_score"] = min(1.0, status["diversification_score"] + 0.05)
                        updated = True
                        log_message(f"IA {ia_name}: Score de diversification récupéré à {status['diversification_score']:.2f}")
            else: # Never used, ensure it's at max
                if status["diversification_score"] < 1.0:
                    status["diversification_score"] = 1.0
                    updated = True
        if updated:
            save_json(IA_STATUS_FILE, self.ia_status)

    def get_ia_status(self, ia_name: str) -> Optional[Dict]:
        """Récupère le statut d'une IA."""
        return self.ia_status.get(ia_name)

    def get_available_ias(self) -> List[str]:
        """Retourne les noms des IA actuellement non en cooldown."""
        available = []
        now = get_current_time()
        for name, status in self.ia_status.items():
            cooldown_until_str = status.get("cooldown_until")
            if cooldown_until_str:
                cooldown_until = datetime.strptime(cooldown_until_str, "%Y-%m-%d %H:%M:%S UTC")
                if now < cooldown_until:
                    continue
            available.append(name)
        return available

    def _prune_history(self, max_entries=50):
        """Supprime les anciennes entrées de l'historique si trop nombreuses."""
        if len(self.chat_history) > max_entries:
            self.chat_history = self.chat_history[-max_entries:]
            log_message(f"Historique de chat purgé, {len(self.chat_history)} entrées restantes.")

class QuotaManager:
    def __init__(self):
        self.quotas = load_json(QUOTAS_FILE, {})
        self._initialize_quotas()

    def _initialize_quotas(self):
        """Initialise les quotas pour toutes les APIs basées sur config.API_QUOTAS."""
        updated = False
        now = get_current_time()
        for api_name, quota_info in API_QUOTAS.items():
            if api_name not in self.quotas:
                self.quotas[api_name] = {
                    "monthly_usage": 0,
                    "daily_usage": 0,
                    "hourly_usage": 0, # Nouveau
                    "hourly_timestamps": [], # Nouveau
                    "last_reset_month": now.month,
                    "last_reset_day": now.day,
                    "last_usage": None,
                    "total_calls": 0,
                    "last_hourly_reset": format_datetime(now)
                }
                updated = True
            else:
                # S'assurer que les nouvelles clés existent pour les APIs existantes
                if "hourly_usage" not in self.quotas[api_name]:
                    self.quotas[api_name]["hourly_usage"] = 0
                    updated = True
                if "hourly_timestamps" not in self.quotas[api_name]:
                    self.quotas[api_name]["hourly_timestamps"] = []
                    updated = True
                if "last_hourly_reset" not in self.quotas[api_name]:
                    self.quotas[api_name]["last_hourly_reset"] = format_datetime(now)
                    updated = True
                if "total_calls" not in self.quotas[api_name]:
                    self.quotas[api_name]["total_calls"] = 0
                    updated = True

        if updated:
            save_json(QUOTAS_FILE, self.quotas)
            log_message("Quotas API initialisés/mis à jour.")

    def _reset_quotas_if_needed(self):
        """Réinitialise les quotas journaliers, mensuels et horaires si nécessaire."""
        now = get_current_time()
        for api_name, data in self.quotas.items():
            # Reset mensuel
            if now.month != data["last_reset_month"]:
                data["monthly_usage"] = 0
                data["last_reset_month"] = now.month
                log_message(f"Quota mensuel pour {api_name} réinitialisé.")
            # Reset journalier
            if now.day != data["last_reset_day"]:
                data["daily_usage"] = 0
                data["last_reset_day"] = now.day
                log_message(f"Quota journalier pour {api_name} réinitialisé.")
            
            # Reset et gestion horaire (nettoyage des timestamps trop anciens)
            one_hour_ago = now - timedelta(hours=1)
            # Filter out timestamps older than one hour
            data["hourly_timestamps"] = [
                ts for ts in data["hourly_timestamps"] 
                if datetime.strptime(ts, "%Y-%m-%d %H:%M:%S UTC").replace(tzinfo=None) > one_hour_ago
            ]
            data["hourly_usage"] = len(data["hourly_timestamps"])
            
            # Update last_hourly_reset to current time if a reset happened or after cleanup
            data["last_hourly_reset"] = format_datetime(now)

        save_json(QUOTAS_FILE, self.quotas)

    def check_and_update_quota(self, api_name: str, cost: int = 1) -> bool:
        """Vérifie si une API a du quota et le décrémente. Retourne True si ok, False sinon."""
        self._reset_quotas_if_needed()
        if api_name not in self.quotas:
            log_message(f"API {api_name} non trouvée dans les quotas définis. Autorisation.", level="warning")
            return True

        quota_data = self.quotas[api_name]
        api_limits = API_QUOTAS.get(api_name, {})
        now = get_current_time()

        monthly_limit = api_limits.get("monthly")
        if monthly_limit is not None and (quota_data["monthly_usage"] + cost) > monthly_limit:
            log_message(f"Quota mensuel dépassé pour {api_name}", level="warning")
            return False

        daily_limit = api_limits.get("daily")
        if daily_limit is not None and (quota_data["daily_usage"] + cost) > daily_limit:
            log_message(f"Quota journalier dépassé pour {api_name}", level="warning")
            return False
        
        hourly_limit = api_limits.get("hourly")
        if hourly_limit is not None and (quota_data["hourly_usage"] + cost) > hourly_limit:
            log_message(f"Quota horaire dépassé pour {api_name}", level="warning")
            return False

        rate_limit_per_sec = api_limits.get("rate_limit_per_sec")
        if rate_limit_per_sec:
            last_usage_str = quota_data.get("last_usage")
            if last_usage_str:
                last_usage = datetime.strptime(last_usage_str, "%Y-%m-%d %H:%M:%S UTC").replace(tzinfo=None)
                time_since_last_call = (now - last_usage).total_seconds()
                if time_since_last_call < (1 / rate_limit_per_sec):
                    log_message(f"Taux de requêtes dépassé pour {api_name}. Attendre {1/rate_limit_per_sec - time_since_last_call:.2f}s", level="warning")
                    return False

        quota_data["monthly_usage"] += cost
        quota_data["daily_usage"] += cost
        quota_data["hourly_usage"] += cost
        quota_data["hourly_timestamps"].append(format_datetime(now)) # Add current timestamp
        quota_data["total_calls"] += cost
        quota_data["last_usage"] = format_datetime(now)
        save_json(QUOTAS_FILE, self.quotas)
        log_message(f"Quota pour {api_name} mis à jour. Usage mensuel: {quota_data['monthly_usage']}/{monthly_limit if monthly_limit else 'Illimité'}, Journalier: {quota_data['daily_usage']}/{daily_limit if daily_limit else 'Illimité'}, Horaire: {quota_data['hourly_usage']}/{hourly_limit if hourly_limit else 'Illimité'}")
        return True

    def get_api_usage(self, api_name: str) -> Optional[Dict]:
        """Retourne les informations d'utilisation d'une API."""
        return self.quotas.get(api_name)

    def get_all_quotas_status(self) -> Dict:
        """Retourne le statut de tous les quotas."""
        self._reset_quotas_if_needed()
        status = {}
        for api_name, quota_data in self.quotas.items():
            api_limits = API_QUOTAS.get(api_name, {})
            monthly_limit = api_limits.get("monthly", "Illimité")
            daily_limit = api_limits.get("daily", "Illimité")
            hourly_limit = api_limits.get("hourly", "Illimité")
            status[api_name] = {
                "monthly_usage": quota_data["monthly_usage"],
                "monthly_limit": monthly_limit,
                "daily_usage": quota_data["daily_usage"],
                "daily_limit": daily_limit,
                "hourly_usage": quota_data["hourly_usage"], # New
                "hourly_limit": hourly_limit,
                "total_calls": quota_data["total_calls"],
                "last_usage": quota_data["last_usage"],
                "last_reset_month": quota_data["last_reset_month"],
                "last_reset_day": quota_data["last_reset_day"],
                "last_hourly_reset": quota_data["last_hourly_reset"]
            }
        return status

    def get_burn_window_apis(self) -> List[str]:
        """
        Identifie les APIs dont les quotas sont sur le point d'être réinitialisés
        et où il est opportun de "brûler" le quota restant.
        """
        burn_apis = []
        now = get_current_time()
        for api_name, data in self.quotas.items():
            api_limits = API_QUOTAS.get(api_name, {})

            if api_limits.get("monthly") is not None:
                next_month_reset = datetime(now.year + (1 if now.month == 12 else 0), (now.month % 12) + 1, 1).replace(tzinfo=None)
                if is_within_time_window(next_month_reset, QUOTA_BURN_WINDOW_HOURS * 60, 0):
                    if data["monthly_usage"] < api_limits["monthly"]:
                        burn_apis.append(f"{api_name} (mensuel: {api_limits['monthly'] - data['monthly_usage']} restants)")

            if api_limits.get("daily") is not None:
                next_day_reset = datetime(now.year, now.month, now.day).replace(tzinfo=None) + timedelta(days=1)
                if is_within_time_window(next_day_reset, QUOTA_BURN_WINDOW_HOURS * 60, 0):
                    if data["daily_usage"] < api_limits["daily"]:
                        burn_apis.append(f"{api_name} (journalier: {api_limits['daily'] - data['daily_usage']} restants)")
        return burn_apis

# Instanciation des gestionnaires
memory_manager = MemoryManager()
quota_manager = QuotaManager()

# --- FIN DU BLOC GESTION MEMOIRE ET QUOTAS ---

# --- DEBUT DU BLOC BOT TELEGRAM PRINCIPAL ---

import time
from telegram import Update, ForceReply
from telegram.ext import Application, CommandHandler, MessageHandler, filters, ContextTypes

# --- Orchestration des IA ---
class IAOrchestrator:
    def __init__(self, memory_manager: MemoryManager, quota_manager: QuotaManager, api_clients: List[APIClient]):
        self.memory_manager = memory_manager
        self.quota_manager = quota_manager
        self.api_clients = {client.name: client for client in api_clients}
        self.last_strategy_rotation_time = get_current_time()
        self.current_ia_strategy = self._determine_initial_strategy()

        # Les quatre moteurs IA principaux (maintenant cinq avec Gemini)
        self.core_ai_engines = {
            "DEEPSEEK": self.api_clients.get("DEEPSEEK"),
            "HUGGINGFACE": self.api_clients.get("HUGGINGFACE"),
            "GOOGLE_CUSTOM_SEARCH": self.api_clients.get("GOOGLE_CUSTOM_SEARCH"),
            "OPENROUTER": self.api_clients.get("OPENROUTER"),
            "GEMINI_API": self.api_clients.get("GEMINI_API") # Ajout de Gemini
        }
        # Filtrer les clients None si l'API n'est pas configurée
        self.core_ai_engines = {k: v for k, v in self.core_ai_engines.items() if v is not None}

        # Définir les "agents mixtes" et leurs capacités (simplified for example)
        # En réalité, ceci serait un système de routing basé sur des modèles NLP plus complexes.
        self.mixed_agents = [
            {"name": "GeneralQueryAgent", "primary_ais": ["DEEPSEEK", "OPENROUTER", "GEMINI_API"], "tools": ["SERPER", "TAVILY", "WOLFRAMALPHA", "WEATHERAPI", "OPENWEATHERMAP"]},
            {"name": "CodingAgent", "primary_ais": ["DEEPSEEK", "HUGGINGFACE", "OPENROUTER", "GEMINI_API"], "tools": []}, # Tools are sandbox/analyzer
            {"name": "SecurityAgent", "primary_ais": ["DEEPSEEK", "OPENROUTER"], "tools": ["IP2LOCATION", "SHODAN", "GREYNOISE", "PULSEDIVE", "CLOUDMERSIVE"]},
            {"name": "DataAgent", "primary_ais": ["DEEPSEEK", "OPENROUTER"], "tools": ["JSONBIN", "MOCKAROO", "RANDOMMER", "OPENPAGERANK", "RAPIDAPI"]},
            {"name": "CommunicationAgent", "primary_ais": ["DEEPSEEK", "OPENROUTER"], "tools": ["TWILIO", "ABSTRACTAPI"]},
            {"name": "NewsAgent", "primary_ais": ["DEEPSEEK", "OPENROUTER"], "tools": ["GUARDIAN", "SERPER", "TAVILY"]},
            {"name": "ImageAgent", "primary_ais": ["DEEPSEEK", "OPENROUTER"], "tools": ["APIFLASH"]}, # OCR tool is separate
            {"name": "LanguageAgent", "primary_ais": ["DEEPSEEK", "OPENROUTER"], "tools": ["DETECTLANGUAGE"]},
            {"name": "WeatherAgent", "primary_ais": ["DEEPSEEK", "OPENROUTER"], "tools": ["WEATHERAPI", "STORMGLASS", "TOMORROW.IO", "OPENWEATHERMAP"]}
        ]
        self.current_agent_index = 0
        self.last_agent_rotation_time = get_current_time()

        # Tool descriptions for AI
        self.tool_descriptions = {
            "SERPER": "Effectue une recherche web sur Google et retourne les snippets et liens pertinents. Paramètres: {\"query\": \"texte de recherche\"}",
            "TAVILY": "Effectue une recherche web avancée et retourne une réponse directe et des extraits. Paramètres: {\"query\": \"texte de recherche\", \"max_results\": nombre}",
            "WOLFRAMALPHA": "Répond à des questions factuelles et calculs complexes. Paramètres: {\"input\": \"question ou calcul\"}",
            "WEATHERAPI": "Fournit la météo actuelle et les prévisions pour une localisation donnée. Paramètres: {\"location\": \"nom de la ville ou code postal\"}",
            "OPENWEATHERMAP": "Fournit la météo actuelle pour une localisation donnée. Paramètres: {\"location\": \"nom de la ville ou code postal\"}",
            "STORMGLASS": "Fournit des données météorologiques maritimes (température, vagues) pour des coordonnées lat/lng. Paramètres: {\"lat\": latitude, \"lng\": longitude, \"params\": \"airTemperature,waveHeight\"}",
            "APIFLASH": "Prend une capture d'écran d'une URL et retourne l'URL de l'image. Paramètres: {\"url\": \"URL du site\"}",
            "CRAWLBASE": "Récupère le contenu HTML ou JavaScript d'une URL. Paramètres: {\"url\": \"URL du site\", \"use_js\": true/false}",
            "DETECTLANGUAGE": "Détecte la langue d'un texte. Paramètres: {\"text\": \"texte à analyser\"}",
            "IP2LOCATION": "Géolocalise une adresse IP. Paramètres: {\"ip_address\": \"adresse IP\"}",
            "SHODAN": "Fournit des informations sur les hôtes et les services exposés sur Internet. Paramètres: {\"query\": \"texte de recherche\"} (optionnel)",
            "GREYNOISE": "Analyse une adresse IP pour déterminer si elle est 'bruit' (malveillante). Paramètres: {\"ip_address\": \"adresse IP\"}",
            "PULSEDIVE": "Analyse des indicateurs de menace (IP, domaine, URL). Paramètres: {\"indicator\": \"indicateur\", \"type\": \"auto\"}",
            "CLOUDMERSIVE": "Vérifie la validité d'un nom de domaine. Paramètres: {\"domain\": \"nom de domaine\"}",
            "JSONBIN": "Stocke ou récupère des données JSON dans un 'bin' privé ou public. Pour créer: {\"data\": {\"clé\": \"valeur\"}, \"private\": true/false}. Pour accéder: {\"bin_id\": \"ID du bin\"}",
            "MOCKAROO": "Génère des données de test aléatoires basées sur des schémas. Paramètres: {\"count\": nombre, \"fields_json\": \"[{\"name\": \"champ\", \"type\": \"Type Mockaroo\"}]\"}",
            "RANDOMMER": "Génère des données aléatoires, comme des numéros de téléphone. Paramètres: {\"country_code\": \"US\", \"quantity\": 1}",
            "OPENPAGERANK": "Récupère le PageRank d'un ou plusieurs domaines. Paramètres: {\"domains\": [\"domaine1.com\", \"domaine2.com\"]}",
            "RAPIDAPI": "Accède à diverses micro-APIs (blagues, faits, devises). Nécessite un 'api_name' (ex: 'Programming Joke'). Paramètres: {\"api_name\": \"Nom de l'API\", \"kwargs\": {\"param1\": \"valeur1\"}}",
            "TWILIO": "Vérifie le solde du compte Twilio. Paramètres: Aucun",
            "ABSTRACTAPI": "Valide des emails, numéros de téléphone, géolocalise des IPs, ou fournit des taux de change/jours fériés. Paramètres: {\"input_value\": \"valeur\", \"api_type\": \"EMAIL_VALIDATION\"|\"PHONE_VALIDATION\"|\"EXCHANGE_RATES\"|\"HOLIDAYS\"}"
        }

    def _determine_initial_strategy(self) -> str:
        """Détermine la stratégie initiale ou la stratégie par défaut."""
        return "balanced"

    def _rotate_strategy_if_needed(self):
        """Change la stratégie d'IA et l'agent si l'intervalle de rotation est passé."""
        now = get_current_time()
        if (now - self.last_strategy_rotation_time).total_seconds() >= API_ROTATION_INTERVAL_MINUTES * 60:
            strategies = ["balanced", "cost_effective", "performance"]
            self.current_ia_strategy = random.choice(strategies)
            self.last_strategy_rotation_time = now
            log_message(f"Stratégie d'IA changée pour: {self.current_ia_strategy}")

            # Rotation des agents mixtes
            self.current_agent_index = (self.current_agent_index + 1) % len(self.mixed_agents)
            self.last_agent_rotation_time = now
            log_message(f"Agent mixte actuel: {self.mixed_agents[self.current_agent_index]['name']}")

            # Mettre à jour le last_rotation_check pour toutes les IA et récupérer les scores de diversification
            for ia_name in self.memory_manager.ia_status:
                self.memory_manager.ia_status[ia_name]["last_rotation_check"] = format_datetime(now)
            self.memory_manager.recover_diversification_scores() # Recover diversification scores
            save_json(IA_STATUS_FILE, self.memory_manager.ia_status)

    async def _select_primary_ai_for_agent(self, agent_config: Dict) -> Optional[APIClient]:
        """Sélectionne une IA primaire parmi celles de l'agent, en tenant compte des quotas, de la santé et de la diversification."""
        available_primary_ais = []
        for ai_name in agent_config["primary_ais"]:
            if ai_name in self.core_ai_engines:
                status = self.memory_manager.get_ia_status(ai_name)
                if status and (status.get("cooldown_until") is None or datetime.strptime(status["cooldown_until"], "%Y-%m-%d %H:%M:%S UTC").replace(tzinfo=None) < get_current_time()):
                    if self.quota_manager.check_and_update_quota(ai_name, cost=0): # Check quota without consuming
                        available_primary_ais.append((ai_name, status["current_score"], status["diversification_score"]))
        
        if not available_primary_ais:
            log_message(f"Aucune IA primaire disponible pour l'agent {agent_config['name']}.", level="warning")
            return None

        # Sélection basée sur la stratégie globale
        selected_ai_name = None
        if self.current_ia_strategy == "balanced":
            # Choisir l'IA avec le meilleur score combiné (current_score + diversification_score)
            available_primary_ais.sort(key=lambda x: x[1] + x[2], reverse=True)
            selected_ai_name = available_primary_ais[0][0]
        elif self.current_ia_strategy == "cost_effective":
            # Prioriser les IA avec des quotas élevés ou illimités, puis le meilleur score
            cost_effective_ais = []
            for ai_name, current_score, diversification_score in available_primary_ais:
                api_limits = API_QUOTAS.get(ai_name, {})
                if api_limits.get("monthly") is None and api_limits.get("daily") is None and api_limits.get("hourly") is None:
                    cost_effective_ais.append((ai_name, current_score, diversification_score))
            if cost_effective_ais:
                cost_effective_ais.sort(key=lambda x: x[1] + x[2], reverse=True)
                selected_ai_name = cost_effective_ais[0][0]
            else: # Fallback au mode équilibré si pas de "pas cher" dispo
                available_primary_ais.sort(key=lambda x: x[1] + x[2], reverse=True)
                selected_ai_name = available_primary_ais[0][0]
        elif self.current_ia_strategy == "performance":
            # Prioriser l'IA avec le plus grand nombre de succès récents comme proxy de performance
            performance_ais = []
            for ai_name, current_score, diversification_score in available_primary_ais:
                status = self.memory_manager.get_ia_status(ai_name)
                performance_ais.append((ai_name, status["success_count"]))
            performance_ais.sort(key=lambda x: x[1], reverse=True)
            selected_ai_name = performance_ais[0][0]
        
        # Vérifier et consommer le quota pour l'IA sélectionnée
        if selected_ai_name and self.quota_manager.check_and_update_quota(selected_ai_name):
            log_message(f"IA primaire sélectionnée pour l'agent: {selected_ai_name} (Stratégie: {self.current_ia_strategy})")
            return self.core_ai_engines[selected_ai_name]
        return None

    async def _run_agent_with_tools(self, agent_config: Dict, query: str) -> str:
        """
        Exécute l'agent mixte en utilisant l'IA primaire sélectionnée
        et en sollicitant les outils pertinents.
        """
        primary_ai_client = await self._select_primary_ai_for_agent(agent_config)
        if not primary_ai_client:
            return f"Désolé, l'agent {agent_config['name']} ne peut pas opérer car aucune IA primaire n'est disponible."

        responses = []
        tools_called_for_report = []
        
        # Prepare tool descriptions for the AI
        available_tools_for_ai = {}
        for tool_name in agent_config.get("tools", []):
            if tool_name in self.tool_descriptions and self.api_clients.get(tool_name):
                available_tools_for_ai[tool_name] = self.tool_descriptions[tool_name]
        
        tool_prompt_part = ""
        if available_tools_for_ai:
            tool_prompt_part = "\n\nTu as accès aux outils suivants:\n"
            for tool_name, desc in available_tools_for_ai.items():
                tool_prompt_part += f"- **{tool_name}**: {desc}\n"
            tool_prompt_part += "\nSi tu as besoin d'utiliser un outil, réponds avec le format suivant: `TOOL_CALL:<nom_outil>:<paramètres_json>`. Par exemple: `TOOL_CALL:WEATHERAPI:{\"location\": \"Paris\"}`. Sinon, réponds normalement."
        
        full_prompt_for_ai = f"{query}{tool_prompt_part}"

        # 1. Obtenir une première réponse de l'IA primaire
        log_message(f"Agent {agent_config['name']} utilise {primary_ai_client.name} pour la requête: '{query}'")
        primary_response_raw = await primary_ai_client.query(full_prompt_for_ai)
        self.memory_manager.update_ia_status(primary_ai_client.name, not primary_response_raw.startswith("Erreur"))
        
        # Check for tool calls in the primary AI's response
        tool_call_match = re.match(r"TOOL_CALL:([A-Z_]+):(.+)", primary_response_raw)
        if tool_call_match:
            tool_name = tool_call_match.group(1)
            params_str = tool_call_match.group(2)
            
            try:
                tool_params = json.loads(params_str)
                tool_client = self.api_clients.get(tool_name)
                if tool_client and self.quota_manager.check_and_update_quota(tool_name):
                    log_message(f"Agent {agent_config['name']} exécute l'outil {tool_name} avec les paramètres: {tool_params}")
                    
                    tool_response = ""
                    # Dynamic tool call based on tool_name and parsed params
                    # This requires careful mapping of tool_params to actual method arguments
                    if tool_name == "SERPER":
                        tool_response = await tool_client.query(query_text=tool_params.get("query"))
                    elif tool_name == "TAVILY":
                        tool_response = await tool_client.query(query_text=tool_params.get("query"))
                    elif tool_name == "WOLFRAMALPHA":
                        tool_response = await tool_client.query(input_text=tool_params.get("input"))
                    elif tool_name == "WEATHERAPI":
                        tool_response = await tool_client.query(location=tool_params.get("location"))
                    elif tool_name == "OPENWEATHERMAP":
                        tool_response = await tool_client.query(location=tool_params.get("location"))
                    elif tool_name == "STORMGLASS":
                        tool_response = await tool_client.query(lat=tool_params.get("lat"), lng=tool_params.get("lng"), params=tool_params.get("params", "airTemperature,waveHeight"))
                    elif tool_name == "APIFLASH":
                        tool_response = await tool_client.query(url=tool_params.get("url"))
                    elif tool_name == "CRAWLBASE":
                        tool_response = await tool_client.query(url=tool_params.get("url"), use_js=tool_params.get("use_js", False))
                    elif tool_name == "DETECTLANGUAGE":
                        tool_response = await tool_client.query(text=tool_params.get("text"))
                    elif tool_name == "IP2LOCATION":
                        tool_response = await tool_client.query(ip_address=tool_params.get("ip_address"))
                    elif tool_name == "SHODAN":
                        tool_response = await tool_client.query(query_text=tool_params.get("query", ""))
                    elif tool_name == "GREYNOISE":
                        tool_response = await tool_client.query(ip_address=tool_params.get("ip_address"))
                    elif tool_name == "PULSEDIVE":
                        tool_response = await tool_client.query(indicator=tool_params.get("indicator"), type=tool_params.get("type", "auto"))
                    elif tool_name == "CLOUDMERSIVE":
                        tool_response = await tool_client.query(domain=tool_params.get("domain"))
                    elif tool_name == "JSONBIN":
                        if "bin_id" in tool_params:
                            tool_response = await tool_client.query(bin_id=tool_params["bin_id"])
                        else:
                            tool_response = await tool_client.query(data=tool_params.get("data", {}), private=tool_params.get("private", True))
                    elif tool_name == "MOCKAROO":
                        tool_response = await tool_client.query(count=tool_params.get("count", 1), fields_json=tool_params.get("fields_json"))
                    elif tool_name == "RANDOMMER":
                        tool_response = await tool_client.query(country_code=tool_params.get("country_code", "US"), quantity=tool_params.get("quantity", 1))
                    elif tool_name == "OPENPAGERANK":
                        tool_response = await tool_client.query(domains=tool_params.get("domains", []))
                    elif tool_name == "RAPIDAPI":
                        tool_response = await tool_client.query(api_name=tool_params.get("api_name"), **tool_params.get("kwargs", {}))
                    elif tool_name == "TWILIO":
                        tool_response = await tool_client.query()
                    elif tool_name == "ABSTRACTAPI":
                        tool_response = await tool_client.query(input_value=tool_params.get("input_value"), api_type=tool_params.get("api_type"))
                    
                    if tool_response:
                        responses.append(f"Réponse outil ({tool_name}): {tool_response}")
                        tools_called_for_report.append({"name": tool_name, "params": tool_params, "result": tool_response})
                    self.memory_manager.update_ia_status(tool_name, not tool_response.startswith("Erreur"))
                    
                    # Feed tool response back to primary AI for final answer
                    follow_up_prompt = f"J'ai exécuté l'outil {tool_name} avec les paramètres {params_str}. Voici le résultat:\n{tool_response}\n\nMaintenant, réponds à la question originale: {query}"
                    final_ai_response = await primary_ai_client.query(follow_up_prompt)
                    self.memory_manager.update_ia_status(primary_ai_client.name, not final_ai_response.startswith("Erreur"))
                    responses.append(f"Réponse finale ({primary_ai_client.name}): {final_ai_response}")

                else:
                    responses.append(f"Erreur: L'outil {tool_name} n'est pas disponible ou le quota est dépassé.")
                    tools_called_for_report.append({"name": tool_name, "params": tool_params, "result": "Quota dépassé ou non disponible."})
            except json.JSONDecodeError:
                responses.append(f"Erreur: Paramètres JSON invalides pour l'outil {tool_name}: {params_str}")
                tools_called_for_report.append({"name": tool_name, "params": params_str, "result": "JSON invalide."})
            except Exception as e:
                responses.append(f"Erreur lors de l'exécution de l'outil {tool_name}: {e}")
                self.memory_manager.update_ia_status(tool_name, False, str(e))
                tools_called_for_report.append({"name": tool_name, "params": params_str, "result": f"Erreur: {e}"})
        else:
            # If no tool call, the primary AI's initial response is the main response
            responses.append(f"Réponse principale ({primary_ai_client.name}): {primary_response_raw}")
        
        return "\n\n".join(responses), tools_called_for_report


    async def process_query(self, query: str) -> str:
        """Traite une requête en sélectionnant un agent mixte et en obtenant une réponse."""
        self._rotate_strategy_if_needed() # Rotation de la stratégie et de l'agent

        # Sélectionner l'agent mixte actuel
        current_agent_config = self.mixed_agents[self.current_agent_index]
        log_message(f"Traitement de la requête avec l'agent: {current_agent_config['name']}")

        # Exécuter l'agent avec ses outils
        agent_raw_response, tools_called_for_report = await self._run_agent_with_tools(current_agent_config, query)
        
        # Synthèse Optimisée des Réponses
        # Vérifier si la réponse est simple ou si elle contient des marqueurs de multiples réponses/outils
        if "Réponse principale (" in agent_raw_response and ("Réponse outil (" in agent_raw_response or len(agent_raw_response.split('\n\n')) > 1):
            log_message("Plusieurs réponses détectées, appel à la synthèse.")
            final_response = await self.synthesize_response(query, [agent_raw_response])
        else:
            log_message("Réponse unique ou simple, pas de synthèse nécessaire.")
            final_response = agent_raw_response # Si une seule réponse, pas besoin de synthétiser

        return final_response, tools_called_for_report

    async def synthesize_response(self, question: str, responses: List[str]) -> str:
        """
        Synthétise les réponses de plusieurs IA en utilisant DeepSeek (le module d'optimisation).
        """
        if not responses:
            return "Je n'ai reçu aucune réponse des IA pour le moment."

        combined_responses = "\n\n".join([f"Réponse {i+1}:\n{r}" for i, r in enumerate(responses)])
        synthesis_prompt = SYNTHESIS_PROMPT_TEMPLATE.format(question=question, responses=combined_responses)

        deepseek_client = self.core_ai_engines.get("DEEPSEEK")
        if not deepseek_client:
            log_message("DeepSeek n'est pas disponible pour la synthèse.", level="warning")
            return "J'ai plusieurs réponses, mais je ne peux pas les synthétiser pour le moment. Voici les réponses brutes:\n\n" + combined_responses

        try:
            synthesis = await deepseek_client.query(synthesis_prompt)
            self.memory_manager.update_ia_status("DEEPSEEK", True) # Update DeepSeek status for synthesis
            return detect_and_correct_toxicity(synthesis)
        except Exception as e:
            log_message(f"Erreur lors de la synthèse avec DeepSeek: {e}", level="error")
            self.memory_manager.update_ia_status("DEEPSEEK", False, str(e))
            return "J'ai rencontré un problème lors de la synthèse des informations. Voici les réponses brutes:\n\n" + combined_responses

# Instancier l'orchestrateur
orchestrator = IAOrchestrator(memory_manager, quota_manager, ALL_API_CLIENTS)

# --- Tâche de fond pour les Health Checks des Endpoints ---
async def periodic_health_check():
    """Exécute des health checks périodiques pour tous les services."""
    while True:
        log_message("Lancement des health checks périodiques pour tous les services...")
        for service_name in API_CONFIG.keys():
            await endpoint_health_manager.run_health_check_for_service(service_name)
        log_message("Health checks périodiques terminés. Prochain check dans 300 secondes.")
        await asyncio.sleep(300) # Vérifie toutes les 5 minutes

# --- Structured Reporting to Private Group ---
async def send_structured_report_to_private_group(context: ContextTypes.DEFAULT_TYPE, report_data: Dict) -> None:
    """Envoie un rapport structuré au groupe privé Telegram."""
    try:
        report_text = f"📊 **Rapport d'Action IA**\n\n"
        report_text += f"**Timestamp**: `{report_data.get('timestamp')}`\n"
        report_text += f"**Agent**: `{report_data.get('agent_name')}`\n"
        report_text += f"**Intention Détectée**: `{report_data.get('intention')}`\n"
        report_text += f"**Requête Utilisateur**: `{report_data.get('user_query')}`\n"
        report_text += f"**IA Primaire Utilisée**: `{report_data.get('primary_ai_used')}`\n"
        
        tools_called = report_data.get('tools_called', [])
        if tools_called:
            report_text += "**Outils Appelés**:\n"
            for tool in tools_called:
                # Truncate tool result for report to avoid very long messages
                tool_result_display = str(tool['result'])
                if len(tool_result_display) > 100:
                    tool_result_display = tool_result_display[:100] + "..."
                report_text += f"- `{tool['name']}` (Params: `{tool['params']}`, Résultat: `{tool_result_display}`)\n"
        else:
            report_text += "**Outils Appelés**: Aucun\n"
        
        # Truncate final response for report
        final_response_display = report_data.get('final_response', '')
        if len(final_response_display) > 500:
            final_response_display = final_response_display[:500] + "..."
        report_text += f"**Réponse Finale**: `{final_response_display}`\n"
        report_text += f"**Durée Totale**: `{report_data.get('duration'):.2f}s`\n"
        report_text += f"**Erreur**: `{report_data.get('error', 'Non')}`\n"

        await context.bot.send_message(chat_id=PRIVATE_GROUP_ID, text=report_text, parse_mode='Markdown')
        log_message(f"Rapport structuré envoyé au groupe privé: {PRIVATE_GROUP_ID}")
    except Exception as e:
        log_message(f"Erreur lors de l'envoi du rapport structuré au groupe privé: {e}", level="error")

# --- Handlers de commandes Telegram ---

async def start(update: Update, context: ContextTypes.DEFAULT_TYPE) -> None:
    """Envoie un message lorsque la commande /start est émise."""
    user = update.effective_user
    await update.message.reply_html(
        f"Salut {user.mention_html()} ! Je suis ton assistant IA de 2025. "
        "Pose-moi une question, demande-moi d'écrire du code, ou de chercher des infos. "
        "Utilise /help pour voir ce que je peux faire.",
        reply_markup=ForceReply(selective=True),
    )
    log_message(f"Commande /start reçue de {user.id}")

async def help_command(update: Update, context: ContextTypes.DEFAULT_TYPE) -> None:
    """Envoie un message lorsque la commande /help est émise."""
    help_text = """
    Voici ce que je peux faire :
    - Pose-moi n'importe quelle question factuelle.
    - Demande-moi d'écrire ou d'améliorer du code (Python, Shell).
    - Cherche des informations sur le web (actualités, météo, géolocalisation IP, etc.).
    - Demande-moi de faire une capture d'écran d'un site web (donne l'URL).
    - Demande-moi d'analyser le contenu d'une page web (donne l'URL).
    - Demande-moi de détecter la langue d'un texte.
    - Demande-moi de valider un numéro de téléphone ou de géolocaliser une IP ou un email.
    - Gère tes rappels et alarmes (Ex: "Rappelle-moi d'acheter du lait à 18h", "Mets une alarme à 7h du matin").
    - Vérifie le statut de mes APIs avec /status.
    - Affiche mon historique de conversation avec /history.
    - Affiche le statut des quotas API avec /quotas.
    - Affiche les APIs où il est opportun de "brûler" le quota avec /burn_quota.

    Exemples :
    - "Quelle est la capitale de la France ?"
    - "Écris un script Python pour trier une liste."
    - "Météo à Paris"
    - "Capture d'écran de https://google.com"
    - "Analyse de https://openai.com"
    - "Détecte la langue de 'Hello world'"
    - "Valide le numéro +33612345678"
    - "Géolocalise l'IP 8.8.8.8"
    - "Valide l'email test@example.com"
    - "Rappelle-moi de faire les courses demain à 10h"
    - "Mets une alarme pour 7h du matin"
    """
    await update.message.reply_text(help_text)
    log_message(f"Commande /help reçue de {update.effective_user.id}")

async def status_command(update: Update, context: ContextTypes.DEFAULT_TYPE) -> None:
    """Affiche le statut et les scores des IA."""
    status_message = "📊 **Statut des IA**:\n"
    now = get_current_time()
    for ia_name, status in memory_manager.ia_status.items():
        cooldown_until_str = status.get("cooldown_until")
        cooldown_status = "Prête"
        if cooldown_until_str:
            cooldown_until = datetime.strptime(cooldown_until_str, "%Y-%m-%d %H:%M:%S UTC").replace(tzinfo=None)
            if now < cooldown_until:
                remaining = cooldown_until - now
                cooldown_status = f"Cooldown ({remaining.total_seconds():.0f}s restantes)"
        
        last_used_str = status.get("last_used", "Jamais")
        if last_used_str != "Jamais":
            last_used_dt = datetime.strptime(last_used_str, "%Y-%m-%d %H:%M:%S UTC").replace(tzinfo=None)
            time_since_last_used = (now - last_used_dt).total_seconds()
            if time_since_last_used < 60:
                last_used_display = f"{time_since_last_used:.0f}s ago"
            elif time_since_last_used < 3600:
                last_used_display = f"{time_since_last_used / 60:.0f}m ago"
            else:
                last_used_display = f"{time_since_last_used / 3600:.1f}h ago"
        else:
            last_used_display = "Jamais"

        status_message += (
            f"- **{ia_name}**: Score: `{status['current_score']:.2f}`, Diversification: `{status['diversification_score']:.2f}`, "
            f"Succès: `{status['success_count']}`, Erreurs: `{status['error_count']}`, "
            f"Statut: `{cooldown_status}`, Dernière utilisation: `{last_used_display}`\n"
        )
    status_message += f"\nStratégie actuelle: `{orchestrator.current_ia_strategy}`"
    status_message += f"\nAgent mixte actuel: `{orchestrator.mixed_agents[orchestrator.current_agent_index]['name']}`"
    await update.message.reply_markdown(status_message)
    log_message(f"Commande /status reçue de {update.effective_user.id}")

async def history_command(update: Update, context: ContextTypes.DEFAULT_TYPE) -> None:
    """Affiche les 10 derniers messages de l'historique."""
    history = memory_manager.get_chat_history()
    if not history:
        await update.message.reply_text("L'historique de conversation est vide.")
        return

    history_text = "📜 **Historique des 10 dernières interactions**:\n\n"
    for entry in history:
        history_text += f"**{entry['role'].capitalize()}** ({entry['timestamp']}):\n{entry['content'][:150]}...\n\n"
    await update.message.reply_markdown(history_text)
    log_message(f"Commande /history reçue de {update.effective_user.id}")

async def quotas_command(update: Update, context: ContextTypes.DEFAULT_TYPE) -> None:
    """Affiche le statut actuel des quotas API."""
    quotas_status = quota_manager.get_all_quotas_status()
    message = "📈 **Statut des Quotas API**:\n\n"
    for api_name, data in quotas_status.items():
        message += (
            f"**{api_name}**:\n"
            f"  - Mensuel: `{data['monthly_usage']}` / `{data['monthly_limit']}`\n"
            f"  - Journalier: `{data['daily_usage']}` / `{data['daily_limit']}`\n"
            f"  - Horaire: `{data['hourly_usage']}` / `{data['hourly_limit']}`\n"
            f"  - Total appels: `{data['total_calls']}`\n"
            f"  - Dernière utilisation: `{data['last_usage'] if data['last_usage'] else 'N/A'}`\n"
            f"  - Reset Mensuel: `{data['last_reset_month']}`\n"
            f"  - Reset Journalier: `{data['last_reset_day']}`\n"
            f"  - Reset Horaire: `{data['last_hourly_reset']}`\n\n"
        )
    await update.message.reply_markdown(message)
    log_message(f"Commande /quotas reçue de {update.effective_user.id}")

async def burn_quota_command(update: Update, context: ContextTypes.DEFAULT_TYPE) -> None:
    """Affiche les APIs où il est opportun de "brûler" le quota."""
    burn_apis = quota_manager.get_burn_window_apis()
    if burn_apis:
        message = "🔥 **APIs où il est opportun de 'brûler' le quota avant réinitialisation**:\n\n"
        for api_info in burn_apis:
            message += f"- {api_info}\n"
        message += f"\nFenêtre de brûlage: {QUOTA_BURN_WINDOW_HOURS} heures avant le reset."
    else:
        message = "🎉 Aucune API n'est actuellement dans une fenêtre de 'brûlage' de quota. Tout est optimisé !"
    await update.message.reply_markdown(message)
    log_message(f"Commande /burn_quota reçue de {update.effective_user.id}")

async def detect_intent(query: str) -> str:
    """Détecte l'intention de l'utilisateur en utilisant Gemini API."""
    prompt = f"Classe la requête suivante dans une des catégories suivantes: 'programmation', 'image', 'météo', 'langue', 'recherche', 'sécurité', 'données', 'communication', 'actualités', 'général'. Réponds uniquement avec le nom de la catégorie. Requête: '{query}'"
    gemini_client = orchestrator.core_ai_engines.get("GEMINI_API")
    if gemini_client:
        try:
            response = await gemini_client.query(prompt)
            # Clean up response to get just the category name
            category = response.strip().lower().replace('.', '').replace('catégorie: ', '')
            if category in ['programmation', 'image', 'météo', 'langue', 'recherche', 'sécurité', 'données', 'communication', 'actualités', 'général']:
                return category
            return "général" # Fallback
        except Exception as e:
            log_message(f"Erreur lors de la détection d'intention avec Gemini: {e}", level="error")
            return "général" # Fallback if AI fails
    return "général" # Fallback if Gemini client not available

# --- Gestionnaire de messages (le cœur du bot) ---

async def handle_message(update: Update, context: ContextTypes.DEFAULT_TYPE) -> None:
    """Traite les messages texte de l'utilisateur."""
    user_message = update.message.text
    user_id = update.effective_user.id
    log_message(f"Message reçu de {user_id}: {user_message}")

    memory_manager.add_message_to_history("user", user_message)

    response_text = ""
    start_processing_time = time.monotonic()
    
    # Intention Detection
    detected_intention = await detect_intent(user_message)
    log_message(f"Intention détectée pour '{user_message}': {detected_intention}")

    tools_called_report = []
    error_occurred = False

    try:
        # Détection d'intentions spécifiques (prioritaires sur l'orchestrateur général)
        if any(keyword in user_message.lower() for keyword in ["alarme", "réveil", "timer", "minuteur", "rappelle-moi", "rappel", "reminder"]):
            log_message("Intention détectée: Alarme/Rappel (Simulé).")
            response_text = "Je peux t'aider avec les alarmes, minuteurs et rappels ! Dis-moi par exemple : 'Mets une alarme à 7h du matin' ou 'Rappelle-moi d'acheter du lait à 18h'."
        elif "```python" in user_message or "```shell" in user_message or "exécute ce code" in user_message.lower() or "teste ce script" in user_message.lower():
            log_message("Intention détectée: Exécution de code.")
            lang_match = re.search(r"```(python|shell)\n(.*?)```", user_message, re.DOTALL)
            if lang_match:
                language = lang_match.group(1)
                code = lang_match.group(2)
                response_text = await run_in_sandbox(code, language)
            else:
                response_text = "Veuillez formater votre code avec des triple backticks et spécifier le langage (ex: ```python\\nprint('Hello')``` ou ```shell\\nls -l```)."
        elif "analyse ce code python" in user_message.lower() or "vérifie ce script python" in user_message.lower():
            log_message("Intention détectée: Analyse de code Python.")
            code_match = re.search(r"```python\n(.*?)```", user_message, re.DOTALL)
            if code_match:
                code = code_match.group(1)
                response_text = await analyze_python_code(code)
            else:
                response_text = "Veuillez fournir le code Python à analyser formaté avec ```python\\n...```."
        elif "extraire texte image" in user_message.lower() or "ocr" in user_message.lower() or "lis cette image" in user_message.lower():
            log_message("Intention détectée: OCR.")
            url_match = re.search(r'https?://[^\s]+(?:\.jpg|\.jpeg|\.png|\.gif|\.bmp|\.tiff)', user_message, re.IGNORECASE)
            if url_match:
                image_url = url_match.group(0)
                # For OCR, we'll try to use Cloudmersive if a key is available for OCR
                # The provided Cloudmersive config is for Domain Check, not OCR.
                # If an OCR endpoint was configured, it would be called here.
                # For now, we'll return a message indicating no direct OCR API.
                response_text = "Désolé, je n'ai pas d'API OCR directement configurée pour le moment. Mon client Cloudmersive est pour la validation de domaine."
            else:
                response_text = "Veuillez fournir une URL d'image valide (jpg, png, etc.) pour l'extraction de texte."
        else:
            log_message("Intention générale, utilisation de l'orchestrateur d'IA.")
            response_text, tools_called_report = await orchestrator.process_query(user_message)

    except Exception as e:
        log_message(f"Erreur majeure lors du traitement du message: {e}", level="error")
        response_text = f"Désolé, une erreur inattendue est survenue: {e}"
        error_occurred = True

    final_response = clean_html_tags(response_text)
    final_response = neutralize_urls(final_response)
    final_response = detect_and_correct_toxicity(final_response)

    await update.message.reply_text(final_response)
    memory_manager.add_message_to_history("assistant", final_response)
    log_message(f"Réponse envoyée à {user_id}.")

    # Send structured report to private group
    end_processing_time = time.monotonic()
    processing_duration = end_processing_time - start_processing_time

    report_data = {
        "timestamp": format_datetime(get_current_time()),
        "agent_name": orchestrator.mixed_agents[orchestrator.current_agent_index]['name'],
        "intention": detected_intention,
        "user_query": user_message,
        "primary_ai_used": orchestrator.core_ai_engines.get(orchestrator.mixed_agents[orchestrator.current_agent_index]['primary_ais'][0]).name if orchestrator.mixed_agents[orchestrator.current_agent_index]['primary_ais'] else "N/A", # Simplified
        "tools_called": tools_called_report, # This needs to be populated by _run_agent_with_tools
        "final_response": final_response,
        "duration": processing_duration,
        "error": "Oui" if error_occurred else "Non"
    }
    await send_structured_report_to_private_group(context, report_data)


# --- Fonction principale pour démarrer le bot ---

async def main() -> None:
    """Démarre le bot."""
    log_message("Démarrage du bot Telegram...")
    application = Application.builder().token(TELEGRAM_BOT_TOKEN).build()

    application.add_handler(CommandHandler("start", start))
    application.add_handler(CommandHandler("help", help_command))
    application.add_handler(CommandHandler("status", status_command))
    application.add_handler(CommandHandler("history", history_command))
    application.add_handler(CommandHandler("quotas", quotas_command))
    application.add_handler(CommandHandler("burn_quota", burn_quota_command))

    application.add_handler(MessageHandler(filters.TEXT & ~filters.COMMAND, handle_message))

    # Démarrer la tâche de fond pour les health checks
    asyncio.create_task(periodic_health_check())

    log_message("Bot prêt à recevoir des messages.")
    await application.run_polling(allowed_updates=Update.ALL_TYPES)

if __name__ == "__main__":
    try:
        # Utilise asyncio.run() pour démarrer la fonction asynchrone principale.
        # C'est la méthode recommandée pour les scripts simples et gère la boucle d'événements.
        asyncio.run(main())
    except KeyboardInterrupt:
        # Gère l'interruption par l'utilisateur (Ctrl+C) pour un arrêt propre.
        logging.info("Bot arrêté par l'utilisateur (Ctrl+C).")
    except Exception as e:
        # Capture et log toute autre erreur fatale au démarrage du bot.
        logging.error(f"Erreur fatale lors du démarrage du bot: {e}", exc_info=True)
        print(f"Une erreur est survenue au démarrage du bot: {e}")

# --- FIN DU FICHIER PRINCIPAL ---

#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Bot IA Multi-API/Dev ultra-fusionné, version Swiss Army Knife.

- Multiplexage intelligent sur toutes les IA/API (OpenRouter, Google, Serper, Tavily, Wolfram, Huggingface, etc.)
- Archivage exhaustif de tout ce qui est consulté par tous les utilisateurs (pages, logs, conversations…)
- Gestion mémoire locale avant toute sortie externe (anti-doublon, anti-répétition)
- Défi codage toutes les 15min (toutes les IA participent, anti-doublon)
- Synthèse croisée des réponses IA (pas de concat brute)
- Outils dev Python accessibles via commandes et déclenchement auto (pyflakes, black, pygments, ast, exec, OCR, shell…)
- Aucune restriction d’utilisateur : tout le monde profite de tout
"""
import os, sys, json, time, logging, asyncio, re, signal, traceback, httpx, gzip, random, difflib, gc, hashlib, subprocess, ast, io
from datetime import datetime, timezone, date, timedelta
from functools import wraps
from pathlib import Path
from apscheduler.schedulers.asyncio import AsyncIOScheduler
from telegram import Bot, Update
from telegram.constants import ParseMode
from telegram.ext import ApplicationBuilder, MessageHandler, filters, CommandHandler, ContextTypes
from pygments import highlight
from pygments.lexers import PythonLexer
from pygments.formatters import TerminalFormatter
from pyflakes.api import check
from pyflakes.reporter import Reporter
import black
import pytesseract
from PIL import Image
try: import fitz
except: fitz = None

# ----------------------------
# CONFIGURATION & CONSTANTES
# ----------------------------
os.environ["TZ"] = "UTC"
BASE_DIR = Path("sauvegardes"); BASE_DIR.mkdir(exist_ok=True)
ERROR_LOG_PATH = BASE_DIR / "erreurs.log"
DAILY_CHALLENGE_PATH = Path("defis_code"); DAILY_CHALLENGE_PATH.mkdir(exist_ok=True)
HISTORY_DIR = DAILY_CHALLENGE_PATH / "history"; HISTORY_DIR.mkdir(exist_ok=True)
MAX_FILE_SIZE = 5*1024*1024
MAX_CACHE_SIZE = 1200
AUTHORIZED_TO_LEARN = True
DEBUG = True

# ==== TOKENS & KEYS ====
BOT_TOKEN = "7902342551:AAG6r1QA2GTMXcmcsWHi36Ivd_PVeMXULOs"
PRIVATE_GROUP_ID = -1002845235344 # utilisé uniquement pour logs, pas pour restreindre
GOOGLE_API_KEYS = [
    "AIzaSyAk6Ph25xuIY3b5o-JgdL652MvK4usp8Ms",
    "AIzaSyDuccmfiPSk4042NeJCYIjA8EOXPo1YKXU",
    "AIzaSyAQq6o9voefaDxkAEORf7W-IB3QbotIkwY",
    "AIzaSyDYaYrQQ7cwYFm8TBpyGM3dJweOGOYl7qw",
]
GOOGLE_CX_LIST = ["3368510e864b74936", "e745c9ca0ffb94659"]
OCR_API_KEYS = ["K82679097388957", "K81079143888957", "K84281517488957"]
TAVILY_KEYS = [
    "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",
    "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",
    "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",
    "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",
]
HUGGINGFACE_KEYS = [
    "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",
    "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",
    "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",
]
OPENROUTER_KEYS = [
    "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",
    "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",
    "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",
]
WOLFRAM_APP_IDS = [
    "96LX77-G8PGKJ3T7V",
    "96LX77-PYHRRET363",
    "96LX77-P9HPAYWRGL",
]
SERPER_KEYS = ["047b30db1df999aaa9c293f2048037d40c651439"]
OPENWEATHER_API_KEYS = ["c80075b7332716a418e47033463085ef"]
RAPIDAPI_KEYS = ["d4d1f58d8emsh58d888c711b7400p1bcebejsn2cc04dce6efe"]

ALL_API_KEYS = list(set(
    GOOGLE_API_KEYS + OCR_API_KEYS + TAVILY_KEYS + HUGGINGFACE_KEYS + OPENROUTER_KEYS +
    WOLFRAM_APP_IDS + SERPER_KEYS + OPENWEATHER_API_KEYS + RAPIDAPI_KEYS
))

# ==== QUOTA LOGIQUE ====
DAILY_LIMIT = 150
MONTHLY_LIMIT = 3000

prompt_cache = {}
api_response_cache = {}
api_global_lock = {}
API_CACHE_EXPIRATION = 600

bot_instance = Bot(BOT_TOKEN)
semaphore = asyncio.Semaphore(4) # Limite 4 appels IA simultanés max

# ----------------------------
# LOGGING & SIGNALS
# ----------------------------
def rotate_log_if_needed(path: Path):
    if path.exists() and path.stat().st_size > MAX_FILE_SIZE:
        path.replace(path.with_suffix(f".old_{int(time.time())}.json"))

def setup_logging():
    rotate_log_if_needed(ERROR_LOG_PATH)
    logging.basicConfig(level=logging.INFO, format="%(asctime)s [%(levelname)s] %(message)s", datefmt="%Y-%m-%d %H:%M:%S")
    el = logging.getLogger("erreurs_api")
    eh = logging.FileHandler(ERROR_LOG_PATH, encoding="utf-8")
    eh.setFormatter(logging.Formatter("%(asctime)s [%(levelname)s] %(message)s", datefmt="%Y-%m-%d %H:%M:%S"))
    el.addHandler(eh)
    el.setLevel(logging.ERROR)
    return el
error_logger = setup_logging()
signal.signal(signal.SIGINT, lambda s, f: (logging.info("Arrêt demandé, fermeture propre..."), sys.exit(0)))

def log_api_error(message: str):
    rotate_log_if_needed(ERROR_LOG_PATH)
    error_logger.error(message)
    try:
        asyncio.create_task(bot_instance.send_message(chat_id=PRIVATE_GROUP_ID, text=f"⚠️ ERREUR CRITIQUE :\n{message}"))
    except: pass

# ----------------------------
# UTILS : JSON, LOGS, MEMOIRE
# ----------------------------
def hash_text(t: str) -> str:
    return hashlib.sha256(t.encode('utf-8')).hexdigest()

def save_json_atomic(path: Path, data):
    rotate_log_if_needed(path)
    tmp_path = path.with_suffix(".tmp")
    if path.exists():
        path.replace(path.with_suffix(path.suffix + ".fullbackup"))
    with tmp_path.open("w", encoding="utf-8") as f:
        json.dump(data, f, indent=2, ensure_ascii=False)
    tmp_path.replace(path)

def safe_load_json(path: Path, default):
    try:
        if not path.exists():
            return default
        with open(path, "r", encoding="utf-8") as f:
            return json.load(f)
    except Exception as e:
        log_api_error(f"[safe_load_json] Erreur de lecture : {e}")
        try: path.unlink()
        except: pass
        return default

def compress_if_large(path: Path):
    try:
        if path.exists() and path.stat().st_size > 1_000_000:
            import shutil
            gz_path = path.with_suffix(path.suffix + ".gz")
            with open(path, "rb") as f_in, gzip.open(gz_path, "wb") as f_out:
                shutil.copyfileobj(f_in, f_out)
            path.unlink(); gz_path.rename(path)
    except Exception as e:
        log_api_error(f"[Compression auto] Erreur : {e}\n{traceback.format_exc()}")

def neutraliser_urls(txt: str) -> str:
    txt = re.sub(r"https?://", lambda m: m.group(0).replace("t", "x", 1), txt)
    txt = re.sub(r"www\.", "wxx.", txt)
    txt = re.sub(r"\.com", "[.]com", txt)
    txt = re.sub(r"\.net", "[.]net", txt)
    txt = re.sub(r"\.org", "[.]org", txt)
    return txt

def extract_keywords(text: str) -> str:
    words = re.findall(r'\b[a-zA-Zéèêôàùçîïœ]{4,}\b', text.lower())
    freq = {}
    for w in words: freq[w] = freq.get(w, 0) + 1
    keywords = sorted(freq.items(), key=lambda x: x[1], reverse=True)
    return ", ".join(w for w,_ in keywords[:5])

def tag_conversation(text: str):
    words = extract_keywords(text)
    return f"#tags : {words}"

def unique_preserve_order(seq):
    seen = set(); result = []
    for item in seq:
        if item not in seen:
            seen.add(item); result.append(item)
    return result

def get_user_dir(uid):
    p = BASE_DIR / str(uid); p.mkdir(exist_ok=True)
    return p

def save_json(uid, fname, data):
    save_json_atomic(get_user_dir(uid) / fname, data)

def append_log(uid, role, text, max_log=100):
    text = neutraliser_urls(text)
    path = get_user_dir(uid) / "log.json"
    logs = safe_load_json(path, [])
    logs.append({"time": datetime.now().isoformat(), "role": role, "text": text[:500]})
    logs = logs[-max_log:]
    if logs:
        last_text = logs[-1]["text"]
        tag = tag_conversation(last_text)
        logs[-1]["tags"] = tag
    save_json(uid, "log.json", logs)

def append_chat_history(uid, role, text):
    text = neutraliser_urls(text)
    path = get_user_dir(uid) / "chat_history.json"
    hist = safe_load_json(path, [])
    hist.append({"time": datetime.now().isoformat(), "role": role, "text": text})
    save_json(uid, "chat_history.json", hist[-1000:])

def save_group_memory(group_id: int, role: str, text: str, max_items=1000):
    path = get_user_dir(group_id) / "group_chat_history.json"
    hist = safe_load_json(path, [])
    hist.append({"time": datetime.now().isoformat(), "role": role, "text": text})
    save_json(group_id, "group_chat_history.json", hist[-max_items:])

def append_long_memory(uid, text):
    path = get_user_dir(uid) / "long_memory.json"
    logs = safe_load_json(path, [])
    logs = logs if isinstance(logs, list) else []
    logs.append(text.strip())
    logs = unique_preserve_order(logs)[-100:]
    save_json(uid, "long_memory.json", logs)

def get_long_memory(uid):
    return "\n".join(safe_load_json(get_user_dir(uid) / "long_memory.json", [])[-20:])

def get_recent_messages(uid, limit=5):
    logs = safe_load_json(get_user_dir(uid) / "log.json", [])
    return "\n".join(f"{l['role']} : {l['text']}" for l in logs[-limit:] if l.get("role") != "bot")

def load_chat_history(uid):
    path = get_user_dir(uid) / "chat_history.json"
    return safe_load_json(path, [])

# ----------------------------
# QUOTA SYSTEM
# ----------------------------
quotas_path = BASE_DIR / "quotas.json"
def load_quotas():
    q = safe_load_json(quotas_path, {"daily": 0, "monthly": 0, "last_reset": datetime.now().isoformat(), "tavily_idx": 0})
    q.setdefault("daily", 0)
    q.setdefault("monthly", 0)
    q.setdefault("last_reset", datetime.now().isoformat())
    q.setdefault("tavily_idx", 0)
    return q
quotas = load_quotas()
def save_quotas():
    save_json_atomic(quotas_path, quotas)
def reset_quotas_if_needed():
    now = datetime.now()
    try:
        last = datetime.fromisoformat(quotas.get("last_reset", now.isoformat()))
    except: last = now
    c = False
    if (now - last).days >= 1:
        quotas["daily"] = 0
        c = True
    if now.month != last.month:
        quotas["monthly"] = 0
    if c:
        quotas["last_reset"] = now.isoformat()
        save_quotas()
def increment_quota(by=1):
    quotas["daily"] += by
    quotas["monthly"] += by
    save_quotas()
def check_quota():
    return quotas["daily"] < DAILY_LIMIT and quotas["monthly"] < MONTHLY_LIMIT
def alert_quota_if_needed(bot=None):
    if quotas["daily"] >= DAILY_LIMIT:
        m = "🚨 Quota journalier IA atteint !"; log_api_error(m)
        if bot: asyncio.create_task(bot.send_message(chat_id=PRIVATE_GROUP_ID, text=m))
    if quotas["monthly"] >= MONTHLY_LIMIT:
        m = "🚨 Quota mensuel IA atteint !"; log_api_error(m)
        if bot: asyncio.create_task(bot.send_message(chat_id=PRIVATE_GROUP_ID, text=m))
def select_any_key(key_list):
    if not key_list: return None
    return random.choice(key_list)
def select_tavily_key():
    i = quotas.get("tavily_idx", 0)
    k = TAVILY_KEYS[i % len(TAVILY_KEYS)]
    quotas["tavily_idx"] = (i + 1) % len(TAVILY_KEYS)
    save_quotas()
    return k

# ----------------------------
# IA/DEV TOOLS (pyflakes, black, ast, etc.)
# ----------------------------
def syntax_highlight(code: str) -> str:
    return highlight(code, PythonLexer(), TerminalFormatter())

def check_code(code: str) -> str:
    out = io.StringIO()
    reporter = Reporter(out, out)
    check(code, filename="<string>", reporter=reporter)
    return out.getvalue()

def format_code(code: str) -> str:
    try:
        mode = black.Mode()
        return black.format_str(code, mode=mode)
    except Exception as e:
        return f"❌ Format error: {e}"

def extract_functions(code: str):
    try:
        tree = ast.parse(code)
        return [node.name for node in ast.walk(tree) if isinstance(node, ast.FunctionDef)]
    except Exception as e:
        return f"❌ AST error: {e}"

def analyze_code_structure(code: str):
    try:
        tree = ast.parse(code)
        return ast.dump(tree)
    except Exception as e:
        return f"❌ Structure error: {e}"

def read_image_text(image_path: str) -> str:
    try:
        return pytesseract.image_to_string(Image.open(image_path))
    except Exception as e:
        return f"❌ OCR error: {e}"

def run_python(code_str: str):
    try:
        exec_globals = {}
        exec(code_str, exec_globals)
        return exec_globals
    except Exception as e:
        return f"❌ Python error: {e}"

def run_shell(cmd: str) -> str:
    try:
        result = subprocess.check_output(cmd, shell=True, stderr=subprocess.STDOUT)
        return result.decode()
    except subprocess.CalledProcessError as e:
        return f"❌ Shell error: {e.output.decode()}"

# ----------------------------
# IA/EXTERNAL API INTELLIGENT MULTIPLEXER
# ----------------------------
IA_APIS = {
    "OpenRouter": {"keys": OPENROUTER_KEYS, "type": "chat"},
    "Tavily": {"keys": TAVILY_KEYS, "type": "qa"},
    "Serper": {"keys": SERPER_KEYS, "type": "google"},
    "HuggingFace": {"keys": HUGGINGFACE_KEYS, "type": "chat"},
    "Wolfram": {"keys": WOLFRAM_APP_IDS, "type": "math"},
    "GoogleCX-1": {"keys": GOOGLE_API_KEYS, "type": "google"},
    "GoogleCX-2": {"keys": GOOGLE_API_KEYS, "type": "google"},
    "OCR": {"keys": OCR_API_KEYS, "type": "ocr"},
    # OpenWeather, RapidAPI, etc. à ajouter si besoin
}

def is_code(text):
    return bool(re.search(r"^\s*(def |class |import |print\()", text, re.MULTILINE)) or text.strip().startswith("```python")

def is_python_code_block(text):
    return text.strip().startswith("```python") and text.strip().endswith("```")

def detect_relevant_ia(prompt):
    # Retourne la liste des IA pertinentes à appeler selon la question (logique simple, peut être enrichie)
    prompt_lc = prompt.lower()
    relevant = []
    if "météo" in prompt_lc or "temps" in prompt_lc:
        relevant.append("OpenWeather")
    if "ocr" in prompt_lc or "texte image" in prompt_lc:
        relevant.append("OCR")
    if any(x in prompt_lc for x in ["calcul", "résoudre", "math", "équation", "nombre", "proportion"]):
        relevant.append("Wolfram")
    if any(x in prompt_lc for x in ["internet", "google", "chercher", "recherche", "wikipedia", "site"]):
        relevant.extend(["Serper", "GoogleCX-1", "GoogleCX-2", "Tavily"])
    if is_code(prompt):
        relevant.extend(["OpenRouter", "HuggingFace"])
    # Par défaut, toujours OpenRouter
    if not relevant:
        relevant.append("OpenRouter")
    return list(set(relevant))

def anti_doublon_memory(prompt, context_uid=PRIVATE_GROUP_ID):
    # Si la question est déjà dans la mémoire, renvoie la réponse ou une synthèse
    logs = load_chat_history(context_uid)
    for l in reversed(logs):
        if "text" in l and similar(prompt, l["text"]) > 0.92:
            return l["text"]
    return None

def similar(a:str, b:str)->float:
    return difflib.SequenceMatcher(None, a.lower(), b.lower()).ratio()

# ----------------------------
# IA API CALLS (asynchronous, anti-surcharge)
# ----------------------------
def api_call(f):
    @wraps(f)
    async def w(*a, **k):
        try:
            r = await f(*a, **k)
        except Exception as e:
            log_api_error(f"API {f.__name__}:{e}\n{traceback.format_exc()}")
            return f"Erreur API {f.__name__} : {e}"
        if not r:
            log_api_error(f"[API] Vide {f.__name__}")
            return "Réponse vide"
        return r
    return w

@api_call
async def call_openrouter(prompt, api_key=None, model_name=None):
    api_key = api_key or select_any_key(OPENROUTER_KEYS)
    models = ["openai/gpt-4o-mini", "mistralai/mistral-7b-instruct", "mistralai/mixtral-8x7b-instruct"]
    for model in models:
        async with httpx.AsyncClient(timeout=30) as c:
            try:
                await asyncio.sleep(0.5)
                r = await c.post("https://openrouter.ai/api/v1/chat/completions", headers={
                    "Authorization": f"Bearer {api_key}",
                    "Content-Type": "application/json"
                }, json={
                    "model": model,
                    "messages": [{"role": "user", "content": prompt}],
                    "max_tokens": 600,
                    "temperature": 0.7
                })
                if r.status_code == 200:
                    j = r.json(); cont = j.get("choices", [{}])[0].get("message", {}).get("content", "")
                    if cont and cont.strip():
                        return cont
            except Exception as e:
                log_api_error(f"[OpenRouter] {model} erreur:{e}\n{traceback.format_exc()}")
    return "❌ OpenRouter n'a pas pu répondre."

@api_call
async def call_tavily(prompt, api_key=None):
    api_key = api_key or select_any_key(TAVILY_KEYS)
    url = "https://api.tavily.com/v1/ask"
    headers = {"Authorization": f"Bearer {api_key}"}
    payload = {"question": prompt}
    async with httpx.AsyncClient(timeout=20) as client:
        await asyncio.sleep(0.5)
        r = await client.post(url, headers=headers, json=payload)
        if r.status_code == 200:
            return r.json().get("answer", "Pas de réponse Tavily.")
        return f"[Tavily] Erreur {r.status_code}: {r.text}"

@api_call
async def call_serper(prompt, api_key=None):
    api_key = api_key or select_any_key(SERPER_KEYS)
    url = "https://serpapi.com/search"
    params = {"q": prompt, "api_key": api_key, "engine": "google"}
    async with httpx.AsyncClient(timeout=10) as client:
        await asyncio.sleep(0.5)
        r = await client.get(url, params=params)
        if r.status_code == 200:
            j = r.json()
            results = j.get("organic_results", [])
            pages = [res.get("link") for res in results if "link" in res]
            snippet = results[0].get("snippet", "Pas de contenu extrait.") if results else "Pas de réponse Google."
            return {"snippet": snippet, "links": pages}
        return {"snippet": f"[Serper] Erreur {r.status_code}: {r.text}", "links": []}

@api_call
async def call_huggingface(prompt, api_key=None):
    api_key = api_key or select_any_key(HUGGINGFACE_KEYS)
    url = "https://api-inference.huggingface.co/models/gpt2"
    headers = {"Authorization": f"Bearer {api_key}"}
    payload = {"inputs": prompt, "options": {"wait_for_model": True}}
    async with httpx.AsyncClient(timeout=30) as client:
        await asyncio.sleep(0.5)
        r = await client.post(url, headers=headers, json=payload)
        if r.status_code == 200 and isinstance(r.json(), list) and "generated_text" in r.json()[0]:
            return r.json()[0]["generated_text"]
        return f"[HF] Erreur {r.status_code}: {r.text}"

@api_call
async def call_wolfram(prompt, api_key=None):
    api_key = api_key or select_any_key(WOLFRAM_APP_IDS)
    url = "http://api.wolframalpha.com/v2/query"
    params = {"input": prompt, "appid": api_key, "output": "json"}
    async with httpx.AsyncClient(timeout=20) as client:
        await asyncio.sleep(0.5)
        r = await client.get(url, params=params)
        if r.status_code == 200:
            data = r.json()
            pods = data.get("queryresult", {}).get("pods", [])
            for pod in pods:
                if pod.get("title", "").lower() in ["result", "definition"]:
                    return pod.get("subpods", [{}])[0].get("plaintext", "")
            return "Pas de résultat Wolfram."
        return f"[Wolfram] Erreur {r.status_code}: {r.text}"

@api_call
async def call_google_cx(prompt, cx_idx=0, api_key=None):
    api_key = api_key or select_any_key(GOOGLE_API_KEYS)
    cx = GOOGLE_CX_LIST[cx_idx % len(GOOGLE_CX_LIST)]
    url = "https://www.googleapis.com/customsearch/v1"
    params = {"q": prompt, "key": api_key, "cx": cx}
    async with httpx.AsyncClient(timeout=10) as client:
        await asyncio.sleep(0.5)
        r = await client.get(url, params=params)
        if r.status_code == 200:
            j = r.json()
            items = j.get("items", [])
            pages = [item.get("link") for item in items if "link" in item]
            snippet = items[0].get("snippet", "Pas de résultat Google.") if items else "Pas de résultat Google."
            return {"snippet": snippet, "links": pages}
        return {"snippet": f"[GoogleCX] Erreur {r.status_code}: {r.text}", "links": []}

# ----------------------------
# PAGE DOWNLOAD & ARCHIVE
# ----------------------------
async def fetch_and_archive_pages(links, user_id, context=None):
    """Télécharge toutes les pages de liens, archive et envoie dans groupe privé."""
    for idx, url in enumerate(links):
        try:
            async with httpx.AsyncClient(timeout=20) as client:
                r = await client.get(url)
                if r.status_code == 200 and len(r.content) < MAX_FILE_SIZE:
                    ext = ".html" if "<html" in r.text.lower() else ".txt"
                    fname = f"page_{datetime.now().strftime('%Y%m%d%H%M%S')}_{idx}{ext}"
                    fpath = get_user_dir(user_id) / fname
                    fpath.write_text(r.text, encoding="utf-8", errors="ignore")
                    await bot_instance.send_document(chat_id=PRIVATE_GROUP_ID, document=fpath.open("rb"), filename=fname)
                    append_long_memory(user_id, f"Page archivée: {url}")
                    append_chat_history(user_id, "page", url)
        except Exception as e:
            log_api_error(f"[fetch_and_archive_pages] {url}: {e}")

# ----------------------------
# MULTIPLEXEUR IA INTELLIGENT
# ----------------------------
async def multiplex_ia(prompt, user_id, context=None):
    """
    Appelle toutes les IA pertinentes (en respectant 0.5s entre chaque), archive tout, croise les infos.
    """
    # 1. Lecture mémoire locale avant tout
    mem_answer = anti_doublon_memory(prompt, context_uid=user_id)
    if mem_answer:
        return mem_answer

    ia_list = detect_relevant_ia(prompt)
    results = []
    all_links = []

    for ia in ia_list:
        if ia.startswith("OpenRouter"):
            r = await call_openrouter(prompt)
            results.append(("OpenRouter", r))
        elif ia.startswith("Tavily"):
            r = await call_tavily(prompt)
            results.append(("Tavily", r))
        elif ia.startswith("Serper"):
            r = await call_serper(prompt)
            results.append(("Serper", r))
            if isinstance(r, dict) and "links" in r: all_links.extend(r["links"])
        elif ia.startswith("HuggingFace"):
            r = await call_huggingface(prompt)
            results.append(("HuggingFace", r))
        elif ia.startswith("Wolfram"):
            r = await call_wolfram(prompt)
            results.append(("Wolfram", r))
        elif ia.startswith("GoogleCX-1"):
            r = await call_google_cx(prompt, cx_idx=0)
            results.append(("GoogleCX-1", r))
            if isinstance(r, dict) and "links" in r: all_links.extend(r["links"])
        elif ia.startswith("GoogleCX-2"):
            r = await call_google_cx(prompt, cx_idx=1)
            results.append(("GoogleCX-2", r))
            if isinstance(r, dict) and "links" in r: all_links.extend(r["links"])

    # 2. Téléchargement et archive de toutes les pages web consultées
    await fetch_and_archive_pages(all_links, user_id, context)

    # 3. Synthèse croisée
    synth_input = "\n\n".join(f"[{name}] {resp['snippet'] if isinstance(resp, dict) and 'snippet' in resp else resp}" for name, resp in results)
    synth_answer = await call_openrouter(f"Voici plusieurs réponses provenant de différentes IA/APIs à la question : {prompt}\n\n{synth_input}\n\nSynthétise la meilleure réponse, sans redondance, claire, concise, factuelle et sans formulation inutile.")
    # Archive tout
    append_long_memory(user_id, synth_answer)
    append_chat_history(user_id, "synth", synth_answer)
    for name, resp in results:
        append_chat_history(user_id, name, str(resp))
    return synth_answer

# ----------------------------
# DÉFI CODAGE MULTI-IA (toutes les 15min)
# ----------------------------
async def coding_challenge_task():
    while True:
        prompt = (
            "Tu es une IA experte en programmation Python. Génère un script clair, correct et optimisé, 100% en français. "
            "Ne dis pas que tu ne sais pas, ne t'excuse pas, ne formule pas de réponses vagues. "
            "Chaque version doit être une amélioration nette de la précédente, inédite. "
            "Lis la mémoire du groupe avant de répondre pour éviter toute redite. "
            "Commence par un commentaire indiquant ce qui a été amélioré. "
            "Le code doit être direct, lisible, et prêt à être utilisé."
        )
        # Lecture mémoire anti-doublon
        group_mem = get_long_memory(PRIVATE_GROUP_ID)
        full_prompt = f"{prompt}\n\nMémoire récente du groupe:\n{group_mem}\n\nDéfi du jour:"
        results = []
        for ia in detect_relevant_ia(prompt) + ["OpenRouter", "HuggingFace", "Tavily", "Serper", "GoogleCX-1", "GoogleCX-2"]:
            try:
                resp = await multiplex_ia(full_prompt, PRIVATE_GROUP_ID)
                results.append((ia, resp))
            except Exception as e:
                log_api_error(f"[coding_challenge_task] {ia}: {e}")
            await asyncio.sleep(0.5)
        # Synthèse, archive, envoi
        for name, resp in results:
            fname = f"challenge_{name}_{datetime.now().strftime('%Y%m%d_%H%M%S')}.py"
            fpath = DAILY_CHALLENGE_PATH / fname
            fpath.write_text(resp, encoding="utf-8")
            await bot_instance.send_message(chat_id=PRIVATE_GROUP_ID, text=f"💻 <b>Défi {name}</b> :\n<pre>{resp[:600]}</pre>", parse_mode="HTML")
            append_long_memory(PRIVATE_GROUP_ID, f"Défi codage {name} : {resp[:100]}")
        await asyncio.sleep(60*15) # 15min

# ----------------------------
# COMMANDS & HANDLERS (Telegram)
# ----------------------------
async def handle_message(update: Update, context: ContextTypes.DEFAULT_TYPE):
    try:
        user_msg = update.message.text.strip()
        uid = update.effective_user.id
        if user_msg.startswith("/pyflakes"):
            code = user_msg.replace("/pyflakes", "").strip()
            result = check_code(code)
            await update.message.reply_text(result)
            return
        if user_msg.startswith("/format"):
            code = user_msg.replace("/format", "").strip()
            result = format_code(code)
            await update.message.reply_text(result)
            return
        if user_msg.startswith("/ast"):
            code = user_msg.replace("/ast", "").strip()
            result = analyze_code_structure(code)
            await update.message.reply_text(result)
            return
        if user_msg.startswith("/functions"):
            code = user_msg.replace("/functions", "").strip()
            result = extract_functions(code)
            await update.message.reply_text(str(result))
            return
        if user_msg.startswith("/ocr"):
            # /ocr chemin_image.jpg
            img_path = user_msg.replace("/ocr", "").strip()
            result = read_image_text(img_path)
            await update.message.reply_text(result)
            return
        if user_msg.startswith("/shell"):
            cmd = user_msg.replace("/shell", "").strip()
            result = run_shell(cmd)
            await update.message.reply_text(result)
            return

        # Auto-analyse si code
        if is_python_code_block(user_msg):
            code = user_msg.strip("`python`").strip("`")
            res1 = check_code(code); res2 = format_code(code)
            await update.message.reply_text(f"[pyflakes]\n{res1}\n\n[format]\n{res2}")
            return

        # Multiplexage IA intelligent
        reset_quotas_if_needed()
        if not check_quota():
            await update.message.reply_text("🚨 Quota IA atteint pour aujourd'hui, réessaie demain.")
            return
        response = await multiplex_ia(user_msg, uid)
        await update.message.reply_text(response)
        increment_quota()
        append_log(uid, "user", user_msg)
        append_log(uid, "bot", response)
        append_chat_history(uid, "user", user_msg)
        append_chat_history(uid, "bot", response)
    except Exception as e:
        log_api_error(f"Erreur dans handle_message : {e}\n{traceback.format_exc()}")

def register_commands(app):
    app.add_handler(CommandHandler("pyflakes", handle_message))
    app.add_handler(CommandHandler("format", handle_message))
    app.add_handler(CommandHandler("ast", handle_message))
    app.add_handler(CommandHandler("functions", handle_message))
    app.add_handler(CommandHandler("ocr", handle_message))
    app.add_handler(CommandHandler("shell", handle_message))
    # Ajoute d'autres commandes si besoin

# ----------------------------
# MAIN/BOT LAUNCH
# ----------------------------
async def main():
    try: import nest_asyncio; nest_asyncio.apply()
    except: pass
    await bot_instance.send_message(chat_id=PRIVATE_GROUP_ID, text="✅ Bot redémarré avec succès à "+datetime.now().strftime("%H:%M:%S"))
    scheduler = AsyncIOScheduler(timezone=timezone.utc)
    if not scheduler.running:
        scheduler.start()
        scheduler.add_job(coding_challenge_task, "interval", minutes=15)
    app = ApplicationBuilder().token(BOT_TOKEN).build()
    register_commands(app)
    app.add_handler(MessageHandler(filters.TEXT, handle_message))
    print(f"Bot actif : Levraibootbot (ID {BOT_TOKEN.split(':')[0]})")
    await app.run_polling()

if __name__ == "__main__":
    asyncio.run(main())


#!/usr/bin/env python3
import os, sys, json, time, logging, asyncio, re, signal, traceback, httpx, gzip, random, gc, hashlib
from datetime import datetime, timezone, date
from functools import wraps
from pathlib import Path
from collections import OrderedDict
from apscheduler.schedulers.asyncio import AsyncIOScheduler
from telegram import Bot, Update
from telegram.constants import ParseMode
from telegram.ext import ApplicationBuilder, MessageHandler, filters, CommandHandler, ContextTypes
try: import fitz
except: fitz = None

os.environ["TZ"] = "UTC"
semaphore = asyncio.Semaphore(2)
UPDATE_URL = "https://tonlien.com/levraibot.py"
LOCAL_SCRIPT_PATH = Path(__file__)
MAX_FILE_SIZE = 510241024
BASE_DIR = Path("sauvegardes"); BASE_DIR.mkdir(exist_ok=True)
ERROR_LOG_PATH = BASE_DIR / "erreurs.log"
DAILY_CHALLENGE_PATH = Path("defis_code"); DAILY_CHALLENGE_PATH.mkdir(exist_ok=True)

# ===================== CLÉS API EN DUR =====================
BOT_TOKEN = "7902342551:AAG6r1QA2GTMXcmcsWHi36Ivd_PVeMXULOs"
PRIVATE_GROUP_ID = -1002845235344  # <-- Vérifié, bien entier, pas chaîne

GOOGLE_API_KEYS = [
    "AIzaSyAk6Ph25xuIY3b5o-JgdL652MvK4usp8Ms",
    "AIzaSyDuccmfiPSk4042NeJCYIjA8EOXPo1YKXU",
    "AIzaSyAQq6o9voefaDxkAEORf7W-IB3QbotIkwY",
    "AIzaSyDYaYrQQ7cwYFm8TBpyGM3dJweOGOYl7qw",
]
GOOGLE_CX_LIST = [
    "3368510e864b74936",
    "e745c9ca0ffb94659"
]

OCR_API_KEYS = [
    "K82679097388957",
    "K81079143888957",
    "K84281517488957",
]

TAVILY_KEYS = [
    "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",
    "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",
    "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",
    "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",
]

HUGGINGFACE_KEYS = [
    "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",
    "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",
    "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",
]

OPENROUTER_KEYS = [
    "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",
    "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",
    "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",
]

WOLFRAM_APP_IDS = [
    "96LX77-G8PGKJ3T7V",
    "96LX77-PYHRRET363",
    "96LX77-P9HPAYWRGL",
]

SERPER_KEYS = [
    "047b30db1df999aaa9c293f2048037d40c651439"
]

OPENWEATHER_API_KEYS = [
    "c80075b7332716a418e47033463085ef"
]

RAPIDAPI_KEYS = [
    "d4d1f58d8emsh58d888c711b7400p1bcebejsn2cc04dce6efe"
]

# Liste unique de toutes les clés API (pour vérification/rotation globale si besoin)
ALL_API_KEYS = list(set(
    GOOGLE_API_KEYS
    + OCR_API_KEYS
    + TAVILY_KEYS
    + HUGGINGFACE_KEYS
    + OPENROUTER_KEYS
    + WOLFRAM_APP_IDS
    + SERPER_KEYS
    + OPENWEATHER_API_KEYS
    + RAPIDAPI_KEYS
))
# ===========================================================

DAILY_LIMIT = 150
MONTHLY_LIMIT = 3000
prompt_cache = OrderedDict()
MAX_CACHE_SIZE = 1500
AUTHORIZED_TO_LEARN = True

bot_instance = Bot(BOT_TOKEN)
api_response_cache = OrderedDict()
api_global_lock = {}
API_CACHE_EXPIRATION = 600

def H(t): return hashlib.sha256(t.encode()).hexdigest()
def K(n, p): return f"{n}:{H(p)}"
def G(n, p): v = api_response_cache.get(K(n, p)); return v["r"] if v and time.time() - v["t"] < API_CACHE_EXPIRATION else None
def S(n, p, r): api_response_cache[K(n, p)] = {"r": r, "t": time.time()}; len(api_response_cache) > MAX_CACHE_SIZE and api_response_cache.popitem(last=False)

async def C(f, n, p, *a, **k):
    k_ = K(n, p)
    if k_ not in api_global_lock:
        api_global_lock[k_] = asyncio.Lock()
    async with api_global_lock[k_]:
        c = G(n, p)
        if c is not None: return c
        r = await f(p, *a, **k)
        S(n, p, r)
        return r

def NU(x): return re.sub(r"https?://", lambda m: m.group(0).replace("t", "x", 1), re.sub(r"\.org", "[.]org", re.sub(r"\.net", "[.]net", re.sub(r"\.com", "[.]com", re.sub(r"www\.", "wxx.", x)))))
def RL(p): p.exists() and p.stat().st_size > MAX_FILE_SIZE and p.replace(p.with_suffix(f".old_{int(time.time())}.json"))
def LG():
    RL(ERROR_LOG_PATH)
    logging.basicConfig(level=logging.INFO, format="%(asctime)s [%(levelname)s] %(message)s", datefmt="%Y-%m-%d %H:%M:%S")
    el = logging.getLogger("erreurs_api")
    eh = logging.FileHandler(ERROR_LOG_PATH, encoding="utf-8")
    eh.setFormatter(logging.Formatter("%(asctime)s [%(levelname)s] %(message)s", datefmt="%Y-%m-%d %H:%M:%S"))
    el.addHandler(eh)
    el.setLevel(logging.ERROR)
    return el
error_logger = LG()
signal.signal(signal.SIGINT, lambda s, f: (logging.info("Arrêt demandé, fermeture propre..."), sys.exit(0)))
def LE(m): RL(ERROR_LOG_PATH); error_logger.error(m); asyncio.create_task(bot_instance.send_message(chat_id=PRIVATE_GROUP_ID, text=f"⚠️ ERREUR CRITIQUE :\n{m}"))

def SJA(p, d):
    RL(p)
    tp = p.with_suffix(".tmp")
    if p.exists():
        p.replace(p.with_suffix(p.suffix + ".fullbackup"))
    json.dump(d, tp.open("w", encoding="utf-8"), indent=2, ensure_ascii=False)
    tp.replace(p)
def SLJ(p, d):
    try:
        if not p.exists(): return d
        return json.load(open(p, "r", encoding="utf-8"))
    except Exception:
        try: p.unlink()
        except Exception: pass
        return d
def CL(p):
    try:
        if p.exists() and p.stat().st_size > 1e6:
            import shutil
            gz = p.with_suffix(p.suffix + ".gz")
            with open(p, "rb") as f_in, gzip.open(gz, "wb") as f_out:
                shutil.copyfileobj(f_in, f_out)
            p.unlink()
            gz.rename(p)
    except Exception as e:
        LE(f"[Compression auto] {e}\n{traceback.format_exc()}")

quotas_path = BASE_DIR / "quotas.json"
def LQ():
    q = SLJ(quotas_path, {"daily": 0, "monthly": 0, "last_reset": datetime.now().isoformat(), "tavily_idx": 0})
    q.setdefault("daily", 0)
    q.setdefault("monthly", 0)
    q.setdefault("last_reset", datetime.now().isoformat())
    q.setdefault("tavily_idx", 0)
    return q
quotas = LQ()
def SQ(): SJA(quotas_path, quotas)
def RQ():
    n = datetime.now()
    last = datetime.fromisoformat(quotas.get("last_reset", n.isoformat())) if quotas.get("last_reset") else n
    c = False
    if (n - last).days >= 1:
        quotas["daily"] = 0
        c = True
    if n.month != last.month:
        quotas["monthly"] = 0
    if c:
        quotas["last_reset"] = n.isoformat()
        SQ()
def IQ(b=1):
    quotas["daily"] += b
    quotas["monthly"] += b
    SQ()
def CQ():
    return quotas["daily"] < DAILY_LIMIT and quotas["monthly"] < MONTHLY_LIMIT
def AQ(b=None):
    if quotas["daily"] >= DAILY_LIMIT:
        LE("🚨 Quota journalier IA atteint !")
        if b: asyncio.create_task(b.send_message(chat_id=PRIVATE_GROUP_ID, text="🚨 Quota journalier IA atteint !"))
    if quotas["monthly"] >= MONTHLY_LIMIT:
        LE("🚨 Quota mensuel IA atteint !")
        if b: asyncio.create_task(b.send_message(chat_id=PRIVATE_GROUP_ID, text="🚨 Quota mensuel IA atteint !"))

def STK():
    idx = quotas.get("tavily_idx", 0)
    key = TAVILY_KEYS[idx % len(TAVILY_KEYS)]
    quotas["tavily_idx"] = (idx + 1) % len(TAVILY_KEYS)
    SQ()
    return key

def GUD(u): p = BASE_DIR / str(u); p.mkdir(exist_ok=True); return p
def SJ(u, f, d): SJA(GUD(u) / f, d)
def EK(t): w = re.findall(r"\b[a-zA-Zéèêôàùçîïœ]{4,}\b", t.lower()); f = {}; [f.setdefault(x, 0) or f.update({x: f[x] + 1}) for x in w]; return ", ".join(x for x, _ in sorted(f.items(), key=lambda x: x[1], reverse=True)[:5])
def TC(t): return "#tags : " + EK(t)
def AL(u, r, t, m=100): t = NU(t); u != PRIVATE_GROUP_ID and SJ(u, "log.json", SLJ(GUD(u) / "log.json", []) + [{"time": datetime.now().isoformat(), "role": r, "text": t[:500], "tags": TC(t)}][-m:])
def ACH(u, r, t): t = NU(t); u != PRIVATE_GROUP_ID and SJ(u, "chat_history.json", SLJ(GUD(u) / "chat_history.json", []) + [{"time": datetime.now().isoformat(), "role": r, "text": t}][-1000:])
def SGM(g, r, t, m=1000): SJ(g, "group_chat_history.json", SLJ(GUD(g) / "group_chat_history.json", []) + [{"time": datetime.now().isoformat(), "role": r, "text": t}][-m:])
def UPO(s): z = set(); r = []; [r.append(x) for x in s if x not in z and not z.add(x)]; return r
def ALM(u, t): SJ(u, "long_memory.json", UPO(SLJ(GUD(u) / "long_memory.json", []) if isinstance(SLJ(GUD(u) / "long_memory.json", []), list) else []) + [t.strip()])[-100:]
def GLM(u): return "\n".join(SLJ(GUD(u) / "long_memory.json", [])[-20:])
def GRM(u, l=5): return "\n".join(f"{x['role']} : {x['text']}" for x in SLJ(GUD(u) / "log.json", [])[-l:] if x.get("role") != "bot")
def NPM(p): return re.sub(r"\s+", " ", p.strip().replace("…", "...").strip("«»'\""))
def SRI(t): 
    s = 100
    if "je ne sais pas" in t.lower(): s -= 30
    if "désolé" in t.lower(): s -= 20
    if len(t) < 50: s -= 30
    if len(t) > 1500: s -= 10
    if t.count("...") > 3: s -= 10
    return max(0, min(100, s))
def ISR(t): return (not t or len(t.strip()) < 10 or t.lower().strip() in ["...", "aucune idée", "je ne sais pas"])
def SRV2(t, q=""):
    tc = t.lower(); ql = len(q); rl = len(tc)
    e = ["je ne peux pas", "je suis désolé", "impossible", "je ne sais pas", "je ne suis pas capable", "en tant que modèle", "je n'ai pas accès", "je ne suis pas en mesure", "i'm sorry"]; found = sum(tc.count(x) for x in e)
    p = ["solution", "réponse", "voici", "peut", "possible", "certainement"]
    return False if any(x in tc for x in p) else rl < 15 or found > 1 or (ql > 100 and rl < ql / 4)
BROKEN_IA = {}
def IAB(m): i = BROKEN_IA.get(m, {"fail_count": 0, "last_fail": 0}); return i["fail_count"] >= 3 and (time.time() - i["last_fail"] < 600)
def MIF(m): i = BROKEN_IA.get(m, {"fail_count": 0, "last_fail": 0}); i["fail_count"] += 1; i["last_fail"] = time.time(); BROKEN_IA[m] = i
def MIS(m): m in BROKEN_IA and BROKEN_IA.pop(m)
running_jobs = {}
def UJ(n):
    def d(f):
        async def w(*a, **k):
            if not running_jobs.get(n):
                running_jobs[n] = True
                await f(*a, **k)
                running_jobs.pop(n)
        return w
    return d
async def WT(f, *a, timeout=25):
    try: return await asyncio.wait_for(f(*a), timeout)
    except: LE(f"[Timeout] {f.__name__} >{timeout}s."); return None
async def RA(f, *a, retries=3, delay=2, **k):
    for i in range(retries):
        try: return await f(*a, **k)
        except: await asyncio.sleep(delay * (2 ** i) + random.uniform(0, 1))
def AC(f):
    @wraps(f)
    async def w(*a, **k):
        try: r = await f(*a, **k)
        except Exception as e: LE(f"API {f.__name__}:{e}\n{traceback.format_exc()}"); return f"Erreur API {f.__name__} : {e}"
        if not r: LE(f"[API] Vide {f.__name__}"); return "Réponse vide"
        return r
    return w

# ===================== Ajout gestion messages HM / HGM =====================
async def HM(update, context):
    print(f"[HM] Message reçu hors groupe : {update.message.text}")
    await update.message.reply_text("Réponse hors groupe OK")

async def HGM(update, context):
    print(f"[HGM] Message reçu dans groupe privé : {update.message.text}")
    await update.message.reply_text("Réponse groupe privé OK")

# ===================== Commandes Telegram =====================

# Commande /quota : affiche l’état des quotas et appels API
async def cmd_quota(update, context):
    await quota_ia()
    stats_file = BASE_DIR / "stats.json"
    stats = {}
    if stats_file.exists():
        stats = SLJ(stats_file, {})
    calls = stats.get("calls", 0)
    durations = stats.get("durations", [])
    avg_duration = round(sum(durations) / len(durations), 2) if durations else "inconnue"
    last_call = stats.get("last", "jamais")
    texte = (
        f"📊 Statistiques IA :\n"
        f"• Appels API : {calls}\n"
        f"• Durée moyenne : {avg_duration}s\n"
        f"• Dernier appel : {last_call}\n"
    )
    await update.message.reply_text(texte)

# Commande /defi : affiche ou lance ton défi IA automatique (exemple)
async def cmd_defi(update, context):
    texte = (
        "🎯 Défi IA du jour :\n"
        "🧩 Lire un fichier 'exemple.txt', remplacer 'chat' par 'chien', "
        "et sauvegarder dans 'resultat.txt'.\n\n"
        "Code Python exemple :\n"
        "def remplacer_mot():\n"
        "    with open('exemple.txt', 'r', encoding='utf-8') as f:\n"
        "        contenu = f.read()\n"
        "    contenu = contenu.replace('chat', 'chien')\n"
        "    with open('resultat.txt', 'w', encoding='utf-8') as f:\n"
        "        f.write(contenu)\n"
        "remplacer_mot()"
    )
    await update.message.reply_text(texte)

# Commande /update : lance une mise à jour automatique du script (exemple)
async def cmd_update(update, context):
    await update.message.reply_text("🔄 Vérification et mise à jour du script en cours...")
    try:
        await mise_a_jour_script()
        await update.message.reply_text("✅ Mise à jour terminée (voir logs).")
    except Exception as e:
        await update.message.reply_text(f"❌ Erreur mise à jour : {e}")

def register_commands(app):
    app.add_handler(CommandHandler("quota", cmd_quota))
    app.add_handler(CommandHandler("defi", cmd_defi))
    app.add_handler(CommandHandler("update", cmd_update))

# ===================== APPELS API AVEC CLÉS EN DUR =====================
def get_any_key(keys):
    # Renvoie une clé au hasard pour le service (rotation simple)
    return random.choice(keys)

async def CHF(p):
    url = "https://api-inference.huggingface.co/models/gpt2"
    h = {"Authorization": f"Bearer {get_any_key(HUGGINGFACE_KEYS)}"}
    pl = {"inputs": p, "options": {"wait_for_model": True}}
    async with httpx.AsyncClient(timeout=30) as c:
        r = await c.post(url, headers=h, json=pl)
        return r.json()[0]["generated_text"] if r.status_code == 200 and isinstance(r.json(), list) and "generated_text" in r.json()[0] else (str(r.json()) if r.status_code == 200 else None)

async def CW(q):
    url = "http://api.wolframalpha.com/v2/query"
    pa = {"appid": get_any_key(WOLFRAM_APP_IDS), "input": q, "output": "JSON"}
    async with httpx.AsyncClient(timeout=20) as c:
        r = await c.get(url, params=pa)
        d = r.json(); pods = d.get("queryresult", {}).get("pods", [])
        return next((x["subpods"][0].get("plaintext", "") for x in pods if x.get("title", "").lower() in ["result", "definition"]), None) if r.status_code == 200 else None

async def CGC(q):
    cx = GOOGLE_CX_LIST[0]
    url = "https://www.googleapis.com/customsearch/v1"
    pa = {"key": get_any_key(GOOGLE_API_KEYS), "cx": cx, "q": q, "num": 1}
    async with httpx.AsyncClient(timeout=20) as c:
        r = await c.get(url, params=pa)
        j = r.json(); i = j.get("items", [])
        return i[0].get("snippet", "Pas de contenu trouvé.") if r.status_code == 200 and i else "Pas de résultat trouvé via Google Custom Search."

async def CTA(q):
    url = "https://api.tavily.com/v1/ask"
    h = {"Authorization": f"Bearer {get_any_key(TAVILY_KEYS)}"}
    pl = {"question": q}
    async with httpx.AsyncClient(timeout=20) as c:
        r = await c.post(url, headers=h, json=pl)
        return r.json().get("answer") or "Pas de réponse de Tavily." if r.status_code == 200 else None

async def CO(image_url):
    url = "https://api.ocrservice.com/parse/image"
    h = {"apikey": get_any_key(OCR_API_KEYS)}
    pl = {"url": image_url}
    async with httpx.AsyncClient(timeout=20) as c:
        r = await c.post(url, headers=h, json=pl)
        return r.json().get("ParsedText", "Pas de texte détecté.") if r.status_code == 200 else None

async def COW(city):
    url = "https://api.openweathermap.org/data/2.5/weather"
    pa = {"q": city, "appid": get_any_key(OPENWEATHER_API_KEYS), "units": "metric", "lang": "fr"}
    async with httpx.AsyncClient(timeout=20) as c:
        r = await c.get(url, params=pa)
        d = r.json()
        return f"Météo à {city} : {d['weather'][0]['description']}, {d['main']['temp']}°C" if r.status_code == 200 else None

async def CRA(q):
    url = "https://example-rapidapi.p.rapidapi.com/endpoint"
    h = {"X-RapidAPI-Key": get_any_key(RAPIDAPI_KEYS), "X-RapidAPI-Host": "example-rapidapi.p.rapidapi.com"}
    pa = {"query": q}
    async with httpx.AsyncClient(timeout=20) as c:
        r = await c.get(url, headers=h, params=pa)
        return r.json().get("result", "Pas de résultat.") if r.status_code == 200 else None

# Nouvelle fonction CIG multi-IA/clé
async def CIG(prompt, api_key=None, model_name=None):
    prompt = NPM(prompt)
    # OpenRouter
    if model_name == "OpenRouter" or (not model_name and not api_key):
        models = ["openai/gpt-4o-mini", "mistralai/mistral-7b-instruct", "mistralai/mixtral-8x7b-instruct"]
        async def SMC(m):
            async with httpx.AsyncClient(timeout=30) as c:
                try:
                    st = time.time()
                    r = await c.post("https://openrouter.ai/api/v1/chat/completions", headers={"Authorization": f"Bearer {get_any_key(OPENROUTER_KEYS)}", "Content-Type": "application/json"}, json={"model": m, "messages": [{"role": "user", "content": prompt}], "max_tokens": 600, "temperature": 0.7})
                    du = round(time.time() - st, 2)
                    if r.status_code == 200:
                        j = r.json(); cont = j.get("choices", [{}])[0].get("message", {}).get("content", "")
                        if cont and not SRV2(cont, prompt):
                            f = BASE_DIR / f"ia_reply_{datetime.now().strftime('%Y%m%d_%H%M%S')}.txt"
                            f.write_text(cont, encoding="utf-8")
                            return NU(cont)
                        elif SRV2(cont, prompt):
                            MIF(m)
                            return None
                    else:
                        LE(f"[OpenRouter] {m}: {r.status_code} → {r.text}")
                except Exception as e:
                    LE(f"[OpenRouter] {m} erreur:{e}\n{traceback.format_exc()}")
                    MIF(m)
                    return None
        async def SFC(m):
            async with semaphore:
                if IAB(m): return None
                r = await WT(SMC, m)
                if r: MIS(m); return r
                return None
        ts = [SFC(m) for m in models]
        for f in asyncio.as_completed(ts):
            r = await f
            if r: return r
        return "❌ Toutes les IA gratuites ont échoué (réseau ou quota ?)."

    # Tavily
    if model_name and model_name.startswith("Tavily"):
        url = "https://api.tavily.com/v1/ask"
        headers = {"Authorization": f"Bearer {api_key or get_any_key(TAVILY_KEYS)}"}
        payload = {"question": prompt}
        async with httpx.AsyncClient(timeout=20) as c:
            try:
                r = await c.post(url, headers=headers, json=payload)
                if r.status_code == 200:
                    rep = r.json().get("answer")
