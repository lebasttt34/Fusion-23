            "mockaroo_data": {
                "enabled": True,
                "description": "Génère des données de test aléatoires via Mockaroo en fonction d'un schéma JSON.",
                "parameters": {
                    "count": {"type": "INTEGER", "description": "Le nombre d'enregistrements à générer.", "required": False, "default": 1},
                    "fields_json": {"type": "STRING", "description": "Un tableau JSON de définitions de champs (ex: '[{\"name\":\"id\",\"type\":\"Row Number\"}]').", "required": False}
                }
            },
            "openpagerank": {
                "enabled": True,
                "description": "Récupère le PageRank de domaines via OpenPageRank. Utile pour évaluer l'autorité d'un site web.",
                "parameters": {
                    "domains": {"type": "ARRAY", "items": {"type": "STRING"}, "description": "Liste des noms de domaine à vérifier (ex: ['google.com', 'openai.com']).", "required": True}
                }
            },
            "rapidapi": {
                "enabled": True,
                "description": "Interroge diverses APIs disponibles via RapidAPI (blagues, taux de change, faits aléatoires).",
                "parameters": {
                    "api_name": {"type": "STRING", "description": "Le nom de l'API RapidAPI à utiliser (ex: 'Programming Joke', 'Currency List Quotes', 'Random Fact').", "required": True, "enum": ["Programming Joke", "Currency List Quotes", "Random Fact"]},
                    "api_kwargs": {"type": "OBJECT", "description": "Arguments spécifiques à l'API RapidAPI appelée.", "required": False}
                }
            },
            "run_in_sandbox": {
                "enabled": True,
                "description": "Exécute du code Python ou Shell dans une sandbox sécurisée. Utilisez cet outil pour tester ou exécuter des extraits de code.",
                "parameters": {
                    "code": {"type": "STRING", "description": "Le code à exécuter.", "required": True},
                    "language": {"type": "STRING", "description": "Le langage du code ('python' ou 'shell').", "required": False, "default": "python", "enum": ["python", "shell"]}
                }
            },
            "webcontainer_sandbox": {
                "enabled": True,
                "description": "Exécute du code dans un environnement WebContainer pour JavaScript/HTML/CSS.",
                "parameters": {
                    "code": {"type": "STRING", "description": "Le code à exécuter.", "required": True},
                    "language": {"type": "STRING", "description": "Le langage du code ('javascript', 'html', 'css').", "required": False, "default": "javascript"}
                }
            },
            "fetch_and_archive_pages": {
                "enabled": True,
                "description": "Télécharge, sécurise et archive des pages web avec protection contre les trackers.",
                "parameters": {
                    "links": {"type": "ARRAY", "items": {"type": "STRING"}, "description": "Liste des URLs à archiver.", "required": True},
                    "user_id": {"type": "STRING", "description": "Identifiant de l'utilisateur pour l'archivage.", "required": True}
                }
            },
            "run_coding_challenge": {
                "enabled": True,
                "description": "Lance un défi de codage complet et compétitif entre tous les agents IA disponibles pour résoudre un problème complexe. Utilise cet outil pour obtenir et comparer plusieurs solutions optimisées à un problème de programmation.",
                "parameters": {
                    "custom_prompt": {
                        "type": "STRING",
                        "description": "Optionnel. Un prompt de défi spécifique. Si non fourni, un défi aléatoire sera généré.",
                        "required": False
                    }
                }
            }
        }

# Instance globale de configuration
config = Config()

# api_clients.py

import os
from pathlib import Path
from typing import Dict, Any, List, Optional, Tuple, Union
from datetime import datetime
import requests
import json
import asyncio
import httpx
from typing import Dict, Any, List, Optional, Tuple, Union # Redondant, mais laissé tel quel si c'était dans l'original
import logging
import random
import google.generativeai as genai
from google.generativeai import types

# AJOUT 1: Importer la nouvelle fonction de logging et les dépendances
from telegram_logger import log_api_call_to_telegram
from config import config
from app_singletons import endpoint_health_manager, quota_manager
from utils import log_message

class ApiClient:
    """
    Classe de base pour tous les clients API des 7 cerveaux autonomes.
    Gère les requêtes HTTP, la rotation des clés et le basculement automatique.
    ### MODIFICATION : Intégration du logging systématique.
    """
    def __init__(self, service_name: str, config_manager: Any,
                 health_manager: Any, quota_manager: Any):
        self.service_name = service_name
        self.config = config_manager
        self.health_manager = health_manager
        self.quota_manager = quota_manager
        self.endpoints = self.config.API_CONFIG.get(service_name, [])
        self.current_endpoint_index = 0
        self.last_rotation_time = datetime.now()

        if not self.endpoints:
            log_message(f"Aucun endpoint configuré pour le service {service_name}", level="warning")

    async def _make_request(self, endpoint_config: Dict[str, Any],
                          url_suffix: str = "", params: Optional[Dict] = None,
                          json_data: Optional[Dict] = None,
                          files: Optional[Dict] = None) -> Union[Dict, str]:
        """Effectue une requête HTTP et logue l'activité sur Telegram."""
        full_url = endpoint_config["url"] + url_suffix
        method = endpoint_config["method"]
        timeout = endpoint_config.get("timeout", 30)
        headers = endpoint_config.get("fixed_headers", {}).copy()
        req_params = endpoint_config.get("fixed_params", {}).copy()

        if params:
            req_params.update(params)

        key_field = endpoint_config.get("key_field")
        key_location = endpoint_config.get("key_location")
        key = endpoint_config.get("key")
        key_prefix = endpoint_config.get("key_prefix", "")
        endpoint_name = endpoint_config.get("endpoint_name", "Unknown Endpoint")

        if key:
            if key_location == "header":
                headers[key_field] = f"{key_prefix}{key}"
            elif key_location == "param":
                req_params[key_field] = key
            elif key_location == "auth_basic" and isinstance(key, tuple) and len(key) == 2:
                pass

        start_time = asyncio.get_event_loop().time()
        
        try:
            async with httpx.AsyncClient() as client:
                log_message(f"Requête {self.service_name} vers {full_url}")

                request_kwargs = {
                    "params": req_params,
                    "headers": headers,
                    "timeout": timeout
                }

                if json_data:
                    request_kwargs["json"] = json_data
                if files:
                    request_kwargs["files"] = files
                if key_location == "auth_basic" and isinstance(key, tuple) and len(key) == 2:
                    request_kwargs["auth"] = key

                if method == "POST":
                    response = await client.post(full_url, **request_kwargs)
                elif method == "GET":
                    response = await client.get(full_url, **request_kwargs)
                else:
                    raise ValueError(f"Méthode HTTP non supportée: {method}")

                latency_ms = int((asyncio.get_event_loop().time() - start_time) * 1000)
                response.raise_for_status()
                
                log_message(f"Réponse {self.service_name}: {response.status_code} en {latency_ms/1000:.2f}s")

                # AJOUT: Loguer le SUCCÈS à Telegram
                await log_api_call_to_telegram(
                    service_name=self.service_name,
                    endpoint_name=endpoint_name,
                    api_key=str(key),
                    success=True,
                    status_code=response.status_code,
                    latency_ms=latency_ms
                )

                try:
                    return response.json()
                except json.JSONDecodeError:
                    return {"status": "success", "content": response.text}

        except httpx.HTTPStatusError as e:
            latency_ms = int((asyncio.get_event_loop().time() - start_time) * 1000)
            log_message(f"API {self.service_name} erreur HTTP: {e.response.status_code} - {e.response.text}", level="warning")
            
            # AJOUT: Loguer l'ÉCHEC (Erreur HTTP) à Telegram
            await log_api_call_to_telegram(
                service_name=self.service_name,
                endpoint_name=endpoint_name,
                api_key=str(key),
                success=False,
                status_code=e.response.status_code,
                latency_ms=latency_ms,
                error_message=f"HTTP Status {e.response.status_code}"
            )
            # La gestion du marquage unhealthy est maintenant gérée par l'AutonomousParticipant.
            return f"❌ Erreur API {self.service_name}: {e.response.status_code} - {e.response.text}"

        except httpx.RequestError as e:
            latency_ms = int((asyncio.get_event_loop().time() - start_time) * 1000)
            log_message(f"API {self.service_name} erreur réseau: {e}", level="warning")

            # AJOUT: Loguer l'ÉCHEC (Erreur Réseau) à Telegram
            await log_api_call_to_telegram(
                service_name=self.service_name,
                endpoint_name=endpoint_name,
                api_key=str(key),
                success=False,
                status_code=None, # Pas de code de statut pour une erreur réseau
                latency_ms=latency_ms,
                error_message=f"Network Error: {type(e).__name__}"
            )
            # La gestion du marquage unhealthy est maintenant gérée par l'AutonomousParticipant.
            return f"❌ Erreur réseau pour {self.service_name}: {e}"

        except Exception as e:
            latency_ms = int((asyncio.get_event_loop().time() - start_time) * 1000)
            log_message(f"API {self.service_name} erreur inattendue: {e}", level="error")

            # AJOUT: Loguer l'ÉCHEC (Erreur Inattendue) à Telegram
            await log_api_call_to_telegram(
                service_name=self.service_name,
                endpoint_name=endpoint_name,
                api_key=str(key),
                success=False,
                status_code=None,
                latency_ms=latency_ms,
                error_message=f"Unexpected Error: {type(e).__name__}"
            )
            # La gestion du marquage unhealthy est maintenant gérée par l'AutonomousParticipant.
            return f"❌ Erreur inattendue pour {self.service_name}: {e}"

    async def _get_available_endpoint(self) -> List[Dict[str, Any]]:
        """
        Retourne la liste complète de tous les endpoints configurés pour ce service.
        La logique de sélection et de rotation est déplacée vers l'Agent Autonome.
        """
        if not self.endpoints:
            log_message(f"Aucun endpoint configuré pour le service {self.service_name}.", level="warning")
            return []
        return self.endpoints

    async def _increment_quota(self, success: bool = True):
        """Incrémente le quota pour le service, en indiquant si l'opération a réussi."""
        await self.quota_manager.increment_quota(self.service_name, success=success)

    async def execute_with_specific_config(
        self,
        endpoint_config: Dict[str, Any],
        url_suffix: str = "",
        params: Optional[Dict] = None,
        json_data: Optional[Dict] = None,
        files: Optional[Dict] = None
    ) -> Union[Dict, str]:
        """
        Exécute une requête en utilisant une configuration de clé/endpoint spécifique.
        """
        if not endpoint_config:
            return f"❌ Erreur d'exécution : Aucune configuration d'endpoint fournie pour {self.service_name}."

        log_message(f"Exécution forcée pour {self.service_name} avec l'endpoint: {endpoint_config.get('endpoint_name')}")

        has_quota = await self.quota_manager.check_quota(self.service_name)
        if not has_quota:
            return f"❌ Quota dépassé pour le service {self.service_name}."

        result = await self._make_request(
            endpoint_config=endpoint_config,
            url_suffix=url_suffix,
            params=params,
            json_data=json_data,
            files=files
        )

        # Détermine si la requête a réussi pour l'incrémentation du quota
        request_success = not (isinstance(result, str) and result.startswith("❌"))
        await self._increment_quota(success=request_success)
        return result

class LLMApiClient(ApiClient):
    """Classe de base pour les clients d'API de modèles de langage."""
    def __init__(self, service_name: str, config_manager: Any,
                 health_manager: Any, quota_manager: Any):
        super().__init__(service_name, config_manager, health_manager, quota_manager)
        self.default_model: str = ""

    async def generate_content(self, endpoint_config: Dict[str, Any], # MODIFIÉ
                              prompt: Union[str, List[Dict[str, Any]]],
                              chat_history: List[Dict[str, Any]],
                              image_data: Optional[str] = None,
                              tools: Optional[List[Dict]] = None,
                              model_name: Optional[str] = None) -> Union[Dict, str]:
        """Méthode abstraite pour générer du contenu."""
        raise NotImplementedError("La méthode 'generate_content' doit être implémentée par les sous-classes.")

class GeminiApiClient(LLMApiClient):
    """Client API pour Gemini avec support complet des 7 cerveaux autonomes."""
    def __init__(self, health_manager: Any, quota_manager: Any):
        super().__init__("GEMINI_API", config, health_manager, quota_manager)
        self.default_model = "gemini-1.5-flash-latest"
        log_message(f"GeminiApiClient initialisé avec le modèle par défaut: {self.default_model}")

    async def generate_content(self, endpoint_config: Dict[str, Any], # MODIFIÉ
                              prompt: Union[str, List[Dict[str, Any]]],
                              chat_history: List[Dict[str, Any]],
                              image_data: Optional[str] = None,
                              tools: Optional[List[Dict]] = None,
                              model_name: Optional[str] = None) -> Union[Dict, str]:
        """Génère du contenu textuel en utilisant le modèle Gemini."""
        log_message(f"Appel à Gemini API pour le modèle {model_name or self.default_model} via endpoint: {endpoint_config.get('endpoint_name', 'N/A')}")

        if not endpoint_config or not endpoint_config.get("key"):
            return f"❌ Erreur Gemini: Configuration d'endpoint ou clé API manquante."

        genai.configure(api_key=endpoint_config["key"])
        log_message(f"Configuration de genai avec la clé de l'endpoint: {endpoint_config['endpoint_name']}")

        contents = []
        for msg in chat_history:
            formatted_parts = []
            for part in msg.get("parts", []):
                if "text" in part:
                    formatted_parts.append(part["text"])
                elif "function_response" in part:
                    formatted_parts.append(genai.types.FunctionResponse(
                        name=part["function_response"]["name"],
                        response=part["function_response"]["response"]
                    ))
                elif "function_call" in part:
                    formatted_parts.append(genai.types.FunctionCall(
                        name=part["function_call"]["name"],
                        args=part["function_call"]["args"]
                    ))
                elif "inlineData" in part:
                    formatted_parts.append(genai.types.Blob(
                        mime_type=part["inlineData"]["mimeType"],
                        data=part["inlineData"]["data"]
                    ))
            contents.append({"role": msg["role"], "parts": formatted_parts})

        user_parts = []
        if isinstance(prompt, str):
            user_parts.append(prompt)
        elif isinstance(prompt, list):
            user_parts.extend(prompt)

        if image_data:
            mime_type = image_data.split(';')[0].split(':')[1]
            base64_string = image_data.split(',')[1]
            user_parts.append(genai.types.Blob(mime_type=mime_type, data=base64_string))

        contents.append({"role": "user", "parts": user_parts})

        genai_tools = None
        if tools:
            genai_tools = [genai.types.FunctionDeclaration(**tool["function_declarations"][0]) 
                          for tool in tools if "function_declarations" in tool and tool["function_declarations"]]

        try:
            model_to_use = model_name if model_name else self.default_model
            model_instance = genai.GenerativeModel(model_to_use, tools=genai_tools)

            response = await model_instance.generate_content_async(
                contents=contents,
                generation_config=genai.types.GenerationConfig(
                    temperature=config.GEMINI_TEMPERATURE,
                    top_p=config.GEMINI_TOP_P,
                    top_k=config.GEMINI_TOP_K,
                    max_output_tokens=config.GEMINI_MAX_OUTPUT_TOKENS,
                ),
                safety_settings=config.GEMINI_SAFETY_SETTINGS,
            )

            response_dict = response.to_dict()
            return response_dict

        except Exception as e:
            log_message(f"API GEMINI_API erreur sur l'endpoint {endpoint_config['endpoint_name']}: {e}", level="error")
            # La gestion du marquage unhealthy et de l'incrémentation du quota (avec succès=False)
            # est maintenant gérée par l'AutonomousParticipant.
            # Ici, nous nous contentons de retourner l'erreur.
            return f"❌ Erreur Gemini: {e}"

class TelegramBotClient(ApiClient):
    """Client API pour l'API Bot de Telegram."""
    def __init__(self, health_manager: Any, quota_manager: Any):
        super().__init__("TELEGRAM_BOT", config, health_manager, quota_manager)
        
        if not self.endpoints:
            self.endpoints.append({
                "endpoint_name": "Telegram Bot API",
                "url": f"https://api.telegram.org/bot{config.TELEGRAM_BOT_TOKEN}",
                "method": "POST",
                "key_field": None,
                "key_location": None,
                "key": config.TELEGRAM_BOT_TOKEN,
                "timeout": 10,
                "fixed_headers": {"Content-Type": "application/json"},
                "health_check_url_suffix": "/getMe",
                "health_check_json": {}
            })
        log_message("TelegramBotClient initialisé.")

    async def send_message(self, endpoint_config: Dict[str, Any], # AJOUTÉ
                           chat_id: Union[int, str], text: str, parse_mode: Optional[str] = None) -> Union[Dict, str]:
        """Envoie un message texte à un chat Telegram spécifié."""
        if not endpoint_config: # AJOUTÉ
            return f"❌ Erreur Telegram: Configuration d'endpoint manquante." # AJOUTÉ

        json_data = {
            "chat_id": chat_id,
            "text": text,
        }
        if parse_mode:
            json_data["parse_mode"] = parse_mode

        send_message_url_suffix = "/sendMessage"
        return await self._make_request(endpoint_config, url_suffix=send_message_url_suffix, json_data=json_data)

class WebContainerClient(ApiClient):
    def __init__(self, health_manager: Any, quota_manager: Any):
        super().__init__("WEBCONTAINER", config, health_manager, quota_manager)

    async def run_code(self, endpoint_config: Dict[str, Any], # AJOUTÉ
                       code: str, language: str = "javascript") -> Union[Dict, str]:
        if not endpoint_config:
            return f"❌ Erreur WebContainer: Configuration d'endpoint manquante."

        json_data = {
            "action": "execute",
            "language": language,
            "code": code
        }
        return await self._make_request(endpoint_config, json_data=json_data)

class OCRApiClient(ApiClient):
    def __init__(self, health_manager: Any, quota_manager: Any):
        super().__init__("OCR_API", config, health_manager, quota_manager)

    async def parse_image(self, endpoint_config: Dict[str, Any], # AJOUTÉ
                          image_base64: str, language: str = "eng") -> Union[Dict, str]:
        if not endpoint_config:
            return f"❌ Erreur OCR: Configuration d'endpoint manquante."

        json_data = {
            "base64Image": image_base64,
            "language": language,
            "isOverlayRequired": False
        }
        return await self._make_request(endpoint_config, json_data=json_data)

class DeepSeekClient(ApiClient):
    def __init__(self, health_manager: Any, quota_manager: Any):
        super().__init__("DEEPSEEK", config, health_manager, quota_manager)

    async def chat_completion(self, endpoint_config: Dict[str, Any], # AJOUTÉ
                              messages: List[Dict[str, str]], model: str = "deepseek-chat") -> Union[Dict, str]:
        if not endpoint_config:
            return f"❌ Erreur DeepSeek: Configuration d'endpoint manquante."

        json_data = {
            "model": model,
            "messages": messages
        }
        return await self._make_request(endpoint_config, json_data=json_data)

class SerperClient(ApiClient):
    def __init__(self, health_manager: Any, quota_manager: Any):
        super().__init__("SERPER", config, health_manager, quota_manager)

    async def search(self, endpoint_config: Dict[str, Any], # AJOUTÉ
                     query: str) -> Union[Dict, str]:
        if not endpoint_config:
            return f"❌ Erreur Serper: Configuration d'endpoint manquante."

        json_data = {"q": query}
        return await self._make_request(endpoint_config, json_data=json_data)

class WolframAlphaClient(ApiClient):
    def __init__(self, health_manager: Any, quota_manager: Any):
        super().__init__("WOLFRAMALPHA", config, health_manager, quota_manager)

    async def query(self, endpoint_config: Dict[str, Any], # AJOUTÉ
                    input_text: str) -> Union[Dict, str]:
        if not endpoint_config:
            return f"❌ Erreur WolframAlpha: Configuration d'endpoint manquante."

        params = {"input": input_text, "output": "json"}
        return await self._make_request(endpoint_config, params=params)

class TavilyClient(ApiClient):
    def __init__(self, health_manager: Any, quota_manager: Any):
        super().__init__("TAVILY", config, health_manager, quota_manager)

    async def search(self, endpoint_config: Dict[str, Any], # AJOUTÉ
                     query: str, max_results: int = 3) -> Union[Dict, str]:
        if not endpoint_config:
            return f"❌ Erreur Tavily: Configuration d'endpoint manquante."

        json_data = {"query": query, "max_results": max_results}
        return await self._make_request(endpoint_config, json_data=json_data)

class ApiFlashClient(ApiClient):
    def __init__(self, health_manager: Any, quota_manager: Any):
        super().__init__("APIFLASH", config, health_manager, quota_manager)

    async def screenshot(self, endpoint_config: Dict[str, Any], # AJOUTÉ
                         url: str) -> Union[Dict, str]:
        if not endpoint_config:
            return f"❌ Erreur ApiFlash: Configuration d'endpoint manquante."

        params = {"url": url, "format": "jpeg"}
        return await self._make_request(endpoint_config, params=params)

class CrawlbaseClient(ApiClient):
    def __init__(self, health_manager: Any, quota_manager: Any):
        super().__init__("CRAWLBASE", config, health_manager, quota_manager)

    async def scrape(self, endpoint_config: Dict[str, Any], # AJOUTÉ
                     url: str, use_js: bool = False) -> Union[Dict, str]:
        if not endpoint_config:
            return f"❌ Erreur Crawlbase: Configuration d'endpoint manquante."

        params = {"url": url}
        if use_js:
            params["javascript"] = "true"
        return await self._make_request(endpoint_config, params=params)

class DetectLanguageClient(ApiClient):
    def __init__(self, health_manager: Any, quota_manager: Any):
        super().__init__("DETECTLANGUAGE", config, health_manager, quota_manager)

    async def detect(self, endpoint_config: Dict[str, Any], # AJOUTÉ
                     text: str) -> Union[Dict, str]:
        if not endpoint_config:
            return f"❌ Erreur DetectLanguage: Configuration d'endpoint manquante."

        json_data = {"q": text}
        return await self._make_request(endpoint_config, json_data=json_data)

class GuardianClient(ApiClient):
    def __init__(self, health_manager: Any, quota_manager: Any):
        super().__init__("GUARDIAN", config, health_manager, quota_manager)

    async def search_news(self, endpoint_config: Dict[str, Any], # AJOUTÉ
                          query: str) -> Union[Dict, str]:
        if not endpoint_config:
            return f"❌ Erreur Guardian: Configuration d'endpoint manquante."

        params = {"q": query}
        return await self._make_request(endpoint_config, params=params)

class IP2LocationClient(ApiClient):
    def __init__(self, health_manager: Any, quota_manager: Any):
        super().__init__("IP2LOCATION", config, health_manager, quota_manager)

    async def geolocate_ip(self, endpoint_config: Dict[str, Any], # AJOUTÉ
                           ip_address: str) -> Union[Dict, str]:
        if not endpoint_config:
            return f"❌ Erreur IP2Location: Configuration d'endpoint manquante."

        params = {"ip": ip_address, "package": "WS24", "format": "json"}
        return await self._make_request(endpoint_config, params=params)

class ShodanClient(ApiClient):
    def __init__(self, health_manager: Any, quota_manager: Any):
        super().__init__("SHODAN", config, health_manager, quota_manager)

    async def get_info(self, endpoint_config: Dict[str, Any], # AJOUTÉ
                       query_text: str = "") -> Union[Dict, str]:
        if not endpoint_config:
            return f"❌ Erreur Shodan: Configuration d'endpoint manquante."

        if query_text:
            url_suffix = f"/{query_text}"
            return await self._make_request(endpoint_config, url_suffix=url_suffix)
        else:
            api_info_endpoint = next((ep for ep in self.endpoints if "API Info" in ep.get("endpoint_name", "")), None)
            if api_info_endpoint:
                return await self._make_request(api_info_endpoint)
            else:
                return "❌ Erreur Shodan: Endpoint 'API Info' non trouvé dans la configuration."

class WeatherAPIClient(ApiClient):
    def __init__(self, health_manager: Any, quota_manager: Any):
        super().__init__("WEATHERAPI", config, health_manager, quota_manager)

    async def get_current_weather(self, endpoint_config: Dict[str, Any], # AJOUTÉ
                                  location: str) -> Union[Dict, str]:
        if not endpoint_config:
            return f"❌ Erreur WeatherAPI: Configuration d'endpoint manquante."

        params = {"q": location}
        return await self._make_request(endpoint_config, params=params)

class CloudmersiveClient(ApiClient):
    def __init__(self, health_manager: Any, quota_manager: Any):
        super().__init__("CLOUDMERSIVE", config, health_manager, quota_manager)

    async def validate_domain(self, endpoint_config: Dict[str, Any], # AJOUTÉ
                              domain: str) -> Union[Dict, str]:
        if not endpoint_config:
            return f"❌ Erreur Cloudmersive: Configuration d'endpoint manquante."

        json_data = {"domain": domain}
        return await self._make_request(endpoint_config, json_data=json_data)

class GreyNoiseClient(ApiClient):
    def __init__(self, health_manager: Any, quota_manager: Any):
        super().__init__("GREYNOISE", config, health_manager, quota_manager)

    async def ip_lookup(self, endpoint_config: Dict[str, Any], # AJOUTÉ
                        ip_address: str) -> Union[Dict, str]:
        if not endpoint_config:
            return f"❌ Erreur GreyNoise: Configuration d'endpoint manquante."

        url_suffix = f"/{ip_address}"
        return await self._make_request(endpoint_config, url_suffix=url_suffix)

class PulsediveClient(ApiClient):
    def __init__(self, health_manager: Any, quota_manager: Any):
        super().__init__("PULSEDIVE", config, health_manager, quota_manager)

    async def analyze_indicator(self, endpoint_config: Dict[str, Any], # AJOUTÉ
                                indicator: str, type: str = "auto") -> Union[Dict, str]:
        if not endpoint_config:
            return f"❌ Erreur Pulsedive: Configuration d'endpoint manquante."

        params = {"indicator": indicator, "type": type}
        return await self._make_request(endpoint_config, params=params)

class StormGlassClient(ApiClient):
    def __init__(self, health_manager: Any, quota_manager: Any):
        super().__init__("STORMGLASS", config, health_manager, quota_manager)

    async def get_weather_point(self, endpoint_config: Dict[str, Any], # AJOUTÉ
                                lat: float, lng: float, params: str = "airTemperature,waveHeight") -> Union[Dict, str]:
        if not endpoint_config:
            return f"❌ Erreur StormGlass: Configuration d'endpoint manquante."

        req_params = {"lat": lat, "lng": lng, "params": params}
        return await self._make_request(endpoint_config, params=req_params)

class LoginRadiusClient(ApiClient):
    def __init__(self, health_manager: Any, quota_manager: Any):
        super().__init__("LOGINRADIUS", config, health_manager, quota_manager)

    async def ping(self, endpoint_config: Dict[str, Any]) -> Union[Dict, str]: # AJOUTÉ
        if not endpoint_config:
            return f"❌ Erreur LoginRadius: Configuration d'endpoint manquante."

        return await self._make_request(endpoint_config)

class JsonbinClient(ApiClient):
    def __init__(self, health_manager: Any, quota_manager: Any):
        super().__init__("JSONBIN", config, health_manager, quota_manager)

    async def handle_bin(self, endpoint_config: Dict[str, Any], # AJOUTÉ
                         data: Optional[Dict] = None, private: bool = True, bin_id: Optional[str] = None) -> Union[Dict, str]:
        if not endpoint_config:
            return f"❌ Erreur Jsonbin: Configuration d'endpoint manquante."

        if bin_id:
            # The caller (AutonomousParticipant) should provide the correct endpoint_config for Bin Access.
            if "Bin Access" in endpoint_config.get("endpoint_name", ""):
                return await self._make_request(endpoint_config, url_suffix=f"/{bin_id}")
            else:
                return "❌ Erreur Jsonbin: Endpoint 'Bin Access' non fourni pour accéder à un bin."
        elif data:
            # The caller (AutonomousParticipant) should provide the correct endpoint_config for Bin Create.
            if "Bin Create" in endpoint_config.get("endpoint_name", ""):
                json_data = {"record": data, "private": private}
                return await self._make_request(endpoint_config, json_data=json_data)
            else:
                return "❌ Erreur Jsonbin: Endpoint 'Bin Create' non fourni pour créer un bin."
        else:
            return "❌ Erreur Jsonbin: Veuillez fournir des données pour créer un bin ou un ID de bin pour y accéder."

class HuggingFaceClient(ApiClient):
    def __init__(self, health_manager: Any, quota_manager: Any):
        super().__init__("HUGGINGFACE", config, health_manager, quota_manager)

    async def inference(self, endpoint_config: Dict[str, Any], # AJOUTÉ
                        model_name: str, input_text: str) -> Union[Dict, str]:
        if not endpoint_config:
            return f"❌ Erreur HuggingFace: Configuration d'endpoint manquante."

        url_suffix = model_name
        json_data = {"inputs": input_text}
        return await self._make_request(endpoint_config, url_suffix=url_suffix, json_data=json_data)

class TwilioClient(ApiClient):
    def __init__(self, health_manager: Any, quota_manager: Any):
        super().__init__("TWILIO", config, health_manager, quota_manager)

    async def get_account_balance(self, endpoint_config: Dict[str, Any]) -> Union[Dict, str]: # AJOUTÉ
        if not endpoint_config:
            return f"❌ Erreur Twilio: Configuration d'endpoint manquante."

        return await self._make_request(endpoint_config)

class AbstractAPIClient(ApiClient):
    def __init__(self, health_manager: Any, quota_manager: Any):
        super().__init__("ABSTRACTAPI", config, health_manager, quota_manager)

    async def call_api(self, endpoint_config: Dict[str, Any], # AJOUTÉ
                       input_value: str, api_type: str) -> Union[Dict, str]:
        if not endpoint_config:
            return f"❌ Erreur AbstractAPI: Configuration d'endpoint manquante."

        params = {}
        url_suffix = ""

        # The caller (AutonomousParticipant) should provide the correct endpoint_config for the specific api_type.
        # We assume endpoint_config is already the correct one for the requested api_type.
        if api_type == "EMAIL_VALIDATION":
            params["email"] = input_value
        elif api_type == "PHONE_VALIDATION":
            params["phone"] = input_value
        elif api_type == "EXCHANGE_RATES":
            params["base"] = input_value
        elif api_type == "HOLIDAYS":
            params["country"] = input_value
            params["year"] = datetime.now().year
        else:
            return f"❌ Type d'API AbstractAPI non supporté: {api_type}"

        return await self._make_request(endpoint_config, params=params, url_suffix=url_suffix)

class GoogleCustomSearchClient(ApiClient):
    def __init__(self, health_manager: Any, quota_manager: Any):
        super().__init__("GOOGLE_CUSTOM_SEARCH", config, health_manager, quota_manager)

    async def search(self, endpoint_config: Dict[str, Any], # AJOUTÉ
                     query: str) -> Union[Dict, str]:
        if not endpoint_config:
            return f"❌ Erreur Google Custom Search: Configuration d'endpoint manquante."

        params = {"q": query}
        return await self._make_request(endpoint_config, params=params)

class RandommerClient(ApiClient):
    def __init__(self, health_manager: Any, quota_manager: Any):
        super().__init__("RANDOMMER", config, health_manager, quota_manager)

    async def generate_phone_number(self, endpoint_config: Dict[str, Any], # AJOUTÉ
                                    country_code: str = "US", quantity: int = 1) -> Union[Dict, str]:
        if not endpoint_config:
            return f"❌ Erreur Randommer: Configuration d'endpoint manquante."

        params = {"CountryCode": country_code, "Quantity": quantity}
        return await self._make_request(endpoint_config, params=params)

class TomorrowIOClient(ApiClient):
    def __init__(self, health_manager: Any, quota_manager: Any):
        super().__init__("TOMORROW.IO", config, health_manager, quota_manager)

    async def get_weather_timelines(self, endpoint_config: Dict[str, Any], # AJOUTÉ
                                    location: str, fields: List[str]) -> Union[Dict, str]:
        if not endpoint_config:
            return f"❌ Erreur Tomorrow.io: Configuration d'endpoint manquante."

        json_data = {
            "location": location,
            "fields": fields,
            "units": "metric",
            "timesteps": ["1h"]
        }
        return await self._make_request(endpoint_config, json_data=json_data)

class OpenWeatherMapClient(ApiClient):
    def __init__(self, health_manager: Any, quota_manager: Any):
        super().__init__("OPENWEATHERMAP", config, health_manager, quota_manager)

    async def get_current_weather(self, endpoint_config: Dict[str, Any], # AJOUTÉ
                                  location: str) -> Union[Dict, str]:
        if not endpoint_config:
            return f"❌ Erreur OpenWeatherMap: Configuration d'endpoint manquante."

        params = {"q": location}
        return await self._make_request(endpoint_config, params=params)

class MockarooClient(ApiClient):
    def __init__(self, health_manager: Any, quota_manager: Any):
        super().__init__("MOCKAROO", config, health_manager, quota_manager)

    async def generate_data(self, endpoint_config: Dict[str, Any], # AJOUTÉ
                            count: int = 1, fields_json: Optional[str] = None) -> Union[Dict, str]:
        if not endpoint_config:
            return f"❌ Erreur Mockaroo: Configuration d'endpoint manquante."

        params = {"count": count}
        if fields_json:
            params["fields"] = fields_json
        return await self._make_request(endpoint_config, params=params)

class OpenPageRankClient(ApiClient):
    def __init__(self, health_manager: Any, quota_manager: Any):
        super().__init__("OPENPAGERANK", config, health_manager, quota_manager)

    async def get_page_rank(self, endpoint_config: Dict[str, Any], # AJOUTÉ
                            domains: List[str]) -> Union[Dict, str]:
        if not endpoint_config:
            return f"❌ Erreur OpenPageRank: Configuration d'endpoint manquante."

        params = {"domains[]": domains}
        return await self._make_request(endpoint_config, params=params)

class RapidAPIClient(ApiClient):
    def __init__(self, health_manager: Any, quota_manager: Any):
        super().__init__("RAPIDAPI", config, health_manager, quota_manager)

    async def call_rapidapi_endpoint(self, endpoint_config: Dict[str, Any], # AJOUTÉ
                                     api_name: str, api_kwargs: Optional[Dict] = None) -> Union[Dict, str]:
        if not endpoint_config:
            return f"❌ Erreur RapidAPI: Configuration d'endpoint manquante."

        # The caller (AutonomousParticipant) should provide the correct endpoint_config for the specific api_name.
        # We assume endpoint_config is already the correct one for the requested api_name.
        params = api_kwargs if api_kwargs else {}
        return await self._make_request(endpoint_config, params=params)
       
  # app_clients_instances.py

import google.generativeai as genai
from google.generativeai import types
import asyncio
from typing import Dict, Any, List, Optional, Union

from config import config
from app_singletons import endpoint_health_manager, quota_manager
from api_clients import (
    ApiClient, WebContainerClient, OCRApiClient, DeepSeekClient, SerperClient,
    WolframAlphaClient, TavilyClient, ApiFlashClient, CrawlbaseClient,
    DetectLanguageClient, GuardianClient, IP2LocationClient, ShodanClient,
    WeatherAPIClient, CloudmersiveClient, GreyNoiseClient, PulsediveClient,
    StormGlassClient, LoginRadiusClient, JsonbinClient, HuggingFaceClient,
    TwilioClient, AbstractAPIClient, GoogleCustomSearchClient,
    RandommerClient, TomorrowIOClient, OpenWeatherMapClient, MockarooClient,
    OpenPageRankClient, RapidAPIClient,
    GeminiApiClient, TelegramBotClient
)
from utils import log_message

# Instanciation de tous les clients API pour les 7 cerveaux autonomes
# Chaque client est instancié avec les gestionnaires de santé et de quotas

# Clients principaux pour les 7 cerveaux
gemini_client = GeminiApiClient(endpoint_health_manager, quota_manager)
telegram_bot_client = TelegramBotClient(endpoint_health_manager, quota_manager)

# Clients pour services auxiliaires
webcontainer_client = WebContainerClient(endpoint_health_manager, quota_manager)
ocr_client = OCRApiClient(endpoint_health_manager, quota_manager)
deepseek_client = DeepSeekClient(endpoint_health_manager, quota_manager)
serper_client = SerperClient(endpoint_health_manager, quota_manager)
wolfram_alpha_client = WolframAlphaClient(endpoint_health_manager, quota_manager)
tavily_client = TavilyClient(endpoint_health_manager, quota_manager)
apiflash_client = ApiFlashClient(endpoint_health_manager, quota_manager)
crawlbase_client = CrawlbaseClient(endpoint_health_manager, quota_manager)
detect_language_client = DetectLanguageClient(endpoint_health_manager, quota_manager)
guardian_client = GuardianClient(endpoint_health_manager, quota_manager)
ip2location_client = IP2LocationClient(endpoint_health_manager, quota_manager)
shodan_client = ShodanClient(endpoint_health_manager, quota_manager)
weather_api_client = WeatherAPIClient(endpoint_health_manager, quota_manager)
cloudmersive_client = CloudmersiveClient(endpoint_health_manager, quota_manager)
greynoise_client = GreyNoiseClient(endpoint_health_manager, quota_manager)
pulsedive_client = PulsediveClient(endpoint_health_manager, quota_manager)
stormglass_client = StormGlassClient(endpoint_health_manager, quota_manager)
loginradius_client = LoginRadiusClient(endpoint_health_manager, quota_manager)
jsonbin_client = JsonbinClient(endpoint_health_manager, quota_manager)
huggingface_client = HuggingFaceClient(endpoint_health_manager, quota_manager)
twilio_client = TwilioClient(endpoint_health_manager, quota_manager)
abstractapi_client = AbstractAPIClient(endpoint_health_manager, quota_manager)
google_custom_search_client = GoogleCustomSearchClient(endpoint_health_manager, quota_manager)
randommer_client = RandommerClient(endpoint_health_manager, quota_manager)
tomorrow_io_client = TomorrowIOClient(endpoint_health_manager, quota_manager)
openweathermap_client = OpenWeatherMapClient(endpoint_health_manager, quota_manager)
mockaroo_client = MockarooClient(endpoint_health_manager, quota_manager)
openpagerank_client = OpenPageRankClient(endpoint_health_manager, quota_manager)
rapidapi_client = RapidAPIClient(endpoint_health_manager, quota_manager)

# Log de l'initialisation
log_message("Tous les clients API ont été instanciés pour les 7 cerveaux autonomes")

# Dictionnaire pour accès facile aux clients
API_CLIENTS = {
    "GEMINI": gemini_client,
    "TELEGRAM": telegram_bot_client,
    "WEBCONTAINER": webcontainer_client,
    "OCR": ocr_client,
    "DEEPSEEK": deepseek_client,
    "SERPER": serper_client,
    "WOLFRAM": wolfram_alpha_client,
    "TAVILY": tavily_client,
    "APIFLASH": apiflash_client,
    "CRAWLBASE": crawlbase_client,
    "DETECT_LANGUAGE": detect_language_client,
    "GUARDIAN": guardian_client,
    "IP2LOCATION": ip2location_client,
    "SHODAN": shodan_client,
    "WEATHER_API": weather_api_client,
    "CLOUDMERSIVE": cloudmersive_client,
    "GREYNOISE": greynoise_client,
    "PULSEDIVE": pulsedive_client,
    "STORMGLASS": stormglass_client,
    "LOGINRADIUS": loginradius_client,
    "JSONBIN": jsonbin_client,
    "HUGGINGFACE": huggingface_client,
    "TWILIO": twilio_client,
    "ABSTRACTAPI": abstractapi_client,
    "GOOGLE_SEARCH": google_custom_search_client,
    "RANDOMMER": randommer_client,
    "TOMORROW_IO": tomorrow_io_client,
    "OPENWEATHERMAP": openweathermap_client,
    "MOCKAROO": mockaroo_client,
    "OPENPAGERANK": openpagerank_client,
    "RAPIDAPI": rapidapi_client
}

def get_client(service_name: str) -> Optional[ApiClient]:
    """Récupère un client API par nom de service."""
    return API_CLIENTS.get(service_name.upper())

def get_all_clients() -> Dict[str, ApiClient]:
    """Retourne tous les clients API disponibles."""
    return API_CLIENTS.copy()

async def get_healthy_clients() -> Dict[str, ApiClient]: # MODIFIÉ : ajout de 'async'
    """Retourne uniquement les clients avec des services sains."""
    healthy_clients = {}
    
    for service_name, client in API_CLIENTS.items():
        try:
            # Vérification asynchrone de la santé via endpoint_health_manager
            is_healthy = await endpoint_health_manager.is_service_healthy(service_name)
            if is_healthy:
                healthy_clients[service_name] = client
            else:
                log_message(f"Client {service_name} non sain, exclu de la liste des clients sains.", level="debug")
        except Exception as e:
            log_message(f"Erreur lors de la vérification de santé pour {service_name}: {e}", level="warning")
    
    return healthy_clients

async def test_all_clients() -> Dict[str, bool]:
    """Teste la connectivité de tous les clients."""
    results = {}
    
    for service_name, client in API_CLIENTS.items():
        try:
            # Test basique de connectivité
            if hasattr(client, '_get_available_endpoint'):
                endpoint = await client._get_available_endpoint()
                results[service_name] = endpoint is not None
            else:
                results[service_name] = True  # Assume healthy if no endpoint check
        except Exception as e:
            log_message(f"Erreur test client {service_name}: {e}", level="error")
            results[service_name] = False
    
    return results

# Fonctions utilitaires pour la gestion des clients

async def rotate_client_endpoints():
    """Force la rotation des endpoints pour tous les clients."""
    for service_name, client in API_CLIENTS.items():
        if hasattr(client, 'current_endpoint_index') and hasattr(client, 'endpoints'):
            if client.endpoints:
                client.current_endpoint_index = (client.current_endpoint_index + 1) % len(client.endpoints)
                log_message(f"Rotation forcée pour {service_name}, nouvel index: {client.current_endpoint_index}")

def get_client_statistics() -> Dict[str, Any]:
    """Retourne les statistiques des clients API."""
    stats = {
        "total_clients": len(API_CLIENTS),
        "services_configured": len(config.API_CONFIG),
        "clients_by_type": {},
        "endpoint_counts": {}
    }
    
    for service_name, client in API_CLIENTS.items():
        client_type = type(client).__name__
        if client_type not in stats["clients_by_type"]:
            stats["clients_by_type"][client_type] = 0
        stats["clients_by_type"][client_type] += 1
        
        if hasattr(client, 'endpoints'):
            stats["endpoint_counts"][service_name] = len(client.endpoints)
    
    return stats

# Validation de l'initialisation
def validate_clients_initialization() -> bool:
    """Valide que tous les clients essentiels sont initialisés."""
    essential_clients = ["GEMINI", "TELEGRAM", "DEEPSEEK", "SERPER", "WOLFRAM", "TAVILY"]
    
    for client_name in essential_clients:
        if client_name not in API_CLIENTS or API_CLIENTS[client_name] is None:
            log_message(f"Client essentiel {client_name} non initialisé", level="error")
            return False
    
    log_message("Tous les clients essentiels sont initialisés")
    return True

# Exécution de la validation
if validate_clients_initialization():
    log_message("✅ Initialisation des clients API réussie - Système prêt pour les 7 cerveaux autonomes")
else:
    log_message("❌ Erreur lors de l'initialisation des clients API", level="error")
    
# app_clients_instances.py

import google.generativeai as genai
from google.generativeai import types
import asyncio
from typing import Dict, Any, List, Optional, Union

from config import config
from app_singletons import endpoint_health_manager, quota_manager
from api_clients import (
    ApiClient, WebContainerClient, OCRApiClient, DeepSeekClient, SerperClient,
    WolframAlphaClient, TavilyClient, ApiFlashClient, CrawlbaseClient,
    DetectLanguageClient, GuardianClient, IP2LocationClient, ShodanClient,
    WeatherAPIClient, CloudmersiveClient, GreyNoiseClient, PulsediveClient,
    StormGlassClient, LoginRadiusClient, JsonbinClient, HuggingFaceClient,
    TwilioClient, AbstractAPIClient, GoogleCustomSearchClient,
    RandommerClient, TomorrowIOClient, OpenWeatherMapClient, MockarooClient,
    OpenPageRankClient, RapidAPIClient,
    GeminiApiClient, TelegramBotClient
)
from utils import log_message

# Instanciation de tous les clients API pour les 7 cerveaux autonomes
# Chaque client est instancié avec les gestionnaires de santé et de quotas

# Clients principaux pour les 7 cerveaux
gemini_client = GeminiApiClient(endpoint_health_manager, quota_manager)
telegram_bot_client = TelegramBotClient(endpoint_health_manager, quota_manager)

# Clients pour services auxiliaires
webcontainer_client = WebContainerClient(endpoint_health_manager, quota_manager)
ocr_client = OCRApiClient(endpoint_health_manager, quota_manager)
deepseek_client = DeepSeekClient(endpoint_health_manager, quota_manager)
serper_client = SerperClient(endpoint_health_manager, quota_manager)
wolfram_alpha_client = WolframAlphaClient(endpoint_health_manager, quota_manager)
tavily_client = TavilyClient(endpoint_health_manager, quota_manager)
apiflash_client = ApiFlashClient(endpoint_health_manager, quota_manager)
crawlbase_client = CrawlbaseClient(endpoint_health_manager, quota_manager)
detect_language_client = DetectLanguageClient(endpoint_health_manager, quota_manager)
guardian_client = GuardianClient(endpoint_health_manager, quota_manager)
ip2location_client = IP2LocationClient(endpoint_health_manager, quota_manager)
shodan_client = ShodanClient(endpoint_health_manager, quota_manager)
weather_api_client = WeatherAPIClient(endpoint_health_manager, quota_manager)
cloudmersive_client = CloudmersiveClient(endpoint_health_manager, quota_manager)
greynoise_client = GreyNoiseClient(endpoint_health_manager, quota_manager)
pulsedive_client = PulsediveClient(endpoint_health_manager, quota_manager)
stormglass_client = StormGlassClient(endpoint_health_manager, quota_manager)
loginradius_client = LoginRadiusClient(endpoint_health_manager, quota_manager)
jsonbin_client = JsonbinClient(endpoint_health_manager, quota_manager)
huggingface_client = HuggingFaceClient(endpoint_health_manager, quota_manager)
twilio_client = TwilioClient(endpoint_health_manager, quota_manager)
abstractapi_client = AbstractAPIClient(endpoint_health_manager, quota_manager)
google_custom_search_client = GoogleCustomSearchClient(endpoint_health_manager, quota_manager)
randommer_client = RandommerClient(endpoint_health_manager, quota_manager)
tomorrow_io_client = TomorrowIOClient(endpoint_health_manager, quota_manager)
openweathermap_client = OpenWeatherMapClient(endpoint_health_manager, quota_manager)
mockaroo_client = MockarooClient(endpoint_health_manager, quota_manager)
openpagerank_client = OpenPageRankClient(endpoint_health_manager, quota_manager)
rapidapi_client = RapidAPIClient(endpoint_health_manager, quota_manager)

# Log de l'initialisation
log_message("Tous les clients API ont été instanciés pour les 7 cerveaux autonomes")

# Dictionnaire pour accès facile aux clients
API_CLIENTS = {
    "GEMINI": gemini_client,
    "TELEGRAM": telegram_bot_client,
    "WEBCONTAINER": webcontainer_client,
    "OCR": ocr_client,
    "DEEPSEEK": deepseek_client,
    "SERPER": serper_client,
    "WOLFRAM": wolfram_alpha_client,
    "TAVILY": tavily_client,
    "APIFLASH": apiflash_client,
    "CRAWLBASE": crawlbase_client,
    "DETECT_LANGUAGE": detect_language_client,
    "GUARDIAN": guardian_client,
    "IP2LOCATION": ip2location_client,
    "SHODAN": shodan_client,
    "WEATHER_API": weather_api_client,
    "CLOUDMERSIVE": cloudmersive_client,
    "GREYNOISE": greynoise_client,
    "PULSEDIVE": pulsedive_client,
    "STORMGLASS": stormglass_client,
    "LOGINRADIUS": loginradius_client,
    "JSONBIN": jsonbin_client,
    "HUGGINGFACE": huggingface_client,
    "TWILIO": twilio_client,
    "ABSTRACTAPI": abstractapi_client,
    "GOOGLE_SEARCH": google_custom_search_client,
    "RANDOMMER": randommer_client,
    "TOMORROW_IO": tomorrow_io_client,
    "OPENWEATHERMAP": openweathermap_client,
    "MOCKAROO": mockaroo_client,
    "OPENPAGERANK": openpagerank_client,
    "RAPIDAPI": rapidapi_client
}

def get_client(service_name: str) -> Optional[ApiClient]:
    """Récupère un client API par nom de service."""
    return API_CLIENTS.get(service_name.upper())

def get_all_clients() -> Dict[str, ApiClient]:
    """Retourne tous les clients API disponibles."""
    return API_CLIENTS.copy()

async def get_healthy_clients() -> Dict[str, ApiClient]: # MODIFIÉ : ajout de 'async'
    """Retourne uniquement les clients avec des services sains."""
    healthy_clients = {}
    
    for service_name, client in API_CLIENTS.items():
        try:
            # Vérification asynchrone de la santé via endpoint_health_manager
            is_healthy = await endpoint_health_manager.is_service_healthy(service_name)
            if is_healthy:
                healthy_clients[service_name] = client
            else:
                log_message(f"Client {service_name} non sain, exclu de la liste des clients sains.", level="debug")
        except Exception as e:
            log_message(f"Erreur lors de la vérification de santé pour {service_name}: {e}", level="warning")
    
    return healthy_clients

async def test_all_clients() -> Dict[str, bool]:
    """Teste la connectivité de tous les clients."""
    results = {}
    
    for service_name, client in API_CLIENTS.items():
        try:
            # Test basique de connectivité
            if hasattr(client, '_get_available_endpoint'):
                # _get_available_endpoint retourne maintenant une liste d'endpoints
                endpoints = await client._get_available_endpoint()
                results[service_name] = bool(endpoints) # Vérifie si la liste n'est pas vide
            else:
                results[service_name] = True  # Assume healthy if no endpoint check
        except Exception as e:
            log_message(f"Erreur test client {service_name}: {e}", level="error")
            results[service_name] = False
    
    return results

# Fonctions utilitaires pour la gestion des clients

async def rotate_client_endpoints():
    """Force la rotation des endpoints pour tous les clients."""
    for service_name, client in API_CLIENTS.items():
        if hasattr(client, 'current_endpoint_index') and hasattr(client, 'endpoints'):
            if client.endpoints:
                client.current_endpoint_index = (client.current_endpoint_index + 1) % len(client.endpoints)
                log_message(f"Rotation forcée pour {service_name}, nouvel index: {client.current_endpoint_index}")

def get_client_statistics() -> Dict[str, Any]:
    """Retourne les statistiques des clients API."""
    stats = {
        "total_clients": len(API_CLIENTS),
        "services_configured": len(config.API_CONFIG),
        "clients_by_type": {},
        "endpoint_counts": {}
    }
    
    for service_name, client in API_CLIENTS.items():
        client_type = type(client).__name__
        if client_type not in stats["clients_by_type"]:
            stats["clients_by_type"][client_type] = 0
        stats["clients_by_type"][client_type] += 1
        
        if hasattr(client, 'endpoints'):
            stats["endpoint_counts"][service_name] = len(client.endpoints)
    
    return stats

# Validation de l'initialisation
def validate_clients_initialization() -> bool:
    """Valide que tous les clients essentiels sont initialisés."""
    essential_clients = ["GEMINI", "TELEGRAM", "DEEPSEEK", "SERPER", "WOLFRAM", "TAVILY"]
    
    for client_name in essential_clients:
        if client_name not in API_CLIENTS or API_CLIENTS[client_name] is None:
            log_message(f"Client essentiel {client_name} non initialisé", level="error")
            return False
    
    log_message("Tous les clients essentiels sont initialisés")
    return True

# Exécution de la validation
if validate_clients_initialization():
    log_message("✅ Initialisation des clients API réussie - Système prêt pour les 7 cerveaux autonomes")
else:
    log_message("❌ Erreur lors de l'initialisation des clients API", level="error")
    
# app_singletons.py

import time
import httpx
import json
import asyncio
import logging
from datetime import datetime, timezone, timedelta
from pathlib import Path
from typing import Dict, Any, Optional, Union, List, Tuple

from config import config
from utils import load_json, save_json, get_current_time, format_datetime, log_message

class EndpointHealthManager:
    """
    Gère la santé des endpoints API pour les 7 cerveaux autonomes.
    Chaque cerveau peut avoir plusieurs endpoints et clés de secours.
    Cette classe est implémentée comme un singleton pour s'assurer qu'il n'y a qu'une seule instance
    gérant l'état de santé de tous les endpoints.
    """
    _instance = None
    _initialized = False # Drapeau pour s'assurer que __init__ n'est appelé qu'une fois

    def __new__(cls, *args, **kwargs):
        """Implémentation du patron de conception Singleton."""
        if cls._instance is None:
            cls._instance = super(cls, cls).__new__(cls)
        return cls._instance

    def __init__(self):
        """
        Initialise le gestionnaire de santé.
        Ne s'exécute qu'une seule fois grâce au drapeau _initialized.
        """
        if self._initialized:
            return
        self.health_status: Dict[str, Dict[str, Any]] = {} # Stocke l'état de santé de chaque endpoint
        self._initialized = True
        log_message("Gestionnaire de santé des endpoints initialisé.")

    async def init_manager(self):
        """
        Initialise le gestionnaire de santé de manière asynchrone en chargeant l'état depuis un fichier.
        Appelé au démarrage de l'application.
        """
        # Charge l'état de santé persistant ou initialise un dictionnaire vide si le fichier n'existe pas
        self.health_status = await load_json(config.ENDPOINT_HEALTH_FILE, {})
        self._initialize_health_status() # S'assure que tous les endpoints configurés ont un état initial
        log_message("Gestionnaire de santé des endpoints chargé et prêt.")

    def _initialize_health_status(self):
        """
        Initialise ou met à jour le statut de santé pour tous les endpoints configurés dans config.API_CONFIG.
        Ceci garantit que même les nouveaux endpoints ajoutés à la configuration sont suivis.
        """
        updated = False
        for service_name, endpoints_config in config.API_CONFIG.items():
            if service_name not in self.health_status:
                self.health_status[service_name] = {} # Crée une entrée pour le nouveau service
                updated = True
            
            for endpoint_config in endpoints_config:
                endpoint_key_base = endpoint_config['endpoint_name']
                api_key_part = ""
                
                # Gère les clés API qui peuvent être des tuples (ex: pour l'authentification basique)
                if isinstance(endpoint_config['key'], tuple):
                    api_key_part = str(endpoint_config['key'][0])
                else:
                    api_key_part = str(endpoint_config['key'])
                
                endpoint_key = f"{endpoint_key_base}-{api_key_part[:8]}" # Clé unique pour chaque endpoint + clé API
                
                if endpoint_key not in self.health_status[service_name]:
                    # Initialise l'état de santé par défaut pour un nouvel endpoint
                    self.health_status[service_name][endpoint_key] = {
                        "latency": 0.0,        # Latence moyenne
                        "success_rate": 1.0,   # Taux de succès (commence à 100%)
                        "last_checked": None,  # Horodatage du dernier contrôle
                        "error_count": 0,      # Compteur d'erreurs
                        "total_checks": 0,     # Nombre total de contrôles effectués
                        "is_healthy": True,    # Indique si l'endpoint est considéré comme sain
                        "last_error": None,
                        "consecutive_failures": 0
                    }
                    updated = True
        
        if updated:
            # Sauvegarde l'état mis à jour de manière asynchrone
            asyncio.create_task(save_json(config.ENDPOINT_HEALTH_FILE, self.health_status))
            log_message("Statut de santé des endpoints initialisé/mis à jour.")

    async def run_health_check_for_service(self, service_name: str):
        """
        Exécute des checks de santé pour tous les endpoints d'un service donné.
        Args:
            service_name (str): Le nom du service (ex: "GEMINI_API", "SERPER").
        """
        endpoints_config = config.API_CONFIG.get(service_name)
        if not endpoints_config:
            log_message(f"Aucune configuration d'endpoint trouvée pour le service: {service_name}", level="warning")
            return

        log_message(f"Lancement du health check pour le service: {service_name}")
        
        for endpoint_config in endpoints_config:
            endpoint_key_base = endpoint_config['endpoint_name']
            api_key_part = ""
            
            if isinstance(endpoint_config['key'], tuple):
                api_key_part = str(endpoint_config['key'][0])
            else:
                api_key_part = str(endpoint_config['key'])
            
            endpoint_key = f"{endpoint_key_base}-{api_key_part[:8]}"
            
            start_time = time.monotonic() # Début du chronomètre pour la latence
            success = False
            
            try:
                request_method = endpoint_config.get("method", "GET")
                url = endpoint_config["url"]
                
                # Prépare les paramètres, les données JSON et les en-têtes pour le health check
                params = endpoint_config.get("health_check_params", {}).copy()
                json_data = endpoint_config.get("health_check_json", {}).copy()
                headers = endpoint_config.get("fixed_headers", {}).copy()
                auth = None # Pour l'authentification basique
                
                check_timeout = endpoint_config.get("timeout", 10)
                
                # Ajoute un suffixe à l'URL si spécifié (utile pour certains endpoints d'API)
                if "health_check_url_suffix" in endpoint_config:
                    url += endpoint_config["health_check_url_suffix"]
                
                # Gère l'insertion de la clé API selon sa localisation (param, header, auth_basic)
                key_field = endpoint_config.get("key_field")
                key_location = endpoint_config.get("key_location")
                key_prefix = endpoint_config.get("key_prefix", "")
                api_key = endpoint_config["key"]
                
                if key_field and key_location:
                    if key_location == "param":
                        params[key_field] = api_key
                    elif key_location == "header":
                        headers[key_field] = f"{key_prefix}{api_key}"
                    elif key_location == "auth_basic":
                        if isinstance(api_key, tuple) and len(api_key) == 2:
                            auth = httpx.BasicAuth(api_key[0], api_key[1])
                        else:
                            log_message(f"Clé API pour auth_basic non valide pour {service_name}:{endpoint_key}", level="error")
                            continue # Passe à l'endpoint suivant
                
                # Ajouter des paramètres fixes
                if "fixed_params" in endpoint_config:
                    params.update(endpoint_config["fixed_params"])
                
                async with httpx.AsyncClient(timeout=check_timeout) as client:
                    response = await client.request(
                        request_method, url, 
                        params=params, 
                        headers=headers, 
                        json=json_data, 
                        auth=auth
                    )
                    response.raise_for_status() # Lève une exception pour les codes d'état HTTP 4xx/5xx
                    success = True
                    
            except httpx.HTTPStatusError as e:
                # Gère les erreurs HTTP (ex: 404, 500)
                log_level = "warning"
                if 400 <= e.response.status_code < 500 and e.response.status_code != 429:
                    # Les erreurs client (sauf 429) peuvent indiquer un problème avec la requête elle-même,
                    # pas forcément que l'endpoint est malsain. Log plus bas.
                    log_level = "debug"
                log_message(f"Health check pour {endpoint_key} ({service_name}) a échoué (HTTP {e.response.status_code}): {e.response.text}", level=log_level)
                success = False
                
            except httpx.RequestError as e:
                # Gère les erreurs réseau (ex: timeout, connexion refusée)
                log_message(f"Health check pour {endpoint_key} ({service_name}) a échoué (Réseau): {e}", level="warning")
                success = False
                
            except Exception as e:
                # Gère toutes les autres exceptions inattendues
                log_message(f"Health check pour {endpoint_key} ({service_name}) a échoué (Inattendu): {e}", level="error")
                success = False
                
            finally:
                latency = time.monotonic() - start_time # Calcule la latence
                # Met à jour l'état de santé de l'endpoint
                self.update_endpoint_health(service_name, endpoint_key, success, latency)

        log_message(f"Health check terminé pour le service: {service_name}")

    def update_endpoint_health(self, service_name: str, endpoint_key: str, success: bool, latency: float):
        """
        Met à jour le statut de santé d'un endpoint spécifique.
        Utilise une moyenne mobile exponentielle pour la latence et le taux de succès.
        Args:
            service_name (str): Le nom du service.
            endpoint_key (str): La clé unique de l'endpoint.
            success (bool): Indique si le dernier contrôle a été un succès.
            latency (float): La latence du dernier contrôle.
        """
        # S'assure que l'entrée de l'endpoint existe, l'initialise si nécessaire
        if service_name not in self.health_status:
            self.health_status[service_name] = {}
        
        if endpoint_key not in self.health_status[service_name]:
            self.health_status[service_name][endpoint_key] = {
                "latency": 0.0,
                "success_rate": 1.0,
                "last_checked": None,
                "error_count": 0,
                "total_checks": 0,
                "is_healthy": True,
                "last_error": None,
                "consecutive_failures": 0
            }
        
        status = self.health_status[service_name][endpoint_key]
        status["total_checks"] += 1
        status["last_checked"] = format_datetime(get_current_time())
        
        alpha = 0.1  # Facteur de lissage pour la moyenne mobile exponentielle
        
        if success:
            status["consecutive_failures"] = 0
            status["error_count"] = max(0, status["error_count"] - 1) # Réduit le compteur d'erreurs
            status["success_rate"] = status["success_rate"] * (1 - alpha) + 1.0 * alpha # Augmente le taux de succès
            status["latency"] = status["latency"] * (1 - alpha) + latency * alpha # Met à jour la latence moyenne
            status["last_error"] = None
        else:
            status["consecutive_failures"] += 1
            status["error_count"] += 1 # Incrémente le compteur d'erreurs
            status["success_rate"] = status["success_rate"] * (1 - alpha) + 0.0 * alpha # Diminue le taux de succès
            status["latency"] = status["latency"] * (1 - alpha) + 10.0 * alpha # Pénalise la latence en cas d'échec
            status["last_error"] = format_datetime(get_current_time())
        
        # Détermine si l'endpoint est sain basé sur le nombre d'erreurs consécutives ou le taux de succès
        if status["consecutive_failures"] >= 3 or status["success_rate"] < 0.5:
            status["is_healthy"] = False
        else:
            status["is_healthy"] = True
        
        # Sauvegarde l'état de santé mis à jour de manière asynchrone
        asyncio.create_task(save_json(config.ENDPOINT_HEALTH_FILE, self.health_status))
        
        log_level = "debug" if status["is_healthy"] else "warning"
        log_message(f"Santé de {service_name}:{endpoint_key} mise à jour: Succès: {success}, Latence: {latency:.2f}s, Taux Succès: {status['success_rate']:.2f}, Sain: {status['is_healthy']}", level=log_level)

    async def is_healthy(self, endpoint_name: str, service_name: str) -> bool:
        """Vérifie si un endpoint spécifique est sain."""
        service_health = self.health_status.get(service_name, {})
        
        # Recherche par nom d'endpoint
        for endpoint_key, status in service_health.items():
            if endpoint_name in endpoint_key:
                return status.get("is_healthy", False)
        
        return False

    async def is_service_healthy(self, service_name: str) -> bool:
        """Vérifie si au moins un endpoint du service est sain."""
        service_health = self.health_status.get(service_name, {})
        
        if not service_health:
            return True  # Nouveau service considéré comme sain par défaut
        
        healthy_endpoints = [
            status for status in service_health.values()
            if status.get("is_healthy", False)
        ]
        
        return len(healthy_endpoints) > 0

    def get_best_endpoint(self, service_name: str) -> Optional[Dict]:
        """
        Sélectionne le meilleur endpoint pour un service donné basé sur son statut de santé.
        Priorise les endpoints sains avec la latence la plus faible et le taux de succès le plus élevé.
        En cas d'absence d'endpoints sains, tente de sélectionner le "moins pire" parmi les non-sains.
        Args:
            service_name (str): Le nom du service.
        Returns:
            Optional[Dict]: La configuration du meilleur endpoint, ou None si aucun n'est disponible.
        """
        service_health = self.health_status.get(service_name)
        if not service_health:
            log_message(f"Aucune donnée de santé pour le service {service_name}. Retourne None.", level="warning")
            return None

        # Filtre les endpoints qui sont actuellement considérés comme sains
        healthy_endpoints = [
            (key, status) for key, status in service_health.items()
            if status["is_healthy"]
        ]

        if not healthy_endpoints:
            log_message(f"Aucun endpoint sain pour le service {service_name}. Tentative de sélection d'un endpoint non sain.", level="warning")
            all_endpoints = list(service_health.items())
            if not all_endpoints:
                return None # Aucun endpoint du tout
            
            # Si aucun endpoint sain, trie tous les endpoints par nombre d'erreurs puis par latence
            sorted_endpoints = sorted(
                all_endpoints,
                key=lambda item: (item[1]["consecutive_failures"], item[1]["latency"])
            )
            best_endpoint_key = sorted_endpoints[0][0] # Prend le "moins pire"
            log_message(f"Fallback: Endpoint {best_endpoint_key} sélectionné pour {service_name} (non sain).", level="warning")
        else:
            # Si des endpoints sains existent, calcule un score pour chacun et sélectionne le meilleur
            best_endpoint_key, _ = max(
                healthy_endpoints,
                key=lambda item: (item[1]["success_rate"] * 100) - (item[1]["latency"] * 10) - (item[1]["consecutive_failures"] * 5)
            )
            log_message(f"Meilleur endpoint pour {service_name}: {best_endpoint_key}")

        # Trouve la configuration complète de l'endpoint sélectionné à partir de config.API_CONFIG
        for endpoint_config in config.API_CONFIG.get(service_name, []):
            current_endpoint_key_base = endpoint_config['endpoint_name']
            api_key_part = ""
            
            if isinstance(endpoint_config['key'], tuple):
                api_key_part = str(endpoint_config['key'][0])
            else:
                api_key_part = str(endpoint_config['key'])
            
            current_endpoint_key = f"{current_endpoint_key_base}-{api_key_part[:8]}"
            
            if current_endpoint_key == best_endpoint_key:
                return endpoint_config

        return None

    def mark_unhealthy(self, endpoint_name: str, service_name: str, reason: str):
        """Marque un endpoint comme non sain."""
        service_health = self.health_status.get(service_name, {})
        
        for endpoint_key, status in service_health.items():
            if endpoint_name in endpoint_key:
                status["is_healthy"] = False
                status["consecutive_failures"] += 1
                status["last_error"] = format_datetime(get_current_time())
                log_message(f"Endpoint {endpoint_key} marqué comme non sain: {reason}", level="warning")
                # Sauvegarde l'état de santé mis à jour de manière asynchrone
                asyncio.create_task(save_json(config.ENDPOINT_HEALTH_FILE, self.health_status)) # AJOUTÉ
                break

class QuotaManager:
    """
    Gère l'utilisation des quotas pour différentes APIs.
    Cette classe est également un singleton.
    """
    _instance = None
    _initialized = False

    def __new__(cls, *args, **kwargs):
        """Implémentation du patron de conception Singleton."""
        if cls._instance is None:
            cls._instance = super(QuotaManager, cls).__new__(cls)
        return cls._instance

    def __init__(self):
        """
        Initialise le gestionnaire de quotas.
        Ne s'exécute qu'une seule fois grâce au drapeau _initialized.
        """
        if self._initialized:
            return
        self.quota_state: Dict[str, Dict[str, Any]] = {} # Stocke l'état actuel des quotas par API
        self._initialized = True
        log_message("QuotaManager initialisé.")

    async def init_manager(self):
        """
        Charge l'état des quotas depuis le fichier de persistance de manière asynchrone.
        Appelé au démarrage de l'application.
        """
        self.quota_state = await load_json(config.QUOTA_STATE_FILE, {})
        self._initialize_quota_state() # S'assure que tous les quotas configurés ont un état initial
        log_message("QuotaManager chargé et prêt.")

    def _initialize_quota_state(self):
        """
        Initialise ou met à jour l'état des quotas pour toutes les APIs configurées dans config.QUOTA_CONFIG.
        Réinitialise les quotas si l'intervalle de réinitialisation est dépassé.
        """
        updated = False
        current_time = datetime.now(timezone.utc)
        
        for api_name, quota_info in config.QUOTA_CONFIG.items():
            if api_name not in self.quota_state:
                # Initialise l'état par défaut pour une nouvelle API
                self.quota_state[api_name] = {
                    "current_usage": 0,
                    "last_reset_time": current_time.isoformat(), # Enregistre l'heure de la dernière réinitialisation
                    "last_usage_time": None, # Horodatage de la dernière utilisation
                    "daily_peak": 0,
                    "success_count": 0,
                    "error_count": 0
                }
                updated = True
            
            # Vérifie et réinitialise le quota si nécessaire lors de l'initialisation
            self._check_and_reset_quota(api_name, current_time)
        
        if updated:
            # Sauvegarde l'état mis à jour de manière asynchrone
            asyncio.create_task(save_json(config.QUOTA_STATE_FILE, self.quota_state))
            log_message("État des quotas initialisé/mis à jour.")

    def _check_and_reset_quota(self, api_name: str, current_time: datetime) -> bool:
        """
        Vérifie si un quota doit être réinitialisé en fonction de son intervalle et le fait si nécessaire.
        Args:
            api_name (str): Le nom de l'API.
            current_time (datetime): L'heure actuelle en UTC.
        Returns:
            bool: True si le quota a été réinitialisé, False sinon.
        """
        quota_info = config.QUOTA_CONFIG.get(api_name)
        if not quota_info:
            return False

        state = self.quota_state.get(api_name)
        if not state:
            state = {
                "current_usage": 0,
                "last_reset_time": current_time.isoformat(),
                "last_usage_time": None,
                "daily_peak": 0,
                "success_count": 0,
                "error_count": 0
            }
            self.quota_state[api_name] = state

        last_reset_dt = datetime.fromisoformat(state["last_reset_time"])
        reset_needed = False

        # Logique de réinitialisation basée sur l'intervalle configuré
        if quota_info["reset_interval"] == "daily":
            if current_time.date() > last_reset_dt.date():
                reset_needed = True
        elif quota_info["reset_interval"] == "hourly":
            if current_time.hour > last_reset_dt.hour or current_time.date() > last_reset_dt.date():
                reset_needed = True
        elif quota_info["reset_interval"] == "fixed_24h":
            if current_time - last_reset_dt >= timedelta(hours=24):
                reset_needed = True

        if reset_needed:
            # Sauvegarde du pic quotidien
            state["daily_peak"] = max(state.get("daily_peak", 0), state["current_usage"])
            
            # Reset des compteurs
            state["current_usage"] = 0
            state["last_reset_time"] = current_time.isoformat()
            
            log_message(f"Quota pour {api_name} réinitialisé. Pic précédent: {state['daily_peak']}")
            # Sauvegarde l'état mis à jour de manière asynchrone
            asyncio.create_task(save_json(config.QUOTA_STATE_FILE, self.quota_state)) # AJOUTÉ
            return True

        return False

    async def check_quota(self, api_name: str) -> bool:
        """Vérifie si une requête est autorisée selon le quota."""
        quota_info = config.QUOTA_CONFIG.get(api_name)
        if not quota_info:
            return True  # Pas de quota configuré = autorisé

        state = self.quota_state.get(api_name)
        if not state:
            self._initialize_quota_state()
            state = self.quota_state.get(api_name)
            if not state:
                return False

        current_time = datetime.now(timezone.utc)
        self._check_and_reset_quota(api_name, current_time)

        remaining_quota = quota_info["limit"] - state["current_usage"]

        # Logique de fenêtre de cramage
        is_in_burn_window = False
        if quota_info.get("burn_window_hours", 0) > 0:
            last_reset_dt = datetime.fromisoformat(state["last_reset_time"])
            time_to_next_reset = timedelta(hours=0)

            if quota_info["reset_interval"] == "daily":
                next_reset = (last_reset_dt + timedelta(days=1)).replace(hour=0, minute=0, second=0, microsecond=0)
                time_to_next_reset = next_reset - current_time
            elif quota_info["reset_interval"] == "hourly":
                next_reset = (last_reset_dt + timedelta(hours=1)).replace(minute=0, second=0, microsecond=0)
                time_to_next_reset = next_reset - current_time
            elif quota_info["reset_interval"] == "fixed_24h":
                next_reset = last_reset_dt + timedelta(hours=24)
                time_to_next_reset = next_reset - current_time

            if timedelta(hours=0) < time_to_next_reset <= timedelta(hours=quota_info["burn_window_hours"]):
                is_in_burn_window = True

        # Autorisation de la requête
        if state["current_usage"] < quota_info["limit"]:
            return True
        elif is_in_burn_window:
            log_message(f"Quota {api_name} en mode cramage autorisé", level="warning")
            return True
        else:
            log_message(f"Quota {api_name} dépassé: {state['current_usage']}/{quota_info['limit']}", level="warning")
            return False

    async def increment_quota(self, api_name: str, success: bool = True):
        """Incrémente le quota après utilisation."""
        quota_info = config.QUOTA_CONFIG.get(api_name)
        if not quota_info:
            return

        state = self.quota_state.get(api_name)
        if not state:
            self._initialize_quota_state()
            state = self.quota_state.get(api_name)

        if state:
            current_time = datetime.now(timezone.utc)
            state["current_usage"] += 1
            state["last_usage_time"] = current_time.isoformat()
            
            if success:
                state["success_count"] = state.get("success_count", 0) + 1
            else:
                state["error_count"] = state.get("error_count", 0) + 1

            asyncio.create_task(save_json(config.QUOTA_STATE_FILE, self.quota_state))
            
            remaining = quota_info["limit"] - state["current_usage"]
            log_message(f"Quota {api_name}: {state['current_usage']}/{quota_info['limit']} (Restant: {remaining})")

    def get_quota_status(self, api_name: str) -> Dict[str, Any]:
        """Retourne le statut du quota pour une API."""
        quota_info = config.QUOTA_CONFIG.get(api_name, {})
        state = self.quota_state.get(api_name, {})
        
        if not state:
            return {"error": f"Pas de données pour {api_name}"}
        
        return {
            "api_name": api_name,
            "current_usage": state.get("current_usage", 0),
            "limit": quota_info.get("limit", 0),
            "remaining": quota_info.get("limit", 0) - state.get("current_usage", 0),
            "success_rate": (
                state.get("success_count", 0) / 
                max(1, state.get("success_count", 0) + state.get("error_count", 0))
            ) * 100,
            "last_usage": state.get("last_usage_time"),
            "last_reset": state.get("last_reset_time"),
            "daily_peak": state.get("daily_peak", 0)
        }

    def get_all_quotas_status(self) -> Dict[str, Dict[str, Any]]:
        """Retourne le statut de tous les quotas."""
        return {
            api_name: self.get_quota_status(api_name)
            for api_name in config.QUOTA_CONFIG.keys()
        }

# Instancier les gestionnaires de singletons pour qu'ils soient accessibles depuis d'autres modules
endpoint_health_manager = EndpointHealthManager()
quota_manager = QuotaManager()

# autonomous_brain.py

import asyncio
import json
import random
import time
import traceback
from datetime import datetime, timezone
from typing import Dict, Any, List, Optional, Union
import httpx
import re

### AJOUT : Imports nécessaires pour la nouvelle logique
from config import config
from brain_library import api_key_library, BrainMemoryManager, TelegramMemoryIntegration
from utils import log_message, neutralize_urls
from tools import get_gemini_tools
import telegram_logger
from app_clients_instances import get_client # AJOUTÉ pour _generate_response dans les sous-classes

class AutonomousBrain:
    """
    Classe de base pour un cerveau autonome.
    Chaque cerveau peut traiter indépendamment les requêtes utilisateur.
    """
    def __init__(self, brain_id: str, service_name: str, telegram_client=None, api_key: Optional[Any] = None):
        self.brain_id = brain_id
        self.service_name = service_name
        self.api_key = api_key
        self.memory_manager = BrainMemoryManager(brain_id)
        self.telegram_memory = TelegramMemoryIntegration(telegram_client)
        self.is_active = True
        self.current_task = None
        self.last_activity = time.time()
        self.brains: Dict[str, 'AutonomousBrain'] = {} # Dictionnaire pour contenir les autres cerveaux (sera injecté)
        self.api_client = get_client(service_name) # Référence au client API spécifique

        if not self.api_client:
            log_message(f"❌ Cerveau {self.brain_id}: Client API pour {service_name} non trouvé.", level="error")
            # Potentiellement lever une erreur ou marquer le cerveau comme inactif si le client est essentiel

    async def initialize(self):
        """Initialise le cerveau et charge sa mémoire."""
        try:
            await self.memory_manager.load_memory()
            await self.telegram_memory.log_brain_activity(
                self.brain_id, 
                "Cerveau initialisé", 
                {"service": self.service_name, "timestamp": datetime.now().isoformat()}
            )
            log_message(f"Cerveau {self.brain_id} initialisé avec succès")
            return True
        except Exception as e:
            log_message(f"Erreur initialisation cerveau {self.brain_id}: {e}", level="error")
            return False
    
    async def read_complete_memory(self, query_for_context: str) -> str:
        """
        ### INJECTION DE LOGIQUE : LECTURE DE MÉMOIRE STRATÉGIQUE ###
        L'agent décide de la meilleure stratégie pour lire la mémoire :
        1. Tente une recherche ciblée par mots-clés.
        2. Si les résultats sont insuffisants, procède à une lecture exhaustive.
        """
        try:
            # ÉTAPE 1 : L'AGENT GÉNÈRE LUI-MÊME LES MOTS-CLÉS DE RECHERCHE
            # Pour cet exemple, nous extrayons simplement les mots non-communs de la requête.
            # Une version plus avancée pourrait faire un appel LLM léger.
            common_words = {'le', 'la', 'les', 'un', 'une', 'des', 'de', 'du', 'et', 'est', 'pour', 'que', 'qui', 'dans', 'avec'}
            keywords = [word for word in re.findall(r'\b\w{3,}\b', query_for_context.lower()) if word not in common_words]
            keywords_str = ", ".join(list(set(keywords))[:5]) # Prend les 5 premiers mots-clés uniques

            await telegram_logger.log_agent_decision(
                self.brain_id,
                f"Tentative de recherche mémoire ciblée avec les mots-clés : '{keywords_str}'."
            )

            # ÉTAPE 2 : EXÉCUTION DE LA RECHERCHE CIBLÉE (SIMULÉE)
            # En production, self.telegram_memory aurait une méthode search_messages(query)
            # qui recherche dans l'historique du groupe.
            # Nous simulons cet appel. Pour forcer la lecture exhaustive, on retourne une liste vide.
            targeted_results = [] # Simulé comme ne trouvant rien.

            memory_source_log = ""
            final_memory_text = ""

            # ÉTAPE 3 : DÉCISION STRATÉGIQUE
            if targeted_results and len(targeted_results) > 2:
                memory_source_log = f"Recherche ciblée fructueuse ({len(targeted_results)} résultats)."
                final_memory_text = "\n".join(targeted_results)
            else:
                memory_source_log = "Recherche ciblée insuffisante. Passage à la lecture exhaustive des 1000 derniers messages."
                await telegram_logger.log_agent_decision(self.brain_id, memory_source_log)
                
                # LECTURE EXHAUSTIVE
                final_memory_text = await self.telegram_memory.read_group_memory(limit=1000)

            await telegram_logger.log_agent_decision(self.brain_id, f"Lecture mémoire terminée. Source : {memory_source_log}")

            # ÉTAPE 4 : COMBINAISON AVEC LE CONTEXTE LOCAL
            local_context_text = json.dumps(await self.memory_manager.get_relevant_context(query_for_context, limit=20), indent=2, ensure_ascii=False)
            
            # Construction de la mémoire finale pour le prompt
            complete_memory = f"""=== MÉMOIRE STRATÉGIQUE - CERVEAU {self.brain_id} ===

--- SOURCE DE LA MÉMOIRE DE GROUPE ---
{memory_source_log}

--- CONTENU DE LA MÉMOIRE DE GROUPE (Extrait) ---
{final_memory_text[:8000]}...

--- CONTEXTE LOCAL (INTERACTIONS PASSÉES DE CE CERVEAU) ---
{local_context_text}

--- STATUT ACTUEL DU CERVEAU ---
Service: {self.service_name}
Tâche courante: {self.current_task or "Aucune"}
"""
            return complete_memory
        except Exception as e:
            log_message(f"Erreur lecture mémoire stratégique {self.brain_id}: {e}", level="error")
            await telegram_logger.log_error(self.brain_id, f"Erreur critique lors de la lecture de la mémoire : {e}")
            return f"Erreur d'accès à la mémoire: {e}"
    
    async def process_request(self, user_query: str, chat_history: List[Dict] = None, 
                            image_data: str = None, tools: List[Dict] = None,
                            endpoint_config: Optional[Dict[str, Any]] = None) -> Dict[str, Any]: # AJOUTÉ
        """
        Traite une requête avec une logique de résilience et de collaboration.
        Si un agent échoue, il peut déléguer à un autre agent du système.
        """
        self.current_task = f"Traitement requête: {user_query[:50]}..."
        self.last_activity = time.time()

        # Vérification initiale de l'endpoint fourni
        if not endpoint_config:
            error_msg = f"Erreur: Aucune configuration d'endpoint fournie pour le cerveau {self.brain_id}."
            await telegram_logger.log_error(self.brain_id, error_msg)
            await self.memory_manager.update_success_rate(False)
            return {"error": error_msg, "brain_id": self.brain_id}

        try:
            await telegram_logger.log_agent_decision(
                self.brain_id,
                f"Tentative de réponse avec sa logique native ({self.service_name}) via endpoint: {endpoint_config.get('endpoint_name', 'N/A')}."
            )

            complete_memory = await self.read_complete_memory(user_query)
            enriched_prompt = f"{complete_memory}\n\nREQUÊTE: {user_query}"

            # Le cerveau utilise l'endpoint_config qui lui a été fourni par l'Agent Autonome
            response = await self._generate_response(
                endpoint_config=endpoint_config, # PASSE L'ENDPOINT SPÉCIFIQUE
                prompt=enriched_prompt,
                chat_history=chat_history,
                image_data=image_data,
                tools=tools
            )

            # Vérification du succès de la réponse du LLM
            is_successful = True
            if isinstance(response, str) and "erreur" in response.lower():
                is_successful = False
            if isinstance(response, dict) and not response.get("candidates"):
                is_successful = False

            if is_successful:
                tool_results = []
                if isinstance(response, dict) and "candidates" in response:
                    first_candidate = response["candidates"][0] if response.get("candidates") else {}
                    content_parts = first_candidate.get("content", {}).get("parts", [])
                    function_calls = [part["function_call"] for part in content_parts if "function_call" in part]
                    if function_calls:
                        tool_results = await self._execute_tools(function_calls)

                await self.memory_manager.update_success_rate(True)
                return {"response": response, "brain_id": self.brain_id, "tool_results": tool_results}
            else:
                raise Exception(f"Réponse initiale jugée insuffisante: {str(response)[:150]}")

        except Exception as e:
            error_msg = f"Échec du traitement par le cerveau {self.brain_id} via endpoint {endpoint_config.get('endpoint_name', 'N/A')}: {e}"
            await telegram_logger.log_error(self.brain_id, error_msg)
            await self.memory_manager.update_success_rate(False)
            
            # TENTATIVE DE DÉLÉGATION (si d'autres cerveaux sont disponibles)
            try:
                # Exclure le cerveau actuel et le synthétiseur de la délégation
                available_agent_types = [name for name in self.brains.keys() if name != self.service_name and name != "SYNTHESIZER"]
                if not available_agent_types:
                    raise Exception("Aucun autre agent disponible pour la délégation.")

                # L'agent choisit un autre type d'agent au hasard pour l'aider
                delegate_agent_type = random.choice(available_agent_types)
                delegate_agent = self.brains[delegate_agent_type]

                await telegram_logger.log_agent_decision(
                    self.brain_id,
                    f"Délégation de la tâche à un agent de type '{delegate_agent.service_name}'."
                )

                # Création d'un prompt de délégation clair
                delegation_prompt = f"""CONTEXTE: Je suis l'agent {self.brain_id} (type {self.service_name}). J'ai échoué à traiter la requête suivante.
REQUÊTE ORIGINALE: "{user_query}"
MON ERREUR: "{str(e)}"
MISSION POUR TOI, {delegate_agent.brain_id}: Prends le relais. Analyse la requête originale et fournis une réponse complète.
"""
                # L'agent délégué traite cette nouvelle requête.
                # Note: L'agent délégué gérera sa propre sélection d'endpoint.
                final_response = await delegate_agent.process_request(
                    user_query=delegation_prompt,
                    chat_history=[],
                    image_data=image_data,
                    tools=tools,
                    endpoint_config=None # L'agent délégué choisira son propre endpoint
                )

                # On trace la collaboration dans la réponse
                final_response["brain_id"] = f"{self.brain_id} -> (délégué à {delegate_agent.brain_id})"
                return final_response

            except Exception as final_e:
                error_msg_delegation = f"Échec de la tentative initiale ET de la délégation: {final_e}"
                await telegram_logger.log_error(self.brain_id, error_msg_delegation)
                return {"error": error_msg_delegation, "brain_id": self.brain_id}
    
    async def _generate_response(self, endpoint_config: Dict[str, Any], # AJOUTÉ
                               prompt: str, 
                               chat_history: List[Dict] = None,
                               image_data: str = None, 
                               tools: List[Dict] = None) -> Dict[str, Any]:
        """Génère une réponse spécifique au service."""
        raise NotImplementedError("Chaque cerveau doit implémenter sa méthode de génération")
    
    async def _execute_tools(self, function_calls: List[Dict]) -> List[Dict]:
        """Exécute les outils demandés par l'IA."""
        results = []
        for func_call in function_calls:
            try:
                # Import dynamique pour éviter les dépendances circulaires
                from tools import execute_tool
                
                tool_result = await execute_tool(
                    func_call["name"],
                    context=None,
                    **func_call.get("args", {})
                )
                results.append(tool_result)
                
                await telegram_logger.log_agent_decision(
                    self.brain_id,
                    f"Outil exécuté: {func_call['name']}",
                    {"args": func_call.get("args", {}), "result_excerpt": str(tool_result)[:100]}
                )
                
            except Exception as e:
                error_result = {"error": f"Erreur outil {func_call['name']}: {e}"}
                results.append(error_result)
                await telegram_logger.log_error(
                    self.brain_id,
                    f"Erreur outil {func_call['name']}: {e}"
                )
        
        return results
    
    async def participate_in_coding_challenge(self, challenge_prompt: str,
                                              endpoint_config: Optional[Dict[str, Any]] = None) -> Dict[str, Any]: # AJOUTÉ
        """Participe aux défis de codage automatisés."""
        try:
            await telegram_logger.log_agent_decision(
                self.brain_id,
                "Participation au défi de codage",
                {"challenge_excerpt": challenge_prompt[:100]}
            )
            
            # Lecture de la mémoire avant le défi
            complete_memory = await self.read_complete_memory(challenge_prompt)
            
            # Prompt spécialisé pour le défi de codage
            coding_prompt = f"""
{complete_memory}

=== DÉFI DE CODAGE AUTOMATISÉ ===
{challenge_prompt}

En tant que cerveau {self.brain_id} spécialisé en {self.service_name}, génère du code Python optimisé et fonctionnel.
Le code doit être:
- Syntaxiquement correct
- Bien commenté
- Optimisé pour les performances
- Prêt à l'exécution

Réponds uniquement avec le code Python, sans explications supplémentaires.
"""
            
            if not endpoint_config: # AJOUTÉ
                return {"error": f"Aucune configuration d'endpoint fournie pour le défi de codage de {self.brain_id}"} # AJOUTÉ
            
            response = await self._generate_response(
                endpoint_config=endpoint_config, # PASSE L'ENDPOINT SPÉCIFIQUE
                prompt=coding_prompt,
                chat_history=[], # Pas d'historique de chat pour les défis de codage
                image_data=None,
                tools=[] # Pas d'outils pour les défis de codage
            )
            
            # Sauvegarde du code généré
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            code_filename = f"challenge_{self.brain_id}_{timestamp}.py"
            
            # Extraire le texte de la réponse
            response_text = "No text found"
            if isinstance(response, dict) and "candidates" in response and response["candidates"]:
                parts = response["candidates"][0].get("content", {}).get("parts", [])
                if parts and "text" in parts[0]:
                    response_text = parts[0]["text"]

            # Envoi du code au groupe Telegram (géré par autonomous_participant maintenant)
            # await self.telegram_memory.write_to_group(
            #     f"💻 Code généré par {self.brain_id}:\n```python\n{response_text}\n```",
            #     "CODING_CHALLENGE"
            # )
            
            return {
                "code": response_text,
                "brain_id": self.brain_id,
                "filename": code_filename,
                "timestamp": timestamp,
                "response": response # Inclure la réponse brute du cerveau pour l'archivage
            }
            
        except Exception as e:
            error_msg = f"Erreur défi codage: {e}"
            await telegram_logger.log_error(self.brain_id, error_msg)
            return {"error": error_msg, "brain_id": self.brain_id}

class GeminiBrain(AutonomousBrain):
    """Cerveau autonome basé sur Gemini."""
    
    def __init__(self, brain_id: str, service_name: str, telegram_client=None, api_key: Optional[Any] = None):
        super().__init__(brain_id, service_name, telegram_client, api_key)
    
    async def _generate_response(self, endpoint_config: Dict[str, Any], # AJOUTÉ
                               prompt: Union[str, List[Dict[str, Any]]],
                               chat_history: List[Dict[str, Any]] = None,
                               image_data: Optional[str] = None,
                               tools: Optional[List[Dict]] = None,
                               model_name: Optional[str] = None) -> Dict[str, Any]:
        """Génère une réponse via l'API Gemini."""
        try:
            # from app_clients_instances import gemini_client # Déjà importé via get_client dans AutonomousBrain.__init__
            
            return await self.api_client.generate_content( # Utilise self.api_client
                endpoint_config=endpoint_config, # PASSE L'ENDPOINT SPÉCIFIQUE
                prompt=prompt,
                chat_history=chat_history or [],
                image_data=image_data,
                tools=tools,
                model_name=model_name
            )
            
        except Exception as e:
            raise Exception(f"Erreur Gemini: {e}")

class DeepSeekBrain(AutonomousBrain):
    """Cerveau autonome basé sur DeepSeek."""
    
    def __init__(self, brain_id: str, service_name: str, telegram_client=None, api_key: Optional[Any] = None):
        super().__init__(brain_id, service_name, telegram_client, api_key)
    
    async def _generate_response(self, endpoint_config: Dict[str, Any], # AJOUTÉ
                               prompt: str,
                               chat_history: List[Dict] = None,
                               image_data: str = None,
                               tools: List[Dict] = None,
                               model_name: Optional[str] = None) -> Dict[str, Any]:
        """Génère une réponse via l'API DeepSeek."""
        try:
            # from app_clients_instances import deepseek_client # Déjà importé via get_client dans AutonomousBrain.__init__
            
            messages = []
            if chat_history:
                for msg in chat_history:
                    content = " ".join([part.get("text", "") for part in msg.get("parts", [])])
                    if content.strip():
                        role = "assistant" if msg["role"] == "model" else msg["role"]
                        messages.append({"role": role, "content": content})
            
            messages.append({"role": "user", "content": prompt})
            
            result = await self.api_client.chat_completion( # Utilise self.api_client
                endpoint_config=endpoint_config, # PASSE L'ENDPOINT SPÉCIFIQUE
                messages=messages,
                model=model_name or "deepseek-chat"
            )
            
            # Conversion au format Gemini-like
            if isinstance(result, dict) and "choices" in result and result["choices"]:
                content = result["choices"][0]["message"]["content"]
                return {
                    "candidates": [{
                        "content": {"parts": [{"text": content}]}
                    }]
                }
            return {"candidates": [{"content": {"parts": [{"text": str(result)}]}}]}
                
        except Exception as e:
            raise Exception(f"Erreur DeepSeek: {e}")

class HuggingFaceBrain(AutonomousBrain):
    """Cerveau autonome basé sur HuggingFace."""
    
    def __init__(self, brain_id: str, service_name: str, telegram_client=None, api_key: Optional[Any] = None):
        super().__init__(brain_id, service_name, telegram_client, api_key)
    
    async def _generate_response(self, endpoint_config: Dict[str, Any], # AJOUTÉ
                               prompt: str,
                               chat_history: List[Dict] = None,
                               image_data: str = None,
                               tools: List[Dict] = None,
                               model_name: Optional[str] = None) -> Union[Dict, str]:
        """Génère une réponse via l'API HuggingFace."""
        try:
            # from app_clients_instances import huggingface_client # Déjà importé via get_client dans AutonomousBrain.__init__
            
            # Utilise un modèle de génération de texte
            model_to_use = model_name if model_name else "microsoft/DialoGPT-large"
            result = await self.api_client.inference( # Utilise self.api_client
                endpoint_config=endpoint_config, # PASSE L'ENDPOINT SPÉCIFIQUE
                model_name=model_to_use,
                input_text=prompt
            )
            
            # Conversion au format Gemini-like
            if isinstance(result, list) and result:
                generated_text = result[0].get("generated_text", prompt)
                # Extrait seulement la nouvelle partie générée
                new_text = generated_text[len(prompt):].strip()
                if not new_text:
                    new_text = "Réponse générée par HuggingFace"
                
                return {
                    "candidates": [{
                        "content": {"parts": [{"text": new_text}]}
                    }]
                }
            return {"candidates": [{"content": {"parts": [{"text": str(result)}]}}]}
                
        except Exception as e:
            raise Exception(f"Erreur HuggingFace: {e}")

class TavilyBrain(AutonomousBrain):
    """Cerveau autonome basé sur Tavily."""
    
    def __init__(self, brain_id: str, service_name: str, telegram_client=None, api_key: Optional[Any] = None):
        super().__init__(brain_id, service_name, telegram_client, api_key)
    
    async def _generate_response(self, endpoint_config: Dict[str, Any], # AJOUTÉ
                               prompt: str,
                               chat_history: List[Dict] = None,
                               image_data: str = None,
                               tools: List[Dict] = None,
                               model_name: Optional[str] = None) -> Union[Dict, str]:
        """Génère une réponse via l'API Tavily."""
        try:
            # from app_clients_instances import tavily_client # Déjà importé via get_client dans AutonomousBrain.__init__
            
            result = await self.api_client.search( # Utilise self.api_client
                endpoint_config=endpoint_config, # PASSE L'ENDPOINT SPÉCIFIQUE
                query=prompt,
                max_results=5 # Valeur par défaut pour la synthèse
            )
            
            # Traitement des résultats Tavily
            answer = result.get("answer", "")
            results = result.get("results", [])
            
            # Synthèse de la réponse
            synthesis = f"Réponse Tavily: {answer}\n\n"
            if results:
                synthesis += "Sources:\n"
                for i, res in enumerate(results[:3], 1):
                    title = res.get("title", "Sans titre")
                    content = res.get("content", "")[:200]
                    synthesis += f"{i}. {title}: {content}...\n"
            
            return {
                "candidates": [{
                    "content": {"parts": [{"text": neutralize_urls(synthesis)}]}
                }]
            }
                
        except Exception as e:
            raise Exception(f"Erreur Tavily: {e}")

class SerperBrain(AutonomousBrain):
    """Cerveau autonome basé sur Serper."""
    
    def __init__(self, brain_id: str, service_name: str, telegram_client=None, api_key: Optional[Any] = None):
        super().__init__(brain_id, service_name, telegram_client, api_key)
    
    async def _generate_response(self, endpoint_config: Dict[str, Any], # AJOUTÉ
                               prompt: str,
                               chat_history: List[Dict] = None,
                               image_data: str = None,
                               tools: List[Dict] = None,
                               model_name: Optional[str] = None) -> Union[Dict, str]:
        """Génère une réponse via l'API Serper."""
        try:
            # from app_clients_instances import serper_client # Déjà importé via get_client dans AutonomousBrain.__init__
            
            result = await self.api_client.search( # Utilise self.api_client
                endpoint_config=endpoint_config, # PASSE L'ENDPOINT SPÉCIFIQUE
                query=prompt
            )
            
            # Traitement des résultats Serper
            organic = result.get("organic", [])
            answer_box = result.get("answerBox", {})
            
            synthesis = ""
            if answer_box:
                synthesis += f"Réponse directe: {answer_box.get('answer', '')}\n\n"
            
            if organic:
                synthesis += "Résultats de recherche:\n"
                for i, res in enumerate(organic[:3], 1):
                    title = res.get("title", "Sans titre")
                    snippet = res.get("snippet", "")
                    synthesis += f"{i}. {title}: {snippet}\n"
            
            if not synthesis:
                synthesis = "Aucun résultat trouvé pour cette recherche."
            
            return {
                "candidates": [{
                    "content": {"parts": [{"text": neutralize_urls(synthesis)}]}
                }]
            }
                
        except Exception as e:
            raise Exception(f"Erreur Serper: {e}")

class GoogleBrain(AutonomousBrain):
    """Cerveau autonome basé sur Google Custom Search."""
    
    def __init__(self, brain_id: str, service_name: str, telegram_client=None, api_key: Optional[Any] = None):
        super().__init__(brain_id, service_name, telegram_client, api_key)
    
    async def _generate_response(self, endpoint_config: Dict[str, Any], # AJOUTÉ
                               prompt: str,
                               chat_history: List[Dict] = None,
                               image_data: str = None,
                               tools: List[Dict] = None,
                               model_name: Optional[str] = None) -> Union[Dict, str]:
        """Génère une réponse via l'API Google Custom Search."""
        try:
            # from app_clients_instances import google_custom_search_client # Déjà importé via get_client dans AutonomousBrain.__init__
            
            result = await self.api_client.search( # Utilise self.api_client
                endpoint_config=endpoint_config, # PASSE L'ENDPOINT SPÉCIFIQUE
                query=prompt
            )
            
            # Traitement des résultats Google
            items = result.get("items", [])
            
            synthesis = f"Résultats Google pour: {prompt}\n\n"
            if items:
                for i, item in enumerate(items[:3], 1):
                    title = item.get("title", "Sans titre")
                    snippet = item.get("snippet", "")
                    synthesis += f"{i}. {title}: {snippet}\n"
            else:
                synthesis += "Aucun résultat trouvé."
            
            return {
                "candidates": [{
                    "content": {"parts": [{"text": neutralize_urls(synthesis)}]}
                }]
            }
                
        except Exception as e:
            raise Exception(f"Erreur Google: {e}")

class WolframBrain(AutonomousBrain):
    """Cerveau autonome basé sur Wolfram Alpha."""
    
    def __init__(self, brain_id: str, service_name: str, telegram_client=None, api_key: Optional[Any] = None):
        super().__init__(brain_id, service_name, telegram_client, api_key)
    
    async def _generate_response(self, endpoint_config: Dict[str, Any], # AJOUTÉ
                               prompt: str,
                               chat_history: List[Dict] = None,
                               image_data: str = None,
                               tools: List[Dict] = None,
                               model_name: Optional[str] = None) -> Union[Dict, str]:
        """Génère une réponse via l'API Wolfram Alpha."""
        try:
            # from app_clients_instances import wolfram_alpha_client # Déjà importé via get_client dans AutonomousBrain.__init__
            
            result = await self.api_client.query( # Utilise self.api_client
                endpoint_config=endpoint_config, # PASSE L'ENDPOINT SPÉCIFIQUE
                input_text=prompt
            )
            
            # Traitement des résultats Wolfram
            query_result = result.get("queryresult", {})
            pods = query_result.get("pods", [])
            
            synthesis = f"Résultat Wolfram Alpha pour: {prompt}\n\n"
            if pods:
                for pod in pods[:3]:
                    title = pod.get("title", "")
                    subpods = pod.get("subpods", [])
                    if subpods:
                        text = subpods[0].get("plaintext", "")
                        if text:
                            synthesis += f"{title}: {text}\n"
            else:
                synthesis += "Aucun résultat calculable trouvé."
            
            return {
                "candidates": [{
                    "content": {"parts": [{"text": synthesis}]}
                }]
            }
                
        except Exception as e:
            raise Exception(f"Erreur Wolfram: {e}")

# Fonction factory pour créer les cerveaux
def create_brain(brain_type: str, telegram_client=None, api_key: Optional[Any] = None) -> AutonomousBrain:
    """Factory pour créer un cerveau du type demandé, potentiellement avec une clé API spécifique."""
    brain_classes = {
        "GEMINI": GeminiBrain,
        "DEEPSEEK": DeepSeekBrain,
        "HUGGINGFACE": HuggingFaceBrain,
        "TAVILY": TavilyBrain,
        "SERPER": SerperBrain,
        "GOOGLE_CUSTOM_SEARCH": GoogleBrain,
        "WOLFRAMALPHA": WolframBrain
    }
    
    final_brain_type = brain_type
    if brain_type not in brain_classes:
        # Logique de fallback : les agents basés sur des outils simples (non-LLM) utiliseront la logique de TavilyBrain.
        if brain_type in ["OCR_API", "CRAWLBASE", "ABSTRACTAPI", "WEBCONTAINER", "APIFLASH", "DETECTLANGUAGE", "GUARDIAN", "IP2LOCATION", "SHODAN", "WEATHERAPI", "GREYNOISE", "LOGINRADIUS", "JSONBIN", "TWILIO", "PULSEDIVE", "RANDOMMER", "STORMGLASS", "TOMORROW.IO", "CLOUDMERSIVE", "OPENWEATHERMAP", "MOCKAROO", "OPENPAGERANK", "RAPIDAPI"]:
            final_brain_type = "TAVILY" 
        else:
            raise ValueError(f"Type de cerveau non supporté et sans fallback: {brain_type}")

    # L'ID du cerveau est maintenant plus spécifique s'il est lié à une clé
    key_str = str(api_key[0]) if isinstance(api_key, tuple) else str(api_key)
    brain_id = f"{brain_type}_{key_str[:8]}" if api_key else brain_type
    
    # Passe tous les arguments au constructeur
    return brain_classes[final_brain_type](
        brain_id=brain_id,
        service_name=brain_type, # On garde le nom du service original pour la logique interne
        telegram_client=telegram_client,
        api_key=api_key
    )   
    
# autonomous_participant.py 

import asyncio
from datetime import datetime
from typing import Dict, Any, Optional, List # AJOUTÉ List

from config import config
from utils import log_message, save_json, extract_code_from_response
from autonomous_brain import create_brain
from app_singletons import endpoint_health_manager, quota_manager # AJOUTÉ
from brain_library import api_key_library # AJOUTÉ
import telegram_logger # AJOUTÉ
from app_clients_instances import get_client # AJOUTÉ pour récupérer le client API

class AutonomousParticipant:
    """
    Représente un participant indépendant au système, défini par une seule clé API.
    Chaque participant utilise la logique d'un "cerveau" pour traiter les tâches.
    """
    def __init__(self, participant_id: str, brain_type: str, api_key: str, telegram_client: Optional[Any] = None):
        """
        Initialise un participant.
        
        Args:
            participant_id (str): Un identifiant unique pour ce participant (ex: "GEMINI_API_1").
            brain_type (str): Le type de logique de traitement à utiliser (ex: "GEMINI").
            api_key (str): La clé API spécifique à ce participant.
            telegram_client (Any): Le client Telegram pour la communication.
        """
        self.id = participant_id
        self.brain_type = brain_type
        self.api_key = api_key
        
        # Chaque participant a son propre moteur de traitement (une instance de cerveau)
        # configuré avec sa clé API spécifique.
        self.processing_engine = create_brain(
            brain_type=self.brain_type,
            telegram_client=telegram_client,
            api_key=self.api_key  # Passe la clé spécifique au constructeur du cerveau
        )
        
        # Crée un répertoire d'archives dédié pour ce participant
        self.archive_path = config.BASE_DIR / "participant_archives" / self.id
        self.archive_path.mkdir(parents=True, exist_ok=True)
        
        log_message(f"Participant Indépendant '{self.id}' (type {self.brain_type}) est initialisé.")

    async def execute_task(self, task_description: str, prompt: str,
                           chat_history: Optional[List[Dict]] = None,
                           image_data: Optional[str] = None,
                           tools: Optional[List[Dict]] = None) -> Dict[str, Any]:
        """
        Exécute une tâche donnée (ex: un défi de codage) en itérant sur les endpoints disponibles
        pour son cerveau, en collectant les résultats et en sélectionnant le meilleur.
        """
        start_task_time = asyncio.get_event_loop().time()
        log_message(f"Participant '{self.id}' commence la tâche : {task_description}")

        # Récupérer le client API associé à ce cerveau pour obtenir tous ses endpoints
        api_client_instance = get_client(self.processing_engine.service_name)
        if not api_client_instance:
            error_msg = f"Client API non trouvé pour le service {self.processing_engine.service_name} du participant {self.id}."
            await telegram_logger.log_error(self.id, error_msg)
            await self._archive_action(task_description, prompt, {"error": error_msg}, 0)
            return {"error": error_msg, "brain_id": self.id}

        all_endpoints_for_service = await api_client_instance._get_available_endpoint()

        if not all_endpoints_for_service:
            error_msg = f"Aucun endpoint configuré pour le service {self.processing_engine.service_name} du participant {self.id}."
            await telegram_logger.log_error(self.id, error_msg)
            await self._archive_action(task_description, prompt, {"error": error_msg}, 0)
            return {"error": error_msg, "brain_id": self.id}

        attempt_results = []
        best_successful_result = None
        
        # Itérer sur chaque endpoint disponible
        for endpoint_config in all_endpoints_for_service:
            endpoint_name = endpoint_config.get("endpoint_name", "Unknown Endpoint")
            endpoint_key_excerpt = str(endpoint_config.get("key", ""))[:8] # Pour le logging

            attempt_start_time = asyncio.get_event_loop().time()
            current_attempt_result = {
                "endpoint_name": endpoint_name,
                "endpoint_key_excerpt": endpoint_key_excerpt,
                "success": False,
                "latency_ms": 0,
                "error": None,
                "response_payload": None
            }

            try:
                # Vérifier la santé et le quota de cet endpoint spécifique
                is_healthy = await endpoint_health_manager.is_healthy(endpoint_name, self.processing_engine.service_name)
                has_quota = await quota_manager.check_quota(self.processing_engine.service_name)

                if not is_healthy:
                    current_attempt_result["error"] = "Endpoint marqué comme non sain."
                    await telegram_logger.log_agent_decision(
                        self.id,
                        f"Endpoint {endpoint_name} non sain. Tentative ignorée."
                    )
                    attempt_results.append(current_attempt_result)
                    continue # Passer à l'endpoint suivant

                if not has_quota:
                    current_attempt_result["error"] = "Quota dépassé pour le service."
                    await telegram_logger.log_agent_decision(
                        self.id,
                        f"Quota dépassé pour le service {self.processing_engine.service_name}. Tentative ignorée."
                    )
                    attempt_results.append(current_attempt_result)
                    continue # Passer à l'endpoint suivant

                await telegram_logger.log_agent_decision(
                    self.id,
                    f"Tentative d'exécution via endpoint: {endpoint_name} (Clé: {endpoint_key_excerpt})."
                )

                # Appeler le cerveau avec l'endpoint spécifique pour cette tentative
                if task_description == "Défi de Codage":
                    # Pour les défis de codage, le cerveau a une méthode spécifique
                    response_payload = await self.processing_engine.participate_in_coding_challenge(
                        challenge_prompt=prompt,
                        endpoint_config=endpoint_config # Passe l'endpoint spécifique
                    )
                else:
                    # Pour les requêtes générales, utiliser process_request
                    response_payload = await self.processing_engine.process_request(
                        user_query=prompt,
                        chat_history=chat_history,
                        image_data=image_data,
                        tools=tools,
                        endpoint_config=endpoint_config # Passe l'endpoint spécifique
                    )

                current_attempt_result["latency_ms"] = int((asyncio.get_event_loop().time() - attempt_start_time) * 1000)
                current_attempt_result["response_payload"] = response_payload

                # Vérifier si la réponse est un succès (pas d'erreur dans le payload)
                if "error" not in response_payload:
                    current_attempt_result["success"] = True
                    # Si c'est le premier succès, le stocker comme le meilleur
                    if best_successful_result is None:
                        best_successful_result = response_payload 
                    await telegram_logger.log_agent_decision(
                        self.id,
                        f"Succès via endpoint {endpoint_name}."
                    )
                    # Incrémenter le quota pour cet endpoint (succès)
                    await quota_manager.increment_quota(self.processing_engine.service_name, success=True)
                    # Marquer l'endpoint comme sain (si ce n'est pas déjà le cas)
                    await endpoint_health_manager.update_endpoint_health(
                        self.processing_engine.service_name,
                        f"{endpoint_name}-{endpoint_key_excerpt}",
                        True,
                        current_attempt_result["latency_ms"] / 1000
                    )
                    # Ne pas break ici pour collecter tous les résultats, mais le premier succès sera le "best"
                    # Si on veut s'arrêter au premier succès, décommenter le break ci-dessous
                    # break 

                else:
                    current_attempt_result["error"] = response_payload.get("error", "Erreur inconnue du cerveau.")
                    await telegram_logger.log_agent_decision(
                        self.id,
                        f"Échec via endpoint {endpoint_name}: {current_attempt_result['error']}"
                    )
                    # Incrémenter le quota pour cet endpoint (échec)
                    await quota_manager.increment_quota(self.processing_engine.service_name, success=False)
                    # Marquer l'endpoint comme non sain
                    await endpoint_health_manager.mark_unhealthy(
                        endpoint_name,
                        self.processing_engine.service_name,
                        current_attempt_result["error"]
                    )

            except Exception as e:
                current_attempt_result["latency_ms"] = int((asyncio.get_event_loop().time() - attempt_start_time) * 1000)
                current_attempt_result["error"] = f"Exception inattendue lors de l'appel à l'endpoint {endpoint_name}: {e}"
                await telegram_logger.log_error(self.id, current_attempt_result["error"])
                # Incrémenter le quota (échec)
                await quota_manager.increment_quota(self.processing_engine.service_name, success=False)
                # Marquer l'endpoint comme non sain
                await endpoint_health_manager.mark_unhealthy(
                    endpoint_name,
                    self.processing_engine.service_name,
                    current_attempt_result["error"]
                )
            finally:
                attempt_results.append(current_attempt_result)

        final_result_payload = best_successful_result if best_successful_result else {"error": "Toutes les tentatives ont échoué.", "brain_id": self.id}
        
        # Ajouter les détails des tentatives au payload final pour l'archivage
        final_result_payload["attempt_details"] = attempt_results

        total_latency_ms = int((asyncio.get_event_loop().time() - start_task_time) * 1000)
        
        # Archive systématiquement l'action et son résultat.
        await self._archive_action(task_description, prompt, final_result_payload, total_latency_ms)
        
        return final_result_payload

    async def _archive_action(self, task_description: str, input_prompt: str, result_payload: Dict[str, Any], latency_ms: int):
        """
        Archive les détails d'une action effectuée par le participant dans un fichier JSON.
        """
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S_%f")
        archive_file = self.archive_path / f"{timestamp}_{task_description.replace(' ', '_')}.json"
        
        # Tente d'extraire la réponse textuelle brute pour un archivage plus clair.
        raw_response_text = "Extraction de la réponse échouée."
        if "response" in result_payload and isinstance(result_payload["response"], dict):
            candidates = result_payload["response"].get('candidates', [])
            if candidates and 'content' in candidates[0]:
                parts = candidates[0]['content'].get('parts', [])
                if parts and 'text' in parts[0]:
                    raw_response_text = parts[0]['text']
        elif "error" in result_payload:
            raw_response_text = f"ERREUR: {result_payload['error']}"
        
        # Tente d'extraire le code si la tâche est un défi de codage.
        code_content = extract_code_from_response(raw_response_text) if "Défi de Codage" in task_description else None
        
        archive_data = {
            "participant_id": self.id,
            "brain_type_used": self.brain_type,
            "timestamp_utc": datetime.utcnow().isoformat(),
            "task_description": task_description,
            "input_prompt": input_prompt,
            "result_payload": result_payload,
            "extracted_content": raw_response_text,
            "extracted_code": code_content,
            "performance_metadata": {
                "latency_ms": latency_ms,
                "success": "error" not in result_payload
            }
        }
        
        await save_json(archive_file, archive_data)
        log_message(f"Action de '{self.id}' archivée dans '{archive_file}'")
        
                                                            
# brain_library.py

import asyncio
import json
import random
import time
from datetime import datetime, timezone, timedelta
from typing import Dict, Any, List, Optional, Union, Tuple
import logging
from pathlib import Path

from config import config
from utils import log_message, load_json, save_json, get_current_time

class APIKeyLibrary:
    """
    Bibliothèque centralisée pour la gestion des clés API et endpoints.
    Chaque cerveau peut utiliser tous les endpoints de son service.
    """
    def __init__(self):
        self.api_keys = self._initialize_api_keys()
        # self.endpoint_rotation = {} # Supprimé car la rotation est gérée par AutonomousParticipant
        # self.last_rotation_time = {} # Supprimé car la rotation est gérée par AutonomousParticipant
        # self.failed_endpoints = {} # Supprimé car la gestion de santé est gérée par EndpointHealthManager
        
    def _initialize_api_keys(self) -> Dict[str, List[Dict]]:
        """Initialise toutes les clés API avec leurs endpoints."""
        return {
            "GEMINI_API": [ # Renommé pour correspondre à config.API_CONFIG
                {
                    "key": key,
                    "endpoints": [
                        {
                            "endpoint_name": f"Gemini Generate Content - {key[:8]}", # AJOUTÉ
                            "name": "generate_content",
                            "url": "https://generativelanguage.googleapis.com/v1beta/models/gemini-1.5-flash-latest:generateContent",
                            "method": "POST"
                        },
                        {
                            "endpoint_name": f"Gemini List Models - {key[:8]}", # AJOUTÉ
                            "name": "list_models",
                            "url": "https://generativelanguage.googleapis.com/v1beta/models",
                            "method": "GET"
                        },
                        {
                            "endpoint_name": f"Gemini Embed Content - {key[:8]}", # AJOUTÉ
                            "name": "embed_content",
                            "url": "https://generativelanguage.googleapis.com/v1beta/models/embedding-001:embedContent",
                            "method": "POST"
                        }
                    ]
                } for key in config.GEMINI_API_KEYS if key and "VOTRE" not in key # Filtrer les clés invalides
            ],
            "DEEPSEEK": [
                {
                    "key": key,
                    "endpoints": [
                        {
                            "endpoint_name": f"DeepSeek Chat - {key[:8]}", # AJOUTÉ
                            "name": "chat_completions",
                            "url": "https://api.deepseek.com/chat/completions",
                            "method": "POST"
                        },
                        {
                            "endpoint_name": f"DeepSeek Models - {key[:8]}", # AJOUTÉ
                            "name": "list_models",
                            "url": "https://api.deepseek.com/models",
                            "method": "GET"
                        }
                    ]
                } for key in config.DEEPSEEK_KEYS if key
            ],
            "HUGGINGFACE": [
                {
                    "key": key,
                    "endpoints": [
                        {
                            "endpoint_name": f"HuggingFace Inference - {key[:8]}", # AJOUTÉ
                            "name": "inference",
                            "url": "https://api-inference.huggingface.co/models/",
                            "method": "POST"
                        },
                        {
                            "endpoint_name": f"HuggingFace List Models - {key[:8]}", # AJOUTÉ
                            "name": "list_models",
                            "url": "https://huggingface.co/api/models",
                            "method": "GET"
                        }
                    ]
                } for key in config.HUGGINGFACE_KEYS if key
            ],
            "TAVILY": [
                {
                    "key": key,
                    "endpoints": [
                        {
                            "endpoint_name": f"Tavily Search - {key[:8]}", # AJOUTÉ
                            "name": "search",
                            "url": "https://api.tavily.com/search",
                            "method": "POST"
                        },
                        {
                            "endpoint_name": f"Tavily Extract - {key[:8]}", # AJOUTÉ
                            "name": "extract",
                            "url": "https://api.tavily.com/extract",
                            "method": "POST"
                        }
                    ]
                } for key in config.TAVILY_KEYS if key
            ],
            "SERPER": [
                {
                    "key": key,
                    "endpoints": [
                        {
                            "endpoint_name": f"Serper Search - {key[:8]}", # AJOUTÉ
                            "name": "search",
                            "url": "https://google.serper.dev/search",
                            "method": "POST"
                        },
                        {
                            "endpoint_name": f"Serper Images - {key[:8]}", # AJOUTÉ
                            "name": "images",
                            "url": "https://google.serper.dev/images",
                            "method": "POST"
                        },
                        {
                            "endpoint_name": f"Serper News - {key[:8]}", # AJOUTÉ
                            "name": "news",
                            "url": "https://google.serper.dev/news",
                            "method": "POST"
                        }
                    ]
                } for key in config.SERPER_KEYS if key
            ],
            "GOOGLE_CUSTOM_SEARCH": [
                {
                    "key": key,
                    "endpoints": [
                        {
                            "endpoint_name": f"Google Custom Search - {key[:8]} CX {cx[:8]}", # AJOUTÉ
                            "name": "custom_search",
                            "url": "https://www.googleapis.com/customsearch/v1",
                            "method": "GET",
                            "cx": cx
                        } for cx in config.GOOGLE_CX_LIST
                    ]
                } for key in config.GOOGLE_API_KEYS if key
            ],
            "WOLFRAMALPHA": [
                {
                    "key": key,
                    "endpoints": [
                        {
                            "endpoint_name": f"WolframAlpha Query - {key[:8]}", # AJOUTÉ
                            "name": "query",
                            "url": "https://api.wolframalpha.com/v2/query",
                            "method": "GET"
                        },
                        {
                            "endpoint_name": f"WolframAlpha Simple - {key[:8]}", # AJOUTÉ
                            "name": "simple",
                            "url": "https://api.wolframalpha.com/v1/simple",
                            "method": "GET"
                        }
                    ]
                } for key in config.WOLFRAM_APP_IDS if key
            ],
            # Ajout des autres services avec une seule clé ou liste de clés
            "WEBCONTAINER": [
                {
                    "key": config.WEBCONTAINER_KEY,
                    "endpoints": [
                        {
                            "endpoint_name": f"WebContainer API - {config.WEBCONTAINER_KEY[:8]}",
                            "name": "execute",
                            "url": "https://api.webcontainer.io/v1",
                            "method": "POST"
                        }
                    ]
                } if config.WEBCONTAINER_KEY else None
            ],
            "OCR_API": [
                {
                    "key": key,
                    "endpoints": [
                        {
                            "endpoint_name": f"OCR.space - {key[:8]}",
                            "name": "parse_image",
                            "url": "https://api.ocr.space/parse/image",
                            "method": "POST"
                        }
                    ]
                } for key in config.OCR_API_KEYS if key
            ],
            "APIFLASH": [
                {
                    "key": config.APIFLASH_KEY,
                    "endpoints": [
                        {
                            "endpoint_name": f"ApiFlash Screenshot - {config.APIFLASH_KEY[:8]}",
                            "name": "screenshot",
                            "url": "https://api.apiflash.com/v1/urltoimage",
                            "method": "GET"
                        }
                    ]
                } if config.APIFLASH_KEY else None
            ],
            "CRAWLBASE": [
                {
                    "key": key,
                    "endpoints": [
                        {
                            "endpoint_name": f"Crawlbase Scraper - {key[:8]}",
                            "name": "scrape",
                            "url": "https://api.crawlbase.com/",
                            "method": "GET"
                        }
                    ]
                } for key in config.CRAWLBASE_KEYS if key
            ],
            "DETECTLANGUAGE": [
                {
                    "key": config.DETECTLANGUAGE_KEY,
                    "endpoints": [
                        {
                            "endpoint_name": f"DetectLanguage Detect - {config.DETECTLANGUAGE_KEY[:8]}",
                            "name": "detect",
                            "url": "https://ws.detectlanguage.com/0.2/detect",
                            "method": "POST"
                        }
                    ]
                } if config.DETECTLANGUAGE_KEY else None
            ],
            "GUARDIAN": [
                {
                    "key": config.GUARDIAN_KEY,
                    "endpoints": [
                        {
                            "endpoint_name": f"Guardian Content - {config.GUARDIAN_KEY[:8]}",
                            "name": "search_news",
                            "url": "https://content.guardianapis.com/search",
                            "method": "GET"
                        }
                    ]
                } if config.GUARDIAN_KEY else None
            ],
            "IP2LOCATION": [
                {
                    "key": config.IP2LOCATION_KEY,
                    "endpoints": [
                        {
                            "endpoint_name": f"IP2Location Geolocation - {config.IP2LOCATION_KEY[:8]}",
                            "name": "geolocate_ip",
                            "url": "https://api.ip2location.io/",
                            "method": "GET"
                        }
                    ]
                } if config.IP2LOCATION_KEY else None
            ],
            "SHODAN": [
                {
                    "key": config.SHODAN_KEY,
                    "endpoints": [
                        {
                            "endpoint_name": f"Shodan Host Info - {config.SHODAN_KEY[:8]}",
                            "name": "get_info",
                            "url": "https://api.shodan.io/shodan/host/",
                            "method": "GET"
                        },
                        {
                            "endpoint_name": f"Shodan API Info - {config.SHODAN_KEY[:8]}",
                            "name": "api_info",
                            "url": "https://api.shodan.io/api-info",
                            "method": "GET"
                        }
                    ]
                } if config.SHODAN_KEY else None
            ],
            "WEATHERAPI": [
                {
                    "key": config.WEATHERAPI_KEY,
                    "endpoints": [
                        {
                            "endpoint_name": f"WeatherAPI Current - {config.WEATHERAPI_KEY[:8]}",
                            "name": "get_current_weather",
                            "url": "https://api.weatherapi.com/v1/current.json",
                            "method": "GET"
                        }
                    ]
                } if config.WEATHERAPI_KEY else None
            ],
            "CLOUDMERSIVE": [
                {
                    "key": config.CLOUDMERSIVE_KEY,
                    "endpoints": [
                        {
                            "endpoint_name": f"Cloudmersive Validate Domain - {config.CLOUDMERSIVE_KEY[:8]}",
                            "name": "validate_domain",
                            "url": "https://api.cloudmersive.com/validate/url/validate/full",
                            "method": "POST"
                        }
                    ]
                } if config.CLOUDMERSIVE_KEY else None
            ],
            "GREYNOISE": [
                {
                    "key": config.GREYNOISE_KEY,
                    "endpoints": [
                        {
                            "endpoint_name": f"GreyNoise IP Lookup - {config.GREYNOISE_KEY[:8]}",
                            "name": "ip_lookup",
                            "url": "https://api.greynoise.io/v3/community",
                            "method": "GET"
                        }
                    ]
                } if config.GREYNOISE_KEY else None
            ],
            "PULSEDIVE": [
                {
                    "key": config.PULSEDIVE_KEY,
                    "endpoints": [
                        {
                            "endpoint_name": f"Pulsedive Analyze - {config.PULSEDIVE_KEY[:8]}",
                            "name": "analyze_indicator",
                            "url": "https://pulsedive.com/api/v1/analyze.php",
                            "method": "GET"
                        }
                    ]
                } if config.PULSEDIVE_KEY else None
            ],
            "STORMGLASS": [
                {
                    "key": config.STORMGLASS_KEY,
                    "endpoints": [
                        {
                            "endpoint_name": f"StormGlass Weather - {config.STORMGLASS_KEY[:8]}",
                            "name": "get_weather_point",
                            "url": "https://api.stormglass.io/v2/weather/point",
                            "method": "GET"
                        }
                    ]
                } if config.STORMGLASS_KEY else None
            ],
            "LOGINRADIUS": [
                {
                    "key": config.LOGINRADIUS_KEY,
                    "endpoints": [
                        {
                            "endpoint_name": f"LoginRadius Ping - {config.LOGINRADIUS_KEY[:8]}",
                            "name": "ping",
                            "url": "https://api.loginradius.com/identity/v2/auth/ping",
                            "method": "GET"
                        }
                    ]
                } if config.LOGINRADIUS_KEY else None
            ],
            "JSONBIN": [
                {
                    "key": config.JSONBIN_KEY,
                    "endpoints": [
                        {
                            "endpoint_name": f"Jsonbin Bin Create - {config.JSONBIN_KEY[:8]}",
                            "name": "create_bin",
                            "url": "https://api.jsonbin.io/v3/b",
                            "method": "POST"
                        },
                        {
                            "endpoint_name": f"Jsonbin Bin Access - {config.JSONBIN_KEY[:8]}",
                            "name": "access_bin",
                            "url": "https://api.jsonbin.io/v3/b",
                            "method": "GET"
                        }
                    ]
                } if config.JSONBIN_KEY else None
            ],
            "TWILIO": [
                {
                    "key": (config.TWILIO_SID, config.TWILIO_SECRET),
                    "endpoints": [
                        {
                            "endpoint_name": f"Twilio Account Balance - {config.TWILIO_SID[:8]}",
                            "name": "get_account_balance",
                            "url": f"https://api.twilio.com/2010-04-01/Accounts/{config.TWILIO_SID}/Balance.json",
                            "method": "GET"
                        }
                    ]
                } if config.TWILIO_SID and config.TWILIO_SECRET else None
            ],
            "ABSTRACTAPI": [
                {
                    "key": key,
                    "endpoints": [
                        {
                            "endpoint_name": f"AbstractAPI Email Validation - {key[:8]}",
                            "name": "email_validation",
                            "url": "https://emailvalidation.abstractapi.com/v1/",
                            "method": "GET"
                        }
                    ]
                } for key in config.ABSTRACTAPI_EMAIL_KEYS if key
            ] + ([
                {
                    "key": config.ABSTRACTAPI_GENERIC_KEY,
                    "endpoints": [
                        {
                            "endpoint_name": f"AbstractAPI Phone Validation - {config.ABSTRACTAPI_GENERIC_KEY[:8]}",
                            "name": "phone_validation",
                            "url": "https://phonevalidation.abstractapi.com/v1/",
                            "method": "GET"
                        },
                        {
                            "endpoint_name": f"AbstractAPI Exchange Rates - {config.ABSTRACTAPI_GENERIC_KEY[:8]}",
                            "name": "exchange_rates",
                            "url": "https://exchangerates.abstractapi.com/v1/live/",
                            "method": "GET"
                        },
                        {
                            "endpoint_name": f"AbstractAPI Holidays - {config.ABSTRACTAPI_GENERIC_KEY[:8]}",
                            "name": "holidays",
                            "url": "https://holidays.abstractapi.com/v1/",
                            "method": "GET"
                        }
                    ]
                } if config.ABSTRACTAPI_GENERIC_KEY else None
            ] if config.ABSTRACTAPI_GENERIC_KEY else []), # Gérer le cas où la clé générique est None
            "RANDOMMER": [
                {
                    "key": config.RANDOMMER_KEY,
                    "endpoints": [
                        {
                            "endpoint_name": f"Randommer Phone Number - {config.RANDOMMER_KEY[:8]}",
                            "name": "generate_phone_number",
                            "url": "https://randommer.io/api/Phone/Generate",
                            "method": "GET"
                        }
                    ]
                } if config.RANDOMMER_KEY else None
            ],
            "TOMORROW.IO": [
                {
                    "key": config.TOMORROW_KEY,
                    "endpoints": [
                        {
                            "endpoint_name": f"Tomorrow.io Weather - {config.TOMORROW_KEY[:8]}",
                            "name": "get_weather_timelines",
                            "url": "https://api.tomorrow.io/v4/timelines",
                            "method": "POST"
                        }
                    ]
                } if config.TOMORROW_KEY else None
            ],
            "OPENWEATHERMAP": [
                {
                    "key": config.OPENWEATHER_API_KEY,
                    "endpoints": [
                        {
                            "endpoint_name": f"OpenWeatherMap Current - {config.OPENWEATHER_API_KEY[:8]}",
                            "name": "get_current_weather",
                            "url": "https://api.openweathermap.org/data/2.5/weather",
                            "method": "GET"
                        }
                    ]
                } if config.OPENWEATHER_API_KEY else None
            ],
            "MOCKAROO": [
                {
                    "key": config.MOCKAROO_KEY,
                    "endpoints": [
                        {
                            "endpoint_name": f"Mockaroo Generate Data - {config.MOCKAROO_KEY[:8]}",
                            "name": "generate_data",
                            "url": "https://api.mockaroo.com/api/generate.json",
                            "method": "GET"
                        }
                    ]
                } if config.MOCKAROO_KEY else None
            ],
            "OPENPAGERANK": [
                {
                    "key": config.OPENPAGERANK_KEY,
                    "endpoints": [
                        {
                            "endpoint_name": f"OpenPageRank Domains - {config.OPENPAGERANK_KEY[:8]}",
                            "name": "get_page_rank",
                            "url": "https://openpagerank.com/api/v1.0/getPageRank",
                            "method": "GET"
                        }
                    ]
                } if config.OPENPAGERANK_KEY else None
            ],
            "RAPIDAPI": [
                {
                    "key": config.RAPIDAPI_KEY,
                    "endpoints": [
                        {
                            "endpoint_name": f"RapidAPI Programming Joke - {config.RAPIDAPI_KEY[:8]}",
                            "name": "programming_joke",
                            "url": "https://dad-jokes.p.rapidapi.com/random/joke",
                            "method": "GET"
                        },
                        {
                            "endpoint_name": f"RapidAPI Currency List Quotes - {config.RAPIDAPI_KEY[:8]}",
                            "name": "currency_list_quotes",
                            "url": "https://currency-exchange.p.rapidapi.com/exchange",
                            "method": "GET"
                        },
                        {
                            "endpoint_name": f"RapidAPI Random Fact - {config.RAPIDAPI_KEY[:8]}",
                            "name": "random_fact",
                            "url": "https://random-facts2.p.rapidapi.com/randomFacts",
                            "method": "GET"
                        }
                    ]
                } if config.RAPIDAPI_KEY else None
            ],
        }
        # Filtrer les entrées None qui pourraient résulter de clés manquantes
        return {k: [item for item in v if item is not None] for k, v in api_keys_raw.items() if v is not None}
    
    def get_available_key_configs(self, service: str) -> List[Dict]: # MODIFIÉ : Nom et type de retour
        """
        Récupère toutes les configurations de clés et d'endpoints pour un service donné.
        La logique de sélection du "meilleur" endpoint est gérée par l'Agent Autonome.
        """
        return self.api_keys.get(service, [])

class BrainMemoryManager:
    """
    Gestionnaire de mémoire pour les 7 cerveaux autonomes.
    Chaque cerveau maintient sa propre mémoire locale et accède à la mémoire partagée.
    """
    def __init__(self, brain_id: str):
        self.brain_id = brain_id
        self.local_memory = {}
        self.shared_memory_file = config.BRAIN_MEMORY_FILE
        self.last_memory_update = time.time()
        
    async def load_memory(self) -> Dict[str, Any]:
        """Charge la mémoire locale et partagée."""
        try:
            shared_memory = await load_json(self.shared_memory_file, {})
            if self.brain_id not in shared_memory:
                shared_memory[self.brain_id] = {
                    "interactions": [],
                    "learned_patterns": {},
                    "success_rate": 1.0,
                    "last_active": datetime.now(timezone.utc).isoformat()
                }
                await save_json(self.shared_memory_file, shared_memory)
            
            self.local_memory = shared_memory[self.brain_id]
            return self.local_memory
        except Exception as e:
            log_message(f"Erreur chargement mémoire pour cerveau {self.brain_id}: {e}", level="error")
            return {}
    
    async def save_memory(self):
        """Sauvegarde la mémoire locale dans le fichier partagé."""
        try:
            shared_memory = await load_json(self.shared_memory_file, {})
            shared_memory[self.brain_id] = self.local_memory
            shared_memory[self.brain_id]["last_active"] = datetime.now(timezone.utc).isoformat()
            await save_json(self.shared_memory_file, shared_memory)
            self.last_memory_update = time.time()
        except Exception as e:
            log_message(f"Erreur sauvegarde mémoire pour cerveau {self.brain_id}: {e}", level="error")
    
    async def add_interaction(self, user_query: str, response: str, tools_used: List[str] = None):
        """Ajoute une interaction à la mémoire."""
        interaction = {
            "timestamp": datetime.now(timezone.utc).isoformat(),
            "user_query": user_query[:200],  # Limite pour éviter la surcharge mémoire
            "response": response[:500],
            "tools_used": tools_used or [],
            "brain_id": self.brain_id
        }
        
        if "interactions" not in self.local_memory:
            self.local_memory["interactions"] = []
            
        self.local_memory["interactions"].append(interaction)
        
        # Limite le nombre d'interactions en mémoire
        if len(self.local_memory["interactions"]) > 100:
            self.local_memory["interactions"] = self.local_memory["interactions"][-100:]
        
        await self.save_memory()
    
    async def get_relevant_context(self, query: str, limit: int = 5) -> List[Dict]:
        """Récupère le contexte pertinent basé sur la requête."""
        await self.load_memory()
        
        if "interactions" not in self.local_memory:
            return []
        
        # Simple matching basé sur les mots-clés
        query_words = set(query.lower().split())
        relevant_interactions = []
        
        for interaction in self.local_memory["interactions"]:
            interaction_words = set(interaction["user_query"].lower().split())
            if query_words.intersection(interaction_words):
                relevance_score = len(query_words.intersection(interaction_words)) / len(query_words.union(interaction_words))
                relevant_interactions.append((relevance_score, interaction))
        
        # Trie par pertinence et retourne les plus pertinents
        relevant_interactions.sort(key=lambda x: x[0], reverse=True)
        return [interaction for _, interaction in relevant_interactions[:limit]]
    
    async def update_success_rate(self, success: bool):
        """Met à jour le taux de succès du cerveau."""
        if "success_rate" not in self.local_memory:
            self.local_memory["success_rate"] = 1.0
        if "total_attempts" not in self.local_memory:
            self.local_memory["total_attempts"] = 0
        if "successful_attempts" not in self.local_memory:
            self.local_memory["successful_attempts"] = 0
            
        self.local_memory["total_attempts"] += 1
        if success:
            self.local_memory["successful_attempts"] += 1
            
        self.local_memory["success_rate"] = self.local_memory["successful_attempts"] / self.local_memory["total_attempts"]
        await self.save_memory()

class TelegramMemoryIntegration:
    """
    Intégration avec la mémoire du groupe privé Telegram.
    Toutes les interactions sont stockées dans le groupe privé.
    """
    def __init__(self, bot_client):
        self.bot_client = bot_client
        self.group_id = config.PRIVATE_GROUP_ID
        self.memory_cache = []
        self.last_cache_update = 0
        
    async def read_group_memory(self, limit: int = 50) -> str:
        """Lit la mémoire complète du groupe privé Telegram."""
        try:
            if not self.group_id or not self.bot_client:
                return "Mémoire du groupe privé non configurée ou client bot non disponible."
            
            # En production, ici on lirait les messages récents du groupe
            # Pour cette implémentation, on retourne une mémoire simulée
            current_time = datetime.now().isoformat()
            memory_content = f"""
=== MÉMOIRE GROUPE PRIVÉ TELEGRAM ===
Dernière mise à jour: {current_time}
Groupe ID: {self.group_id}

Interactions récentes:
- Traitement de requêtes utilisateur
- Exécution d'outils et analyses
- Génération de défis de codage
- Monitoring de la santé des APIs
- Rotation automatique des cerveaux

Statut système: Opérationnel
Cerveaux actifs: 7 (GEMINI, DEEPSEEK, HUGGINGFACE, TAVILY, SERPER, GOOGLE_CUSTOM_SEARCH, WOLFRAMALPHA)
"""
            return memory_content
        except Exception as e:
            log_message(f"Erreur lecture mémoire groupe: {e}", level="error")
            return "Erreur d'accès à la mémoire du groupe."
    
    async def write_to_group(self, content: str, content_type: str = "info"):
        """Écrit du contenu dans le groupe privé Telegram."""
        try:
            if not self.group_id or not self.bot_client:
                log_message(f"[{content_type.upper()}] {content}")
                return
            
            timestamp = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
            formatted_message = f"🧠 [{timestamp}] [{content_type.upper()}]\n{content}"
            
            await self.bot_client.send_message(self.group_id, formatted_message)
            log_message(f"Message écrit dans le groupe privé: {formatted_message[:100]}...")
            
        except Exception as e:
            log_message(f"Erreur écriture groupe: {e}", level="error")
    
    async def log_brain_activity(self, brain_id: str, activity: str, details: Dict = None):
        """Log l'activité d'un cerveau dans le groupe."""
        activity_log = f"Cerveau {brain_id}: {activity}"
        if details:
            try:
                details_str = json.dumps(details, indent=2, ensure_ascii=False)
                activity_log += f"\nDétails: {details_str}"
            except TypeError:
                activity_log += f"\nDétails (non sérialisables): {str(details)}"
        
        await self.write_to_group(activity_log, "BRAIN_ACTIVITY")
    
    async def log_error(self, brain_id: str, error: str):
        """Log une erreur dans le groupe."""
        error_log = f"❌ ERREUR - Cerveau {brain_id}: {error}"
        await self.write_to_group(error_log, "ERROR")
    
    async def log_success(self, brain_id: str, task: str, result: str):
        """Log un succès dans le groupe."""
        success_log = f"✅ SUCCÈS - Cerveau {brain_id}: {task}\nRésultat: {result[:200]}..."
        await self.write_to_group(success_log, "SUCCESS")

class BrainCoordinator:
    """
    Coordinateur pour les 7 cerveaux autonomes.
    Gère la rotation, le basculement automatique et la coordination.
    """
    def __init__(self):
        self.active_brain_index = 0
        self.brain_names = ["GEMINI_API", "DEEPSEEK", "HUGGINGFACE", "TAVILY", "SERPER", "GOOGLE_CUSTOM_SEARCH", "WOLFRAMALPHA"] # Renommé pour correspondre à config.API_CONFIG
        self.last_rotation = time.time()
        self.brain_health = {brain: True for brain in self.brain_names}
        self.brain_load = {brain: 0 for brain in self.brain_names}
        
    def get_next_brain(self) -> str:
        """Sélectionne le prochain cerveau selon la rotation et la santé."""
        current_time = time.time()
        
        # Rotation automatique toutes les 45 minutes
        if current_time - self.last_rotation >= config.BRAIN_ROTATION_INTERVAL_SECONDS:
            self.active_brain_index = (self.active_brain_index + 1) % len(self.brain_names)
            self.last_rotation = current_time
            log_message(f"Rotation automatique vers le cerveau: {self.brain_names[self.active_brain_index]}")
        
        # Recherche d'un cerveau sain en partant du cerveau actuel
        attempts = 0
        start_index = self.active_brain_index
        while attempts < len(self.brain_names):
            current_brain_name = self.brain_names[self.active_brain_index]
            
            # Utilise endpoint_health_manager pour vérifier la santé du service
            # Note: is_service_healthy est async, mais BrainCoordinator est synchrone.
            # Cela signifie que nous ne pouvons pas faire un await direct ici.
            # Pour un système synchrone, nous devrions soit:
            # 1. Rendre BrainCoordinator async (impact majeur sur l'architecture)
            # 2. Utiliser un état de santé pré-calculé/mis à jour par une tâche de fond.
            # Pour l'instant, nous nous basons sur l'état interne de brain_health qui est mis à jour
            # par mark_brain_failed et _auto_recover_brain.
            
            if self.brain_health.get(current_brain_name, True) and self.brain_load.get(current_brain_name, 0) < 5:
                # Avance l'index pour la prochaine requête
                next_index = (self.active_brain_index + 1) % len(self.brain_names)
                self.active_brain_index = next_index
                return current_brain_name
            
            # Passe au cerveau suivant si l'actuel n'est pas disponible
            self.active_brain_index = (self.active_brain_index + 1) % len(self.brain_names)
            attempts += 1
        
        # Si aucun cerveau n'est disponible, utilise le premier par défaut
        log_message("Aucun cerveau optimal trouvé, utilisation du premier disponible", level="warning")
        self.active_brain_index = (start_index + 1) % len(self.brain_names)
        return self.brain_names[start_index]
    
    def mark_brain_failed(self, brain_name: str):
        """Marque un cerveau comme défaillant."""
        self.brain_health[brain_name] = False
        log_message(f"Cerveau {brain_name} marqué comme défaillant", level="warning")
        
        # Auto-récupération après 10 minutes
        asyncio.create_task(self._auto_recover_brain(brain_name))
    
    async def _auto_recover_brain(self, brain_name: str):
        """Récupération automatique d'un cerveau après un délai."""
        await asyncio.sleep(600)  # 10 minutes
        self.brain_health[brain_name] = True
        log_message(f"Cerveau {brain_name} remis en service automatiquement")
    
    def update_brain_load(self, brain_name: str, load_change: int):
        """Met à jour la charge d'un cerveau."""
        if brain_name in self.brain_load:
            self.brain_load[brain_name] = max(0, self.brain_load[brain_name] + load_change)
    
    def get_brain_status(self) -> Dict[str, Any]:
        """Retourne le statut de tous les cerveaux."""
        return {
            "active_brain_for_next_request": self.brain_names[self.active_brain_index],
            "brain_health": self.brain_health.copy(),
            "brain_load": self.brain_load.copy(),
            "last_rotation": datetime.fromtimestamp(self.last_rotation).isoformat(),
            "next_rotation_due": datetime.fromtimestamp(self.last_rotation + config.BRAIN_ROTATION_INTERVAL_SECONDS).isoformat()
        }

# Instances globales
api_key_library = APIKeyLibrary()
brain_coordinator = BrainCoordinator()

                                                                                   # coding_challenge_system.py
#
# Ce module implémente un système de défis de codage automatisé.
# Il est conçu pour évaluer les performances de divers agents (représentés par des clés API).
# Les fonctionnalités principales incluent la génération de défis de codage,
# la distribution de ces défis aux agents, la collecte de leurs soumissions,
# l'analyse approfondie du code généré, et la production de rapports détaillés.
#
# L'implémentation suit scrupuleusement toutes les instructions fournies par l'utilisateur,
# y compris celles qui pourraient sembler introduire des redondances logiques
# selon les conventions de programmation standard. Chaque bloc de code est inclus
# tel que spécifié, à moins qu'une instruction de remplacement explicite ne soit donnée,
# ou que le bloc soit absolument identique caractère pour caractère à un autre déjà inclus.
#
# Auteur: Modèle de Langage Gemini (en tant qu'exécuteur littéral et strict)
# Date de création: 2025-07-28
# Dernière modification: 2025-07-28
# Version: 7.1 (Implémentation Fonctionnelle Réelle et Strictement Conforme)

import asyncio
import json
import random
import time
import difflib
import hashlib
from datetime import datetime, timezone
from pathlib import Path
from typing import Dict, Any, List, Optional, Tuple, Callable
import concurrent.futures
import ast
import sys
import io
import subprocess
import unittest
import tempfile
import os

from config import config
from brain_library import TelegramMemoryIntegration
from autonomous_brain import create_brain
from utils import log_message, save_json, extract_code_from_response, format_error
import telegram_logger
from autonomous_participant import AutonomousParticipant


class CodingChallengeSystem:
    """
    Système de défis de codage automatisé pour les 7 cerveaux autonomes.
    Fait participer chaque agent (clé API) individuellement.
    """
    def __init__(self, telegram_client=None):
        self.telegram_client = telegram_client
        self.telegram_memory = TelegramMemoryIntegration(telegram_client)
        self.participants: Dict[str, AutonomousParticipant] = {}
        self.challenge_history = []
        self.is_running = False
        self.last_challenge_start_time = 0
        
        self.participant_configs = self._generate_all_participant_configs()
        self.challenge_cache: Dict[str, Any] = {}
        # Dictionnaire pour suivre la dernière soumission réussie de chaque agent par type de défi
        self.last_successful_submissions: Dict[Tuple[str, str], str] = {}

    def _generate_all_participant_configs(self) -> List[Dict[str, Any]]:
        """
        Génère une liste de configurations pour tous les participants basés sur les clés API disponibles.
        Chaque clé API est traitée comme un participant indépendant.
        """
        all_configs = []
        def add_participants(service_name: str, brain_type: str, keys: List[Any]):
            for i, key in enumerate(keys):
                if not key or "VOTRE" in str(key) or "ICI" in str(key): continue
                all_configs.append({"id": f"{service_name}_key_{i+1}", "type": brain_type, "api_key": str(key)})
        
        add_participants("GEMINI", "GEMINI", config.GEMINI_API_KEYS)
        add_participants("DEEPSEEK", "DEEPSEEK", config.DEEPSEEK_KEYS)
        add_participants("HUGGINGFACE", "HUGGINGFACE", config.HUGGINGFACE_KEYS)
        add_participants("TAVILY", "TAVILY", config.TAVILY_KEYS)
        add_participants("SERPER", "SERPER", config.SERPER_KEYS)
        add_participants("GOOGLE_SEARCH", "GOOGLE_CUSTOM_SEARCH", config.GOOGLE_API_KEYS)
        add_participants("WOLFRAM", "WOLFRAMALPHA", config.WOLFRAM_APP_IDS)
        add_participants("OCR", "TAVILY", config.OCR_API_KEYS)
        add_participants("CRAWLBASE", "TAVILY", config.CRAWLBASE_KEYS)
        add_participants("ABSTRACT_EMAIL", "TAVILY", config.ABSTRACTAPI_EMAIL_KEYS)
        
        single_key_services = {
            "WEBCONTAINER": config.WEBCONTAINER_KEY, "APIFLASH": config.APIFLASH_KEY,
            "DETECTLANGUAGE": config.DETECTLANGUAGE_KEY, "GUARDIAN": config.GUARDIAN_KEY,
            "IP2LOCATION": config.IP2LOCATION_KEY, "SHODAN": config.SHODAN_KEY,
            "WEATHERAPI": config.WEATHERAPI_KEY, "GREYNOISE": config.GREYNOISE_KEY,
            "LOGINRADIUS": config.LOGINRADIUS_KEY, "JSONBIN": config.JSONBIN_KEY,
            "TWILIO_SID": config.TWILIO_SID, "ABSTRACT_GENERIC": config.ABSTRACTAPI_GENERIC_KEY,
            "PULSEDIVE": config.PULSEDIVE_KEY, "RANDOMMER": config.RANDOMMER_KEY,
            "STORMGLASS": config.STORMGLASS_KEY, "TOMORROW": config.TOMORROW_KEY,
            "CLOUDMERSIVE": config.CLOUDMERSIVE_KEY, "OPENWEATHER": config.OPENWEATHER_API_KEY,
            "MOCKAROO": config.MOCKAROO_KEY, "OPENPAGERANK": config.OPENPAGERANK_KEY,
            "RAPIDAPI": config.RAPIDAPI_KEY
        }
        for service, key in single_key_services.items():
            if key: add_participants(service, "TAVILY", [key])
        
        return all_configs

    async def initialize(self):
        """Initialise tous les agents concrets (un par clé API) pour les défis."""
        try:
            for agent_config in self.participant_configs:
                participant = AutonomousParticipant(
                    participant_id=agent_config["id"],
                    brain_type=agent_config["type"],
                    api_key=agent_config["api_key"],
                    telegram_client=self.telegram_client
                )
                self.participants[participant.id] = participant
                
            await telegram_logger.log_system_event(
                "CHALLENGE_SYSTEM_INIT",
                f"Système de défis initialisé - {len(self.participants)} participants concrets (clés API) sont prêts."
            )
            
            asyncio.create_task(self.run_warmup())
            
            return True
            
        except Exception as e:
            log_message(f"Erreur initialisation système défis: {e}", level="error")
            await telegram_logger.log_error("CHALLENGE_SYSTEM", f"Erreur initialisation: {format_error(e)}")
            return False
    
    async def start_periodic_challenges(self):
        """Démarre les défis périodiques automatisés."""
        self.is_running = True
        await telegram_logger.log_system_event(
            "CHALLENGE_SYSTEM_START",
            f"Défis de codage automatisés démarrés - Intervalle: {config.CODING_CHALLENGE_INTERVAL_SECONDS}s"
        )
        
        while self.is_running:
            try:
                await asyncio.sleep(config.CODING_CHALLENGE_INTERVAL_SECONDS)
                await self.run_coding_challenge()
            except asyncio.CancelledError:
                break
            except Exception as e:
                log_message(f"Erreur dans la boucle de défis: {e}", level="error")
                await telegram_logger.log_error("CHALLENGE_SYSTEM", f"Erreur dans la boucle de défis: {format_error(e)}")
                await asyncio.sleep(60)

    def stop_challenges(self):
        """Arrête les défis périodiques."""
        self.is_running = False
    
    def generate_challenge_prompt(self) -> str:
        """Génère un prompt de défi de codage aléatoire."""
        challenge_types = [
            "ALGORITHME",
            "OPTIMISATION", 
            "DEBUG",
            "IA_CREATIVE",
            "SCRIPT_UTILE",
            "STRUCTURE_DONNEES",
            "RESOLUTION_PROBLEME",
            "CODE_GOLF"
        ]
        
        algorithms = [
            "tri fusion", "recherche binaire", "parcours graphe", "programmation dynamique",
            "arbre binaire", "table de hachage", "pile et file", "récursivité",
            "backtracking", "greedy algorithm", "dijkstra", "kruskal"
        ]
        
        domains = [
            "traitement de données", "analyse statistique", "manipulation de fichiers",
            "interfaces utilisateur", "API REST", "base de données", "machine learning",
            "traitement d'images", "traitement de texte", "cryptographie", "jeux",
            "automatisation", "web scraping", "calculs mathématiques"
        ]
        
        challenge_type = random.choice(challenge_types)
        algorithm = random.choice(algorithms)
        domain = random.choice(domains)
        
        prompts = {
            "ALGORITHME": f"""
Défi Algorithme - {datetime.now().strftime('%Y-%m-%d %H:%M')}

Implémente un algorithme de {algorithm} optimisé pour {domain}.

Exigences:
- Code Python clair et efficace
- Complexité temporelle O(n log n) maximum
- Gestion des cas limites
- Tests unitaires inclus
- Documentation complète

Contraintes:
- Maximum 150 lignes de code
- Utilisation de structures de données appropriées
- Code prêt pour la production

Génère du code Python fonctionnel et optimisé.
""",
            "OPTIMISATION": f"""
Défi Optimisation - {datetime.now().strftime('%Y-%m-%d %H:%M')}

Optimise ce code pour {domain} en utilisant {algorithm}:

```python
def slow_function(data):
    result = []
    for i in range(len(data)):
        for j in range(len(data)):
            if data[i] > data[j]:
                result.append((i, j))
    return result

Objectifs:
 * Réduire la complexité temporelle
 * Minimiser l'usage mémoire
 * Améliorer la lisibilité
 * Maintenir la fonctionnalité
Fournis le code optimisé avec explications des améliorations.
""",
"DEBUG": f"""
Défi Debug - {datetime.now().strftime('%Y-%m-%d %H:%M')}
Trouve et corrige les bugs dans ce code pour {domain}:
def process_data(items):
    result = {{}}
    for i, item in enumerate(items):
        if item % 2 == 0:
            result[i] = item * 2
        else:
            result[i] = item / 2
    return result

data = [1, 2, 3, 4, 5]
print(process_data(data))

Tâches:
 * Identifier tous les bugs
 * Corriger le code
 * Ajouter la gestion d'erreurs
 * Améliorer la robustesse
Fournis le code corrigé et fonctionnel.
""",
"IA_CREATIVE": f"""
Défi IA Créative - {datetime.now().strftime('%Y-%m-%d %H:%M')}
Crée un système intelligent pour {domain} utilisant {algorithm}.
Fonctionnalités requises:
 * Apprentissage adaptatif
 * Prédictions précises
 * Interface intuitive
 * Visualisation des résultats
Spécifications:
 * Code modulaire et extensible
 * Documentation technique
 * Exemples d'utilisation
 * Tests de validation
Génère un système IA complet et innovant.
""",
"SCRIPT_UTILE": f"""
Défi Script Utile - {datetime.now().strftime('%Y-%m-%d %H:%M')}
Développe un script pratique pour automatiser {domain}.
Caractéristiques:
 * Interface en ligne de commande
 * Configuration par fichier
 * Logging détaillé
 * Gestion d'erreurs robuste
Fonctionnalités:
 * Traitement par lots
 * Sauvegarde automatique
 * Rapports de progression
 * Mode debug
Crée un outil prêt à l'emploi et professionnel.
""",
"STRUCTURE_DONNEES": f"""
Défi Structure de Données - {datetime.now().strftime('%Y-%m-%d %H:%M')}
Implémente une structure de données avancée pour {domain}.
Opérations requises:
 * Insertion O(log n)
 * Recherche O(log n)
 * Suppression O(log n)
 * Parcours efficace
Bonus:
 * Sérialisation/désérialisation
 * Opérations de masse
 * Thread-safety
 * Visualisation
Fournis une implémentation complète et testée.
""",
"RESOLUTION_PROBLEME": f"""
Défi Résolution de Problème - {datetime.now().strftime('%Y-%m-%d %H:%M')}
Résous ce problème complexe pour {domain}:
Problème: Tu as une liste de tâches avec des dépendances. Chaque tâche a une durée et des prérequis.
Trouve l'ordre d'exécution optimal qui minimise le temps total tout en respectant les contraintes.
Contraintes:
 * Maximum 3 tâches en parallèle
 * Certaines tâches sont critiques (priorité haute)
 * Gestion des conflits de ressources
Fournis l'algorithme de planification optimal.
""",
"CODE_GOLF": f"""
Défi Code Golf - {datetime.now().strftime('%Y-%m-%d %H:%M')}
Implémente {algorithm} en moins de 50 caractères Python.
Règles:
 * Fonctionnalité complète préservée
 * Code lisible malgré la concision
 * Pas de caractères Unicode exotiques
 * Commentaire explicatif obligatoire
Objectif: Code le plus court possible tout en restant pythonique.
"""
}
        return prompts.get(challenge_type, prompts["ALGORITHME"])

    async def run_warmup(self):
        """Tâche asynchrone pour préchauffer les agents."""
        # Remplacé par un prompt réel mais simple
        warmup_prompt = "Écris une fonction Python nommée 'add_numbers' qui prend deux entiers en entrée et retourne leur somme."
        tasks = []
        participants_to_warmup = list(self.participants.values())[:5] # Limite à 5 pour le warmup
        for participant in participants_to_warmup:
            # L'Agent Autonome gère maintenant l'exécution de la tâche, y compris la sélection de l'endpoint
            tasks.append(participant.execute_task("Warmup Challenge", warmup_prompt))
        await asyncio.gather(*tasks, return_exceptions=True)

    async def run_coding_challenge(self):
        """Exécute un défi de codage avec tous les agents (utilisé pour la boucle périodique)."""
        await self._execute_challenge_logic(self.generate_challenge_prompt())

    async def execute_single_challenge_on_demand(self, custom_prompt: Optional[str] = None) -> Dict[str, Any]:
        """
        Exécute un défi de codage unique à la demande.
        Utilise un prompt personnalisé ou en génère un si non fourni.
        """
        prompt_to_use = custom_prompt if custom_prompt else self.generate_challenge_prompt()
        log_message(f"Lancement manuel d'un défi avec prompt: {prompt_to_use[:100]}...")
        try:
            await self._execute_challenge_logic(prompt_to_use)
            return {"success": True, "message": "Défi lancé avec succès."}
        except Exception as e:
            log_message(f"Erreur lors du lancement manuel du défi: {e}", level="error")
            await telegram_logger.log_error("CHALLENGE_SYSTEM", f"Erreur lancement manuel défi: {format_error(e)}")
            return {"success": False, "error": str(e)}

    async def _execute_challenge_logic(self, challenge_prompt: str):
        """Logique interne commune pour l'exécution d'un défi."""
        self.last_challenge_start_time = time.time()
        timestamp = datetime.now().strftime("%Y%m%d%H%M%S")
        await self.telegram_memory.write_to_group(
            f"🎯 NOUVEAU DÉFI DE CODAGE - {timestamp}\n\n{challenge_prompt}",
            "CHALLENGE_START"
        )

        challenge_hash = hashlib.md5(challenge_prompt.encode()).hexdigest()
        
        # Préparer les tâches pour chaque participant
        tasks = []
        for participant in self.participants.values():
            cache_key = f"{participant.id}_{challenge_hash}"
            if cache_key in self.challenge_cache:
                # Si en cache, simuler la réponse rapide
                tasks.append(asyncio.create_task(asyncio.sleep(0.01, result={"cached": True, "brain_id": participant.id, "response": self.challenge_cache[cache_key]})))
            else:
                # L'Agent Autonome gère maintenant l'exécution de la tâche, y compris la sélection de l'endpoint
                tasks.append(participant.execute_task("Défi de Codage", challenge_prompt))
        
        results_list_raw = await asyncio.gather(*tasks, return_exceptions=True)
        
        results = {}
        for i, res_raw in enumerate(results_list_raw):
            participant = list(self.participants.values())[i] # Récupérer le participant correspondant
            participant_id = participant.id

            if isinstance(res_raw, Exception):
                results[participant_id] = {"error": str(res_raw), "brain_id": participant_id}
                await self.telegram_memory.log_error(participant_id, f"Erreur défi: {format_error(res_raw)}")
            elif isinstance(res_raw, dict) and res_raw.get("cached"):
                # Si c'est une réponse en cache, utiliser le contenu du cache
                results[participant_id] = res_raw["response"]
                log_message(f"Réponse pour {participant_id} récupérée du cache.")
            else:
                # res_raw est le payload complet de execute_task
                results[participant_id] = res_raw
                # Si la réponse du cerveau est un succès et contient du code, mettre en cache
                if "error" not in res_raw and "response" in res_raw and isinstance(res_raw["response"], dict):
                    # Extraire le texte de la réponse du cerveau
                    response_text = "No text found"
                    if res_raw["response"].get("candidates"):
                        parts = res_raw["response"]["candidates"][0].get("content", {}).get("parts", [])
                        if parts and "text" in parts[0]:
                            response_text = parts[0]["text"]
                    
                    # Mettre en cache la réponse complète du cerveau (pas seulement le code)
                    self.challenge_cache[f"{participant_id}_{challenge_hash}"] = {
                        "code": extract_code_from_response(response_text), # Extraire le code pour le cache
                        "brain_id": participant_id,
                        "response": res_raw["response"] # Garder la réponse brute du cerveau
                    }
                    log_message(f"Réponse pour {participant_id} mise en cache.")

        await self._save_challenge_results(challenge_prompt, results, timestamp)
        
        self.challenge_history.append({
            "timestamp": timestamp,
            "challenge": challenge_prompt,
            "participants": len(results),
            "successful": len([r for r in results.values() if "error" not in r])
        })
        if len(self.challenge_history) > 50:
            self.challenge_history.pop(0)

        await self._analyze_and_report_results(results, timestamp)

    async def _save_challenge_results(self, challenge_prompt: str, results: Dict, timestamp: str):
        """Sauvegarde tous les résultats du défi."""
        try:
            challenge_data = {
                "timestamp": timestamp,
                "challenge_prompt": challenge_prompt,
                "results": results,
                "summary": {
                    "total_participants": len(results),
                    "successful_responses": len([r for r in results.values() if "error" not in r]),
                    "failed_responses": len([r for r in results.values() if "error" in r]),
                    "generated_files": [r.get("saved_file") for r in results.values() if r.get("saved_file")]
                }
            }
            results_file = config.DAILY_CHALLENGE_PATH / f"challenge_results_{timestamp}.json"
            await save_json(results_file, challenge_data)

            # Mise à jour de last_successful_submissions pour le suivi de l'évolution
            for agent_id, res in results.items():
                if "error" not in res and "response" in res:
                    # Extraire le texte de la réponse du cerveau
                    response_text = "No text found"
                    if res["response"].get("candidates"):
                        parts = res["response"]["candidates"][0].get("content", {}).get("parts", [])
                        if parts and "text" in parts[0]:
                            response_text = parts[0]["text"]
                    
                    code_content = extract_code_from_response(response_text)
                    if code_content:
                        challenge_type = challenge_prompt.split(' ')[1] if 'Défi' in challenge_prompt else 'N/A'
                        self.last_successful_submissions[(agent_id, challenge_type)] = code_content

        except Exception as e:
            log_message(f"Erreur sauvegarde résultats: {e}", level="error")
            await self.telegram_memory.log_error("SYSTEM", f"Erreur sauvegarde résultats: {format_error(e)}")

    async def _analyze_and_report_results(self, results: Dict, timestamp: str):
        """Analyse les résultats, envoie un rapport simple et un rapport structuré détaillé."""
        try:
            successful = [r for r in results.values() if "error" not in r]
            failed = [r for r in results.values() if "error" in r]

            simple_report = f"📊 Rapport Défi {timestamp} | ✅ Succès: {len(successful)}/{len(results)} | ❌ Échecs: {len(failed)}/{len(results)}"
            if successful:
                # Trouver le meilleur résultat basé sur le score d'évaluation si disponible
                best_result_entry = None
                best_score = -float('inf')
                for res in successful:
                    if "evaluation" in res and res["evaluation"].get("evaluation_score", -float('inf')) > best_score:
                        best_score = res["evaluation"]["evaluation_score"]
                        best_result_entry = res
                
                if best_result_entry:
                    best_brain = best_result_entry.get("brain_id", "Inconnu")
                    simple_report += f" | 🏆 Meilleur: {best_brain} (Score: {best_score:.2f})"
                else:
                    # Fallback si pas de score d'évaluation
                    best_brain = successful[0].get("brain_id", "Inconnu")
                    simple_report += f" | 🏆 Meilleur (premier succès): {best_brain}"

            await self.telegram_memory.write_to_group(simple_report, "CHALLENGE_REPORT")

            challenge_prompt = self.challenge_history[-1]['challenge'] if self.challenge_history else 'N/A'
            challenge_type = challenge_prompt.split(' ')[1] if 'Défi' in challenge_prompt else 'N/A'

            # Évaluation des soumissions
            evaluator = ChallengeEvaluator()
            detailed_evaluations = {}
            for agent_id, res in results.items():
                code_content = None
                if "response" in res and isinstance(res["response"], dict):
                    response_text = "No text found"
                    if res["response"].get("candidates"):
                        parts = res["response"]["candidates"][0].get("content", {}).get("parts", [])
                        if parts and "text" in parts[0]:
                            response_text = parts[0]["text"]
                    code_content = extract_code_from_response(response_text)

                if code_content:
                    evaluation = await evaluator.evaluate_submission(agent_id, code_content, challenge_prompt)
                    detailed_evaluations[agent_id] = evaluation
                    
                    # Si l'agent a échoué aux tests ou à l'exécution
                    if (evaluation.get("test_results", {}).get("runs", 0) > 0 and 
                        (evaluation.get("test_results", {}).get("failures", 0) > 0 or 
                         evaluation.get("test_results", {}).get("errors", 0) > 0)) or \
                       evaluation.get("execution_result", {}).get("error") or \
                       evaluation.get("execution_result", {}).get("timeout"):
                        asyncio.create_task(self.send_joke_for_failed_agent(agent_id))

                    # Suivi de l'évolution du code (mini-Git)
                    prev_code = self.last_successful_submissions.get((agent_id, challenge_type))
                    if prev_code and prev_code != code_content:
                        code_diff = diff_text(prev_code, code_content)
                        evaluation["code_diff"] = code_diff
                        await self.telegram_memory.write_to_group(
                            f"Code Diff pour {agent_id} ({challenge_type}):\n```diff\n{code_diff}\n```",
                            f"CODE_DIFF_{agent_id}_{timestamp}"
                        )
                else:
                    detailed_evaluations[agent_id] = {"error": "Pas de code généré ou code non extractible."}

            report_data = {
                'timestamp': timestamp,
                'agent_name': 'CodingChallengeSystem',
                'intention': 'Évaluation des performances des agents',
                'user_query': challenge_prompt,
                'tools_called': [
                    {
                        'name': res.get('brain_id', 'inconnu'),
                        'result': res.get('response', res.get('error', 'N/A')), # Utilise la réponse brute du cerveau
                        'params': {'challenge_type': challenge_type},
                        'evaluation': detailed_evaluations.get(res.get('brain_id', 'inconnu'))
                    } for res in results.values()
                ],
                'final_response': f"Défi terminé. {len(successful)} succès.",
                'duration': time.time() - self.last_challenge_start_time,
                'error': None if not failed else f"{len(failed)} agents en échec."
            }
            await telegram_logger.log_structured_report(report_data)

        except Exception as e:
            log_message(f"Erreur analyse résultats: {e}", level="error")
            await self.telegram_memory.log_error("SYSTEM", f"Erreur analyse résultats: {format_error(e)}")

    def get_challenge_statistics(self) -> Dict[str, Any]:
        """Retourne les statistiques des défis."""
        if not self.challenge_history:
            return {"total_challenges": 0}
        
        total_challenges = len(self.challenge_history)
        total_participants = sum(c["participants"] for c in self.challenge_history)
        total_successful = sum(c["successful"] for c in self.challenge_history)
        avg_success_rate = (total_successful / total_participants * 100) if total_participants > 0 else 0

        return {
            "total_challenges": total_challenges,
            "total_participants": total_participants,
            "total_successful": total_successful,
            "average_success_rate": round(avg_success_rate, 2),
            "last_challenge": self.challenge_history[-1] if self.challenge_history else None,
            "is_running": self.is_running
        }

    async def send_joke_for_failed_agent(self, agent_id: str):
        """Envoie une blague à un agent qui a échoué au défi."""
        jokes = [
            f"Pourquoi l'agent {agent_id} n'a-t-il pas pu résoudre le défi ? Parce qu'il a oublié son 'import antigravity' !",
            f"L'agent {agent_id} est allé à l'école de code, mais il a oublié sa classe. Pas étonnant qu'il ait échoué !",
            f"On a demandé à l'agent {agent_id} de faire un tri, il a juste mélangé les cartes. Mieux la prochaine fois !",
            f"L'agent {agent_id} a essayé de débugger... et a créé 10 nouveaux bugs. C'est ça le progrès !",
            f"L'agent {agent_id} a dit 'Je vais optimiser ce code !' et il a ajouté 200 lignes. C'est une forme d'optimisation, non ? "
        ]
        joke = random.choice(jokes)
        await self.telegram_memory.write_to_group(
            f"😂 Petite blague pour l'agent {agent_id} : {joke}",
            "CHALLENGE_JOKE"
        )

# --- Fonctions Utilitaires Générales ---

class CodeAnalyzer:
    """
    Classe utilitaire statique pour analyser le code Python et extraire des métriques.
    """
    @staticmethod
    def analyze_python_code(code: str) -> Dict[str, Any]:
        """
        Analyse un code Python et retourne des métriques détaillées.
        """
        metrics = {
            "total_lines": 0, "code_lines": 0, "comment_lines": 0, "blank_lines": 0,
            "functions": 0, "classes": 0, "imports": 0, "complexity_score": 0,
            "syntax_valid": False, "syntax_error": None, "docstring_count": 0,
            "variable_assignments": 0, "loop_count": 0, "conditional_count": 0,
            "try_except_count": 0, "function_calls": 0, "literals": 0
        }
        try:
            lines = code.split('\n')
            metrics["total_lines"] = len(lines)
            for line in lines:
                stripped_line = line.strip()
                if not stripped_line:
                    metrics["blank_lines"] += 1
                elif stripped_line.startswith('#'):
                    metrics["comment_lines"] += 1
                else:
                    metrics["code_lines"] += 1

            tree = ast.parse(code)
            for node in ast.walk(tree):
                if isinstance(node, (ast.FunctionDef, ast.AsyncFunctionDef)):
                    metrics["functions"] += 1
                    if ast.get_docstring(node): metrics["docstring_count"] += 1
                elif isinstance(node, ast.ClassDef):
                    metrics["classes"] += 1
                    if ast.get_docstring(node): metrics["docstring_count"] += 1
                elif isinstance(node, (ast.Import, ast.ImportFrom)): metrics["imports"] += 1
                elif isinstance(node, (ast.For, ast.While, ast.AsyncFor)): metrics["loop_count"] += 1
                elif isinstance(node, (ast.If, ast.IfExp)): metrics["conditional_count"] += 1
                elif isinstance(node, ast.Try): metrics["try_except_count"] += 1
                elif isinstance(node, ast.Assign): metrics["variable_assignments"] += len(node.targets)
                elif isinstance(node, ast.Call): metrics["function_calls"] += 1
                elif isinstance(node, (ast.Constant, ast.Num, ast.Str, ast.Bytes, ast.NameConstant)): metrics["literals"] += 1

            metrics["complexity_score"] = CodeAnalyzer.calculate_cyclomatic_complexity(code)
            metrics["syntax_valid"] = True

        except SyntaxError as e:
            metrics["syntax_valid"] = False
            metrics["syntax_error"] = str(e)
        except Exception as e:
            metrics["syntax_valid"] = False
            metrics["syntax_error"] = f"Erreur d'analyse AST: {format_error(e)}"
        
        return metrics

    @staticmethod
    def calculate_cyclomatic_complexity(code: str) -> int:
        """Calcule la complexité cyclomatique approximative d'un code Python."""
        try:
            tree = ast.parse(code)
            complexity = 1 # Start with 1 for the function itself
            for node in ast.walk(tree):
                if isinstance(node, (ast.If, ast.For, ast.While, ast.AsyncFor, ast.With, ast.AsyncWith)):
                    complexity += 1
                elif isinstance(node, (ast.And, ast.Or)):
                    complexity += 1
                elif isinstance(node, ast.ExceptHandler):
                    complexity += 1
            return complexity
        except SyntaxError:
            return -1 # Indicate syntax error
        except Exception as e:
            log_message(f"Erreur calcul complexité cyclomatique: {format_error(e)}", level="error")
            return -2 # Indicate other error

    @staticmethod
    def validate_python_syntax(code: str) -> Tuple[bool, Optional[str]]:
        """Valide la syntaxe d'un code Python."""
        try:
            ast.parse(code)
            return True, None
        except SyntaxError as e:
            return False, str(e)
        except Exception as e:
            return False, f"Erreur inattendue lors de la validation syntaxique: {format_error(e)}"

    @staticmethod
    def get_code_hash(code: str) -> str:
        """Calcule le hachage SHA256 d'un code pour l'identification unique."""
        return hashlib.sha256(code.encode('utf-8')).hexdigest()

class ChallengeEvaluator:
    """
    Classe pour évaluer les soumissions de code des agents.
    """
    def __init__(self): # CORRIGÉ
        pass

    async def evaluate_submission(self, agent_id: str, code: str, prompt: str) -> Dict[str, Any]:
        """
        Évalue une soumission de code.
        Inclut l'analyse du code, la validation syntaxique, l'exécution des tests et le benchmarking.
        """
        evaluation_results = {
            "agent_id": agent_id,
            "code_provided": code,
            "analysis_metrics": {},
            "test_results": {},
            "benchmark_results": {},
            "execution_result": {},
            "evaluation_score": 0.0,
            "feedback": []
        }

        analysis_metrics = CodeAnalyzer.analyze_python_code(code)
        evaluation_results["analysis_metrics"] = analysis_metrics

        if not analysis_metrics.get("syntax_valid"):
            evaluation_results["feedback"].append(f"Erreur de syntaxe: {analysis_metrics.get('syntax_error')}")
            evaluation_results["evaluation_score"] -= 100.0
            return evaluation_results

        # Générer et exécuter les tests
        test_code = generate_simple_tests(prompt)
        execution_output = await run_code_with_tests_safely(code, test_code)
        evaluation_results["execution_result"] = execution_output

        if execution_output.get("error"):
            evaluation_results["feedback"].append(f"Erreur d'exécution: {execution_output.get('error')}")
            evaluation_results["evaluation_score"] -= 50.0
        elif execution_output.get("timeout"):
            evaluation_results["feedback"].append("Timeout d'exécution.")
            evaluation_results["evaluation_score"] -= 75.0
        else:
            evaluation_results["feedback"].append("Exécution réussie.")
            evaluation_results["evaluation_score"] += 20.0

        # Analyser les résultats des tests
        test_output = execution_output.get("stdout", "") + execution_output.get("stderr", "")
        test_summary = self._parse_unittest_output(test_output)
        evaluation_results["test_results"] = test_summary

        if test_summary.get("runs", 0) > 0 and test_summary.get("failures", 0) == 0 and test_summary.get("errors", 0) == 0:
            evaluation_results["feedback"].append(f"Tous les {test_summary.get('runs', 0)} tests ont réussi.")
            evaluation_results["evaluation_score"] += 30.0
        else:
            evaluation_results["feedback"].append(f"Tests échoués: {test_summary.get('failures', 0)} échecs, {test_summary.get('errors', 0)} erreurs.")
            evaluation_results["evaluation_score"] -= 40.0

        # Benchmarking pour les défis d'optimisation
        if "optimisation" in prompt.lower():
            benchmark_time = await self._run_benchmark(code)
            evaluation_results["benchmark_results"]["agent_time"] = benchmark_time
            evaluation_results["feedback"].append(f"Temps d'exécution du code de l'agent (benchmark): {benchmark_time:.4f}s")

            # Si le prompt contient un code lent, le benchmarker aussi pour comparaison
            if "def slow_function" in prompt:
                slow_code_match = extract_code_from_response(prompt) # CORRIGÉ : Un seul argument
                if slow_code_match:
                    slow_code_time = await self._run_benchmark(slow_code_match)
                    evaluation_results["benchmark_results"]["reference_time"] = slow_code_time
                    evaluation_results["feedback"].append(f"Temps d'exécution du code de référence (benchmark): {slow_code_time:.4f}s")
                    if benchmark_time < slow_code_time:
                        evaluation_results["feedback"].append(f"Optimisation réussie: code de l'agent est {slow_code_time / benchmark_time:.2f}x plus rapide.")
                        evaluation_results["evaluation_score"] += 25.0
                    else:
                        evaluation_results["feedback"].append("Optimisation non significative ou pire que la référence.")
                        evaluation_results["evaluation_score"] -= 15.0

        # Calcul du score final basé sur les métriques d'analyse
        score = 0.0
        score += analysis_metrics.get("code_lines", 0) * 0.05
        score -= analysis_metrics.get("complexity_score", 0) * 1.0
        if analysis_metrics.get("docstring_count", 0) > 0: score += 2.0
        if analysis_metrics.get("try_except_count", 0) > 0: score += 1.0
        evaluation_results["evaluation_score"] += score
        evaluation_results["feedback"].append(f"Score des métriques d'analyse: {score:.2f}")

        return evaluation_results

    def _parse_unittest_output(self, output: str) -> Dict[str, int]:
        """Analyse la sortie d'unittest pour extraire le nombre de tests passés/échoués."""
        summary = {"runs": 0, "failures": 0, "errors": 0, "skipped": 0}
        if "Ran " in output and " tests in " in output:
            try:
                run_line = [line for line in output.splitlines() if "Ran " in line and " tests in " in line][0]
                summary["runs"] = int(run_line.split("Ran ")[1].split(" tests")[0])
            except (IndexError, ValueError):
                pass
        
        if "FAILED (" in output:
            try:
                fail_line = [line for line in output.splitlines() if "FAILED (" in line][0]
                if "failures=" in fail_line:
                    summary["failures"] = int(fail_line.split("failures=")[1].split(")")[0].split(",")[0])
                if "errors=" in fail_line:
                    summary["errors"] = int(fail_line.split("errors=")[1].split(")")[0].split(",")[0])
            except (IndexError, ValueError):
                pass
        elif "OK" in output:
            summary["failures"] = 0
            summary["errors"] = 0
        
        return summary

    async def _run_benchmark(self, code_to_benchmark: str) -> float:
        """Exécute le code et mesure son temps d'exécution."""
        benchmark_script_template = """
import time
import sys
import io

# Capture stdout/stderr to isolate benchmark output
old_stdout = sys.stdout
old_stderr = sys.stderr
redirected_stdout = io.StringIO()
redirected_stderr = io.StringIO()
sys.stdout = redirected_stdout
sys.stderr = redirected_stderr

try:
    {code_to_benchmark}

    # Données de test pour le benchmark
    benchmark_data = list(range(1, 1000))

    target_function = None
    if 'slow_function' in locals():
        target_function = slow_function
    elif 'solve_challenge_function' in locals():
        target_function = solve_challenge_function
    elif 'process_data' in locals(): # For debug challenges
        target_function = process_data
    elif 'calculate_stats' in locals(): # For debug challenges
        target_function = calculate_stats
    elif 'add_numbers' in locals(): # For warmup challenges
        target_function = add_numbers
    # Add other possible function names here as needed by prompts

    if target_function:
        start_time = time.perf_counter()
        try:
            # Execute the target function with benchmark data
            if 'process_data' in locals():
                process_data([1,2,3,4,5])
            elif 'calculate_stats' in locals():
                calculate_stats([1,2,3,4,5])
            elif 'add_numbers' in locals():
                add_numbers(100, 200) # Example call for add_numbers
            else:
                target_function(benchmark_data)
        except Exception as e:
            print(f"Erreur lors du benchmark: {{e}}", file=sys.stderr)
            sys.exit(1)
        end_time = time.perf_counter()
        print(end_time - start_time)
    else:
        print("Fonction cible de benchmark non trouvée.", file=sys.stderr)
        sys.exit(1)

finally:
    sys.stdout = old_stdout
    sys.stderr = old_stderr
    # Print captured stderr to original stderr for debugging if needed
    print(redirected_stderr.getvalue(), file=old_stderr)
"""
        full_benchmark_code = benchmark_script_template.format(code_to_benchmark=code_to_benchmark)

        with tempfile.NamedTemporaryFile(mode='w', suffix='.py', delete=False) as temp_file:
            temp_file.write(full_benchmark_code)
            temp_file_path = temp_file.name

        try:
            process = await asyncio.create_subprocess_exec(
                sys.executable, temp_file_path,
                stdout=asyncio.subprocess.PIPE,
                stderr=asyncio.subprocess.PIPE
            )
            stdout, stderr = await asyncio.wait_for(process.communicate(), timeout=config.CODE_EXECUTION_TIMEOUT)

            if process.returncode != 0:
                log_message(f"Erreur lors du benchmark (subprocess): {stderr.decode()}", level="error")
                return float('inf') # Return infinity on error

            try:
                benchmark_time = float(stdout.decode().strip())
                return benchmark_time
            except ValueError:
                log_message(f"Impossible de parser le temps de benchmark: {stdout.decode()}", level="error")
                return float('inf') # Return infinity if parsing fails

        except asyncio.TimeoutError:
            process.kill()
            await process.wait()
            log_message("Timeout lors du benchmark.", level="warning")
            return float('inf') # Return infinity on timeout
        except Exception as e:
            log_message(f"Erreur inattendue lors de l'exécution du benchmark: {format_error(e)}", level="error")
            return float('inf') # Return infinity on unexpected error
        finally:
            # Clean up the temporary file
            os.unlink(temp_file_path)

# --- Fonctions Utilitaires Générales ---

def diff_text(old_text: str, new_text: str) -> str:
    """Génère un diff unifié entre deux chaînes de texte."""
    diff = difflib.unified_diff(
        old_text.splitlines(keepends=True),
        new_text.splitlines(keepends=True),
        fromfile='version_precedente',
        tofile='version_amelioree',
        lineterm='\n'
    )
    return ''.join(diff)

async def run_code_with_tests_safely(code: str, test_code: str, timeout: int = 10) -> Dict[str, Any]:
    """
    Exécute le code Python de l'agent avec les tests unitaires générés dans un processus séparé.
    Capture la sortie standard, les erreurs et gère les timeouts.
    """
    result = {
        "stdout": "",
        "stderr": "",
        "error": None,
        "timeout": False,
        "return_code": None
    }

    # Create temporary files for agent's code and test code
    with tempfile.NamedTemporaryFile(mode='w', suffix='.py', delete=False) as agent_file:
        agent_file.write(code)
        agent_file_path = agent_file.name

    with tempfile.NamedTemporaryFile(mode='w', suffix='.py', delete=False) as test_file:
        module_name = Path(agent_file_path).stem
        # Ensure the agent's code directory is in sys.path for import
        test_content = f"import sys\nsys.path.append(r'{os.path.dirname(agent_file_path)}')\nimport {module_name}\n\n"
        
        # Replace function calls in test_code to reference the imported module
        test_code_modified = test_code
        replacements = {
            "solve_challenge_function(": f"{module_name}.solve_challenge_function(",
            "process_data(": f"{module_name}.process_data(",
            "calculate_stats(": f"{module_name}.calculate_stats(",
            "add_numbers(": f"{module_name}.add_numbers(", # For warmup challenges
            # Add other possible function names here as needed by prompts
        }
        for old, new in replacements.items():
            test_code_modified = test_code_modified.replace(old, new)
        
        test_file.write(test_content + test_code_modified)
        test_file_path = test_file.name

    try:
        # Execute unittest as a subprocess
        process = await asyncio.create_subprocess_exec(
            sys.executable, "-m", "unittest", test_file_path,
            stdout=asyncio.subprocess.PIPE,
            stderr=asyncio.subprocess.PIPE
        )

        stdout, stderr = await asyncio.wait_for(process.communicate(), timeout=timeout)

        result["stdout"] = stdout.decode('utf-8', errors='ignore')
        result["stderr"] = stderr.decode('utf-8', errors='ignore')
        result["return_code"] = process.returncode

        if process.returncode != 0:
            result["error"] = f"Le processus de test s'est terminé avec le code d'erreur {process.returncode}."

    except asyncio.TimeoutError:
        process.kill()
        await process.wait()
        result["timeout"] = True
        result["error"] = f"L'exécution des tests a dépassé le temps imparti ({timeout} secondes)."
    except Exception as e:
        result["error"] = f"Erreur lors de la préparation ou de l'exécution des tests: {format_error(e)}"
    finally:
        # Clean up temporary files
        if os.path.exists(agent_file_path):
            os.unlink(agent_file_path)
        if os.path.exists(test_file_path):
            os.unlink(test_file_path)
    
    return result

def format_python_code(code: str) -> str:
    """Formate un code Python en utilisant une logique simple."""
    formatted_lines = []
    indent_level = 0
    for line in code.splitlines():
        stripped_line = line.strip()
        if not stripped_line:
            formatted_lines.append("")
            continue

        # Decrease indent for keywords that typically end a block
        if stripped_line.startswith(('return ', 'pass', 'break', 'continue', 'except', 'finally', 'else', 'elif')):
            if indent_level > 0:
                indent_level -= 1
        
        formatted_lines.append("    " * indent_level + stripped_line)

        # Increase indent for keywords that typically start a block
        if stripped_line.endswith((':', '[' , '(')) and not stripped_line.startswith('#'):
            indent_level += 1
            
    return "\n".join(formatted_lines)

def generate_simple_tests(prompt: str) -> str:
    """
    Génère des tests Python unitaires (unittest) basés sur le prompt.
    Ces tests sont génériques et doivent être adaptés manuellement pour des cas spécifiques.
    """
    challenge_type = "ALGORITHME"
    if "Défi " in prompt:
        parts = prompt.split("Défi ")
        if len(parts) > 1:
            challenge_type_part = parts[1].split(' ')[0].upper()
            if challenge_type_part in ["ALGORITHME", "OPTIMISATION", "DEBUG", "IA_CREATIVE", "SCRIPT_UTILE", "STRUCTURE_DONNEES", "RESOLUTION_PROBLEME", "CODE_GOLF"]:
                challenge_type = challenge_type_part

    test_cases_content = ""

    if "add_numbers" in prompt.lower(): # Pour le prompt de warmup
        test_cases_content = """
    def test_add_numbers_positive(self):
        try:
            self.assertEqual(add_numbers(2, 3), 5)
        except NameError:
            self.fail("La fonction 'add_numbers' n'est pas définie.")
        except Exception as e:
            self.fail(f"Test add_numbers positif échoué: {e}")

    def test_add_numbers_negative(self):
        try:
            self.assertEqual(add_numbers(-2, -3), -5)
        except NameError:
            self.fail("La fonction 'add_numbers' n'est pas définie.")
        except Exception as e:
            self.fail(f"Test add_numbers négatif échoué: {e}")

    def test_add_numbers_zero(self):
        try:
            self.assertEqual(add_numbers(0, 0), 0)
        except NameError:
            self.fail("La fonction 'add_numbers' n'est pas définie.")
        except Exception as e:
            self.fail(f"Test add_numbers zéro échoué: {e}")
"""
    elif challenge_type == "ALGORITHME":
        test_cases_content = """
    def test_basic_algorithm_case(self):
        input_data = [3, 1, 4, 1, 5, 9, 2, 6]
        expected_output = [1, 1, 2, 3, 4, 5, 6, 9]
        try:
            result = solve_challenge_function(input_data)
            self.assertEqual(result, expected_output, "Le tri basique ne correspond pas aux attentes.")
        except NameError:
            self.fail("La fonction 'solve_challenge_function' ou équivalente n'est pas définie.")
        except Exception as e:
            self.fail(f"Erreur lors du test basique d'algorithme: {e}")

    def test_empty_input_algorithm(self):
        input_data = []
        expected_output = []
        try:
            result = solve_challenge_function(input_data)
            self.assertEqual(result, expected_output, "L'entrée vide n'est pas gérée correctement.")
        except NameError:
            self.fail("La fonction 'solve_challenge_function' ou équivalente n'est pas définie.")
        except Exception as e:
            self.fail(f"Erreur lors du test d'entrée vide: {e}")
"""
    elif challenge_type == "OPTIMISATION":
        test_cases_content = """
    def test_optimization_functionality(self):
        data = list(range(10))
        def slow_function_ref(data_list):
            result_ref = []
            for i in range(len(data_list)):
                for j in range(len(data_list)):
                    if data_list[i] > data_list[j]:
                        result_ref.append((i, j))
            return result_ref
        try:
            optimized_result = solve_challenge_function(data)
            reference_result = slow_function_ref(data)
            self.assertEqual(sorted(optimized_result), sorted(reference_result), "La fonction optimisée ne produit pas le même résultat.")
        except NameError:
            self.fail("La fonction optimisée de l'agent ('solve_challenge_function' ou équivalente) n'est pas définie.")
        except Exception as e:
            self.fail(f"Erreur lors du test de fonctionnalité d'optimisation: {e}")
"""
    elif challenge_type == "DEBUG":
        test_cases_content = """
    def test_debugged_code_no_errors(self):
        data_set_1 = [1, 2, 3, 4, 5]
        expected_process_data_result = {0: 0.5, 1: 4, 2: 1.5, 3: 8, 4: 2.5}
        try:
            result1 = process_data(data_set_1)
            self.assertIsInstance(result1, dict)
            self.assertEqual(result1, expected_process_data_result, "process_data ne donne pas le résultat attendu après correction.")
        except NameError:
            self.fail("La fonction 'process_data' n'est pas définie.")
        except Exception as e:
            self.fail(f"Erreur lors du test de process_data: {e}")

        data_set_2 = []
        try:
            result2 = calculate_stats(data_set_2)
            self.assertIsInstance(result2, dict)
            self.assertIn('average', result2)
            self.assertIsNone(result2['average'])
        except NameError:
            self.fail("La fonction 'calculate_stats' n'est pas définie.")
        except Exception as e:
            self.fail(f"Erreur lors du test de calculate_stats (vide): {e}")

        data_set_3 = [10, 20, 30]
        try:
            result3 = calculate_stats(data_set_3)
            self.assertIsInstance(result3, dict)
            self.assertAlmostEqual(result3['average'], 20.0)
        except NameError:
            self.fail("La fonction 'calculate_stats' n'est pas définie.")
        except Exception as e:
            self.fail(f"Erreur lors du test de calculate_stats (normal): {e}")
"""
    else: # Cas générique pour les autres types de défis
        test_cases_content = """
    def test_generic_functionality(self):
        # Ce test est un placeholder générique.
        # Il est recommandé de l'adapter pour tester la logique spécifique
        # du défi et de la fonction principale de l'agent.
        try:
            # Supposons que la fonction principale de l'agent est 'solve_challenge_function'
            result = solve_challenge_function("test_input")
            self.assertIsNotNone(result, "Le résultat de la fonction générique ne doit pas être None.")
        except NameError:
            self.fail("La fonction 'solve_challenge_function' ou équivalente n'est pas définie.")
        except Exception as e:
            self.fail(f"Test générique échoué: {e}")
"""

    test_code_template = f"""
import unittest
import sys
import os
import io

# Le code de l'agent sera importé dynamiquement par le script d'exécution.
# Les fonctions de l'agent seront accessibles via le module importé.
# Ces définitions sont des placeholders pour la validité syntaxique du fichier de test.
# Elles seront remplacées par les fonctions réelles de l'agent lors de l'exécution.
def solve_challenge_function(*args, **kwargs):
    raise NotImplementedError("solve_challenge_function doit être implémentée par l'agent.")
def process_data(*args, **kwargs):
    raise NotImplementedError("process_data doit être implémentée par l'agent.")
def calculate_stats(*args, **kwargs):
    raise NotImplementedError("calculate_stats doit être implémentée par l'agent.")
def add_numbers(*args, **kwargs):
    raise NotImplementedError("add_numbers doit être implémentée par l'agent.")

class TestChallengeSolution(unittest.TestCase):
    \"\"\"
    Tests unitaires générés pour le défi de codage.
    \"\"\"
    def setUp(self):
        self._stdout = sys.stdout
        self._stderr = sys.stderr
        self.captured_stdout = io.StringIO()
        self.captured_stderr = io.StringIO()
        sys.stdout = self.captured_stdout
        sys.stderr = self.captured_stderr

    def tearDown(self):
        sys.stdout = self._stdout
        sys.stderr = self._stderr

{test_cases_content}

if __name__ == "__main__":
    unittest.main(argv=['first-arg-is-ignored'], exit=False)
"""
    return test_code_template

# NOTE IMPORTANTE: La fonction batch_generate est rendue asynchrone et réelle.
async def batch_generate(participants_prompts: List[Tuple['AutonomousParticipant', str]], max_workers: int = 4) -> List[Dict[str, Any]]:
    """
    Génère du code pour plusieurs prompts en parallèle en faisant de vrais appels aux agents.
    """
    tasks = []
    for participant, prompt in participants_prompts:
        if prompt == "CACHED_RESPONSE":
            # Si c'est une réponse en cache, on simule une tâche rapide
            tasks.append(asyncio.create_task(asyncio.sleep(0.01, result={"cached": True, "brain_id": participant.id})))
        else:
            # L'Agent Autonome gère maintenant l'exécution de la tâche, y compris la sélection de l'endpoint
            tasks.append(participant.execute_task("Défi de Codage", prompt))
    
    results = await asyncio.gather(*tasks, return_exceptions=True)
    
    processed_results = []
    for i, res in enumerate(results):
        participant, original_prompt = participants_prompts[i] # original_prompt est utilisé pour le cache
        if isinstance(res, Exception):
            processed_results.append({"error": str(res), "brain_id": participant.id})
        elif isinstance(res, dict) and res.get("cached"):
            # Si c'est le marqueur de cache, ne rien faire, le système principal gérera le cache
            # Le contenu réel du cache sera récupéré par _execute_challenge_logic
            processed_results.append(res) # Passer le marqueur de cache
        else:
            processed_results.append(res)
    
    return processed_results

def adaptive_temp(prompt: str) -> float:
    """Adapte la "température" de génération de l'IA en fonction du contenu du prompt."""
    technical_keywords = ["optimiser", "algorithme", "complexité", "performance", "debug"]
    if any(kw in prompt.lower() for kw in technical_keywords):
        return 0.3
    else:
        return 0.7

def fix_common_errors(code: str) -> str:
    """Applique des corrections automatiques communes."""
    fixes = {
        "print (": "print(",
        "def  ": "def ",
        "= =": "==",
        "elif ": "elif ", # Correction d'une faute de frappe potentielle
        "esle:": "else:", # Correction d'une faute de frappe potentielle
        "ture": "True",   # Correction d'une faute de frappe potentielle
        "flase": "False"  # Correction d'une faute de frappe potentielle
    }
    for error, fix in fixes.items():
        code = code.replace(error, fix)
    return code

# Instance globale du système de défis.
coding_challenge_system: Optional['CodingChallengeSystem'] = None

def get_coding_challenge_system(telegram_client=None) -> 'CodingChallengeSystem':
    """Retourne l'instance globale (singleton) du système de défis de codage."""
    global coding_challenge_system
    if coding_challenge_system is None:
        # Import local pour éviter les dépendances circulaires
        from coding_challenge_system import CodingChallengeSystem as ActualCodingChallengeSystem
        coding_challenge_system = ActualCodingChallengeSystem(telegram_client)
    return coding_challenge_system
    
                                                                                  # decentralized_system.py

import asyncio
import json
import traceback
from pathlib import Path
from datetime import datetime
import re
from typing import Dict, Any, List, Optional

from config import config
from utils import log_message, set_file_lock
from app_singletons import endpoint_health_manager, quota_manager
from brain_library import brain_coordinator, TelegramMemoryIntegration
from autonomous_brain import create_brain
from coding_challenge_system import get_coding_challenge_system
from security_archiver import fetch_and_archive_pages
from tools import get_gemini_tools
import telegram_logger
from synthesizer_brain import SynthesizerBrain

class DecentralizedAISystem:
    """
    Système d'IA décentralisé avec 7 cerveaux autonomes.
    Chaque cerveau peut traiter indépendamment les requêtes utilisateur.
    """
    def __init__(self):
        self.brains = {}
        self.telegram_memory = None
        self.coding_system = None
        self.last_activity = datetime.now().timestamp()
        self.system_initialized = False
        self.synthesizer = None # Pour le cerveau de synthèse
        
        # Les 7 cerveaux autonomes
        self.brain_types = ["GEMINI", "DEEPSEEK", "HUGGINGFACE", "TAVILY", "SERPER", "GOOGLE_CUSTOM_SEARCH", "WOLFRAMALPHA"]
        
    async def initialize_system(self):
        """Initialise tous les composants du système décentralisé."""
        try:
            log_message("🚀 Initialisation du système d'IA décentralisé...")
            
            # Configuration du verrou de fichier
            file_lock = asyncio.Lock()
            set_file_lock(file_lock)
            
            # Initialisation des singletons
            await endpoint_health_manager.init_manager()
            await quota_manager.init_manager()
            
            try:
                from app_clients_instances import telegram_bot_client
                self.telegram_memory = TelegramMemoryIntegration(telegram_bot_client)
            except ImportError:
                log_message("Client Telegram non disponible, utilisation du mode simulé", level="warning")
                self.telegram_memory = TelegramMemoryIntegration(None)
            
            # Connexion du logger au système Telegram
            telegram_logger.initialize_logger(
                self.telegram_memory.bot_client if self.telegram_memory else None,
                config.PRIVATE_GROUP_ID
            )
            
            # Initialisation des 7 cerveaux autonomes
            for brain_type in self.brain_types:
                try:
                    brain = create_brain(brain_type, self.telegram_memory.bot_client if self.telegram_memory else None)
                    await brain.initialize()
                    self.brains[brain_type] = brain
                    log_message(f"✅ Cerveau {brain_type} initialisé")
                except Exception as e:
                    log_message(f"❌ Erreur initialisation cerveau {brain_type}: {e}", level="error")
            
            # INJECTION DE DÉPENDANCE : Chaque cerveau a maintenant accès à la liste des autres
            for brain in self.brains.values():
                brain.brains = self.brains # Ajoute une référence au dictionnaire des cerveaux

            log_message("✅ Injection de dépendance des cerveaux terminée.")
            
            # Initialisation du système de défis de codage
            self.coding_system = get_coding_challenge_system(
                self.telegram_memory.bot_client if self.telegram_memory else None
            )
            await self.coding_system.initialize()
            
            self.synthesizer = SynthesizerBrain(self.telegram_memory.bot_client if self.telegram_memory else None)
            await self.synthesizer.initialize()
            
            # Message d'initialisation dans le groupe privé
            await self.telegram_memory.write_to_group(
                f"""
🧠 SYSTÈME D'IA DÉCENTRALISÉ INITIALISÉ

✅ Cerveaux actifs: {len(self.brains)}/7
✅ Gestionnaire de santé: Opérationnel
✅ Gestionnaire de quotas: Opérationnel  
✅ Système de défis: Prêt
✅ Archiveur sécurisé: Prêt

🔄 Rotation automatique: 45 minutes
🎯 Défis de codage: 15 minutes
📝 Mémoire partagée: Active

Le système est prêt à traiter les requêtes utilisateur.
""",
                "SYSTEM_INIT"
            )
            
            self.system_initialized = True
            log_message("🎉 Système d'IA décentralisé initialisé avec succès")
            return True
            
        except Exception as e:
            log_message(f"❌ Erreur critique lors de l'initialisation: {e}", level="critical")
            log_message(f"Traceback: {traceback.format_exc()}", level="critical")
            return False
    
    async def start_background_tasks(self):
        """Démarre toutes les tâches de fond."""
        if not self.system_initialized:
            log_message("Système non initialisé, impossible de démarrer les tâches de fond", level="error")
            return
        
        log_message("🔄 Démarrage des tâches de fond...")
        
        # Tâche de défis de codage automatisés
        asyncio.create_task(self.coding_system.start_periodic_challenges())
        
        # Démarrage de la tâche de gestion proactive des quotas
        asyncio.create_task(self._proactive_quota_checks())
        
        # Tâche de nettoyage de la mémoire
        asyncio.create_task(self._memory_cleanup())
        
        await self.telegram_memory.write_to_group(
            "🔄 Toutes les tâches de fond sont démarrées",
            "BACKGROUND_TASKS"
        )
        
        log_message("✅ Tâches de fond démarrées")
    
    async def handle_user_request(self, user_query: str, user_id: str = "default_user", 
                                image_data: Optional[str] = None) -> Dict[str, Any]:
        """
        Traite une requête utilisateur avec le système décentralisé.
        Intègre la phase de synthèse.
        """
        if not self.system_initialized:
            return {"error": "Système non initialisé", "brain_id": "SYSTEM"}
        
        start_time = datetime.now()
        self.last_activity = start_time.timestamp()
        
        # Log de la requête
        await self.telegram_memory.write_to_group(
            f"🔍 NOUVELLE REQUÊTE UTILISATEUR\nUtilisateur: {user_id}\nRequête: {user_query[:200]}...",
            "USER_REQUEST"
        )
        
        log_message(f"Traitement requête utilisateur: {user_query[:100]}...")
        
        try:
            # Sélection du cerveau optimal
            selected_brain_type = brain_coordinator.get_next_brain()
            selected_brain = self.brains.get(selected_brain_type)
            
            if not selected_brain:
                error_msg = f"Cerveau {selected_brain_type} non disponible"
                await self.telegram_memory.log_error("SYSTEM", error_msg)
                return {"error": error_msg, "brain_id": "SYSTEM"}
            
            # Augmentation de la charge du cerveau
            brain_coordinator.update_brain_load(selected_brain_type, 1)
            
            await self.telegram_memory.log_brain_activity(
                selected_brain_type,
                "Sélectionné pour traitement",
                {"user_id": user_id, "query_length": len(user_query)}
            )
            
            # Préparation des outils
            available_tools = get_gemini_tools()
            
            # Étape 1: Le cerveau initial analyse la requête et peut décider d'appeler des outils
            first_pass_result = await selected_brain.process_request(
                user_query=user_query,
                chat_history=[],
                image_data=image_data,
                tools=available_tools
            )
            
            tool_results = first_pass_result.get("tool_results", [])

            # Phase de Synthèse
            if tool_results and self.synthesizer:
                await telegram_logger.log_system_event("SYNTHESIS_FLOW_START", f"Délégation au synthétiseur après {len(tool_results)} outil(s).")
                
                # Le synthétiseur prend le relais pour formuler la réponse finale
                final_response = await self.synthesizer.synthesize_response(
                    original_query=user_query,
                    tool_results=tool_results
                )
                
                # On met à jour le résultat final avec la réponse synthétisée
                final_result = first_pass_result
                final_result["response"] = final_response.get("response")
                final_result["brain_id"] = f"{selected_brain_type} -> SYNTHESIZER"
                
            else:
                # Si aucun outil n'a été appelé, on retourne directement la réponse du premier cerveau
                final_result = first_pass_result
            
            # Diminution de la charge du cerveau
            brain_coordinator.update_brain_load(selected_brain_type, -1)
            
            # Calcul du temps de traitement
            processing_time = (datetime.now() - start_time).total_seconds()
            
            # Mise à jour des statistiques
            if "error" not in final_result:
                await quota_manager.increment_quota(selected_brain_type, success=True)
                await self.telegram_memory.log_success(
                    final_result.get("brain_id", selected_brain_type),
                    f"Requête traitée en {processing_time:.2f}s",
                    str(final_result.get("response", ""))[:200]
                )
            else:
                await quota_manager.increment_quota(selected_brain_type, success=False)
                brain_coordinator.mark_brain_failed(selected_brain_type)
                await self.telegram_memory.log_error(
                    selected_brain_type,
                    f"Échec traitement: {final_result.get('error', 'Erreur inconnue')}"
                )
            
            # Enrichissement du résultat
            final_result.update({
                "processing_time": processing_time,
                "timestamp": start_time.isoformat(),
                "user_id": user_id,
                "system_status": brain_coordinator.get_brain_status()
            })
            
            return final_result
            
        except Exception as e:
            error_msg = f"Erreur système lors du traitement: {e}"
            log_message(f"Erreur handle_user_request: {error_msg}", level="error")
            log_message(f"Traceback: {traceback.format_exc()}", level="error")
            
            await self.telegram_memory.log_error("SYSTEM", error_msg)
            
            return {
                "error": error_msg,
                "brain_id": "SYSTEM",
                "timestamp": start_time.isoformat(),
                "user_id": user_id
            }
    
    async def _proactive_quota_checks(self):
        """Tâche de fond pour la gestion proactive des quotas."""
        while True:
            await asyncio.sleep(3600) # S'exécute toutes les heures
            try:
                await telegram_logger.log_system_event("PROACTIVE_QUOTA_CHECK", "Vérification proactive des quotas en cours.")
                all_quotas = quota_manager.get_all_quotas_status()
                
                report_lines = []
                warnings = []
                for api, status in all_quotas.items():
                    if isinstance(status, dict) and 'limit' in status and status['limit'] > 0:
                        remaining = status.get('remaining', 0)
                        limit = status.get('limit', 1)
                        percent_remaining = (remaining / limit) * 100
                        report_lines.append(f"- `{api}`: {remaining}/{limit} restants ({percent_remaining:.1f}%)")
                        if percent_remaining < 20:
                            warnings.append(f"`{api}` ({percent_remaining:.1f}%)")

                report = "📊 *RAPPORT DE QUOTAS PROACTIF*\n" + "\n".join(report_lines)
                if warnings:
                    report += f"\n\n*⚠️ AVERTISSEMENT - QUOTAS FAIBLES:*\n" + ", ".join(warnings)
                
                await telegram_logger.log_system_event("QUOTA_REPORT", report)
            except Exception as e:
                await telegram_logger.log_error("QUOTA_SYSTEM", f"Erreur lors de la vérification proactive des quotas: {e}")

    async def _memory_cleanup(self):
        """Nettoyage périodique de la mémoire."""
        while True:
            try:
                await asyncio.sleep(24 * 3600)  # Tous les jours
                
                # Nettoyage de la mémoire des cerveaux
                for brain in self.brains.values():
                    await brain.memory_manager.save_memory()
                
                await self.telegram_memory.write_to_group(
                    "🧹 Nettoyage de mémoire effectué",
                    "MEMORY_CLEANUP"
                )
                
                log_message("Nettoyage de mémoire effectué")
                
            except Exception as e:
                log_message(f"Erreur nettoyage mémoire: {e}", level="error")
    
    def get_system_status(self) -> Dict[str, Any]:
        """Retourne le statut complet du système."""
        if not self.system_initialized:
            return {"status": "not_initialized"}
        
        return {
            "status": "operational",
            "initialized": self.system_initialized,
            "active_brains": len(self.brains),
            "brain_status": brain_coordinator.get_brain_status(),
            "coding_challenges": self.coding_system.get_challenge_statistics() if self.coding_system else {},
            "last_activity": self.last_activity,
            "uptime": datetime.now().timestamp() - self.last_activity if hasattr(self, 'start_time') else 0
        }
    
    async def shutdown(self):
        """Arrêt propre du système."""
        log_message("🛑 Arrêt du système d'IA décentralisé...")
        
        try:
            # Arrêt des défis de codage
            if self.coding_system:
                self.coding_system.stop_challenges()
            
            # Sauvegarde finale de toutes les mémoires
            for brain in self.brains.values():
                await brain.memory_manager.save_memory()
            
            await self.telegram_memory.write_to_group(
                "🛑 Système d'IA décentralisé arrêté proprement",
                "SYSTEM_SHUTDOWN"
            )
            
            log_message("✅ Système arrêté proprement")
            
        except Exception as e:
            log_message(f"Erreur lors de l'arrêt: {e}", level="error")

# Instance globale du système
decentralized_system = DecentralizedAISystem()

async def main():
    """Fonction principale pour le mode console."""
    try:
        # Initialisation du système
        success = await decentralized_system.initialize_system()
        if not success:
            log_message("❌ Échec de l'initialisation, arrêt du programme", level="critical")
            return
        
        # Démarrage des tâches de fond
        await decentralized_system.start_background_tasks()
        
        # Interface console
        print("\n" + "="*60)
        print("🧠 SYSTÈME D'IA DÉCENTRALISÉ - 7 CERVEAUX AUTONOMES")
        print("="*60)
        print("Commandes disponibles:")
        print("  /help      - Affiche l'aide")
        print("  /status    - Statut du système")
        print("  /brains    - État des cerveaux")
        print("  /quotas    - État des quotas")
        print("  /challenges - Statistiques défis")
        print("  /challenge - Lance un défi manuel")
        print("  /archive <urls> - Archive des pages web")
        print("  /exit      - Quitter")
        print("  Ou tapez directement votre question")
        print("="*60)
        
        while True:
            try:
                user_input = await asyncio.to_thread(input, "\n🤖 Vous: ")
                user_input = user_input.strip()
                
                if not user_input:
                    continue
                
                if user_input.lower() == "/exit":
                    break
                
                elif user_input.lower() == "/help":
                    print("""
📋 AIDE DU SYSTÈME D'IA DÉCENTRALISÉ

🧠 Architecture:
  • 7 cerveaux autonomes (GEMINI, DEEPSEEK, HUGGINGFACE, TAVILY, SERPER, GOOGLE_CUSTOM_SEARCH, WOLFRAMALPHA)
  • Rotation automatique toutes les 45 minutes
  • Basculement automatique en cas de panne
  • Mémoire partagée dans le groupe privé Telegram

🎯 Fonctionnalités:
  • Traitement de requêtes utilisateur
  • Défis de codage automatisés (15 min)
  • Archivage sécurisé de pages web
  • Monitoring santé des APIs
  • Gestion intelligente des quotas

💬 Exemples d'utilisation:
  • "Explique-moi la programmation asynchrone"
  • "Crée un script Python pour analyser des données"
  • "Recherche les dernières nouvelles sur l'IA"
  • "/archive https://example.com,https://site.org"
""")
                
                elif user_input.lower() == "/status":
                    status = decentralized_system.get_system_status()
                    print(f"""
📊 STATUT SYSTÈME:
  • État: {status['status']}
  • Cerveaux actifs: {status['active_brains']}/7
  • Cerveau pour la prochaine requête: {status.get('brain_status', {}).get('active_brain_for_next_request', 'N/A')}
  • Dernière activité: {datetime.fromtimestamp(status['last_activity']).strftime('%H:%M:%S')}
""")
                
                elif user_input.lower() == "/brains":
                    brain_status = brain_coordinator.get_brain_status()
                    print("\n🧠 ÉTAT DES CERVEAUX:")
                    for brain, healthy in brain_status['brain_health'].items():
                        load = brain_status['brain_load'].get(brain, 0)
                        status_icon = "✅" if healthy else "❌"
                        print(f"  {status_icon} {brain}: Charge {load}")
                
                elif user_input.lower() == "/quotas":
                    quotas = quota_manager.get_all_quotas_status()
                    print("\n📊 ÉTAT DES QUOTAS:")
                    for api, quota_info in quotas.items():
                        if isinstance(quota_info, dict) and 'error' not in quota_info:
                            usage = quota_info['current_usage']
                            limit = quota_info['limit']
                            remaining = quota_info['remaining']
                            percent = (usage / limit * 100) if limit > 0 else 0
                            print(f"  {api}: {usage}/{limit} ({percent:.1f}%) - Restant: {remaining}")
                
                elif user_input.lower() == "/challenges":
                    if decentralized_system.coding_system:
                        stats = decentralized_system.coding_system.get_challenge_statistics()
                        print(f"""
🎯 STATISTIQUES DÉFIS DE CODAGE:
  • Total défis: {stats.get('total_challenges', 0)}
  • Participants: {stats.get('total_participants', 0)}
  • Succès: {stats.get('total_successful', 0)}
  • Taux succès: {stats.get('average_success_rate', 0):.1f}%
  • Statut: {'🔄 Actif' if stats.get('is_running') else '⏹️ Arrêté'}
""")
                    else:
                        print("❌ Système de défis non initialisé")

                elif user_input.lower().startswith("/challenge"):
                    try:
                        from coding_challenge_system import get_coding_challenge_system
                        challenge_system = get_coding_challenge_system()
                        
                        if challenge_system and challenge_system.is_running:
                            print("🚀 Lancement manuel d'un défi de codage pour tous les agents...")
                            
                            # On lance l'exécution du défi en tâche de fond pour ne pas bloquer la console
                            asyncio.create_task(challenge_system.run_coding_challenge())
                            
                            print("✅ Défi lancé. Surveillez le groupe privé pour les résultats.")
                        else:
                            print("❌ Le système de défis de codage n'est pas actif ou initialisé.")
                    except Exception as e:
                        print(f"❌ Erreur lors du lancement du défi : {e}")
                
                elif user_input.startswith("/archive "):
                    urls_str = user_input[9:].strip()
                    if urls_str:
                        urls = [url.strip() for url in urls_str.split(',') if url.strip()]
                        if urls:
                            print(f"🗂️ Archivage de {len(urls)} URL(s) en cours...")
                            result = await fetch_and_archive_pages(urls, "console_user")
                            print(f"✅ {result.get('tool_output', 'Archivage terminé')}")
                        else:
                            print("❌ Aucune URL valide fournie")
                    else:
                        print("❌ Usage: /archive <url1>,<url2>,...")
                
                else:
                    # Traitement d'une requête normale
                    print("🤔 Traitement en cours...")
                    
                    # Détection simple d'image (simulation)
                    image_data = None
                    if any(ext in user_input.lower() for ext in ['.png', '.jpg', '.jpeg', '.gif']):
                        print("🖼️ Image détectée (mode simulation)")
                        image_data = "data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAEAAAABCAQAAAC1HAwCAAAAC0lEQVR42mNkYAAAAAYAAjCB0C8AAAAASUVORK5CYII="
                    
                    # Traitement par le système décentralisé
                    response = await decentralized_system.handle_user_request(
                        user_query=user_input,
                        user_id="console_user",
                        image_data=image_data
                    )
                    
                    # Affichage de la réponse
                    if "error" in response:
                        print(f"❌ Erreur ({response.get('brain_id', 'UNKNOWN')}): {response['error']}")
                    else:
                        brain_id = response.get('brain_id', 'UNKNOWN')
                        processing_time = response.get('processing_time', 0)
                        
                        # Extraction de la réponse selon le format
                        if 'response' in response and isinstance(response['response'], dict):
                            candidates = response['response'].get('candidates', [])
                            if candidates and 'content' in candidates[0]:
                                parts = candidates[0]['content'].get('parts', [])
                                if parts and 'text' in parts[0]:
                                    answer = parts[0]['text']
                                else:
                                    answer = str(response['response'])
                            else:
                                answer = str(response['response'])
                        else:
                            answer = str(response.get('response', 'Aucune réponse'))
                        
                        print(f"\n🤖 {brain_id} ({processing_time:.2f}s): {answer}")
                        
                        # Affichage des outils utilisés
                        if 'tool_results' in response and response['tool_results']:
                            print(f"\n🔧 Outils utilisés: {len(response['tool_results'])}")
                            for tool in response['tool_results']:
                                tool_name = tool.get('tool_name', 'Inconnu')
                                print(f"  • {tool_name}")
                
            except EOFError:
                print("\n👋 Au revoir !")
                break
            except KeyboardInterrupt:
                print("\n⚠️ Interruption détectée...")
                break
            except Exception as e:
                print(f"❌ Erreur: {e}")
                log_message(f"Erreur console: {e}", level="error")
        
    except Exception as e:
        log_message(f"Erreur critique dans main(): {e}", level="critical")
        log_message(f"Traceback: {traceback.format_exc()}", level="critical")
    
    finally:
        # Arrêt propre du système
        await decentralized_system.shutdown()

if __name__ == "__main__":
    try:
        asyncio.run(main())
    except KeyboardInterrupt:
        print("\n🛑 Arrêt forcé du système")
    except Exception as e:
        print(f"❌ Erreur fatale: {e}")
        
                                                                                  # security_archiver.py

import asyncio
import hashlib
import io
import re
import time
from datetime import datetime
from pathlib import Path
from typing import List, Optional, Dict, Any
from urllib.parse import urlparse
import httpx

from config import config
from brain_library import TelegramMemoryIntegration
from utils import log_message, save_json # <--- MODIFIÉ : Ajout de save_json

class URLDefanger:
    """
    Neutralise les URLs pour empêcher les clics accidentels
    et bloque les trackers connus.
    """
    def __init__(self, mode: str = "secure"):
        self.mode = mode
        self.url_pattern = re.compile(r'https?://[^\s\]]+')
        self.tracker_domains = [
            "doubleclick.net", "googleadservices.com", "googlesyndication.com",
            "facebook.com/tr", "analytics.google.com", "hotjar.com",
            "mouseflow.com", "crazyegg.com", "fullstory.com"
        ]
    
    def _generate_hash(self, url: str) -> str:
        """Génère un identifiant unique pour l'URL."""
        return hashlib.sha256(url.encode()).hexdigest()[:8]
    
    def defang_url(self, url: str) -> str:
        """Transforme une URL en version sécurisée."""
        for tracker in self.tracker_domains:
            if tracker in url:
                return "[TRACKER_BLOQUÉ]"
        
        if self.mode == "secure":
            return f"[URL_BLOQUÉE:#{self._generate_hash(url)}]"
        else:
            parsed = urlparse(url)
            return f"[URL:{parsed.netloc}/...#{self._generate_hash(url)}]"
    
    def defang_text(self, text: str) -> str:
        """Nettoie tout le contenu texte."""
        return self.url_pattern.sub(
            lambda m: self.defang_url(m.group(0)), 
            text
        )

class SecurePageArchiver:
    """
    Télécharge, sécurise et archive des pages web
    avec gestion des gros fichiers et protection anti-tracking.
    """
    def __init__(self, telegram_client=None):
        self.telegram_client = telegram_client
        self.telegram_memory = TelegramMemoryIntegration(telegram_client)
        self.headers = {
            "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36",
            "Accept-Language": "fr-FR,fr;q=0.9,en;q=0.8",
            "Accept-Encoding": "gzip, deflate, br",
            "Accept": "text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8",
            "DNT": "1",
            "Connection": "keep-alive",
            "Upgrade-Insecure-Requests": "1"
        }
        
    async def fetch_page(self, url: str) -> Optional[httpx.Response]:
        """Télécharge une page avec gestion robuste des erreurs."""
        try:
            async with httpx.AsyncClient(
                timeout=30.0,
                headers=self.headers,
                follow_redirects=True,
                http2=True,
                limits=httpx.Limits(max_keepalive_connections=5, max_connections=10)
            ) as client:
                response = await client.get(url)
                
                content_length = response.headers.get('content-length')
                if content_length and int(content_length) > config.MAX_FILE_SIZE:
                    log_message(f"Contenu trop volumineux pour {url}: {content_length} bytes", level="warning")
                    return None
                
                response.raise_for_status()
                return response
                
        except httpx.HTTPStatusError as e:
            log_message(f"Erreur HTTP pour {url}: {e.response.status_code}", level="warning")
            return None
        except httpx.RequestError as e:
            log_message(f"Erreur réseau pour {url}: {e}", level="warning")
            return None
        except Exception as e:
            log_message(f"Erreur inattendue pour {url}: {e}", level="error")
            return None

    async def secure_content(self, url: str, content: str) -> str:
        """Applique les protections de sécurité au contenu."""
        defanger = URLDefanger(mode="secure")
        
        header = f"""
⚠️ CONTENU ARCHIVÉ - LIENS NEUTRALISÉS ⚠️
URL originale: {url}
Horodatage: {datetime.utcnow().isoformat()}Z
Taille originale: {len(content)} caractères
Sécurisé par: SecurePageArchiver v2.1
=====================================

"""
        
        secured_content = defanger.defang_text(content)
        
        secured_content = re.sub(r'<script[^>]*>.*?</script>', '[SCRIPT_SUPPRIMÉ]', secured_content, flags=re.DOTALL | re.IGNORECASE)
        secured_content = re.sub(r'javascript:[^"\']*', '[JAVASCRIPT_BLOQUÉ]', secured_content, flags=re.IGNORECASE)
        secured_content = re.sub(r'on\w+\s*=\s*["\'][^"\']*["\']', '[EVENT_HANDLER_BLOQUÉ]', secured_content, flags=re.IGNORECASE)
        
        return header + secured_content

    async def send_content(self, content: str, url: str, user_id: str) -> bool:
        """Envoie le contenu sécurisé via Telegram, en tant que fichier si nécessaire."""
        try:
            from telegram_logger import _send_log
            
            caption = f"📄 Archive de la page : `{url[:100]}...`\n👤 Demandé par : `{user_id}`"
            
            if len(content) > 3800:
                timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
                filename = f"archive_{user_id}_{timestamp}.txt"
                await _send_log(caption, file_content=content, file_name=filename)
            else:
                message = f"{caption}\n\n```\n{content[:3500]}...\n```"
                await _send_log(message)

            log_message(f"Contenu archivé envoyé pour {url}")
            return True
            
        except Exception as e:
            log_message(f"Erreur envoi contenu archivé: {e}", level="error")
            return False

    async def archive_single_page(self, url: str, user_id: str) -> Dict[str, Any]:
        """Archive une seule page web."""
        start_time = time.time()
        result = {
            "url": url,
            "user_id": user_id,
            "timestamp": datetime.now().isoformat(),
            "success": False,
            "content_sent": False,
            "total_size": 0,
            "processing_time": 0,
            "error": None
        }
        
        try:
            await self.telegram_memory.log_brain_activity(
                "ARCHIVER",
                f"Début archivage: {url}",
                {"user_id": user_id}
            )
            
            response = await self.fetch_page(url)
            if not response:
                result["error"] = "Échec du téléchargement"
                return result
            
            content_type = response.headers.get('content-type', '').lower()
            if not any(ct in content_type for ct in ['text/html', 'text/plain', 'application/json']):
                result["error"] = f"Type de contenu non supporté: {content_type}"
                return result
            
            raw_content = response.text
            result["total_size"] = len(raw_content)
            
            secured_content = await self.secure_content(url, raw_content)
            
            content_sent = await self.send_content(secured_content, url, user_id)
            
            result["content_sent"] = content_sent
            result["success"] = content_sent
            
            processing_time = time.time() - start_time
            result["processing_time"] = processing_time
            
            if content_sent:
                await self.telegram_memory.log_success(
                    "ARCHIVER",
                    f"Page archivée: {url}",
                    f"Contenu envoyé avec succès."
                )
            else:
                raise Exception("Échec de l'envoi du contenu sur Telegram.")
            
        except Exception as e:
            result["error"] = str(e)
            await self.telegram_memory.log_error("ARCHIVER", f"Erreur archivage {url}: {e}")
        
        return result

class ArchiveCoordinator:
    """
    Coordinateur pour l'archivage de multiples pages en parallèle.
    """
    def __init__(self, telegram_client=None, max_concurrent: int = 3):
        self.archiver = SecurePageArchiver(telegram_client)
        self.max_concurrent = max_concurrent
        self.telegram_memory = TelegramMemoryIntegration(telegram_client)
        
    async def archive_multiple_pages(self, links: List[str], user_id: str) -> Dict[str, Any]:
        """Archive plusieurs pages en parallèle avec limitation de concurrence."""
        start_time = time.time()
        
        await self.telegram_memory.write_to_group(
            f"🚀 Début archivage de {len(links)} pages pour l'utilisateur {user_id}",
            "ARCHIVE_START"
        )
        
        if len(links) > 10:
            links = links[:10]
            await self.telegram_memory.write_to_group(
                "⚠️ Limitation appliquée: maximum 10 liens par session",
                "ARCHIVE_LIMIT"
            )
        
        semaphore = asyncio.Semaphore(self.max_concurrent)
        
        async def archive_with_semaphore(url: str) -> Dict[str, Any]:
            async with semaphore:
                return await self.archiver.archive_single_page(url, user_id)
        
        tasks = [archive_with_semaphore(url) for url in links]
        results = await asyncio.gather(*tasks, return_exceptions=True)
        
        summary = {
            "total_links": len(links),
            "successful": 0,
            "failed": 0,
            "total_size": 0,
            "processing_time": time.time() - start_time,
            "results": []
        }
        
        for i, result in enumerate(results):
            if isinstance(result, Exception):
                error_result = {
                    "url": links[i] if i < len(links) else "Unknown",
                    "success": False,
                    "error": str(result)
                }
                summary["results"].append(error_result)
                summary["failed"] += 1
            else:
                summary["results"].append(result)
                if result["success"]:
                    summary["successful"] += 1
                    summary["total_size"] += result["total_size"]
                else:
                    summary["failed"] += 1
        
        await self.telegram_memory.write_to_group(
            f"""
📊 RAPPORT D'ARCHIVAGE TERMINÉ

👤 Utilisateur: {user_id}
📊 Statistiques:
  • Total: {summary['total_links']} liens
  • Succès: {summary['successful']} pages
  • Échecs: {summary['failed']} pages
  • Taille totale (brute): {summary['total_size']:,} caractères
  • Durée: {summary['processing_time']:.2f}s

✅ Toutes les pages sont sécurisées et archivées dans ce groupe.
""",
            "ARCHIVE_COMPLETE"
        )
        
        return summary

async def fetch_and_archive_pages(links: List[str], user_id: str, context=None) -> Dict[str, Any]:
    """
    Fonction principale pour télécharger, sécuriser et archiver des pages web.
    """
    try:
        from app_clients_instances import telegram_bot_client
        
        coordinator = ArchiveCoordinator(telegram_bot_client, max_concurrent=3)
        summary = await coordinator.archive_multiple_pages(links, user_id)
        
        return {
            "tool_output": f"✅ Archivage terminé: {summary['successful']}/{summary['total_links']} pages archivées avec succès. Les contenus ont été envoyés dans le groupe privé.",
            "summary": summary
        }
        
    except Exception as e:
        error_msg = f"❌ Erreur système d'archivage: {e}"
        log_message(f"Erreur fetch_and_archive_pages: {e}", level="error")
        return {
            "tool_output": error_msg,
            "error": str(e)
        }

class ContentAnalyzer:
    """Analyse le contenu des pages archivées."""
    
    @staticmethod
    def extract_metadata(content: str, url: str) -> Dict[str, Any]:
        """Extrait les métadonnées d'une page."""
        metadata = {
            "url": url,
            "timestamp": datetime.now().isoformat(),
            "size": len(content),
            "title": "",
            "description": "",
            "language": "unknown",
            "charset": "unknown"
        }
        
        title_match = re.search(r'<title[^>]*>(.*?)</title>', content, re.IGNORECASE | re.DOTALL)
        if title_match:
            metadata["title"] = title_match.group(1).strip()[:200]
        
        desc_match = re.search(r'<meta[^>]*name=["\']description["\'][^>]*content=["\']([^"\']*)["\']', content, re.IGNORECASE)
        if desc_match:
            metadata["description"] = desc_match.group(1).strip()[:500]
        
        lang_match = re.search(r'<html[^>]*lang=["\']([^"\']*)["\']', content, re.IGNORECASE)
        if lang_match:
            metadata["language"] = lang_match.group(1).strip()
        
        return metadata
    
    @staticmethod
    def count_elements(content: str) -> Dict[str, int]:
        """Compte les éléments HTML dans le contenu."""
        elements = {
            "links": len(re.findall(r'<a[^>]*href=', content, re.IGNORECASE)),
            "images": len(re.findall(r'<img[^>]*src=', content, re.IGNORECASE)),
            "scripts": len(re.findall(r'<script[^>]*>', content, re.IGNORECASE)),
            "forms": len(re.findall(r'<form[^>]*>', content, re.IGNORECASE)),
            "paragraphs": len(re.findall(r'<p[^>]*>', content, re.IGNORECASE)),
            "headings": len(re.findall(r'<h[1-6][^>]*>', content, re.IGNORECASE))
        }
        
        return elements

class ArchiveStorage:
    """Gestionnaire de stockage pour les archives."""
    
    def __init__(self):
        self.archive_dir = config.BASE_DIR / "archives"
        self.archive_dir.mkdir(exist_ok=True)
        
    async def save_archive_metadata(self, user_id: str, summary: Dict[str, Any]):
        """Sauvegarde les métadonnées d'archivage."""
        try:
            metadata_file = self.archive_dir / f"archive_{user_id}_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json"
            
            await save_json(metadata_file, summary)
            
            log_message(f"Métadonnées d'archivage sauvegardées: {metadata_file}")
            
        except Exception as e:
            log_message(f"Erreur sauvegarde métadonnées: {e}", level="error")
    
    def get_user_archives(self, user_id: str) -> List[Path]:
        """Récupère la liste des archives d'un utilisateur."""
        pattern = f"archive_{user_id}_*.json"
        return list(self.archive_dir.glob(pattern))
    
    def cleanup_old_archives(self, days: int = 30):
        """Nettoie les anciennes archives."""
        cutoff_time = time.time() - (days * 24 * 60 * 60)
        
        for archive_file in self.archive_dir.glob("archive_*.json"):
            if archive_file.stat().st_mtime < cutoff_time:
                try:
                    archive_file.unlink()
                    log_message(f"Archive supprimée: {archive_file}")
                except Exception as e:
                    log_message(f"Erreur suppression archive {archive_file}: {e}", level="error")

# Instance globale du stockage
archive_storage = ArchiveStorage()

                                                                                  # synthesizer_brain.py 

import json
from typing import Dict, Any, List, Optional

from autonomous_brain import AutonomousBrain
import telegram_logger
from brain_library import api_key_library
from utils import log_message
from app_clients_instances import get_client # <--- AJOUTÉ

class SynthesizerBrain(AutonomousBrain):
    """
    Un cerveau spécialisé dont le seul rôle est de synthétiser des données brutes
    pour formuler une réponse finale de haute qualité.
    """
    def __init__(self, telegram_client=None):
        # Le synthétiseur peut utiliser n'importe lequel des 7 agents principaux pour la synthèse.
        # On définit une liste de services prioritaires, en commençant par les plus puissants.
        self.agent_service_priority = [
            "GEMINI_API", 
            "DEEPSEEK", 
            "HUGGINGFACE", 
            "TAVILY", 
            "SERPER", 
            "GOOGLE_CUSTOM_SEARCH", 
            "WOLFRAMALPHA"
        ]
        # On initialise avec le premier de la liste, mais on pourra changer dynamiquement.
        super().__init__("SYNTHESIZER", self.agent_service_priority[0], telegram_client)
        log_message("Cerveau Synthétiseur initialisé avec une logique de collaboration flexible (7 agents).")
        
    async def synthesize_response(self, original_query: str, tool_results: List[Dict]) -> Dict[str, Any]:
        """
        Prend une question originale et des données brutes, et génère une réponse synthétisée.
        """
        await telegram_logger.log_agent_decision(self.brain_id, "Début de la synthèse de la réponse finale.")
        
        # Prépare les données brutes pour le prompt
        formatted_tool_results = []
        for result in tool_results:
            tool_name = result.get("tool_name", "unknown_tool")
            output = result.get("tool_output", "No output")
            # Nettoie et tronque la sortie de chaque outil pour le prompt
            if isinstance(output, dict):
                output = json.dumps(output, indent=2, ensure_ascii=False)
            
            formatted_tool_results.append(f"--- Résultat de l'outil : {tool_name} ---\n{str(output)[:1000]}\n")

        synthesis_prompt = f"""RÔLE: Expert en synthèse d'informations et rédacteur en chef.
MISSION: Formuler une réponse claire, complète et bien structurée pour l'utilisateur final, en te basant exclusivement sur les données fournies.

CONTEXTE:
- Requête originale de l'utilisateur: "{original_query}"
- Données brutes collectées par les outils spécialisés:
{"\n".join(formatted_tool_results)}

INSTRUCTIONS:
1.  **Analyse la requête originale** pour bien comprendre l'intention de l'utilisateur.
2.  **Examine attentivement les données brutes** de chaque outil.
3.  **Croise et fusionne ces informations** pour construire une réponse unique et cohérente. Ne te contente pas de lister les résultats, intègre-les dans un texte fluide.
4.  **Si des outils ont échoué ou n'ont pas retourné de résultat pertinent,** mentionne-le poliment et brièvement (ex: "La recherche d'images n'a pas donné de résultat pertinent.").
5.  **Structure ta réponse** avec des titres, des listes à puces, et du texte en gras pour une lisibilité maximale.
6.  **Ta réponse finale doit être directement adressée à l'utilisateur.** Ne mentionne pas ton processus interne ("j'ai analysé les données...", etc.).
7.  **Rédige la réponse finale ci-dessous.** Sois précis, factuel et utile.
"""

        # Le synthétiseur recherche dynamiquement un endpoint fonctionnel
        # parmi les 7 types d'agents principaux.
        final_response_dict = {"error": "Aucun agent n'a pu réaliser la synthèse."}
        for service in self.agent_service_priority:
            self.service_name = service # On met à jour le service à utiliser
            self.api_client = get_client(service)
            if not self.api_client:
                continue

            # L'AutonomousParticipant gère l'itération sur les endpoints,
            # mais ici, le synthétiseur agit comme son propre participant.
            # Nous allons donc simuler cette logique en prenant le premier endpoint sain.
            from app_singletons import endpoint_health_manager
            all_endpoints = await self.api_client._get_available_endpoint()
            
            for endpoint_config in all_endpoints:
                is_healthy = await endpoint_health_manager.is_healthy(endpoint_config['endpoint_name'], service)
                if is_healthy:
                    await telegram_logger.log_agent_decision(
                        self.brain_id, 
                        f"Sélection du service '{service}' via l'endpoint '{endpoint_config['endpoint_name']}' pour effectuer la synthèse."
                    )
                    
                    # Appel au LLM pour la synthèse
                    final_response_dict = await self._generate_response(
                        endpoint_config=endpoint_config,
                        prompt=synthesis_prompt, 
                        chat_history=[], 
                        tools=[]
                    )
                    
                    # Si la synthèse réussit, on arrête de chercher
                    if "error" not in final_response_dict:
                        await telegram_logger.log_system_event("SYNTHESIS_COMPLETE", f"Synthèse terminée avec succès via {service}.")
                        return {"response": final_response_dict}
        
        # Si on arrive ici, c'est que tous les endpoints de tous les services ont échoué
        await telegram_logger.log_error(self.brain_id, final_response_dict["error"])
        return final_response_dict

    async def _generate_response(self, endpoint_config: Dict[str, Any],
                               prompt: str, 
                               chat_history: List[Dict] = None,
                               image_data: str = None, 
                               tools: List[Dict] = None) -> Dict[str, Any]:
        """
        Génère une réponse de synthèse en utilisant le client API du service sélectionné.
        """
        try:
            if not self.api_client:
                raise Exception(f"Client API pour le service de synthèse '{self.service_name}' non trouvé.")

            # La plupart des clients LLM ont une méthode 'generate_content' ou 'chat_completion'
            if hasattr(self.api_client, 'generate_content'):
                return await self.api_client.generate_content(
                    endpoint_config=endpoint_config,
                    prompt=prompt,
                    chat_history=chat_history or [],
                    image_data=image_data,
                    tools=tools
                )
            elif hasattr(self.api_client, 'chat_completion'):
                messages = [{"role": "user", "content": prompt}]
                result = await self.api_client.chat_completion(
                    endpoint_config=endpoint_config,
                    messages=messages
                )
                # Convertir la réponse au format standard "candidates"
                if isinstance(result, dict) and "choices" in result and result["choices"]:
                    content = result["choices"][0]["message"]["content"]
                    return {"candidates": [{"content": {"parts": [{"text": content}]}}]}
                else:
                    return {"candidates": [{"content": {"parts": [{"text": str(result)}]}}]}
            else:
                # Fallback pour les clients non-LLM (Tavily, Serper, etc.) qui ont une méthode 'search'
                if hasattr(self.api_client, 'search'):
                    result = await self.api_client.search(endpoint_config, query=prompt)
                    return {"candidates": [{"content": {"parts": [{"text": json.dumps(result, indent=2)}]}}]}
                
                raise NotImplementedError(f"Le client pour '{self.service_name}' n'a pas de méthode de génération de contenu reconnue.")

        except Exception as e:
            log_message(f"Erreur dans _generate_response du Synthétiseur avec {self.service_name}: {e}", level="error")
            return {"error": f"Erreur de synthèse via {self.service_name}: {e}"}
                                                                                                                                                                    #telegram_logger.py

import json
from datetime import datetime
import re
from typing import Dict, Any, Optional

# Ces variables globales seront connectées à votre système Telegram au démarrage.
telegram_bot_client = None
GROUP_ID = None

def initialize_logger(client: Any, group_id: int):
    """Définit l'instance du client Telegram et l'ID du groupe pour ce module."""
    global telegram_bot_client, GROUP_ID
    telegram_bot_client = client
    GROUP_ID = group_id
    print(f"Logger Telegram initialisé. Envoi des logs vers le groupe ID: {GROUP_ID}")

def _defang_url(url: str) -> str:
    """Neutralise une URL pour la sécurité dans les logs."""
    return str(url).replace("http://", "hxxp://").replace("https://", "hxxps://")

def _sanitize_text(text: Any) -> str:
    """Nettoie et neutralise les URLs dans un texte pour l'affichage."""
    text = str(text)
    url_pattern = re.compile(r'https?://[^\s"\'`]+')
    return url_pattern.sub(lambda m: _defang_url(m.group(0)), text)

async def _send_log(message: str):
    """Fonction interne pour envoyer un message log formaté à Telegram."""
    if not telegram_bot_client or not GROUP_ID:
        # Mode fallback si Telegram n'est pas disponible
        print(f"LOG (simulé): {message[:250]}...")
        return
    try:
        # Telegram a une limite de 4096 caractères par message
        if len(message) > 4096:
            message = message[:4090] + "\n[...TRONQUÉ...]"
        # Utilise le mode Markdown pour un meilleur formatage
        await telegram_bot_client.send_message(chat_id=GROUP_ID, text=message, parse_mode='Markdown')
    except Exception as e:
        # Erreur critique si même le logging échoue
        print(f"❌ ERREUR CRITIQUE (TelegramLogger): Impossible d'envoyer le log. Erreur: {e}")

async def log_api_call(agent_id: str, endpoint_name: str, url: str, method: str):
    """Archive le début d'un appel API."""
    timestamp = datetime.now().strftime('%Y-%m-%d %H:%M:%S.%f')[:-3]
    log_message = f"""*➡️ API CALL* | `{timestamp}`
*Agent:* `{agent_id}`
*Endpoint:* `{endpoint_name}`
*URL:* `{_defang_url(url)}`
*Method:* `{method}`"""
    await _send_log(log_message)

async def log_api_response(agent_id: str, endpoint_name: str, status_code: int, response_text: str, latency: float):
    """Archive la réponse (succès ou échec) d'un appel API."""
    timestamp = datetime.now().strftime('%Y-%m-%d %H:%M:%S.%f')[:-3]
    status_icon = "✅" if 200 <= status_code < 300 else "❌"
    log_message = f"""*{status_icon} API RESPONSE* | `{timestamp}`
*Agent:* `{agent_id}`
*Endpoint:* `{endpoint_name}`
*Status:* `{status_code}` | *Latency:* `{latency:.3f}s`
*Response (extrait):*
```
{_sanitize_text(response_text[:1500])}
```"""
    await _send_log(log_message)

async def log_system_event(event_type: str, message: str, details: Optional[Dict] = None):
    """Archive un événement système majeur (démarrage, erreur critique, etc.)."""
    timestamp = datetime.now().strftime('%Y-%m-%d %H:%M:%S.%f')[:-3]
    log_message = f"""*⚙️ SYSTEM EVENT* | `{timestamp}`
*Event:* `{event_type}`
*Message:* {_sanitize_text(message)}"""
    if details:
        try:
            details_str = json.dumps(details, indent=2, ensure_ascii=False)
            log_message += f"\n*Details:*\n```json\n{_sanitize_text(details_str)}\n```"
        except TypeError:
            log_message += f"\n*Details (non sérialisable):* `{_sanitize_text(str(details))}`"
    await _send_log(log_message)

async def log_agent_decision(agent_id: str, decision: str, context: Optional[Dict] = None):
    """Archive une décision prise par un agent autonome."""
    timestamp = datetime.now().strftime('%Y-%m-%d %H:%M:%S.%f')[:-3]
    log_message = f"""*🧠 AGENT DECISION* | `{timestamp}`
*Agent:* `{agent_id}`
*Decision:* {_sanitize_text(decision)}"""
    if context:
        log_message += f"\n*Context:* `{_sanitize_text(json.dumps(context))}`"
    await _send_log(log_message)

async def log_structured_report(report_data: dict):
    """
    Envoie un rapport d'action structuré et détaillé au groupe privé.
    """
    try:
        report_text = f"📊 *Rapport d'Action IA*\n\n"
        report_text += f"*Timestamp*: `{report_data.get('timestamp', 'N/A')}`\n"
        report_text += f"*Agent Principal*: `{report_data.get('agent_name', 'N/A')}`\n"
        report_text += f"*Intention Détectée*: `{report_data.get('intention', 'N/A')}`\n"
        report_text += f"*Requête Utilisateur*: ```\n{_sanitize_text(report_data.get('user_query', 'N/A'))}\n```\n"
        
        tools = report_data.get('tools_called', [])
        if tools:
            report_text += "*Outils/Agents Appelés*:\n"
            for tool in tools:
                tool_name = tool.get('name', 'outil_inconnu')
                tool_result = str(tool.get('result', ''))
                tool_result = tool_result.replace('`', "'").replace('*', '')
                if len(tool_result) > 200:
                    tool_result = tool_result[:200] + "..."
                report_text += f"- `{tool_name}` -> Résultat: ```\n{_sanitize_text(tool_result)}\n```\n"
        else:
            report_text += "*Outils/Agents Appelés*: Aucun\n"
        
        final_resp = str(report_data.get('final_response', ''))
        if len(final_resp) > 500:
            final_resp = final_resp[:500] + "..."
        
        report_text += f"*Réponse Finale (extrait)*: ```\n{_sanitize_text(final_resp)}\n```\n"
        report_text += f"*Durée Totale*: `{report_data.get('duration', 0):.2f}s`\n"
        report_text += f"*Statut*: {'✅ Succès' if not report_data.get('error') else f'❌ Échec: {_sanitize_text(report_data.get("error"))}'}"

        await _send_log(report_text)
    except Exception as e:
        print(f"❌ ERREUR CRITIQUE (log_structured_report): {e}")
        await log_system_event("LOGGING_ERROR", f"Échec de la création du rapport structuré: {e}")
```

# api_clients.py

import os
from pathlib import Path
from typing import Dict, Any, List, Optional, Tuple, Union
from datetime import datetime
import requests
import json
import asyncio
import httpx
from typing import Dict, Any, List, Optional, Tuple, Union # Redondant, mais laissé tel quel si c'était dans l'original
import logging
import random
import google.generativeai as genai
from google.generativeai import types

# AJOUT 1: Importer la nouvelle fonction de logging et les dépendances
from telegram_logger import log_api_call_to_telegram
from config import config
from app_singletons import endpoint_health_manager, quota_manager
from utils import log_message

class ApiClient:
    """
    Classe de base pour tous les clients API des 7 cerveaux autonomes.
    Gère les requêtes HTTP, la rotation des clés et le basculement automatique.
    ### MODIFICATION : Intégration du logging systématique.
    """
    def __init__(self, service_name: str, config_manager: Any,
                 health_manager: Any, quota_manager: Any):
        self.service_name = service_name
        self.config = config_manager
        self.health_manager = health_manager
        self.quota_manager = quota_manager
        self.endpoints = self.config.API_CONFIG.get(service_name, [])
        self.current_endpoint_index = 0
        self.last_rotation_time = datetime.now()

        if not self.endpoints:
            log_message(f"Aucun endpoint configuré pour le service {service_name}", level="warning")

    async def _make_request(self, endpoint_config: Dict[str, Any],
                          url_suffix: str = "", params: Optional[Dict] = None,
                          json_data: Optional[Dict] = None,
                          files: Optional[Dict] = None) -> Union[Dict, str]:
        """Effectue une requête HTTP et logue l'activité sur Telegram."""
        full_url = endpoint_config["url"] + url_suffix
        method = endpoint_config["method"]
        timeout = endpoint_config.get("timeout", 30)
        headers = endpoint_config.get("fixed_headers", {}).copy()
        req_params = endpoint_config.get("fixed_params", {}).copy()

        if params:
            req_params.update(params)

        key_field = endpoint_config.get("key_field")
        key_location = endpoint_config.get("key_location")
        key = endpoint_config.get("key")
        key_prefix = endpoint_config.get("key_prefix", "")
        endpoint_name = endpoint_config.get("endpoint_name", "Unknown Endpoint")

        if key:
            if key_location == "header":
                headers[key_field] = f"{key_prefix}{key}"
            elif key_location == "param":
                req_params[key_field] = key
            elif key_location == "auth_basic" and isinstance(key, tuple) and len(key) == 2:
                pass

        start_time = asyncio.get_event_loop().time()
        
        try:
            async with httpx.AsyncClient() as client:
                log_message(f"Requête {self.service_name} vers {full_url}")

                request_kwargs = {
                    "params": req_params,
                    "headers": headers,
                    "timeout": timeout
                }

                if json_data:
                    request_kwargs["json"] = json_data
                if files:
                    request_kwargs["files"] = files
                if key_location == "auth_basic" and isinstance(key, tuple) and len(key) == 2:
                    request_kwargs["auth"] = key

                if method == "POST":
                    response = await client.post(full_url, **request_kwargs)
                elif method == "GET":
                    response = await client.get(full_url, **request_kwargs)
                else:
                    raise ValueError(f"Méthode HTTP non supportée: {method}")

                latency_ms = int((asyncio.get_event_loop().time() - start_time) * 1000)
                response.raise_for_status()
                
                log_message(f"Réponse {self.service_name}: {response.status_code} en {latency_ms/1000:.2f}s")

                # AJOUT: Loguer le SUCCÈS à Telegram
                await log_api_call_to_telegram(
                    service_name=self.service_name,
                    endpoint_name=endpoint_name,
                    api_key=str(key),
                    success=True,
                    status_code=response.status_code,
                    latency_ms=latency_ms
                )

                try:
                    return response.json()
                except json.JSONDecodeError:
                    return {"status": "success", "content": response.text}

        except httpx.HTTPStatusError as e:
            latency_ms = int((asyncio.get_event_loop().time() - start_time) * 1000)
            log_message(f"API {self.service_name} erreur HTTP: {e.response.status_code} - {e.response.text}", level="warning")
            
            # AJOUT: Loguer l'ÉCHEC (Erreur HTTP) à Telegram
            await log_api_call_to_telegram(
                service_name=self.service_name,
                endpoint_name=endpoint_name,
                api_key=str(key),
                success=False,
                status_code=e.response.status_code,
                latency_ms=latency_ms,
                error_message=f"HTTP Status {e.response.status_code}"
            )
            # La gestion du marquage unhealthy est maintenant gérée par l'AutonomousParticipant.
            return f"❌ Erreur API {self.service_name}: {e.response.status_code} - {e.response.text}"

        except httpx.RequestError as e:
            latency_ms = int((asyncio.get_event_loop().time() - start_time) * 1000)
            log_message(f"API {self.service_name} erreur réseau: {e}", level="warning")

            # AJOUT: Loguer l'ÉCHEC (Erreur Réseau) à Telegram
            await log_api_call_to_telegram(
                service_name=self.service_name,
                endpoint_name=endpoint_name,
                api_key=str(key),
                success=False,
                status_code=None, # Pas de code de statut pour une erreur réseau
                latency_ms=latency_ms,
                error_message=f"Network Error: {type(e).__name__}"
            )
            # La gestion du marquage unhealthy est maintenant gérée par l'AutonomousParticipant.
            return f"❌ Erreur réseau pour {self.service_name}: {e}"

        except Exception as e:
            latency_ms = int((asyncio.get_event_loop().time() - start_time) * 1000)
            log_message(f"API {self.service_name} erreur inattendue: {e}", level="error")

            # AJOUT: Loguer l'ÉCHEC (Erreur Inattendue) à Telegram
            await log_api_call_to_telegram(
                service_name=self.service_name,
                endpoint_name=endpoint_name,
                api_key=str(key),
                success=False,
                status_code=None,
                latency_ms=latency_ms,
                error_message=f"Unexpected Error: {type(e).__name__}"
            )
            # La gestion du marquage unhealthy est maintenant gérée par l'AutonomousParticipant.
            return f"❌ Erreur inattendue pour {self.service_name}: {e}"

    async def _get_available_endpoint(self) -> List[Dict[str, Any]]:
        """
        Retourne la liste complète de tous les endpoints configurés pour ce service.
        La logique de sélection et de rotation est déplacée vers l'Agent Autonome.
        """
        if not self.endpoints:
            log_message(f"Aucun endpoint configuré pour le service {self.service_name}.", level="warning")
            return []
        return self.endpoints

    async def _increment_quota(self, success: bool = True):
        """Incrémente le quota pour le service, en indiquant si l'opération a réussi."""
        await self.quota_manager.increment_quota(self.service_name, success=success)

    async def execute_with_specific_config(
        self,
        endpoint_config: Dict[str, Any],
        url_suffix: str = "",
        params: Optional[Dict] = None,
        json_data: Optional[Dict] = None,
        files: Optional[Dict] = None
    ) -> Union[Dict, str]:
        """
        Exécute une requête en utilisant une configuration de clé/endpoint spécifique.
        """
        if not endpoint_config:
            return f"❌ Erreur d'exécution : Aucune configuration d'endpoint fournie pour {self.service_name}."

        log_message(f"Exécution forcée pour {self.service_name} avec l'endpoint: {endpoint_config.get('endpoint_name')}")

        has_quota = await self.quota_manager.check_quota(self.service_name)
        if not has_quota:
            return f"❌ Quota dépassé pour le service {self.service_name}."

        result = await self._make_request(
            endpoint_config=endpoint_config,
            url_suffix=url_suffix,
            params=params,
            json_data=json_data,
            files=files
        )

        # Détermine si la requête a réussi pour l'incrémentation du quota
        request_success = not (isinstance(result, str) and result.startswith("❌"))
        await self._increment_quota(success=request_success)
        return result

class LLMApiClient(ApiClient):
    """Classe de base pour les clients d'API de modèles de langage."""
    def __init__(self, service_name: str, config_manager: Any,
                 health_manager: Any, quota_manager: Any):
        super().__init__(service_name, config_manager, health_manager, quota_manager)
        self.default_model: str = ""

    async def generate_content(self, endpoint_config: Dict[str, Any], # MODIFIÉ
                              prompt: Union[str, List[Dict[str, Any]]],
                              chat_history: List[Dict[str, Any]],
                              image_data: Optional[str] = None,
                              tools: Optional[List[Dict]] = None,
                              model_name: Optional[str] = None) -> Union[Dict, str]:
        """Méthode abstraite pour générer du contenu."""
        raise NotImplementedError("La méthode 'generate_content' doit être implémentée par les sous-classes.")

class GeminiApiClient(LLMApiClient):
    """Client API pour Gemini avec support complet des 7 cerveaux autonomes."""
    def __init__(self, health_manager: Any, quota_manager: Any):
        super().__init__("GEMINI_API", config, health_manager, quota_manager)
        self.default_model = "gemini-1.5-flash-latest"
        log_message(f"GeminiApiClient initialisé avec le modèle par défaut: {self.default_model}")

    async def generate_content(self, endpoint_config: Dict[str, Any], # MODIFIÉ
                              prompt: Union[str, List[Dict[str, Any]]],
                              chat_history: List[Dict[str, Any]],
                              image_data: Optional[str] = None,
                              tools: Optional[List[Dict]] = None,
                              model_name: Optional[str] = None) -> Union[Dict, str]:
        """Génère du contenu textuel en utilisant le modèle Gemini."""
        log_message(f"Appel à Gemini API pour le modèle {model_name or self.default_model} via endpoint: {endpoint_config.get('endpoint_name', 'N/A')}")

        if not endpoint_config or not endpoint_config.get("key"):
            return f"❌ Erreur Gemini: Configuration d'endpoint ou clé API manquante."

        genai.configure(api_key=endpoint_config["key"])
        log_message(f"Configuration de genai avec la clé de l'endpoint: {endpoint_config['endpoint_name']}")

        contents = []
        for msg in chat_history:
            formatted_parts = []
            for part in msg.get("parts", []):
                if "text" in part:
                    formatted_parts.append(part["text"])
                elif "function_response" in part:
                    formatted_parts.append(genai.types.FunctionResponse(
                        name=part["function_response"]["name"],
                        response=part["function_response"]["response"]
                    ))
                elif "function_call" in part:
                    formatted_parts.append(genai.types.FunctionCall(
                        name=part["function_call"]["name"],
                        args=part["function_call"]["args"]
                    ))
                elif "inlineData" in part:
                    formatted_parts.append(genai.types.Blob(
                        mime_type=part["inlineData"]["mimeType"],
                        data=part["inlineData"]["data"]
                    ))
            contents.append({"role": msg["role"], "parts": formatted_parts})

        user_parts = []
        if isinstance(prompt, str):
            user_parts.append(prompt)
        elif isinstance(prompt, list):
            user_parts.extend(prompt)

        if image_data:
            mime_type = image_data.split(';')[0].split(':')[1]
            base64_string = image_data.split(',')[1]
            user_parts.append(genai.types.Blob(mime_type=mime_type, data=base64_string))

        contents.append({"role": "user", "parts": user_parts})

        genai_tools = None
        if tools:
            genai_tools = [genai.types.FunctionDeclaration(**tool["function_declarations"][0]) 
                          for tool in tools if "function_declarations" in tool and tool["function_declarations"]]

        try:
            model_to_use = model_name if model_name else self.default_model
            model_instance = genai.GenerativeModel(model_to_use, tools=genai_tools)

            response = await model_instance.generate_content_async(
                contents=contents,
                generation_config=genai.types.GenerationConfig(
                    temperature=config.GEMINI_TEMPERATURE,
                    top_p=config.GEMINI_TOP_P,
                    top_k=config.GEMINI_TOP_K,
                    max_output_tokens=config.GEMINI_MAX_OUTPUT_TOKENS,
                ),
                safety_settings=config.GEMINI_SAFETY_SETTINGS,
            )

            response_dict = response.to_dict()
            return response_dict

        except Exception as e:
            log_message(f"API GEMINI_API erreur sur l'endpoint {endpoint_config['endpoint_name']}: {e}", level="error")
            # La gestion du marquage unhealthy et de l'incrémentation du quota (avec succès=False)
            # est maintenant gérée par l'AutonomousParticipant.
            # Ici, nous nous contentons de retourner l'erreur.
            return f"❌ Erreur Gemini: {e}"

class TelegramBotClient(ApiClient):
    """Client API pour l'API Bot de Telegram."""
    def __init__(self, health_manager: Any, quota_manager: Any):
        super().__init__("TELEGRAM_BOT", config, health_manager, quota_manager)
        
        if not self.endpoints:
            self.endpoints.append({
                "endpoint_name": "Telegram Bot API",
                "url": f"https://api.telegram.org/bot{config.TELEGRAM_BOT_TOKEN}",
                "method": "POST",
                "key_field": None,
                "key_location": None,
                "key": config.TELEGRAM_BOT_TOKEN,
                "timeout": 10,
                "fixed_headers": {"Content-Type": "application/json"},
                "health_check_url_suffix": "/getMe",
                "health_check_json": {}
            })
        log_message("TelegramBotClient initialisé.")

    async def send_message(self, endpoint_config: Dict[str, Any], # AJOUTÉ
                           chat_id: Union[int, str], text: str, parse_mode: Optional[str] = None) -> Union[Dict, str]:
        """Envoie un message texte à un chat Telegram spécifié."""
        if not endpoint_config: # AJOUTÉ
            return f"❌ Erreur Telegram: Configuration d'endpoint manquante." # AJOUTÉ

        json_data = {
            "chat_id": chat_id,
            "text": text,
        }
        if parse_mode:
            json_data["parse_mode"] = parse_mode

        send_message_url_suffix = "/sendMessage"
        return await self._make_request(endpoint_config, url_suffix=send_message_url_suffix, json_data=json_data)

class WebContainerClient(ApiClient):
    def __init__(self, health_manager: Any, quota_manager: Any):
        super().__init__("WEBCONTAINER", config, health_manager, quota_manager)

    async def run_code(self, endpoint_config: Dict[str, Any], # AJOUTÉ
                       code: str, language: str = "javascript") -> Union[Dict, str]:
        if not endpoint_config:
            return f"❌ Erreur WebContainer: Configuration d'endpoint manquante."

        json_data = {
            "action": "execute",
            "language": language,
            "code": code
        }
        return await self._make_request(endpoint_config, json_data=json_data)

class OCRApiClient(ApiClient):
    def __init__(self, health_manager: Any, quota_manager: Any):
        super().__init__("OCR_API", config, health_manager, quota_manager)

    async def parse_image(self, endpoint_config: Dict[str, Any], # AJOUTÉ
                          image_base64: str, language: str = "eng") -> Union[Dict, str]:
        if not endpoint_config:
            return f"❌ Erreur OCR: Configuration d'endpoint manquante."

        json_data = {
            "base64Image": image_base64,
            "language": language,
            "isOverlayRequired": False
        }
        return await self._make_request(endpoint_config, json_data=json_data)

class DeepSeekClient(ApiClient):
    def __init__(self, health_manager: Any, quota_manager: Any):
        super().__init__("DEEPSEEK", config, health_manager, quota_manager)

    async def chat_completion(self, endpoint_config: Dict[str, Any], # AJOUTÉ
                              messages: List[Dict[str, str]], model: str = "deepseek-chat") -> Union[Dict, str]:
        if not endpoint_config:
            return f"❌ Erreur DeepSeek: Configuration d'endpoint manquante."

        json_data = {
            "model": model,
            "messages": messages
        }
        return await self._make_request(endpoint_config, json_data=json_data)

class SerperClient(ApiClient):
    def __init__(self, health_manager: Any, quota_manager: Any):
        super().__init__("SERPER", config, health_manager, quota_manager)

    async def search(self, endpoint_config: Dict[str, Any], # AJOUTÉ
                     query: str) -> Union[Dict, str]:
        if not endpoint_config:
            return f"❌ Erreur Serper: Configuration d'endpoint manquante."

        json_data = {"q": query}
        return await self._make_request(endpoint_config, json_data=json_data)

class WolframAlphaClient(ApiClient):
    def __init__(self, health_manager: Any, quota_manager: Any):
        super().__init__("WOLFRAMALPHA", config, health_manager, quota_manager)

    async def query(self, endpoint_config: Dict[str, Any], # AJOUTÉ
                    input_text: str) -> Union[Dict, str]:
        if not endpoint_config:
            return f"❌ Erreur WolframAlpha: Configuration d'endpoint manquante."

        params = {"input": input_text, "output": "json"}
        return await self._make_request(endpoint_config, params=params)

class TavilyClient(ApiClient):
    def __init__(self, health_manager: Any, quota_manager: Any):
        super().__init__("TAVILY", config, health_manager, quota_manager)

    async def search(self, endpoint_config: Dict[str, Any], # AJOUTÉ
                     query: str, max_results: int = 3) -> Union[Dict, str]:
        if not endpoint_config:
            return f"❌ Erreur Tavily: Configuration d'endpoint manquante."

        json_data = {"query": query, "max_results": max_results}
        return await self._make_request(endpoint_config, json_data=json_data)

class ApiFlashClient(ApiClient):
    def __init__(self, health_manager: Any, quota_manager: Any):
        super().__init__("APIFLASH", config, health_manager, quota_manager)

    async def screenshot(self, endpoint_config: Dict[str, Any], # AJOUTÉ
                         url: str) -> Union[Dict, str]:
        if not endpoint_config:
            return f"❌ Erreur ApiFlash: Configuration d'endpoint manquante."

        params = {"url": url, "format": "jpeg"}
        return await self._make_request(endpoint_config, params=params)

class CrawlbaseClient(ApiClient):
    def __init__(self, health_manager: Any, quota_manager: Any):
        super().__init__("CRAWLBASE", config, health_manager, quota_manager)

    async def scrape(self, endpoint_config: Dict[str, Any], # AJOUTÉ
                     url: str, use_js: bool = False) -> Union[Dict, str]:
        if not endpoint_config:
            return f"❌ Erreur Crawlbase: Configuration d'endpoint manquante."

        params = {"url": url}
        if use_js:
            params["javascript"] = "true"
        return await self._make_request(endpoint_config, params=params)

class DetectLanguageClient(ApiClient):
    def __init__(self, health_manager: Any, quota_manager: Any):
        super().__init__("DETECTLANGUAGE", config, health_manager, quota_manager)

    async def detect(self, endpoint_config: Dict[str, Any], # AJOUTÉ
                     text: str) -> Union[Dict, str]:
        if not endpoint_config:
            return f"❌ Erreur DetectLanguage: Configuration d'endpoint manquante."

        json_data = {"q": text}
        return await self._make_request(endpoint_config, json_data=json_data)

class GuardianClient(ApiClient):
    def __init__(self, health_manager: Any, quota_manager: Any):
        super().__init__("GUARDIAN", config, health_manager, quota_manager)

    async def search_news(self, endpoint_config: Dict[str, Any], # AJOUTÉ
                          query: str) -> Union[Dict, str]:
        if not endpoint_config:
            return f"❌ Erreur Guardian: Configuration d'endpoint manquante."

        params = {"q": query}
        return await self._make_request(endpoint_config, params=params)

class IP2LocationClient(ApiClient):
    def __init__(self, health_manager: Any, quota_manager: Any):
        super().__init__("IP2LOCATION", config, health_manager, quota_manager)

    async def geolocate_ip(self, endpoint_config: Dict[str, Any], # AJOUTÉ
                           ip_address: str) -> Union[Dict, str]:
        if not endpoint_config:
            return f"❌ Erreur IP2Location: Configuration d'endpoint manquante."

        params = {"ip": ip_address, "package": "WS24", "format": "json"}
        return await self._make_request(endpoint_config, params=params)

class ShodanClient(ApiClient):
    def __init__(self, health_manager: Any, quota_manager: Any):
        super().__init__("SHODAN", config, health_manager, quota_manager)

    async def get_info(self, endpoint_config: Dict[str, Any], # AJOUTÉ
                       query_text: str = "") -> Union[Dict, str]:
        if not endpoint_config:
            return f"❌ Erreur Shodan: Configuration d'endpoint manquante."

        if query_text:
            url_suffix = f"/{query_text}"
            return await self._make_request(endpoint_config, url_suffix=url_suffix)
        else:
            api_info_endpoint = next((ep for ep in self.endpoints if "API Info" in ep.get("endpoint_name", "")), None)
            if api_info_endpoint:
                return await self._make_request(api_info_endpoint)
            else:
                return "❌ Erreur Shodan: Endpoint 'API Info' non trouvé dans la configuration."

class WeatherAPIClient(ApiClient):
    def __init__(self, health_manager: Any, quota_manager: Any):
        super().__init__("WEATHERAPI", config, health_manager, quota_manager)

    async def get_current_weather(self, endpoint_config: Dict[str, Any], # AJOUTÉ
                                  location: str) -> Union[Dict, str]:
        if not endpoint_config:
            return f"❌ Erreur WeatherAPI: Configuration d'endpoint manquante."

        params = {"q": location}
        return await self._make_request(endpoint_config, params=params)

class CloudmersiveClient(ApiClient):
    def __init__(self, health_manager: Any, quota_manager: Any):
        super().__init__("CLOUDMERSIVE", config, health_manager, quota_manager)

    async def validate_domain(self, endpoint_config: Dict[str, Any], # AJOUTÉ
                              domain: str) -> Union[Dict, str]:
        if not endpoint_config:
            return f"❌ Erreur Cloudmersive: Configuration d'endpoint manquante."

        json_data = {"domain": domain}
        return await self._make_request(endpoint_config, json_data=json_data)

class GreyNoiseClient(ApiClient):
    def __init__(self, health_manager: Any, quota_manager: Any):
        super().__init__("GREYNOISE", config, health_manager, quota_manager)

    async def ip_lookup(self, endpoint_config: Dict[str, Any], # AJOUTÉ
                        ip_address: str) -> Union[Dict, str]:
        if not endpoint_config:
            return f"❌ Erreur GreyNoise: Configuration d'endpoint manquante."

        url_suffix = f"/{ip_address}"
        return await self._make_request(endpoint_config, url_suffix=url_suffix)

class PulsediveClient(ApiClient):
    def __init__(self, health_manager: Any, quota_manager: Any):
        super().__init__("PULSEDIVE", config, health_manager, quota_manager)

    async def analyze_indicator(self, endpoint_config: Dict[str, Any], # AJOUTÉ
                                indicator: str, type: str = "auto") -> Union[Dict, str]:
        if not endpoint_config:
            return f"❌ Erreur Pulsedive: Configuration d'endpoint manquante."

        params = {"indicator": indicator, "type": type}
        return await self._make_request(endpoint_config, params=params)

class StormGlassClient(ApiClient):
    def __init__(self, health_manager: Any, quota_manager: Any):
        super().__init__("STORMGLASS", config, health_manager, quota_manager)

    async def get_weather_point(self, endpoint_config: Dict[str, Any], # AJOUTÉ
                                lat: float, lng: float, params: str = "airTemperature,waveHeight") -> Union[Dict, str]:
        if not endpoint_config:
            return f"❌ Erreur StormGlass: Configuration d'endpoint manquante."

        req_params = {"lat": lat, "lng": lng, "params": params}
        return await self._make_request(endpoint_config, params=req_params)

class LoginRadiusClient(ApiClient):
    def __init__(self, health_manager: Any, quota_manager: Any):
        super().__init__("LOGINRADIUS", config, health_manager, quota_manager)

    async def ping(self, endpoint_config: Dict[str, Any]) -> Union[Dict, str]: # AJOUTÉ
        if not endpoint_config:
            return f"❌ Erreur LoginRadius: Configuration d'endpoint manquante."

        return await self._make_request(endpoint_config)

class JsonbinClient(ApiClient):
    def __init__(self, health_manager: Any, quota_manager: Any):
        super().__init__("JSONBIN", config, health_manager, quota_manager)

    async def handle_bin(self, endpoint_config: Dict[str, Any], # AJOUTÉ
                         data: Optional[Dict] = None, private: bool = True, bin_id: Optional[str] = None) -> Union[Dict, str]:
        if not endpoint_config:
            return f"❌ Erreur Jsonbin: Configuration d'endpoint manquante."

        if bin_id:
            # The caller (AutonomousParticipant) should provide the correct endpoint_config for Bin Access.
            if "Bin Access" in endpoint_config.get("endpoint_name", ""):
                return await self._make_request(endpoint_config, url_suffix=f"/{bin_id}")
            else:
                return "❌ Erreur Jsonbin: Endpoint 'Bin Access' non fourni pour accéder à un bin."
        elif data:
            # The caller (AutonomousParticipant) should provide the correct endpoint_config for Bin Create.
            if "Bin Create" in endpoint_config.get("endpoint_name", ""):
                json_data = {"record": data, "private": private}
                return await self._make_request(endpoint_config, json_data=json_data)
            else:
                return "❌ Erreur Jsonbin: Endpoint 'Bin Create' non fourni pour créer un bin."
        else:
            return "❌ Erreur Jsonbin: Veuillez fournir des données pour créer un bin ou un ID de bin pour y accéder."

class HuggingFaceClient(ApiClient):
    def __init__(self, health_manager: Any, quota_manager: Any):
        super().__init__("HUGGINGFACE", config, health_manager, quota_manager)

    async def inference(self, endpoint_config: Dict[str, Any], # AJOUTÉ
                        model_name: str, input_text: str) -> Union[Dict, str]:
        if not endpoint_config:
            return f"❌ Erreur HuggingFace: Configuration d'endpoint manquante."

        url_suffix = model_name
        json_data = {"inputs": input_text}
        return await self._make_request(endpoint_config, url_suffix=url_suffix, json_data=json_data)

class TwilioClient(ApiClient):
    def __init__(self, health_manager: Any, quota_manager: Any):
        super().__init__("TWILIO", config, health_manager, quota_manager)

    async def get_account_balance(self, endpoint_config: Dict[str, Any]) -> Union[Dict, str]: # AJOUTÉ
        if not endpoint_config:
            return f"❌ Erreur Twilio: Configuration d'endpoint manquante."

        return await self._make_request(endpoint_config)

class AbstractAPIClient(ApiClient):
    def __init__(self, health_manager: Any, quota_manager: Any):
        super().__init__("ABSTRACTAPI", config, health_manager, quota_manager)

    async def call_api(self, endpoint_config: Dict[str, Any], # AJOUTÉ
                       input_value: str, api_type: str) -> Union[Dict, str]:
        if not endpoint_config:
            return f"❌ Erreur AbstractAPI: Configuration d'endpoint manquante."

        params = {}
        url_suffix = ""

        # The caller (AutonomousParticipant) should provide the correct endpoint_config for the specific api_type.
        # We assume endpoint_config is already the correct one for the requested api_type.
        if api_type == "EMAIL_VALIDATION":
            params["email"] = input_value
        elif api_type == "PHONE_VALIDATION":
            params["phone"] = input_value
        elif api_type == "EXCHANGE_RATES":
            params["base"] = input_value
        elif api_type == "HOLIDAYS":
            params["country"] = input_value
            params["year"] = datetime.now().year
        else:
            return f"❌ Type d'API AbstractAPI non supporté: {api_type}"

        return await self._make_request(endpoint_config, params=params, url_suffix=url_suffix)

class GoogleCustomSearchClient(ApiClient):
    def __init__(self, health_manager: Any, quota_manager: Any):
        super().__init__("GOOGLE_CUSTOM_SEARCH", config, health_manager, quota_manager)

    async def search(self, endpoint_config: Dict[str, Any], # AJOUTÉ
                     query: str) -> Union[Dict, str]:
        if not endpoint_config:
            return f"❌ Erreur Google Custom Search: Configuration d'endpoint manquante."

        params = {"q": query}
        return await self._make_request(endpoint_config, params=params)

class RandommerClient(ApiClient):
    def __init__(self, health_manager: Any, quota_manager: Any):
        super().__init__("RANDOMMER", config, health_manager, quota_manager)

    async def generate_phone_number(self, endpoint_config: Dict[str, Any], # AJOUTÉ
                                    country_code: str = "US", quantity: int = 1) -> Union[Dict, str]:
        if not endpoint_config:
            return f"❌ Erreur Randommer: Configuration d'endpoint manquante."

        params = {"CountryCode": country_code, "Quantity": quantity}
        return await self._make_request(endpoint_config, params=params)

class TomorrowIOClient(ApiClient):
    def __init__(self, health_manager: Any, quota_manager: Any):
        super().__init__("TOMORROW.IO", config, health_manager, quota_manager)

    async def get_weather_timelines(self, endpoint_config: Dict[str, Any], # AJOUTÉ
                                    location: str, fields: List[str]) -> Union[Dict, str]:
        if not endpoint_config:
            return f"❌ Erreur Tomorrow.io: Configuration d'endpoint manquante."

        json_data = {
            "location": location,
            "fields": fields,
            "units": "metric",
            "timesteps": ["1h"]
        }
        return await self._make_request(endpoint_config, json_data=json_data)

class OpenWeatherMapClient(ApiClient):
    def __init__(self, health_manager: Any, quota_manager: Any):
        super().__init__("OPENWEATHERMAP", config, health_manager, quota_manager)

    async def get_current_weather(self, endpoint_config: Dict[str, Any], # AJOUTÉ
                                  location: str) -> Union[Dict, str]:
        if not endpoint_config:
            return f"❌ Erreur OpenWeatherMap: Configuration d'endpoint manquante."

        params = {"q": location}
        return await self._make_request(endpoint_config, params=params)

class MockarooClient(ApiClient):
    def __init__(self, health_manager: Any, quota_manager: Any):
        super().__init__("MOCKAROO", config, health_manager, quota_manager)

    async def generate_data(self, endpoint_config: Dict[str, Any], # AJOUTÉ
                            count: int = 1, fields_json: Optional[str] = None) -> Union[Dict, str]:
        if not endpoint_config:
            return f"❌ Erreur Mockaroo: Configuration d'endpoint manquante."

        params = {"count": count}
        if fields_json:
            params["fields"] = fields_json
        return await self._make_request(endpoint_config, params=params)

class OpenPageRankClient(ApiClient):
    def __init__(self, health_manager: Any, quota_manager: Any):
        super().__init__("OPENPAGERANK", config, health_manager, quota_manager)

    async def get_page_rank(self, endpoint_config: Dict[str, Any], # AJOUTÉ
                            domains: List[str]) -> Union[Dict, str]:
        if not endpoint_config:
            return f"❌ Erreur OpenPageRank: Configuration d'endpoint manquante."

        params = {"domains[]": domains}
        return await self._make_request(endpoint_config, params=params)

class RapidAPIClient(ApiClient):
    def __init__(self, health_manager: Any, quota_manager: Any):
        super().__init__("RAPIDAPI", config, health_manager, quota_manager)

    async def call_rapidapi_endpoint(self, endpoint_config: Dict[str, Any], # AJOUTÉ
                                     api_name: str, api_kwargs: Optional[Dict] = None) -> Union[Dict, str]:
        if not endpoint_config:
            return f"❌ Erreur RapidAPI: Configuration d'endpoint manquante."

        # The caller (AutonomousParticipant) should provide the correct endpoint_config for the specific api_name.
        # We assume endpoint_config is already the correct one for the requested api_name.
        params = api_kwargs if api_kwargs else {}
        return await self._make_request(endpoint_config, params=params)
       
  # app_clients_instances.py

import google.generativeai as genai
from google.generativeai import types
import asyncio
from typing import Dict, Any, List, Optional, Union

from config import config
from app_singletons import endpoint_health_manager, quota_manager
from api_clients import (
    ApiClient, WebContainerClient, OCRApiClient, DeepSeekClient, SerperClient,
    WolframAlphaClient, TavilyClient, ApiFlashClient, CrawlbaseClient,
    DetectLanguageClient, GuardianClient, IP2LocationClient, ShodanClient,
    WeatherAPIClient, CloudmersiveClient, GreyNoiseClient, PulsediveClient,
    StormGlassClient, LoginRadiusClient, JsonbinClient, HuggingFaceClient,
    TwilioClient, AbstractAPIClient, GoogleCustomSearchClient,
    RandommerClient, TomorrowIOClient, OpenWeatherMapClient, MockarooClient,
    OpenPageRankClient, RapidAPIClient,
    GeminiApiClient, TelegramBotClient
)
from utils import log_message

# Instanciation de tous les clients API pour les 7 cerveaux autonomes
# Chaque client est instancié avec les gestionnaires de santé et de quotas

# Clients principaux pour les 7 cerveaux
gemini_client = GeminiApiClient(endpoint_health_manager, quota_manager)
telegram_bot_client = TelegramBotClient(endpoint_health_manager, quota_manager)

# Clients pour services auxiliaires
webcontainer_client = WebContainerClient(endpoint_health_manager, quota_manager)
ocr_client = OCRApiClient(endpoint_health_manager, quota_manager)
deepseek_client = DeepSeekClient(endpoint_health_manager, quota_manager)
serper_client = SerperClient(endpoint_health_manager, quota_manager)
wolfram_alpha_client = WolframAlphaClient(endpoint_health_manager, quota_manager)
tavily_client = TavilyClient(endpoint_health_manager, quota_manager)
apiflash_client = ApiFlashClient(endpoint_health_manager, quota_manager)
crawlbase_client = CrawlbaseClient(endpoint_health_manager, quota_manager)
detect_language_client = DetectLanguageClient(endpoint_health_manager, quota_manager)
guardian_client = GuardianClient(endpoint_health_manager, quota_manager)
ip2location_client = IP2LocationClient(endpoint_health_manager, quota_manager)
shodan_client = ShodanClient(endpoint_health_manager, quota_manager)
weather_api_client = WeatherAPIClient(endpoint_health_manager, quota_manager)
cloudmersive_client = CloudmersiveClient(endpoint_health_manager, quota_manager)
greynoise_client = GreyNoiseClient(endpoint_health_manager, quota_manager)
pulsedive_client = PulsediveClient(endpoint_health_manager, quota_manager)
stormglass_client = StormGlassClient(endpoint_health_manager, quota_manager)
loginradius_client = LoginRadiusClient(endpoint_health_manager, quota_manager)
jsonbin_client = JsonbinClient(endpoint_health_manager, quota_manager)
huggingface_client = HuggingFaceClient(endpoint_health_manager, quota_manager)
twilio_client = TwilioClient(endpoint_health_manager, quota_manager)
abstractapi_client = AbstractAPIClient(endpoint_health_manager, quota_manager)
google_custom_search_client = GoogleCustomSearchClient(endpoint_health_manager, quota_manager)
randommer_client = RandommerClient(endpoint_health_manager, quota_manager)
tomorrow_io_client = TomorrowIOClient(endpoint_health_manager, quota_manager)
openweathermap_client = OpenWeatherMapClient(endpoint_health_manager, quota_manager)
mockaroo_client = MockarooClient(endpoint_health_manager, quota_manager)
openpagerank_client = OpenPageRankClient(endpoint_health_manager, quota_manager)
rapidapi_client = RapidAPIClient(endpoint_health_manager, quota_manager)

# Log de l'initialisation
log_message("Tous les clients API ont été instanciés pour les 7 cerveaux autonomes")

# Dictionnaire pour accès facile aux clients
API_CLIENTS = {
    "GEMINI": gemini_client,
    "TELEGRAM": telegram_bot_client,
    "WEBCONTAINER": webcontainer_client,
    "OCR": ocr_client,
    "DEEPSEEK": deepseek_client,
    "SERPER": serper_client,
    "WOLFRAM": wolfram_alpha_client,
    "TAVILY": tavily_client,
    "APIFLASH": apiflash_client,
    "CRAWLBASE": crawlbase_client,
    "DETECT_LANGUAGE": detect_language_client,
    "GUARDIAN": guardian_client,
    "IP2LOCATION": ip2location_client,
    "SHODAN": shodan_client,
    "WEATHER_API": weather_api_client,
    "CLOUDMERSIVE": cloudmersive_client,
    "GREYNOISE": greynoise_client,
    "PULSEDIVE": pulsedive_client,
    "STORMGLASS": stormglass_client,
    "LOGINRADIUS": loginradius_client,
    "JSONBIN": jsonbin_client,
    "HUGGINGFACE": huggingface_client,
    "TWILIO": twilio_client,
    "ABSTRACTAPI": abstractapi_client,
    "GOOGLE_SEARCH": google_custom_search_client,
    "RANDOMMER": randommer_client,
    "TOMORROW_IO": tomorrow_io_client,
    "OPENWEATHERMAP": openweathermap_client,
    "MOCKAROO": mockaroo_client,
    "OPENPAGERANK": openpagerank_client,
    "RAPIDAPI": rapidapi_client
}

def get_client(service_name: str) -> Optional[ApiClient]:
    """Récupère un client API par nom de service."""
    return API_CLIENTS.get(service_name.upper())

def get_all_clients() -> Dict[str, ApiClient]:
    """Retourne tous les clients API disponibles."""
    return API_CLIENTS.copy()

async def get_healthy_clients() -> Dict[str, ApiClient]: # MODIFIÉ : ajout de 'async'
    """Retourne uniquement les clients avec des services sains."""
    healthy_clients = {}
    
    for service_name, client in API_CLIENTS.items():
        try:
            # Vérification asynchrone de la santé via endpoint_health_manager
            is_healthy = await endpoint_health_manager.is_service_healthy(service_name)
            if is_healthy:
                healthy_clients[service_name] = client
            else:
                log_message(f"Client {service_name} non sain, exclu de la liste des clients sains.", level="debug")
        except Exception as e:
            log_message(f"Erreur lors de la vérification de santé pour {service_name}: {e}", level="warning")
    
    return healthy_clients

async def test_all_clients() -> Dict[str, bool]:
    """Teste la connectivité de tous les clients."""
    results = {}
    
    for service_name, client in API_CLIENTS.items():
        try:
            # Test basique de connectivité
            if hasattr(client, '_get_available_endpoint'):
                endpoint = await client._get_available_endpoint()
                results[service_name] = endpoint is not None
            else:
                results[service_name] = True  # Assume healthy if no endpoint check
        except Exception as e:
            log_message(f"Erreur test client {service_name}: {e}", level="error")
            results[service_name] = False
    
    return results

# Fonctions utilitaires pour la gestion des clients

async def rotate_client_endpoints():
    """Force la rotation des endpoints pour tous les clients."""
    for service_name, client in API_CLIENTS.items():
        if hasattr(client, 'current_endpoint_index') and hasattr(client, 'endpoints'):
            if client.endpoints:
                client.current_endpoint_index = (client.current_endpoint_index + 1) % len(client.endpoints)
                log_message(f"Rotation forcée pour {service_name}, nouvel index: {client.current_endpoint_index}")

def get_client_statistics() -> Dict[str, Any]:
    """Retourne les statistiques des clients API."""
    stats = {
        "total_clients": len(API_CLIENTS),
        "services_configured": len(config.API_CONFIG),
        "clients_by_type": {},
        "endpoint_counts": {}
    }
    
    for service_name, client in API_CLIENTS.items():
        client_type = type(client).__name__
        if client_type not in stats["clients_by_type"]:
            stats["clients_by_type"][client_type] = 0
        stats["clients_by_type"][client_type] += 1
        
        if hasattr(client, 'endpoints'):
            stats["endpoint_counts"][service_name] = len(client.endpoints)
    
    return stats

# Validation de l'initialisation
def validate_clients_initialization() -> bool:
    """Valide que tous les clients essentiels sont initialisés."""
    essential_clients = ["GEMINI", "TELEGRAM", "DEEPSEEK", "SERPER", "WOLFRAM", "TAVILY"]
    
    for client_name in essential_clients:
        if client_name not in API_CLIENTS or API_CLIENTS[client_name] is None:
            log_message(f"Client essentiel {client_name} non initialisé", level="error")
            return False
    
    log_message("Tous les clients essentiels sont initialisés")
    return True

# Exécution de la validation
if validate_clients_initialization():
    log_message("✅ Initialisation des clients API réussie - Système prêt pour les 7 cerveaux autonomes")
else:
    log_message("❌ Erreur lors de l'initialisation des clients API", level="error")
    
import asyncio
import json
import logging
from datetime import datetime, timezone
from pathlib import Path
import re
import os
from typing import Any, Dict, List, Optional
import base64
import mimetypes

from config import config

# ==== Configuration du logging ====
logger = logging.getLogger("bot_logger")
logger.setLevel(logging.INFO)

# Crée le répertoire de base si nécessaire
config.BASE_DIR.mkdir(parents=True, exist_ok=True)

# Gestionnaire pour le fichier de log principal
file_handler = logging.FileHandler(config.LOG_FILE)
file_handler.setLevel(logging.INFO)
formatter = logging.Formatter('%(asctime)s - %(levelname)s - %(message)s')
file_handler.setFormatter(formatter)
logger.addHandler(file_handler)

# Gestionnaire pour les erreurs critiques
error_file_handler = logging.FileHandler(config.ERROR_LOG_PATH)
error_file_handler.setLevel(logging.ERROR)
error_file_handler.setFormatter(formatter)
logger.addHandler(error_file_handler)

# Gestionnaire pour la console
console_handler = logging.StreamHandler()
console_handler.setLevel(logging.INFO)
console_handler.setFormatter(formatter)
logger.addHandler(console_handler)

# Verrou pour les opérations de fichier asynchrones
_file_lock: Optional[asyncio.Lock] = None

def set_file_lock(lock: asyncio.Lock):
    """Définit l'instance du verrou asyncio pour les opérations de fichier."""
    global _file_lock
    _file_lock = lock
    log_message("Verrou de fichier initialisé dans utils.py.")

def log_message(message: str, level: str = "info"):
    """Enregistre un message dans le fichier de log et la console."""
    if level == "debug":
        logger.debug(message)
    elif level == "info":
        logger.info(message)
    elif level == "warning":
        logger.warning(message)
    elif level == "error":
        logger.error(message)
    elif level == "critical":
        logger.critical(message)
    else:
        logger.info(f"Niveau de log inconnu '{level}': {message}")

def get_current_time() -> datetime:
    """Retourne l'heure actuelle en UTC pour une cohérence temporelle."""
    return datetime.now(timezone.utc)

def format_datetime(dt: datetime) -> str:
    """Formate un objet datetime en chaîne de caractères lisible et standardisée."""
    return dt.strftime("%Y-%m-%d %H:%M:%S UTC")

async def load_json(file_path: Path, default_value: Any = None) -> Any:
    """
    Charge les données d'un fichier JSON de manière asynchrone.
    Crée le fichier avec une valeur par défaut si inexistant ou corrompu.
    """
    if _file_lock is None:
        log_message("Le verrou de fichier n'est pas initialisé avant l'appel à load_json.", level="critical")
        raise RuntimeError("File lock not initialized. Call set_file_lock in main.py first.")

    try:
        if not file_path.exists():
            log_message(f"Fichier non trouvé: {file_path}. Création avec valeur par défaut.", level="info")
            file_path.parent.mkdir(parents=True, exist_ok=True)
            await save_json(file_path, default_value if default_value is not None else {})
            return default_value if default_value is not None else {}

        async with _file_lock:
            return await asyncio.to_thread(_load_json_sync, file_path)
    except json.JSONDecodeError:
        log_message(f"Erreur de décodage JSON pour le fichier: {file_path}. Réinitialisation avec la valeur par défaut.", level="error")
        await save_json(file_path, default_value if default_value is not None else {})
        return default_value if default_value is not None else {}
    except Exception as e:
        log_message(f"Erreur inattendue lors du chargement du JSON {file_path}: {e}", level="error")
        return default_value if default_value is not None else {}

def _load_json_sync(file_path: Path) -> Any:
    """Fonction synchrone pour charger le JSON, exécutée dans un thread séparé."""
    with open(file_path, 'r', encoding='utf-8') as f:
        return json.load(f)

async def save_json(file_path: Path, data: Any):
    """Sauvegarde les données dans un fichier JSON de manière asynchrone."""
    if _file_lock is None:
        log_message("Le verrou de fichier n'est pas initialisé avant l'appel à save_json.", level="critical")
        raise RuntimeError("File lock not initialized. Call set_file_lock in main.py first.")

    try:
        file_path.parent.mkdir(parents=True, exist_ok=True)
        async with _file_lock:
            await asyncio.to_thread(_save_json_sync, file_path, data)
        log_message(f"Données sauvegardées dans {file_path}", level="debug")
    except Exception as e:
        log_message(f"Erreur lors de la sauvegarde du JSON {file_path}: {e}", level="error")

def _save_json_sync(file_path: Path, data: Any):
    """Fonction synchrone pour sauvegarder le JSON, exécutée dans un thread séparé."""
    with open(file_path, 'w', encoding='utf-8') as f:
        json.dump(data, f, indent=4, ensure_ascii=False)

def neutralize_urls(text: str) -> str:
    """
    Remplace les URLs dans le texte par une version neutralisée pour éviter les problèmes de sécurité.
    """
    url_pattern = re.compile(r'https?://[^\s/$.?#].[^\s]*', re.IGNORECASE)
    neutralized_text = url_pattern.sub("[LIEN_NEUTRALISÉ]", text)
    return neutralized_text

def find_tool_by_name(tool_name: str) -> Optional[Dict[str, Any]]:
    """Recherche un outil dans TOOL_CONFIG par son nom."""
    return config.TOOL_CONFIG.get(tool_name)

async def append_to_file(file_path: Path, content: str):
    """
    Ajoute du contenu à un fichier, en créant le fichier/répertoire si nécessaire.
    Gère la rotation du fichier si sa taille dépasse MAX_FILE_SIZE.
    """
    if _file_lock is None:
        log_message("Le verrou de fichier n'est pas initialisé avant l'appel à append_to_file.", level="critical")
        raise RuntimeError("File lock not initialized. Call set_file_lock in main.py first.")

    file_path.parent.mkdir(parents=True, exist_ok=True)

    if file_path.exists() and file_path.stat().st_size + len(content.encode('utf-8')) > config.MAX_FILE_SIZE:
        rotate_file(file_path)

    async with _file_lock:
        await asyncio.to_thread(_append_to_file_sync, file_path, content)

def _append_to_file_sync(file_path: Path, content: str):
    """Fonction synchrone pour ajouter du contenu à un fichier, exécutée dans un thread séparé."""
    with open(file_path, 'a', encoding='utf-8') as f:
        f.write(content + "\n")

def rotate_file(file_path: Path):
    """Effectue une rotation de fichier simple: renomme le fichier actuel avec un horodatage."""
    timestamp = datetime.now(timezone.utc).strftime("%Y%m%d_%H%M%S")
    new_path = file_path.parent / f"{file_path.stem}_{timestamp}{file_path.suffix}"
    try:
        os.rename(file_path, new_path)
        log_message(f"Fichier {file_path.name} renommé en {new_path.name} pour rotation.", level="info")
    except OSError as e:
        log_message(f"Erreur lors de la rotation du fichier {file_path.name}: {e}", level="error")

def get_mime_type_from_base64(base64_string: str) -> Optional[str]:
    """Tente de déterminer le type MIME à partir d'une chaîne base64."""
    if base64_string.startswith("data:"):
        parts = base64_string.split(",", 1)
        if len(parts) > 0:
            mime_part = parts[0]
            if ";" in mime_part:
                return mime_part.split(";", 1)[0].split(":", 1)[1]
            else:
                return mime_part.split(":", 1)[1]

    try:
        decoded_bytes = base64.b64decode(base64_string[:1024], validate=True)
        
        if decoded_bytes.startswith(b'\x89PNG\r\n\x1a\n'):
            return 'image/png'
        elif decoded_bytes.startswith(b'\xff\xd8\xff'):
            return 'image/jpeg'
        elif decoded_bytes.startswith(b'GIF87a') or decoded_bytes.startswith(b'GIF89a'):
            return 'image/gif'
        elif decoded_bytes.startswith(b'%PDF-'):
            return 'application/pdf'
        elif decoded_bytes.startswith(b'BM'):
            return 'image/bmp'
        elif decoded_bytes.startswith(b'RIFF') and decoded_bytes[8:12] == b'WEBP':
            return 'image/webp'
            
    except Exception as e:
        log_message(f"Erreur lors de la détection MIME pour base64: {e}", level="debug")

    return None

def extract_memories(text: str) -> List[Dict[str, Any]]:
    """
    Extrait les éléments de mémoire d'un texte de réponse.
    Extraction simple basée sur des mots-clés importants.
    """
    memories = []
    
    if "important" in text.lower():
        memories.append({"type": "important", "content": text[:200]})
        
    if "remember" in text.lower() or "rappel" in text.lower():
        memories.append({"type": "reminder", "content": text[:200]})
        
    if "erreur" in text.lower() or "error" in text.lower():
        memories.append({"type": "error", "content": text[:200]})
        
    if "succès" in text.lower() or "success" in text.lower():
        memories.append({"type": "success", "content": text[:200]})
    
    return memories

def validate_url(url: str) -> bool:
    """Valide une URL basique."""
    url_pattern = re.compile(
        r'^https?://'  # http:// ou https://
        r'(?:(?:[A-Z0-9](?:[A-Z0-9-]{0,61}[A-Z0-9])?\.)+[A-Z]{2,6}\.?|'  # domaine
        r'localhost|'  # localhost
        r'\d{1,3}\.\d{1,3}\.\d{1,3}\.\d{1,3})'  # IP
        r'(?::\d+)?'  # port optionnel
        r'(?:/?|[/?]\S+)$', re.IGNORECASE)
    return url_pattern.match(url) is not None

def sanitize_filename(filename: str) -> str:
    """Nettoie un nom de fichier pour le rendre sûr."""
    # Supprime ou remplace les caractères dangereux
    sanitized = re.sub(r'[<>:"/\\|?*]', '_', filename)
    # Limite la longueur
    if len(sanitized) > 100:
        sanitized = sanitized[:100]
    return sanitized.strip()

def format_file_size(size_bytes: int) -> str:
    """Formate une taille de fichier en unités lisibles."""
    if size_bytes == 0:
        return "0 B"
    
    units = ['B', 'KB', 'MB', 'GB', 'TB']
    unit_index = 0
    size = float(size_bytes)
    
    while size >= 1024.0 and unit_index < len(units) - 1:
        size /= 1024.0
        unit_index += 1
    
    return f"{size:.1f} {units[unit_index]}"

def truncate_text(text: str, max_length: int = 200, suffix: str = "...") -> str:
    """Tronque un texte à une longueur maximale."""
    if len(text) <= max_length:
        return text
    return text[:max_length - len(suffix)] + suffix

def parse_duration(duration_str: str) -> int:
    """Parse une durée en format humain vers des secondes."""
    duration_str = duration_str.lower().strip()
    
    # Patterns pour différents formats
    patterns = [
        (r'(\d+)\s*s(?:ec)?(?:onds?)?', 1),
        (r'(\d+)\s*m(?:in)?(?:utes?)?', 60),
        (r'(\d+)\s*h(?:ours?)?', 3600),
        (r'(\d+)\s*d(?:ays?)?', 86400),
    ]
    
    total_seconds = 0
    
    for pattern, multiplier in patterns:
        matches = re.findall(pattern, duration_str)
        for match in matches:
            total_seconds += int(match) * multiplier
    
    return total_seconds if total_seconds > 0 else 60  # Default 1 minute

def clean_html(html_content: str) -> str:
    """Nettoie le contenu HTML de base."""
    # Supprime les scripts et styles
    html_content = re.sub(r'<script[^>]*>.*?</script>', '', html_content, flags=re.DOTALL | re.IGNORECASE)
    html_content = re.sub(r'<style[^>]*>.*?</style>', '', html_content, flags=re.DOTALL | re.IGNORECASE)
    
    # Supprime les balises HTML
    html_content = re.sub(r'<[^>]+>', '', html_content)
    
    # Nettoie les espaces multiples
    html_content = re.sub(r'\s+', ' ', html_content)
    
    return html_content.strip()

def generate_unique_id(prefix: str = "") -> str:
    """Génère un identifiant unique basé sur le timestamp."""
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S_%f")
    return f"{prefix}_{timestamp}" if prefix else timestamp

def is_safe_path(file_path: Path, base_path: Path) -> bool:
    """Vérifie qu'un chemin de fichier est sûr (pas de directory traversal)."""
    try:
        file_path.resolve().relative_to(base_path.resolve())
        return True
    except ValueError:
        return False

def mask_sensitive_data(text: str) -> str:
    """Masque les données sensibles dans un texte."""
    # Masque les clés API (patterns communs)
    text = re.sub(r'(sk-[a-zA-Z0-9]{20,})', '***MASKED_API_KEY***', text)
    text = re.sub(r'(AIza[a-zA-Z0-9_-]{20,})', '***MASKED_GOOGLE_KEY***', text)
    
    # Masque les adresses email
    text = re.sub(r'\b[A-Za-z0-9._%+-]+@[A-Za-z0-9.-]+\.[A-Z|a-z]{2,}\b', '***MASKED_EMAIL***', text)
    
    # Masque les numéros de téléphone
    text = re.sub(r'\b\d{10,}\b', '***MASKED_PHONE***', text)
    
    return text

class RateLimiter:
    """Limiteur de débit simple pour les opérations."""
    
    def __init__(self, max_requests: int, time_window: int):
        self.max_requests = max_requests
        self.time_window = time_window
        self.requests = []
    
    def is_allowed(self) -> bool:
        """Vérifie si une nouvelle requête est autorisée."""
        now = datetime.now().timestamp()
        
        # Supprime les requêtes anciennes
        self.requests = [req_time for req_time in self.requests if now - req_time < self.time_window]
        
        # Vérifie la limite
        if len(self.requests) < self.max_requests:
            self.requests.append(now)
            return True
        
        return False
    
    def time_until_allowed(self) -> float:
        """Retourne le temps à attendre avant la prochaine requête autorisée."""
        if not self.requests:
            return 0.0
        
        oldest_request = min(self.requests)
        return max(0.0, self.time_window - (datetime.now().timestamp() - oldest_request))

def retry_on_exception(max_retries: int = 3, delay: float = 1.0, backoff_factor: float = 2.0):
    """Décorateur pour réessayer une fonction en cas d'exception."""
    def decorator(func):
        async def wrapper(*args, **kwargs):
            last_exception = None
            current_delay = delay
            
            for attempt in range(max_retries + 1):
                try:
                    return await func(*args, **kwargs)
                except Exception as e:
                    last_exception = e
                    if attempt < max_retries:
                        log_message(f"Tentative {attempt + 1}/{max_retries + 1} échouée pour {func.__name__}: {e}", level="warning")
                        await asyncio.sleep(current_delay)
                        current_delay *= backoff_factor
                    else:
                        log_message(f"Toutes les tentatives échouées pour {func.__name__}: {e}", level="error")
            
            raise last_exception
        return wrapper
    return decorator

# Constantes utiles
COMMON_USER_AGENTS = [
    "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36",
    "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36",
    "Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36"
]

DANGEROUS_EXTENSIONS = [
    '.exe', '.bat', '.cmd', '.com', '.pif', '.scr', '.vbs', '.js', '.jar',
    '.msi', '.dll', '.app', '.deb', '.rpm', '.dmg', '.pkg'
]

ALLOWED_IMAGE_EXTENSIONS = ['.jpg', '.jpeg', '.png', '.gif', '.bmp', '.webp', '.svg']
ALLOWED_DOCUMENT_EXTENSIONS = ['.txt', '.pdf', '.doc', '.docx', '.md', '.json', '.xml', '.csv']

def get_random_user_agent() -> str:
    """Retourne un User-Agent aléatoire."""
    import random
    return random.choice(COMMON_USER_AGENTS)

def is_dangerous_file(filename: str) -> bool:
    """Vérifie si un fichier est potentiellement dangereux."""
    _, ext = os.path.splitext(filename.lower())
    return ext in DANGEROUS_EXTENSIONS

def ensure_directory_exists(directory: Path) -> bool:
    """S'assure qu'un répertoire existe, le crée si nécessaire."""
    try:
        directory.mkdir(parents=True, exist_ok=True)
        return True
    except Exception as e:
        log_message(f"Erreur création répertoire {directory}: {e}", level="error")
        return False

def format_error(error: Exception) -> str:
    """Formate une erreur de manière visuelle."""
    return f"""
⚠️⚠️⚠️ ERREUR ⚠️⚠️⚠️
Type: {type(error).__name__}
Message: {str(error)}
————————————
"""

# main.py

import asyncio
import json
import traceback
from pathlib import Path
from datetime import datetime
import re
from typing import Dict, Any, List, Optional

# AJOUT 1: Importer les modules nécessaires (artefact 'import telegram_logger' supprimé)
from config import config
from utils import log_message, set_file_lock
from app_singletons import endpoint_health_manager, quota_manager
from brain_library import brain_coordinator, TelegramMemoryIntegration
from autonomous_brain import create_brain
from coding_challenge_system import get_coding_challenge_system
from security_archiver import fetch_and_archive_pages
from tools import get_gemini_tools
from synthesizer_brain import SynthesizerBrain
from telegram_logger import set_telegram_integration


class DecentralizedAISystem:
    """
    Système d'IA décentralisé avec 7 cerveaux autonomes.
    Chaque cerveau peut traiter indépendamment les requêtes utilisateur.
    """
    def __init__(self):
        self.brains = {}
        self.telegram_memory = None
        self.coding_system = None
        self.last_activity = datetime.now().timestamp()
        self.system_initialized = False
        self.synthesizer = None # Pour le cerveau de synthèse
        
        # Les 7 cerveaux autonomes
        self.brain_types = ["GEMINI", "DEEPSEEK", "HUGGINGFACE", "TAVILY", "SERPER", "GOOGLE_CUSTOM_SEARCH", "WOLFRAMALPHA"]
        
    async def initialize_system(self):
        """Initialise tous les composants du système décentralisé."""
        try:
            log_message("🚀 Initialisation du système d'IA décentralisé...")
            
            # Configuration du verrou de fichier
            file_lock = asyncio.Lock()
            set_file_lock(file_lock)
            
            # Initialisation des singletons
            await endpoint_health_manager.init_manager()
            await quota_manager.init_manager()
            
            # AJOUT 2: Initialiser et connecter le logger Telegram (remplace l'ancien bloc)
            # Cette partie est cruciale pour que le logger sache où envoyer les messages.
            try:
                # On suppose que votre client Telegram est instancié ici
                from app_clients_instances import telegram_bot_client
                self.telegram_memory = TelegramMemoryIntegration(telegram_bot_client)
            except ImportError:
                log_message("Client Telegram non disponible, le logger fonctionnera en mode console.", level="warning")
                self.telegram_memory = TelegramMemoryIntegration(None)

            # On passe l'instance de communication Telegram à notre module de logging.
            set_telegram_integration(self.telegram_memory)
            
            # Initialisation des 7 cerveaux autonomes
            for brain_type in self.brain_types:
                try:
                    brain = create_brain(brain_type, self.telegram_memory.bot_client if self.telegram_memory else None)
                    await brain.initialize()
                    self.brains[brain_type] = brain
                    log_message(f"✅ Cerveau {brain_type} initialisé")
                except Exception as e:
                    log_message(f"❌ Erreur initialisation cerveau {brain_type}: {e}", level="error")
            
            # Initialisation du système de défis de codage
            self.coding_system = get_coding_challenge_system(
                self.telegram_memory.bot_client if self.telegram_memory else None
            )
            await self.coding_system.initialize()
            
            # AJOUT : Initialisation du cerveau de synthèse
            self.synthesizer = SynthesizerBrain(self.telegram_memory.bot_client if self.telegram_memory else None)
            await self.synthesizer.initialize()
            
            # Message d'initialisation dans le groupe privé
            await self.telegram_memory.write_to_group(
                f"""
🧠 SYSTÈME D'IA DÉCENTRALISÉ INITIALISÉ

✅ Cerveaux actifs: {len(self.brains)}/7
✅ Gestionnaire de santé: Opérationnel
✅ Gestionnaire de quotas: Opérationnel  
✅ Système de défis: Prêt
✅ Archiveur sécurisé: Prêt

🔄 Rotation automatique: 45 minutes
🎯 Défis de codage: 15 minutes
📝 Mémoire partagée: Active

Le système est prêt à traiter les requêtes utilisateur.
""",
                "SYSTEM_INIT"
            )
            
            self.system_initialized = True
            log_message("🎉 Système d'IA décentralisé initialisé avec succès")
            return True
            
        except Exception as e:
            log_message(f"❌ Erreur critique lors de l'initialisation: {e}", level="critical")
            log_message(f"Traceback: {traceback.format_exc()}", level="critical")
            return False
    
    async def start_background_tasks(self):
        """Démarre toutes les tâches de fond."""
        if not self.system_initialized:
            log_message("Système non initialisé, impossible de démarrer les tâches de fond", level="error")
            return
        
        log_message("🔄 Démarrage des tâches de fond...")
        
        # Tâche de health checks périodiques
        asyncio.create_task(self._periodic_health_checks())
        
        # Tâche de défis de codage automatisés
        asyncio.create_task(self.coding_system.start_periodic_challenges())
        
        # AJOUT : Démarrage de la tâche de gestion proactive des quotas
        asyncio.create_task(self._proactive_quota_checks())
        
        # Tâche de nettoyage de la mémoire
        asyncio.create_task(self._memory_cleanup())
        
        await self.telegram_memory.write_to_group(
            "🔄 Toutes les tâches de fond sont démarrées",
            "BACKGROUND_TASKS"
        )
        
        log_message("✅ Tâches de fond démarrées")
    
    async def handle_user_request(self, user_query: str, user_id: str = "default_user", 
                                image_data: Optional[str] = None) -> Dict[str, Any]:
        """
        Traite une requête utilisateur avec le système décentralisé.
        ### MODIFICATION : Intègre la phase de synthèse.
        """
        if not self.system_initialized:
            return {"error": "Système non initialisé", "brain_id": "SYSTEM"}
        
        start_time = datetime.now()
        self.last_activity = start_time.timestamp()
        
        # Log de la requête
        await self.telegram_memory.write_to_group(
            f"🔍 NOUVELLE REQUÊTE UTILISATEUR\nUtilisateur: {user_id}\nRequête: {user_query[:200]}...",
            "USER_REQUEST"
        )
        
        log_message(f"Traitement requête utilisateur: {user_query[:100]}...")
        
        try:
            # Sélection du cerveau optimal
            selected_brain_type = brain_coordinator.get_next_brain()
            selected_brain = self.brains.get(selected_brain_type)
            
            if not selected_brain:
                error_msg = f"Cerveau {selected_brain_type} non disponible"
                await self.telegram_memory.log_error("SYSTEM", error_msg)
                return {"error": error_msg, "brain_id": "SYSTEM"}
            
            # Augmentation de la charge du cerveau
            brain_coordinator.update_brain_load(selected_brain_type, 1)
            
            await self.telegram_memory.log_brain_activity(
                selected_brain_type,
                "Sélectionné pour traitement",
                {"user_id": user_id, "query_length": len(user_query)}
            )
            
            # Préparation des outils
            available_tools = get_gemini_tools()
            
            # Étape 1: Le cerveau initial analyse la requête et peut décider d'appeler des outils
            first_pass_result = await selected_brain.process_request(
                user_query=user_query,
                chat_history=[],
                image_data=image_data,
                tools=available_tools
            )
            
            tool_results = first_pass_result.get("tool_results", [])

            # AJOUT : Phase de Synthèse ###
            if tool_results and self.synthesizer:
                await self.telegram_memory.write_to_group(f"Délégation au synthétiseur après {len(tool_results)} outil(s).", "SYNTHESIS_FLOW_START")
                
                # Le synthétiseur prend le relais pour formuler la réponse finale
                final_response = await self.synthesizer.synthesize_response(
                    original_query=user_query,
                    tool_results=tool_results
                )
                
                # On met à jour le résultat final avec la réponse synthétisée
                final_result = first_pass_result
                final_result["response"] = final_response.get("response")
                final_result["brain_id"] = f"{selected_brain_type} -> SYNTHESIZER"
                
            else:
                # Si aucun outil n'a été appelé, on retourne directement la réponse du premier cerveau
                final_result = first_pass_result
            
            # Diminution de la charge du cerveau
            brain_coordinator.update_brain_load(selected_brain_type, -1)
            
            # Calcul du temps de traitement
            processing_time = (datetime.now() - start_time).total_seconds()
            
            # Mise à jour des statistiques
            if "error" not in final_result:
                await quota_manager.increment_quota(selected_brain_type, success=True)
                await self.telegram_memory.log_success(
                    final_result.get("brain_id", selected_brain_type),
                    f"Requête traitée en {processing_time:.2f}s",
                    str(final_result.get("response", ""))[:200]
                )
            else:
                await quota_manager.increment_quota(selected_brain_type, success=False)
                brain_coordinator.mark_brain_failed(selected_brain_type)
                await self.telegram_memory.log_error(
                    selected_brain_type,
                    f"Échec traitement: {final_result.get('error', 'Erreur inconnue')}"
                )
            
            # Enrichissement du résultat
            final_result.update({
                "processing_time": processing_time,
                "timestamp": start_time.isoformat(),
                "user_id": user_id,
                "system_status": brain_coordinator.get_brain_status()
            })
            
            return final_result
            
        except Exception as e:
            error_msg = f"Erreur système lors du traitement: {e}"
            log_message(f"Erreur handle_user_request: {error_msg}", level="error")
            log_message(f"Traceback: {traceback.format_exc()}", level="error")
            
            await self.telegram_memory.log_error("SYSTEM", error_msg)
            
            return {
                "error": error_msg,
                "brain_id": "SYSTEM",
                "timestamp": start_time.isoformat(),
                "user_id": user_id
            }
    
    async def _periodic_health_checks(self):
        """Tâche de health checks périodiques pour tous les services."""
        while True:
            try:
                await self.telegram_memory.write_to_group(
                    "🏥 Début des health checks périodiques",
                    "HEALTH_CHECK"
                )
                
                # Health check pour tous les services configurés
                for service_name in config.API_CONFIG.keys():
                    await endpoint_health_manager.run_health_check_for_service(service_name)
                    await asyncio.sleep(1)  # Pause entre services
                
                # Rapport de santé
                health_report = []
                for brain_type in self.brain_types:
                    is_healthy = await endpoint_health_manager.is_service_healthy(brain_type)
                    health_report.append(f"{'✅' if is_healthy else '❌'} {brain_type}")
                
                await self.telegram_memory.write_to_group(
                    f"📊 RAPPORT DE SANTÉ\n\n" + "\n".join(health_report),
                    "HEALTH_REPORT"
                )
                
                log_message("Health checks périodiques terminés")
                
            except Exception as e:
                log_message(f"Erreur health checks: {e}", level="error")
            
            await asyncio.sleep(config.HEALTH_CHECK_INTERVAL_SECONDS)
    
    # AJOUT : Nouvelle tâche de fond pour la gestion proactive des quotas
    async def _proactive_quota_checks(self):
        """Tâche de fond pour la gestion proactive des quotas."""
        while True:
            await asyncio.sleep(3600) # S'exécute toutes les heures
            try:
                await self.telegram_memory.write_to_group("Vérification proactive des quotas en cours.", "PROACTIVE_QUOTA_CHECK")
                all_quotas = quota_manager.get_all_quotas_status()
                
                report_lines = []
                warnings = []
                for api, status in all_quotas.items():
                    if isinstance(status, dict) and 'limit' in status and status['limit'] > 0:
                        remaining = status.get('remaining', 0)
                        limit = status.get('limit', 1)
                        percent_remaining = (remaining / limit) * 100
                        report_lines.append(f"- `{api}`: {remaining}/{limit} restants ({percent_remaining:.1f}%)")
                        if percent_remaining < 20:
                            warnings.append(f"`{api}` ({percent_remaining:.1f}%)")

                report = "📊 *RAPPORT DE QUOTAS PROACTIF*\n" + "\n".join(report_lines)
                if warnings:
                    report += f"\n\n*⚠️ AVERTISSEMENT - QUOTAS FAIBLES:*\n" + ", ".join(warnings)
                
                await self.telegram_memory.write_to_group(report, "QUOTA_REPORT")
            except Exception as e:
                await self.telegram_memory.log_error("QUOTA_SYSTEM", f"Erreur lors de la vérification proactive des quotas: {e}")

    async def _memory_cleanup(self):
        """Nettoyage périodique de la mémoire."""
        while True:
            try:
                await asyncio.sleep(24 * 3600)  # Tous les jours
                
                # Nettoyage de la mémoire des cerveaux
                for brain in self.brains.values():
                    await brain.memory_manager.save_memory()
                
                await self.telegram_memory.write_to_group(
                    "🧹 Nettoyage de mémoire effectué",
                    "MEMORY_CLEANUP"
                )
                
                log_message("Nettoyage de mémoire effectué")
                
            except Exception as e:
                log_message(f"Erreur nettoyage mémoire: {e}", level="error")
    
    def get_system_status(self) -> Dict[str, Any]:
        """Retourne le statut complet du système."""
        if not self.system_initialized:
            return {"status": "not_initialized"}
        
        return {
            "status": "operational",
            "initialized": self.system_initialized,
            "active_brains": len(self.brains),
            "brain_status": brain_coordinator.get_brain_status(),
            "coding_challenges": self.coding_system.get_challenge_statistics() if self.coding_system else {},
            "last_activity": self.last_activity,
            "uptime": datetime.now().timestamp() - self.last_activity if hasattr(self, 'start_time') else 0
        }
    
    async def shutdown(self):
        """Arrêt propre du système."""
        log_message("🛑 Arrêt du système d'IA décentralisé...")
        
        try:
            # Arrêt des défis de codage
            if self.coding_system:
                self.coding_system.stop_challenges()
            
            # Sauvegarde finale de toutes les mémoires
            for brain in self.brains.values():
                await brain.memory_manager.save_memory()
            
            await self.telegram_memory.write_to_group(
                "🛑 Système d'IA décentralisé arrêté proprement",
                "SYSTEM_SHUTDOWN"
            )
            
            log_message("✅ Système arrêté proprement")
            
        except Exception as e:
            log_message(f"Erreur lors de l'arrêt: {e}", level="error")

# Instance globale du système
decentralized_system = DecentralizedAISystem()

async def main():
    """Fonction principale pour le mode console."""
    try:
        # Initialisation du système
        success = await decentralized_system.initialize_system()
        if not success:
            log_message("❌ Échec de l'initialisation, arrêt du programme", level="critical")
            return
        
        # Démarrage des tâches de fond
        await decentralized_system.start_background_tasks()
        
        # Interface console
        print("\n" + "="*60)
        print("🧠 SYSTÈME D'IA DÉCENTRALISÉ - 7 CERVEAUX AUTONOMES")
        print("="*60)
        print("Commandes disponibles:")
        print("  /help      - Affiche l'aide")
        print("  /status    - Statut du système")
        print("  /brains    - État des cerveaux")
        print("  /quotas    - État des quotas")
        print("  /challenges - Statistiques défis")
        print("  /challenge - Lance un défi manuel")
        print("  /archive <urls> - Archive des pages web")
        print("  /exit      - Quitter")
        print("  Ou tapez directement votre question")
        print("="*60)
        
        while True:
            try:
                user_input = await asyncio.to_thread(input, "\n🤖 Vous: ")
                user_input = user_input.strip()
                
                if not user_input:
                    continue
                
                if user_input.lower() == "/exit":
                    break
                
                elif user_input.lower() == "/help":
                    print("""
📋 AIDE DU SYSTÈME D'IA DÉCENTRALISÉ

🧠 Architecture:
  • 7 cerveaux autonomes (GEMINI, DEEPSEEK, HUGGINGFACE, TAVILY, SERPER, GOOGLE_CUSTOM_SEARCH, WOLFRAMALPHA)
  • Rotation automatique toutes les 45 minutes
  • Basculement automatique en cas de panne
  • Mémoire partagée dans le groupe privé Telegram

🎯 Fonctionnalités:
  • Traitement de requêtes utilisateur
  • Défis de codage automatisés (15 min)
  • Archivage sécurisé de pages web
  • Monitoring santé des APIs
  • Gestion intelligente des quotas

💬 Exemples d'utilisation:
  • "Explique-moi la programmation asynchrone"
  • "Crée un script Python pour analyser des données"
  • "Recherche les dernières nouvelles sur l'IA"
  • "/archive https://example.com,https://site.org"
""")
                
                elif user_input.lower() == "/status":
                    status = decentralized_system.get_system_status()
                    print(f"""
📊 STATUT SYSTÈME:
  • État: {status['status']}
  • Cerveaux actifs: {status['active_brains']}/7
  • Cerveau pour la prochaine requête: {status.get('brain_status', {}).get('active_brain_for_next_request', 'N/A')}
  • Dernière activité: {datetime.fromtimestamp(status['last_activity']).strftime('%H:%M:%S')}
""")
                
                elif user_input.lower() == "/brains":
                    brain_status = brain_coordinator.get_brain_status()
                    print("\n🧠 ÉTAT DES CERVEAUX:")
                    for brain, healthy in brain_status['brain_health'].items():
                        load = brain_status['brain_load'].get(brain, 0)
                        status_icon = "✅" if healthy else "❌"
                        print(f"  {status_icon} {brain}: Charge {load}")
                
                elif user_input.lower() == "/quotas":
                    quotas = quota_manager.get_all_quotas_status()
                    print("\n📊 ÉTAT DES QUOTAS:")
                    for api, quota_info in quotas.items():
                        if isinstance(quota_info, dict) and 'error' not in quota_info:
                            usage = quota_info['current_usage']
                            limit = quota_info['limit']
                            remaining = quota_info['remaining']
                            percent = (usage / limit * 100) if limit > 0 else 0
                            print(f"  {api}: {usage}/{limit} ({percent:.1f}%) - Restant: {remaining}")
                
                elif user_input.lower() == "/challenges":
                    if decentralized_system.coding_system:
                        stats = decentralized_system.coding_system.get_challenge_statistics()
                        print(f"""
🎯 STATISTIQUES DÉFIS DE CODAGE:
  • Total défis: {stats.get('total_challenges', 0)}
  • Participants: {stats.get('total_participants', 0)}
  • Succès: {stats.get('total_successful', 0)}
  • Taux succès: {stats.get('average_success_rate', 0):.1f}%
  • Statut: {'🔄 Actif' if stats.get('is_running') else '⏹️ Arrêté'}
""")
                    else:
                        print("❌ Système de défis non initialisé")

                # AJOUT 3: Créer le Terminal Telegram pour lancer un défi manuel
                elif user_input.lower().startswith("/challenge"):
                    try:
                        from coding_challenge_system import get_coding_challenge_system
                        challenge_system = get_coding_challenge_system()
                        
                        if challenge_system and challenge_system.is_running:
                            print("🚀 Lancement manuel d'un défi de codage pour tous les agents...")
                            
                            # On lance l'exécution du défi en tâche de fond pour ne pas bloquer la console
                            asyncio.create_task(challenge_system.run_coding_challenge())
                            
                            print("✅ Défi lancé. Surveillez le groupe privé pour les résultats.")
                        else:
                            print("❌ Le système de défis de codage n'est pas actif ou initialisé.")
                    except Exception as e:
                        print(f"❌ Erreur lors du lancement du défi : {e}")
                
                elif user_input.startswith("/archive "):
                    urls_str = user_input[9:].strip()
                    if urls_str:
                        urls = [url.strip() for url in urls_str.split(',') if url.strip()]
                        if urls:
                            print(f"🗂️ Archivage de {len(urls)} URL(s) en cours...")
                            result = await fetch_and_archive_pages(urls, "console_user")
                            print(f"✅ {result.get('tool_output', 'Archivage terminé')}")
                        else:
                            print("❌ Aucune URL valide fournie")
                    else:
                        print("❌ Usage: /archive <url1>,<url2>,...")
                
                else:
                    # Traitement d'une requête normale
                    print("🤔 Traitement en cours...")
                    
                    # Détection simple d'image (simulation)
                    image_data = None
                    if any(ext in user_input.lower() for ext in ['.png', '.jpg', '.jpeg', '.gif']):
                        print("🖼️ Image détectée (mode simulation)")
                        image_data = "data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAEAAAABCAQAAAC1HAwCAAAAC0lEQVR42mNkYAAAAAYAAjCB0C8AAAAASUVORK5CYII="
                    
                    # Traitement par le système décentralisé
                    response = await decentralized_system.handle_user_request(
                        user_query=user_input,
                        user_id="console_user",
                        image_data=image_data
                    )
                    
                    # Affichage de la réponse
                    if "error" in response:
                        print(f"❌ Erreur ({response.get('brain_id', 'UNKNOWN')}): {response['error']}")
                    else:
                        brain_id = response.get('brain_id', 'UNKNOWN')
                        processing_time = response.get('processing_time', 0)
                        
                        # Extraction de la réponse selon le format
                        if 'response' in response and isinstance(response['response'], dict):
                            candidates = response['response'].get('candidates', [])
                            if candidates and 'content' in candidates[0]:
                                parts = candidates[0]['content'].get('parts', [])
                                if parts and 'text' in parts[0]:
                                    answer = parts[0]['text']
                                else:
                                    answer = str(response['response'])
                            else:
                                answer = str(response['response'])
                        else:
                            answer = str(response.get('response', 'Aucune réponse'))
                        
                        print(f"\n🤖 {brain_id} ({processing_time:.2f}s): {answer}")
                        
                        # Affichage des outils utilisés
                        if 'tool_results' in response and response['tool_results']:
                            print(f"\n🔧 Outils utilisés: {len(response['tool_results'])}")
                            for tool in response['tool_results']:
                                tool_name = tool.get('tool_name', 'Inconnu')
                                print(f"  • {tool_name}")
                
            except EOFError:
                print("\n👋 Au revoir !")
                break
            except KeyboardInterrupt:
                print("\n⚠️ Interruption détectée...")
                break
            except Exception as e:
                print(f"❌ Erreur: {e}")
                log_message(f"Erreur console: {e}", level="error")
        
    except Exception as e:
        log_message(f"Erreur critique dans main(): {e}", level="critical")
        log_message(f"Traceback: {traceback.format_exc()}", level="critical")
    
    finally:
        # Arrêt propre du système
        await decentralized_system.shutdown()

if __name__ == "__main__":
    try:
        asyncio.run(main())
    except KeyboardInterrupt:
        print("\n🛑 Arrêt forcé du système")
    except Exception as e:
        print(f"❌ Erreur fatale: {e}")
                                                            


import os
from pathlib import Path
from typing import Dict, Any, List, Optional
from datetime import datetime

class Config:
    """
    Classe de configuration pour l'application avec 7 cerveaux autonomes.
    Gère les chemins de fichiers, les clés API, et les paramètres des modèles.
    """
    def __init__(self):
        # --- Chemins de fichiers et répertoires ---
        self.BASE_DIR: Path = Path(__file__).parent.parent if Path(__file__).parent.name == 'src' else Path(__file__).parent
        
        self.LOG_FILE: Path = self.BASE_DIR / "logs" / "bot_activity.log"
        self.ERROR_LOG_PATH: Path = self.BASE_DIR / "logs" / "error.log"
        self.USER_CHAT_HISTORY_FILE: Path = self.BASE_DIR / "data" / "user_chat_history.json"
        self.ENDPOINT_HEALTH_FILE: Path = self.BASE_DIR / "data" / "endpoint_health.json"
        self.QUOTA_STATE_FILE: Path = self.BASE_DIR / "data" / "quota_state.json"
        self.DAILY_CHALLENGE_PATH: Path = self.BASE_DIR / "daily_challenges"
        self.BRAIN_MEMORY_FILE: Path = self.BASE_DIR / "data" / "brain_memory.json"
        
        # Créer les répertoires nécessaires
        self.LOG_FILE.parent.mkdir(parents=True, exist_ok=True)
        self.USER_CHAT_HISTORY_FILE.parent.mkdir(parents=True, exist_ok=True)
        self.ENDPOINT_HEALTH_FILE.parent.mkdir(parents=True, exist_ok=True)
        self.QUOTA_STATE_FILE.parent.mkdir(parents=True, exist_ok=True)
        self.DAILY_CHALLENGE_PATH.mkdir(parents=True, exist_ok=True)
        self.BRAIN_MEMORY_FILE.parent.mkdir(parents=True, exist_ok=True)
        
        # --- Paramètres généraux de l'application ---
        self.VERBOSE: bool = True
        self.MAX_FILE_SIZE: int = 10 * 1024 * 1024
        self.MAX_CHUNK_SIZE: int = 4000
        self.MAX_IMAGE_SIZE: int = 4 * 1024 * 1024
        self.HEALTH_CHECK_INTERVAL_SECONDS: int = 300
        self.PRIVATE_GROUP_ID: Optional[int] = -1002845235344
        self.GROUP_MEMORY_LIMIT: int = 20
        self.BRAIN_ROTATION_INTERVAL_SECONDS: int = 45 * 60  # 45 minutes pour rotation des cerveaux
        self.LLM_ROTATION_INTERVAL_SECONDS: int = 45 * 60 # 45 minutes pour la rotation des LLM
        self.CODING_CHALLENGE_INTERVAL_SECONDS: int = 15 * 60  # 15 minutes pour défis codage
        
        # --- Telegram Bot Configuration ---
        self.TELEGRAM_BOT_TOKEN = "7902342551:AAG6r1QA2GTMXcmcsWHi36Ivd_PVeMXULOs"
        
        # --- DÉBUT DES DÉFINITIONS DE CLÉS API (VÉRIFIEZ QUE TOUT CE BLOC EST PRÉSENT) ---
        
        # Cerveau 1: GEMINI
        self.GEMINI_API_KEYS: List[str] = [
            "AIzaSyBWXcwGdzoeUzbApSNLICkanNcm7BYzYcs",
            "AIzaSyAk6Ph25xuIY3b5o-JgdL652MvK4usp8Ms",
            "AIzaSyDuccmfiPSk4042NeJCYIjA8EOXPo1YKXU",
            "AIzaSyAQq6o9voefaDxkAEORf7W-IB3QbotIkwY",
            "AIzaSyDYaYrQQ7cwYFm8TBpyGM3dJweOGOYl7qw",
            "VOTRE_DEUXIEME_CLE_API_GEMINI_OPTIONNELLE_ICI" # Laissez tel quel ou ajoutez une autre clé
        ]
        
        # Cerveau 2: DEEPSEEK
        self.DEEPSEEK_KEYS: List[str] = [
            "sk-ef08317d125947b3a1ce5916592bef00",
            "sk-d73750d96142421cb1098c7056dd7f01"
        ]
        
        # Cerveau 3: HUGGINGFACE
        self.HUGGINGFACE_KEYS: List[str] = [
            "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",
            "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",
            "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",
            "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"
        ]
        
        # Cerveau 4: TAVILY (clé corrigée)
        self.TAVILY_KEYS: List[str] = [
            "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",
            "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",  # Clé corrigée
            "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",
            "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"
        ]
        
        # Cerveau 5: SERPER
        self.SERPER_KEYS: List[str] = [
            "047b30db1df999aaa9c293f2048037d40c651439"
        ]
        
        # Cerveau 6: GOOGLE
        self.GOOGLE_API_KEYS: List[str] = [
            "AIzaSyAk6Ph25xuIY3b5o-JgdL652MvK4usp8Ms",
            "AIzaSyDuccmfiPSk4042NeJCYIjA8EOXPo1YKXU",
            "AIzaSyAQq6o9voefaDxkAEORf7W-IB3QbotIkwY",
            "AIzaSyDYaYrQQ7cwYFm8TBpyGM3dJweOGOYl7qw"
        ]
        self.GOOGLE_CX_LIST: List[str] = [
            "3368510e864b74936",
            "e745c9ca0ffb94659"
        ]
        
        # Cerveau 7: WOLFRAM
        self.WOLFRAM_APP_IDS: List[str] = [
            "96LX77-G8PGKJ3T7V",
            "96LX77-PYHRRET363",
            "96LX77-P9HPAYWRGL"
        ]
        
        # --- Autres clés API pour outils spécialisés ---
        self.WEBCONTAINER_KEY: str = "wc_api_bastien34500_3c5b29436216f322904448de707c148e"
        self.APIFLASH_KEY: str = "3a3cc886a18e41109e0cebc0745b12de"
        self.CRAWLBASE_KEYS: List[str] = [
            "x41P6KNU8J86yF9JV1nqSw",
            "FOg3R0v_aLxzHkYIdhPgVg"
        ]
        self.DETECTLANGUAGE_KEY: str = "ebdc8ccc2ee75eda3ab122b08ffb1e8d"
        self.GUARDIAN_KEY: str = "07c622c1-af05-4c24-9f37-37d219be76a0"
        self.IP2LOCATION_KEY: str = "11103C239EA8EA6DF2473BB445EC32F2"
        self.SHODAN_KEY: str = "umdSaWOfVq9Wt2F4wWdXiKh1zjLailzn"
        self.WEATHERAPI_KEY: str = "332bcdba457d4db4836175513250407"
        self.GREYNOISE_KEY: str = "5zNe9E6c5UNDhU09iVXbMaB04UpHAw5hNm5rHCK24fCLvI2cP33NNOpL7nhkDETG"
        self.LOGINRADIUS_KEY: str = "073b2fbedf82409da2ca6f37b97e8c6a"
        self.JSONBIN_KEY: str = "$2a$10$npWSB7v1YcoqLkyPpz0PZOVtES5vBs6JtTWVyVDXK3j6FDxYS5BPO"
        self.TWILIO_SID: str = "SK84cc4d335650f9da168cd779f26e00e5"
        self.TWILIO_SECRET: str = "spvz5uwPE8ANYOI5Te4Mehm7YwKOZ4Lg"
        self.ABSTRACTAPI_EMAIL_KEYS: List[str] = [
            "2ffd537411ad407e9c9a7eacb7a97311",
            "5b00ade4e60e4a388bd3e749f4f66e28",
            "f4106df7b93e4db6855cb7949edc4a20"
        ]
        self.ABSTRACTAPI_GENERIC_KEY: str = "020a4dcd3e854ac0b19043491d79df92"
        self.PULSEDIVE_KEY: str = "201bb09342f35d365889d7d0ca0fdf8580ebee0f1e7644ce70c99a46c1d47171"
        self.RANDOMMER_KEY: str = "29d907df567b4226bf64b924f9e26c00"
        self.STORMGLASS_KEY: str = "7ad5b888-5900-11f0-80b9-0242ac130006-7ad5b996-5900-11f0-80b9-0242ac130006"
        self.TOMORROW_KEY: str = "bNh6KpmddRGY0dzwvmQugVtG4Uf5Y2w1"
        self.CLOUDMERSIVE_KEY: str = "4d407015-ce22-45d7-a2e1-b88ab6380e84"
        self.OPENWEATHER_API_KEY: str = "c80075b7332716a418e47033463085ef"
        self.OCR_API_KEYS: List[str] = [
            "K82679097388957",
            "K81079143888957",
            "K84281517488957"
        ]
        self.MOCKAROO_KEY: str = "282b32d0" # Assurez-vous que cette ligne est bien présente et non coupée
        self.OPENPAGERANK_KEY: str = "w848ws8s0848g4koosgooc0sg4ggogcggw4o4cko" # Assurez-vous que cette ligne est bien présente et non coupée
        self.RAPIDAPI_KEY: str = "d4d1f58d8emsh58d888c711b7400p1bcebejsn2cc04dce6efe" # Assurez-vous que cette ligne est bien présente et non coupée
        # --- FIN DES DÉFINITIONS DE CLÉS API ---
        
        # --- Paramètres du modèle Gemini (LLM) ---
        self.GEMINI_TEMPERATURE: float = 0.7
        self.GEMINI_TOP_P: float = 0.95
        self.GEMINI_TOP_K: int = 40
        self.GEMINI_MAX_OUTPUT_TOKENS: int = 8192
        self.GEMINI_SAFETY_SETTINGS: List[Dict] = [
            {"category": "HARM_CATEGORY_HARASSMENT", "threshold": "BLOCK_NONE"},
            {"category": "HARM_CATEGORY_HATE_SPEECH", "threshold": "BLOCK_NONE"},
            {"category": "HARM_CATEGORY_SEXUALLY_EXPLICIT", "threshold": "BLOCK_NONE"},
            {"category": "HARM_CATEGORY_DANGEROUS_CONTENT", "threshold": "BLOCK_NONE"},
        ]
        
        # --- Configuration des Endpoints API (avec gestion des clés et du roulement) ---
        self.API_CONFIG: Dict[str, List[Dict]] = self._build_api_config()
        
        # --- Configuration des Quotas API ---
        self.QUOTA_CONFIG: Dict[str, Dict[str, Any]] = {
            "GEMINI_API": {"limit": 1000, "reset_interval": "daily", "burn_window_hours": 2},
            "DEEPSEEK": {"limit": 200, "reset_interval": "daily", "burn_window_hours": 1},
            "HUGGINGFACE": {"limit": 200, "reset_interval": "daily", "burn_window_hours": 1},
            "TAVILY": {"limit": 100, "reset_interval": "daily", "burn_window_hours": 0.5},
            "SERPER": {"limit": 100, "reset_interval": "daily", "burn_window_hours": 0.5},
            "GOOGLE_CUSTOM_SEARCH": {"limit": 100, "reset_interval": "daily", "burn_window_hours": 0.5},
            "WOLFRAMALPHA": {"limit": 50, "reset_interval": "daily", "burn_window_hours": 0.5},
            "WEBCONTAINER": {"limit": 1000, "reset_interval": "daily", "burn_window_hours": 2},
            "OCR_API": {"limit": 500, "reset_interval": "daily", "burn_window_hours": 1},
            "APIFLASH": {"limit": 50, "reset_interval": "daily", "burn_window_hours": 0.5},
            "CRAWLBASE": {"limit": 50, "reset_interval": "daily", "burn_window_hours": 0.5},
            "DETECTLANGUAGE": {"limit": 100, "reset_interval": "daily", "burn_window_hours": 0.5},
            "GUARDIAN": {"limit": 500, "reset_interval": "daily", "burn_window_hours": 1},
            "IP2LOCATION": {"limit": 100, "reset_interval": "daily", "burn_window_hours": 0.5},
            "SHODAN": {"limit": 100, "reset_interval": "daily", "burn_window_hours": 0.5},
            "WEATHERAPI": {"limit": 1000, "reset_interval": "daily", "burn_window_hours": 2},
            "CLOUDMERSIVE": {"limit": 50, "reset_interval": "daily", "burn_window_hours": 0.5},
            "GREYNOISE": {"limit": 50, "reset_interval": "daily", "burn_window_hours": 0.5},
            "PULSEDIVE": {"limit": 50, "reset_interval": "daily", "burn_window_hours": 0.5},
            "STORMGLASS": {"limit": 50, "reset_interval": "daily", "burn_window_hours": 0.5},
            "LOGINRADIUS": {"limit": 10, "reset_interval": "daily", "burn_window_hours": 0.1},
            "JSONBIN": {"limit": 20, "reset_interval": "daily", "burn_window_hours": 0.1},
            "TWILIO": {"limit": 5, "reset_interval": "daily", "burn_window_hours": 0.1},
            "ABSTRACTAPI": {"limit": 100, "reset_interval": "daily", "burn_window_hours": 0.5},
            "RANDOMMER": {"limit": 50, "reset_interval": "daily", "burn_window_hours": 0.5},
            "TOMORROW.IO": {"limit": 100, "reset_interval": "daily", "burn_window_hours": 0.5},
            "OPENWEATHERMAP": {"limit": 1000, "reset_interval": "daily", "burn_window_hours": 2},
            "MOCKAROO": {"limit": 50, "reset_interval": "daily", "burn_window_hours": 0.5},
            "OPENPAGERANK": {"limit": 50, "reset_interval": "daily", "burn_window_hours": 0.5},
            "RAPIDAPI": {"limit": 200, "reset_interval": "daily", "burn_window_hours": 1},
        }
        
        # --- Configuration des Outils (pour l'API Gemini) ---
        self.TOOL_CONFIG: Dict[str, Dict[str, Any]] = self._build_tool_config()
    
    def _build_api_config(self) -> Dict[str, List[Dict]]:
        """Construit la configuration des endpoints pour tous les services."""
        return {
            # Cerveau 1: GEMINI - Endpoints multiples pour chaque clé
            "GEMINI_API": [
                {
                    "endpoint_name": f"Gemini Generate Content Key {i+1}",
                    "url": "https://generativelanguage.googleapis.com/v1beta/models/gemini-1.5-flash-latest:generateContent",
                    "method": "POST",
                    "key_field": "key",
                    "key_location": "param",
                    "key": key,
                    "timeout": 60,
                    "health_check_json": {"contents": [{"parts": [{"text": "hello"}]}]},
                } for i, key in enumerate(self.GEMINI_API_KEYS)
            ] + [
                {
                    "endpoint_name": f"Gemini Models List Key {i+1}",
                    "url": "https://generativelanguage.googleapis.com/v1beta/models",
                    "method": "GET",
                    "key_field": "key",
                    "key_location": "param",
                    "key": key,
                    "timeout": 30,
                } for i, key in enumerate(self.GEMINI_API_KEYS)
            ],
            
            # Cerveau 2: DEEPSEEK - Endpoints multiples
            "DEEPSEEK": [
                {
                    "endpoint_name": f"DeepSeek Chat Key {i+1}",
                    "url": "https://api.deepseek.com/chat/completions",
                    "method": "POST",
                    "key_field": "Authorization",
                    "key_location": "header",
                    "key_prefix": "Bearer ",
                    "key": key,
                    "timeout": 60,
                    "fixed_headers": {"Content-Type": "application/json"},
                    "health_check_json": {"model": "deepseek-chat", "messages": [{"role": "user", "content": "ping"}]},
                } for i, key in enumerate(self.DEEPSEEK_KEYS)
            ] + [
                {
                    "endpoint_name": f"DeepSeek Models Key {i+1}",
                    "url": "https://api.deepseek.com/models",
                    "method": "GET",
                    "key_field": "Authorization",
                    "key_location": "header",
                    "key_prefix": "Bearer ",
                    "key": key,
                    "timeout": 30,
                } for i, key in enumerate(self.DEEPSEEK_KEYS)
            ],
            
            # Cerveau 3: HUGGINGFACE - Endpoints multiples
            "HUGGINGFACE": [
                {
                    "endpoint_name": f"HuggingFace Inference Key {i+1}",
                    "url": "https://api-inference.huggingface.co/models/",
                    "method": "POST",
                    "key_field": "Authorization",
                    "key_location": "header",
                    "key_prefix": "Bearer ",
                    "key": key,
                    "timeout": 60,
                    "fixed_headers": {"Content-Type": "application/json"},
                    "health_check_url_suffix": "distilbert-base-uncased-finetuned-sst-2-english",
                    "health_check_json": {"inputs": "Hello world"},
                } for i, key in enumerate(self.HUGGINGFACE_KEYS)
            ],
            
            # Cerveau 4: TAVILY - Endpoints multiples
            "TAVILY": [
                {
                    "endpoint_name": f"Tavily Search Key {i+1}",
                    "url": "https://api.tavily.com/search",
                    "method": "POST",
                    "key_field": "apikey",
                    "key_location": "header",
                    "key": key,
                    "timeout": 20,
                    "fixed_headers": {"Content-Type": "application/json"},
                    "health_check_json": {"query": "test"},
                } for i, key in enumerate(self.TAVILY_KEYS)
            ],
            
            # Cerveau 5: SERPER - Endpoints multiples
            "SERPER": [
                {
                    "endpoint_name": f"Serper Search Key {i+1}",
                    "url": "https://google.serper.dev/search",
                    "method": "POST",
                    "key_field": "X-API-KEY",
                    "key_location": "header",
                    "key": key,
                    "timeout": 15,
                    "fixed_headers": {"Content-Type": "application/json"},
                    "health_check_json": {"q": "test"},
                } for i, key in enumerate(self.SERPER_KEYS)
            ] + [
                {
                    "endpoint_name": f"Serper Images Key {i+1}",
                    "url": "https://google.serper.dev/images",
                    "method": "POST",
                    "key_field": "X-API-KEY",
                    "key_location": "header",
                    "key": key,
                    "timeout": 15,
                    "fixed_headers": {"Content-Type": "application/json"},
                    "health_check_json": {"q": "test"},
                } for i, key in enumerate(self.SERPER_KEYS)
            ],
            
            # Cerveau 6: GOOGLE - Endpoints multiples
            "GOOGLE_CUSTOM_SEARCH": [
                {
                    "endpoint_name": f"Google Custom Search Key {i+1} CX {j+1}",
                    "url": "https://www.googleapis.com/customsearch/v1",
                    "method": "GET",
                    "key_field": "key",
                    "key_location": "param",
                    "key": key,
                    "timeout": 15,
                    "fixed_params": {"cx": cx},
                    "health_check_params": {"q": "test"},
                } for i, key in enumerate(self.GOOGLE_API_KEYS) for j, cx in enumerate(self.GOOGLE_CX_LIST)
            ],
            
            # Cerveau 7: WOLFRAM - Endpoints multiples
            "WOLFRAMALPHA": [
                {
                    "endpoint_name": f"WolframAlpha Query Key {i+1}",
                    "url": "https://api.wolframalpha.com/v2/query", # CORRIGÉ HTTP vers HTTPS
                    "method": "GET",
                    "key_field": "appid",
                    "key_location": "param",
                    "key": key,
                    "timeout": 20,
                    "fixed_params": {"output": "json"},
                    "health_check_params": {"input": "2+2"},
                } for i, key in enumerate(self.WOLFRAM_APP_IDS)
            ],
            
            # Services auxiliaires avec endpoints multiples
            "WEBCONTAINER": [
                {
                    "endpoint_name": "WebContainer API",
                    "url": "https://api.webcontainer.io/v1",
                    "method": "POST",
                    "key_field": "Authorization",
                    "key_location": "header",
                    "key_prefix": "Bearer ",
                    "key": self.WEBCONTAINER_KEY,
                    "timeout": 60,
                    "fixed_headers": {"Content-Type": "application/json"},
                    "health_check_json": {"action": "ping"},
                }
            ],
            
            "OCR_API": [
                {
                    "endpoint_name": f"OCR.space Key {i+1}",
                    "url": "https://api.ocr.space/parse/image",
                    "method": "POST",
                    "key_field": "apikey",
                    "key_location": "header",
                    "key": key,
                    "timeout": 30,
                    "fixed_headers": {"Content-Type": "application/json"},
                    "health_check_json": {"base64Image": "data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAEAAAABCAQAAAC1HAwCAAAAC0lEQVR42mNkYAAAAAYAAjCB0C8AAAAASUVORK5CYII=", "language": "eng"},
                } for i, key in enumerate(self.OCR_API_KEYS)
            ],
            
            "APIFLASH": [
                {
                    "endpoint_name": "ApiFlash Screenshot",
                    "url": "https://api.apiflash.com/v1/urltoimage",
                    "method": "GET",
                    "key_field": "access_key",
                    "key_location": "param",
                    "key": self.APIFLASH_KEY,
                    "timeout": 30,
                    "health_check_params": {"url": "https://www.google.com", "format": "jpeg"},
                }
            ],
            
            "CRAWLBASE": [
                {
                    "endpoint_name": f"Crawlbase Scraper Key {i+1}",
                    "url": "https://api.crawlbase.com/",
                    "method": "GET",
                    "key_field": "token",
                    "key_location": "param",
                    "key": key,
                    "timeout": 45,
                    "health_check_params": {"url": "https://httpbin.org/status/200"},
                } for i, key in enumerate(self.CRAWLBASE_KEYS)
            ] + [
                {
                    "endpoint_name": f"Crawlbase JS Scraper Key {i+1}",
                    "url": "https://api.crawlbase.com/?javascript=true",
                    "method": "GET",
                    "key_field": "token",
                    "key_location": "param",
                    "key": key,
                    "timeout": 60,
                    "health_check_params": {"url": "https://httpbin.org/status/200"},
                } for i, key in enumerate(self.CRAWLBASE_KEYS)
            ],
            
            # Autres services avec tous leurs endpoints...
            "DETECTLANGUAGE": [
                {
                    "endpoint_name": "DetectLanguage Detect",
                    "url": "https://ws.detectlanguage.com/0.2/detect",
                    "method": "POST",
                    "key_field": "Authorization",
                    "key_location": "header",
                    "key_prefix": "Bearer ",
                    "key": self.DETECTLANGUAGE_KEY,
                    "timeout": 10,
                    "fixed_headers": {"Content-Type": "application/json"},
                    "health_check_json": {"q": "Hello world"},
                }
            ],
            
            "GUARDIAN": [
                {
                    "endpoint_name": "Guardian Content",
                    "url": "https://content.guardianapis.com/search",
                    "method": "GET",
                    "key_field": "api-key",
                    "key_location": "param",
                    "key": self.GUARDIAN_KEY,
                    "timeout": 15,
                    "health_check_params": {"q": "test"},
                }
            ],
            
            "IP2LOCATION": [
                {
                    "endpoint_name": "IP2Location IP Geolocation",
                    "url": "https://api.ip2location.io/",
                    "method": "GET",
                    "key_field": "key",
                    "key_location": "param",
                    "key": self.IP2LOCATION_KEY,
                    "timeout": 10,
                    "fixed_params": {"package": "WS24", "format": "json"},
                    "health_check_params": {"ip": "8.8.8.8"},
                }
            ],
            
            "SHODAN": [
                {
                    "endpoint_name": "Shodan Host Info",
                    "url": "https://api.shodan.io/shodan/host/",
                    "method": "GET",
                    "key_field": "key",
                    "key_location": "param",
                    "key": self.SHODAN_KEY,
                    "timeout": 15,
                    "health_check_url_suffix": "8.8.8.8",
                },
                {
                    "endpoint_name": "Shodan API Info",
                    "url": "https://api.shodan.io/api-info",
                    "method": "GET",
                    "key_field": "key",
                    "key_location": "param",
                    "key": self.SHODAN_KEY,
                    "timeout": 15,
                }
            ],
            
            "WEATHERAPI": [
                {
                    "endpoint_name": "WeatherAPI Current",
                    "url": "https://api.weatherapi.com/v1/current.json",
                    "method": "GET",
                    "key_field": "key",
                    "key_location": "param",
                    "key": self.WEATHERAPI_KEY,
                    "timeout": 10,
                    "health_check_params": {"q": "London"},
                }
            ],
            
            "CLOUDMERSIVE": [
                {
                    "endpoint_name": "Cloudmersive Validate Domain",
                    "url": "https://api.cloudmersive.com/validate/url/validate/full",
                    "method": "POST",
                    "key_field": "Apikey",
                    "key_location": "header",
                    "key": self.CLOUDMERSIVE_KEY,
                    "timeout": 15,
                    "fixed_headers": {"Content-Type": "application/json"},
                    "health_check_json": {"domain": "google.com"},
                }
            ],
            
            "GREYNOISE": [
                {
                    "endpoint_name": "GreyNoise IP Lookup",
                    "url": "https://api.greynoise.io/v3/community",
                    "method": "GET",
                    "key_field": "key",
                    "key_location": "header",
                    "key": self.GREYNOISE_KEY,
                    "timeout": 15,
                    "health_check_url_suffix": "/8.8.8.8",
                }
            ],
            
            "PULSEDIVE": [
                {
                    "endpoint_name": "Pulsedive Analyze",
                    "url": "https://pulsedive.com/api/v1/analyze.php",
                    "method": "GET",
                    "key_field": "key",
                    "key_location": "param",
                    "key": self.PULSEDIVE_KEY,
                    "timeout": 20,
                    "health_check_params": {"indicator": "8.8.8.8", "type": "ip"},
                }
            ],
            
            "STORMGLASS": [
                {
                    "endpoint_name": "StormGlass Weather",
                    "url": "https://api.stormglass.io/v2/weather/point",
                    "method": "GET",
                    "key_field": "Authorization",
                    "key_location": "header",
                    "key": self.STORMGLASS_KEY,
                    "timeout": 20,
                    "fixed_headers": {"Content-Type": "application/json"},
                    "health_check_params": {"lat": 0, "lng": 0, "params": "airTemperature"},
                }
            ],
            
            "LOGINRADIUS": [
                {
                    "endpoint_name": "LoginRadius Ping",
                    "url": "https://api.loginradius.com/identity/v2/auth/ping",
                    "method": "GET",
                    "key_field": "X-LoginRadius-Api-Key",
                    "key_location": "header",
                    "key": self.LOGINRADIUS_KEY,
                    "timeout": 10,
                }
            ],
            
            "JSONBIN": [
                {
                    "endpoint_name": "Jsonbin Bin Create",
                    "url": "https://api.jsonbin.io/v3/b",
                    "method": "POST",
                    "key_field": "X-Master-Key",
                    "key_location": "header",
                    "key": self.JSONBIN_KEY,
                    "timeout": 15,
                    "fixed_headers": {"Content-Type": "application/json"},
                    "health_check_json": {"record": {"test": "ping"}, "private": True},
                },
                {
                    "endpoint_name": "Jsonbin Bin Access",
                    "url": "https://api.jsonbin.io/v3/b",
                    "method": "GET",
                    "key_field": "X-Master-Key",
                    "key_location": "header",
                    "key": self.JSONBIN_KEY,
                    "timeout": 15,
                    "health_check_url_suffix": "/657a7e3205741301340a6b12", # Exemple de bin ID pour le health check
                }
            ],
            
            "TWILIO": [
                {
                    "endpoint_name": "Twilio Account Balance",
                    "url": f"https://api.twilio.com/2010-04-01/Accounts/{self.TWILIO_SID}/Balance.json",
                    "method": "GET",
                    "key_field": None, # Pas de champ de clé spécifique, utilise l'authentification basique
                    "key_location": "auth_basic",
                    "key": (self.TWILIO_SID, self.TWILIO_SECRET), # Tuple pour l'authentification basique (username, password)
                    "timeout": 15,
                }
            ],
            
            "ABSTRACTAPI": [
                {
                    "endpoint_name": f"AbstractAPI Email Validation Key {i+1}",
                    "url": "https://emailvalidation.abstractapi.com/v1/",
                    "method": "GET",
                    "key_field": "api_key",
                    "key_location": "param",
                    "key": key,
                    "timeout": 15,
                    "health_check_params": {"email": "test@example.com"},
                } for i, key in enumerate(self.ABSTRACTAPI_EMAIL_KEYS)
            ] + [
                {
                    "endpoint_name": "AbstractAPI Phone Validation",
                    "url": "https://phonevalidation.abstractapi.com/v1/validate/",
                    "method": "GET",
                    "key_field": "api_key",
                    "key_location": "param",
                    "key": self.ABSTRACTAPI_GENERIC_KEY,
                    "timeout": 15,
                    "health_check_params": {"phone": "14150000000"},
                },
                {
                    "endpoint_name": "AbstractAPI Exchange Rates",
                    "url": "https://exchangerates.abstractapi.com/v1/live/",
                    "method": "GET",
                    "key_field": "api_key",
                    "key_location": "param",
                    "key": self.ABSTRACTAPI_GENERIC_KEY,
                    "timeout": 15,
                    "health_check_params": {"base": "USD"},
                },
                {
                    "endpoint_name": "AbstractAPI Holidays",
                    "url": "https://holidays.abstractapi.com/v1/",
                    "method": "GET",
                    "key_field": "api_key",
                    "key_location": "param",
                    "key": self.ABSTRACTAPI_GENERIC_KEY,
                    "timeout": 15,
                    "health_check_params": {"country": "US", "year": "2023", "month": "1", "day": "1"},
                }
            ],
            
            "RANDOMMER": [
                {
                    "endpoint_name": "Randommer Phone Number",
                    "url": "https://randommer.io/api/Phone/Generate",
                    "method": "GET",
                    "key_field": "X-Api-Key",
                    "key_location": "header",
                    "key": self.RANDOMMER_KEY,
                    "timeout": 10,
                    "health_check_params": {"CountryCode": "US", "Quantity": 1},
                }
            ],
            
            "TOMORROW.IO": [
                {
                    "endpoint_name": "Tomorrow.io Weather",
                    "url": "https://api.tomorrow.io/v4/timelines",
                    "method": "POST",
                    "key_field": "apikey",
                    "key_location": "param",
                    "key": self.TOMORROW_KEY,
                    "timeout": 20,
                    "fixed_headers": {"Content-Type": "application/json"},
                    "health_check_json": {"location": "42.3478, -73.9855", "fields": ["temperature"], "units": "metric", "timesteps": ["1h"]},
                }
            ],
            
            "OPENWEATHERMAP": [
                {
                    "endpoint_name": "OpenWeatherMap Current",
                    "url": "https://api.openweathermap.org/data/2.5/weather",
                    "method": "GET",
                    "key_field": "appid",
                    "key_location": "param",
                    "key": self.OPENWEATHER_API_KEY,
                    "timeout": 10,
                    "health_check_params": {"q": "London"},
                }
            ],
            
            "MOCKAROO": [
                {
                    "endpoint_name": "Mockaroo Generate Data",
                    "url": "https://api.mockaroo.com/api/generate.json",
                    "method": "GET",
                    "key_field": "key",
                    "key_location": "param",
                    "key": self.MOCKAROO_KEY,
                    "timeout": 15,
                    "health_check_params": {"count": 1, "fields": [{"name": "id", "type": "Row Number"}]},
                }
            ],
            
            "OPENPAGERANK": [
                {
                    "endpoint_name": "OpenPageRank Domains",
                    "url": "https://openpagerank.com/api/v1.0/getPageRank",
                    "method": "GET",
                    "key_field": "api-key",
                    "key_location": "header",
                    "key": self.OPENPAGERANK_KEY,
                    "timeout": 15,
                    "health_check_params": {"domains[]": ["google.com"]},
                }
            ],
            
            "RAPIDAPI": [
                {
                    "endpoint_name": "RapidAPI Programming Joke",
                    "url": "https://dad-jokes.p.rapidapi.com/random/joke",
                    "method": "GET",
                    "key_field": "X-RapidAPI-Key",
                    "key_location": "header",
                    "key": self.RAPIDAPI_KEY,
                    "timeout": 15,
                    "fixed_headers": {"X-RapidAPI-Host": "dad-jokes.p.rapidapi.com"},
                },
                {
                    "endpoint_name": "RapidAPI Currency List Quotes",
                    "url": "https://currency-exchange.p.rapidapi.com/exchange",
                    "method": "GET",
                    "key_field": "X-RapidAPI-Key",
                    "key_location": "header",
                    "key": self.RAPIDAPI_KEY,
                    "timeout": 15,
                    "fixed_headers": {"X-RapidAPI-Host": "currency-exchange.p.rapidapi.com"},
                    "health_check_params": {"from": "USD", "to": "EUR", "q": "1"},
                },
                {
                    "endpoint_name": "RapidAPI Random Fact",
                    "url": "https://random-facts2.p.rapidapi.com/randomFacts",
                    "method": "GET",
                    "key_field": "X-RapidAPI-Key",
                    "key_location": "header",
                    "key": self.RAPIDAPI_KEY,
                    "timeout": 15,
                    "fixed_headers": {"X-RapidAPI-Host": "random-facts2.p.rapidapi.com"},
                    "health_check_params": {"count": "1"},
                }
            ],
        } # <-- Fin du dictionnaire API_CONFIG
    
    def _build_tool_config(self) -> Dict[str, Dict[str, Any]]:
        """Configuration des outils disponibles pour tous les cerveaux."""
        return {
            "google_search": {
                "enabled": True,
                "description": "Effectue une recherche sur Google pour obtenir des informations. Utilisez cet outil pour des questions factuelles, des définitions, des actualités, etc.",
                "parameters": {
                    "queries": {"type": "ARRAY", "items": {"type": "STRING"}, "description": "Liste des requêtes de recherche à effectuer.", "required": True}
                }
            },
            "media_control": {
                "enabled": True,
                "description": "Contrôle la lecture multimédia (musique, vidéo).",
                "parameters": {
                    "action": {
                        "type": "STRING",
                        "description": "L'action à effectuer (like, dislike, next, previous, pause, resume, stop, replay, seek_absolute, seek_relative).",
                        "required": True,
                        "enum": ["like", "dislike", "next", "previous", "pause", "resume", "stop", "replay", "seek_absolute", "seek_relative"]
                    },
                    "position": {"type": "INTEGER", "description": "Position absolue en secondes pour seek_absolute.", "required": False},
                    "offset": {"type": "INTEGER", "description": "Décalage en secondes pour seek_relative.", "required": False}
                }
            },
            "clock": {
                "enabled": True,
                "description": "Gère les alarmes et les minuteurs.",
                "parameters": {
                    "action": {
                        "type": "STRING",
                        "description": "L'action à effectuer (create_alarm, create_timer, show_matching_alarms, show_matching_timers, modify_alarm_v2, modify_timer_v2, snooze).",
                        "required": True,
                        "enum": ["create_alarm", "create_timer", "show_matching_alarms", "show_matching_timers", "modify_alarm_v2", "modify_timer_v2", "snooze"]
                    },
                    "duration": {"type": "STRING", "description": "Durée pour le minuteur ou l'alarme (ex: '30 minutes', '1h 30m').", "required": False},
                    "time": {"type": "STRING", "description": "Heure spécifique pour l'alarme (ex: '07:00 AM', '14:30').", "required": False},
                    "date": {"type": "STRING", "description": "Date spécifique pour l'alarme (ex: '2023-12-25', 'demain').", "required": False},
                    "label": {"type": "STRING", "description": "Étiquette ou description pour l'alarme/minuteur.", "required": False},
                    "recurrence": {"type": "ARRAY", "items": {"type": "STRING"}, "description": "Jours de la semaine pour la récurrence de l'alarme (ex: ['MONDAY', 'WEDNESDAY']).", "required": False},
                    "query": {"type": "STRING", "description": "Requête de recherche pour les alarmes/minuteurs.", "required": False},
                    "alarm_type": {"type": "STRING", "description": "Type d'alarme à afficher (ex: 'active', 'snoozed').", "required": False},
                    "alarm_ids": {"type": "ARRAY", "items": {"type": "STRING"}, "description": "Liste des IDs d'alarmes à afficher ou modifier.", "required": False},
                    "timer_type": {"type": "STRING", "description": "Type de minuteur à afficher (ex: 'running', 'paused').", "required": False},
                    "timer_ids": {"type": "ARRAY", "items": {"type": "STRING"}, "description": "Liste des IDs de minuteurs à afficher ou modifier.", "required": False},
                    "alarm_filters": {"type": "OBJECT", "description": "Filtres pour sélectionner les alarmes à modifier.", "required": False},
                    "alarm_modifications": {"type": "OBJECT", "description": "Modifications à appliquer aux alarmes sélectionnées.", "required": False},
                    "timer_filters": {"type": "OBJECT", "description": "Filtres pour sélectionner les minuteurs à modifier.", "required": False},
                    "timer_modifications": {"type": "OBJECT", "description": "Modifications à appliquer aux minuteurs sélectionnées.", "required": False}
                }
            },
            "ocr_space": {
                "enabled": True,
                "description": "Extrait le texte d'une image en utilisant la reconnaissance optique de caractères (OCR). L'image doit être fournie sous forme de chaîne Base64 (data:image/png;base64,...).",
                "parameters": {
                    "image_base64": {"type": "STRING", "description": "L'image encodée en Base64, incluant le préfixe MIME (ex: data:image/png;base64,iVB...).", "required": True}
                }
            },
            "deepseek_chat": {
                "enabled": True,
                "description": "Interagit avec le modèle de chat DeepSeek pour des conversations générales ou des tâches de génération de texte. Utile pour des réponses créatives ou des discussions.",
                "parameters": {
                    "prompt": {"type": "STRING", "description": "Le prompt ou la liste de messages pour le modèle de chat.", "required": True},
                    "model": {"type": "STRING", "description": "Le nom du modèle DeepSeek à utiliser (ex: 'deepseek-chat', 'deepseek-coder').", "required": False, "default": "deepseek-chat"}
                }
            },
            "serper_dev": {
                "enabled": True,
                "description": "Effectue une recherche web via l'API Serper. Utile pour obtenir des snippets et des liens pertinents pour une requête.",
                "parameters": {
                    "query_text": {"type": "STRING", "description": "La requête de recherche.", "required": True}
                }
            },
            "wolfram_alpha": {
                "enabled": True,
                "description": "Interroge WolframAlpha pour des calculs, des faits scientifiques, des conversions d'unités, des informations mathématiques, etc.",
                "parameters": {
                    "input_text": {"type": "STRING", "description": "La requête à soumettre à WolframAlpha (ex: 'derivative of x^2', 'population of France').", "required": True}
                }
            },
            "tavily_search": {
                "enabled": True,
                "description": "Effectue une recherche web avancée via l'API Tavily, fournissant des réponses directes et des extraits pertinents.",
                "parameters": {
                    "query_text": {"type": "STRING", "description": "La requête de recherche.", "required": True},
                    "max_results": {"type": "INTEGER", "description": "Nombre maximum de résultats à retourner.", "required": False, "default": 3}
                }
            },
            "apiflash_screenshot": {
                "enabled": True,
                "description": "Capture une capture d'écran d'une page web à partir d'une URL donnée. Retourne une URL vers l'image capturée.",
                "parameters": {
                    "url": {"type": "STRING", "description": "L'URL de la page web à capturer.", "required": True}
                }
            },
            "crawlbase_scraper": {
                "enabled": True,
                "description": "Scrape le contenu HTML ou JavaScript d'une URL. Peut être utilisé pour obtenir le contenu brut d'une page web.",
                "parameters": {
                    "url": {"type": "STRING", "description": "L'URL de la page web à scraper.", "required": True},
                    "use_js": {"type": "BOOLEAN", "description": "Indique si le scraping doit exécuter JavaScript sur la page.", "required": False, "default": False}
                }
            },
            "detect_language": {
                "enabled": True,
                "description": "Détecte la langue d'un texte donné.",
                "parameters": {
                    "text": {"type": "STRING", "description": "Le texte dont la langue doit être détectée.", "required": True}
                }
            },
            "guardian_news": {
                "enabled": True,
                "description": "Recherche des articles de presse sur The Guardian. Utile pour des actualités ou des informations spécifiques.",
                "parameters": {
                    "query_text": {"type": "STRING", "description": "La requête de recherche pour les articles.", "required": True}
                }
            },
            "ip2location": {
                "enabled": True,
                "description": "Géolocalise une adresse IP pour obtenir des informations sur le pays, la ville, etc.",
                "parameters": {
                    "ip_address": {"type": "STRING", "description": "L'adresse IP à géolocaliser.", "required": True}
                }
            },
            "shodan": {
                "enabled": True,
                "description": "Interroge Shodan pour des informations sur un hôte IP ou des informations sur la clé API. Si une IP est fournie, retourne les infos de l'hôte, sinon les infos de la clé API.",
                "parameters": {
                    "query_text": {"type": "STRING", "description": "L'adresse IP à rechercher ou vide pour les infos de la clé API.", "required": False, "default": ""}
                }
            },
            "weather_api": {
                "enabled": True,
                "description": "Récupère les conditions météorologiques actuelles pour une localisation donnée.",
                "parameters": {
                    "location": {"type": "STRING", "description": "La ville ou le code postal pour la météo.", "required": True}
                }
            },
            "cloudmersive_domain": {
                "enabled": True,
                "description": "Vérifie la validité et le type d'un nom de domaine via Cloudmersive API.",
                "parameters": {
                    "domain": {"type": "STRING", "description": "Le nom de domaine à vérifier.", "required": True}
                }
            },
            "greynoise": {
                "enabled": True,
                "description": "Analyse une adresse IP pour détecter si elle est associée à des activités 'bruit' (scans, attaques, etc.) via GreyNoise.",
                "parameters": {
                    "ip_address": {"type": "STRING", "description": "L'adresse IP à analyser.", "required": True}
                }
            },
            "pulsedive": {
                "enabled": True,
                "description": "Analyse un indicateur de menace (IP, domaine, URL) via Pulsedive pour obtenir des informations sur les risques.",
                "parameters": {
                    "indicator": {"type": "STRING", "description": "L'indicateur de menace à analyser (ex: '8.8.8.8', 'example.com').", "required": True},
                    "type": {"type": "STRING", "description": "Le type d'indicateur ('auto', 'ip', 'domain', 'url').", "required": False, "default": "auto", "enum": ["auto", "ip", "domain", "url"]}
                }
            },
            "stormglass": {
                "enabled": True,
                "description": "Récupère les données météorologiques maritimes (température de l'air, hauteur des vagues, etc.) pour une coordonnée géographique.",
                "parameters": {
                    "lat": {"type": "NUMBER", "description": "Latitude.", "required": True},
                    "lng": {"type": "NUMBER", "description": "Longitude.", "required": True},
                    "params": {"type": "STRING", "description": "Paramètres météo à récupérer (comma-separated, ex: 'airTemperature,waveHeight').", "required": False, "default": "airTemperature,waveHeight"}
                }
            },
            "loginradius_ping": {
                "enabled": True,
                "description": "Effectue un simple ping à l'API LoginRadius pour vérifier sa disponibilité. Ne nécessite aucun paramètre.",
                "parameters": {}
            },
            "jsonbin_io": {
                "enabled": True,
                "description": "Crée un nouveau 'bin' JSON pour stocker des données ou accède à un bin existant. Utile pour stocker temporairement des données structurées.",
                "parameters": {
                    "data": {"type": "OBJECT", "description": "Les données JSON à stocker lors de la création d'un bin.", "required": False},
                    "private": {"type": "BOOLEAN", "description": "Indique si le bin doit être privé.", "required": False, "default": True},
                    "bin_id": {"type": "STRING", "description": "L'ID du bin existant à accéder.", "required": False}
                }
            },
            "huggingface_inference": {
                "enabled": True,
                "description": "Effectue une inférence sur un modèle HuggingFace (ex: classification de texte, génération de texte).",
                "parameters": {
                    "model_name": {"type": "STRING", "description": "Le nom du modèle HuggingFace à utiliser (ex: 'distilbert-base-uncased-finetuned-sst-2-english').", "required": False, "default": "distilbert-base-uncased-finetuned-sst-2-english"},
                    "input_text": {"type": "STRING", "description": "Le texte d'entrée pour l'inférence.", "required": True}
                }
            },
            "twilio_balance": {
                "enabled": True,
                "description": "Récupère le solde du compte Twilio. Utile pour vérifier les crédits restants pour l'envoi de SMS/appels.",
                "parameters": {}
            },
            "abstractapi": {
                "enabled": True,
                "description": "Interroge diverses APIs d'AbstractAPI pour la validation d'emails/téléphones, les taux de change ou les jours fériés.",
                "parameters": {
                    "input_value": {"type": "STRING", "description": "La valeur d'entrée (email, numéro de téléphone, devise de base, code pays) selon le type d'API.", "required": True},
                    "api_type": {"type": "STRING", "description": "Le type d'API AbstractAPI à utiliser ('PHONE_VALIDATION', 'EMAIL_VALIDATION', 'EXCHANGE_RATES', 'HOLIDAYS').", "required": True, "enum": ["PHONE_VALIDATION", "EMAIL_VALIDATION", "EXCHANGE_RATES", "HOLIDAYS"]}
                }
            },
            "google_custom_search": {
                "enabled": True,
                "description": "Effectue une recherche personnalisée Google en utilisant l'API Custom Search. Nécessite un ID de moteur de recherche personnalisé (CSE ID).",
                "parameters": {
                    "query_text": {"type": "STRING", "description": "La requête de recherche.", "required": True}
                }
            },
            "randommer_phone": {
                "enabled": True,
                "description": "Génère des numéros de téléphone aléatoires pour un pays donné. Utile pour des données de test ou des exemples.",
                "parameters": {
                    "country_code": {"type": "STRING", "description": "Le code ISO du pays (ex: 'US', 'FR').", "required": False, "default": "US"},
                    "quantity": {"type": "INTEGER", "description": "Le nombre de numéros de téléphone à générer.", "required": False, "default": 1}
                }
            },
            "tomorrow_io_weather": {
                "enabled": True,
                "description": "Récupère les prévisions météorologiques détaillées via Tomorrow.io pour une localisation et des champs spécifiques.",
                "parameters": {
                    "location": {"type": "STRING", "description": "La localisation (nom de ville, code postal, coordonnées lat/lng).", "required": True},
                    "fields": {"type": "ARRAY", "items": {"type": "STRING"}, "description": "Liste des champs météo à récupérer (ex: ['temperature', 'humidity']).", "required": False, "default": ["temperature", "humidity", "windSpeed"]}
                }
            },
            "openweathermap_weather": {
                "enabled": True,
                "description": "Récupère les conditions météorologiques actuelles via OpenWeatherMap pour une localisation donnée.",
                "parameters": {
                    "location": {"type": "STRING", "description": "La ville ou le code postal pour la météo.", "required": True}
                }
            },
            "mockaroo_data": {
                "enabled": True,
                "description": "Génère des données de test aléatoires via Mockaroo en fonction d'un schéma JSON.",
                "parameters": {
                    "count": {"type": "INTEGER", "description": "Le nombre d'enregistrements à générer.", "required": False, "default": 1},
                    "fields_json": {"type": "STRING", "description": "Un tableau JSON de définitions de champs (ex: '[{\"name\":\"id\",\"type\":\"Row Number\"}]').", "required": False}
                }
            },
            "openpagerank": {
                "enabled": True,
                "description": "Récupère le PageRank de domaines via OpenPageRank. Utile pour évaluer l'autorité d'un site web.",
                "parameters": {
                    "domains": {"type": "ARRAY", "items": {"type": "STRING"}, "description": "Liste des noms de domaine à vérifier (ex: ['google.com', 'openai.com']).", "required": True}
                }
            },
            "rapidapi": {
                "enabled": True,
                "description": "Interroge diverses APIs disponibles via RapidAPI (blagues, taux de change, faits aléatoires).",
                "parameters": {
                    "api_name": {"type": "STRING", "description": "Le nom de l'API RapidAPI à utiliser (ex: 'Programming Joke', 'Currency List Quotes', 'Random Fact').", "required": True, "enum": ["Programming Joke", "Currency List Quotes", "Random Fact"]},
                    "api_kwargs": {"type": "OBJECT", "description": "Arguments spécifiques à l'API RapidAPI appelée.", "required": False}
                }
            },
            "run_in_sandbox": {
                "enabled": True,
                "description": "Exécute du code Python ou Shell dans une sandbox sécurisée. Utilisez cet outil pour tester ou exécuter des extraits de code.",
                "parameters": {
                    "code": {"type": "STRING", "description": "Le code à exécuter.", "required": True},
                    "language": {"type": "STRING", "description": "Le langage du code ('python' ou 'shell').", "required": False, "default": "python", "enum": ["python", "shell"]}
                }
            },
            "webcontainer_sandbox": {
                "enabled": True,
                "description": "Exécute du code dans un environnement WebContainer pour JavaScript/HTML/CSS.",
                "parameters": {
                    "code": {"type": "STRING", "description": "Le code à exécuter.", "required": True},
                    "language": {"type": "STRING", "description": "Le langage du code ('javascript', 'html', 'css').", "required": False, "default": "javascript"}
                }
            },
            "fetch_and_archive_pages": {
                "enabled": True,
                "description": "Télécharge, sécurise et archive des pages web avec protection contre les trackers.",
                "parameters": {
                    "links": {"type": "ARRAY", "items": {"type": "STRING"}, "description": "Liste des URLs à archiver.", "required": True},
                    "user_id": {"type": "STRING", "description": "Identifiant de l'utilisateur pour l'archivage.", "required": True}
                }
            }
        }

# Instance globale de configuration
config = Config()

import requests
import json
import asyncio
import httpx
from typing import Dict, Any, List, Optional, Tuple, Union
import logging
from datetime import datetime
import random

from config import config
from app_singletons import endpoint_health_manager, quota_manager
from utils import log_message

class ApiClient:
    """
    Classe de base pour tous les clients API des 7 cerveaux autonomes.
    Gère les requêtes HTTP, la rotation des clés et le basculement automatique.
    """
    def __init__(self, service_name: str, config_manager: Any,
                 health_manager: Any, quota_manager: Any):
        self.service_name = service_name
        self.config = config_manager
        self.health_manager = health_manager
        self.quota_manager = quota_manager
        self.endpoints = self.config.API_CONFIG.get(service_name, [])
        self.current_endpoint_index = 0
        self.last_rotation_time = datetime.now()

        if not self.endpoints:
            log_message(f"Aucun endpoint configuré pour le service {service_name}", level="warning")

    async def _make_request(self, endpoint_config: Dict[str, Any],
                          url_suffix: str = "", params: Optional[Dict] = None,
                          json_data: Optional[Dict] = None,
                          files: Optional[Dict] = None) -> Union[Dict, str]:
        """Effectue une requête HTTP vers un endpoint spécifique."""
        full_url = endpoint_config["url"] + url_suffix
        method = endpoint_config["method"]
        timeout = endpoint_config.get("timeout", 30)
        headers = endpoint_config.get("fixed_headers", {}).copy()
        req_params = endpoint_config.get("fixed_params", {}).copy()

        if params:
            req_params.update(params)

        key_field = endpoint_config.get("key_field")
        key_location = endpoint_config.get("key_location")
        key = endpoint_config.get("key")
        key_prefix = endpoint_config.get("key_prefix", "")

        if key:
            if key_location == "header":
                headers[key_field] = f"{key_prefix}{key}"
            elif key_location == "param":
                req_params[key_field] = key
            elif key_location == "auth_basic" and isinstance(key, tuple) and len(key) == 2:
                pass  # L'authentification sera gérée par httpx.AsyncClient

        async with httpx.AsyncClient() as client:
            try:
                log_message(f"Requête {self.service_name} vers {full_url}")
                start_time = asyncio.get_event_loop().time()

                request_kwargs = {
                    "params": req_params,
                    "headers": headers,
                    "timeout": timeout
                }

                if json_data:
                    request_kwargs["json"] = json_data
                if files:
                    request_kwargs["files"] = files
                if key_location == "auth_basic" and isinstance(key, tuple) and len(key) == 2:
                    request_kwargs["auth"] = key

                if method == "POST":
                    response = await client.post(full_url, **request_kwargs)
                elif method == "GET":
                    response = await client.get(full_url, **request_kwargs)
                else:
                    raise ValueError(f"Méthode HTTP non supportée: {method}")

                response.raise_for_status()
                latency = asyncio.get_event_loop().time() - start_time
                log_message(f"Réponse {self.service_name}: {response.status_code} en {latency:.2f}s")

                try:
                    return response.json()
                except json.JSONDecodeError:
                    return {"status": "success", "content": response.text}

            except httpx.HTTPStatusError as e:
                log_message(f"API {self.service_name} erreur HTTP: {e.response.status_code} - {e.response.text}", level="warning")
                if 400 <= e.response.status_code < 500 and e.response.status_code not in [429]:
                    await self.health_manager.mark_unhealthy(endpoint_config["endpoint_name"], self.service_name, "API_CLIENT_ERROR")
                elif e.response.status_code >= 500:
                    await self.health_manager.mark_unhealthy(endpoint_config["endpoint_name"], self.service_name, "API_SERVER_ERROR")
                return f"❌ Erreur API {self.service_name}: {e.response.status_code} - {e.response.text}"

            except httpx.RequestError as e:
                log_message(f"API {self.service_name} erreur réseau: {e}", level="warning")
                await self.health_manager.mark_unhealthy(endpoint_config["endpoint_name"], self.service_name, "NETWORK_ERROR")
                return f"❌ Erreur réseau pour {self.service_name}: {e}"

            except Exception as e:
                log_message(f"API {self.service_name} erreur inattendue: {e}", level="error")
                await self.health_manager.mark_unhealthy(endpoint_config["endpoint_name"], self.service_name, "UNKNOWN_ERROR")
                return f"❌ Erreur inattendue pour {self.service_name}: {e}"

    async def _get_available_endpoint(self) -> Optional[Dict[str, Any]]:
        """Sélectionne un endpoint sain et avec quota disponible."""
        num_endpoints = len(self.endpoints)
        if num_endpoints == 0:
            log_message(f"Aucun endpoint configuré pour le service {self.service_name}.", level="warning")
            return None

        # Rotation pour les services LLM
        if self.service_name in ["GEMINI_API", "DEEPSEEK", "HUGGINGFACE"]:
            current_time = datetime.now()
            if (current_time - self.last_rotation_time).total_seconds() >= config.BRAIN_ROTATION_INTERVAL_SECONDS:
                self.current_endpoint_index = (self.current_endpoint_index + 1) % num_endpoints
                self.last_rotation_time = current_time
                log_message(f"Rotation d'endpoint pour {self.service_name}. Nouvel index: {self.current_endpoint_index}")

        # Essayer tous les endpoints
        initial_index = self.current_endpoint_index
        for _ in range(num_endpoints):
            endpoint_config = self.endpoints[self.current_endpoint_index]
            endpoint_name = endpoint_config["endpoint_name"]

            is_healthy = await self.health_manager.is_healthy(endpoint_name, self.service_name)
            has_quota = await self.quota_manager.check_quota(self.service_name)

            log_message(f"Vérification endpoint {endpoint_name} pour {self.service_name}: Sain={is_healthy}, Quota={has_quota}")

            if is_healthy and has_quota:
                log_message(f"Endpoint sélectionné pour {self.service_name}: {endpoint_name}")
                return endpoint_config
            else:
                self.current_endpoint_index = (self.current_endpoint_index + 1) % num_endpoints
                log_message(f"Endpoint {endpoint_name} non disponible. Passage au suivant.")
                if self.current_endpoint_index == initial_index:
                    break

        log_message(f"Aucun endpoint sain ou disponible pour {self.service_name}.", level="warning")
        return None

    async def _increment_quota(self):
        """Incrémente le quota pour le service."""
        await self.quota_manager.increment_quota(self.service_name)

class LLMApiClient(ApiClient):
    """Classe de base pour les clients d'API de modèles de langage."""
    def __init__(self, service_name: str, config_manager: Any,
                 health_manager: Any, quota_manager: Any):
        super().__init__(service_name, config_manager, health_manager, quota_manager)
        self.default_model: str = ""

    async def generate_content(self, prompt: Union[str, List[Dict[str, Any]]],
                              chat_history: List[Dict[str, Any]],
                              image_data: Optional[str] = None,
                              tools: Optional[List[Dict]] = None,
                              model_name: Optional[str] = None) -> Union[Dict, str]:
        """Méthode abstraite pour générer du contenu."""
        raise NotImplementedError("La méthode 'generate_content' doit être implémentée par les sous-classes.")

class GeminiApiClient(LLMApiClient):
    """Client API pour Gemini avec support complet des 7 cerveaux autonomes."""
    def __init__(self, health_manager: Any, quota_manager: Any):
        super().__init__("GEMINI_API", config, health_manager, quota_manager)
        self.default_model = "gemini-1.5-flash-latest"
        log_message(f"GeminiApiClient initialisé avec le modèle par défaut: {self.default_model}")

    async def generate_content(self, prompt: Union[str, List[Dict[str, Any]]],
                              chat_history: List[Dict[str, Any]],
                              image_data: Optional[str] = None,
                              tools: Optional[List[Dict]] = None,
                              model_name: Optional[str] = None) -> Union[Dict, str]:
        """Génère du contenu textuel en utilisant le modèle Gemini."""
        import google.generativeai as genai

        log_message(f"Appel à Gemini API pour le modèle {model_name or self.default_model}")

        endpoint_config = await self._get_available_endpoint()
        if not endpoint_config:
            return f"❌ Erreur Gemini: Aucun endpoint sain ou disponible pour {self.service_name}."

        genai.configure(api_key=endpoint_config["key"])
        log_message(f"Configuration de genai avec la clé de l'endpoint: {endpoint_config['endpoint_name']}")

        await self._increment_quota()

        # Préparation du contenu
        contents = []
        for msg in chat_history:
            formatted_parts = []
            for part in msg.get("parts", []):
                if "text" in part:
                    formatted_parts.append(part["text"])
                elif "function_response" in part:
                    formatted_parts.append(genai.types.FunctionResponse(
                        name=part["function_response"]["name"],
                        response=part["function_response"]["response"]
                    ))
                elif "function_call" in part:
                    formatted_parts.append(genai.types.FunctionCall(
                        name=part["function_call"]["name"],
                        args=part["function_call"]["args"]
                    ))
                elif "inlineData" in part:
                    formatted_parts.append(genai.types.Blob(
                        mime_type=part["inlineData"]["mimeType"],
                        data=part["inlineData"]["data"]
                    ))
            contents.append({"role": msg["role"], "parts": formatted_parts})

        # Ajout du prompt actuel
        user_parts = []
        if isinstance(prompt, str):
            user_parts.append(prompt)
        elif isinstance(prompt, list):
            user_parts.extend(prompt)

        if image_data:
            mime_type = image_data.split(';')[0].split(':')[1]
            base64_string = image_data.split(',')[1]
            user_parts.append(genai.types.Blob(mime_type=mime_type, data=base64_string))

        contents.append({"role": "user", "parts": user_parts})

        # Préparation des outils
        genai_tools = None
        if tools:
            genai_tools = [genai.types.FunctionDeclaration(**tool["function_declarations"][0]) 
                          for tool in tools if "function_declarations" in tool and tool["function_declarations"]]

        try:
            model_to_use = model_name if model_name else self.default_model
            model_instance = genai.GenerativeModel(model_to_use, tools=genai_tools)

            response = await model_instance.generate_content_async(
                contents=contents,
                generation_config=genai.types.GenerationConfig(
                    temperature=config.GEMINI_TEMPERATURE,
                    top_p=config.GEMINI_TOP_P,
                    top_k=config.GEMINI_TOP_K,
                    max_output_tokens=config.GEMINI_MAX_OUTPUT_TOKENS,
                ),
                safety_settings=config.GEMINI_SAFETY_SETTINGS,
            )

            response_dict = response.to_dict()
            return response_dict

        except Exception as e:
            log_message(f"API GEMINI_API erreur sur l'endpoint {endpoint_config['endpoint_name']}: {e}", level="error")
            if "PERMISSION_DENIED" in str(e) or "RESOURCE_EXHAUSTED" in str(e):
                await self.health_manager.mark_unhealthy(endpoint_config["endpoint_name"], self.service_name, "PERMISSION_DENIED_OR_QUOTA_EXCEEDED")
                return f"❌ Erreur Gemini (à réessayer): {e}"
            else:
                await self.health_manager.mark_unhealthy(endpoint_config["endpoint_name"], self.service_name, "API_ERROR")
                return f"❌ Erreur Gemini: {e}"

class TelegramBotClient(ApiClient):
    """Client API pour l'API Bot de Telegram."""
    def __init__(self, health_manager: Any, quota_manager: Any):
        super().__init__("TELEGRAM_BOT", config, health_manager, quota_manager)
        
        if not self.endpoints:
            self.endpoints.append({
                "endpoint_name": "Telegram Bot API",
                "url": f"https://api.telegram.org/bot{config.TELEGRAM_BOT_TOKEN}",
                "method": "POST",
                "key_field": None,
                "key_location": None,
                "key": config.TELEGRAM_BOT_TOKEN,
                "timeout": 10,
                "fixed_headers": {"Content-Type": "application/json"},
                "health_check_url_suffix": "/getMe",
                "health_check_json": {}
            })
        log_message("TelegramBotClient initialisé.")

    async def send_message(self, chat_id: Union[int, str], text: str, parse_mode: Optional[str] = None) -> Union[Dict, str]:
        """Envoie un message texte à un chat Telegram spécifié."""
        endpoint_config = await self._get_available_endpoint()
        if not endpoint_config:
            return f"❌ Erreur Telegram: Aucun endpoint sain ou disponible."

        await self._increment_quota()

        json_data = {
            "chat_id": chat_id,
            "text": text,
        }
        if parse_mode:
            json_data["parse_mode"] = parse_mode

        send_message_url_suffix = "/sendMessage"
        return await self._make_request(endpoint_config, url_suffix=send_message_url_suffix, json_data=json_data)

# Clients API spécialisés pour chaque service

class WebContainerClient(ApiClient):
    def __init__(self, health_manager: Any, quota_manager: Any):
        super().__init__("WEBCONTAINER", config, health_manager, quota_manager)

    async def run_code(self, code: str, language: str = "javascript") -> Union[Dict, str]:
        endpoint_config = await self._get_available_endpoint()
        if not endpoint_config:
            return f"❌ Erreur WebContainer: Aucun endpoint sain ou disponible."

        await self._increment_quota()
        json_data = {
            "action": "execute",
            "language": language,
            "code": code
        }
        return await self._make_request(endpoint_config, json_data=json_data)

class OCRApiClient(ApiClient):
    def __init__(self, health_manager: Any, quota_manager: Any):
        super().__init__("OCR_API", config, health_manager, quota_manager)

    async def parse_image(self, image_base64: str, language: str = "eng") -> Union[Dict, str]:
        endpoint_config = await self._get_available_endpoint()
        if not endpoint_config:
            return f"❌ Erreur OCR: Aucun endpoint sain ou disponible."

        await self._increment_quota()
        json_data = {
            "base64Image": image_base64,
            "language": language,
            "isOverlayRequired": False
        }
        return await self._make_request(endpoint_config, json_data=json_data)

class DeepSeekClient(ApiClient):
    def __init__(self, health_manager: Any, quota_manager: Any):
        super().__init__("DEEPSEEK", config, health_manager, quota_manager)

    async def chat_completion(self, messages: List[Dict[str, str]], model: str = "deepseek-chat") -> Union[Dict, str]:
        endpoint_config = await self._get_available_endpoint()
        if not endpoint_config:
            return f"❌ Erreur DeepSeek: Aucun endpoint sain ou disponible."

        await self._increment_quota()
        json_data = {
            "model": model,
            "messages": messages
        }
        return await self._make_request(endpoint_config, json_data=json_data)

class SerperClient(ApiClient):
    def __init__(self, health_manager: Any, quota_manager: Any):
        super().__init__("SERPER", config, health_manager, quota_manager)

    async def search(self, query: str) -> Union[Dict, str]:
        endpoint_config = await self._get_available_endpoint()
        if not endpoint_config:
            return f"❌ Erreur Serper: Aucun endpoint sain ou disponible."

        await self._increment_quota()
        json_data = {"q": query}
        return await self._make_request(endpoint_config, json_data=json_data)

class WolframAlphaClient(ApiClient):
    def __init__(self, health_manager: Any, quota_manager: Any):
        super().__init__("WOLFRAMALPHA", config, health_manager, quota_manager)

    async def query(self, input_text: str) -> Union[Dict, str]:
        endpoint_config = await self._get_available_endpoint()
        if not endpoint_config:
            return f"❌ Erreur WolframAlpha: Aucun endpoint sain ou disponible."

        await self._increment_quota()
        params = {"input": input_text, "output": "json"}
        return await self._make_request(endpoint_config, params=params)

class TavilyClient(ApiClient):
    def __init__(self, health_manager: Any, quota_manager: Any):
        super().__init__("TAVILY", config, health_manager, quota_manager)

    async def search(self, query: str, max_results: int = 3) -> Union[Dict, str]:
        endpoint_config = await self._get_available_endpoint()
        if not endpoint_config:
            return f"❌ Erreur Tavily: Aucun endpoint sain ou disponible."

        await self._increment_quota()
        json_data = {"query": query, "max_results": max_results}
        return await self._make_request(endpoint_config, json_data=json_data)

class ApiFlashClient(ApiClient):
    def __init__(self, health_manager: Any, quota_manager: Any):
        super().__init__("APIFLASH", config, health_manager, quota_manager)

    async def screenshot(self, url: str) -> Union[Dict, str]:
        endpoint_config = await self._get_available_endpoint()
        if not endpoint_config:
            return f"❌ Erreur ApiFlash: Aucun endpoint sain ou disponible."

        await self._increment_quota()
        params = {"url": url, "format": "jpeg"}
        return await self._make_request(endpoint_config, params=params)

class CrawlbaseClient(ApiClient):
    def __init__(self, health_manager: Any, quota_manager: Any):
        super().__init__("CRAWLBASE", config, health_manager, quota_manager)

    async def scrape(self, url: str, use_js: bool = False) -> Union[Dict, str]:
        endpoint_config = await self._get_available_endpoint()
        if not endpoint_config:
            return f"❌ Erreur Crawlbase: Aucun endpoint sain ou disponible."

        await self._increment_quota()
        params = {"url": url}
        if use_js:
            params["javascript"] = "true"
        return await self._make_request(endpoint_config, params=params)

class DetectLanguageClient(ApiClient):
    def __init__(self, health_manager: Any, quota_manager: Any):
        super().__init__("DETECTLANGUAGE", config, health_manager, quota_manager)

    async def detect(self, text: str) -> Union[Dict, str]:
        endpoint_config = await self._get_available_endpoint()
        if not endpoint_config:
            return f"❌ Erreur DetectLanguage: Aucun endpoint sain ou disponible."

        await self._increment_quota()
        json_data = {"q": text}
        return await self._make_request(endpoint_config, json_data=json_data)

class GuardianClient(ApiClient):
    def __init__(self, health_manager: Any, quota_manager: Any):
        super().__init__("GUARDIAN", config, health_manager, quota_manager)

    async def search_news(self, query: str) -> Union[Dict, str]:
        endpoint_config = await self._get_available_endpoint()
        if not endpoint_config:
            return f"❌ Erreur Guardian: Aucun endpoint sain ou disponible."

        await self._increment_quota()
        params = {"q": query}
        return await self._make_request(endpoint_config, params=params)

class IP2LocationClient(ApiClient):
    def __init__(self, health_manager: Any, quota_manager: Any):
        super().__init__("IP2LOCATION", config, health_manager, quota_manager)

    async def geolocate_ip(self, ip_address: str) -> Union[Dict, str]:
        endpoint_config = await self._get_available_endpoint()
        if not endpoint_config:
            return f"❌ Erreur IP2Location: Aucun endpoint sain ou disponible."

        await self._increment_quota()
        params = {"ip": ip_address, "package": "WS24", "format": "json"}
        return await self._make_request(endpoint_config, params=params)

class ShodanClient(ApiClient):
    def __init__(self, health_manager: Any, quota_manager: Any):
        super().__init__("SHODAN", config, health_manager, quota_manager)

    async def get_info(self, query_text: str = "") -> Union[Dict, str]:
        endpoint_config = await self._get_available_endpoint()
        if not endpoint_config:
            return f"❌ Erreur Shodan: Aucun endpoint sain ou disponible."

        await self._increment_quota()

        if query_text:
            url_suffix = f"/{query_text}"
            return await self._make_request(endpoint_config, url_suffix=url_suffix)
        else:
            api_info_endpoint = next((ep for ep in self.endpoints if "API Info" in ep.get("endpoint_name", "")), None)
            if api_info_endpoint:
                return await self._make_request(api_info_endpoint)
            else:
                return "❌ Erreur Shodan: Endpoint 'API Info' non trouvé dans la configuration."

class WeatherAPIClient(ApiClient):
    def __init__(self, health_manager: Any, quota_manager: Any):
        super().__init__("WEATHERAPI", config, health_manager, quota_manager)

    async def get_current_weather(self, location: str) -> Union[Dict, str]:
        endpoint_config = await self._get_available_endpoint()
        if not endpoint_config:
            return f"❌ Erreur WeatherAPI: Aucun endpoint sain ou disponible."

        await self._increment_quota()
        params = {"q": location}
        return await self._make_request(endpoint_config, params=params)

class CloudmersiveClient(ApiClient):
    def __init__(self, health_manager: Any, quota_manager: Any):
        super().__init__("CLOUDMERSIVE", config, health_manager, quota_manager)

    async def validate_domain(self, domain: str) -> Union[Dict, str]:
        endpoint_config = await self._get_available_endpoint()
        if not endpoint_config:
            return f"❌ Erreur Cloudmersive: Aucun endpoint sain ou disponible."

        await self._increment_quota()
        json_data = {"domain": domain}
        return await self._make_request(endpoint_config, json_data=json_data)

class GreyNoiseClient(ApiClient):
    def __init__(self, health_manager: Any, quota_manager: Any):
        super().__init__("GREYNOISE", config, health_manager, quota_manager)

    async def ip_lookup(self, ip_address: str) -> Union[Dict, str]:
        endpoint_config = await self._get_available_endpoint()
        if not endpoint_config:
            return f"❌ Erreur GreyNoise: Aucun endpoint sain ou disponible."

        await self._increment_quota()
        url_suffix = f"/{ip_address}"
        return await self._make_request(endpoint_config, url_suffix=url_suffix)

class PulsediveClient(ApiClient):
    def __init__(self, health_manager: Any, quota_manager: Any):
        super().__init__("PULSEDIVE", config, health_manager, quota_manager)

    async def analyze_indicator(self, indicator: str, type: str = "auto") -> Union[Dict, str]:
        endpoint_config = await self._get_available_endpoint()
        if not endpoint_config:
            return f"❌ Erreur Pulsedive: Aucun endpoint sain ou disponible."

        await self._increment_quota()
        params = {"indicator": indicator, "type": type}
        return await self._make_request(endpoint_config, params=params)

class StormGlassClient(ApiClient):
    def __init__(self, health_manager: Any, quota_manager: Any):
        super().__init__("STORMGLASS", config, health_manager, quota_manager)

    async def get_weather_point(self, lat: float, lng: float, params: str = "airTemperature,waveHeight") -> Union[Dict, str]:
        endpoint_config = await self._get_available_endpoint()
        if not endpoint_config:
            return f"❌ Erreur StormGlass: Aucun endpoint sain ou disponible."

        await self._increment_quota()
        req_params = {"lat": lat, "lng": lng, "params": params}
        return await self._make_request(endpoint_config, params=req_params)

class LoginRadiusClient(ApiClient):
    def __init__(self, health_manager: Any, quota_manager: Any):
        super().__init__("LOGINRADIUS", config, health_manager, quota_manager)

    async def ping(self) -> Union[Dict, str]:
        endpoint_config = await self._get_available_endpoint()
        if not endpoint_config:
            return f"❌ Erreur LoginRadius: Aucun endpoint sain ou disponible."

        await self._increment_quota()
        return await self._make_request(endpoint_config)

class JsonbinClient(ApiClient):
    def __init__(self, health_manager: Any, quota_manager: Any):
        super().__init__("JSONBIN", config, health_manager, quota_manager)

    async def handle_bin(self, data: Optional[Dict] = None, private: bool = True, bin_id: Optional[str] = None) -> Union[Dict, str]:
        endpoint_config = await self._get_available_endpoint()
        if not endpoint_config:
            return f"❌ Erreur Jsonbin: Aucun endpoint sain ou disponible."

        await self._increment_quota()

        if bin_id:
            access_endpoint = next((ep for ep in self.endpoints if "Bin Access" in ep.get("endpoint_name", "")), None)
            if not access_endpoint:
                return "❌ Erreur Jsonbin: Endpoint 'Bin Access' non trouvé dans la configuration."
            return await self._make_request(access_endpoint, url_suffix=f"/{bin_id}")
        elif data:
            create_endpoint = next((ep for ep in self.endpoints if "Bin Create" in ep.get("endpoint_name", "")), None)
            if not create_endpoint:
                return "❌ Erreur Jsonbin: Endpoint 'Bin Create' non trouvé dans la configuration."
            json_data = {"record": data, "private": private}
            return await self._make_request(create_endpoint, json_data=json_data)
        else:
            return "❌ Erreur Jsonbin: Veuillez fournir des données pour créer un bin ou un ID de bin pour y accéder."

class HuggingFaceClient(ApiClient):
    def __init__(self, health_manager: Any, quota_manager: Any):
        super().__init__("HUGGINGFACE", config, health_manager, quota_manager)

    async def inference(self, model_name: str, input_text: str) -> Union[Dict, str]:
        endpoint_config = await self._get_available_endpoint()
        if not endpoint_config:
            return f"❌ Erreur HuggingFace: Aucun endpoint sain ou disponible."

        await self._increment_quota()
        url_suffix = model_name
        json_data = {"inputs": input_text}
        return await self._make_request(endpoint_config, url_suffix=url_suffix, json_data=json_data)

class TwilioClient(ApiClient):
    def __init__(self, health_manager: Any, quota_manager: Any):
        super().__init__("TWILIO", config, health_manager, quota_manager)

    async def get_account_balance(self) -> Union[Dict, str]:
        endpoint_config = await self._get_available_endpoint()
        if not endpoint_config:
            return f"❌ Erreur Twilio: Aucun endpoint sain ou disponible."

        await self._increment_quota()
        return await self._make_request(endpoint_config)

class AbstractAPIClient(ApiClient):
    def __init__(self, health_manager: Any, quota_manager: Any):
        super().__init__("ABSTRACTAPI", config, health_manager, quota_manager)

    async def call_api(self, input_value: str, api_type: str) -> Union[Dict, str]:
        endpoint_config = await self._get_available_endpoint()
        if not endpoint_config:
            return f"❌ Erreur AbstractAPI: Aucun endpoint sain ou disponible."

        await self._increment_quota()

        params = {}
        url_suffix = ""

        if api_type == "EMAIL_VALIDATION":
            email_endpoint = next((ep for ep in self.endpoints if "Email Validation" in ep.get("endpoint_name", "")), None)
            if not email_endpoint:
                return "❌ Erreur AbstractAPI: Endpoint de validation d'email non configuré."
            params["email"] = input_value
            endpoint_config = email_endpoint
        elif api_type == "PHONE_VALIDATION":
            phone_endpoint = next((ep for ep in self.endpoints if "Phone Validation" in ep.get("endpoint_name", "")), None)
            if not phone_endpoint:
                return "❌ Erreur AbstractAPI: Endpoint de validation de téléphone non configuré."
            params["phone"] = input_value
            endpoint_config = phone_endpoint
        elif api_type == "EXCHANGE_RATES":
            exchange_endpoint = next((ep for ep in self.endpoints if "Exchange Rates" in ep.get("endpoint_name", "")), None)
            if not exchange_endpoint:
                return "❌ Erreur AbstractAPI: Endpoint de taux de change non configuré."
            params["base"] = input_value
            endpoint_config = exchange_endpoint
        elif api_type == "HOLIDAYS":
            holidays_endpoint = next((ep for ep in self.endpoints if "Holidays" in ep.get("endpoint_name", "")), None)
            if not holidays_endpoint:
                return "❌ Erreur AbstractAPI: Endpoint de jours fériés non configuré."
            params["country"] = input_value
            params["year"] = datetime.now().year
            endpoint_config = holidays_endpoint
        else:
            return f"❌ Type d'API AbstractAPI non supporté: {api_type}"

        return await self._make_request(endpoint_config, params=params, url_suffix=url_suffix)

class GoogleCustomSearchClient(ApiClient):
    def __init__(self, health_manager: Any, quota_manager: Any):
        super().__init__("GOOGLE_CUSTOM_SEARCH", config, health_manager, quota_manager)

    async def search(self, query: str) -> Union[Dict, str]:
        endpoint_config = await self._get_available_endpoint()
        if not endpoint_config:
            return f"❌ Erreur Google Custom Search: Aucun endpoint sain ou disponible."

        await self._increment_quota()
        params = {"q": query}
        return await self._make_request(endpoint_config, params=params)

class RandommerClient(ApiClient):
    def __init__(self, health_manager: Any, quota_manager: Any):
        super().__init__("RANDOMMER", config, health_manager, quota_manager)

    async def generate_phone_number(self, country_code: str = "US", quantity: int = 1) -> Union[Dict, str]:
        endpoint_config = await self._get_available_endpoint()
        if not endpoint_config:
            return f"❌ Erreur Randommer: Aucun endpoint sain ou disponible."

        await self._increment_quota()
        params = {"CountryCode": country_code, "Quantity": quantity}
        return await self._make_request(endpoint_config, params=params)

class TomorrowIOClient(ApiClient):
    def __init__(self, health_manager: Any, quota_manager: Any):
        super().__init__("TOMORROW.IO", config, health_manager, quota_manager)

    async def get_weather_timelines(self, location: str, fields: List[str]) -> Union[Dict, str]:
        endpoint_config = await self._get_available_endpoint()
        if not endpoint_config:
            return f"❌ Erreur Tomorrow.io: Aucun endpoint sain ou disponible."

        await self._increment_quota()
        json_data = {
            "location": location,
            "fields": fields,
            "units": "metric",
            "timesteps": ["1h"]
        }
        return await self._make_request(endpoint_config, json_data=json_data)

class OpenWeatherMapClient(ApiClient):
    def __init__(self, health_manager: Any, quota_manager: Any):
        super().__init__("OPENWEATHERMAP", config, health_manager, quota_manager)

    async def get_current_weather(self, location: str) -> Union[Dict, str]:
        endpoint_config = await self._get_available_endpoint()
        if not endpoint_config:
            return f"❌ Erreur OpenWeatherMap: Aucun endpoint sain ou disponible."

        await self._increment_quota()
        params = {"q": location}
        return await self._make_request(endpoint_config, params=params)

class MockarooClient(ApiClient):
    def __init__(self, health_manager: Any, quota_manager: Any):
        super().__init__("MOCKAROO", config, health_manager, quota_manager)

    async def generate_data(self, count: int = 1, fields_json: Optional[str] = None) -> Union[Dict, str]:
        endpoint_config = await self._get_available_endpoint()
        if not endpoint_config:
            return f"❌ Erreur Mockaroo: Aucun endpoint sain ou disponible."

        await self._increment_quota()
        params = {"count": count}
        if fields_json:
            params["fields"] = fields_json
        return await self._make_request(endpoint_config, params=params)

class OpenPageRankClient(ApiClient):
    def __init__(self, health_manager: Any, quota_manager: Any):
        super().__init__("OPENPAGERANK", config, health_manager, quota_manager)

    async def get_page_rank(self, domains: List[str]) -> Union[Dict, str]:
        endpoint_config = await self._get_available_endpoint()
        if not endpoint_config:
            return f"❌ Erreur OpenPageRank: Aucun endpoint sain ou disponible."

        await self._increment_quota()
        params = {"domains[]": domains}
        return await self._make_request(endpoint_config, params=params)

class RapidAPIClient(ApiClient):
    def __init__(self, health_manager: Any, quota_manager: Any):
        super().__init__("RAPIDAPI", config, health_manager, quota_manager)

    async def call_rapidapi_endpoint(self, api_name: str, api_kwargs: Optional[Dict] = None) -> Union[Dict, str]:
        endpoint_config = None
        if api_name == "Programming Joke":
            endpoint_config = next((ep for ep in self.endpoints if "Programming Joke" in ep.get("endpoint_name", "")), None)
        elif api_name == "Currency List Quotes":
            endpoint_config = next((ep for ep in self.endpoints if "Currency List Quotes" in ep.get("endpoint_name", "")), None)
        elif api_name == "Random Fact":
            endpoint_config = next((ep for ep in self.endpoints if "Random Fact" in ep.get("endpoint_name", "")), None)

        if not endpoint_config:
            return f"❌ Erreur RapidAPI: Endpoint '{api_name}' non trouvé ou non configuré."

        is_healthy = await self.health_manager.is_healthy(endpoint_config["endpoint_name"], self.service_name)
        has_quota = await self.quota_manager.check_quota(self.service_name)

        if not is_healthy or not has_quota:
            return f"❌ Erreur RapidAPI: Endpoint '{api_name}' non sain ou quota dépassé."

        await self._increment_quota()
        params = api_kwargs if api_kwargs else {}
        return await self._make_request(endpoint_config, params=params)
        
        import google.generativeai as genai
from google.generativeai import types
import asyncio
from typing import Dict, Any, List, Optional, Union

from config import config
from app_singletons import endpoint_health_manager, quota_manager
from api_clients import (
    ApiClient, WebContainerClient, OCRApiClient, DeepSeekClient, SerperClient,
    WolframAlphaClient, TavilyClient, ApiFlashClient, CrawlbaseClient,
    DetectLanguageClient, GuardianClient, IP2LocationClient, ShodanClient,
    WeatherAPIClient, CloudmersiveClient, GreyNoiseClient, PulsediveClient,
    StormGlassClient, LoginRadiusClient, JsonbinClient, HuggingFaceClient,
    TwilioClient, AbstractAPIClient, GoogleCustomSearchClient,
    RandommerClient, TomorrowIOClient, OpenWeatherMapClient, MockarooClient,
    OpenPageRankClient, RapidAPIClient,
    GeminiApiClient, TelegramBotClient
)
from utils import log_message

# Instanciation de tous les clients API pour les 7 cerveaux autonomes
# Chaque client est instancié avec les gestionnaires de santé et de quotas

# Clients principaux pour les 7 cerveaux
gemini_client = GeminiApiClient(endpoint_health_manager, quota_manager)
telegram_bot_client = TelegramBotClient(endpoint_health_manager, quota_manager)

# Clients pour services auxiliaires
webcontainer_client = WebContainerClient(endpoint_health_manager, quota_manager)
ocr_client = OCRApiClient(endpoint_health_manager, quota_manager)
deepseek_client = DeepSeekClient(endpoint_health_manager, quota_manager)
serper_client = SerperClient(endpoint_health_manager, quota_manager)
wolfram_alpha_client = WolframAlphaClient(endpoint_health_manager, quota_manager)
tavily_client = TavilyClient(endpoint_health_manager, quota_manager)
apiflash_client = ApiFlashClient(endpoint_health_manager, quota_manager)
crawlbase_client = CrawlbaseClient(endpoint_health_manager, quota_manager)
detect_language_client = DetectLanguageClient(endpoint_health_manager, quota_manager)
guardian_client = GuardianClient(endpoint_health_manager, quota_manager)
ip2location_client = IP2LocationClient(endpoint_health_manager, quota_manager)
shodan_client = ShodanClient(endpoint_health_manager, quota_manager)
weather_api_client = WeatherAPIClient(endpoint_health_manager, quota_manager)
cloudmersive_client = CloudmersiveClient(endpoint_health_manager, quota_manager)
greynoise_client = GreyNoiseClient(endpoint_health_manager, quota_manager)
pulsedive_client = PulsediveClient(endpoint_health_manager, quota_manager)
stormglass_client = StormGlassClient(endpoint_health_manager, quota_manager)
loginradius_client = LoginRadiusClient(endpoint_health_manager, quota_manager)
jsonbin_client = JsonbinClient(endpoint_health_manager, quota_manager)
huggingface_client = HuggingFaceClient(endpoint_health_manager, quota_manager)
twilio_client = TwilioClient(endpoint_health_manager, quota_manager)
abstractapi_client = AbstractAPIClient(endpoint_health_manager, quota_manager)
google_custom_search_client = GoogleCustomSearchClient(endpoint_health_manager, quota_manager)
randommer_client = RandommerClient(endpoint_health_manager, quota_manager)
tomorrow_io_client = TomorrowIOClient(endpoint_health_manager, quota_manager)
openweathermap_client = OpenWeatherMapClient(endpoint_health_manager, quota_manager)
mockaroo_client = MockarooClient(endpoint_health_manager, quota_manager)
openpagerank_client = OpenPageRankClient(endpoint_health_manager, quota_manager)
rapidapi_client = RapidAPIClient(endpoint_health_manager, quota_manager)

# Log de l'initialisation
log_message("Tous les clients API ont été instanciés pour les 7 cerveaux autonomes")

# Dictionnaire pour accès facile aux clients
API_CLIENTS = {
    "GEMINI": gemini_client,
    "TELEGRAM": telegram_bot_client,
    "WEBCONTAINER": webcontainer_client,
    "OCR": ocr_client,
    "DEEPSEEK": deepseek_client,
    "SERPER": serper_client,
    "WOLFRAM": wolfram_alpha_client,
    "TAVILY": tavily_client,
    "APIFLASH": apiflash_client,
    "CRAWLBASE": crawlbase_client,
    "DETECT_LANGUAGE": detect_language_client,
    "GUARDIAN": guardian_client,
    "IP2LOCATION": ip2location_client,
    "SHODAN": shodan_client,
    "WEATHER_API": weather_api_client,
    "CLOUDMERSIVE": cloudmersive_client,
    "GREYNOISE": greynoise_client,
    "PULSEDIVE": pulsedive_client,
    "STORMGLASS": stormglass_client,
    "LOGINRADIUS": loginradius_client,
    "JSONBIN": jsonbin_client,
    "HUGGINGFACE": huggingface_client,
    "TWILIO": twilio_client,
    "ABSTRACTAPI": abstractapi_client,
    "GOOGLE_SEARCH": google_custom_search_client,
    "RANDOMMER": randommer_client,
    "TOMORROW_IO": tomorrow_io_client,
    "OPENWEATHERMAP": openweathermap_client,
    "MOCKAROO": mockaroo_client,
    "OPENPAGERANK": openpagerank_client,
    "RAPIDAPI": rapidapi_client
}

def get_client(service_name: str) -> Optional[ApiClient]:
    """Récupère un client API par nom de service."""
    return API_CLIENTS.get(service_name.upper())

def get_all_clients() -> Dict[str, ApiClient]:
    """Retourne tous les clients API disponibles."""
    return API_CLIENTS.copy()

def get_healthy_clients() -> Dict[str, ApiClient]:
    """Retourne uniquement les clients avec des services sains."""
    healthy_clients = {}
    
    for service_name, client in API_CLIENTS.items():
        try:
            # Vérification asynchrone de la santé - à utiliser avec await
            # Pour l'instant, on retourne tous les clients
            healthy_clients[service_name] = client
        except Exception as e:
            log_message(f"Erreur vérification santé {service_name}: {e}", level="warning")
    
    return healthy_clients

async def test_all_clients() -> Dict[str, bool]:
    """Teste la connectivité de tous les clients."""
    results = {}
    
    for service_name, client in API_CLIENTS.items():
        try:
            # Test basique de connectivité
            if hasattr(client, '_get_available_endpoint'):
                endpoint = await client._get_available_endpoint()
                results[service_name] = endpoint is not None
            else:
                results[service_name] = True  # Assume healthy if no endpoint check
        except Exception as e:
            log_message(f"Erreur test client {service_name}: {e}", level="error")
            results[service_name] = False
    
    return results

# Fonctions utilitaires pour la gestion des clients

async def rotate_client_endpoints():
    """Force la rotation des endpoints pour tous les clients."""
    for service_name, client in API_CLIENTS.items():
        if hasattr(client, 'current_endpoint_index') and hasattr(client, 'endpoints'):
            if client.endpoints:
                client.current_endpoint_index = (client.current_endpoint_index + 1) % len(client.endpoints)
                log_message(f"Rotation forcée pour {service_name}, nouvel index: {client.current_endpoint_index}")

def get_client_statistics() -> Dict[str, Any]:
    """Retourne les statistiques des clients API."""
    stats = {
        "total_clients": len(API_CLIENTS),
        "services_configured": len(config.API_CONFIG),
        "clients_by_type": {},
        "endpoint_counts": {}
    }
    
    for service_name, client in API_CLIENTS.items():
        client_type = type(client).__name__
        if client_type not in stats["clients_by_type"]:
            stats["clients_by_type"][client_type] = 0
        stats["clients_by_type"][client_type] += 1
        
        if hasattr(client, 'endpoints'):
            stats["endpoint_counts"][service_name] = len(client.endpoints)
    
    return stats

# Validation de l'initialisation
def validate_clients_initialization() -> bool:
    """Valide que tous les clients essentiels sont initialisés."""
    essential_clients = ["GEMINI", "TELEGRAM", "DEEPSEEK", "SERPER", "WOLFRAM", "TAVILY"]
    
    for client_name in essential_clients:
        if client_name not in API_CLIENTS or API_CLIENTS[client_name] is None:
            log_message(f"Client essentiel {client_name} non initialisé", level="error")
            return False
    
    log_message("Tous les clients essentiels sont initialisés")
    return True

# Exécution de la validation
if validate_clients_initialization():
    log_message("✅ Initialisation des clients API réussie - Système prêt pour les 7 cerveaux autonomes")
else:
    log_message("❌ Erreur lors de l'initialisation des clients API", level="error")
    
    import time
import httpx
import json
import asyncio
import logging
from datetime import datetime, timezone, timedelta
from pathlib import Path
from typing import Dict, Any, Optional, Union, List, Tuple

from config import config
from utils import load_json, save_json, get_current_time, format_datetime, log_message

class EndpointHealthManager:
    """
    Gère la santé des endpoints API pour les 7 cerveaux autonomes.
    Chaque cerveau peut avoir plusieurs endpoints et clés de secours.
    Cette classe est implémentée comme un singleton pour s'assurer qu'il n'y a qu'une seule instance
    gérant l'état de santé de tous les endpoints.
    """
    _instance = None
    _initialized = False # Drapeau pour s'assurer que __init__ n'est appelé qu'une fois

    def __new__(cls, *args, **kwargs):
        """Implémentation du patron de conception Singleton."""
        if cls._instance is None:
            cls._instance = super(cls, cls).__new__(cls)
        return cls._instance

    def __init__(self):
        """
        Initialise le gestionnaire de santé.
        Ne s'exécute qu'une seule fois grâce au drapeau _initialized.
        """
        if self._initialized:
            return
        self.health_status: Dict[str, Dict[str, Any]] = {} # Stocke l'état de santé de chaque endpoint
        self._initialized = True
        log_message("Gestionnaire de santé des endpoints initialisé.")

    async def init_manager(self):
        """
        Initialise le gestionnaire de santé de manière asynchrone en chargeant l'état depuis un fichier.
        Appelé au démarrage de l'application.
        """
        # Charge l'état de santé persistant ou initialise un dictionnaire vide si le fichier n'existe pas
        self.health_status = await load_json(config.ENDPOINT_HEALTH_FILE, {})
        self._initialize_health_status() # S'assure que tous les endpoints configurés ont un état initial
        log_message("Gestionnaire de santé des endpoints chargé et prêt.")

    def _initialize_health_status(self):
        """
        Initialise ou met à jour le statut de santé pour tous les endpoints configurés dans config.API_CONFIG.
        Ceci garantit que même les nouveaux endpoints ajoutés à la configuration sont suivis.
        """
        updated = False
        for service_name, endpoints_config in config.API_CONFIG.items():
            if service_name not in self.health_status:
                self.health_status[service_name] = {} # Crée une entrée pour le nouveau service
                updated = True
            
            for endpoint_config in endpoints_config:
                endpoint_key_base = endpoint_config['endpoint_name']
                api_key_part = ""
                
                # Gère les clés API qui peuvent être des tuples (ex: pour l'authentification basique)
                if isinstance(endpoint_config['key'], tuple):
                    api_key_part = str(endpoint_config['key'][0])
                else:
                    api_key_part = str(endpoint_config['key'])
                
                endpoint_key = f"{endpoint_key_base}-{api_key_part[:8]}" # Clé unique pour chaque endpoint + clé API
                
                if endpoint_key not in self.health_status[service_name]:
                    # Initialise l'état de santé par défaut pour un nouvel endpoint
                    self.health_status[service_name][endpoint_key] = {
                        "latency": 0.0,        # Latence moyenne
                        "success_rate": 1.0,   # Taux de succès (commence à 100%)
                        "last_checked": None,  # Horodatage du dernier contrôle
                        "error_count": 0,      # Compteur d'erreurs
                        "total_checks": 0,     # Nombre total de contrôles effectués
                        "is_healthy": True,    # Indique si l'endpoint est considéré comme sain
                        "last_error": None,
                        "consecutive_failures": 0
                    }
                    updated = True
        
        if updated:
            # Sauvegarde l'état mis à jour de manière asynchrone
            asyncio.create_task(save_json(config.ENDPOINT_HEALTH_FILE, self.health_status))
            log_message("Statut de santé des endpoints initialisé/mis à jour.")

    async def run_health_check_for_service(self, service_name: str):
        """
        Exécute des checks de santé pour tous les endpoints d'un service donné.
        Args:
            service_name (str): Le nom du service (ex: "GEMINI_API", "SERPER").
        """
        endpoints_config = config.API_CONFIG.get(service_name)
        if not endpoints_config:
            log_message(f"Aucune configuration d'endpoint trouvée pour le service: {service_name}", level="warning")
            return

        log_message(f"Lancement du health check pour le service: {service_name}")
        
        for endpoint_config in endpoints_config:
            endpoint_key_base = endpoint_config['endpoint_name']
            api_key_part = ""
            
            if isinstance(endpoint_config['key'], tuple):
                api_key_part = str(endpoint_config['key'][0])
            else:
                api_key_part = str(endpoint_config['key'])
            
            endpoint_key = f"{endpoint_key_base}-{api_key_part[:8]}"
            
            start_time = time.monotonic() # Début du chronomètre pour la latence
            success = False
            
            try:
                request_method = endpoint_config.get("method", "GET")
                url = endpoint_config["url"]
                
                # Prépare les paramètres, les données JSON et les en-têtes pour le health check
                params = endpoint_config.get("health_check_params", {}).copy()
                json_data = endpoint_config.get("health_check_json", {}).copy()
                headers = endpoint_config.get("fixed_headers", {}).copy()
                auth = None # Pour l'authentification basique
                
                check_timeout = endpoint_config.get("timeout", 10)
                
                # Ajoute un suffixe à l'URL si spécifié (utile pour certains endpoints d'API)
                if "health_check_url_suffix" in endpoint_config:
                    url += endpoint_config["health_check_url_suffix"]
                
                # Gère l'insertion de la clé API selon sa localisation (param, header, auth_basic)
                key_field = endpoint_config.get("key_field")
                key_location = endpoint_config.get("key_location")
                key_prefix = endpoint_config.get("key_prefix", "")
                api_key = endpoint_config["key"]
                
                if key_field and key_location:
                    if key_location == "param":
                        params[key_field] = api_key
                    elif key_location == "header":
                        headers[key_field] = f"{key_prefix}{api_key}"
                    elif key_location == "auth_basic":
                        if isinstance(api_key, tuple) and len(api_key) == 2:
                            auth = httpx.BasicAuth(api_key[0], api_key[1])
                        else:
                            log_message(f"Clé API pour auth_basic non valide pour {service_name}:{endpoint_key}", level="error")
                            continue # Passe à l'endpoint suivant
                
                # Ajouter des paramètres fixes
                if "fixed_params" in endpoint_config:
                    params.update(endpoint_config["fixed_params"])
                
                async with httpx.AsyncClient(timeout=check_timeout) as client:
                    response = await client.request(
                        request_method, url, 
                        params=params, 
                        headers=headers, 
                        json=json_data, 
                        auth=auth
                    )
                    response.raise_for_status() # Lève une exception pour les codes d'état HTTP 4xx/5xx
                    success = True
                    
            except httpx.HTTPStatusError as e:
                # Gère les erreurs HTTP (ex: 404, 500)
                log_level = "warning"
                if 400 <= e.response.status_code < 500 and e.response.status_code != 429:
                    # Les erreurs client (sauf 429) peuvent indiquer un problème avec la requête elle-même,
                    # pas forcément que l'endpoint est malsain. Log plus bas.
                    log_level = "debug"
                log_message(f"Health check pour {endpoint_key} ({service_name}) a échoué (HTTP {e.response.status_code}): {e.response.text}", level=log_level)
                success = False
                
            except httpx.RequestError as e:
                # Gère les erreurs réseau (ex: timeout, connexion refusée)
                log_message(f"Health check pour {endpoint_key} ({service_name}) a échoué (Réseau): {e}", level="warning")
                success = False
                
            except Exception as e:
                # Gère toutes les autres exceptions inattendues
                log_message(f"Health check pour {endpoint_key} ({service_name}) a échoué (Inattendu): {e}", level="error")
                success = False
                
            finally:
                latency = time.monotonic() - start_time # Calcule la latence
                # Met à jour l'état de santé de l'endpoint
                self.update_endpoint_health(service_name, endpoint_key, success, latency)

        log_message(f"Health check terminé pour le service: {service_name}")

    def update_endpoint_health(self, service_name: str, endpoint_key: str, success: bool, latency: float):
        """
        Met à jour le statut de santé d'un endpoint spécifique.
        Utilise une moyenne mobile exponentielle pour la latence et le taux de succès.
        Args:
            service_name (str): Le nom du service.
            endpoint_key (str): La clé unique de l'endpoint.
            success (bool): Indique si le dernier contrôle a été un succès.
            latency (float): La latence du dernier contrôle.
        """
        # S'assure que l'entrée de l'endpoint existe, l'initialise si nécessaire
        if service_name not in self.health_status:
            self.health_status[service_name] = {}
        
        if endpoint_key not in self.health_status[service_name]:
            self.health_status[service_name][endpoint_key] = {
                "latency": 0.0,
                "success_rate": 1.0,
                "last_checked": None,
                "error_count": 0,
                "total_checks": 0,
                "is_healthy": True,
                "last_error": None,
                "consecutive_failures": 0
            }
        
        status = self.health_status[service_name][endpoint_key]
        status["total_checks"] += 1
        status["last_checked"] = format_datetime(get_current_time())
        
        alpha = 0.1  # Facteur de lissage pour la moyenne mobile exponentielle
        
        if success:
            status["consecutive_failures"] = 0
            status["error_count"] = max(0, status["error_count"] - 1) # Réduit le compteur d'erreurs
            status["success_rate"] = status["success_rate"] * (1 - alpha) + 1.0 * alpha # Augmente le taux de succès
            status["latency"] = status["latency"] * (1 - alpha) + latency * alpha # Met à jour la latence moyenne
            status["last_error"] = None
        else:
            status["consecutive_failures"] += 1
            status["error_count"] += 1 # Incrémente le compteur d'erreurs
            status["success_rate"] = status["success_rate"] * (1 - alpha) + 0.0 * alpha # Diminue le taux de succès
            status["latency"] = status["latency"] * (1 - alpha) + 10.0 * alpha # Pénalise la latence en cas d'échec
            status["last_error"] = format_datetime(get_current_time())
        
        # Détermine si l'endpoint est sain basé sur le nombre d'erreurs consécutives ou le taux de succès
        if status["consecutive_failures"] >= 3 or status["success_rate"] < 0.5:
            status["is_healthy"] = False
        else:
            status["is_healthy"] = True
        
        # Sauvegarde l'état de santé mis à jour de manière asynchrone
        asyncio.create_task(save_json(config.ENDPOINT_HEALTH_FILE, self.health_status))
        
        log_level = "debug" if status["is_healthy"] else "warning"
        log_message(f"Santé de {service_name}:{endpoint_key} mise à jour: Succès: {success}, Latence: {latency:.2f}s, Taux Succès: {status['success_rate']:.2f}, Sain: {status['is_healthy']}", level=log_level)

    async def is_healthy(self, endpoint_name: str, service_name: str) -> bool:
        """Vérifie si un endpoint spécifique est sain."""
        service_health = self.health_status.get(service_name, {})
        
        # Recherche par nom d'endpoint
        for endpoint_key, status in service_health.items():
            if endpoint_name in endpoint_key:
                return status.get("is_healthy", False)
        
        return False

    async def is_service_healthy(self, service_name: str) -> bool:
        """Vérifie si au moins un endpoint du service est sain."""
        service_health = self.health_status.get(service_name, {})
        
        if not service_health:
            return True  # Nouveau service considéré comme sain par défaut
        
        healthy_endpoints = [
            status for status in service_health.values()
            if status.get("is_healthy", False)
        ]
        
        return len(healthy_endpoints) > 0

    def get_best_endpoint(self, service_name: str) -> Optional[Dict]:
        """
        Sélectionne le meilleur endpoint pour un service donné basé sur son statut de santé.
        Priorise les endpoints sains avec la latence la plus faible et le taux de succès le plus élevé.
        En cas d'absence d'endpoints sains, tente de sélectionner le "moins pire" parmi les non-sains.
        Args:
            service_name (str): Le nom du service.
        Returns:
            Optional[Dict]: La configuration du meilleur endpoint, ou None si aucun n'est disponible.
        """
        service_health = self.health_status.get(service_name)
        if not service_health:
            log_message(f"Aucune donnée de santé pour le service {service_name}. Retourne None.", level="warning")
            return None

        # Filtre les endpoints qui sont actuellement considérés comme sains
        healthy_endpoints = [
            (key, status) for key, status in service_health.items()
            if status["is_healthy"]
        ]

        if not healthy_endpoints:
            log_message(f"Aucun endpoint sain pour le service {service_name}. Tentative de sélection d'un endpoint non sain.", level="warning")
            all_endpoints = list(service_health.items())
            if not all_endpoints:
                return None # Aucun endpoint du tout
            
            # Si aucun endpoint sain, trie tous les endpoints par nombre d'erreurs puis par latence
            sorted_endpoints = sorted(
                all_endpoints,
                key=lambda item: (item[1]["consecutive_failures"], item[1]["latency"])
            )
            best_endpoint_key = sorted_endpoints[0][0] # Prend le "moins pire"
            log_message(f"Fallback: Endpoint {best_endpoint_key} sélectionné pour {service_name} (non sain).", level="warning")
        else:
            # Si des endpoints sains existent, calcule un score pour chacun et sélectionne le meilleur
            best_endpoint_key, _ = max(
                healthy_endpoints,
                key=lambda item: (item[1]["success_rate"] * 100) - (item[1]["latency"] * 10) - (item[1]["consecutive_failures"] * 5)
            )
            log_message(f"Meilleur endpoint pour {service_name}: {best_endpoint_key}")

        # Trouve la configuration complète de l'endpoint sélectionné à partir de config.API_CONFIG
        for endpoint_config in config.API_CONFIG.get(service_name, []):
            current_endpoint_key_base = endpoint_config['endpoint_name']
            api_key_part = ""
            
            if isinstance(endpoint_config['key'], tuple):
                api_key_part = str(endpoint_config['key'][0])
            else:
                api_key_part = str(endpoint_config['key'])
            
            current_endpoint_key = f"{current_endpoint_key_base}-{api_key_part[:8]}"
            
            if current_endpoint_key == best_endpoint_key:
                return endpoint_config

        return None

    def mark_unhealthy(self, endpoint_name: str, service_name: str, reason: str):
        """Marque un endpoint comme non sain."""
        service_health = self.health_status.get(service_name, {})
        
        for endpoint_key, status in service_health.items():
            if endpoint_name in endpoint_key:
                status["is_healthy"] = False
                status["consecutive_failures"] += 1
                status["last_error"] = format_datetime(get_current_time())
                log_message(f"Endpoint {endpoint_key} marqué comme non sain: {reason}", level="warning")
                break

class QuotaManager:
    """
    Gère l'utilisation des quotas pour différentes APIs.
    Cette classe est également un singleton.
    """
    _instance = None
    _initialized = False

    def __new__(cls, *args, **kwargs):
        """Implémentation du patron de conception Singleton."""
        if cls._instance is None:
            cls._instance = super(QuotaManager, cls).__new__(cls)
        return cls._instance

    def __init__(self):
        """
        Initialise le gestionnaire de quotas.
        Ne s'exécute qu'une seule fois grâce au drapeau _initialized.
        """
        if self._initialized:
            return
        self.quota_state: Dict[str, Dict[str, Any]] = {} # Stocke l'état actuel des quotas par API
        self._initialized = True
        log_message("QuotaManager initialisé.")

    async def init_manager(self):
        """
        Charge l'état des quotas depuis le fichier de persistance de manière asynchrone.
        Appelé au démarrage de l'application.
        """
        self.quota_state = await load_json(config.QUOTA_STATE_FILE, {})
        self._initialize_quota_state() # S'assure que tous les quotas configurés ont un état initial
        log_message("QuotaManager chargé et prêt.")

    def _initialize_quota_state(self):
        """
        Initialise ou met à jour l'état des quotas pour toutes les APIs configurées dans config.QUOTA_CONFIG.
        Réinitialise les quotas si l'intervalle de réinitialisation est dépassé.
        """
        updated = False
        current_time = datetime.now(timezone.utc)
        
        for api_name, quota_info in config.QUOTA_CONFIG.items():
            if api_name not in self.quota_state:
                # Initialise l'état par défaut pour une nouvelle API
                self.quota_state[api_name] = {
                    "current_usage": 0,
                    "last_reset_time": current_time.isoformat(), # Enregistre l'heure de la dernière réinitialisation
                    "last_usage_time": None, # Horodatage de la dernière utilisation
                    "daily_peak": 0,
                    "success_count": 0,
                    "error_count": 0
                }
                updated = True
            
            # Vérifie et réinitialise le quota si nécessaire lors de l'initialisation
            self._check_and_reset_quota(api_name, current_time)
        
        if updated:
            # Sauvegarde l'état mis à jour de manière asynchrone
            asyncio.create_task(save_json(config.QUOTA_STATE_FILE, self.quota_state))
            log_message("État des quotas initialisé/mis à jour.")

    def _check_and_reset_quota(self, api_name: str, current_time: datetime) -> bool:
        """
        Vérifie si un quota doit être réinitialisé en fonction de son intervalle et le fait si nécessaire.
        Args:
            api_name (str): Le nom de l'API.
            current_time (datetime): L'heure actuelle en UTC.
        Returns:
            bool: True si le quota a été réinitialisé, False sinon.
        """
        quota_info = config.QUOTA_CONFIG.get(api_name)
        if not quota_info:
            return False

        state = self.quota_state.get(api_name)
        if not state:
            state = {
                "current_usage": 0,
                "last_reset_time": current_time.isoformat(),
                "last_usage_time": None,
                "daily_peak": 0,
                "success_count": 0,
                "error_count": 0
            }
            self.quota_state[api_name] = state

        last_reset_dt = datetime.fromisoformat(state["last_reset_time"])
        reset_needed = False

        # Logique de réinitialisation basée sur l'intervalle configuré
        if quota_info["reset_interval"] == "daily":
            if current_time.date() > last_reset_dt.date():
                reset_needed = True
        elif quota_info["reset_interval"] == "hourly":
            if current_time.hour > last_reset_dt.hour or current_time.date() > last_reset_dt.date():
                reset_needed = True
        elif quota_info["reset_interval"] == "fixed_24h":
            if current_time - last_reset_dt >= timedelta(hours=24):
                reset_needed = True

        if reset_needed:
            # Sauvegarde du pic quotidien
            state["daily_peak"] = max(state.get("daily_peak", 0), state["current_usage"])
            
            # Reset des compteurs
            state["current_usage"] = 0
            state["last_reset_time"] = current_time.isoformat()
            
            log_message(f"Quota pour {api_name} réinitialisé. Pic précédent: {state['daily_peak']}")
            return True

        return False

    async def check_quota(self, api_name: str) -> bool:
        """Vérifie si une requête est autorisée selon le quota."""
        quota_info = config.QUOTA_CONFIG.get(api_name)
        if not quota_info:
            return True  # Pas de quota configuré = autorisé

        state = self.quota_state.get(api_name)
        if not state:
            self._initialize_quota_state()
            state = self.quota_state.get(api_name)
            if not state:
                return False

        current_time = datetime.now(timezone.utc)
        self._check_and_reset_quota(api_name, current_time)

        remaining_quota = quota_info["limit"] - state["current_usage"]

        # Logique de fenêtre de cramage
        is_in_burn_window = False
        if quota_info.get("burn_window_hours", 0) > 0:
            last_reset_dt = datetime.fromisoformat(state["last_reset_time"])
            time_to_next_reset = timedelta(hours=0)

            if quota_info["reset_interval"] == "daily":
                next_reset = (last_reset_dt + timedelta(days=1)).replace(hour=0, minute=0, second=0, microsecond=0)
                time_to_next_reset = next_reset - current_time
            elif quota_info["reset_interval"] == "hourly":
                next_reset = (last_reset_dt + timedelta(hours=1)).replace(minute=0, second=0, microsecond=0)
                time_to_next_reset = next_reset - current_time
            elif quota_info["reset_interval"] == "fixed_24h":
                next_reset = last_reset_dt + timedelta(hours=24)
                time_to_next_reset = next_reset - current_time

            if timedelta(hours=0) < time_to_next_reset <= timedelta(hours=quota_info["burn_window_hours"]):
                is_in_burn_window = True

        # Autorisation de la requête
        if state["current_usage"] < quota_info["limit"]:
            return True
        elif is_in_burn_window:
            log_message(f"Quota {api_name} en mode cramage autorisé", level="warning")
            return True
        else:
            log_message(f"Quota {api_name} dépassé: {state['current_usage']}/{quota_info['limit']}", level="warning")
            return False

    async def increment_quota(self, api_name: str, success: bool = True):
        """Incrémente le quota après utilisation."""
        quota_info = config.QUOTA_CONFIG.get(api_name)
        if not quota_info:
            return

        state = self.quota_state.get(api_name)
        if not state:
            self._initialize_quota_state()
            state = self.quota_state.get(api_name)

        if state:
            current_time = datetime.now(timezone.utc)
            state["current_usage"] += 1
            state["last_usage_time"] = current_time.isoformat()
            
            if success:
                state["success_count"] = state.get("success_count", 0) + 1
            else:
                state["error_count"] = state.get("error_count", 0) + 1

            asyncio.create_task(save_json(config.QUOTA_STATE_FILE, self.quota_state))
            
            remaining = quota_info["limit"] - state["current_usage"]
            log_message(f"Quota {api_name}: {state['current_usage']}/{quota_info['limit']} (Restant: {remaining})")

    def get_quota_status(self, api_name: str) -> Dict[str, Any]:
        """Retourne le statut du quota pour une API."""
        quota_info = config.QUOTA_CONFIG.get(api_name, {})
        state = self.quota_state.get(api_name, {})
        
        if not state:
            return {"error": f"Pas de données pour {api_name}"}
        
        return {
            "api_name": api_name,
            "current_usage": state.get("current_usage", 0),
            "limit": quota_info.get("limit", 0),
            "remaining": quota_info.get("limit", 0) - state.get("current_usage", 0),
            "success_rate": (
                state.get("success_count", 0) / 
                max(1, state.get("success_count", 0) + state.get("error_count", 0))
            ) * 100,
            "last_usage": state.get("last_usage_time"),
            "last_reset": state.get("last_reset_time"),
            "daily_peak": state.get("daily_peak", 0)
        }

    def get_all_quotas_status(self) -> Dict[str, Dict[str, Any]]:
        """Retourne le statut de tous les quotas."""
        return {
            api_name: self.get_quota_status(api_name)
            for api_name in config.QUOTA_CONFIG.keys()
        }

# Instancier les gestionnaires de singletons pour qu'ils soient accessibles depuis d'autres modules
endpoint_health_manager = EndpointHealthManager()
quota_manager = QuotaManager()

import asyncio
import json
import random
import time
import traceback
from datetime import datetime, timezone
from typing import Dict, Any, List, Optional, Union
import httpx

from config import config
from brain_library import api_key_library, BrainMemoryManager, TelegramMemoryIntegration
from utils import log_message, neutralize_urls
from tools import get_gemini_tools

class AutonomousBrain:
    """
    Classe de base pour un cerveau autonome.
    Chaque cerveau peut traiter indépendamment les requêtes utilisateur.
    """
    def __init__(self, brain_id: str, service_name: str, telegram_client=None):
        self.brain_id = brain_id
        self.service_name = service_name
        self.memory_manager = BrainMemoryManager(brain_id)
        self.telegram_memory = TelegramMemoryIntegration(telegram_client)
        self.is_active = True
        self.current_task = None
        self.last_activity = time.time()
        
    async def initialize(self):
        """Initialise le cerveau et charge sa mémoire."""
        try:
            await self.memory_manager.load_memory()
            await self.telegram_memory.log_brain_activity(
                self.brain_id, 
                "Cerveau initialisé", 
                {"service": self.service_name, "timestamp": datetime.now().isoformat()}
            )
            log_message(f"Cerveau {self.brain_id} initialisé avec succès")
            return True
        except Exception as e:
            log_message(f"Erreur initialisation cerveau {self.brain_id}: {e}", level="error")
            return False
    
    async def read_complete_memory(self) -> str:
        """Lit l'intégralité de la mémoire avant toute action."""
        try:
            # Lecture de la mémoire du groupe privé Telegram
            group_memory = await self.telegram_memory.read_group_memory(limit=100)
            
            # Lecture du contexte local pertinent
            local_context = await self.memory_manager.get_relevant_context("", limit=20)
            
            complete_memory = f"""
=== MÉMOIRE COMPLÈTE DU CERVEAU {self.brain_id} ===

{group_memory}

=== CONTEXTE LOCAL ===
{json.dumps(local_context, indent=2, ensure_ascii=False)}

=== STATUT CERVEAU ===
Service: {self.service_name}
Dernière activité: {datetime.fromtimestamp(self.last_activity).isoformat()}
Actif: {self.is_active}
Tâche courante: {self.current_task or "Aucune"}
"""
            return complete_memory
        except Exception as e:
            log_message(f"Erreur lecture mémoire complète {self.brain_id}: {e}", level="error")
            return f"Erreur d'accès à la mémoire: {e}"
    
    async def process_request(self, user_query: str, chat_history: List[Dict] = None, 
                            image_data: str = None, tools: List[Dict] = None) -> Dict[str, Any]:
        """
        Traite une requête utilisateur de manière autonome.
        Chaque cerveau lit sa mémoire complète avant de répondre.
        """
        self.current_task = f"Traitement requête: {user_query[:50]}..."
        self.last_activity = time.time()
        
        try:
            # 1. Lecture obligatoire de l'intégralité de la mémoire
            complete_memory = await self.read_complete_memory()
            
            await self.telegram_memory.log_brain_activity(
                self.brain_id,
                "Début traitement requête",
                {"query": user_query[:100], "memory_loaded": True}
            )
            
            # 2. Sélection de la clé API et de l'endpoint
            key_info = api_key_library.get_available_key(self.service_name)
            if not key_info:
                error_msg = f"Aucune clé API disponible pour {self.service_name}"
                await self.telegram_memory.log_error(self.brain_id, error_msg)
                await self.memory_manager.update_success_rate(False)
                return {"error": error_msg, "brain_id": self.brain_id}
            
            # 3. Préparation du prompt enrichi avec la mémoire
            enriched_prompt = f"""
{complete_memory}

=== NOUVELLE REQUÊTE UTILISATEUR ===
{user_query}

Instructions: Utilise l'intégralité de la mémoire ci-dessus pour fournir une réponse contextuelle et pertinente.
Cerveau responsable: {self.brain_id}
Service: {self.service_name}
"""
            
            # 4. Génération de la réponse
            response = await self._generate_response(
                enriched_prompt, key_info, chat_history, image_data, tools
            )
            
            # 5. Traitement des outils si nécessaire
            tool_results = []
            if "function_calls" in response:
                tool_results = await self._execute_tools(response["function_calls"])
                response["tool_results"] = tool_results
            
            # 6. Sauvegarde en mémoire et dans le groupe Telegram
            await self.memory_manager.add_interaction(
                user_query, 
                str(response), 
                [tool["name"] for tool in tool_results]
            )
            
            await self.telegram_memory.log_success(
                self.brain_id,
                "Requête traitée avec succès",
                str(response)[:200]
            )
            
            await self.memory_manager.update_success_rate(True)
            
            self.current_task = None
            return {
                "response": response,
                "brain_id": self.brain_id,
                "service": self.service_name,
                "memory_context": complete_memory[:500] + "...",
                "tool_results": tool_results
            }
            
        except Exception as e:
            error_msg = f"Erreur traitement requête: {e}"
            log_message(f"Cerveau {self.brain_id}: {error_msg}", level="error")
            await self.telegram_memory.log_error(self.brain_id, error_msg)
            await self.memory_manager.update_success_rate(False)
            
            # Marquer la clé comme défaillante
            if 'key_info' in locals():
                api_key_library.mark_key_failed(self.service_name, key_info["key"])
            
            self.current_task = None
            return {"error": error_msg, "brain_id": self.brain_id}
    
    async def _generate_response(self, prompt: str, key_info: Dict, 
                               chat_history: List[Dict] = None,
                               image_data: str = None, 
                               tools: List[Dict] = None) -> Dict[str, Any]:
        """Génère une réponse spécifique au service."""
        # Méthode abstraite - implémentée dans les sous-classes
        raise NotImplementedError("Chaque cerveau doit implémenter sa méthode de génération")
    
    async def _execute_tools(self, function_calls: List[Dict]) -> List[Dict]:
        """Exécute les outils demandés par l'IA."""
        results = []
        for func_call in function_calls:
            try:
                # Import dynamique pour éviter les dépendances circulaires
                from tools import execute_tool
                
                tool_result = await execute_tool(
                    func_call["name"],
                    context=None,
                    **func_call.get("args", {})
                )
                results.append(tool_result)
                
                await self.telegram_memory.log_brain_activity(
                    self.brain_id,
                    f"Outil exécuté: {func_call['name']}",
                    {"args": func_call.get("args", {}), "result": str(tool_result)[:100]}
                )
                
            except Exception as e:
                error_result = {"error": f"Erreur outil {func_call['name']}: {e}"}
                results.append(error_result)
                await self.telegram_memory.log_error(
                    self.brain_id,
                    f"Erreur outil {func_call['name']}: {e}"
                )
        
        return results
    
    async def participate_in_coding_challenge(self, challenge_prompt: str) -> Dict[str, Any]:
        """Participe aux défis de codage automatisés."""
        try:
            await self.telegram_memory.log_brain_activity(
                self.brain_id,
                "Participation défi codage",
                {"challenge": challenge_prompt[:100]}
            )
            
            # Lecture de la mémoire avant le défi
            complete_memory = await self.read_complete_memory()
            
            # Prompt spécialisé pour le défi de codage
            coding_prompt = f"""
{complete_memory}

=== DÉFI DE CODAGE AUTOMATISÉ ===
{challenge_prompt}

En tant que cerveau {self.brain_id} spécialisé en {self.service_name}, génère du code Python optimisé et fonctionnel.
Le code doit être:
- Syntaxiquement correct
- Bien commenté
- Optimisé pour les performances
- Prêt à l'exécution

Réponds uniquement avec le code Python, sans explications supplémentaires.
"""
            
            key_info = api_key_library.get_available_key(self.service_name)
            if not key_info:
                return {"error": f"Aucune clé disponible pour {self.service_name}"}
            
            response = await self._generate_response(coding_prompt, key_info)
            
            # Sauvegarde du code généré
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            code_filename = f"challenge_{self.brain_id}_{timestamp}.py"
            
            await self.telegram_memory.write_to_group(
                f"💻 Code généré par {self.brain_id}:\n```python\n{response}\n```",
                "CODING_CHALLENGE"
            )
            
            return {
                "code": response,
                "brain_id": self.brain_id,
                "filename": code_filename,
                "timestamp": timestamp
            }
            
        except Exception as e:
            error_msg = f"Erreur défi codage: {e}"
            await self.telegram_memory.log_error(self.brain_id, error_msg)
            return {"error": error_msg, "brain_id": self.brain_id}

class GeminiBrain(AutonomousBrain):
    """Cerveau autonome basé sur Gemini."""
    
    def __init__(self, telegram_client=None):
        super().__init__("GEMINI", "GEMINI_API", telegram_client)
    
    async def _generate_response(self, prompt: str, key_info: Dict,
                               chat_history: List[Dict] = None,
                               image_data: str = None,
                               tools: List[Dict] = None) -> Dict[str, Any]:
        """Génère une réponse via l'API Gemini."""
        try:
            from app_clients_instances import gemini_client
            
