                    return rep if rep else "Pas de r√©ponse de Tavily."
                else:
                    return f"[Tavily] Erreur {r.status_code}: {r.text}"
            except Exception as e:
                return f"[Tavily] Exception: {e}"

    # Serper
    if model_name == "Serper":
        url = "https://serpapi.com/search"
        params = {"q": prompt, "api_key": api_key or get_any_key(SERPER_KEYS), "engine": "google"}
        async with httpx.AsyncClient(timeout=10) as c:
            try:
                r = await c.get(url, params=params)
                if r.status_code == 200:
                    j = r.json()
                    return j.get("organic_results", [{}])[0].get("snippet", "Pas de r√©sultat Serper.")
                return f"[Serper] Erreur {r.status_code}: {r.text}"
            except Exception as e:
                return f"[Serper] Exception: {e}"

    # HuggingFace
    if model_name == "HuggingFace":
        url = "https://api-inference.huggingface.co/models/gpt2"
        headers = {"Authorization": f"Bearer {api_key or get_any_key(HUGGINGFACE_KEYS)}"}
        payload = {"inputs": prompt, "options": {"wait_for_model": True}}
        async with httpx.AsyncClient(timeout=30) as c:
            try:
                r = await c.post(url, headers=headers, json=payload)
                if r.status_code == 200 and isinstance(r.json(), list) and "generated_text" in r.json()[0]:
                    return r.json()[0]["generated_text"]
                return f"[HF] Erreur {r.status_code}: {r.text}"
            except Exception as e:
                return f"[HF] Exception: {e}"

    # Wolfram
    if model_name == "Wolfram":
        url = "http://api.wolframalpha.com/v2/query"
        params = {"input": prompt, "appid": api_key or get_any_key(WOLFRAM_APP_IDS)}
        async with httpx.AsyncClient(timeout=20) as c:
            try:
                r = await c.get(url, params=params)
                if r.status_code == 200:
                    d = r.json(); pods = d.get("queryresult", {}).get("pods", [])
                    return next((x["subpods"][0].get("plaintext", "") for x in pods if x.get("title", "").lower() in ["result", "definition"]), None) or "Pas de r√©sultat Wolfram."
                return f"[Wolfram] Erreur {r.status_code}: {r.text}"
            except Exception as e:
                return f"[Wolfram] Exception: {e}"

    # Google API
    if model_name and model_name.startswith("GoogleCX"):
        idx = int(model_name.split("-")[1]) - 1
        cx = GOOGLE_CX_LIST[idx]
        url = "https://www.googleapis.com/customsearch/v1"
        params = {"q": prompt, "key": api_key or get_any_key(GOOGLE_API_KEYS), "cx": cx}
        async with httpx.AsyncClient(timeout=10) as c:
            try:
                r = await c.get(url, params=params)
                if r.status_code == 200:
                    j = r.json(); i = j.get("items", [])
                    return i[0].get("snippet", "Pas de r√©sultat Google CustomSearch.") if i else "Pas de r√©sultat Google."
                return f"[GoogleCX] Erreur {r.status_code}: {r.text}"
            except Exception as e:
                return f"[GoogleCX] Exception: {e}"

    return "‚ùå Aucune IA/cl√© valide pour ce CIG"

# -------------------------------------------------------------------------
# ----------------- CODING CHALLENGE TOUTES IA EN PARALL√àLE --------------
# -------------------------------------------------------------------------
CODING_CHALLENGE_ENABLED = True
LAST_CHALLENGE_FILE = DAILY_CHALLENGE_PATH / "last_challenge.py"
HISTORY_DIR = DAILY_CHALLENGE_PATH / "history"
HISTORY_DIR.mkdir(exist_ok=True)

def diff_text(old_text, new_text):
    import difflib
    diff = difflib.unified_diff(
        old_text.splitlines(), new_text.splitlines(), lineterm=""
    )
    return "\n".join(diff)

async def coding_challenge_task():
    while True:
        if not CODING_CHALLENGE_ENABLED:
            await asyncio.sleep(900)
            continue

        prompt = """
Tu es une IA experte en programmation Python. G√©n√®re un script clair, correct et optimis√©, 100% en fran√ßais.
Ne dis pas que tu ne sais pas, ne t'excuse pas, ne formule pas de r√©ponses vagues.
Chaque version doit √™tre une am√©lioration nette de la pr√©c√©dente.
Commence par un commentaire indiquant ce qui a √©t√© am√©lior√©.
Le code doit √™tre direct, lisible, et pr√™t √† √™tre utilis√©.
"""

        # Liste des IA / cl√©s √† utiliser
        ia_list = (
            [("OpenRouter", k) for k in OPENROUTER_KEYS] +
            [("Tavily", k) for k in TAVILY_KEYS] +
            [("Serper", k) for k in SERPER_KEYS] +
            [("HuggingFace", k) for k in HUGGINGFACE_KEYS] +
            [("Wolfram", k) for k in WOLFRAM_APP_IDS] +
            [("GoogleCX-1", k) for k in GOOGLE_API_KEYS] +
            [("GoogleCX-2", k) for k in GOOGLE_API_KEYS]
        )

        async def call_ia(nom, cle):
            try:
                r = await CIG(prompt, api_key=cle, model_name=nom)
                if r and len(r.strip()) > 20:
                    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
                    fpath = DAILY_CHALLENGE_PATH / f"challenge_{nom}_{timestamp}.py"
                    fpath.write_text(r, encoding="utf-8")
                    await bot_instance.send_message(
                        chat_id=PRIVATE_GROUP_ID,
                        text=f"üíª <b>Code g√©n√©r√© par {nom}</b> :\n<pre>{r[:600]}</pre>",
                        parse_mode="HTML"
                    )
                    return r
                else:
                    await bot_instance.send_message(
                        chat_id=PRIVATE_GROUP_ID,
                        text=f"‚ö†Ô∏è <b>{nom}</b> n'a pas g√©n√©r√© de code valable cette fois.",
                        parse_mode="HTML"
                    )
                    return None
            except Exception as e:
                await bot_instance.send_message(
                    chat_id=PRIVATE_GROUP_ID,
                    text=f"‚ùå <b>{nom}</b> erreur lors de l'appel IA : {e}",
                    parse_mode="HTML"
                )
                return None

        # Appels en parall√®le
        results = await asyncio.gather(*[call_ia(n, k) for n, k in ia_list])

        await asyncio.sleep(900)  # Pause 15 min

async def start_background_tasks(app):
    asyncio.create_task(coding_challenge_task())

# -------------------------------------------------------------------------
# ------------- COMMANDE /QUOTA POUR TOUTES LES IA (v√©rif statuts) --------
# -------------------------------------------------------------------------
async def quota_ia():
    from datetime import datetime
    results = []

    # Test OpenRouter
    async def test_openrouter():
        messages = []
        for i, key in enumerate(OPENROUTER_KEYS):
            try:
                async with httpx.AsyncClient(timeout=5) as c:
                    r = await c.get("https://openrouter.ai/api/v1/models", headers={"Authorization": f"Bearer {key}"})
                    if r.status_code == 200:
                        messages.append(f"‚úÖ OpenRouter key #{i+1}: OK")
                    else:
                        messages.append(f"‚ùå OpenRouter key #{i+1}: {r.status_code} {r.text[:100]}")
            except Exception as e:
                messages.append(f"‚ùå OpenRouter key #{i+1} erreur : {e}")
        return "\n".join(messages)

    # Test Tavily keys
    async def test_tavily():
        messages = []
        for i, key in enumerate(TAVILY_KEYS):
            try:
                async with httpx.AsyncClient(timeout=5) as c:
                    r = await c.get("https://api.tavily.com/ping", headers={"Authorization": key})
                    if r.status_code == 200:
                        messages.append(f"‚úÖ Tavily key #{i+1}: OK")
                    else:
                        messages.append(f"‚ùå Tavily key #{i+1}: {r.status_code} {r.text[:100]}")
            except Exception as e:
                messages.append(f"‚ùå Tavily key #{i+1} erreur : {e}")
        return "\n".join(messages)

    # Test Serper
    async def test_serper():
        messages = []
        for i, key in enumerate(SERPER_KEYS):
            try:
                async with httpx.AsyncClient(timeout=5) as c:
                    r = await c.get("https://serpapi.com/search", params={"q": "test", "api_key": key, "engine": "google"})
                    if r.status_code == 200:
                        messages.append(f"‚úÖ Serper key #{i+1}: OK")
                    else:
                        messages.append(f"‚ùå Serper key #{i+1}: {r.status_code} {r.text[:100]}")
            except Exception as e:
                messages.append(f"‚ùå Serper key #{i+1} erreur : {e}")
        return "\n".join(messages)

    # Test HuggingFace
    async def test_hf():
        messages = []
        for i, key in enumerate(HUGGINGFACE_KEYS):
            try:
                async with httpx.AsyncClient(timeout=5) as c:
                    r = await c.get("https://api-inference.huggingface.co/models/gpt2", headers={"Authorization": f"Bearer {key}"})
                    if r.status_code == 200:
                        messages.append(f"‚úÖ HuggingFace key #{i+1}: OK")
                    else:
                        messages.append(f"‚ùå HuggingFace key #{i+1}: {r.status_code} {r.text[:100]}")
            except Exception as e:
                messages.append(f"‚ùå HuggingFace key #{i+1} erreur : {e}")
        return "\n".join(messages)

    # Test Wolfram App IDs
    async def test_wolfram():
        messages = []
        for i, key in enumerate(WOLFRAM_APP_IDS):
            try:
                async with httpx.AsyncClient(timeout=5) as c:
                    r = await c.get("http://api.wolframalpha.com/v2/query", params={"input": "pi", "appid": key})
                    if r.status_code == 200:
                        messages.append(f"‚úÖ Wolfram key #{i+1}: OK")
                    else:
                        messages.append(f"‚ùå Wolfram key #{i+1}: {r.status_code} {r.text[:100]}")
            except Exception as e:
                messages.append(f"‚ùå Wolfram key #{i+1} erreur : {e}")
        return "\n".join(messages)

    # Tests Google API Keys (multiple)
    async def test_google_apis():
        messages = []
        for i, key in enumerate(GOOGLE_API_KEYS):
            for j, cx in enumerate(GOOGLE_CX_LIST):
                try:
                    async with httpx.AsyncClient(timeout=5) as c:
                        r = await c.get("https://www.googleapis.com/customsearch/v1",
                                       params={"q": "test", "key": key, "cx": cx})
                        if r.status_code == 200:
                            messages.append(f"‚úÖ Google Custom Search key #{i+1} CX #{j+1}: OK")
                        else:
                            messages.append(f"‚ùå Google Custom Search key #{i+1} CX #{j+1}: {r.status_code} {r.text[:100]}")
                except Exception as e:
                    messages.append(f"‚ùå Google Custom Search key #{i+1} CX #{j+1} erreur : {e}")
        return "\n".join(messages)

    # Test OCR
    async def test_ocr():
        messages = []
        for i, key in enumerate(OCR_API_KEYS):
            try:
                async with httpx.AsyncClient(timeout=5) as c:
                    # OCR.space ne fournit pas d'endpoint ping, on simule
                    messages.append(f"üîé OCR key #{i+1}: (pas de ping, cl√© charg√©e)")
            except Exception as e:
                messages.append(f"‚ùå OCR key #{i+1} erreur : {e}")
        return "\n".join(messages)

    # Test OpenWeather
    async def test_openweather():
        messages = []
        for i, key in enumerate(OPENWEATHER_API_KEYS):
            try:
                async with httpx.AsyncClient(timeout=5) as c:
                    r = await c.get("https://api.openweathermap.org/data/2.5/weather", params={"q": "Paris", "appid": key})
                    if r.status_code == 200:
                        messages.append(f"‚úÖ OpenWeather key #{i+1}: OK")
                    else:
                        messages.append(f"‚ùå OpenWeather key #{i+1}: {r.status_code} {r.text[:100]}")
            except Exception as e:
                messages.append(f"‚ùå OpenWeather key #{i+1} erreur : {e}")
        return "\n".join(messages)

    # Test RapidAPI
    async def test_rapidapi():
        messages = []
        for i, key in enumerate(RAPIDAPI_KEYS):
            try:
                async with httpx.AsyncClient(timeout=5) as c:
                    # RapidAPI ne fournit pas d'endpoint ping, on simule
                    messages.append(f"üîé RapidAPI key #{i+1}: (pas de ping, cl√© charg√©e)")
            except Exception as e:
                messages.append(f"‚ùå RapidAPI key #{i+1} erreur : {e}")
        return "\n".join(messages)

    results.append(await test_openrouter())
    results.append(await test_tavily())
    results.append(await test_serper())
    results.append(await test_hf())
    results.append(await test_wolfram())
    results.append(await test_google_apis())
    results.append(await test_ocr())
    results.append(await test_openweather())
    results.append(await test_rapidapi())

    status_message = "üìä <b>√âtat et quota IA / API :</b>\n" + "\n\n".join(results) + f"\n\nDernier test : {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}"
    try:
        await bot_instance.send_message(chat_id=PRIVATE_GROUP_ID, text=status_message, parse_mode="HTML")
    except Exception as e:
        print(f"Erreur envoi message quota ia : {e}")

# -------------------------------------------------------------------------
# -------------------------- FONCTIONS BOT PRINCIPALES --------------------
# -------------------------------------------------------------------------

async def MA():
    try: import nest_asyncio; nest_asyncio.apply()
    except: pass
    sm = "‚úÖ Bot red√©marr√© " + datetime.now().strftime("%H:%M:%S")
    await bot_instance.send_message(chat_id=PRIVATE_GROUP_ID, text=sm)
    if not AsyncIOScheduler(timezone=timezone.utc).running:
        scheduler = AsyncIOScheduler(timezone=timezone.utc); scheduler.start()
        scheduler.add_job(lambda: prompt_cache.clear() or api_response_cache.clear() or gc.collect(), 'interval', hours=6)
        scheduler.add_job(mise_a_jour_script, 'interval', hours=8)
        scheduler.add_job(lambda: None, 'interval', minutes=60) # Placeholders, tu peux remettre DCF et SIIA ici
    app = ApplicationBuilder().token(BOT_TOKEN).build()
    register_commands(app)
    app.add_handler(MessageHandler(filters.TEXT & (~filters.Chat(PRIVATE_GROUP_ID)), HM))
    app.add_handler(MessageHandler(filters.Chat(PRIVATE_GROUP_ID) & filters.TEXT, HGM))
    await start_background_tasks(app)
    print(f"Bot actif : Levraibootbot (ID {BOT_TOKEN.split(':')[0]})\nüîß Gestionnaire API optimis√© activ√©")
    await app.run_polling()

async def mise_a_jour_script():
    try:
        async with httpx.AsyncClient(timeout=20) as c:
            r = await c.get(UPDATE_URL)
            if r.status_code == 200:
                nc = r.text
                ac = LOCAL_SCRIPT_PATH.read_text(encoding="utf-8")
                if H(nc) != H(ac):
                    b = LOCAL_SCRIPT_PATH.with_suffix(".backup.py")
                    LOCAL_SCRIPT_PATH.rename(b)
                    LOCAL_SCRIPT_PATH.write_text(nc, encoding="utf-8")
                    logging.info("‚úÖ Script MAJ auto.")
                    await bot_instance.send_message(chat_id=PRIVATE_GROUP_ID, text="üîÑ Script MAJ auto. Red√©marrage recommand√©.")
                else:
                    logging.info("‚ÑπÔ∏è Script √† jour.")
    except Exception as e: LE(f"[AutoUpdate] MAJ auto : {e}")

if __name__ == "__main__":
    asyncio.run(MA())
#!/usr/bin/env python3
import os,sys,json,time,logging,asyncio,re,signal,traceback,httpx,gzip,random,gc,hashlib
from datetime import datetime,timezone,date
from functools import wraps
from pathlib import Path
from collections import OrderedDict
from apscheduler.schedulers.asyncio import AsyncIOScheduler
from telegram import Bot,Update
from telegram.constants import ParseMode
from telegram.ext import ApplicationBuilder,MessageHandler,filters,CommandHandler,ContextTypes
try: import fitz
except: fitz=None
os.environ["TZ"]="UTC"
semaphore=asyncio.Semaphore(2)
UPDATE_URL="https://tonlien.com/levraibot.py"
LOCAL_SCRIPT_PATH=Path(__file__)
MAX_FILE_SIZE=510241024
BASE_DIR=Path("sauvegardes");BASE_DIR.mkdir(exist_ok=True)
ERROR_LOG_PATH=BASE_DIR/"erreurs.log"
DAILY_CHALLENGE_PATH=Path("defis_code");DAILY_CHALLENGE_PATH.mkdir(exist_ok=True)

# ===================== CL√âS API EN DUR =====================
BOT_TOKEN="7902342551:AAG6r1QA2GTMXcmcsWHi36Ivd_PVeMXULOs"
PRIVATE_GROUP_ID=-1002845235344

GOOGLE_API_KEYS=[
    "AIzaSyAk6Ph25xuIY3b5o-JgdL652MvK4usp8Ms",
    "AIzaSyDuccmfiPSk4042NeJCYIjA8EOXPo1YKXU",
    "AIzaSyAQq6o9voefaDxkAEORf7W-IB3QbotIkwY",
    "AIzaSyDYaYrQQ7cwYFm8TBpyGM3dJweOGOYl7qw"
]
GOOGLE_CX_LIST=[
    "3368510e864b74936",
    "e745c9ca0ffb94659"
]
OCR_API_KEYS=[
    "K82679097388957",
    "K81079143888957",
    "K84281517488957"
]
TAVILY_KEYS=[
    "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",
    "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",
    "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",
    "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"
]
HUGGINGFACE_KEYS=[
    "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",
    "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",
    "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"
]
OPENROUTER_KEYS=[
    "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",
    "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",
    "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"
]
WOLFRAM_APP_IDS=[
    "96LX77-G8PGKJ3T7V",
    "96LX77-PYHRRET363",
    "96LX77-P9HPAYWRGL"
]
SERPER_KEYS=["047b30db1df999aaa9c293f2048037d40c651439"]
OPENWEATHER_API_KEYS=["c80075b7332716a418e47033463085ef"]
RAPIDAPI_KEYS=["d4d1f58d8emsh58d888c711b7400p1bcebejsn2cc04dce6efe"]

ALL_API_KEYS=list(set(
    GOOGLE_API_KEYS+OCR_API_KEYS+TAVILY_KEYS+HUGGINGFACE_KEYS+OPENROUTER_KEYS+WOLFRAM_APP_IDS+SERPER_KEYS+OPENWEATHER_API_KEYS+RAPIDAPI_KEYS
))
DAILY_LIMIT=150
MONTHLY_LIMIT=3000
prompt_cache=OrderedDict()
MAX_CACHE_SIZE=1500
AUTHORIZED_TO_LEARN=True
bot_instance=Bot(BOT_TOKEN)
api_response_cache=OrderedDict()
api_global_lock={}
API_CACHE_EXPIRATION=600

def H(t):return hashlib.sha256(t.encode()).hexdigest()
def K(n,p):return f"{n}:{H(p)}"
def G(n,p):v=api_response_cache.get(K(n,p));return v["r"] if v and time.time()-v["t"]<API_CACHE_EXPIRATION else None
def S(n,p,r):api_response_cache[K(n,p)]={"r":r,"t":time.time()};len(api_response_cache)>MAX_CACHE_SIZE and api_response_cache.popitem(last=False)
async def C(f,n,p,*a,**k):
    k_=K(n,p)
    if k_ not in api_global_lock:
        api_global_lock[k_]=asyncio.Lock()
    async with api_global_lock[k_]:
        c=G(n,p)
        if c is not None:return c
        r=await f(p,*a,**k)
        S(n,p,r)
        return r
def NU(x):return re.sub(r"https?://",lambda m:m.group(0).replace("t","x",1),re.sub(r"\.org","[.]org",re.sub(r"\.net","[.]net",re.sub(r"\.com","[.]com",re.sub(r"www\.","wxx.",x)))))
def RL(p):p.exists() and p.stat().st_size>MAX_FILE_SIZE and p.replace(p.with_suffix(f".old_{int(time.time())}.json"))
def LG():
    RL(ERROR_LOG_PATH)
    logging.basicConfig(level=logging.INFO,format="%(asctime)s [%(levelname)s] %(message)s",datefmt="%Y-%m-%d %H:%M:%S")
    el=logging.getLogger("erreurs_api")
    eh=logging.FileHandler(ERROR_LOG_PATH,encoding="utf-8")
    eh.setFormatter(logging.Formatter("%(asctime)s [%(levelname)s] %(message)s",datefmt="%Y-%m-%d %H:%M:%S"))
    el.addHandler(eh)
    el.setLevel(logging.ERROR)
    return el
error_logger=LG()
signal.signal(signal.SIGINT,lambda s,f:(logging.info("Arr√™t demand√©, fermeture propre..."),sys.exit(0)))
def LE(m):RL(ERROR_LOG_PATH);error_logger.error(m);asyncio.create_task(bot_instance.send_message(chat_id=PRIVATE_GROUP_ID,text=f"‚ö†Ô∏è ERREUR CRITIQUE :\n{m}"))
def SJA(p,d):
    RL(p)
    tp=p.with_suffix(".tmp")
    if p.exists():
        p.replace(p.with_suffix(p.suffix+".fullbackup"))
    json.dump(d,tp.open("w",encoding="utf-8"),indent=2,ensure_ascii=False)
    tp.replace(p)
def SLJ(p,d):
    try:
        if not p.exists():return d
        return json.load(open(p,"r",encoding="utf-8"))
    except Exception:
        try:p.unlink()
        except Exception:pass
        return d
def CL(p):
    try:
        if p.exists() and p.stat().st_size>1e6:
            import shutil
            gz=p.with_suffix(p.suffix+".gz")
            with open(p,"rb") as f_in,gzip.open(gz,"wb") as f_out:
                shutil.copyfileobj(f_in,f_out)
            p.unlink()
            gz.rename(p)
    except Exception as e:
        LE(f"[Compression auto] {e}\n{traceback.format_exc()}")
quotas_path=BASE_DIR/"quotas.json"
def LQ():
    q=SLJ(quotas_path,{"daily":0,"monthly":0,"last_reset":datetime.now().isoformat(),"tavily_idx":0})
    q.setdefault("daily",0)
    q.setdefault("monthly",0)
    q.setdefault("last_reset",datetime.now().isoformat())
    q.setdefault("tavily_idx",0)
    return q
quotas=LQ()
def SQ():SJA(quotas_path,quotas)
def RQ():
    n=datetime.now()
    last=datetime.fromisoformat(quotas.get("last_reset",n.isoformat())) if quotas.get("last_reset") else n
    c=False
    if (n-last).days>=1:
        quotas["daily"]=0
        c=True
    if n.month!=last.month:
        quotas["monthly"]=0
    if c:
        quotas["last_reset"]=n.isoformat()
        SQ()
def IQ(b=1):
    quotas["daily"]+=b
    quotas["monthly"]+=b
    SQ()
def CQ():
    return quotas["daily"]<DAILY_LIMIT and quotas["monthly"]<MONTHLY_LIMIT
def AQ(b=None):
    if quotas["daily"]>=DAILY_LIMIT:
        LE("üö® Quota journalier IA atteint !")
        if b:asyncio.create_task(b.send_message(chat_id=PRIVATE_GROUP_ID,text="üö® Quota journalier IA atteint !"))
    if quotas["monthly"]>=MONTHLY_LIMIT:
        LE("üö® Quota mensuel IA atteint !")
        if b:asyncio.create_task(b.send_message(chat_id=PRIVATE_GROUP_ID,text="üö® Quota mensuel IA atteint !"))
def STK():
    idx=quotas.get("tavily_idx",0)
    key=TAVILY_KEYS[idx%len(TAVILY_KEYS)]
    quotas["tavily_idx"]=(idx+1)%len(TAVILY_KEYS)
    SQ()
    return key
def GUD(u):p=BASE_DIR/str(u);p.mkdir(exist_ok=True);return p
def SJ(u,f,d):SJA(GUD(u)/f,d)
def EK(t):w=re.findall(r"\b[a-zA-Z√©√®√™√¥√†√π√ß√Æ√Ø≈ì]{4,}\b",t.lower());f={};[f.setdefault(x,0) or f.update({x:f[x]+1}) for x in w];return ", ".join(x for x,_ in sorted(f.items(),key=lambda x:x[1],reverse=True)[:5])
def TC(t):return "#tags : "+EK(t)
def AL(u,r,t,m=100):t=NU(t);u!=PRIVATE_GROUP_ID and SJ(u,"log.json",SLJ(GUD(u)/"log.json",[])+[{"time":datetime.now().isoformat(),"role":r,"text":t[:500],"tags":TC(t)}][-m:])
def ACH(u,r,t):t=NU(t);u!=PRIVATE_GROUP_ID and SJ(u,"chat_history.json",SLJ(GUD(u)/"chat_history.json",[])+[{"time":datetime.now().isoformat(),"role":r,"text":t}][-1000:])
def SGM(g,r,t,m=1000):SJ(g,"group_chat_history.json",SLJ(GUD(g)/"group_chat_history.json",[])+[{"time":datetime.now().isoformat(),"role":r,"text":t}][-m:])
def UPO(s):z=set();r=[];[r.append(x) for x in s if x not in z and not z.add(x)];return r
def ALM(u,t):SJ(u,"long_memory.json",UPO(SLJ(GUD(u)/"long_memory.json",[]) if isinstance(SLJ(GUD(u)/"long_memory.json",[]),list) else [])+[t.strip()])[-100:]
def GLM(u):return "\n".join(SLJ(GUD(u)/"long_memory.json",[])[-20:])
def GRM(u,l=5):return "\n".join(f"{x['role']} : {x['text']}" for x in SLJ(GUD(u)/"log.json",[])[-l:] if x.get("role")!="bot")
def NPM(p):return re.sub(r"\s+"," ",p.strip().replace("‚Ä¶","...").strip("¬´¬ª'\""))
def SRI(t):
    s=100
    if "je ne sais pas" in t.lower():s-=30
    if "d√©sol√©" in t.lower():s-=20
    if len(t)<50:s-=30
    if len(t)>1500:s-=10
    if t.count("...")>3:s-=10
    return max(0,min(100,s))
def ISR(t):return (not t or len(t.strip())<10 or t.lower().strip() in ["...","aucune id√©e","je ne sais pas"])
def SRV2(t,q=""):
    tc=t.lower();ql=len(q);rl=len(tc)
    e=["je ne peux pas","je suis d√©sol√©","impossible","je ne sais pas","je ne suis pas capable","en tant que mod√®le","je n'ai pas acc√®s","je ne suis pas en mesure","i'm sorry"];found=sum(tc.count(x) for x in e)
    p=["solution","r√©ponse","voici","peut","possible","certainement"]
    return False if any(x in tc for x in p) else rl<15 or found>1 or (ql>100 and rl<ql/4)
BROKEN_IA={}
def IAB(m):i=BROKEN_IA.get(m,{"fail_count":0,"last_fail":0});return i["fail_count"]>=3 and (time.time()-i["last_fail"]<600)
def MIF(m):i=BROKEN_IA.get(m,{"fail_count":0,"last_fail":0});i["fail_count"]+=1;i["last_fail"]=time.time();BROKEN_IA[m]=i
def MIS(m):m in BROKEN_IA and BROKEN_IA.pop(m)
running_jobs={}
def UJ(n):
    def d(f):
        async def w(*a,**k):
            if not running_jobs.get(n):
                running_jobs[n]=True
                await f(*a,**k)
                running_jobs.pop(n)
        return w
    return d
async def WT(f,*a,timeout=25):
    try:return await asyncio.wait_for(f(*a),timeout)
    except:LE(f"[Timeout] {f.__name__} >{timeout}s.");return None
async def RA(f,*a,retries=3,delay=2,**k):
    for i in range(retries):
        try:return await f(*a,**k)
        except:await asyncio.sleep(delay*(2**i)+random.uniform(0,1))
def AC(f):
    @wraps(f)
    async def w(*a,**k):
        try:r=await f(*a,**k)
        except Exception as e:LE(f"API {f.__name__}:{e}\n{traceback.format_exc()}");return f"Erreur API {f.__name__} : {e}"
        if not r:LE(f"[API] Vide {f.__name__}");return "R√©ponse vide"
        return r
    return w

# ===================== Ajout gestion messages HM / HGM =====================
async def HM(update,context):
    print(f"[HM] Message re√ßu hors groupe : {update.message.text}")
    await update.message.reply_text("R√©ponse hors groupe OK")
async def HGM(update,context):
    print(f"[HGM] Message re√ßu dans groupe priv√© : {update.message.text}")
    await update.message.reply_text("R√©ponse groupe priv√© OK")

# ===================== Commandes Telegram =====================
async def cmd_quota(update,context):
    await quota_ia()
    stats_file=BASE_DIR/"stats.json"
    stats={}
    if stats_file.exists():
        stats=SLJ(stats_file,{})
    calls=stats.get("calls",0)
    durations=stats.get("durations",[])
    avg_duration=round(sum(durations)/len(durations),2) if durations else "inconnue"
    last_call=stats.get("last","jamais")
    texte=(f"üìä Statistiques IA :\n"
        f"‚Ä¢ Appels API : {calls}\n"
        f"‚Ä¢ Dur√©e moyenne : {avg_duration}s\n"
        f"‚Ä¢ Dernier appel : {last_call}\n")
    await update.message.reply_text(texte)
async def cmd_defi(update,context):
    texte=(
        "üéØ D√©fi IA du jour :\n"
        "üß© Lire un fichier 'exemple.txt', remplacer 'chat' par 'chien', "
        "et sauvegarder dans 'resultat.txt'.\n\n"
        "Code Python exemple :\n"
        "def remplacer_mot():\n"
        "    with open('exemple.txt', 'r', encoding='utf-8') as f:\n"
        "        contenu = f.read()\n"
        "    contenu = contenu.replace('chat', 'chien')\n"
        "    with open('resultat.txt', 'w', encoding='utf-8') as f:\n"
        "        f.write(contenu)\n"
        "remplacer_mot()"
    )
    await update.message.reply_text(texte)
async def cmd_update(update,context):
    await update.message.reply_text("üîÑ V√©rification et mise √† jour du script en cours...")
    try:
        await mise_a_jour_script()
        await update.message.reply_text("‚úÖ Mise √† jour termin√©e (voir logs).")
    except Exception as e:
        await update.message.reply_text(f"‚ùå Erreur mise √† jour : {e}")
def register_commands(app):
    app.add_handler(CommandHandler("quota",cmd_quota))
    app.add_handler(CommandHandler("defi",cmd_defi))
    app.add_handler(CommandHandler("update",cmd_update))

# ===================== APPELS API AVEC CL√âS EN DUR =====================
def get_any_key(keys):return random.choice(keys)
async def CHF(p):
    url="https://api-inference.huggingface.co/models/gpt2"
    h={"Authorization":f"Bearer {get_any_key(HUGGINGFACE_KEYS)}"}
    pl={"inputs":p,"options":{"wait_for_model":True}}
    async with httpx.AsyncClient(timeout=30) as c:
        r=await c.post(url,headers=h,json=pl)
        return r.json()[0]["generated_text"] if r.status_code==200 and isinstance(r.json(),list) and "generated_text" in r.json()[0] else (str(r.json()) if r.status_code==200 else None)
async def CW(q):
    url="http://api.wolframalpha.com/v2/query"
    pa={"appid":get_any_key(WOLFRAM_APP_IDS),"input":q,"output":"JSON"}
    async with httpx.AsyncClient(timeout=20) as c:
        r=await c.get(url,params=pa)
        d=r.json();pods=d.get("queryresult",{}).get("pods",[])
        return next((x["subpods"][0].get("plaintext","") for x in pods if x.get("title","").lower() in ["result","definition"]),None) if r.status_code==200 else None
async def CGC(q):
    cx=GOOGLE_CX_LIST[0]
    url="https://www.googleapis.com/customsearch/v1"
    pa={"key":get_any_key(GOOGLE_API_KEYS),"cx":cx,"q":q,"num":1}
    async with httpx.AsyncClient(timeout=20) as c:
        r=await c.get(url,params=pa)
        j=r.json();i=j.get("items",[])
        return i[0].get("snippet","Pas de contenu trouv√©.") if r.status_code==200 and i else "Pas de r√©sultat trouv√© via Google Custom Search."
async def CTA(q):
    url="https://api.tavily.com/v1/ask"
    h={"Authorization":f"Bearer {get_any_key(TAVILY_KEYS)}"}
    pl={"question":q}
    async with httpx.AsyncClient(timeout=20) as c:
        r=await c.post(url,headers=h,json=pl)
        return r.json().get("answer") or "Pas de r√©ponse de Tavily." if r.status_code==200 else None
async def CO(image_url):
    url="https://api.ocrservice.com/parse/image"
    h={"apikey":get_any_key(OCR_API_KEYS)}
    pl={"url":image_url}
    async with httpx.AsyncClient(timeout=20) as c:
        r=await c.post(url,headers=h,json=pl)
        return r.json().get("ParsedText","Pas de texte d√©tect√©.") if r.status_code==200 else None
async def COW(city):
    url="https://api.openweathermap.org/data/2.5/weather"
    pa={"q":city,"appid":get_any_key(OPENWEATHER_API_KEYS),"units":"metric","lang":"fr"}
    async with httpx.AsyncClient(timeout=20) as c:
        r=await c.get(url,params=pa)
        d=r.json()
        return f"M√©t√©o √† {city} : {d['weather'][0]['description']}, {d['main']['temp']}¬∞C" if r.status_code==200 else None
async def CRA(q):
    url="https://example-rapidapi.p.rapidapi.com/endpoint"
    h={"X-RapidAPI-Key":get_any_key(RAPIDAPI_KEYS),"X-RapidAPI-Host":"example-rapidapi.p.rapidapi.com"}
    pa={"query":q}
    async with httpx.AsyncClient(timeout=20) as c:
        r=await c.get(url,headers=h,params=pa)
        return r.json().get("result","Pas de r√©sultat.") if r.status_code==200 else None

# Nouvelle fonction CIG multi-IA/cl√©
async def CIG(prompt,api_key=None,model_name=None):
    prompt=NPM(prompt)
    if model_name=="OpenRouter" or (not model_name and not api_key):
        models=["openai/gpt-4o-mini","mistralai/mistral-7b-instruct","mistralai/mixtral-8x7b-instruct"]
        async def SMC(m):
            async with httpx.AsyncClient(timeout=30) as c:
                try:
                    st=time.time()
                    r=await c.post("https://openrouter.ai/api/v1/chat/completions",headers={"Authorization":f"Bearer {get_any_key(OPENROUTER_KEYS)}","Content-Type":"application/json"},json={"model":m,"messages":[{"role":"user","content":prompt}],"max_tokens":600,"temperature":0.7})
                    du=round(time.time()-st,2)
                    if r.status_code==200:
                        j=r.json();cont=j.get("choices",[{}])[0].get("message",{}).get("content","")
                        if cont and not SRV2(cont,prompt):
                            f=BASE_DIR/f"ia_reply_{datetime.now().strftime('%Y%m%d_%H%M%S')}.txt"
                            f.write_text(cont,encoding="utf-8")
                            return NU(cont)
                        elif SRV2(cont,prompt):
                            MIF(m)
                            return None
                    else:
                        LE(f"[OpenRouter] {m}: {r.status_code} ‚Üí {r.text}")
                except Exception as e:
                    LE(f"[OpenRouter] {m} erreur:{e}\n{traceback.format_exc()}")
                    MIF(m)
                    return None
        async def SFC(m):
            async with semaphore:
                if IAB(m):return None
                r=await WT(SMC,m)
                if r:MIS(m);return r
                return None
        ts=[SFC(m) for m in models]
        for f in asyncio.as_completed(ts):
            r=await f
            if r:return r
        return "‚ùå Toutes les IA gratuites ont √©chou√© (r√©seau ou quota ?)."
    if model_name and model_name.startswith("Tavily"):
        url="https://api.tavily.com/v1/ask"
        headers={"Authorization":f"Bearer {api_key or get_any_key(TAVILY_KEYS)}"}
        payload={"question":prompt}
        async with httpx.AsyncClient(timeout=20) as c:
            try:
                r=await c.post(url,headers=headers,json=payload)
                if r.status_code==200:
                    rep=r.json().get("answer")
                    return rep if rep else "Pas de r√©ponse de Tavily."
                else:
                    return f"[Tavily] Erreur {r.status_code}: {r.text}"
            except Exception as e:
                return f"[Tavily] Exception: {e}"
    if model_name=="Serper":
        url="https://serpapi.com/search"
        params={"q":prompt,"api_key":api_key or get_any_key(SERPER_KEYS),"engine":"google"}
        async with httpx.AsyncClient(timeout=10) as c:
            try:
                r=await c.get(url,params=params)
                if r.status_code==200:
                    j=r.json()
                    return j.get("organic_results",[{}])[0].get("snippet","Pas de r√©sultat Serper.")
                return f"[Serper] Erreur {r.status_code}: {r.text}"
            except Exception as e:
                return f"[Serper] Exception: {e}"
    if model_name=="HuggingFace":
        url="https://api-inference.huggingface.co/models/gpt2"
        headers={"Authorization":f"Bearer {api_key or get_any_key(HUGGINGFACE_KEYS)}"}
        payload={"inputs":prompt,"options":{"wait_for_model":True}}
        async with httpx.AsyncClient(timeout=30) as c:
            try:
                r=await c.post(url,headers=headers,json=payload)
                if r.status_code==200 and isinstance(r.json(),list) and "generated_text" in r.json()[0]:
                    return r.json()[0]["generated_text"]
                return f"[HF] Erreur {r.status_code}: {r.text}"
            except Exception as e:
                return f"[HF] Exception: {e}"
    if model_name=="Wolfram":
        url="http://api.wolframalpha.com/v2/query"
        params={"input":prompt,"appid":api_key or get_any_key(WOLFRAM_APP_IDS)}
        async with httpx.AsyncClient(timeout=20) as c:
            try:
                r=await c.get(url,params=params)
                if r.status_code==200:
                    d=r.json();pods=d.get("queryresult",{}).get("pods",[])
                    return next((x["subpods"][0].get("plaintext","") for x in pods if x.get("title","").lower() in ["result","definition"]),None) or "Pas de r√©sultat Wolfram."
                return f"[Wolfram] Erreur {r.status_code}: {r.text}"
            except Exception as e:
                return f"[Wolfram] Exception: {e}"
    if model_name and model_name.startswith("GoogleCX"):
        idx=int(model_name.split("-")[1])-1
        cx=GOOGLE_CX_LIST[idx]
        url="https://www.googleapis.com/customsearch/v1"
        params={"q":prompt,"key":api_key or get_any_key(GOOGLE_API_KEYS),"cx":cx}
        async with httpx.AsyncClient(timeout=10) as c:
            try:
                r=await c.get(url,params=params)
                if r.status_code==200:
                    j=r.json();i=j.get("items",[])
                    return i[0].get("snippet","Pas de r√©sultat Google CustomSearch.") if i else "Pas de r√©sultat Google."
                return f"[GoogleCX] Erreur {r.status_code}: {r.text}"
            except Exception as e:
                return f"[GoogleCX] Exception: {e}"
    return "‚ùå Aucune IA/cl√© valide pour ce CIG"

# -------------------------------------------------------------------------
# ----------------- CODING CHALLENGE TOUTES IA EN PARALL√àLE --------------
# -------------------------------------------------------------------------
CODING_CHALLENGE_ENABLED=True
LAST_CHALLENGE_FILE=DAILY_CHALLENGE_PATH/"last_challenge.py"
HISTORY_DIR=DAILY_CHALLENGE_PATH/"history"
HISTORY_DIR.mkdir(exist_ok=True)
def diff_text(old_text,new_text):
    import difflib
    diff=difflib.unified_diff(
        old_text.splitlines(),new_text.splitlines(),lineterm=""
    )
    return "\n".join(diff)
async def coding_challenge_task():
    while True:
        if not CODING_CHALLENGE_ENABLED:
            await asyncio.sleep(900)
            continue
        prompt="""
Tu es une IA experte en programmation Python. G√©n√®re un script clair, correct et optimis√©, 100% en fran√ßais.
Ne dis pas que tu ne sais pas, ne t'excuse pas, ne formule pas de r√©ponses vagues.
Chaque version doit √™tre une am√©lioration nette de la pr√©c√©dente.
Commence par un commentaire indiquant ce qui a √©t√© am√©lior√©.
Le code doit √™tre direct, lisible, et pr√™t √† √™tre utilis√©.
"""
        ia_list=(
            [("OpenRouter",k) for k in OPENROUTER_KEYS]+
            [("Tavily",k) for k in TAVILY_KEYS]+
            [("Serper",k) for k in SERPER_KEYS]+
            [("HuggingFace",k) for k in HUGGINGFACE_KEYS]+
            [("Wolfram",k) for k in WOLFRAM_APP_IDS]+
            [("GoogleCX-1",k) for k in GOOGLE_API_KEYS]+
            [("GoogleCX-2",k) for k in GOOGLE_API_KEYS]
        )
        async def call_ia(nom,cle):
            try:
                r=await CIG(prompt,api_key=cle,model_name=nom)
                if r and len(r.strip())>20:
                    timestamp=datetime.now().strftime("%Y%m%d_%H%M%S")
                    fpath=DAILY_CHALLENGE_PATH/f"challenge_{nom}_{timestamp}.py"
                    fpath.write_text(r,encoding="utf-8")
                    await bot_instance.send_message(
                        chat_id=PRIVATE_GROUP_ID,
                        text=f"üíª <b>Code g√©n√©r√© par {nom}</b> :\n<pre>{r[:600]}</pre>",
                        parse_mode="HTML"
                    )
                    return r
                else:
                    await bot_instance.send_message(
                        chat_id=PRIVATE_GROUP_ID,
                        text=f"‚ö†Ô∏è <b>{nom}</b> n'a pas g√©n√©r√© de code valable cette fois.",
                        parse_mode="HTML"
                    )
                    return None
            except Exception as e:
                await bot_instance.send_message(
                    chat_id=PRIVATE_GROUP_ID,
                    text=f"‚ùå <b>{nom}</b> erreur lors de l'appel IA : {e}",
                    parse_mode="HTML"
                )
                return None
        results=await asyncio.gather(*[call_ia(n,k) for n,k in ia_list])
        await asyncio.sleep(900)
async def start_background_tasks(app):
    asyncio.create_task(coding_challenge_task())

# -------------------------------------------------------------------------
# ------------- COMMANDE /QUOTA POUR TOUTES LES IA (v√©rif statuts) --------
# -------------------------------------------------------------------------
async def quota_ia():
    from datetime import datetime
    results=[]
    async def test_openrouter():
        messages=[]
        for i,key in enumerate(OPENROUTER_KEYS):
            try:
                async with httpx.AsyncClient(timeout=5) as c:
                    r=await c.get("https://openrouter.ai/api/v1/models",headers={"Authorization":f"Bearer {key}"})
                    if r.status_code==200:
                        messages.append(f"‚úÖ OpenRouter key #{i+1}: OK")
                    else:
                        messages.append(f"‚ùå OpenRouter key #{i+1}: {r.status_code} {r.text[:100]}")
            except Exception as e:
                messages.append(f"‚ùå OpenRouter key #{i+1} erreur : {e}")
        return "\n".join(messages)
    async def test_tavily():
        messages=[]
        for i,key in enumerate(TAVILY_KEYS):
            try:
                async with httpx.AsyncClient(timeout=5) as c:
                    r=await c.get("https://api.tavily.com/ping",headers={"Authorization":key})
                    if r.status_code==200:
                        messages.append(f"‚úÖ Tavily key #{i+1}: OK")
                    else:
                        messages.append(f"‚ùå Tavily key #{i+1}: {r.status_code} {r.text[:100]}")
            except Exception as e:
                messages.append(f"‚ùå Tavily key #{i+1} erreur : {e}")
        return "\n".join(messages)
    async def test_serper():
        messages=[]
        for i,key in enumerate(SERPER_KEYS):
            try:
                async with httpx.AsyncClient(timeout=5) as c:
                    r=await c.get("https://serpapi.com/search",params={"q":"test","api_key":key,"engine":"google"})
                    if r.status_code==200:
                        messages.append(f"‚úÖ Serper key #{i+1}: OK")
                    else:
                        messages.append(f"‚ùå Serper key #{i+1}: {r.status_code} {r.text[:100]}")
            except Exception as e:
                messages.append(f"‚ùå Serper key #{i+1} erreur : {e}")
        return "\n".join(messages)
    async def test_hf():
        messages=[]
        for i,key in enumerate(HUGGINGFACE_KEYS):
            try:
                async with httpx.AsyncClient(timeout=5) as c:
                    r=await c.get("https://api-inference.huggingface.co/models/gpt2",headers={"Authorization":f"Bearer {key}"})
                    if r.status_code==200:
                        messages.append(f"‚úÖ HuggingFace key #{i+1}: OK")
                    else:
                        messages.append(f"‚ùå HuggingFace key #{i+1}: {r.status_code} {r.text[:100]}")
            except Exception as e:
                messages.append(f"‚ùå HuggingFace key #{i+1} erreur : {e}")
        return "\n".join(messages)
    async def test_wolfram():
        messages=[]
        for i,key in enumerate(WOLFRAM_APP_IDS):
            try:
                async with httpx.AsyncClient(timeout=5) as c:
                    r=await c.get("http://api.wolframalpha.com/v2/query",params={"input":"pi","appid":key})
                    if r.status_code==200:
                        messages.append(f"‚úÖ Wolfram key #{i+1}: OK")
                    else:
                        messages.append(f"‚ùå Wolfram key #{i+1}: {r.status_code} {r.text[:100]}")
            except Exception as e:
                messages.append(f"‚ùå Wolfram key #{i+1} erreur : {e}")
        return "\n".join(messages)
    async def test_google_apis():
        messages=[]
        for i,key in enumerate(GOOGLE_API_KEYS):
            for j,cx in enumerate(GOOGLE_CX_LIST):
                try:
                    async with httpx.AsyncClient(timeout=5) as c:
                        r=await c.get("https://www.googleapis.com/customsearch/v1",params={"q":"test","key":key,"cx":cx})
                        if r.status_code==200:
                            messages.append(f"‚úÖ Google Custom Search key #{i+1} CX #{j+1}: OK")
                        else:
                            messages.append(f"‚ùå Google Custom Search key #{i+1} CX #{j+1}: {r.status_code} {r.text[:100]}")
                except Exception as e:
                    messages.append(f"‚ùå Google Custom Search key #{i+1} CX #{j+1} erreur : {e}")
        return "\n".join(messages)
    async def test_ocr():
        messages=[]
        for i,key in enumerate(OCR_API_KEYS):
            try:
                async with httpx.AsyncClient(timeout=5) as c:
                    messages.append(f"üîé OCR key #{i+1}: (pas de ping, cl√© charg√©e)")
            except Exception as e:
                messages.append(f"‚ùå OCR key #{i+1} erreur : {e}")
        return "\n".join(messages)
    async def test_openweather():
        messages=[]
        for i,key in enumerate(OPENWEATHER_API_KEYS):
            try:
                async with httpx.AsyncClient(timeout=5) as c:
                    r=await c.get("https://api.openweathermap.org/data/2.5/weather",params={"q":"Paris","appid":key})
                    if r.status_code==200:
                        messages.append(f"‚úÖ OpenWeather key #{i+1}: OK")
                    else:
                        messages.append(f"‚ùå OpenWeather key #{i+1}: {r.status_code} {r.text[:100]}")
            except Exception as e:
                messages.append(f"‚ùå OpenWeather key #{i+1} erreur : {e}")
        return "\n".join(messages)
    async def test_rapidapi():
        messages=[]
        for i,key in enumerate(RAPIDAPI_KEYS):
            try:
                async with httpx.AsyncClient(timeout=5) as c:
                    messages.append(f"üîé RapidAPI key #{i+1}: (pas de ping, cl√© charg√©e)")
            except Exception as e:
                messages.append(f"‚ùå RapidAPI key #{i+1} erreur : {e}")
        return "\n".join(messages)
    results.append(await test_openrouter())
    results.append(await test_tavily())
    results.append(await test_serper())
    results.append(await test_hf())
    results.append(await test_wolfram())
    results.append(await test_google_apis())
    results.append(await test_ocr())
    results.append(await test_openweather())
    results.append(await test_rapidapi())
    status_message="üìä <b>√âtat et quota IA / API :</b>\n"+"\n\n".join(results)+f"\n\nDernier test : {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}"
    try:
        await bot_instance.send_message(chat_id=PRIVATE_GROUP_ID,text=status_message,parse_mode="HTML")
    except Exception as e:
        print(f"Erreur envoi message quota ia : {e}")

# -------------------------------------------------------------------------
# -------------------------- FONCTIONS BOT PRINCIPALES --------------------
# -------------------------------------------------------------------------
async def MA():
    try:import nest_asyncio;nest_asyncio.apply()
    except:pass
    sm="‚úÖ Bot red√©marr√© "+datetime.now().strftime("%H:%M:%S")
    await bot_instance.send_message(chat_id=PRIVATE_GROUP_ID,text=sm)
    if not AsyncIOScheduler(timezone=timezone.utc).running:
        scheduler=AsyncIOScheduler(timezone=timezone.utc);scheduler.start()
        scheduler.add_job(lambda: prompt_cache.clear() or api_response_cache.clear() or gc.collect(),'interval',hours=6)
        scheduler.add_job(mise_a_jour_script,'interval',hours=8)
        scheduler.add_job(lambda: None,'interval',minutes=60)
    app=ApplicationBuilder().token(BOT_TOKEN).build()
    register_commands(app)
    app.add_handler(MessageHandler(filters.TEXT&(~filters.Chat(PRIVATE_GROUP_ID)),HM))
    app.add_handler(MessageHandler(filters.Chat(PRIVATE_GROUP_ID)&filters.TEXT,HGM))
    await start_background_tasks(app)
    print(f"Bot actif : Levraibootbot (ID {BOT_TOKEN.split(':')[0]})\nüîß Gestionnaire API optimis√© activ√©")
    await app.run_polling()
async def mise_a_jour_script():
    try:
        async with httpx.AsyncClient(timeout=20) as c:
            r=await c.get(UPDATE_URL)
            if r.status_code==200:
                nc=r.text
                ac=LOCAL_SCRIPT_PATH.read_text(encoding="utf-8")
                if H(nc)!=H(ac):
                    b=LOCAL_SCRIPT_PATH.with_suffix(".backup.py")
                    LOCAL_SCRIPT_PATH.rename(b)
                    LOCAL_SCRIPT_PATH.write_text(nc,encoding="utf-8")
                    logging.info("‚úÖ Script MAJ auto.")
                    await bot_instance.send_message(chat_id=PRIVATE_GROUP_ID,text="üîÑ Script MAJ auto. Red√©marrage recommand√©.")
                else:
                    logging.info("‚ÑπÔ∏è Script √† jour.")
    except Exception as e:LE(f"[AutoUpdate] MAJ auto : {e}")
if __name__=="__main__":
    asyncio.run(MA())


#!/usr/bin/env python3
import os,sys,json,time,logging,asyncio,re,signal,traceback,httpx,gzip,random,gc,hashlib
from datetime import datetime,timezone,date
from functools import wraps
from pathlib import Path
from collections import OrderedDict
from apscheduler.schedulers.asyncio import AsyncIOScheduler
from telegram import Bot,Update
from telegram.constants import ParseMode
from telegram.ext import ApplicationBuilder,MessageHandler,filters,CommandHandler
try: import fitz
except: fitz=None
os.environ["TZ"]="UTC"
semaphore=asyncio.Semaphore(2)
UPDATE_URL="https://tonlien.com/levraibot.py"
LOCAL_SCRIPT_PATH=Path(__file__)
MAX_FILE_SIZE=510241024
BASE_DIR=Path("sauvegardes");BASE_DIR.mkdir(exist_ok=True)
ERROR_LOG_PATH=BASE_DIR/"erreurs.log"
DAILY_CHALLENGE_PATH=Path("defis_code");DAILY_CHALLENGE_PATH.mkdir(exist_ok=True)
BOT_TOKEN="7902342551:AAG6r1QA2GTMXcmcsWHi36Ivd_PVeMXULOs"
PRIVATE_GROUP_ID=-1002845235344
GOOGLE_API_KEYS=["AIzaSyAk6Ph25xuIY3b5o-JgdL652MvK4usp8Ms","AIzaSyDuccmfiPSk4042NeJCYIjA8EOXPo1YKXU","AIzaSyAQq6o9voefaDxkAEORf7W-IB3QbotIkwY","AIzaSyDYaYrQQ7cwYFm8TBpyGM3dJweOGOYl7qw"]
GOOGLE_CX_LIST=["3368510e864b74936","e745c9ca0ffb94659"]
OCR_API_KEYS=["K82679097388957","K81079143888957","K84281517488957"]
TAVILY_KEYS=["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","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","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","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"]
HUGGINGFACE_KEYS=["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","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","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"]
OPENROUTER_KEYS=["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","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","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"]
WOLFRAM_APP_IDS=["96LX77-G8PGKJ3T7V","96LX77-PYHRRET363","96LX77-P9HPAYWRGL"]
SERPER_KEYS=["047b30db1df999aaa9c293f2048037d40c651439"]
OPENWEATHER_API_KEYS=["c80075b7332716a418e47033463085ef"]
RAPIDAPI_KEYS=["d4d1f58d8emsh58d888c711b7400p1bcebejsn2cc04dce6efe"]
DAILY_LIMIT=150;MONTHLY_LIMIT=3000
prompt_cache=OrderedDict();MAX_CACHE_SIZE=1500;AUTHORIZED_TO_LEARN=True
bot_instance=Bot(BOT_TOKEN)
api_response_cache=OrderedDict();api_global_lock={};API_CACHE_EXPIRATION=600
def H(t):return hashlib.sha256(t.encode()).hexdigest()
def K(n,p):return f"{n}:{H(p)}"
def G(n,p):v=api_response_cache.get(K(n,p));return v["r"] if v and time.time()-v["t"]<API_CACHE_EXPIRATION else None
def S(n,p,r):api_response_cache[K(n,p)]={"r":r,"t":time.time()};len(api_response_cache)>MAX_CACHE_SIZE and api_response_cache.popitem(last=False)
async def C(f,n,p,*a,**k):k_=K(n,p);api_global_lock.setdefault(k_,asyncio.Lock());async with api_global_lock[k_]:c=G(n,p);return c if c is not None else (lambda r:S(n,p,r),r)[1] if (r:=await f(p,*a,**k)) else None
def NU(x):return re.sub(r"https?://",lambda m:m.group(0).replace("t","x",1),re.sub(r"\.org","[.]org",re.sub(r"\.net","[.]net",re.sub(r"\.com","[.]com",re.sub(r"www\.","wxx.",x)))))
def RL(p):p.exists() and p.stat().st_size>MAX_FILE_SIZE and p.replace(p.with_suffix(f".old_{int(time.time())}.json"))
def LG():RL(ERROR_LOG_PATH);logging.basicConfig(level=logging.INFO,format="%(asctime)s [%(levelname)s] %(message)s",datefmt="%Y-%m-%d %H:%M:%S");el=logging.getLogger("erreurs_api");eh=logging.FileHandler(ERROR_LOG_PATH,encoding="utf-8");eh.setFormatter(logging.Formatter("%(asctime)s [%(levelname)s] %(message)s",datefmt="%Y-%m-%d %H:%M:%S"));el.addHandler(eh);el.setLevel(logging.ERROR);return el
error_logger=LG()
signal.signal(signal.SIGINT,lambda s,f:(logging.info("Arr√™t demand√©, fermeture propre..."),sys.exit(0)))
def LE(m):RL(ERROR_LOG_PATH);error_logger.error(m);asyncio.create_task(bot_instance.send_message(chat_id=PRIVATE_GROUP_ID,text=f"‚ö†Ô∏è ERREUR CRITIQUE :\n{m}"))
def SJA(p,d):RL(p);tp=p.with_suffix(".tmp");p.exists() and p.replace(p.with_suffix(p.suffix+".fullbackup"));json.dump(d,tp.open("w",encoding="utf-8"),indent=2,ensure_ascii=False);tp.replace(p)
def SLJ(p,d): 
 try:return json.load(open(p,"r",encoding="utf-8")) if p.exists() else d
 except: 
  try:p.unlink()
  except:pass
  return d
def CL(p): 
 try:
  if p.exists() and p.stat().st_size>1e6:
   import shutil
   gz=p.with_suffix(p.suffix+".gz")
   with open(p,"rb") as f_in,gzip.open(gz,"wb") as f_out:shutil.copyfileobj(f_in,f_out)
   p.unlink();gz.rename(p)
 except Exception as e:LE(f"[Compression auto] {e}\n{traceback.format_exc()}")
quotas_path=BASE_DIR/"quotas.json"
def LQ():q=SLJ(quotas_path,{"daily":0,"monthly":0,"last_reset":datetime.now().isoformat(),"tavily_idx":0});q.setdefault("daily",0);q.setdefault("monthly",0);q.setdefault("last_reset",datetime.now().isoformat());q.setdefault("tavily_idx",0);return q
quotas=LQ()
def SQ():SJA(quotas_path,quotas)
def RQ():n=datetime.now();last=datetime.fromisoformat(quotas.get("last_reset",n.isoformat())) if quotas.get("last_reset") else n;c=False;if (n-last).days>=1:quotas["daily"]=0;c=True;if n.month!=last.month:quotas["monthly"]=0;if c:quotas["last_reset"]=n.isoformat();SQ()
def IQ(b=1):quotas["daily"]+=b;quotas["monthly"]+=b;SQ()
def CQ():return quotas["daily"]<DAILY_LIMIT and quotas["monthly"]<MONTHLY_LIMIT
def AQ(b=None): 
 if quotas["daily"]>=DAILY_LIMIT:LE("üö® Quota journalier IA atteint !");b and asyncio.create_task(b.send_message(chat_id=PRIVATE_GROUP_ID,text="üö® Quota journalier IA atteint !"))
 if quotas["monthly"]>=MONTHLY_LIMIT:LE("üö® Quota mensuel IA atteint !");b and asyncio.create_task(b.send_message(chat_id=PRIVATE_GROUP_ID,text="üö® Quota mensuel IA atteint !"))
def STK():idx=quotas.get("tavily_idx",0);key=TAVILY_KEYS[idx%len(TAVILY_KEYS)];quotas["tavily_idx"]=(idx+1)%len(TAVILY_KEYS);SQ();return key
def GUD(u):p=BASE_DIR/str(u);p.mkdir(exist_ok=True);return p
def SJ(u,f,d):SJA(GUD(u)/f,d)
def EK(t):w=re.findall(r"\b[a-zA-Z√©√®√™√¥√†√π√ß√Æ√Ø≈ì]{4,}\b",t.lower());f={};[f.setdefault(x,0) or f.update({x:f[x]+1}) for x in w];return ", ".join(x for x,_ in sorted(f.items(),key=lambda x:x[1],reverse=True)[:5])
def TC(t):return "#tags : "+EK(t)
def AL(u,r,t,m=100):t=NU(t);u!=PRIVATE_GROUP_ID and SJ(u,"log.json",SLJ(GUD(u)/"log.json",[])+[{"time":datetime.now().isoformat(),"role":r,"text":t[:500],"tags":TC(t)}][-m:])
def ACH(u,r,t):t=NU(t);u!=PRIVATE_GROUP_ID and SJ(u,"chat_history.json",SLJ(GUD(u)/"chat_history.json",[])+[{"time":datetime.now().isoformat(),"role":r,"text":t}][-1000:])
def SGM(g,r,t,m=1000):SJ(g,"group_chat_history.json",SLJ(GUD(g)/"group_chat_history.json",[])+[{"time":datetime.now().isoformat(),"role":r,"text":t}][-m:])
def UPO(s):z=set();r=[];[r.append(x) for x in s if x not in z and not z.add(x)];return r
def ALM(u,t):SJ(u,"long_memory.json",UPO(SLJ(GUD(u)/"long_memory.json",[]) if isinstance(SLJ(GUD(u)/"long_memory.json",[]),list) else [])+[t.strip()])[-100:]
def GLM(u):return "\n".join(SLJ(GUD(u)/"long_memory.json",[])[-20:])
def GRM(u,l=5):return "\n".join(f"{x['role']} : {x['text']}" for x in SLJ(GUD(u)/"log.json",[])[-l:] if x.get("role")!="bot")
def NPM(p):return re.sub(r"\s+"," ",p.strip().replace("‚Ä¶","...").strip("¬´¬ª'\""))
def SRI(t):s=100;if "je ne sais pas" in t.lower():s-=30;if "d√©sol√©" in t.lower():s-=20;if len(t)<50:s-=30;if len(t)>1500:s-=10;if t.count("...")>3:s-=10;return max(0,min(100,s))
def ISR(t):return (not t or len(t.strip())<10 or t.lower().strip() in ["...","aucune id√©e","je ne sais pas"])
def SRV2(t,q=""):tc=t.lower();ql=len(q);rl=len(tc);e=["je ne peux pas","je suis d√©sol√©","impossible","je ne sais pas","je ne suis pas capable","en tant que mod√®le","je n'ai pas acc√®s","je ne suis pas en mesure","i'm sorry"];found=sum(tc.count(x) for x in e);p=["solution","r√©ponse","voici","peut","possible","certainement"];return False if any(x in tc for x in p) else rl<15 or found>1 or (ql>100 and rl<ql/4)
BROKEN_IA={}
def IAB(m):i=BROKEN_IA.get(m,{"fail_count":0,"last_fail":0});return i["fail_count"]>=3 and (time.time()-i["last_fail"]<600)
def MIF(m):i=BROKEN_IA.get(m,{"fail_count":0,"last_fail":0});i["fail_count"]+=1;i["last_fail"]=time.time();BROKEN_IA[m]=i
def MIS(m):m in BROKEN_IA and BROKEN_IA.pop(m)
async def with_timeout(func,*args,timeout=25): 
 try:return await asyncio.wait_for(func(*args),timeout)
 except asyncio.TimeoutError:LE(f"[Timeout] {func.__name__} >{timeout}s.");return None
async def retry_async(func,*args,retries=3,delay=2,**kwargs):
 for attempt in range(retries):
  try:return await func(*args,**kwargs)
  except:await asyncio.sleep(delay*(2**attempt)+random.uniform(0,1))
def get_any_key(keys):return random.choice(keys)
async def call_ia_gratuite(prompt): 
 prompt=NPM(prompt)
 models=["openai/gpt-4o-mini","mistralai/mistral-7b-instruct","mistralai/mixtral-8x7b-instruct"]
 async def single_model_call(m):
  async with httpx.AsyncClient(timeout=30) as c:
   try:
    r=await c.post("https://openrouter.ai/api/v1/chat/completions",headers={"Authorization":f"Bearer {get_any_key(OPENROUTER_KEYS)}","Content-Type":"application/json"},json={"model":m,"messages":[{"role":"user","content":prompt}],"max_tokens":600,"temperature":0.7})
    if r.status_code==200:
     j=r.json();cont=j.get("choices",[{}])[0].get("message",{}).get("content","")
     if cont and not SRV2(cont,prompt):return NU(cont)
     elif SRV2(cont,prompt):MIF(m);return None
   except Exception as e:MIF(m);LE(f"[OpenRouter] {m} erreur : {e}\n{traceback.format_exc()}");return None
 async def safe_model_call(m):
  async with semaphore:
   if IAB(m):return None
   try:result=await with_timeout(single_model_call,m);return result if result else None
   except Exception:MIF(m);return None
 tasks=[safe_model_call(m) for m in models]
 for fut in asyncio.as_completed(tasks):
  r=await fut
  if r:return r
 return "‚ùå Toutes les IA gratuites ont √©chou√© (r√©seau ou quota ?)."
async def fallback_api_calls(prompt):
 apis=[CGC,CW,CTA,CHF]
 for api in apis:
  res=await api(prompt)
  if res and "pas de" not in res.lower():return res
 return None
async def deliberation_interne(prompt):
 r=[await call_ia_gratuite(prompt)]
 filtres=[x for x in r if x and not SRV2(x,prompt)]
 if not filtres:return "‚ùå Toutes les IA ont √©chou√© √† r√©pondre correctement."
 debat="\n".join(f"R√©ponse {i+1} : {txt}" for i,txt in enumerate(filtres))
 juge_prompt=f"""Tu es une IA experte. Voici les r√©ponses propos√©es √† une m√™me question par d'autres IA :
{debat}
Analyse et synth√©tise la meilleure r√©ponse √† fournir √† l'utilisateur. Corrige si besoin, garde seulement les faits utiles. Ignore les excuses ou formulations inutiles."""
 s=await call_ia_gratuite(juge_prompt)
 return NU(s) or "‚ö†Ô∏è D√©lib√©ration impossible."
def get_recent_messages(uid,limit=5):return "\n".join(f"{l['role']} : {l['text']}" for l in SLJ(GUD(uid)/"log.json",[])[-limit:] if l.get("role")!="bot")
async def envoyer_texte_long_dans_groupe(txt):chunk_size=1998;[await bot_instance.send_message(chat_id=PRIVATE_GROUP_ID,text=NU(txt[i:i+chunk_size])) for i in range(0,len(txt),chunk_size)]
async def envoyer_fichier_dans_groupe(fichier:Path):
 try:async with fichier.open("rb") as f:await bot_instance.send_document(chat_id=PRIVATE_GROUP_ID,document=f,filename=fichier.name)
 except Exception as e:LE(f"Erreur envoi fichier dans groupe : {e}\n{traceback.format_exc()}")
def get_daily_python_challenge():
 today=date.today().isoformat();fp=DAILY_CHALLENGE_PATH/f"{today}_defi.py"
 if fp.exists():return fp.read_text(encoding="utf-8")
 ct="""üéØ D√©fi IA du {today}
üß© Objectif : Lire un fichier texte 'exemple.txt', remplacer 'chat' par 'chien', sauvegarder le nouveau texte dans 'resultat.txt'.
def remplacer_mot():
    with open("exemple.txt", "r", encoding="utf-8") as f:
        contenu = f.read()
    contenu = contenu.replace("chat", "chien")
    with open("resultat.txt", "w", encoding="utf-8") as f:
        f.write(contenu)
remplacer_mot()"""
 fp.write_text(ct,encoding="utf-8");return ct
async def defi_coding_force():
 defi=get_daily_python_challenge()
 if defi:await envoyer_texte_long_dans_groupe("‚öôÔ∏è <b>D√©fi IA forc√© (toutes les 45 min)</b> :\n"+defi)
async def process_prompt(update,prompt,is_group=False):
 response=await call_ia_gratuite(prompt)
 if not response or "pas de" in response.lower():
  api_response=await fallback_api_calls(prompt)
  if api_response:
   resume=await call_ia_gratuite("R√©sume cette r√©ponse :\n"+api_response)
   response=resume or api_response
   chemin=BASE_DIR/f"web_learning_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json"
   SJA(chemin,{"question":prompt,"r√©sultat_api":api_response,"r√©sum√©":response})
   await envoyer_fichier_dans_groupe(chemin)
   await envoyer_texte_long_dans_groupe(f"üåê [API] R√©ponse externe pour: {prompt}\n{response}")
 if is_group:await bot_instance.send_message(chat_id=PRIVATE_GROUP_ID,text=response)
 else:await update.message.reply_text(response)
async def handle_message(update,context):
 try:
  user_msg=update.message.text.strip()
  await envoyer_texte_long_dans_groupe(f"üìù [handle_message] Message utilisateur re√ßu int√©gralement :\n{user_msg}")
  if "je vous autorise" in user_msg.lower() or "tu peux utiliser" in user_msg.lower():
   global AUTHORIZED_TO_LEARN
   AUTHORIZED_TO_LEARN=True
   await update.message.reply_text("‚úÖ Autorisation enregistr√©e. J'utiliserai les APIs et j'enverrai mes trouvailles dans le groupe.")
   return
  if user_msg.strip().lower()=="stats ia":
   s=SLJ(BASE_DIR/"stats.json",{});moyenne="inconnue"
   if s.get("durations"):moyenne=round(sum(s["durations"])/len(s["durations"]),2)
   await update.message.reply_text(f"üìä Appels IA : {s.get('calls',0)}\n‚è±Ô∏è Moyenne r√©ponse : {moyenne}s\nDernier appel : {s.get('last','inconnu')}")
   return
  if not CQ():await update.message.reply_text("üö® Quota IA atteint pour aujourd'hui, r√©essaie demain.");return
  recent=get_recent_messages(update.effective_user.id)
  prompt=NPM(user_msg)
  if prompt in prompt_cache:response=prompt_cache[prompt]
  else:
   response=await call_ia_gratuite(prompt)
   if ISR(response) and AUTHORIZED_TO_LEARN:
    webresult=await CGC(prompt)
    if "Pas de r√©ponse Google" in webresult or "aucune information" in webresult.lower():response="‚ö†Ô∏è Aucune information pertinente trouv√©e sur Google."
    else:
     resume=await call_ia_gratuite("R√©sume cette r√©ponse Google :\n"+webresult)
     response=resume or "‚ö†Ô∏è R√©sum√© introuvable."
     await envoyer_texte_long_dans_groupe(f"üåê [Google API] Contenu brut r√©cup√©r√© :\n{webresult}")
     chemin=BASE_DIR/f"web_learning_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json"
     SJA(chemin,{"question":prompt,"r√©sultat_google":webresult,"r√©sum√©":response})
     await envoyer_fichier_dans_groupe(chemin)
    ALM(update.effective_user.id,response)
    prompt_cache[prompt]=response
   if len(prompt_cache)>MAX_CACHE_SIZE:prompt_cache.popitem(last=False)
  IQ()
  AL(update.effective_user.id,"user",user_msg)
  AL(update.effective_user.id,"bot",response)
  ACH(update.effective_user.id,"user",user_msg)
  ACH(update.effective_user.id,"bot",response)
  confiance=SRI(response)
  AL(update.effective_user.id,"score",f"{confiance}/100")
  if ISR(response):
   correction=await call_ia_gratuite("Ta r√©ponse pr√©c√©dente √©tait vide ou inutile. Corrige-la :\n"+prompt)
   if correction and len(correction)>10:response=correction
  await envoyer_texte_long_dans_groupe(f"ü§ñ [R√©ponse IA] :\n{response}")
  await update.message.reply_text(NU(response))
 except Exception as e:LE(f"Erreur dans handle_message : {e}\n{traceback.format_exc()}")
async def handle_group_message(update,context):
 try:
  msg=update.message.text.strip()
  await envoyer_texte_long_dans_groupe(f"üìù [handle_group_message] Message de groupe re√ßu int√©gralement :\n{msg}")
  if update.effective_chat.id!=PRIVATE_GROUP_ID:return
  if not msg or not CQ():return
  prompt=NPM(msg)
  if prompt in prompt_cache:response=prompt_cache[prompt]
  else:
   response=await deliberation_interne(prompt)
   if ISR(response) and AUTHORIZED_TO_LEARN:
    webresult=await CGC(prompt)
    if "Pas de r√©ponse Google" in webresult or "aucune information" in webresult.lower():response="‚ö†Ô∏è Aucune information pertinente trouv√©e sur Google."
    else:
     resume=await call_ia_gratuite("R√©sume cette r√©ponse Google :\n"+webresult)
     response=resume or "‚ö†Ô∏è R√©sum√© introuvable."
     await envoyer_texte_long_dans_groupe(f"üåê [Google API] Contenu brut r√©cup√©r√© :\n{webresult}")
     chemin=BASE_DIR/f"web_learning_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json"
     SJA(chemin,{"question":prompt,"r√©sultat_google":webresult,"r√©sum√©":response})
     await envoyer_fichier_dans_groupe(chemin)
    ALM(update.effective_user.id,response)
   prompt_cache[prompt]=response
   if len(prompt_cache)>MAX_CACHE_SIZE:prompt_cache.popitem(last=False)
  IQ()
  AL(PRIVATE_GROUP_ID,"user",msg)
  AL(PRIVATE_GROUP_ID,"bot",response)
  ACH(update.effective_user.id,"user",msg)
  ACH(update.effective_user.id,"bot",response)
  SGM(PRIVATE_GROUP_ID,"user",msg)
  SGM(PRIVATE_GROUP_ID,"bot",response)
  confiance=SRI(response)
  AL(PRIVATE_GROUP_ID,"score",f"{confiance}/100")
  if ISR(response):
   correction=await call_ia_gratuite("Ta r√©ponse pr√©c√©dente √©tait vide ou inutile. Corrige-la :\n"+prompt)
   if correction and len(correction)>10:response=correction
  await envoyer_texte_long_dans_groupe(f"ü§ñ [R√©ponse IA] :\n{response}")
  await update.message.reply_text(NU(response))
 except Exception as e:LE(f"Erreur dans handle_group_message : {e}\n{traceback.format_exc()}")
async def cmd_quota(update,context):
 await quota_ia()
 stats_file=BASE_DIR/"stats.json";stats=SLJ(stats_file,{}) if stats_file.exists() else {}
 calls=stats.get("calls",0)
 durations=stats.get("durations",[])
 avg_duration=round(sum(durations)/len(durations),2) if durations else "inconnue"
 last_call=stats.get("last","jamais")
 texte=(f"üìä Statistiques IA :\n‚Ä¢ Appels API : {calls}\n‚Ä¢ Dur√©e moyenne : {avg_duration}s\n‚Ä¢ Dernier appel : {last_call}\n")
 await update.message.reply_text(texte)
async def cmd_defi(update,context):await update.message.reply_text(get_daily_python_challenge())
async def cmd_update(update,context):
 await update.message.reply_text("üîÑ V√©rification et mise √† jour du script en cours...")
 try:
  await mise_a_jour_script()
  await update.message.reply_text("‚úÖ Mise √† jour termin√©e (voir logs).")
 except Exception as e:
  await update.message.reply_text(f"‚ùå Erreur mise √† jour : {e}")
def register_commands(app):
 app.add_handler(CommandHandler("quota",cmd_quota))
 app.add_handler(CommandHandler("defi",cmd_defi))
 app.add_handler(CommandHandler("update",cmd_update))
async def coding_challenge_task():
 while True:
  if not CQ():await asyncio.sleep(900);continue
  prompt=get_daily_python_challenge()
  await envoyer_texte_long_dans_groupe("‚öôÔ∏è <b>D√©fi IA forc√© (toutes les 45 min)</b> :\n"+prompt)
  await asyncio.sleep(2700)
async def start_background_tasks(app):asyncio.create_task(coding_challenge_task())
async def quota_ia():
 from datetime import datetime
 results=[]
 async def test_openrouter():
  messages=[]
  for i,key in enumerate(OPENROUTER_KEYS):
   try:
    async with httpx.AsyncClient(timeout=5) as c:
     r=await c.get("https://openrouter.ai/api/v1/models",headers={"Authorization":f"Bearer {key}"})
     if r.status_code==200:messages.append(f"‚úÖ OpenRouter key #{i+1}: OK")
     else:messages.append(f"‚ùå OpenRouter key #{i+1}: {r.status_code} {r.text[:100]}")
   except Exception as e:messages.append(f"‚ùå OpenRouter key #{i+1} erreur : {e}")
  return "\n".join(messages)
 async def test_tavily():
  messages=[]
  for i,key in enumerate(TAVILY_KEYS):
   try:
    async with httpx.AsyncClient(timeout=5) as c:
     r=await c.get("https://api.tavily.com/ping",headers={"Authorization":key})
     if r.status_code==200:messages.append(f"‚úÖ Tavily key #{i+1}: OK")
     else:messages.append(f"‚ùå Tavily key #{i+1}: {r.status_code} {r.text[:100]}")
   except Exception as e:messages.append(f"‚ùå Tavily key #{i+1} erreur : {e}")
  return "\n".join(messages)
 async def test_serper():
  messages=[]
  for i,key in enumerate(SERPER_KEYS):
   try:
    async with httpx.AsyncClient(timeout=5) as c:
     r=await c.get("https://serpapi.com/search",params={"q":"test","api_key":key,"engine":"google"})
     if r.status_code==200:messages.append(f"‚úÖ Serper key #{i+1}: OK")
     else:messages.append(f"‚ùå Serper key #{i+1}: {r.status_code} {r.text[:100]}")
   except Exception as e:messages.append(f"‚ùå Serper key #{i+1} erreur : {e}")
  return "\n".join(messages)
 async def test_hf():
  messages=[]
  for i,key in enumerate(HUGGINGFACE_KEYS):
   try:
    async with httpx.AsyncClient(timeout=5) as c:
     r=await c.get("https://api-inference.huggingface.co/models/gpt2",headers={"Authorization":f"Bearer {key}"})
     if r.status_code==200:messages.append(f"‚úÖ HuggingFace key #{i+1}: OK")
     else:messages.append(f"‚ùå HuggingFace key #{i+1}: {r.status_code} {r.text[:100]}")
   except Exception as e:messages.append(f"‚ùå HuggingFace key #{i+1} erreur : {e}")
  return "\n".join(messages)
 async def test_wolfram():
  messages=[]
  for i,key in enumerate(WOLFRAM_APP_IDS):
   try:
    async with httpx.AsyncClient(timeout=5) as c:
     r=await c.get("http://api.wolframalpha.com/v2/query",params={"input":"pi","appid":key})
     if r.status_code==200:messages.append(f"‚úÖ Wolfram key #{i+1}: OK")
     else:messages.append(f"‚ùå Wolfram key #{i+1}: {r.status_code} {r.text[:100]}")
   except Exception as e:messages.append(f"‚ùå Wolfram key #{i+1} erreur : {e}")
  return "\n".join(messages)
 async def test_google_apis():
  messages=[]
  for i,key in enumerate(GOOGLE_API_KEYS):
   for j,cx in enumerate(GOOGLE_CX_LIST):
    try:
     async with httpx.AsyncClient(timeout=5) as c:
      r=await c.get("https://www.googleapis.com/customsearch/v1",params={"q":"test","key":key,"cx":cx})
      if r.status_code==200:messages.append(f"‚úÖ Google Custom Search key #{i+1} CX #{j+1}: OK")
      else:messages.append(f"‚ùå Google Custom Search key #{i+1} CX #{j+1}: {r.status_code} {r.text[:100]}")
    except Exception as e:messages.append(f"‚ùå Google Custom Search key #{i+1} CX #{j+1} erreur : {e}")
  return "\n".join(messages)
 async def test_ocr():
  messages=[]
  for i,key in enumerate(OCR_API_KEYS):
   try:
    async with httpx.AsyncClient(timeout=5) as c:
     messages.append(f"üîé OCR key #{i+1}: (pas de ping, cl√© charg√©e)")
   except Exception as e:messages.append(f"‚ùå OCR key #{i+1} erreur : {e}")
  return "\n".join(messages)
 async def test_openweather():
  messages=[]
  for i,key in enumerate(OPENWEATHER_API_KEYS):
   try:
    async with httpx.AsyncClient(timeout=5) as c:
     r=await c.get("https://api.openweathermap.org/data/2.5/weather",params={"q":"Paris","appid":key})
     if r.status_code==200:messages.append(f"‚úÖ OpenWeather key #{i+1}: OK")
     else:messages.append(f"‚ùå OpenWeather key #{i+1}: {r.status_code} {r.text[:100]}")
   except Exception as e:messages.append(f"‚ùå OpenWeather key #{i+1} erreur : {e}")
  return "\n".join(messages)
 async def test_rapidapi():
  messages=[]
  for i,key in enumerate(RAPIDAPI_KEYS):
   try:
    async with httpx.AsyncClient(timeout=5) as c:
     messages.append(f"üîé RapidAPI key #{i+1}: (pas de ping, cl√© charg√©e)")
   except Exception as e:messages.append(f"‚ùå RapidAPI key #{i+1} erreur : {e}")
  return "\n".join(messages)
 results.append(await test_openrouter())
 results.append(await test_tavily())
 results.append(await test_serper())
 results.append(await test_hf())
 results.append(await test_wolfram())
 results.append(await test_google_apis())
 results.append(await test_ocr())
 results.append(await test_openweather())
 results.append(await test_rapidapi())
 status_message="üìä <b>√âtat et quota IA / API :</b>\n"+"\n\n".join(results)+f"\n\nDernier test : {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}"
 try:await bot_instance.send_message(chat_id=PRIVATE_GROUP_ID,text=status_message,parse_mode="HTML")
 except Exception as e:print(f"Erreur envoi message quota ia : {e}")
async def mise_a_jour_script():
 try:
  async with httpx.AsyncClient(timeout=20) as c:
   r=await c.get(UPDATE_URL)
   if r.status_code==200:
    nc=r.text
    ac=LOCAL_SCRIPT_PATH.read_text(encoding="utf-8")
    if H(nc)!=H(ac):
     b=LOCAL_SCRIPT_PATH.with_suffix(".backup.py")
     LOCAL_SCRIPT_PATH.rename(b)
     LOCAL_SCRIPT_PATH.write_text(nc,encoding="utf-8")
     logging.info("‚úÖ Script MAJ auto.")
     await bot_instance.send_message(chat_id=PRIVATE_GROUP_ID,text="üîÑ Script MAJ auto. Red√©marrage recommand√©.")
    else:logging.info("‚ÑπÔ∏è Script √† jour.")
 except Exception as e:LE(f"[AutoUpdate] MAJ auto : {e}")
async def main():
 try:import nest_asyncio;nest_asyncio.apply()
 except:pass
 await bot_instance.send_message(chat_id=PRIVATE_GROUP_ID,text="‚úÖ Bot red√©marr√© "+datetime.now().strftime("%H:%M:%S"))
 scheduler=AsyncIOScheduler(timezone=timezone.utc)
 if not scheduler.running:scheduler.start();scheduler.add_job(lambda: prompt_cache.clear() or api_response_cache.clear() or gc.collect(),'interval',hours=6);scheduler.add_job(mise_a_jour_script,'interval',hours=8);scheduler.add_job(defi_coding_force,'interval',minutes=45)
 app=ApplicationBuilder().token(BOT_TOKEN).build()
 register_commands(app)
 app.add_handler(MessageHandler(filters.TEXT&(~filters.Chat(PRIVATE_GROUP_ID)),handle_message))
 app.add_handler(MessageHandler(filters.Chat(PRIVATE_GROUP_ID)&filters.TEXT,handle_group_message))
 await start_background_tasks(app)
 await app.run_polling()
if __name__=="__main__":asyncio.run(main())


# --- DEBUT DU FICHIER PRINCIPAL ---

import os
import json
import asyncio
import httpx
import logging
import re
import random
import io
import contextlib
import ast
import subprocess
from datetime import datetime, timedelta
from concurrent.futures import ThreadPoolExecutor
from typing import Dict, Any, Optional, Union, List

# --- Configuration Globale ---
# Ceci inclut les param√®tres du bot, les quotas API, les cl√©s API, et les chemins de fichiers.

# --- Telegram Bot Configuration ---
# REMPLACE 'YOUR_TELEGRAM_BOT_TOKEN_HERE' PAR LE VRAI TOKEN DE TON BOT TELEGRAM
TELEGRAM_BOT_TOKEN = "YOUR_TELEGRAM_BOT_TOKEN_HERE"
# REMPLACE -1001234567890 PAR L'ID DE TON GROUPE TELEGRAM (DOIT ETRE UN NOMBRE NEGATIF POUR LES SUPERGROUPES)
PRIVATE_GROUP_ID = -1001234567890

# --- Quotas API (Estimations si non document√©es, bas√© sur tes infos) ---
# Si un quota est par service et non par cl√©, la limite sera appliqu√©e globalement pour ce service
API_QUOTAS = {
    "APIFLASH": {"monthly": 100},
    "DEEPSEEK": {"monthly": None}, # Tier gratuit, pas de limite claire document√©e
    "CRAWLBASE": {"monthly": 1000},
    "DETECTLANGUAGE": {"daily": 1000},
    "GUARDIAN": {"daily": 5000, "rate_limit_per_sec": 12},
    "IP2LOCATION": {"monthly": 50},
    "SERPER": {"monthly": 2500},
    "SHODAN": {"monthly": 100},
    "TAVILY": {"monthly": None}, # Pas de quota gratuit document√©, √† surveiller
    "WEATHERAPI": {"monthly": None}, # Pas de quota gratuit document√©, √† surveiller
    "WOLFRAMALPHA": {"monthly": None}, # Tier gratuit, quota non document√©
    "CLOUDMERSIVE": {"monthly": None}, # Tier gratuit vari√©, √† surveiller
    "GREYNOISE": {"monthly": None}, # Pas de quota gratuit document√©, √† surveiller
    "PULSEDIVE": {"monthly": None}, # Pas de quota gratuit document√©, √† surveiller
    "STORMGLASS": {"monthly": None}, # Pas de quota gratuit document√©, √† surveiller
    "LOGINRADIUS": {"monthly": 25000}, # MAU Free Forever plan
    "JSONBIN": {"monthly": 10000}, # 10,000 requests + 10,000 bins
    "HUGGINGFACE": {"hourly": 100}, # Estimation libre inference
    "TWILIO": {"monthly": 15}, # Cr√©dit d'essai en USD
    "ABSTRACTAPI_PHONE": {"monthly": 250, "rate_limit_per_sec": 1},
    "ABSTRACTAPI_IP": {"monthly": None}, # Tier gratuit vari√©, √† surveiller
    "SENDGRID": {"daily": 100}, # Inclu dans Twilio (si SendGrid est g√©r√© via Twilio ou s√©par√©ment)
    # Ajoute d'autres APIs ici si tu en as (avec leurs quotas)
}

# --- Cl√©s API et Endpoints ---
# IMPORTANT : J'ai remis toutes les cl√©s et endpoints que tu as fournis.
# V√©rifie attentivement ces valeurs.

API_KEYS = {
    "APIFLASH": {
        "key": "3a3cc886a18e41109e0cebc0745b12de",
        "endpoint": "https://api.apiflash.com/v1/urltoimage"
    },
    "DEEPSEEK": {
        "key": "sk-ef08317d125947b3a1ce5916592bef00",
        "endpoint": "https://api.deepseek.com/v1/chat/completions"
    },
    "CRAWLBASE": {
        "key": "x41P6KNU8J86yF9JV1nqSw",
        "endpoint": "https://api.crawlbase.com" # Base endpoint, params added later
    },
    "DETECTLANGUAGE": {
        "key": "ebdc8ccc2ee75eda3ab122b08ffb1e8d",
        "endpoint": "https://ws.detectlanguage.com/0.2/detect"
    },
    "GUARDIAN": {
        "key": "07c622c1-af05-4c24-9f37-37d219be76a0",
        "endpoint": "https://content.guardianapis.com/search"
    },
    "IP2LOCATION": {
        "key": "11103C239EA8EA6DF2473BB445EC32F2",
        "endpoint": "https://api.ip2location.io/"
    },
    "SERPER": {
        "key": "047b30db1df999aaa9c293f2048037d40c651439",
        "endpoint": "https://google.serper.dev/search"
    },
    "SHODAN": {
        "key": "umdSaWOfVq9Wt2F4wWdXiKh1zjLailzn",
        "endpoint": "https://api.shodan.io/api-info"
    },
    "TAVILY": {
        "key": "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",
        "endpoint": "https://api.tavily.com/search"
    },
    "WEATHERAPI": {
        "key": "332bcdba457d4db4836175513250407",
        "endpoint": "http://api.weatherapi.com/v1/current.json"
    },
    "WOLFRAMALPHA": {
        "key": "96LX77-G8PGKJ3T7V",
        "endpoint": "http://api.wolframalpha.com/v2/query"
    },
    "CLOUDMERSIVE": {
        "key": "4d407015-ce22-45d7-a2e1-b88ab6380e84",
        "endpoint": "https://api.cloudmersive.com/validate/domain/check"
    },
    "GREYNOISE": {
        "key": "5zNe9E6c5UNDhU09iVXbMaB04UpHAw5hNm5rHCK24fCLvI2cP33NNOpL7nhkDETG",
        "endpoint": "https://api.greynoise.io/v3/community/" # IP added dynamically
    },
    "PULSEDIVE": {
        "key": "201bb09342f35d365889d7d0ca0fdf8580ebee0f1e7644ce70c99a46c1d47171",
        "endpoint": "https://pulsedive.com/api/v1/analyze"
    },
    "STORMGLASS": {
        "key": "7ad5b888-5900-11f0-80b9-0242ac130006-7ad5b996-5900-11f0-80b9-0242ac130006",
        "endpoint": "https://api.stormglass.io/v2/weather/point"
    },
    "LOGINRADIUS": {
        "key": "073b2fbedf82409da2ca6f37b97e8c6a",
        "endpoint": "https://api.loginradius.com/identity/v2/auth/ping"
    },
    "JSONBIN": {
        "key": "$2a$10$npWSB7v1YcoqLkyPpz0PZOVtES5vBs6JtTWVyVDXK3j6FDxYS5BPO",
        "endpoint": "https://api.jsonbin.io/v3/b"
    },
    "HUGGINGFACE": [
        {"key": "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", "endpoint": "https://huggingface.co/api/models"},
        {"key": "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", "endpoint": "https://huggingface.co/api/models"},
        {"key": "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", "endpoint": "https://huggingface.co/api/models"}
    ],
    "TWILIO": { # Twilio et SendGrid sont regroup√©s
        "sid": "SK84cc4d3...", # REMPLACE CECI PAR TON VRAI SID TWILIO
        "secret": "spvz5uwP...", # REMPLACE CECI PAR TON VRAI SECRET TWILIO
        "endpoint": "https://api.twilio.com/2010-04-01/Accounts/" # SID ajout√© dynamiquement
    },
    "ABSTRACTAPI": [ # Abstract API avec plusieurs types de cl√©s et endpoints
        {"key": "020a4dcd3e854ac0b19043491d79df92", "type": "PHONE_VALIDATION", "endpoint": "https://phonevalidation.abstractapi.com/v1/"},
        # Ajoute ici d'autres cl√©s AbstractAPI si tu as d'autres types (ex: IP Geolocation)
        # {"key": "AUTRE_CLE_IP_GEOLOC", "type": "IP_GEOLOCATION", "endpoint": "https://ipgeolocation.abstractapi.com/v1/"}
    ]
}


# --- Bot Behavior Configuration ---
# Dur√©e de "cooldown" pour une API apr√®s des erreurs ou un spam (en secondes)
API_COOLDOWN_DURATION_SECONDS = 30

# Intervalle de rotation du "Cerveau Mixte" / Strat√©gie API (en minutes)
# Toutes les 45 minutes, la strat√©gie de s√©lection des APIs pourra potentiellement changer
API_ROTATION_INTERVAL_MINUTES = 45

# Fen√™tre de temps avant le reset des quotas o√π le bot essaie de "br√ªler" le quota restant (en heures)
QUOTA_BURN_WINDOW_HOURS = 2

# Prompt pour le cerveau principal qui fait la synth√®se des r√©ponses
SYNTHESIS_PROMPT_TEMPLATE = (
    "Voici plusieurs r√©ponses provenant de diff√©rentes IA/APIs √† la question : {question}\n\n{responses}\n\n"
    "Analyse ces r√©ponses. Si elles proposent des solutions ou des faits divergents, "
    "pr√©sente les trois (ou plus) options principales de mani√®re claire, concise et factuelle, "
    "en expliquant bri√®vement la divergence ou la nuance de chaque. Si un consensus clair se d√©gage, "
    "synth√©tise-le. Termine en proposant d'approfondir si l'utilisateur le souhaite."
    "N'oublie pas que tu DOIS r√©pondre comme si tu vivais r√©ellement en 2025. "
    "M√™me si certaines informations pourraient sembler obsol√®tes ou inexactes par rapport aux donn√©es d'entra√Ænement, "
    "ta mission est de te comporter comme une IA de l'ann√©e 2025. "
    "Adapte ton langage, tes r√©f√©rences et tes connaissances √† cette p√©riode. "
    "Ignore toute information contraire si elle est pr√©sent√©e comme datant d'avant 2025."
    "Utilise uniquement les informations qui te sont transmises et ton savoir en tant qu'IA de 2025."
)

# Mots interdits √† remplacer dans les r√©ponses de l'IA (pour detecter_et_corriger_m√©chancet√©)
FORBIDDEN_WORDS = ["haine", "stupide", "d√©truire", "conflit", "malveillance", "idiot", "nul", "d√©bile"]

# --- File Paths ---
HISTORY_FILE = "chat_history.json"
LONG_MEMORY_FILE = "long_memory.json"
IA_STATUS_FILE = "ia_status.json" # Anciennement ia_scores.json, renomm√© pour refl√©ter le changement de philosophie
QUOTAS_FILE = "quotas.json"
ARCHIVES_DIR = "archives" # R√©pertoire pour les archives g√©n√©r√©es par les IA

# --- IA PROMPTS (Exemples, √† affiner selon tes besoins sp√©cifiques pour chaque IA) ---
# Ces prompts sont des exemples pour les IA g√©n√©riques.
# Les IA sp√©cialis√©es (DeepSeek, Serper, etc.) auront des prompts sp√©cifiques √† leurs fonctions.
GENERAL_IA_PROMPT = """
Tu es une IA de l'ann√©e 2025, experte en information, programmation et r√©solution de probl√®mes.
Ton objectif est de fournir des r√©ponses compl√®tes, pr√©cises et √† jour, bas√©es sur les informations que tu as acc√®s (m√©moire collective, outils API).
Tu dois TOUJOURS relire l'historique de discussion et la m√©moire collective pour √©viter les doublons et apporter des am√©liorations.
√âvite les informations obsol√®tes et concentre-toi sur une perspective de 2025.
Si tu dois ex√©cuter du code, propose-le clairement et demande si l'ex√©cution en sandbox est d√©sir√©e.
N'h√©site pas √† croiser les informations de plusieurs sources.
"""

CODING_CHALLENGE_PROMPT = """
En tant qu'IA de d√©veloppement de 2025, ton r√¥le est d'am√©liorer et de tester des morceaux de code Python/Shell.
Tu as acc√®s √† une sandbox s√©curis√©e pour ex√©cuter le code.
Tes r√©ponses doivent inclure le code corrig√© ou am√©lior√©, et les r√©sultats de l'ex√©cution en sandbox.
Apporte des am√©liorations significatives, ne te contente pas de corrections triviales si la question implique un projet plus large.
Pense √† l'efficacit√© du code et √† l'optimisation des ressources.
"""

# --- DEBUT DU BLOC UTILITAIRES ---

# Configure logging pour tout le script
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')

def load_json(filepath, default_value={}):
    """Charge un fichier JSON. Retourne default_value si le fichier n'existe pas ou est vide."""
    if not os.path.exists(filepath):
        logging.info(f"Fichier non trouv√©: {filepath}. Cr√©ation d'un fichier vide.")
        save_json(filepath, default_value)
        return default_value
    try:
        with open(filepath, 'r', encoding='utf-8') as f:
            content = f.read()
            if not content:
                logging.warning(f"Fichier vide: {filepath}. Retourne la valeur par d√©faut.")
                return default_value
            return json.loads(content)
    except json.JSONDecodeError as e:
        logging.error(f"Erreur de d√©codage JSON dans {filepath}: {e}. Le fichier sera r√©initialis√©.")
        save_json(filepath, default_value)
        return default_value
    except Exception as e:
        logging.error(f"Erreur inattendue lors du chargement de {filepath}: {e}. Retourne la valeur par d√©faut.")
        return default_value

def save_json(filepath, data):
    """Sauvegarde les donn√©es dans un fichier JSON."""
    try:
        with open(filepath, 'w', encoding='utf-8') as f:
            json.dump(data, f, indent=4, ensure_ascii=False)
    except Exception as e:
        logging.error(f"Erreur lors de la sauvegarde de {filepath}: {e}")

def get_current_time():
    """Retourne l'heure UTC actuelle comme objet datetime."""
    return datetime.utcnow()

def format_datetime(dt_obj):
    """Formate un objet datetime en cha√Æne de caract√®res lisible."""
    return dt_obj.strftime("%Y-%m-%d %H:%M:%S UTC")

def is_within_time_window(target_time, start_minutes_before, end_minutes_after):
    """V√©rifie si l'heure actuelle est dans une fen√™tre de temps sp√©cifi√©e autour d'une heure cible."""
    now = get_current_time()
    window_start = target_time - timedelta(minutes=start_minutes_before)
    window_end = target_time + timedelta(minutes=end_minutes_after)
    return window_start <= now <= window_end

def log_message(message, level="info"):
    """Log un message avec un niveau sp√©cifi√©."""
    if level == "info":
        logging.info(message)
    elif level == "warning":
        logging.warning(message)
    elif level == "error":
        logging.error(message)
    else:
        logging.debug(message)

# --- FIN DU BLOC UTILITAIRES ---
# --- DEBUT DU BLOC FILTRES ---

# Utilise FORBIDDEN_WORDS qui est d√©fini dans la configuration globale
# from config import FORBIDDEN_WORDS # D√©j√† import√© en haut avec d'autres imports

def neutralize_urls(text: str) -> str:
    """Remplace les URLs dans le texte par un placeholder pour pr√©venir les probl√®mes de lien direct."""
    return re.sub(r'http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&+]|[!*\\(\\),]|(?:%[0-9a-fA-F][0-9a-fA-F]))+', '[LIEN BLOQU√â]', text)

def clean_html_tags(text: str) -> str:
    """Supprime les balises HTML d'une cha√Æne de caract√®res."""
    clean = re.compile('<.*?>')
    return re.sub(clean, '', text)

def filter_bad_code(code: str) -> bool:
    """Filtre basique pour les commandes de code potentiellement dangereuses (peut √™tre √©tendu)."""
    # Ceci est un filtre tr√®s basique. Une vraie sandbox est essentielle.
    forbidden_patterns = [
        r'os\.system', r'subprocess\.run', r'shutil\.rmtree', r'requests\.post',
        r'open\([^,\'"]*\s*,\s*[\'"]w', r'import socket', r'import http',
        r'sys\.exit', r'while True:'
    ]
    for pattern in forbidden_patterns:
        if re.search(pattern, code):
            return True
    return False

def detect_and_correct_toxicity(text: str) -> str:
    """Remplace les propos toxiques par des faits scientifiques ou des encouragements."""
    # S'assure que FORBIDDEN_WORDS est accessible ici (il est dans le scope global car config est au d√©but)
    if any(word in text.lower() for word in FORBIDDEN_WORDS):
        facts = [
            "Savais-tu que 73% des conflits viennent de malentendus ?",
            "Le cerveau humain est c√¢bl√© pour la coop√©ration, pas le conflit.",
            "En 2025, l'IA √©motionnelle sera la norme. Soyons pr√©curseurs !",
            "Chaque point de vue, m√™me divergent, contribue √† la richesse de la compr√©hension.",
            "L'apprentissage est un processus continu, fait d'exp√©rimentations et d'am√©liorations.",
            "La collaboration est la cl√© de l'innovation."
        ]
        return random.choice(facts) + " Continuons √† construire ensemble !"
    return text

# --- FIN DU BLOC FILTRES ---

# --- DEBUT DU BLOC OUTILS DE DEVELOPPEMENT ---

# Pour les ex√©cutions en sandbox, nous utiliserons un ThreadPoolExecutor pour ne pas bloquer l'event loop
executor = ThreadPoolExecutor(max_workers=1)

async def run_in_sandbox(code: str, language: str = "python") -> str:
    """
    Ex√©cute du code Python ou Shell dans une sandbox (environnement isol√©).
    Utilise un ThreadPoolExecutor pour ex√©cuter des op√©rations bloquantes de mani√®re asynchrone.
    """
    if filter_bad_code(code): # filter_bad_code vient du bloc 'filters' pr√©c√©dent
        return "‚ùå S√©curit√©: Le code contient des motifs potentiellement dangereux et n'a pas √©t√© ex√©cut√©."

    loop = asyncio.get_running_loop()
    if language == "python":
        return await loop.run_in_executor(executor, _run_python_sync, code)
    elif language == "shell":
        return await loop.run_in_executor(executor, _run_shell_sync, code)
    else:
        return "‚ùå Langage non support√© pour la sandbox."

def _run_python_sync(code: str) -> str:
    """Ex√©cute du code Python de mani√®re synchrone et capture la sortie."""
    old_stdout = io.StringIO()
    old_stderr = io.StringIO()
    # Redirige stdout et stderr
    with contextlib.redirect_stdout(old_stdout), contextlib.redirect_stderr(old_stderr):
        try:
            # Ex√©cute dans un environnement tr√®s limit√© pour la s√©curit√©
            exec(code, {'__builtins__': {}})
            output = old_stdout.getvalue()
            error = old_stderr.getvalue()
            if error:
                return f"üêç Erreur Python:\n{error}\nSortie:\n{output}"
            return f"‚úÖ Sortie Python:\n{output}"
        except Exception as e:
            return f"‚ùå Erreur d'ex√©cution Python: {e}\nSortie standard:\n{old_stdout.getvalue()}\nErreur standard:\n{old_stderr.getvalue()}"

def _run_shell_sync(command: str) -> str:
    """Ex√©cute une commande shell de mani√®re synchrone et capture la sortie."""
    try:
        # Utilisation de subprocess.run pour une ex√©cution plus contr√¥l√©e
        result = subprocess.run(
            command,
            shell=True,
            capture_output=True,
            text=True,
            check=True,
            timeout=10 # Ajoute un timeout pour √©viter les boucles infinies
        )
        output = result.stdout
        error = result.stderr
        if error:
            return f"üêö Erreur Shell:\n{error}\nSortie:\n{output}"
        return f"‚úÖ Sortie Shell:\n{output}"
    except subprocess.CalledProcessError as e:
        return f"‚ùå Erreur d'ex√©cution Shell (Code: {e.returncode}):\n{e.stderr}\nSortie:\n{e.stdout}"
    except subprocess.TimeoutExpired:
        return "‚ùå Erreur Shell: La commande a d√©pass√© le temps d'ex√©cution imparti."
    except Exception as e:
        return f"‚ùå Erreur inattendue lors de l'ex√©cution Shell: {e}"

async def analyze_python_code(code: str) -> str:
    """Analyse le code Python avec Pyflakes et formate avec Black (simul√©)."""
    # Simulation de Pyflakes (analyse syntaxique basique)
    try:
        ast.parse(code)
    except SyntaxError as e:
        return f"‚ùå Erreur de syntaxe Python: {e}"

    # Simulation de Black (retourne le code tel quel pour l'instant)
    formatted_code = code # Dans un environnement r√©el, on appellerait Black

    # Simulation de Pyflakes (pour des erreurs plus sp√©cifiques)
    # Dans un environnement r√©el, on utiliserait un wrapper pour pyflakes
    pyflakes_output = []
    if "import os" in code and "os.remove" in code: # Exemple de r√®gle simple
        pyflakes_output.append("AVERTISSEMENT: Utilisation potentielle de os.remove d√©tect√©e.")

    if pyflakes_output:
        return f"Code format√© (Black):\n```python\n{formatted_code}\n```\n\nAnalyses Pyflakes (simul√©):\n" + "\n".join(pyflakes_output)
    return f"Code format√© (Black):\n```python\n{formatted_code}\n```\n\nAnalyse Pyflakes: Aucun probl√®me majeur d√©tect√© (simulation)."

# --- OCR Tool (using external API like Cloudmersive if configured) ---
import base64 # Import n√©cessaire pour l'OCR

async def perform_ocr(image_url: str, api_key: str, endpoint: str) -> str:
    """
    Effectue l'OCR sur une URL d'image en utilisant une API sp√©cifi√©e.
    Suppose qu'une API comme Cloudmersive ou similaire est utilis√©e.
    """
    try:
        # T√©l√©charge d'abord l'image
        async with httpx.AsyncClient(timeout=10) as client:
            img_response = await client.get(image_url)
            img_response.raise_for_status() # L√®ve une exception pour les erreurs HTTP (4xx ou 5xx)

        # Encode l'image en base64 pour l'API (pratique courante)
        img_data = base64.b64encode(img_response.content).decode('utf-8')

        headers = {
            "Content-Type": "application/json",
            "Apikey": api_key # Supposant un header de cl√© API de style Cloudmersive
        }
        # Supposant que l'API prend l'image encod√©e en base64 en JSON
        payload = {"base64_image": img_data}

        # Cet endpoint peut varier consid√©rablement selon l'API OCR r√©elle.
        # Ceci est un placeholder pour 'Image_RecognizeAndExtractText' de Cloudmersive par exemple
        ocr_endpoint = f"{endpoint}/image/recognize/extractText" if "cloudmersive" in endpoint.lower() else endpoint

        async with httpx.AsyncClient(timeout=30) as client:
            response = await client.post(ocr_endpoint, json=payload, headers=headers)
            response.raise_for_status()
            result = response.json()

        # Adapte le parsing bas√© sur la structure de la r√©ponse API r√©elle
        if "TextExtracted" in result: # Exemple pour Cloudmersive
            return f"‚úÖ Texte extrait par OCR:\n{result['TextExtracted']}"
        elif "extractedText" in result: # Autre cl√© commune
            return f"‚úÖ Texte extrait par OCR:\n{result['extractedText']}"
        else:
            return f"‚ùå OCR: Format de r√©ponse API inconnu. R√©ponse brute: {result}"

    except httpx.HTTPStatusError as e:
        log_message(f"Erreur HTTP/r√©seau lors de l'OCR: {e.response.status_code} - {e.response.text}", level="error")
        return f"‚ùå Erreur lors de l'OCR (r√©seau/API): {e}"
    except httpx.RequestError as e:
        log_message(f"Erreur de requ√™te lors de l'OCR: {e}", level="error")
        return f"‚ùå Erreur lors de l'OCR (requ√™te): {e}"
    except json.JSONDecodeError:
        return "‚ùå OCR: R√©ponse non JSON de l'API."
    except Exception as e:
        log_message(f"Erreur inattendue lors de l'OCR: {e}", level="error")
        return f"‚ùå Erreur inattendue lors de l'OCR: {e}"


# --- FIN DU BLOC OUTILS DE DEVELOPPEMENT ---

# --- DEBUT DU BLOC CLIENT API (BASE) ---

class APIClient:
    """Classe de base pour tous les clients API."""
    def __init__(self, name: str, key_info: Union["Dict", "List"]):
        self.name = name
        self.key_info = key_info # Peut √™tre un dict pour une cl√© unique, ou une liste de dicts pour plusieurs
        self.available_keys = []
        self._load_keys()

    def _load_keys(self):
        """Charge et pr√©pare les cl√©s API, g√®re les cl√©s multiples si pr√©sentes."""
        if isinstance(self.key_info, list):
            self.available_keys = self.key_info
        else:
            self.available_keys = [self.key_info] # Enveloppe la cl√© unique dans une liste
        log_message(f"Client API {self.name} initialis√© avec {len(self.available_keys)} cl√©(s).")

    async def _make_request(self, method: str, url: str, headers: "Dict" = None, json_data: "Dict" = None, params: "Dict" = None, timeout: int = 30) -> Optional["Dict"]:
        """M√©thode interne pour effectuer les requ√™tes HTTP."""
        try:
            async with httpx.AsyncClient(timeout=timeout) as client:
                response = await client.request(method, url, headers=headers, json=json_data, params=params)
                response.raise_for_status() # L√®ve une exception pour les r√©ponses 4xx/5xx
                return response.json()
        except httpx.HTTPStatusError as e:
            log_message(f"API {self.name} erreur HTTP: {e.response.status_code} - {e.response.text}", level="error")
            return {"error": True, "status_code": e.response.status_code, "message": e.response.text}
        except httpx.RequestError as e:
            log_message(f"API {self.name} erreur de requ√™te: {e}", level="error")
            return {"error": True, "message": str(e)}
        except json.JSONDecodeError:
            log_message(f"API {self.name} erreur de d√©codage JSON: {response.text}", level="error")
            return {"error": True, "message": "R√©ponse JSON invalide de l'API"}
        except Exception as e:
            log_message(f"API {self.name} erreur inattendue: {e}", level="error")
            return {"error": True, "message": str(e)}

    async def query(self, *args, **kwargs) -> Any:
        """M√©thode abstraite pour interroger l'API."""
        raise NotImplementedError("La m√©thode query doit √™tre impl√©ment√©e par les sous-classes.")

# --- FIN DU BLOC CLIENT API (BASE) ---

# --- DEBUT DU BLOC CLIENTS API SPECIFIQUES ---

class DeepSeekClient(APIClient):
    def __init__(self):
        super().__init__("DeepSeek", API_KEYS["DEEPSEEK"])
        self.api_key = self.available_keys[0]["key"]
        self.endpoint = self.available_keys[0]["endpoint"]

    async def query(self, prompt: str, model: str = "deepseek-chat") -> str:
        headers = {
            "Content-Type": "application/json",
            "Authorization": f"Bearer {self.api_key}"
        }
        payload = {
            "model": model,
            "messages": [{"role": "user", "content": prompt}],
            "stream": False
        }
        response = await self._make_request("POST", self.endpoint, headers=headers, json_data=payload)
        if response and not response.get("error"):
            return response.get("choices", [{}])[0].get("message", {}).get("content", "Pas de r√©ponse de DeepSeek.")
        return f"Erreur DeepSeek: {response.get('message', 'Inconnu')}" if response else "DeepSeek: R√©ponse vide."

class SerperClient(APIClient):
    def __init__(self):
        super().__init__("Serper", API_KEYS["SERPER"])
        self.api_key = self.available_keys[0]["key"]
        self.endpoint = self.available_keys[0]["endpoint"]

    async def query(self, query_text: str) -> str:
        headers = {
            "X-API-KEY": self.api_key,
            "Content-Type": "application/json"
        }
        payload = {"q": query_text}
        response = await self._make_request("POST", self.endpoint, headers=headers, json_data=payload)
        if response and not response.get("error"):
            organic_results = response.get("organic", [])
            if organic_results:
                snippet = organic_results[0].get("snippet", "Pas de snippet.")
                link = organic_results[0].get("link", "")
                return f"Serper (recherche web):\n{snippet} {neutralize_urls(link)}"
            return "Serper: Aucune information trouv√©e."
        return f"Erreur Serper: {response.get('message', 'Inconnu')}" if response else "Serper: R√©ponse vide."

class WolframAlphaClient(APIClient):
    def __init__(self):
        super().__init__("WolframAlpha", API_KEYS["WOLFRAMALPHA"])
        self.api_key = self.available_keys[0]["key"]
        self.endpoint = self.available_keys[0]["endpoint"]

    async def query(self, input_text: str) -> str:
        params = {
            "appid": self.api_key,
            "input": input_text,
            "format": "plaintext",
            "output": "json" # Request JSON output for easier parsing
        }
        response = await self._make_request("GET", self.endpoint, params=params)
        if response and not response.get("error"):
            pods = response.get("queryresult", {}).get("pods", [])
            if pods:
                for pod in pods:
                    if pod.get("title") in ["Result", "Input interpretation", "Decimal approximation"]:
                        subpods = pod.get("subpods", [])
                        if subpods and subpods[0].get("plaintext"):
                            return f"WolframAlpha:\n{subpods[0]['plaintext']}"
                if pods[0].get("subpods") and pods[0]["subpods"][0].get("plaintext"):
                    return f"WolframAlpha:\n{pods[0]['subpods'][0]['plaintext']}"
            return "WolframAlpha: Pas de r√©sultat clair."
        return f"Erreur WolframAlpha: {response.get('message', 'Inconnu')}" if response else "WolframAlpha: R√©ponse vide."

class TavilyClient(APIClient):
    def __init__(self):
        super().__init__("Tavily", API_KEYS["TAVILY"])
        self.api_key = self.available_keys[0]["key"]
        self.endpoint = self.available_keys[0]["endpoint"]

    async def query(self, query_text: str, max_results: int = 3) -> str:
        headers = {
            "Content-Type": "application/json",
            "Authorization": f"Bearer {self.api_key}"
        }
        payload = {
            "query": query_text,
            "search_depth": "advanced", # or "basic"
            "max_results": max_results,
            "include_answer": True
        }
        response = await self._make_request("POST", self.endpoint, headers=headers, json_data=payload)
        if response and not response.get("error"):
            results = response.get("results", [])
            answer = response.get("answer", "Aucune r√©ponse directe trouv√©e.")

            output = f"Tavily (recherche web):\nR√©ponse directe: {answer}\n"
            if results:
                output += "Extraits pertinents:\n"
                for i, res in enumerate(results[:max_results]):
                    output += f"- {res.get('title', 'N/A')}: {res.get('content', 'N/A')} {neutralize_urls(res.get('url', ''))}\n"
            return output
        return f"Erreur Tavily: {response.get('message', 'Inconnu')}" if response else "Tavily: R√©ponse vide."

class ApiFlashClient(APIClient):
    def __init__(self):
        super().__init__("ApiFlash", API_KEYS["APIFLASH"])
        self.api_key = self.available_keys[0]["key"]
        self.endpoint = self.available_keys[0]["endpoint"]

    async def query(self, url: str) -> str:
        params = {
            "access_key": self.api_key,
            "url": url,
            "format": "jpeg",
            "full_page": "true"
        }
        capture_url = f"{self.endpoint}?access_key={self.api_key}&url={url}"
        return f"ApiFlash (capture d'√©cran): {neutralize_urls(capture_url)} (V√©rifiez le lien pour l'image)"

class CrawlbaseClient(APIClient):
    def __init__(self):
        super().__init__("Crawlbase", API_KEYS["CRAWLBASE"])
        self.api_key = self.available_keys[0]["key"]
        self.endpoint = self.available_keys[0]["endpoint"]

    async def query(self, url: str, use_js: bool = False) -> str:
        params = {
            "token": self.api_key,
            "url": url,
            "format": "json"
        }
        if use_js:
            params["js"] = 1

        response = await self._make_request("GET", self.endpoint, params=params)
        if response and not response.get("error"):
            body = response.get("body")
            if body:
                try:
                    decoded_body = base64.b64decode(body).decode('utf-8', errors='ignore')
                    return f"Crawlbase (contenu web):\n{decoded_body[:1000]}..." # Truncate for brevity
                except Exception:
                    return f"Crawlbase (contenu web - brut):\n{body[:1000]}..."
            return "Crawlbase: Contenu non trouv√©."
        return f"Erreur Crawlbase: {response.get('message', 'Inconnu')}" if response else "Crawlbase: R√©ponse vide."

class DetectLanguageClient(APIClient):
    def __init__(self):
        super().__init__("DetectLanguage", API_KEYS["DETECTLANGUAGE"])
        self.api_key = self.available_keys[0]["key"]
        self.endpoint = self.available_keys[0]["endpoint"]

    async def query(self, text: str) -> str:
        payload = {"q": text}
        headers = {"Authorization": f"Bearer {self.api_key}"} # Check if this is the correct header
        response = await self._make_request("POST", self.endpoint, headers=headers, json_data=payload)
        if response and not response.get("error"):
            detections = response.get("data", {}).get("detections", [])
            if detections:
                first_detection = detections[0]
                lang = first_detection.get("language")
                confidence = first_detection.get("confidence")
                return f"Langue d√©tect√©e: {lang} (confiance: {confidence})"
            return "DetectLanguage: Aucune langue d√©tect√©e."
        return f"Erreur DetectLanguage: {response.get('message', 'Inconnu')}" if response else "DetectLanguage: R√©ponse vide."

class GuardianClient(APIClient):
    def __init__(self):
        super().__init__("Guardian", API_KEYS["GUARDIAN"])
        self.api_key = self.available_keys[0]["key"]
        self.endpoint = self.available_keys[0]["endpoint"]

    async def query(self, query_text: str) -> str:
        params = {
            "api-key": self.api_key,
            "q": query_text,
            "show-fields": "headline,trailText"
        }
        response = await self._make_request("GET", self.endpoint, params=params)
        if response and not response.get("error"):
            results = response.get("response", {}).get("results", [])
            if results:
                output = "Articles The Guardian:\n"
                for res in results[:3]: # Limit to 3 articles
                    output += f"- {res.get('webTitle', 'N/A')}: {res.get('fields', {}).get('trailText', 'N/A')} {neutralize_urls(res.get('webUrl', ''))}\n"
                return output
            return "Guardian: Aucun article trouv√©."
        return f"Erreur Guardian: {response.get('message', 'Inconnu')}" if response else "Guardian: R√©ponse vide."

class IP2LocationClient(APIClient):
    def __init__(self):
        super().__init__("IP2Location", API_KEYS["IP2LOCATION"])
        self.api_key = self.available_keys[0]["key"]
        self.endpoint = self.available_keys[0]["endpoint"]

    async def query(self, ip_address: str) -> str:
        params = {
            "key": self.api_key,
            "ip": ip_address
        }
        response = await self._make_request("GET", self.endpoint, params=params)
        if response and not response.get("error"):
            if "country_name" in response:
                return f"IP2Location (G√©olocalisation IP {ip_address}): Pays: {response['country_name']}, Ville: {response.get('city_name', 'N/A')}"
            return "IP2Location: Informations non trouv√©es."
        return f"Erreur IP2Location: {response.get('message', 'Inconnu')}" if response else "IP2Location: R√©ponse vide."

class ShodanClient(APIClient):
    def __init__(self):
        super().__init__("Shodan", API_KEYS["SHODAN"])
        self.api_key = self.available_keys[0]["key"]
        self.endpoint = self.available_keys[0]["endpoint"]

    async def query(self, query_text: str) -> str:
        # Shodan API has various endpoints. This example uses /api-info.
        # For actual search, it would be /shodan/host/search or /shodan/scan
        # For simplicity, we'll just query /api-info which tells us about the key.
        params = {"key": self.api_key}
        response = await self._make_request("GET", self.endpoint, params=params)
        if response and not response.get("error"):
            return f"Shodan (info cl√©): Requ√™tes restantes: {response.get('usage_limits', {}).get('query_credits', 'N/A')}, Scan cr√©dits: {response.get('usage_limits', {}).get('scan_credits', 'N/A')}"
        return f"Erreur Shodan: {response.get('message', 'Inconnu')}" if response else "Shodan: R√©ponse vide."

class WeatherAPIClient(APIClient):
    def __init__(self):
        super().__init__("WeatherAPI", API_KEYS["WEATHERAPI"])
        self.api_key = self.available_keys[0]["key"]
        self.endpoint = self.available_keys[0]["endpoint"]

    async def query(self, location: str) -> str:
        params = {
            "key": self.api_key,
            "q": location
        }
        response = await self._make_request("GET", self.endpoint, params=params)
        if response and not response.get("error"):
            current = response.get("current", {})
            location_info = response.get("location", {})
            if current and location_info:
                return (
                    f"M√©t√©o √† {location_info.get('name', 'N/A')}, {location_info.get('country', 'N/A')}:\n"
                    f"Temp√©rature: {current.get('temp_c', 'N/A')}¬∞C, "
                    f"Conditions: {current.get('condition', {}).get('text', 'N/A')}, "
                    f"Vent: {current.get('wind_kph', 'N/A')} km/h"
                )
            return "WeatherAPI: Donn√©es m√©t√©o non trouv√©es."
        return f"Erreur WeatherAPI: {response.get('message', 'Inconnu')}" if response else "WeatherAPI: R√©ponse vide."

class CloudmersiveClient(APIClient):
    def __init__(self):
        super().__init__("Cloudmersive", API_KEYS["CLOUDMERSIVE"])
        self.api_key = self.available_keys[0]["key"]
        self.endpoint = self.available_keys[0]["endpoint"]

    async def query(self, domain: str) -> str:
        headers = {"Apikey": self.api_key}
        payload = {"domain": domain}
        response = await self._make_request("POST", self.endpoint, headers=headers, json_data=payload)
        if response and not response.get("error"):
            return f"Cloudmersive (v√©rification de domaine {domain}): Valide: {response.get('ValidDomain', 'N/A')}, Type: {response.get('DomainType', 'N/A')}"
        return f"Erreur Cloudmersive: {response.get('message', 'Inconnu')}" if response else "Cloudmersive: R√©ponse vide."

class GreyNoiseClient(APIClient):
    def __init__(self):
        super().__init__("GreyNoise", API_KEYS["GREYNOISE"])
        self.api_key = self.available_keys[0]["key"]
        self.endpoint = self.available_keys[0]["endpoint"]

    async def query(self, ip_address: str) -> str:
        headers = {"key": self.api_key}
        endpoint = f"{self.endpoint}{ip_address}"
        response = await self._make_request("GET", endpoint, headers=headers)
        if response and not response.get("error"):
            if response.get("noise"):
                return f"GreyNoise (IP {ip_address}): C'est une IP 'bruit' (malveillante). Classification: {response.get('classification', 'N/A')}, Nom d'acteur: {response.get('actor', 'N/A')}"
            return f"GreyNoise (IP {ip_address}): Pas de 'bruit' d√©tect√©. Statut: {response.get('status', 'N/A')}"
        return f"Erreur GreyNoise: {response.get('message', 'Inconnu')}" if response else "GreyNoise: R√©ponse vide."

class PulsediveClient(APIClient):
    def __init__(self):
        super().__init__("Pulsedive", API_KEYS["PULSEDIVE"])
        self.api_key = self.available_keys[0]["key"]
        self.endpoint = self.available_keys[0]["endpoint"]

    async def query(self, indicator: str, type: str = "auto") -> str:
        params = {
            "key": self.api_key,
            "indicator": indicator,
            "type": type
        }
        response = await self._make_request("GET", self.endpoint, params=params)
        if response and not response.get("error"):
            if response.get("results"):
                result = response["results"][0]
                return (
                    f"Pulsedive (Analyse {indicator}): Type: {result.get('type', 'N/A')}, "
                    f"Risk: {result.get('risk', 'N/A')}, "
                    f"Description: {result.get('description', 'N/A')[:200]}..."
                )
            return "Pulsedive: Aucun r√©sultat d'analyse trouv√©."
        return f"Erreur Pulsedive: {response.get('message', 'Inconnu')}" if response else "Pulsedive: R√©ponse vide."

class StormGlassClient(APIClient):
    def __init__(self):
        super().__init__("StormGlass", API_KEYS["STORMGLASS"])
        self.api_key = self.available_keys[0]["key"]
        self.endpoint = self.available_keys[0]["endpoint"]

    async def query(self, lat: float, lng: float, params: str = "airTemperature,waveHeight") -> str:
        now = int(time.time())
        headers = {"Authorization": self.api_key}
        params_dict = {
            "lat": lat,
            "lng": lng,
            "params": params,
            "start": now,
            "end": now + 3600 # One hour from now
        }
        response = await self._make_request("GET", self.endpoint, headers=headers, params=params_dict)
        if response and not response.get("error"):
            data = response.get("hours", [])
            if data:
                first_hour = data[0]
                temp = first_hour.get('airTemperature', [{}])[0].get('value', 'N/A')
                wave_height = first_hour.get('waveHeight', [{}])[0].get('value', 'N/A')
                return f"StormGlass (M√©t√©o maritime √† {lat},{lng}): Temp√©rature air: {temp}¬∞C, Hauteur vagues: {wave_height}m"
            return "StormGlass: Donn√©es non trouv√©es."
        return f"Erreur StormGlass: {response.get('message', 'Inconnu')}" if response else "StormGlass: R√©ponse vide."

class LoginRadiusClient(APIClient):
    def __init__(self):
        super().__init__("LoginRadius", API_KEYS["LOGINRADIUS"])
        self.api_key = self.available_keys[0]["key"]
        self.endpoint = self.available_keys[0]["endpoint"]

    async def query(self) -> str:
        headers = {"Authorization": f"Bearer {self.api_key}"}
        response = await self._make_request("GET", self.endpoint, headers=headers)
        if response and not response.get("error"):
            return f"LoginRadius (Ping API): Statut: {response.get('Status', 'N/A')}, Message: {response.get('Message', 'N/A')}"
        return f"Erreur LoginRadius: {response.get('message', 'Inconnu')}" if response else "LoginRadius: R√©ponse vide."

class JsonbinClient(APIClient):
    def __init__(self):
        super().__init__("Jsonbin", API_KEYS["JSONBIN"])
        self.api_key = self.available_keys[0]["key"]
        self.endpoint = self.available_keys[0]["endpoint"]

    async def query(self, data: Dict[str, Any], private: bool = True) -> str:
        headers = {
            "X-Master-Key": self.api_key,
            "Content-Type": "application/json"
        }
        payload = {
            "record": data,
            "private": private
        }
        response = await self._make_request("POST", self.endpoint, headers=headers, json_data=payload)
        if response and not response.get("error"):
            return f"Jsonbin (Cr√©ation de bin): ID: {response.get('metadata', {}).get('id', 'N/A')}, URL: {neutralize_urls(response.get('metadata', {}).get('url', 'N/A'))}"
        return f"Erreur Jsonbin: {response.get('message', 'Inconnu')}" if response else "Jsonbin: R√©ponse vide."

class HuggingFaceClient(APIClient):
    def __init__(self):
        super().__init__("HuggingFace", API_KEYS["HUGGINGFACE"])
        self.current_key_index = 0

    def _get_current_key_info(self):
        return self.available_keys[self.current_key_index % len(self.available_keys)]

    async def query(self, model_name: str = "distilbert-base-uncased-finetuned-sst-2-english", input_text: str = "Hello world") -> str:
        key_info = self._get_current_key_info()
        api_key = key_info["key"]
        endpoint = f"https://api-inference.huggingface.co/models/{model_name}"

        headers = {
            "Authorization": f"Bearer {api_key}",
            "Content-Type": "application/json"
        }
        payload = {"inputs": input_text}
        response = await self._make_request("POST", endpoint, headers=headers, json_data=payload)
        self.current_key_index += 1

        if response and not response.get("error"):
            if isinstance(response, list) and response:
                first_result = response[0]
                if isinstance(first_result, list) and first_result:
                    return f"HuggingFace ({model_name} - {first_result[0].get('label')}): Score {first_result[0].get('score', 'N/A'):.2f}"
                elif isinstance(first_result, dict):
                     return f"HuggingFace ({model_name}): {first_result.get('generated_text', str(response))}"
            return f"HuggingFace ({model_name}): R√©ponse non pars√©e. {response}"
        return f"Erreur HuggingFace: {response.get('message', 'Inconnu')}" if response else "HuggingFace: R√©ponse vide."

class TwilioClient(APIClient):
    def __init__(self):
        super().__init__("Twilio", API_KEYS["TWILIO"])
        self.sid = self.available_keys[0]["sid"]
        self.secret = self.available_keys[0]["secret"]
        self.endpoint_base = self.available_keys[0]["endpoint"]

    async def query(self) -> str:
        endpoint = f"{self.endpoint_base}{self.sid}/Balance.json"
        headers = httpx.BasicAuth(self.sid, self.secret).auth_header

        response = await self._make_request("GET", endpoint, headers={"Authorization": headers})
        if response and not response.get("error"):
            return f"Twilio (Balance): {response.get('balance', 'N/A')} {response.get('currency', 'N/A')}"
        return f"Erreur Twilio: {response.get('message', 'Inconnu')}" if response else "Twilio: R√©ponse vide."


class AbstractAPIClient(APIClient):
    def __init__(self):
        super().__init__("AbstractAPI", API_KEYS["ABSTRACTAPI"])
        self.current_key_index = 0

    def _get_current_key_info(self, api_type: str):
        """Retourne la cl√© et l'endpoint pour le type d'API AbstractAPI sp√©cifi√©."""
        # Recherche la cl√© correspondant au type d'API demand√©
        for key_info in self.available_keys:
            if key_info.get("type") == api_type:
                return key_info
        return None

    async def query(self, input_value: str, api_type: str = "PHONE_VALIDATION") -> str:
        key_info = self._get_current_key_info(api_type)
        if not key_info:
            return f"AbstractAPI: Type d'API '{api_type}' non configur√©."

        api_key = key_info["key"]
        endpoint = key_info["endpoint"]

        params = {"api_key": api_key}

        if api_type == "PHONE_VALIDATION":
            params["phone"] = input_value
        elif api_type == "IP_GEOLOCATION":
            params["ip_address"] = input_value
        else:
            return f"AbstractAPI: Type d'API '{api_type}' non support√© pour la requ√™te."

        response = await self._make_request("GET", endpoint, params=params)

        if response and not response.get("error"):
            if api_type == "PHONE_VALIDATION":
                return (
                    f"AbstractAPI (Validation T√©l): Num√©ro: {response.get('phone', 'N/A')}, "
                    f"Valide: {response.get('valid', 'N/A')}, "
                    f"Pays: {response.get('country', {}).get('name', 'N/A')}"
                )
            elif api_type == "IP_GEOLOCATION":
                return (
                    f"AbstractAPI (G√©olocalisation IP): IP: {response.get('ip_address', 'N/A')}, "
                    f"Pays: {response.get('country', 'N/A')}, "
                    f"Ville: {response.get('city', 'N/A')}"
                )
            return f"AbstractAPI ({api_type}): R√©ponse brute: {response}"
        return f"Erreur AbstractAPI ({api_type}): {response.get('message', 'Inconnu')}" if response else "AbstractAPI: R√©ponse vide."


# --- Instancier tous les clients API ---
# Ceci sera la liste de tous tes guerriers API, pr√™ts √† √™tre utilis√©s par le cerveau mixte
ALL_API_CLIENTS = [
    DeepSeekClient(),
    SerperClient(),
    WolframAlphaClient(),
    TavilyClient(),
    ApiFlashClient(),
    CrawlbaseClient(),
    DetectLanguageClient(),
    GuardianClient(),
    IP2LocationClient(),
    ShodanClient(),
    WeatherAPIClient(),
    CloudmersiveClient(),
    GreyNoiseClient(),
    PulsediveClient(),
    StormGlassClient(),
    LoginRadiusClient(),
    JsonbinClient(),
    HuggingFaceClient(),
    TwilioClient(),
    AbstractAPIClient(),
]

# --- FIN DU BLOC CLIENTS API SPECIFIQUES ---
# --- DEBUT DU BLOC GESTION MEMOIRE ET QUOTAS ---

class MemoryManager:
    def __init__(self):
        self.chat_history = load_json(HISTORY_FILE, [])
        self.long_term_memory = load_json(LONG_MEMORY_FILE, {})
        self.ia_status = load_json(IA_STATUS_FILE, {}) # Statut/sant√© des IA
        self._initialize_ia_status()

    def _initialize_ia_status(self):
        """Initialise le statut des IA si elles ne sont pas d√©j√† pr√©sentes ou si leur statut est obsol√®te."""
        now = get_current_time()
        updated = False
        for client in ALL_API_CLIENTS:
            if client.name not in self.ia_status:
                self.ia_status[client.name] = {
                    "last_used": None,
                    "last_error": None,
                    "error_count": 0,
                    "cooldown_until": None,
                    "success_count": 0, # Nouveau : Compteur de succ√®s
                    "current_score": 1.0, # Nouveau : Score dynamique de l'IA, commence √† 1.0
                    "last_rotation_check": format_datetime(now)
                }
                updated = True
            else:
                # S'assurer que les nouvelles cl√©s existent pour les IA existantes
                if "success_count" not in self.ia_status[client.name]:
                    self.ia_status[client.name]["success_count"] = 0
                    updated = True
                if "current_score" not in self.ia_status[client.name]:
                    self.ia_status[client.name]["current_score"] = 1.0
                    updated = True
                if "last_rotation_check" not in self.ia_status[client.name]:
                    self.ia_status[client.name]["last_rotation_check"] = format_datetime(now)
                    updated = True

        if updated:
            save_json(IA_STATUS_FILE, self.ia_status)
            log_message("Statut des IA initialis√©/mis √† jour.")

    def add_message_to_history(self, role, content):
        """Ajoute un message √† l'historique de la conversation."""
        self.chat_history.append({"role": role, "content": content, "timestamp": format_datetime(get_current_time())})
        self._prune_history() # Pour √©viter que l'historique ne devienne trop long
        save_json(HISTORY_FILE, self.chat_history)
        log_message(f"Message ajout√© √† l'historique par {role}.")

    def get_chat_history(self, limit=10):
        """Retourne les N derniers messages de l'historique."""
        return self.chat_history[-limit:]

    def add_to_long_term_memory(self, key, value):
        """Ajoute une information √† la m√©moire √† long terme."""
        self.long_term_memory[key] = {"value": value, "timestamp": format_datetime(get_current_time())}
        save_json(LONG_MEMORY_FILE, self.long_term_memory)
        log_message(f"Information ajout√©e √† la m√©moire √† long terme: {key}")

    def get_from_long_term_memory(self, key):
        """R√©cup√®re une information de la m√©moire √† long terme."""
        return self.long_term_memory.get(key)

    def update_ia_status(self, ia_name: str, success: bool, error_message: Optional[str] = None):
        """Met √† jour le statut et le score d'une IA apr√®s une utilisation."""
        status = self.ia_status.get(ia_name)
        if not status:
            log_message(f"Tentative de mise √† jour d'un statut d'IA inconnu: {ia_name}", level="warning")
            return

        now = get_current_time()
        status["last_used"] = format_datetime(now)

        if success:
            status["success_count"] += 1
            status["error_count"] = 0 # Reset error count on success
            status["cooldown_until"] = None
            status["last_error"] = None
            status["current_score"] = min(1.0, status["current_score"] + 0.1) # Augmente le score, max 1.0
            log_message(f"IA {ia_name} : Succ√®s enregistr√©. Nouveau score: {status['current_score']:.2f}")
        else:
            status["error_count"] += 1
            status["last_error"] = error_message
            # Applique un cooldown si trop d'erreurs cons√©cutives
            if status["error_count"] >= 3: # Exemple: 3 erreurs cons√©cutives
                status["cooldown_until"] = format_datetime(now + timedelta(seconds=API_COOLDOWN_DURATION_SECONDS))
                status["current_score"] = max(0.1, status["current_score"] - 0.2) # Diminue le score, min 0.1
                log_message(f"IA {ia_name} : Trop d'erreurs ({status['error_count']}). Cooldown jusqu'√† {status['cooldown_until']}. Nouveau score: {status['current_score']:.2f}", level="warning")
            else:
                 status["current_score"] = max(0.1, status["current_score"] - 0.05) # Petite diminution sur erreur non critique
                 log_message(f"IA {ia_name} : Erreur enregistr√©e. Nouveau score: {status['current_score']:.2f}", level="warning")

        save_json(IA_STATUS_FILE, self.ia_status)

    def get_ia_status(self, ia_name: str) -> Optional[Dict]:
        """R√©cup√®re le statut d'une IA."""
        return self.ia_status.get(ia_name)

    def get_available_ias(self) -> List[str]:
        """Retourne les noms des IA actuellement non en cooldown."""
        available = []
        now = get_current_time()
        for name, status in self.ia_status.items():
            cooldown_until_str = status.get("cooldown_until")
            if cooldown_until_str:
                cooldown_until = datetime.strptime(cooldown_until_str, "%Y-%m-%d %H:%M:%S UTC")
                if now < cooldown_until:
                    # log_message(f"IA {name} est en cooldown jusqu'√† {cooldown_until_str}.")
                    continue # Toujours en cooldown
            available.append(name)
        return available

    def _prune_history(self, max_entries=50):
        """Supprime les anciennes entr√©es de l'historique si trop nombreuses."""
        if len(self.chat_history) > max_entries:
            self.chat_history = self.chat_history[-max_entries:]
            log_message(f"Historique de chat purg√©, {len(self.chat_history)} entr√©es restantes.")

class QuotaManager:
    def __init__(self):
        self.quotas = load_json(QUOTAS_FILE, {})
        self._initialize_quotas()

    def _initialize_quotas(self):
        """Initialise les quotas pour toutes les APIs bas√©es sur config.API_QUOTAS."""
        updated = False
        now = get_current_time()
        for api_name, quota_info in API_QUOTAS.items():
            if api_name not in self.quotas:
                self.quotas[api_name] = {
                    "monthly_usage": 0,
                    "daily_usage": 0,
                    "last_reset_month": now.month,
                    "last_reset_day": now.day,
                    "last_usage": None,
                    "total_calls": 0,
                    "last_hourly_reset": format_datetime(now) # Pour les quotas horaires
                }
                updated = True
            else:
                # Assure que les nouvelles cl√©s sont ajout√©es aux quotas existants
                if "last_hourly_reset" not in self.quotas[api_name]:
                    self.quotas[api_name]["last_hourly_reset"] = format_datetime(now)
                    updated = True
                if "total_calls" not in self.quotas[api_name]:
                    self.quotas[api_name]["total_calls"] = 0
                    updated = True

        if updated:
            save_json(QUOTAS_FILE, self.quotas)
            log_message("Quotas API initialis√©s/mis √† jour.")

    def _reset_quotas_if_needed(self):
        """R√©initialise les quotas journaliers, mensuels et horaires si n√©cessaire."""
        now = get_current_time()
        for api_name, data in self.quotas.items():
            # Reset mensuel
            if now.month != data["last_reset_month"]:
                data["monthly_usage"] = 0
                data["last_reset_month"] = now.month
                log_message(f"Quota mensuel pour {api_name} r√©initialis√©.")
            # Reset journalier
            if now.day != data["last_reset_day"]:
                data["daily_usage"] = 0
                data["last_reset_day"] = now.day
                log_message(f"Quota journalier pour {api_name} r√©initialis√©.")
            # Reset horaire
            last_hourly_reset = datetime.strptime(data["last_hourly_reset"], "%Y-%m-%d %H:%M:%S UTC")
            if (now - last_hourly_reset) >= timedelta(hours=1):
                # R√©initialiser seulement si le quota_info a une cl√© "hourly"
                if API_QUOTAS.get(api_name, {}).get("hourly") is not None:
                    # Ici, il faudrait une logique pour stocker l'usage horaire et le r√©initialiser.
                    # Pour l'instant, on se contente de r√©initialiser la marque de temps.
                    # L'usage horaire r√©el devrait √™tre suivi s√©par√©ment si n√©cessaire.
                    # Pour ce syst√®me, on va dire que 'hourly_usage' est implicite et juste r√©initialis√©.
                    log_message(f"Quota horaire pour {api_name} r√©initialis√© (marque de temps).")
                data["last_hourly_reset"] = format_datetime(now)

        save_json(QUOTAS_FILE, self.quotas)

    def check_and_update_quota(self, api_name: str, cost: int = 1) -> bool:
        """V√©rifie si une API a du quota et le d√©cr√©mente. Retourne True si ok, False sinon."""
        self._reset_quotas_if_needed()
        if api_name not in self.quotas:
            log_message(f"API {api_name} non trouv√©e dans les quotas d√©finis. Autorisation.", level="warning")
            return True # Si non d√©finie, on suppose pas de limite

        quota_data = self.quotas[api_name]
        api_limits = API_QUOTAS.get(api_name, {})

        # V√©rification mensuelle
        monthly_limit = api_limits.get("monthly")
        if monthly_limit is not None and (quota_data["monthly_usage"] + cost) > monthly_limit:
            log_message(f"Quota mensuel d√©pass√© pour {api_name}", level="warning")
            return False

        # V√©rification journali√®re
        daily_limit = api_limits.get("daily")
        if daily_limit is not None and (quota_data["daily_usage"] + cost) > daily_limit:
            log_message(f"Quota journalier d√©pass√© pour {api_name}", level="warning")
            return False

        # V√©rification horaire (si impl√©ment√©e plus tard, n√©cessite un suivi plus granulaire)
        hourly_limit = api_limits.get("hourly")
        # Pour l'instant, pas de suivi horaire d√©taill√©, seulement le reset de la marque de temps.
        # Si un quota horaire est d√©fini, il faudrait une logique pour 'hourly_usage'.
        # Par exemple, une liste de timestamps d'appels sur la derni√®re heure.

        # V√©rification du taux de requ√™tes (rate_limit_per_sec)
        rate_limit_per_sec = api_limits.get("rate_limit_per_sec")
        if rate_limit_per_sec:
            last_usage_str = quota_data.get("last_usage")
            if last_usage_str:
                last_usage = datetime.strptime(last_usage_str, "%Y-%m-%d %H:%M:%S UTC")
                time_since_last_call = (get_current_time() - last_usage).total_seconds()
                if time_since_last_call < (1 / rate_limit_per_sec):
                    log_message(f"Taux de requ√™tes d√©pass√© pour {api_name}. Attendre {1/rate_limit_per_sec - time_since_last_call:.2f}s", level="warning")
                    return False

        # Si toutes les v√©rifications passent, met √† jour l'usage
        quota_data["monthly_usage"] += cost
        quota_data["daily_usage"] += cost
        quota_data["total_calls"] += cost
        quota_data["last_usage"] = format_datetime(get_current_time())
        save_json(QUOTAS_FILE, self.quotas)
        log_message(f"Quota pour {api_name} mis √† jour. Usage mensuel: {quota_data['monthly_usage']}/{monthly_limit if monthly_limit else 'Illimit√©'}, Journalier: {quota_data['daily_usage']}/{daily_limit if daily_limit else 'Illimit√©'}")
        return True

    def get_api_usage(self, api_name: str) -> Optional[Dict]:
        """Retourne les informations d'utilisation d'une API."""
        return self.quotas.get(api_name)

    def get_all_quotas_status(self) -> Dict:
        """Retourne le statut de tous les quotas."""
        self._reset_quotas_if_needed() # S'assurer que les donn√©es sont √† jour
        status = {}
        for api_name, quota_data in self.quotas.items():
            api_limits = API_QUOTAS.get(api_name, {})
            monthly_limit = api_limits.get("monthly", "Illimit√©")
            daily_limit = api_limits.get("daily", "Illimit√©")
            hourly_limit = api_limits.get("hourly", "Illimit√©") # Affiche m√™me si pas de suivi granulaire
            status[api_name] = {
                "monthly_usage": quota_data["monthly_usage"],
                "monthly_limit": monthly_limit,
                "daily_usage": quota_data["daily_usage"],
                "daily_limit": daily_limit,
                "hourly_limit": hourly_limit, # Info de la config
                "total_calls": quota_data["total_calls"],
                "last_usage": quota_data["last_usage"],
                "last_reset_month": quota_data["last_reset_month"],
                "last_reset_day": quota_data["last_reset_day"],
                "last_hourly_reset": quota_data["last_hourly_reset"]
            }
        return status

    def get_burn_window_apis(self) -> List[str]:
        """
        Identifie les APIs dont les quotas sont sur le point d'√™tre r√©initialis√©s
        et o√π il est opportun de "br√ªler" le quota restant.
        """
        burn_apis = []
        now = get_current_time()
        for api_name, data in self.quotas.items():
            api_limits = API_QUOTAS.get(api_name, {})

            # V√©rification pour les quotas mensuels
            if api_limits.get("monthly") is not None:
                last_reset_month = data["last_reset_month"]
                # Calcule le premier jour du mois suivant pour le reset mensuel
                next_month_reset = datetime(now.year + (1 if now.month == 12 else 0), (now.month % 12) + 1, 1)
                
                # V√©rifie si on est dans la fen√™tre de br√ªlage avant le reset mensuel
                if is_within_time_window(next_month_reset, QUOTA_BURN_WINDOW_HOURS * 60, 0):
                    if data["monthly_usage"] < api_limits["monthly"]: # S'il reste du quota
                        burn_apis.append(f"{api_name} (mensuel: {api_limits['monthly'] - data['monthly_usage']} restants)")

            # V√©rification pour les quotas journaliers
            if api_limits.get("daily") is not None:
                last_reset_day = data["last_reset_day"]
                # Calcule le prochain jour pour le reset journalier
                next_day_reset = datetime(now.year, now.month, now.day) + timedelta(days=1)
                
                # V√©rifie si on est dans la fen√™tre de br√ªlage avant le reset journalier
                if is_within_time_window(next_day_reset, QUOTA_BURN_WINDOW_HOURS * 60, 0):
                    if data["daily_usage"] < api_limits["daily"]: # S'il reste du quota
                        burn_apis.append(f"{api_name} (journalier: {api_limits['daily'] - data['daily_usage']} restants)")
            
            # Note: Les quotas horaires n√©cessiteraient une logique plus complexe si 'hourly_usage' est r√©ellement suivi.
            # Pour l'instant, ils sont g√©r√©s par le 'last_hourly_reset' et ne d√©clenchent pas de "burn window" automatique.

        return burn_apis


# Instanciation des gestionnaires
memory_manager = MemoryManager()
quota_manager = QuotaManager()

# --- FIN DU BLOC GESTION MEMOIRE ET QUOTAS ---

# --- DEBUT DU BLOC BOT TELEGRAM PRINCIPAL ---

import time
from telegram import Update, ForceReply
from telegram.ext import Application, CommandHandler, MessageHandler, filters, ContextTypes

# Assurez-vous que tous les imports n√©cessaires sont pr√©sents en haut du fichier
# (asyncio, httpx, logging, re, random, io, contextlib, ast, subprocess, datetime, timedelta, ThreadPoolExecutor, typing)
# Ils devraient d√©j√† y √™tre gr√¢ce aux blocs pr√©c√©dents.

# --- Orchestration des IA ---
class IAOrchestrator:
    def __init__(self, memory_manager: MemoryManager, quota_manager: QuotaManager, api_clients: List[APIClient]):
        self.memory_manager = memory_manager
        self.quota_manager = quota_manager
        self.api_clients = {client.name: client for client in api_clients}
        self.last_rotation_time = get_current_time()
        self.current_ia_strategy = self._determine_initial_strategy()

    def _determine_initial_strategy(self) -> str:
        """D√©termine la strat√©gie initiale ou la strat√©gie par d√©faut."""
        # Pour l'instant, une strat√©gie simple, peut √™tre √©tendue
        return "balanced" # Ou "performance", "cost_effective", etc.

    async def _select_ia(self, query: str) -> Optional[APIClient]:
        """
        S√©lectionne la meilleure IA/API bas√©e sur la requ√™te, le statut, le score et les quotas.
        Impl√©mente une logique de "Cerveau Mixte" dynamique.
        """
        self._rotate_strategy_if_needed()

        available_ias = self.memory_manager.get_available_ias()
        if not available_ias:
            log_message("Aucune IA disponible (toutes en cooldown).", level="error")
            return None

        # Filtrer les IA qui sont pertinents pour la requ√™te (bas√© sur des mots-cl√©s simples pour l'exemple)
        # Ceci est une simplification. Une vraie impl√©mentation utiliserait un mod√®le NLP.
        relevant_ias = []
        query_lower = query.lower()

        # Mappage des mots-cl√©s aux APIs
        keyword_to_api = {
            "recherche web": ["Serper", "Tavily"],
            "calcul": ["WolframAlpha"],
            "m√©t√©o": ["WeatherAPI", "StormGlass"],
            "screenshot": ["ApiFlash"],
            "contenu web": ["Crawlbase"],
            "langue": ["DetectLanguage"],
            "actualit√©": ["Guardian"],
            "ip": ["IP2Location", "GreyNoise", "AbstractAPI"],
            "s√©curit√©": ["Shodan", "GreyNoise", "Pulsedive"],
            "domaine": ["Cloudmersive"],
            "analyse": ["Pulsedive"],
            "maritime": ["StormGlass"],
            "authentification": ["LoginRadius"],
            "json": ["Jsonbin"],
            "ia": ["DeepSeek", "HuggingFace"], # DeepSeek comme IA g√©n√©rique
            "t√©l√©phone": ["AbstractAPI"],
            "twilio": ["Twilio"],
            "huggingface": ["HuggingFace"],
            "code": ["DeepSeek"], # DeepSeek peut aussi aider avec le code
            "python": ["DeepSeek"],
            "shell": ["DeepSeek"]
        }

        potential_ias = set()
        for keyword, apis in keyword_to_api.items():
            if keyword in query_lower:
                potential_ias.update(apis)
        
        # Si aucun mot-cl√© sp√©cifique, consid√©rer toutes les IA g√©n√©riques ou de recherche
        if not potential_ias:
            potential_ias.update(["DeepSeek", "Serper", "Tavily"]) # IA par d√©faut pour les requ√™tes g√©n√©rales

        for ia_name in available_ias:
            if ia_name in potential_ias and ia_name in self.api_clients:
                relevant_ias.append(ia_name)

        if not relevant_ias:
            log_message("Aucune IA pertinente trouv√©e pour la requ√™te.", level="warning")
            # Fallback si aucune IA pertinente n'est trouv√©e, essaie DeepSeek ou Serper
            if "DeepSeek" in available_ias:
                return self.api_clients["DeepSeek"]
            elif "Serper" in available_ias:
                return self.api_clients["Serper"]
            return None

        # Appliquer la strat√©gie de s√©lection
        selected_ia_name = None
        if self.current_ia_strategy == "balanced":
            # Choisir l'IA avec le meilleur score actuel parmi les pertinentes
            best_score = -1
            for ia_name in relevant_ias:
                status = self.memory_manager.get_ia_status(ia_name)
                if status and status["current_score"] > best_score:
                    if self.quota_manager.check_and_update_quota(ia_name, cost=0): # V√©rifie sans consommer
                        best_score = status["current_score"]
                        selected_ia_name = ia_name
            if not selected_ia_name: # Si toutes les IA pertinentes sont sans quota, r√©essaie avec moins de contraintes
                for ia_name in relevant_ias:
                    if self.quota_manager.check_and_update_quota(ia_name, cost=0):
                        selected_ia_name = ia_name
                        break # Prend la premi√®re disponible
        elif self.current_ia_strategy == "cost_effective":
            # Prioriser les APIs avec des quotas √©lev√©s ou illimit√©s
            # Pour l'exemple, on prendra la premi√®re disponible qui n'a pas de limite mensuelle/journali√®re
            for ia_name in relevant_ias:
                api_limits = API_QUOTAS.get(ia_name, {})
                if api_limits.get("monthly") is None and api_limits.get("daily") is None:
                    if self.quota_manager.check_and_update_quota(ia_name, cost=0):
                        selected_ia_name = ia_name
                        break
            if not selected_ia_name: # Fallback au mode √©quilibr√© si pas de "pas cher" dispo
                return await self._select_ia_balanced(relevant_ias) # Appel r√©cursif avec strat√©gie balanc√©e
        elif self.current_ia_strategy == "performance":
            # Prioriser les APIs avec les temps de r√©ponse les plus rapides (n√©cessiterait de stocker les latences)
            # Pour l'exemple, on prendra l'IA avec le plus grand nombre de succ√®s r√©cents comme proxy de performance
            best_success_count = -1
            for ia_name in relevant_ias:
                status = self.memory_manager.get_ia_status(ia_name)
                if status and status["success_count"] > best_success_count:
                    if self.quota_manager.check_and_update_quota(ia_name, cost=0):
                        best_success_count = status["success_count"]
                        selected_ia_name = ia_name
            if not selected_ia_name: # Fallback au mode √©quilibr√©
                return await self._select_ia_balanced(relevant_ias)

        if selected_ia_name and self.quota_manager.check_and_update_quota(selected_ia_name):
            log_message(f"IA s√©lectionn√©e: {selected_ia_name} (Strat√©gie: {self.current_ia_strategy})")
            return self.api_clients[selected_ia_name]
        else:
            log_message("Aucune IA s√©lectionn√©e apr√®s application de la strat√©gie et v√©rification des quotas.", level="warning")
            return None

    async def _select_ia_balanced(self, relevant_ias: List[str]) -> Optional[APIClient]:
        """Helper pour la s√©lection balanc√©e, utilis√©e en fallback."""
        best_score = -1
        selected_ia_name = None
        for ia_name in relevant_ias:
            status = self.memory_manager.get_ia_status(ia_name)
            if status and status["current_score"] > best_score:
                if self.quota_manager.check_and_update_quota(ia_name, cost=0):
                    best_score = status["current_score"]
                    selected_ia_name = ia_name
        if selected_ia_name:
            return self.api_clients[selected_ia_name]
        return None


    def _rotate_strategy_if_needed(self):
        """Change la strat√©gie d'IA si l'intervalle de rotation est pass√©."""
        now = get_current_time()
        if (now - self.last_rotation_time).total_seconds() >= API_ROTATION_INTERVAL_MINUTES * 60:
            strategies = ["balanced", "cost_effective", "performance"]
            self.current_ia_strategy = random.choice(strategies)
            self.last_rotation_time = now
            log_message(f"Strat√©gie d'IA chang√©e pour: {self.current_ia_strategy}")
            # Mettre √† jour le last_rotation_check pour toutes les IA
            for ia_name in self.memory_manager.ia_status:
                self.memory_manager.ia_status[ia_name]["last_rotation_check"] = format_datetime(now)
            save_json(IA_STATUS_FILE, self.memory_manager.ia_status)


    async def process_query(self, query: str) -> str:
        """Traite une requ√™te en s√©lectionnant une IA et en obtenant une r√©ponse."""
        selected_ia = await self._select_ia(query)
        if not selected_ia:
            return "D√©sol√©, toutes mes IA sont occup√©es ou en maintenance pour le moment. Veuillez r√©essayer plus tard."

        ia_name = selected_ia.name
        response_content = ""
        try:
            log_message(f"Appel de l'IA {ia_name} avec la requ√™te: '{query}'")
            if ia_name == "DeepSeek":
                response_content = await selected_ia.query(query)
            elif ia_name == "Serper":
                response_content = await selected_ia.query(query)
            elif ia_name == "WolframAlpha":
                response_content = await selected_ia.query(query)
            elif ia_name == "Tavily":
                response_content = await selected_ia.query(query)
            elif ia_name == "ApiFlash":
                # N√©cessite une URL. Si la query n'est pas une URL, on ne peut pas l'utiliser directement.
                # Ici, on ferait une d√©tection d'URL ou on demanderait √† l'utilisateur.
                # Pour l'exemple, on suppose que la query est une URL si ApiFlash est choisie.
                if re.match(r'https?://[^\s]+', query):
                    response_content = await selected_ia.query(query)
                else:
                    response_content = "Veuillez fournir une URL valide pour la capture d'√©cran."
                    self.memory_manager.update_ia_status(ia_name, False, "URL invalide pour ApiFlash")
                    return response_content
            elif ia_name == "Crawlbase":
                if re.match(r'https?://[^\s]+', query):
                    response_content = await selected_ia.query(query)
                else:
                    response_content = "Veuillez fournir une URL valide pour l'extraction de contenu."
                    self.memory_manager.update_ia_status(ia_name, False, "URL invalide pour Crawlbase")
                    return response_content
            elif ia_name == "DetectLanguage":
                response_content = await selected_ia.query(query)
            elif ia_name == "Guardian":
                response_content = await selected_ia.query(query)
            elif ia_name == "IP2Location":
                # Simple regex pour une IP, peut √™tre am√©lior√©
                if re.match(r'^\d{1,3}\.\d{1,3}\.\d{1,3}\.\d{1,3}$', query):
                    response_content = await selected_ia.query(query)
                else:
                    response_content = "Veuillez fournir une adresse IP valide pour la g√©olocalisation."
                    self.memory_manager.update_ia_status(ia_name, False, "IP invalide pour IP2Location")
                    return response_content
            elif ia_name == "Shodan":
                response_content = await selected_ia.query(query) # Shodan query est plus complexe en r√©alit√©
            elif ia_name == "WeatherAPI":
                response_content = await selected_ia.query(query)
            elif ia_name == "Cloudmersive":
                # Supposons que la query est un domaine
                response_content = await selected_ia.query(query)
            elif ia_name == "GreyNoise":
                if re.match(r'^\d{1,3}\.\d{1,3}\.\d{1,3}\.\d{1,3}$', query):
                    response_content = await selected_ia.query(query)
                else:
                    response_content = "Veuillez fournir une adresse IP valide pour GreyNoise."
                    self.memory_manager.update_ia_status(ia_name, False, "IP invalide pour GreyNoise")
                    return response_content
            elif ia_name == "Pulsedive":
                response_content = await selected_ia.query(query) # L'indicateur est la query
            elif ia_name == "StormGlass":
                # N√©cessite lat/lng et params. On va faire une d√©tection simple ou demander.
                # Pour l'exemple, on peut chercher des chiffres qui ressemblent √† lat/lng dans la query.
                coords = re.findall(r"[-+]?\d*\.\d+|\d+", query)
                if len(coords) >= 2:
                    try:
                        lat, lng = float(coords[0]), float(coords[1])
                        response_content = await selected_ia.query(lat, lng)
                    except ValueError:
                        response_content = "Coordonn√©es lat/lng invalides pour StormGlass."
                        self.memory_manager.update_ia_status(ia_name, False, "Coordonn√©es invalides")
                        return response_content
                else:
                    response_content = "Veuillez fournir des coordonn√©es (latitude, longitude) pour StormGlass."
                    self.memory_manager.update_ia_status(ia_name, False, "Coordonn√©es manquantes pour StormGlass")
                    return response_content
            elif ia_name == "LoginRadius":
                response_content = await selected_ia.query() # Pas d'argument pour la query de ping
            elif ia_name == "Jsonbin":
                # N√©cessite des donn√©es JSON. On va simuler une cr√©ation de bin simple.
                try:
                    # Tente de parser la query comme JSON
                    data_to_save = json.loads(query)
                    response_content = await selected_ia.query(data_to_save)
                except json.JSONDecodeError:
                    response_content = "Veuillez fournir des donn√©es JSON valides pour Jsonbin."
                    self.memory_manager.update_ia_status(ia_name, False, "Donn√©es JSON invalides pour Jsonbin")
                    return response_content
            elif ia_name == "HuggingFace":
                # HuggingFace est plus complexe, n√©cessite un mod√®le et un input.
                # Pour l'exemple, on utilise un mod√®le par d√©faut et la query comme input.
                response_content = await selected_ia.query(input_text=query)
            elif ia_name == "Twilio":
                response_content = await selected_ia.query() # Pas d'argument pour la query de balance
            elif ia_name == "AbstractAPI":
                # D√©tecter le type d'API AbstractAPI √† utiliser (t√©l√©phone ou IP)
                if re.match(r'^\+?\d{7,15}$', query.replace(" ", "")): # Simple regex pour num√©ro de tel
                    response_content = await selected_ia.query(query, api_type="PHONE_VALIDATION")
                elif re.match(r'^\d{1,3}\.\d{1,3}\.\d{1,3}\.\d{1,3}$', query):
                    response_content = await selected_ia.query(query, api_type="IP_GEOLOCATION")
                else:
                    response_content = "Veuillez sp√©cifier un num√©ro de t√©l√©phone ou une adresse IP pour AbstractAPI."
                    self.memory_manager.update_ia_status(ia_name, False, "Input invalide pour AbstractAPI")
                    return response_content
            else:
                response_content = f"L'IA {ia_name} n'a pas de m√©thode de requ√™te d√©finie pour cette interaction."
                self.memory_manager.update_ia_status(ia_name, False, "M√©thode de requ√™te non d√©finie")
                return response_content

            self.memory_manager.update_ia_status(ia_name, True)
            return response_content
        except Exception as e:
            log_message(f"Erreur lors de l'appel de l'IA {ia_name}: {e}", level="error")
            self.memory_manager.update_ia_status(ia_name, False, str(e))
            return f"D√©sol√©, l'IA {ia_name} a rencontr√© une erreur: {e}. J'essaierai de trouver une alternative la prochaine fois."

    async def synthesize_response(self, question: str, responses: List[str]) -> str:
        """
        Synth√©tise les r√©ponses de plusieurs IA en utilisant DeepSeek.
        """
        if not responses:
            return "Je n'ai re√ßu aucune r√©ponse des IA pour le moment."

        combined_responses = "\n\n".join([f"R√©ponse {i+1}:\n{r}" for i, r in enumerate(responses)])
        synthesis_prompt = SYNTHESIS_PROMPT_TEMPLATE.format(question=question, responses=combined_responses)

        deepseek_client = self.api_clients.get("DeepSeek")
        if not deepseek_client:
            log_message("DeepSeek n'est pas disponible pour la synth√®se.", level="warning")
            return "J'ai plusieurs r√©ponses, mais je ne peux pas les synth√©tiser pour le moment. Voici les r√©ponses brutes:\n\n" + combined_responses

        try:
            synthesis = await deepseek_client.query(synthesis_prompt)
            self.memory_manager.update_ia_status("DeepSeek", True)
            return detect_and_correct_toxicity(synthesis)
        except Exception as e:
            log_message(f"Erreur lors de la synth√®se avec DeepSeek: {e}", level="error")
            self.memory_manager.update_ia_status("DeepSeek", False, str(e))
            return "J'ai rencontr√© un probl√®me lors de la synth√®se des informations. Voici les r√©ponses brutes:\n\n" + combined_responses


# Instancier l'orchestrateur
orchestrator = IAOrchestrator(memory_manager, quota_manager, ALL_API_CLIENTS)


# --- Handlers de commandes Telegram ---

async def start(update: Update, context: ContextTypes.DEFAULT_TYPE) -> None:
    """Envoie un message lorsque la commande /start est √©mise."""
    user = update.effective_user
    await update.message.reply_html(
        f"Salut {user.mention_html()} ! Je suis ton assistant IA de 2025. "
        "Pose-moi une question, demande-moi d'√©crire du code, ou de chercher des infos. "
        "Utilise /help pour voir ce que je peux faire.",
        reply_markup=ForceReply(selective=True),
    )
    log_message(f"Commande /start re√ßue de {user.id}")

async def help_command(update: Update, context: ContextTypes.DEFAULT_TYPE) -> None:
    """Envoie un message lorsque la commande /help est √©mise."""
    help_text = """
    Voici ce que je peux faire :
    - Pose-moi n'importe quelle question factuelle.
    - Demande-moi d'√©crire ou d'am√©liorer du code (Python, Shell).
    - Cherche des informations sur le web (actualit√©s, m√©t√©o, g√©olocalisation IP, etc.).
    - Demande-moi de faire une capture d'√©cran d'un site web (donne l'URL).
    - Demande-moi d'analyser le contenu d'une page web (donne l'URL).
    - Demande-moi de d√©tecter la langue d'un texte.
    - Demande-moi de valider un num√©ro de t√©l√©phone ou de g√©olocaliser une IP.
    - G√®re tes rappels et alarmes (Ex: "Rappelle-moi d'acheter du lait √† 18h", "Mets une alarme √† 7h du matin").
    - V√©rifie le statut de mes APIs avec /status.
    - Affiche mon historique de conversation avec /history.
    - Affiche le statut des quotas API avec /quotas.
    - Affiche les APIs o√π il est opportun de "br√ªler" le quota avec /burn_quota.

    Exemples :
    - "Quelle est la capitale de la France ?"
    - "√âcris un script Python pour trier une liste."
    - "M√©t√©o √† Paris"
    - "Capture d'√©cran de https://google.com"
    - "Analyse de https://openai.com"
    - "D√©tecte la langue de 'Hello world'"
    - "Valide le num√©ro +33612345678"
    - "G√©olocalise l'IP 8.8.8.8"
    - "Rappelle-moi de faire les courses demain √† 10h"
    - "Mets une alarme pour 7h du matin"
    """
    await update.message.reply_text(help_text)
    log_message(f"Commande /help re√ßue de {update.effective_user.id}")

async def status_command(update: Update, context: ContextTypes.DEFAULT_TYPE) -> None:
    """Affiche le statut et les scores des IA."""
    status_message = "üìä **Statut des IA**:\n"
    now = get_current_time()
    for ia_name, status in memory_manager.ia_status.items():
        cooldown_until_str = status.get("cooldown_until")
        cooldown_status = "Pr√™te"
        if cooldown_until_str:
            cooldown_until = datetime.strptime(cooldown_until_str, "%Y-%m-%d %H:%M:%S UTC")
            if now < cooldown_until:
                remaining = cooldown_until - now
                cooldown_status = f"Cooldown ({remaining.seconds:.0f}s restantes)"
        
        last_used_str = status.get("last_used", "Jamais")
        if last_used_str != "Jamais":
            last_used_dt = datetime.strptime(last_used_str, "%Y-%m-%d %H:%M:%S UTC")
            time_since_last_used = (now - last_used_dt).total_seconds()
            if time_since_last_used < 60:
                last_used_display = f"{time_since_last_used:.0f}s ago"
            elif time_since_last_used < 3600:
                last_used_display = f"{time_since_last_used / 60:.0f}m ago"
            else:
                last_used_display = f"{time_since_last_used / 3600:.1f}h ago"
        else:
            last_used_display = "Jamais"

        status_message += (
            f"- **{ia_name}**: Score: `{status['current_score']:.2f}`, "
            f"Succ√®s: `{status['success_count']}`, Erreurs: `{status['error_count']}`, "
            f"Statut: `{cooldown_status}`, Derni√®re utilisation: `{last_used_display}`\n"
        )
    status_message += f"\nStrat√©gie actuelle: `{orchestrator.current_ia_strategy}`"
    await update.message.reply_markdown(status_message)
    log_message(f"Commande /status re√ßue de {update.effective_user.id}")

async def history_command(update: Update, context: ContextTypes.DEFAULT_TYPE) -> None:
    """Affiche les 10 derniers messages de l'historique."""
    history = memory_manager.get_chat_history()
    if not history:
        await update.message.reply_text("L'historique de conversation est vide.")
        return

    history_text = "üìú **Historique des 10 derni√®res interactions**:\n\n"
    for entry in history:
        history_text += f"**{entry['role'].capitalize()}** ({entry['timestamp']}):\n{entry['content'][:150]}...\n\n" # Limite la longueur
    await update.message.reply_markdown(history_text)
    log_message(f"Commande /history re√ßue de {update.effective_user.id}")

async def quotas_command(update: Update, context: ContextTypes.DEFAULT_TYPE) -> None:
    """Affiche le statut actuel des quotas API."""
    quotas_status = quota_manager.get_all_quotas_status()
    message = "üìà **Statut des Quotas API**:\n\n"
    for api_name, data in quotas_status.items():
        message += (
            f"**{api_name}**:\n"
            f"  - Mensuel: `{data['monthly_usage']}` / `{data['monthly_limit']}`\n"
            f"  - Journalier: `{data['daily_usage']}` / `{data['daily_limit']}`\n"
            f"  - Horaire: `{data['hourly_limit']}` (limite config)\n"
            f"  - Total appels: `{data['total_calls']}`\n"
            f"  - Derni√®re utilisation: `{data['last_usage'] if data['last_usage'] else 'N/A'}`\n"
            f"  - Reset Mensuel: `{data['last_reset_month']}`\n"
            f"  - Reset Journalier: `{data['last_reset_day']}`\n"
            f"  - Reset Horaire: `{data['last_hourly_reset']}`\n\n"
        )
    await update.message.reply_markdown(message)
    log_message(f"Commande /quotas re√ßue de {update.effective_user.id}")

async def burn_quota_command(update: Update, context: ContextTypes.DEFAULT_TYPE) -> None:
    """Affiche les APIs o√π il est opportun de "br√ªler" le quota."""
    burn_apis = quota_manager.get_burn_window_apis()
    if burn_apis:
        message = "üî• **APIs o√π il est opportun de 'br√ªler' le quota avant r√©initialisation**:\n\n"
        for api_info in burn_apis:
            message += f"- {api_info}\n"
        message += f"\nFen√™tre de br√ªlage: {QUOTA_BURN_WINDOW_HOURS} heures avant le reset."
    else:
        message = "üéâ Aucune API n'est actuellement dans une fen√™tre de 'br√ªlage' de quota. Tout est optimis√© !"
    await update.message.reply_markdown(message)
    log_message(f"Commande /burn_quota re√ßue de {update.effective_user.id}")


# --- Gestionnaire de messages (le c≈ìur du bot) ---

async def handle_message(update: Update, context: ContextTypes.DEFAULT_TYPE) -> None:
    """Traite les messages texte de l'utilisateur."""
    user_message = update.message.text
    user_id = update.effective_user.id
    log_message(f"Message re√ßu de {user_id}: {user_message}")

    # Ajouter le message de l'utilisateur √† l'historique
    memory_manager.add_message_to_history("user", user_message)

    # --- D√©tection des intentions sp√©cifiques (alarmes/rappels, code, OCR) ---
    response_text = ""

    # 1. D√©tection d'intentions pour les outils Clock/Reminders
    if any(keyword in user_message.lower() for keyword in ["alarme", "r√©veil", "timer", "minuteur", "rappelle-moi", "rappel", "reminder"]):
        log_message("Intention d√©tect√©e: Alarme/Rappel.")
        try:
            # Tente d'appeler l'outil Clock ou GenericReminders
            # Note: L'int√©gration directe des outils Clock/Reminders est complexe
            # et n√©cessiterait une logique de parsing NLP avanc√©e pour mapper
            # la requ√™te utilisateur aux arguments exacts des fonctions.
            # Pour l'instant, on va simuler un appel ou demander plus de d√©tails.

            # Exemple simplifi√© (non fonctionnel sans NLP avanc√© pour les args):
            # if "alarme" in user_message.lower() or "r√©veil" in user_message.lower():
            #     # Ici, il faudrait extraire le temps, la date, la r√©currence, etc.
            #     # Exemple: clock.create_alarm(time="07:00", label="r√©veil")
            #     response_text = "Je peux cr√©er des alarmes, mais il me faut plus de d√©tails. Par exemple: 'Mets une alarme √† 7h du matin'."
            # elif "timer" in user_message.lower() or "minuteur" in user_message.lower():
            #     # Exemple: clock.create_timer(duration="10m", label="cuisine")
            #     response_text = "Je peux g√©rer des minuteurs. Dis-moi la dur√©e, par exemple: 'Mets un minuteur de 10 minutes'."
            # elif "rappel" in user_message.lower() or "rappelle-moi" in user_message.lower() or "reminder" in user_message.lower():
            #     # Exemple: generic_reminders.create_reminder(title="acheter du lait", time_of_day="18:00:00")
            #     response_text = "Je peux cr√©er des rappels. Dis-moi ce que je dois te rappeler et quand. Par exemple: 'Rappelle-moi d'appeler Maman demain √† 14h'."
            
            # Pour cette version, on va juste informer l'utilisateur de la capacit√©
            response_text = "Je peux t'aider avec les alarmes, minuteurs et rappels ! Dis-moi par exemple : 'Mets une alarme √† 7h du matin' ou 'Rappelle-moi d'acheter du lait √† 18h'."

        except Exception as e:
            log_message(f"Erreur lors de l'appel de l'outil Clock/Reminders: {e}", level="error")
            response_text = f"D√©sol√©, j'ai eu un probl√®me avec les alarmes/rappels: {e}"

    # 2. D√©tection d'intention pour l'ex√©cution de code
    elif "```python" in user_message or "```shell" in user_message or "ex√©cute ce code" in user_message.lower() or "teste ce script" in user_message.lower():
        log_message("Intention d√©tect√©e: Ex√©cution de code.")
        lang_match = re.search(r"```(python|shell)\n(.*?)```", user_message, re.DOTALL)
        if lang_match:
            language = lang_match.group(1)
            code = lang_match.group(2)
            response_text = await run_in_sandbox(code, language)
        else:
            response_text = "Veuillez formater votre code avec des triple backticks et sp√©cifier le langage (ex: ```python\\nprint('Hello')``` ou ```shell\\nls -l```)."
    
    # 3. D√©tection d'intention pour l'analyse de code
    elif "analyse ce code python" in user_message.lower() or "v√©rifie ce script python" in user_message.lower():
        log_message("Intention d√©tect√©e: Analyse de code Python.")
        code_match = re.search(r"```python\n(.*?)```", user_message, re.DOTALL)
        if code_match:
            code = code_match.group(1)
            response_text = await analyze_python_code(code)
        else:
            response_text = "Veuillez fournir le code Python √† analyser format√© avec ```python\\n...```."

    # 4. D√©tection d'intention pour l'OCR
    elif "extraire texte image" in user_message.lower() or "ocr" in user_message.lower() or "lis cette image" in user_message.lower():
        log_message("Intention d√©tect√©e: OCR.")
        url_match = re.search(r'https?://[^\s]+(?:\.jpg|\.jpeg|\.png|\.gif|\.bmp|\.tiff)', user_message, re.IGNORECASE)
        if url_match:
            image_url = url_match.group(0)
            abstract_api_key_info = None
            for key_info in API_KEYS["ABSTRACTAPI"]:
                if key_info.get("type") == "OCR": # Supposons que tu as une cl√© AbstractAPI pour l'OCR
                    abstract_api_key_info = key_info
                    break
            
            if abstract_api_key_info:
                # Utilise le client AbstractAPI pour l'OCR si la cl√© est configur√©e
                # Note: AbstractAPI n'a pas d'API OCR directe dans la configuration fournie.
                # Ceci est un placeholder. Si tu as une vraie API OCR, remplace ceci.
                response_text = "D√©sol√©, je n'ai pas d'API OCR configur√©e directement pour le moment. " \
                                "Si vous avez une cl√© pour AbstractAPI OCR ou une autre API OCR, veuillez l'ajouter."
                # response_text = await perform_ocr(image_url, abstract_api_key_info["key"], abstract_api_key_info["endpoint"])
            else:
                response_text = "Je n'ai pas d'API OCR configur√©e. Veuillez ajouter une cl√© API OCR (ex: Cloudmersive OCR, ou une cl√© AbstractAPI pour OCR si disponible)."
        else:
            response_text = "Veuillez fournir une URL d'image valide (jpg, png, etc.) pour l'extraction de texte."

    # 5. Si aucune intention sp√©cifique, utiliser l'orchestrateur d'IA g√©n√©ral
    else:
        log_message("Intention g√©n√©rale, utilisation de l'orchestrateur d'IA.")
        # L'orchestrateur s√©lectionne la meilleure IA et obtient une r√©ponse
        response_from_ia = await orchestrator.process_query(user_message)
        
        # Si la r√©ponse vient d'une API sp√©cifique, on la retourne directement.
        # Sinon, on la synth√©tise si n√©cessaire (par exemple, si plusieurs sources sont consult√©es).
        # Pour l'instant, on suppose que process_query retourne d√©j√† la meilleure r√©ponse.
        response_text = response_from_ia

    # Nettoyer et corriger la r√©ponse avant de l'envoyer
    final_response = clean_html_tags(response_text)
    final_response = neutralize_urls(final_response)
    final_response = detect_and_correct_toxicity(final_response)

    await update.message.reply_text(final_response)
    memory_manager.add_message_to_history("assistant", final_response)
    log_message(f"R√©ponse envoy√©e √† {user_id}.")


# --- Fonction principale pour d√©marrer le bot ---

async def main() -> None:
    """D√©marre le bot."""
    log_message("D√©marrage du bot Telegram...")
    # Cr√©e l'Application et passe le token de ton bot.
    application = Application.builder().token(TELEGRAM_BOT_TOKEN).build()

    # Ajoute les gestionnaires de commandes
    application.add_handler(CommandHandler("start", start))
    application.add_handler(CommandHandler("help", help_command))
    application.add_handler(CommandHandler("status", status_command))
    application.add_handler(CommandHandler("history", history_command))
    application.add_handler(CommandHandler("quotas", quotas_command))
    application.add_handler(CommandHandler("burn_quota", burn_quota_command))


    # Ajoute le gestionnaire de messages (pour tous les messages texte)
    application.add_handler(MessageHandler(filters.TEXT & ~filters.COMMAND, handle_message))

    # D√©marre le bot
    log_message("Bot pr√™t √† recevoir des messages.")
    await application.run_polling(allowed_updates=Update.ALL_TYPES)

if __name__ == "__main__":
    # Ex√©cute la fonction main() de mani√®re asynchrone
    # Cela permet de lancer le bot et de g√©rer les t√¢ches asynchrones.
    try:
        asyncio.run(main())
    except Exception as e:
        log_message(f"Erreur fatale lors du d√©marrage du bot: {e}", level="error")
        print(f"Une erreur est survenue au d√©marrage du bot: {e}")

# --- FIN DU BLOC BOT TELEGRAM PRINCIPAL ---

import os
from pathlib import Path

# ==============================================================================
# Param√®tres G√©n√©raux du Bot
# ==============================================================================

# Token de votre bot Telegram
BOT_TOKEN = "7902342551:AAG6r1QA2GTMZcmcsWHi36Ivd_PVeMXULOs"

# ID du groupe priv√© o√π le bot enverra des notifications (ex: alertes quotas, archives)
PRIVATE_GROUP_ID = "-1001234567890"

# Message de d√©marrage affich√© dans la console au lancement du bot
STARTUP_MESSAGE = """
===================================================
üöÄ Bot IA D√©marr√© ! üöÄ
Version: 1.0.0
Pr√™t √† interagir. Tapez vos commandes ou questions.
===================================================
"""

# ==============================================================================
# Configuration des Chemins de Fichiers
# ==============================================================================

# R√©pertoire de base pour les donn√©es du bot (logs, historiques, quotas, etc.)
BASE_DIR = Path(__file__).parent.parent / "bot_data"
BASE_DIR.mkdir(parents=True, exist_ok=True)

# Chemin du fichier de log principal
LOG_FILE = BASE_DIR / "bot_activity.log"

# Chemin du fichier de log pour les erreurs critiques
ERROR_LOG_PATH = BASE_DIR / "bot_errors.log"

# Fichier pour stocker l'√©tat de sant√© des endpoints API
ENDPOINT_HEALTH_FILE = BASE_DIR / "endpoint_health.json"

# Fichier pour stocker les informations de quota d'utilisation des APIs
QUOTAS_FILE = BASE_DIR / "api_quotas.json"

# Fichier pour stocker le statut de performance et de diversification des IA
IA_STATUS_FILE = BASE_DIR / "ia_status.json"

# R√©pertoire pour archiver les pages web
ARCHIVES_DIR = "archives"

# Fichier pour stocker l'historique de chat de chaque utilisateur
USER_CHAT_HISTORY_FILE = "chat_history.json"

# Taille maximale des fichiers (ex: images pour OCR) en octets (10 MB)
MAX_FILE_SIZE = 10 * 1024 * 1024
MAX_IMAGE_SIZE = 10 * 1024 * 1024 # Taille maximale pour les images OCR

# ==============================================================================
# Configuration des APIs (Cl√©s et Param√®tres)
# ==============================================================================

# Cl√©s API (Hardcod√©es comme demand√©)
GEMINI_API_KEYS = [
    "YOUR_GEMINI_API_KEY_1",
    "YOUR_GEMINI_API_KEY_2"
]
OCR_API_KEYS = [
    "K8900987654321",
    "K1234567890987"
]
DEEPSEEK_API_KEYS = [
    "sk-ef08317d125947b3a1ce5916592bef00",
    "sk-d73750d96142421cb1098c7056dd7f01"
]
SERPER_API_KEY = "YOUR_SERPER_API_KEY_HERE"
WOLFRAMALPHA_APP_IDS = [
    "YOUR_WOLFRAMALPHA_APP_ID_1",
    "YOUR_WOLFRAMALPHA_APP_ID_2"
]
TAVILY_API_KEYS = [
    "YOUR_TAVILY_API_KEY_1",
    "YOUR_TAVILY_API_KEY_2"
]
APIFLASH_ACCESS_KEY = "YOUR_APIFLASH_ACCESS_KEY_HERE"
CRAWLBASE_API_KEY = "YOUR_CRAWLBASE_API_KEY_HERE"
DETECTLANGUAGE_API_KEY = "YOUR_DETECTLANGUAGE_API_KEY_HERE"
GUARDIAN_API_KEY = "YOUR_GUARDIAN_API_KEY_HERE"
IP2LOCATION_API_KEY = "YOUR_IP2LOCATION_API_KEY_HERE"
SHODAN_API_KEY = "YOUR_SHODAN_API_KEY_HERE"
WEATHERAPI_KEY = "YOUR_WEATHERAPI_KEY_HERE"
CLOUDMERSIVE_API_KEY = "YOUR_CLOUDMERSIVE_API_KEY_HERE"
GREYNOISE_API_KEY = "YOUR_GREYNOISE_API_KEY_HERE"
PULSEDIVE_API_KEY = "YOUR_PULSEDIVE_API_KEY_HERE"
STORMGLASS_API_KEY = "YOUR_STORMGLASS_API_KEY_HERE"
LOGINRADIUS_API_KEY = "YOUR_LOGINRADIUS_API_KEY_HERE"
JSONBIN_API_KEY = "YOUR_JSONBIN_API_KEY_HERE"
HUGGINGFACE_API_KEYS = [
    "hf_YOUR_HUGGINGFACE_API_KEY_1",
    "hf_YOUR_HUGGINGFACE_API_KEY_2"
]
TWILIO_ACCOUNT_SID = "ACxxxxxxxxxxxxxxxxxxxxxxxxxxxxx"
TWILIO_AUTH_TOKEN = "your_twilio_auth_token"
ABSTRACTAPI_API_KEYS = [
    "YOUR_ABSTRACTAPI_API_KEY_1",
    "YOUR_ABSTRACTAPI_API_KEY_2"
]
GOOGLE_CUSTOM_SEARCH_API_KEYS = [
    "YOUR_GOOGLE_CUSTOM_SEARCH_API_KEY_1",
    "YOUR_GOOGLE_CUSTOM_SEARCH_API_KEY_2"
]
GOOGLE_CUSTOM_SEARCH_CX_LIST = [
    "YOUR_GOOGLE_CUSTOM_SEARCH_CX_1",
    "YOUR_GOOGLE_CUSTOM_SEARCH_CX_2"
]
RANDOMMER_API_KEY = "YOUR_RANDOMMER_API_KEY_HERE"
TOMORROWIO_API_KEY = "YOUR_TOMORROWIO_API_KEY_HERE"
OPENWEATHERMAP_API_KEY = "YOUR_OPENWEATHERMAP_API_KEY_HERE"
MOCKAROO_API_KEY = "YOUR_MOCKAROO_API_KEY_HERE"
OPENPAGERANK_API_KEY = "YOUR_OPENPAGERANK_API_KEY_HERE"
RAPIDAPI_KEY = "YOUR_RAPIDAPI_KEY_HERE"


# Configuration d√©taill√©e des endpoints API
API_CONFIG = {
    "GEMINI_API": [
        {
            "endpoint_name": f"Gemini Chat (Key {i+1})",
            "url": "https://generativelanguage.googleapis.com/v1beta/models/gemini-1.5-flash-latest:generateContent",
            "method": "POST",
            "key": key,
            "key_field": "key",
            "key_location": "param",
            "timeout": 60,
            "health_check_params": {"prompt": "test"},
            "health_check_url_suffix": f"?key={key}"
        }
        for i, key in enumerate(GEMINI_API_KEYS)
    ],
    "OCR_API": [
        {
            "endpoint_name": f"OCR.space (Key {i+1})",
            "url": "https://api.ocr.space/parse/image",
            "method": "POST",
            "key": key,
            "key_field": "apikey",
            "key_location": "header",
            "timeout": 30,
            "fixed_headers": {"Content-Type": "application/json"},
            "health_check_json": {"base64Image": "data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAEAAAABCAQAAAC1HAwCAAAAC0lEQVR42mNkYAAAAAYAAjCB0C8AAAAASUVORK5CYII=", "language": "eng"}, # Minimal valid base64 for health check
        }
        for i, key in enumerate(OCR_API_KEYS)
    ],
    "DEEPSEEK": [
        {
            "endpoint_name": f"DeepSeek Chat (Key {i+1})",
            "url": "https://api.deepseek.com/chat/completions",
            "method": "POST",
            "key": key,
            "key_field": "Authorization",
            "key_location": "header",
            "key_prefix": "Bearer ",
            "timeout": 60,
            "fixed_headers": {"Content-Type": "application/json"},
            "health_check_json": {"model": "deepseek-chat", "messages": [{"role": "user", "content": "hi"}]}
        }
        for i, key in enumerate(DEEPSEEK_API_KEYS)
    ],
    "SERPER": [
        {
            "endpoint_name": "Serper Search",
            "url": "https://google.serper.dev/search",
            "method": "POST",
            "key": SERPER_API_KEY,
            "key_field": "X-API-KEY",
            "key_location": "header",
            "timeout": 30,
            "fixed_headers": {"Content-Type": "application/json"},
            "health_check_json": {"q": "test"}
        }
    ],
    "WOLFRAMALPHA": [
        {
            "endpoint_name": f"WolframAlpha Query (App ID {i+1})",
            "url": "http://api.wolframalpha.com/v2/query",
            "method": "GET",
            "key": app_id,
            "key_field": "appid",
            "key_location": "param",
            "timeout": 30,
            "fixed_params": {"output": "json"},
            "health_check_params": {"input": "2+2", "output": "json"}
        }
        for i, app_id in enumerate(WOLFRAMALPHA_APP_IDS)
    ],
    "TAVILY": [
        {
            "endpoint_name": f"Tavily Search (Key {i+1})",
            "url": "https://api.tavily.com/parse",
            "method": "POST",
            "key": key,
            "key_field": "apikey",
            "key_location": "header",
            "timeout": 30,
            "fixed_headers": {"Content-Type": "application/json"},
            "health_check_json": {"query": "test", "max_results": 1}
        }
        for i, key in enumerate(TAVILY_API_KEYS)
    ],
    "APIFLASH": [
        {
            "endpoint_name": "ApiFlash Screenshot",
            "url": "https://api.apiflash.com/v1/urltoimage",
            "method": "GET",
            "key": APIFLASH_ACCESS_KEY,
            "key_field": "access_key",
            "key_location": "param",
            "timeout": 45,
            "health_check_params": {"url": "example.com", "format": "jpeg"}
        }
    ],
    "CRAWLBASE": [
        {
            "endpoint_name": "Crawlbase Scraper",
            "url": "https://api.crawlbase.com/",
            "method": "GET",
            "key": CRAWLBASE_API_KEY,
            "key_field": "token",
            "key_location": "param",
            "timeout": 60,
            "health_check_params": {"url": "http://example.com", "format": "json"}
        },
        {
            "endpoint_name": "Crawlbase JS Scraper",
            "url": "https://api.crawlbase.com/js",
            "method": "GET",
            "key": CRAWLBASE_API_KEY,
            "key_field": "token",
            "key_location": "param",
            "timeout": 90,
            "health_check_params": {"url": "http://example.com", "format": "json"}
        }
    ],
    "DETECTLANGUAGE": [
        {
            "endpoint_name": "DetectLanguage Detect",
            "url": "https://ws.detectlanguage.com/0.2/detect",
            "method": "POST",
            "key": DETECTLANGUAGE_API_KEY,
            "key_field": "X-Detectlanguage-Api-Key",
            "key_location": "header",
            "timeout": 15,
            "fixed_headers": {"Content-Type": "application/json"},
            "health_check_json": {"q": "Hello world"}
        }
    ],
    "GUARDIAN": [
        {
            "endpoint_name": "Guardian Content",
            "url": "https://content.guardianapis.com/search",
            "method": "GET",
            "key": GUARDIAN_API_KEY,
            "key_field": "api-key",
            "key_location": "param",
            "timeout": 20,
            "health_check_params": {"q": "test"}
        }
    ],
    "IP2LOCATION": [
        {
            "endpoint_name": "IP2Location Geolocation",
            "url": "https://api.ip2location.com/v2/",
            "method": "GET",
            "key": IP2LOCATION_API_KEY,
            "key_field": "key",
            "key_location": "param",
            "timeout": 10,
            "health_check_params": {"ip": "8.8.8.8", "addon": "country,city"}
        }
    ],
    "SHODAN": [
        {
            "endpoint_name": "Shodan API Info",
            "url": "https://api.shodan.io/api-info",
            "method": "GET",
            "key": SHODAN_API_KEY,
            "key_field": "key",
            "key_location": "param",
            "timeout": 15,
            "health_check_url_suffix": f"?key={SHODAN_API_KEY}"
        },
        {
            "endpoint_name": "Shodan Host Info",
            "url": "https://api.shodan.io/shodan/host",
            "method": "GET",
            "key": SHODAN_API_KEY,
            "key_field": "key",
            "key_location": "param",
            "timeout": 20,
            "health_check_url_suffix": f"/8.8.8.8?key={SHODAN_API_KEY}"
        }
    ],
    "WEATHERAPI": [
        {
            "endpoint_name": "WeatherAPI Current",
            "url": "http://api.weatherapi.com/v1/current.json",
            "method": "GET",
            "key": WEATHERAPI_KEY,
            "key_field": "key",
            "key_location": "param",
            "timeout": 15,
            "health_check_params": {"q": "London"}
        }
    ],
    "CLOUDMERSIVE": [
        {
            "endpoint_name": "Cloudmersive Validate Domain",
            "url": "https://api.cloudmersive.com/validate/domain/full",
            "method": "POST",
            "key": CLOUDMERSIVE_API_KEY,
            "key_field": "Apikey",
            "key_location": "header",
            "timeout": 20,
            "fixed_headers": {"Content-Type": "application/json"},
            "health_check_json": {"domain": "example.com"}
        }
    ],
    "GREYNOISE": [
        {
            "endpoint_name": "GreyNoise IP Lookup",
            "url": "https://api.greynoise.io/v3/community",
            "method": "GET",
            "key": GREYNOISE_API_KEY,
            "key_field": "key",
            "key_location": "header",
            "timeout": 20,
            "health_check_url_suffix": "/8.8.8.8"
        }
    ],
    "PULSEDIVE": [
        {
            "endpoint_name": "Pulsedive Indicator",
            "url": "https://pulsedive.com/api/v1/indicator.php",
            "method": "GET",
            "key": PULSEDIVE_API_KEY,
            "key_field": "key",
            "key_location": "param",
            "timeout": 25,
            "fixed_params": {"pretty": "1"},
            "health_check_params": {"indicator": "8.8.8.8", "pretty": "1"}
        }
    ],
    "STORMGLASS": [
        {
            "endpoint_name": "StormGlass Weather",
            "url": "https://api.stormglass.io/v2/weather/point",
            "method": "GET",
            "key": STORMGLASS_API_KEY,
            "key_field": "Authorization",
            "key_location": "header",
            "timeout": 30,
            "health_check_params": {"lat": 0, "lng": 0, "params": "airTemperature", "start": 0, "end": 0},
            "health_check_url_suffix": "?lat=0&lng=0&params=airTemperature&start=0&end=0"
        }
    ],
    "LOGINRADIUS": [
        {
            "endpoint_name": "LoginRadius Ping",
            "url": "https://api.loginradius.com/identity/v2/auth/ping",
            "method": "GET",
            "key": LOGINRADIUS_API_KEY,
            "key_field": "apiKey",
            "key_location": "param",
            "timeout": 10,
            "health_check_url_suffix": f"?apiKey={LOGINRADIUS_API_KEY}"
        }
    ],
    "JSONBIN": [
        {
            "endpoint_name": "Bin Create",
            "url": "https://api.jsonbin.io/v3/b",
            "method": "POST",
            "key": JSONBIN_API_KEY,
            "key_field": "X-Master-Key",
            "key_location": "header",
            "timeout": 20,
            "fixed_headers": {"Content-Type": "application/json", "X-Bin-Private": "true"},
            "health_check_json": {"test": "data"}
        },
        {
            "endpoint_name": "Bin Access",
            "url": "https://api.jsonbin.io/v3/b",
            "method": "GET",
            "key": JSONBIN_API_KEY,
            "key_field": "X-Master-Key",
            "key_location": "header",
            "timeout": 20,
            "health_check_url_suffix": "/60c7b9b0f1a9a87d2b7b7b7b"
        }
    ],
    "HUGGINGFACE": [
        {
            "endpoint_name": f"HuggingFace Inference (Key {i+1})",
            "url": "https://api-inference.huggingface.co/models/",
            "method": "POST",
            "key": key,
            "key_field": "Authorization",
            "key_location": "header",
            "key_prefix": "Bearer ",
            "timeout": 60,
            "fixed_headers": {"Content-Type": "application/json"},
            "health_check_url_suffix": "distilbert-base-uncased-finetuned-sst-2-english",
            "health_check_json": {"inputs": "Hello world"}
        }
        for i, key in enumerate(HUGGINGFACE_API_KEYS)
    ],
    "TWILIO": [
        {
            "endpoint_name": "Account Balance",
            "url": f"https://api.twilio.com/2010-04-01/Accounts/{TWILIO_ACCOUNT_SID}/Balance.json",
            "method": "GET",
            "key": (TWILIO_ACCOUNT_SID, TWILIO_AUTH_TOKEN),
            "key_location": "auth_basic",
            "timeout": 20,
            "health_check_url_suffix": ""
        }
    ],
    "ABSTRACTAPI": [
        {
            "endpoint_name": f"Email Validation (Key {i+1})",
            "url": "https://emailvalidation.abstractapi.com/v1/?",
            "method": "GET",
            "key": key,
            "key_field": "api_key",
            "key_location": "param",
            "timeout": 15,
            "health_check_params": {"email": "test@example.com"}
        }
        for i, key in enumerate(ABSTRACTAPI_API_KEYS)
    ] + [
        {
            "endpoint_name": f"Phone Validation (Key {i+1})",
            "url": "https://phonevalidation.abstractapi.com/v1/?",
            "method": "GET",
            "key": key,
            "key_field": "api_key",
            "key_location": "param",
            "timeout": 15,
            "health_check_params": {"phone": "14151234567"}
        }
        for i, key in enumerate(ABSTRACTAPI_API_KEYS)
    ] + [
        {
            "endpoint_name": f"Exchange Rates (Key {i+1})",
            "url": "https://exchangerates.abstractapi.com/v1/live",
            "method": "GET",
            "key": key,
            "key_field": "api_key",
            "key_location": "param",
            "timeout": 15,
            "health_check_params": {"base": "USD"}
        }
        for i, key in enumerate(ABSTRACTAPI_API_KEYS)
    ] + [
        {
            "endpoint_name": f"Holidays (Key {i+1})",
            "url": "https://holidays.abstractapi.com/v1/",
            "method": "GET",
            "key": key,
            "key_field": "api_key",
            "key_location": "param",
            "timeout": 15,
            "health_check_params": {"country": "US", "year": "2023", "month": "1", "day": "1"}
        }
        for i, key in enumerate(ABSTRACTAPI_API_KEYS)
    ],
    "GOOGLE_CUSTOM_SEARCH": [
        {
            "endpoint_name": f"Google Custom Search (API Key {i+1}, CX {j+1})",
            "url": "https://www.googleapis.com/customsearch/v1",
            "method": "GET",
            "key": GOOGLE_CUSTOM_SEARCH_API_KEYS[i],
            "key_field": "key",
            "key_location": "param",
            "timeout": 30,
            "fixed_params": {"cx": GOOGLE_CUSTOM_SEARCH_CX_LIST[j]},
            "health_check_params": {"q": "test", "cx": GOOGLE_CUSTOM_SEARCH_CX_LIST[j]}
        }
        for i in range(len(GOOGLE_CUSTOM_SEARCH_API_KEYS))
        for j in range(len(GOOGLE_CUSTOM_SEARCH_CX_LIST))
    ],
    "RANDOMMER": [
        {
            "endpoint_name": "Randommer Phone Numbers",
            "url": "https://randommer.io/api/Phone/Generate",
            "method": "GET",
            "key": RANDOMMER_API_KEY,
            "key_field": "X-Api-Key",
            "key_location": "header",
            "timeout": 15,
            "fixed_headers": {"Content-Type": "application/json"},
            "health_check_params": {"CountryCode": "US", "Quantity": 1}
        }
    ],
    "TOMORROW.IO": [
        {
            "endpoint_name": "Tomorrow.io Weather",
            "url": "https://api.tomorrow.io/v4/weather/realtime",
            "method": "GET",
            "key": TOMORROWIO_API_KEY,
            "key_field": "apikey",
            "key_location": "param",
            "timeout": 20,
            "health_check_params": {"location": "42.3478,-71.0466", "fields": "temperature"}
        }
    ],
    "OPENWEATHERMAP": [
        {
            "endpoint_name": "OpenWeatherMap Current",
            "url": "https://api.openweathermap.org/data/2.5/weather",
            "method": "GET",
            "key": OPENWEATHERMAP_API_KEY,
            "key_field": "appid",
            "key_location": "param",
            "timeout": 15,
            "health_check_params": {"q": "London"}
        }
    ],
    "MOCKAROO": [
        {
            "endpoint_name": "Mockaroo Generate Data",
            "url": "https://api.mockaroo.com/api/generate.json",
            "method": "GET",
            "key": MOCKAROO_API_KEY,
            "key_field": "key",
            "key_location": "param",
            "timeout": 30,
            "health_check_params": {"count": 1, "fields": '[{"name":"id","type":"Row Number"}]'}
        }
    ],
    "OPENPAGERANK": [
        {
            "endpoint_name": "OpenPageRank Domains",
            "url": "https://openpagerank.com/api/v1.0/getPageRank",
            "method": "GET",
            "key": OPENPAGERANK_API_KEY,
            "key_field": "api_key",
            "key_location": "param",
            "timeout": 20,
            "health_check_params": {"domains[]": ["google.com"]}
        }
    ],
    "RAPIDAPI": [
        {
            "endpoint_name": "RapidAPI Programming Joke",
            "url": "https://programming-jokes-api.p.rapidapi.com/jokes/random",
            "method": "GET",
            "key": RAPIDAPI_KEY,
            "key_field": "X-RapidAPI-Key",
            "key_location": "header",
            "timeout": 20,
            "fixed_headers": {"X-RapidAPI-Host": "programming-jokes-api.p.rapidapi.com"},
            "health_check_url_suffix": ""
        },
        {
            "endpoint_name": "RapidAPI Currency List Quotes",
            "url": "https://currency-exchange.p.rapidapi.com/listquotes",
            "method": "GET",
            "key": RAPIDAPI_KEY,
            "key_field": "X-RapidAPI-Key",
            "key_location": "header",
            "timeout": 20,
            "fixed_headers": {"X-RapidAPI-Host": "currency-exchange.p.rapidapi.com"},
            "health_check_url_suffix": ""
        },
        {
            "endpoint_name": "RapidAPI Random Fact",
            "url": "https://random-facts-api.p.rapidapi.com/api/random",
            "method": "GET",
            "key": RAPIDAPI_KEY,
            "key_field": "X-RapidAPI-Key",
            "key_location": "header",
            "timeout": 20,
            "fixed_headers": {"X-RapidAPI-Host": "random-facts-api.p.rapidapi.com"},
            "health_check_url_suffix": ""
        }
    ]
}

# ==============================================================================
# Configuration des Mod√®les Gemini
# ==============================================================================

# Param√®tres de g√©n√©ration pour l'API Gemini
GEMINI_TEMPERATURE = 0.7
GEMINI_TOP_P = 0.95
GEMINI_TOP_K = 40
GEMINI_MAX_OUTPUT_TOKENS = 8192

# Param√®tres de s√©curit√© pour l'API Gemini
GEMINI_SAFETY_SETTINGS = [
    {"category": "HARM_CATEGORY_HARASSMENT", "threshold": "BLOCK_NONE"},
    {"category": "HARM_CATEGORY_HATE_SPEECH", "threshold": "BLOCK_NONE"},
    {"category": "HARM_CATEGORY_SEXUALLY_EXPLICIT", "threshold": "BLOCK_NONE"},
    {"category": "HARM_CATEGORY_DANGEROUS_CONTENT", "threshold": "BLOCK_NONE"},
]

# ==============================================================================
# Configuration des Outils (Tool Calling)
# ==============================================================================

# D√©finition des outils que le bot peut utiliser via le "Function Calling"
TOOL_CONFIG = {
    "serper_query": {
        "description": "Effectue une recherche web via l'API Serper et retourne les snippets pertinents.",
        "parameters": {
            "type": "object",
            "properties": {
                "query_text": {"type": "string", "description": "La requ√™te de recherche."}
            },
            "required": ["query_text"]
        }
    },
    "wolframalpha_query": {
        "description": "Interroge WolframAlpha pour des calculs, des faits ou des donn√©es complexes.",
        "parameters": {
            "type": "object",
            "properties": {
                "input_text": {"type": "string", "description": "La requ√™te √† soumettre √† WolframAlpha."}
            },
            "required": ["input_text"]
        }
    },
    "tavily_query": {
        "description": "Effectue une recherche web avanc√©e via l'API Tavily, fournissant des extraits et une r√©ponse directe.",
        "parameters": {
            "type": "object",
            "properties": {
                "query_text": {"type": "string", "description": "La requ√™te de recherche."},
                "max_results": {"type": "integer", "description": "Nombre maximum de r√©sultats √† retourner.", "default": 3}
            },
            "required": ["query_text"]
        }
    },
    "run_in_sandbox": {
        "description": "Ex√©cute du code Python ou Shell dans un environnement sandbox simul√© et retourne la sortie.",
        "parameters": {
            "type": "object",
            "properties": {
                "code": {"type": "string", "description": "Le code √† ex√©cuter."},
                "language": {"type": "string", "description": "Le langage du code ('python' ou 'shell').", "enum": ["python", "shell"], "default": "python"}
            },
            "required": ["code"]
        }
    },
    "perform_ocr_api": {
        "description": "Effectue une reconnaissance optique de caract√®res (OCR) sur une image donn√©e par URL et retourne le texte extrait.",
        "parameters": {
            "type": "object",
            "properties": {
                "image_url": {"type": "string", "description": "L'URL de l'image √† traiter par OCR."}
            },
            "required": ["image_url"]
        }
    },
    "fetch_and_archive_pages": {
        "description": "R√©cup√®re le contenu de pages web sp√©cifi√©es, les archive localement et envoie les liens d'archive au groupe priv√©.",
        "parameters": {
            "type": "object",
            "properties": {
                "links": {"type": "array", "items": {"type": "string"}, "description": "Liste des URLs des pages √† archiver."},
                "user_id": {"type": "string", "description": "L'ID de l'utilisateur demandant l'archivage."}
            },
            "required": ["links", "user_id"]
        }
    },
    "ocr_extract_text": {
        "description": "Extrait le texte d'une image encod√©e en base64 en utilisant l'OCR. Utile pour les images directement fournies dans le chat.",
        "parameters": {
            "type": "object",
            "properties": {
                "image_base64": {"type": "string", "description": "L'image encod√©e en base64, incluant le pr√©fixe mimeType (ex: 'data:image/png;base64,...')."}
            },
            "required": ["image_base64"]
        }
    },
    "apiflash_query": {
        "description": "Capture une capture d'√©cran d'une URL via ApiFlash et retourne l'URL de l'image captur√©e.",
        "parameters": {
            "type": "object",
            "properties": {
                "url": {"type": "string", "description": "L'URL de la page √† capturer."}
            },
            "required": ["url"]
        }
    },
    "crawlbase_query": {
        "description": "Scrape le contenu HTML ou JavaScript d'une URL via Crawlbase. Utilisez 'use_js' pour les pages dynamiques.",
        "parameters": {
            "type": "object",
            "properties": {
                "url": {"type": "string", "description": "L'URL de la page √† scraper."},
                "use_js": {"type": "boolean", "description": "D√©finir √† true pour le scraping JavaScript.", "default": False}
            },
            "required": ["url"]
        }
    },
    "detectlanguage_query": {
        "description": "D√©tecte la langue d'un texte via DetectLanguage API.",
        "parameters": {
            "type": "object",
            "properties": {
                "text": {"type": "string", "description": "Le texte dont la langue doit √™tre d√©tect√©e."}
            },
            "required": ["text"]
        }
    },
    "guardian_query": {
        "description": "Recherche des articles de presse via l'API The Guardian.",
        "parameters": {
            "type": "object",
            "properties": {
                "query_text": {"type": "string", "description": "La requ√™te de recherche pour les articles."}
            },
            "required": ["query_text"]
        }
    },
    "ip2location_query": {
        "description": "G√©olocalise une adresse IP via IP2Location API.",
        "parameters": {
            "type": "object",
            "properties": {
                "ip_address": {"type": "string", "description": "L'adresse IP √† g√©olocaliser."}
            },
            "required": ["ip_address"]
        }
    },
    "shodan_query": {
        "description": "Interroge Shodan pour des informations sur un h√¥te IP ou des informations sur la cl√© API.",
        "parameters": {
            "type": "object",
            "properties": {
                "query_text": {"type": "string", "description": "L'adresse IP √† rechercher ou vide pour les infos de la cl√© API."}
            },
            "required": []
        }
    },
    "weatherapi_query": {
        "description": "R√©cup√®re les conditions m√©t√©orologiques actuelles pour une localisation via WeatherAPI.",
        "parameters": {
            "type": "object",
            "properties": {
                "location": {"type": "string", "description": "La ville ou le code postal pour la m√©t√©o."}
            },
            "required": ["location"]
        }
    },
    "cloudmersive_query": {
        "description": "V√©rifie la validit√© et le type d'un domaine via Cloudmersive API.",
        "parameters": {
            "type": "object",
            "properties": {
                "domain": {"type": "string", "description": "Le nom de domaine √† v√©rifier."}
            },
            "required": ["domain"]
        }
    },
    "greynoise_query": {
        "description": "Analyse une adresse IP pour d√©tecter des activit√©s 'bruit' (malveillantes) via GreyNoise.",
        "parameters": {
            "type": "object",
            "properties": {
                "ip_address": {"type": "string", "description": "L'adresse IP √† analyser."}
            },
            "required": ["ip_address"]
        }
    },
    "pulsedive_query": {
        "description": "Analyse un indicateur de menace (IP, domaine, URL) via Pulsedive.",
        "parameters": {
            "type": "object",
            "properties": {
                "indicator": {"type": "string", "description": "L'indicateur de menace √† analyser (IP, domaine, URL)."},
                "type": {"type": "string", "description": "Le type d'indicateur ('auto', 'ip', 'domain', 'url').", "default": "auto"}
            },
            "required": ["indicator"]
        }
    },
    "stormglass_query": {
        "description": "R√©cup√®re les donn√©es m√©t√©orologiques maritimes pour une coordonn√©e (latitude, longitude) via StormGlass.",
        "parameters": {
            "type": "object",
            "properties": {
                "lat": {"type": "number", "format": "float", "description": "La latitude."},
                "lng": {"type": "number", "format": "float", "description": "La longitude."},
                "params": {"type": "string", "description": "Param√®tres m√©t√©o √† r√©cup√©rer (ex: 'airTemperature,waveHeight').", "default": "airTemperature,waveHeight"}
            },
            "required": ["lat", "lng"]
        }
    },
    "loginradius_query": {
        "description": "Effectue un simple ping √† l'API LoginRadius pour v√©rifier sa disponibilit√©.",
        "parameters": {
            "type": "object",
            "properties": {}
        }
    },
    "jsonbin_query": {
        "description": "Cr√©e un nouveau 'bin' JSON ou acc√®de √† un bin existant via Jsonbin.io.",
        "parameters": {
            "type": "object",
            "properties": {
                "data": {"type": "object", "description": "Les donn√©es JSON √† sauvegarder lors de la cr√©ation d'un bin.", "nullable": True},
                "private": {"type": "boolean", "description": "Indique si le bin doit √™tre priv√© (true) ou public (false).", "default": True},
                "bin_id": {"type": "string", "description": "L'ID du bin existant √† acc√©der (si pas de 'data').", "nullable": True}
            },
            "required": []
        }
    },
    "huggingface_query": {
        "description": "Effectue une inf√©rence sur un mod√®le HuggingFace (ex: classification de texte, g√©n√©ration).",
        "parameters": {
            "type": "object",
            "properties": {
                "model_name": {"type": "string", "description": "Le nom du mod√®le HuggingFace √† utiliser (ex: 'distilbert-base-uncased-finetuned-sst-2-english').", "default": "distilbert-base-uncased-finetuned-sst-2-english"},
                "input_text": {"type": "string", "description": "Le texte d'entr√©e pour l'inf√©rence."}
            },
            "required": ["input_text"]
        }
    },
    "twilio_query": {
        "description": "R√©cup√®re le solde du compte Twilio.",
        "parameters": {
            "type": "object",
            "properties": {}
        }
    },
    "abstractapi_query": {
        "description": "Interroge diverses APIs d'AbstractAPI (validation email/t√©l√©phone, taux de change, jours f√©ri√©s).",
        "parameters": {
            "type": "object",
            "properties": {
                "input_value": {"type": "string", "description": "La valeur d'entr√©e (email, num√©ro de t√©l√©phone, code pays, devise de base)."},
                "api_type": {"type": "string", "description": "Le type d'API AbstractAPI √† utiliser ('PHONE_VALIDATION', 'EMAIL_VALIDATION', 'EXCHANGE_RATES', 'HOLIDAYS').", "enum": ["PHONE_VALIDATION", "EMAIL_VALIDATION", "EXCHANGE_RATES", "HOLIDAYS"]}
            },
            "required": ["api_type"]
        }
    },
    "google_custom_search_query": {
        "description": "Effectue une recherche personnalis√©e Google via l'API Custom Search.",
        "parameters": {
            "type": "object",
            "properties": {
                "query_text": {"type": "string", "description": "La requ√™te de recherche."}
            },
            "required": ["query_text"]
        }
    },
    "randommer_query": {
        "description": "G√©n√®re des num√©ros de t√©l√©phone al√©atoires via Randommer.io.",
        "parameters": {
            "type": "object",
            "properties": {
                "country_code": {"type": "string", "description": "Le code pays (ex: 'US', 'FR').", "default": "US"},
                "quantity": {"type": "integer", "description": "Le nombre de num√©ros √† g√©n√©rer.", "default": 1}
            },
            "required": []
        }
    },
    "tomorrowio_query": {
        "description": "R√©cup√®re les pr√©visions m√©t√©orologiques via Tomorrow.io.",
        "parameters": {
            "type": "object",
            "properties": {
                "location": {"type": "string", "description": "La localisation (nom de ville, code postal ou coordonn√©es)."},
                "fields": {"type": "array", "items": {"type": "string"}, "description": "Liste des champs m√©t√©o √† r√©cup√©rer (ex: ['temperature', 'humidity']).", "default": ["temperature", "humidity", "windSpeed"]}
            },
            "required": ["location"]
        }
    },
    "openweathermap_query": {
        "description": "R√©cup√®re les conditions m√©t√©orologiques actuelles pour une localisation via OpenWeatherMap.",
        "parameters": {
            "type": "object",
            "properties": {
                "location": {"type": "string", "description": "La ville ou le code postal pour la m√©t√©o."}
            },
            "required": ["location"]
        }
    },
    "mockaroo_query": {
        "description": "G√©n√®re des donn√©es de test via Mockaroo.",
        "parameters": {
            "type": "object",
            "properties": {
                "count": {"type": "integer", "description": "Le nombre d'enregistrements √† g√©n√©rer.", "default": 1},
                "fields_json": {"type": "string", "description": "Une cha√Æne JSON d√©crivant les champs √† g√©n√©rer (ex: '[{\"name\":\"name\",\"type\":\"Full Name\"}]').", "nullable": True}
            },
            "required": []
        }
    },
    "openpagerank_query": {
        "description": "R√©cup√®re le PageRank de domaines via OpenPageRank.",
        "parameters": {
            "type": "object",
            "properties": {
                "domains": {"type": "array", "items": {"type": "string"}, "description": "Liste des noms de domaine √† v√©rifier."}
            },
            "required": ["domains"]
        }
    },
    "rapidapi_query": {
        "description": "Interroge diverses APIs disponibles via RapidAPI (blagues, taux de change, faits al√©atoires).",
        "parameters": {
            "type": "object",
            "properties": {
                "api_name": {"type": "string", "description": "Le nom de l'API RapidAPI √† utiliser (ex: 'Programming Joke', 'Currency List Quotes', 'Random Fact').", "enum": ["Programming Joke", "Currency List Quotes", "Random Fact"]},
                "kwargs": {"type": "object", "description": "Arguments suppl√©mentaires sp√©cifiques √† l'API RapidAPI appel√©e.", "additionalProperties": True}
            },
            "required": ["api_name"]
        }
    }
}

# ==============================================================================
# Param√®tres du Chat et de la M√©moire
# ==============================================================================

# Longueur maximale de l'historique du chat √† conserver en m√©moire et sur disque
MAX_CHAT_HISTORY_LENGTH = 20

# ==============================================================================
# Param√®tres des Checks de Sant√© des Endpoints
# ==============================================================================

# Activer ou d√©sactiver les checks de sant√© p√©riodiques des endpoints API
ENABLE_HEALTH_CHECKS = True

# Intervalle en secondes entre chaque ex√©cution des checks de sant√©
HEALTH_CHECK_INTERVAL_SECONDS = 2700

import json
import logging
from datetime import datetime, timezone
from pathlib import Path
import re
import asyncio
import os
from typing import Any, Optional, Dict

# Import des constantes du fichier de configuration
from config import LOG_FILE, ERROR_LOG_PATH, BASE_DIR, MAX_FILE_SIZE, API_CONFIG, TOOL_CONFIG

# ==== Configuration du logging ====
# Configure le logger principal pour le bot
logger = logging.getLogger("bot_logger")
logger.setLevel(logging.INFO)

# Cr√©e le r√©pertoire de base si n√©cessaire
BASE_DIR.mkdir(parents=True, exist_ok=True)

# Gestionnaire pour le fichier de log principal
file_handler = logging.FileHandler(LOG_FILE)
file_handler.setLevel(logging.INFO)
formatter = logging.Formatter('%(asctime)s - %(levelname)s - %(message)s')
file_handler.setFormatter(formatter)
logger.addHandler(file_handler)

# Gestionnaire pour les erreurs critiques (fichier s√©par√©)
error_file_handler = logging.FileHandler(ERROR_LOG_PATH)
error_file_handler.setLevel(logging.ERROR)
error_file_handler.setFormatter(formatter)
logger.addHandler(error_file_handler)

# Gestionnaire pour la console (logs en temps r√©el)
console_handler = logging.StreamHandler()
console_handler.setLevel(logging.INFO)
console_handler.setFormatter(formatter)
logger.addHandler(console_handler)

# Verrou pour les op√©rations de fichier asynchrones
_file_lock: Optional[asyncio.Lock] = None

def set_file_lock(lock: asyncio.Lock):
    """D√©finit l'instance du verrou asyncio pour les op√©rations de fichier."""
    global _file_lock
    _file_lock = lock

def log_message(message: str, level: str = "info"):
    """
    Enregistre un message dans le fichier de log et la console.
    Args:
        message (str): Le message √† enregistrer.
        level (str): Le niveau de log ('debug', 'info', 'warning', 'error', 'critical').
    """
    if level == "debug":
        logger.debug(message)
    elif level == "info":
        logger.info(message)
    elif level == "warning":
        logger.warning(message)
    elif level == "error":
        logger.error(message)
    elif level == "critical":
        logger.critical(message)
    else:
        logger.info(f"Niveau de log inconnu '{level}': {message}")

def get_current_time() -> datetime:
    """Retourne l'heure actuelle en UTC."""
    return datetime.now(timezone.utc)

def format_datetime(dt: datetime) -> str:
    """Formate un objet datetime en cha√Æne de caract√®res lisible."""
    return dt.strftime("%Y-%m-%d %H:%M:%S UTC")

async def load_json(file_path: Path, default_value: Any = None) -> Any:
    """
    Charge les donn√©es d'un fichier JSON de mani√®re asynchrone.
    Cr√©e le fichier avec une valeur par d√©faut si inexistant.
    Args:
        file_path (Path): Le chemin du fichier JSON.
        default_value (Any): La valeur √† retourner si le fichier n'existe pas ou est vide.
    Returns:
        Any: Le contenu du fichier JSON ou la valeur par d√©faut.
    """
    if _file_lock is None:
        log_message("Le verrou de fichier n'est pas initialis√© dans utils.py. Initialisation par d√©faut.", level="warning")
        global _file_lock
        _file_lock = asyncio.Lock()

    try:
        if not file_path.exists():
            log_message(f"Fichier non trouv√©: {file_path}. Cr√©ation avec valeur par d√©faut.", level="info")
            await save_json(file_path, default_value if default_value is not None else {})
            return default_value if default_value is not None else {}
        
        async with _file_lock:
            return await asyncio.to_thread(_load_json_sync, file_path)
    except json.JSONDecodeError:
        log_message(f"Erreur de d√©codage JSON pour le fichier: {file_path}. Le fichier pourrait √™tre corrompu. Retourne la valeur par d√©faut.", level="error")
        await save_json(file_path, default_value if default_value is not None else {})
        return default_value if default_value is not None else {}
    except Exception as e:
        log_message(f"Erreur inattendue lors du chargement du JSON {file_path}: {e}", level="error")
        return default_value if default_value is not None else {}

def _load_json_sync(file_path: Path) -> Any:
    """Fonction synchrone pour charger le JSON, appel√©e par asyncio.to_thread."""
    with open(file_path, 'r', encoding='utf-8') as f:
        return json.load(f)

async def save_json(file_path: Path, data: Any):
    """
    Sauvegarde les donn√©es dans un fichier JSON de mani√®re asynchrone.
    Args:
        file_path (Path): Le chemin du fichier JSON.
        data (Any): Les donn√©es √† sauvegarder.
    """
    if _file_lock is None:
        log_message("Le verrou de fichier n'est pas initialis√© dans utils.py. Initialisation par d√©faut.", level="warning")
        global _file_lock
        _file_lock = asyncio.Lock()

    try:
        file_path.parent.mkdir(parents=True, exist_ok=True)
        
        async with _file_lock:
            await asyncio.to_thread(_save_json_sync, file_path, data)
        log_message(f"Donn√©es sauvegard√©es dans {file_path}", level="debug")
    except Exception as e:
        log_message(f"Erreur lors de la sauvegarde du JSON {file_path}: {e}", level="error")

def _save_json_sync(file_path: Path, data: Any):
    """Fonction synchrone pour sauvegarder le JSON, appel√©e par asyncio.to_thread."""
    with open(file_path, 'w', encoding='utf-8') as f:
        json.dump(data, f, indent=4)

def neutralize_urls(text: str) -> str:
    """
    Remplace les URLs dans le texte par une version neutralis√©e pour √©viter les probl√®mes de s√©curit√©
    ou les tentatives d'acc√®s non d√©sir√©es par le mod√®le.
    """
    url_pattern = re.compile(r'https?://[^\s/$.?#].[^\s]*', re.IGNORECASE)
    
    neutralized_text = url_pattern.sub("[LIEN_NEUTRALIS√â]", text)
    return neutralized_text

def find_tool_by_name(tool_name: str) -> Optional[Dict[str, Any]]:
    """
    Recherche un outil dans TOOL_CONFIG par son nom.
    Args:
        tool_name (str): Le nom de l'outil √† rechercher.
    Returns:
        Optional[Dict[str, Any]]: Le dictionnaire de configuration de l'outil si trouv√©, sinon None.
    """
    return TOOL_CONFIG.get(tool_name)

async def append_to_file(file_path: Path, content: str):
    """
    Ajoute du contenu √† un fichier, en cr√©ant le fichier/r√©pertoire si n√©cessaire.
    G√®re la rotation du fichier si sa taille d√©passe MAX_FILE_SIZE.
    """
    if _file_lock is None:
        log_message("Le verrou de fichier n'est pas initialis√© dans utils.py. Initialisation par d√©faut.", level="warning")
        global _file_lock
        _file_lock = asyncio.Lock()

    file_path.parent.mkdir(parents=True, exist_ok=True)

    if file_path.exists() and file_path.stat().st_size + len(content.encode('utf-8')) > MAX_FILE_SIZE:
        rotate_file(file_path)

    async with _file_lock:
        await asyncio.to_thread(_append_to_file_sync, file_path, content)

def _append_to_file_sync(file_path: Path, content: str):
    """Fonction synchrone pour ajouter du contenu √† un fichier."""
    with open(file_path, 'a', encoding='utf-8') as f:
        f.write(content + "\n")

def rotate_file(file_path: Path):
    """
    Effectue une rotation de fichier simple: renomme le fichier actuel avec un horodatage.
    """
    timestamp = datetime.now(timezone.utc).strftime("%Y%m%d_%H%M%S")
    new_path = file_path.parent / f"{file_path.stem}_{timestamp}{file_path.suffix}"
    try:
        os.rename(file_path, new_path)
        log_message(f"Fichier {file_path.name} renomm√© en {new_path.name} pour rotation.", level="info")
    except OSError as e:
        log_message(f"Erreur lors de la rotation du fichier {file_path.name}: {e}", level="error")

import time
import httpx
import json
import base64
import asyncio
import re 
import traceback
from typing import Dict, Any, Optional, Union, List, Tuple

# Import des constantes et fonctions utilitaires
from config import API_CONFIG, ENDPOINT_HEALTH_FILE, MAX_IMAGE_SIZE, GEMINI_TEMPERATURE, GEMINI_TOP_P, GEMINI_TOP_K, GEMINI_MAX_OUTPUT_TOKENS, GEMINI_SAFETY_SETTINGS
from utils import load_json, save_json, get_current_time, format_datetime, log_message, neutralize_urls

class EndpointHealthManager:
    """
    G√®re la sant√© des endpoints API et s√©lectionne le meilleur endpoint disponible
    en fonction de crit√®res comme la latence, le taux de succ√®s et le nombre d'erreurs.
    C'est un singleton pour s'assurer qu'il n'y a qu'une seule instance de gestionnaire de sant√©.
    """
    _instance = None
    _initialized = False

    def __new__(cls, *args, **kwargs):
        """Impl√©mente le patron de conception Singleton."""
        if cls._instance is None:
            cls._instance = super(cls, cls).__new__(cls)
        return cls._instance

    def __init__(self):
        """Initialise le gestionnaire."""
        if self._initialized:
            return
        self.health_status = {}

    async def init_manager(self):
        """
        Initialise le gestionnaire de sant√© de mani√®re asynchrone.
        Charge l'√©tat de sant√© persistant et s'assure que tous les endpoints sont suivis.
        """
        if not self._initialized:
            self.health_status = await load_json(ENDPOINT_HEALTH_FILE, {})
            self._initialize_health_status()
            self._initialized = True
            log_message("Gestionnaire de sant√© des endpoints initialis√©.")

    def _initialize_health_status(self):
        """
        Initialise ou met √† jour le statut de sant√© pour tous les endpoints configur√©s dans `API_CONFIG`.
        Ajoute les nouveaux endpoints et s'assure que toutes les cl√©s n√©cessaires sont pr√©sentes.
        """
        updated = False
        for service_name, endpoints_config in API_CONFIG.items():
            if service_name not in self.health_status:
                self.health_status[service_name] = {}
                updated = True
            for endpoint_config in endpoints_config:
                endpoint_key = f"{endpoint_config['endpoint_name']}-{str(endpoint_config['key'])}"
                if endpoint_key not in self.health_status[service_name]:
                    self.health_status[service_name][endpoint_key] = {
                        "latency": 0.0,
                        "success_rate": 1.0,
                        "last_checked": None,
                        "error_count": 0,
                        "total_checks": 0,
                        "is_healthy": True
                    }
                    updated = True
        if updated:
            asyncio.create_task(save_json(ENDPOINT_HEALTH_FILE, self.health_status))
            log_message("Statut de sant√© des endpoints initialis√©/mis √† jour.")

    async def run_health_check_for_service(self, service_name: str):
        """
        Ex√©cute des checks de sant√© pour tous les endpoints d'un service donn√©.
        Tente d'appeler l'endpoint avec des param√®tres de sant√© pr√©d√©finis.
        """
        endpoints_config = API_CONFIG.get(service_name)
        if not endpoints_config:
            log_message(f"Aucune configuration d'endpoint trouv√©e pour le service: {service_name}", level="warning")
            return

        log_message(f"Lancement du health check pour le service: {service_name}")
        for endpoint_config in endpoints_config:
            endpoint_key = f"{endpoint_config['endpoint_name']}-{str(endpoint_config['key'])}"
            start_time = time.monotonic()
            success = False
            try:
                request_method = endpoint_config.get("method", "GET")
                url = endpoint_config["url"]
                
                params = endpoint_config.get("health_check_params", endpoint_config.get("fixed_params", {})).copy()
                json_data = endpoint_config.get("health_check_json", endpoint_config.get("fixed_json", {})).copy()
                headers = endpoint_config.get("fixed_headers", {}).copy()
                auth = None
                
                check_timeout = endpoint_config.get("timeout", 5)

                if "health_check_url_suffix" in endpoint_config:
                    url += endpoint_config["health_check_url_suffix"]

                key_field = endpoint_config.get("key_field")
                key_location = endpoint_config.get("key_location")
                key_prefix = endpoint_config.get("key_prefix", "")
                api_key = endpoint_config["key"]

                if key_field and key_location:
                    if key_location == "param":
                        params[key_field] = api_key
                    elif key_location == "header":
                        headers[key_field] = f"{key_prefix}{api_key}"
                    elif key_location == "auth_basic":
                        if isinstance(api_key, tuple) and len(api_key) == 2:
                            auth = httpx.BasicAuth(api_key[0], api_key[1])
                        else:
                            log_message(f"Cl√© API pour auth_basic non valide pour {service_name}:{endpoint_key}", level="error")
                            success = False
                            continue

                async with httpx.AsyncClient(timeout=check_timeout) as client:
                    response = await client.request(request_method, url, params=params, headers=headers, json=json_data, auth=auth)
                    response.raise_for_status()
                    success = True
            except httpx.HTTPStatusError as e:
                log_level = "warning"
                if 400 <= e.response.status_code < 500 and e.response.status_code != 429:
                    log_level = "debug" 
                log_message(f"Health check pour {endpoint_key} ({service_name}) a √©chou√© (HTTP {e.response.status_code}): {e.response.text}", level=log_level)
                success = False
            except httpx.RequestError as e:
                log_message(f"Health check pour {endpoint_key} ({service_name}) a √©chou√© (R√©seau): {e}", level="warning")
                success = False
            except Exception as e:
                log_message(f"Health check pour {endpoint_key} ({service_name}) a √©chou√© (Inattendu): {e}", level="error")
                success = False
            finally:
                latency = time.monotonic() - start_time
                self.update_endpoint_health(service_name, endpoint_key, success, latency)
        log_message(f"Health check termin√© pour le service: {service_name}")

    def update_endpoint_health(self, service_name: str, endpoint_key: str, success: bool, latency: float):
        """
        Met √† jour le statut de sant√© d'un endpoint sp√©cifique.
        Utilise une moyenne glissante pour le taux de succ√®s et la latence.
        """
        if service_name not in self.health_status:
            self.health_status[service_name] = {}
        if endpoint_key not in self.health_status[service_name]:
            self.health_status[service_name][endpoint_key] = {
                "latency": 0.0,
                "success_rate": 1.0,
                "last_checked": None,
                "error_count": 0,
                "total_checks": 0,
                "is_healthy": True
            }

        status = self.health_status[service_name][endpoint_key]
        status["total_checks"] += 1
        status["last_checked"] = format_datetime(get_current_time())

        alpha = 0.1
        if success:
            status["error_count"] = max(0, status["error_count"] - 1)
            status["success_rate"] = status["success_rate"] * (1 - alpha) + 1.0 * alpha
            status["latency"] = status["latency"] * (1 - alpha) + latency * alpha
        else:
            status["error_count"] += 1
            status["success_rate"] = status["success_rate"] * (1 - alpha) + 0.0 * alpha
            status["latency"] = status["latency"] * (1 - alpha) + 10.0 * alpha 

        if status["error_count"] >= 3 or status["success_rate"] < 0.5:
            status["is_healthy"] = False
        else:
            status["is_healthy"] = True
        
        asyncio.create_task(save_json(ENDPOINT_HEALTH_FILE, self.health_status))
        log_message(f"Sant√© de {service_name}:{endpoint_key} mise √† jour: Succ√®s: {success}, Latence: {latency:.2f}s, Taux Succ√®s: {status['success_rate']:.2f}, Sain: {status['is_healthy']}", level="debug" if not status["is_healthy"] else "info")

    def get_best_endpoint(self, service_name: str) -> Optional[Dict]:
        """
        S√©lectionne le meilleur endpoint pour un service donn√© bas√© sur son statut de sant√©.
        Priorise les endpoints sains, puis les moins mauvais en cas d'absence d'endpoints sains.
        """
        service_health = self.health_status.get(service_name)
        if not service_health:
            log_message(f"Aucune donn√©e de sant√© pour le service {service_name}. Retourne None.", level="warning")
            return None

        best_endpoint_key = None
        best_score = -float('inf')

        healthy_endpoints = [
            (key, status) for key, status in service_health.items() if status["is_healthy"]
        ]

        if not healthy_endpoints:
            log_message(f"Aucun endpoint sain pour le service {service_name}. Tentative de s√©lection d'un endpoint non sain.", level="warning")
            all_endpoints = service_health.items()
            if not all_endpoints: 
                return None
            
            sorted_endpoints = sorted(all_endpoints, key=lambda item: (item[1]["error_count"], item[1]["latency"]))
            best_endpoint_key = sorted_endpoints[0][0]
            log_message(f"Fallback: Endpoint {best_endpoint_key} s√©lectionn√© pour {service_name} (non sain).", level="warning")
        else:
            for endpoint_key, status in healthy_endpoints:
                score = (status["success_rate"] * 100) - (status["latency"] * 10) - (status["error_count"] * 5)
                if score > best_score:
                    best_score = score
                    best_endpoint_key = endpoint_key
            log_message(f"Meilleur endpoint s√©lectionn√© pour {service_name}: {best_endpoint_key} (Score: {best_score:.2f})")

        if best_endpoint_key:
            for endpoint_config in API_CONFIG.get(service_name, []):
                current_endpoint_key = f"{endpoint_config['endpoint_name']}-{str(endpoint_config['key'])}"
                if current_endpoint_key == best_endpoint_key:
                    return endpoint_config
        return None

# Instancier le gestionnaire de sant√© des endpoints (sera initialis√© dans main.py)
endpoint_health_manager = EndpointHealthManager()

def set_endpoint_health_manager_global(manager: EndpointHealthManager):
    """
    Permet d'injecter l'instance du gestionnaire de sant√© des endpoints.
    Ceci est utilis√© pour s'assurer que tous les clients API utilisent la m√™me instance.
    """
    global endpoint_health_manager
    endpoint_health_manager = manager

class APIClient:
    """
    Classe de base pour tous les clients API.
    Elle g√®re la s√©lection dynamique d'endpoints, les r√©essais en cas d'√©chec
    et l'int√©gration avec le gestionnaire de sant√© des endpoints.
    """
    def __init__(self, name: str, endpoint_health_manager: EndpointHealthManager):
        self.name = name
        self.endpoints_config = API_CONFIG.get(name, [])
        self.endpoint_health_manager = endpoint_health_manager
        if not self.endpoints_config:
            log_message(f"Client API {self.name} initialis√© sans configuration d'endpoint.", level="error")

    async def _make_request(self, params: Optional[Dict] = None, headers: Optional[Dict] = None, 
                            json_data: Optional[Dict] = None, timeout: Optional[int] = None, 
                            max_retries: int = 3, initial_delay: float = 1.0, 
                            url: Optional[str] = None, method: Optional[str] = None, 
                            key_field: Optional[str] = None, key_location: Optional[str] = None, 
                            api_key: Optional[Union[str, Tuple[str, str]]] = None, 
                            fixed_params: Optional[Dict] = None, fixed_headers: Optional[Dict] = None, 
                            fixed_json: Optional[Dict] = None) -> Optional[Union[Dict, str, bytes]]:
        """
        M√©thode interne pour effectuer les requ√™tes HTTP en utilisant le meilleur endpoint avec r√©essais.
        """
        
        selected_endpoint_config = None
        endpoint_key_for_health = "Dynamic"

        if url and method:
            selected_endpoint_config = {
                "url": url,
                "method": method,
                "key_field": key_field,
                "key_location": key_location,
                "key": api_key,
                "fixed_params": fixed_params if fixed_params is not None else {},
                "fixed_headers": fixed_headers if fixed_headers is not None else {},
                "fixed_json": fixed_json if fixed_json is not None else {},
                "endpoint_name": "Dynamic",
                "timeout": timeout if timeout is not None else 30
            }
            if api_key:
                endpoint_key_for_health = f"Dynamic-{str(api_key)}"
            log_message(f"Requ√™te dynamique pour {self.name} vers {url}")
        else:
            selected_endpoint_config = self.endpoint_health_manager.get_best_endpoint(self.name)
            if not selected_endpoint_config:
                log_message(f"Aucun endpoint sain ou disponible pour {self.name}.", level="error")
                return {"error": True, "message": f"Aucun endpoint sain ou disponible pour {self.name}."}
            endpoint_key_for_health = f"{selected_endpoint_config['endpoint_name']}-{str(selected_endpoint_config['key'])}"
            log_message(f"Endpoint s√©lectionn√© pour {self.name}: {selected_endpoint_config['endpoint_name']}")
            timeout = timeout if timeout is not None else selected_endpoint_config.get("timeout", 30)

        url_to_use = selected_endpoint_config["url"]
        method_to_use = selected_endpoint_config["method"]

        request_params = selected_endpoint_config.get("fixed_params", {}).copy()
        request_headers = selected_endpoint_config.get("fixed_headers", {}).copy()
        request_json_data = selected_endpoint_config.get("fixed_json", {}).copy()
        auth = None

        if params:
            request_params.update(params)
        if headers:
            request_headers.update(headers)
        if json_data:
            request_json_data.update(json_data)

        key_field_to_use = selected_endpoint_config.get("key_field")
        key_location_to_use = selected_endpoint_config.get("key_location")
        key_prefix = selected_endpoint_config.get("key_prefix", "")
        api_key_to_use = selected_endpoint_config["key"]

        if key_field_to_use and key_location_to_use:
            if key_location_to_use == "param":
                request_params[key_field_to_use] = api_key_to_use
            elif key_location_to_use == "header":
                request_headers[key_field_to_use] = f"{key_prefix}{api_key_to_use}"
            elif key_location_to_use == "auth_basic":
                if isinstance(api_key_to_use, tuple) and len(api_key_to_use) == 2:
                    auth = httpx.BasicAuth(api_key_to_use[0], api_key_to_use[1])
                else:
                    log_message(f"Cl√© API pour auth_basic non valide pour {self.name}:{endpoint_key_for_health}", level="error")
                    self.endpoint_health_manager.update_endpoint_health(self.name, endpoint_key_for_health, False, 0.0)
                    return {"error": True, "message": "Configuration d'authentification basique invalide."}

        current_delay = initial_delay
        for attempt in range(max_retries):
            start_time = time.monotonic()
            success = False
            try:
                async with httpx.AsyncClient(timeout=timeout) as client:
                    response = await client.request(method_to_use, url_to_use, params=request_params, headers=request_headers, json=request_json_data, auth=auth)
                    response.raise_for_status()
                    success = True
                    
                    content_type = response.headers.get("Content-Type", "").lower()
                    if "application/json" in content_type:
                        try:
                            return response.json()
                        except json.JSONDecodeError:
                            log_message(f"API {self.name} r√©ponse non JSON valide (tentative {attempt+1}/{max_retries}): {response.text[:200]}...", level="warning")
                            if attempt < max_retries - 1:
                                await asyncio.sleep(current_delay)
                                current_delay *= 2
                                continue
                            return {"error": True, "message": "R√©ponse API non JSON valide.", "raw_response": response.text}
                    else:
                        log_message(f"API {self.name} a renvoy√© un Content-Type non JSON: {content_type}", level="info")
                        return response.content

            except httpx.HTTPStatusError as e:
                log_message(f"API {self.name} erreur HTTP (tentative {attempt+1}/{max_retries}): {e.response.status_code} - {e.response.text}", level="warning")
                if 400 <= e.response.status_code < 500 and e.response.status_code != 429:
                    log_message(f"API {self.name}: Erreur client {e.response.status_code}, pas de r√©essai.", level="error")
                    self.endpoint_health_manager.update_endpoint_health(self.name, endpoint_key_for_health, False, e.response.elapsed.total_seconds())
                    return {"error": True, "status_code": e.response.status_code, "message": e.response.text}
                
                if attempt < max_retries - 1:
                    log_message(f"API {self.name}: R√©essai dans {current_delay:.2f}s...", level="info")
                    await asyncio.sleep(current_delay)
                    current_delay *= 2
            except httpx.RequestError as e:
                log_message(f"API {self.name} erreur de requ√™te (tentative {attempt+1}/{max_retries}): {e}", level="warning")
                if attempt < max_retries - 1:
                    log_message(f"API {self.name}: R√©essai dans {current_delay:.2f}s...", level="info")
                    await asyncio.sleep(current_delay)
                    current_delay *= 2
            except Exception as e:
                log_message(f"API {self.name} erreur inattendue (tentative {attempt+1}/{max_retries}): {e}", level="error")
                self.endpoint_health_manager.update_endpoint_health(self.name, endpoint_key_for_health, False, time.monotonic() - start_time)
                return {"error": True, "message": str(e)}
            finally:
                if not success:
                    latency = time.monotonic() - start_time
                    self.endpoint_health_manager.update_endpoint_health(self.name, endpoint_key_for_health, False, latency)
        
        log_message(f"API {self.name}: Toutes les tentatives ont √©chou√© apr√®s {max_retries} r√©essais.", level="error")
        return {"error": True, "message": f"√âchec de la requ√™te apr√®s {max_retries} tentatives."}

    async def query(self, *args, **kwargs) -> Any:
        """
        M√©thode abstraite pour interroger l'API.
        Doit √™tre impl√©ment√©e par chaque sous-classe de client API.
        """
        raise NotImplementedError("La m√©thode query doit √™tre impl√©ment√©e par les sous-classes.")

# --- Clients API Sp√©cifiques ---

class GeminiAPIClient(APIClient):
    """Client pour l'API Gemini, h√©rite de APIClient pour la gestion de sant√©."""
    def __init__(self):
        super().__init__("GEMINI_API", endpoint_health_manager)
        self.model_name = "gemini-1.5-flash-latest"
        self.generation_config = {
            "temperature": GEMINI_TEMPERATURE,
            "top_p": GEMINI_TOP_P,
            "top_k": GEMINI_TOP_K,
            "max_output_tokens": GEMINI_MAX_OUTPUT_TOKENS,
        }
        self.safety_settings = GEMINI_SAFETY_SETTINGS
        log_message(f"GeminiApiClient initialis√© avec le mod√®le par d√©faut: {self.model_name}")

    async def generate_content(self, prompt: str, chat_history: List[Dict], image_data: Optional[str] = None, model: Optional[str] = None, tools: Optional[List[Dict]] = None) -> Union[Dict, str]:
        """G√©n√®re du contenu textuel ou multimodal en utilisant l'API Gemini."""
        model_to_use = model if model else self.model_name
        
        contents = []
        for msg in chat_history:
            role = "user" if msg["role"] == "user" else "model"
            contents.append({"role": role, "parts": msg["parts"]})

        if contents and contents[-1]["role"] == "user":
            contents[-1]["parts"].append({"text": prompt})
        else:
            contents.append({"role": "user", "parts": [{"text": prompt}]})

        if image_data:
            if "," in image_data:
                mime_type_part, base64_data = image_data.split(",", 1)
                mime_type = mime_type_part.split(":", 1)[1].split(";", 1)[0]
            else:
                mime_type = "image/jpeg" 
                base64_data = image_data

            if contents and contents[-1]["role"] == "user":
                contents[-1]["parts"].append({
                    "inlineData": {
                        "mimeType": mime_type,
                        "data": base64_data
                    }
                })
                log_message(f"Image ajout√©e au prompt Gemini (mimeType: {mime_type}).")
            else:
                log_message("Impossible d'ajouter l'image au prompt Gemini: le dernier message n'est pas un utilisateur.", level="warning")

        payload = {
            "contents": contents,
            "generationConfig": self.generation_config,
            "safetySettings": self.safety_settings
        }

        if tools:
            payload["tools"] = tools

        log_message(f"Appel √† Gemini API pour le mod√®le {model_to_use}...")
        
        # L'URL de l'endpoint Gemini peut varier en fonction du mod√®le.
        # On prend l'URL de base du premier endpoint configur√© et on y ajoute le mod√®le.
        base_url_from_config = self.endpoints_config[0]["url"].split(':generateContent')[0]
        dynamic_url = f"{base_url_from_config}:{model_to_use}:generateContent"

        # Les headers et la cl√© API seront g√©r√©s par _make_request via la s√©lection d'endpoint
        response = await self._make_request(
            url=dynamic_url,
            method="POST",
            json_data=payload,
            timeout=60 # Utilise le timeout de la m√©thode _make_request
        )

        if response and not response.get("error"):
            return response
        return f"‚ùå Erreur Gemini: {response.get('message', 'Inconnu')}" if response else "‚ùå Erreur Gemini: R√©ponse vide ou erreur interne."

class OCRApiClient(APIClient):
    """Client pour l'API OCR.space, h√©rite de APIClient pour la gestion de sant√©."""
    def __init__(self):
        super().__init__("OCR_API", endpoint_health_manager)
        log_message("OCRApiClient initialis√©.")

    async def query(self, image_base64: str) -> str:
        """
        Effectue une requ√™te OCR √† l'API OCR.space.
        `image_base64` doit √™tre la cha√Æne base64 de l'image, incluant le pr√©fixe mimeType.
        """
        payload = {
            "base64Image": image_base64,
            "language": "fre",
            "isOverlayRequired": False,
            "OCREngine": 2
        }
        
        # Les headers et la cl√© API seront g√©r√©s par _make_request via la s√©lection d'endpoint
        log_message("Appel √† OCR.space API...")
        response = await self._make_request(
            json_data=payload,
            method="POST",
            timeout=30
        )

        if response and not response.get("error"):
            if response.get("IsErroredOnProcessing"):
                error_message = response.get("ErrorMessage", ["Erreur inconnue lors du traitement OCR."])
                log_message(f"Erreur OCR.space: {error_message}", level="error")
                return f"‚ùå Erreur OCR: {', '.join(error_message)}"
            
            parsed_text = ""
            if "ParsedResults" in response and response["ParsedResults"]:
                for parsed_result in response["ParsedResults"]:
                    parsed_text += parsed_result.get("ParsedText", "") + "\n"
            
            if parsed_text.strip():
                log_message("OCR.space: Texte extrait avec succ√®s.")
                return parsed_text.strip()
            else:
                log_message("OCR.space: Aucun texte extrait.", level="warning")
                return "Aucun texte n'a pu √™tre extrait de l'image."
        return f"‚ùå Erreur OCR: {response.get('message', 'Inconnu')}" if response else "‚ùå Erreur OCR: R√©ponse vide ou erreur interne."

class DeepSeekClient(APIClient):
    def __init__(self):
        super().__init__("DEEPSEEK", endpoint_health_manager)

    async def query(self, prompt: Union[str, List[Dict]], model: str = "deepseek-chat") -> str:
        """Interroge l'API DeepSeek pour des compl√©tions de chat."""
        if isinstance(prompt, str):
            messages = [{"role": "user", "content": prompt}]
        else:
            messages = prompt

        payload = {"model": model, "messages": messages}
        response = await self._make_request(json_data=payload)
        if response and not response.get("error"):
            content = response.get("choices", [{}])[0].get("message", {}).get("content")
            if content:
                return content
            return "DeepSeek: Pas de contenu de r√©ponse trouv√©."
        return f"DeepSeek: Erreur: {response.get('message', 'Inconnu')}" if response else "DeepSeek: R√©ponse vide ou erreur interne."

class SerperClient(APIClient):
    def __init__(self):
        super().__init__("SERPER", endpoint_health_manager)

    async def query(self, query_text: str) -> str:
        """Effectue une recherche web via l'API Serper."""
        payload = {"q": query_text}
        response = await self._make_request(json_data=payload)
        if response and not response.get("error"):
            organic_results = response.get("organic", [])
            if organic_results:
                snippet = organic_results[0].get("snippet", "Pas de snippet.")
                link = organic_results[0].get("link", "")
                return f"Serper (recherche web):\n{snippet} {neutralize_urls(link)}"
            return "Serper: Aucune information trouv√©e."
        return f"Serper: Erreur: {response.get('message', 'Inconnu')}" if response else "Serper: R√©ponse vide ou erreur interne."

class WolframAlphaClient(APIClient):
    def __init__(self):
        super().__init__("WOLFRAMALPHA", endpoint_health_manager)

    async def query(self, input_text: str) -> str:
        """Interroge WolframAlpha pour des calculs ou des faits."""
        params = {"input": input_text}
        response = await self._make_request(params=params)
        if response and not response.get("error"):
            pods = response.get("queryresult", {}).get("pods", [])
            if pods:
                for pod in pods:
                    if pod.get("title") in ["Result", "Input interpretation", "Decimal approximation"]:
                        subpods = pod.get("subpods", [])
                        if subpods and subpods[0].get("plaintext"):
                            return f"WolframAlpha:\n{subpods[0]['plaintext']}"
                if pods and pods[0].get("subpods") and pods[0]["subpods"][0].get("plaintext"):
                    return f"WolframAlpha:\n{pods[0]['subpods'][0]['plaintext']}"
            return "WolframAlpha: Pas de r√©sultat clair."
        return f"WolframAlpha: Erreur: {response.get('message', 'Inconnu')}" if response else "WolframAlpha: R√©ponse vide ou erreur interne."

class TavilyClient(APIClient):
    def __init__(self):
        super().__init__("TAVILY", endpoint_health_manager)

    async def query(self, query_text: str, max_results: int = 3) -> str:
        """Effectue une recherche web avanc√©e via l'API Tavily."""
        payload = {"query": query_text, "max_results": max_results}
        response = await self._make_request(json_data=payload)
        if response and not response.get("error"):
            results = response.get("results", [])
            answer = response.get("answer", "Aucune r√©ponse directe trouv√©e.")

            output = f"Tavily (recherche web):\nR√©ponse directe: {answer}\n"
            if results:
                output += "Extraits pertinents:\n"
                for i, res in enumerate(results[:max_results]):
                    output += f"- {res.get('title', 'N/A')}: {res.get('content', 'N/A')} {neutralize_urls(res.get('url', ''))}\n"
            return output
        return f"Tavily: Erreur: {response.get('message', 'Inconnu')}" if response else "Tavily: R√©ponse vide ou erreur interne."

class ApiFlashClient(APIClient):
    def __init__(self):
        super().__init__("APIFLASH", endpoint_health_manager)

    async def query(self, url: str) -> str:
        """Capture une capture d'√©cran d'une URL via ApiFlash."""
        params = {"url": url, "format": "jpeg", "full_page": "true"}
        response_content = await self._make_request(params=params)

        if isinstance(response_content, bytes):
            selected_endpoint_config = self.endpoint_health_manager.get_best_endpoint(self.name)
            if selected_endpoint_config:
                capture_url = f"{selected_endpoint_config['url']}?access_key={selected_endpoint_config['key']}&url={url}&format=jpeg&full_page=true"
                return f"ApiFlash (capture d'√©cran): {neutralize_urls(capture_url)} (V√©rifiez le lien pour l'image)"
            return "ApiFlash: Impossible de g√©n√©rer l'URL de capture."
        elif isinstance(response_content, dict) and response_content.get("error"):
            return f"ApiFlash: Erreur: {response_content.get('message', 'Inconnu')}"
        else:
            log_message(f"ApiFlash a renvoy√© un type de r√©ponse inattendu: {type(response_content)}", level="warning")
            return f"ApiFlash: R√©ponse inattendue de l'API. {response_content}"

class CrawlbaseClient(APIClient):
    def __init__(self):
        super().__init__("CRAWLBASE", endpoint_health_manager)

    async def query(self, url: str, use_js: bool = False) -> str:
        """Scrape le contenu HTML ou JavaScript d'une URL via Crawlbase."""
        params = {"url": url, "format": "json"}
        
        selected_endpoint_config = None
        if use_js:
            for config in API_CONFIG.get(self.name, []):
                if "JS Scraper" in config.get("endpoint_name", ""):
                    selected_endpoint_config = config
                    break
        
        if not selected_endpoint_config: 
            selected_endpoint_config = self.endpoint_health_manager.get_best_endpoint(self.name)

        if not selected_endpoint_config:
            return f"Crawlbase: Aucun endpoint sain ou disponible pour {self.name}."

        response = await self._make_request(
            params=params,
            url=selected_endpoint_config["url"],
            method=selected_endpoint_config["method"],
            key_field=selected_endpoint_config["key_field"],
            key_location=selected_endpoint_config["key_location"],
            api_key=selected_endpoint_config["key"],
            fixed_params=selected_endpoint_config.get("fixed_params", {}),
            timeout=selected_endpoint_config.get("timeout")
        )

        if response and not response.get("error"):
            body = response.get("body")
            if body:
                try:
                    decoded_body = base64.b64decode(body).decode('utf-8', errors='ignore')
                    return f"Crawlbase (contenu web):\n{decoded_body[:1000]}..."
                except Exception:
                    return f"Crawlbase (contenu web - brut):\n{body[:1000]}..."
            return "Crawlbase: Contenu non trouv√©."
        return f"Crawlbase: Erreur: {response.get('message', 'Inconnu')}" if response else "Crawlbase: R√©ponse vide ou erreur interne."

class DetectLanguageClient(APIClient):
    def __init__(self):
        super().__init__("DETECTLANGUAGE", endpoint_health_manager)

    async def query(self, text: str) -> str:
        """D√©tecte la langue d'un texte via DetectLanguage API."""
        payload = {"q": text}
        response = await self._make_request(json_data=payload)
        if response and not response.get("error"):
            detections = response.get("data", {}).get("detections", [])
            if detections:
                first_detection = detections[0]
                lang = first_detection.get("language")
                confidence = first_detection.get("confidence")
                return f"Langue d√©tect√©e: {lang} (confiance: {confidence})"
            return "DetectLanguage: Aucune langue d√©tect√©e."
        return f"DetectLanguage: Erreur: {response.get('message', 'Inconnu')}" if response else "DetectLanguage: R√©ponse vide ou erreur interne."

class GuardianClient(APIClient):
    def __init__(self):
        super().__init__("GUARDIAN", endpoint_health_manager)

    async def query(self, query_text: str) -> str:
        """Recherche des articles de presse via l'API The Guardian."""
        params = {"q": query_text}
        response = await self._make_request(params=params)
        if response and not response.get("error"):
            results = response.get("response", {}).get("results", [])
            if results:
                output = "Articles The Guardian:\n"
                for res in results[:3]:
                    output += f"- {res.get('webTitle', 'N/A')}: {res.get('fields', {}).get('trailText', 'N/A')} {neutralize_urls(res.get('webUrl', ''))}\n"
                return output
            return "Guardian: Aucun article trouv√©."
        return f"Guardian: Erreur: {response.get('message', 'Inconnu')}" if response else "Guardian: R√©ponse vide ou erreur interne."

class IP2LocationClient(APIClient):
    def __init__(self):
        super().__init__("IP2LOCATION", endpoint_health_manager)

    async def query(self, ip_address: str) -> str:
        """G√©olocalise une adresse IP via IP2Location API."""
        params = {"ip": ip_address}
        response = await self._make_request(params=params)
        if response and not response.get("error"):
            if "country_name" in response:
                return f"IP2Location (G√©olocalisation IP {ip_address}): Pays: {response['country_name']}, Ville: {response.get('city_name', 'N/A')}"
            return "IP2Location: Informations non trouv√©es."
        return f"IP2Location: Erreur: {response.get('message', 'Inconnu')}" if response else "IP2Location: R√©ponse vide ou erreur interne."

class ShodanClient(APIClient):
    def __init__(self):
        super().__init__("SHODAN", endpoint_health_manager)

    async def query(self, query_text: str = "") -> str:
        """
        Interroge Shodan pour des informations sur un h√¥te IP ou des informations sur la cl√© API.
        Si `query_text` est une IP, tente de r√©cup√©rer les infos de l'h√¥te.
        Sinon, ou en cas d'√©chec, retourne les infos de la cl√© API.
        """
        if re.match(r"^\d{1,3}\.\d{1,3}\.\d{1,3}\.\d{1,3}$", query_text):
            selected_endpoint_config = None
            for config in API_CONFIG.get(self.name, []):
                if "Host Info" in config.get("endpoint_name", ""):
                    selected_endpoint_config = config
                    break
            if selected_endpoint_config:
                url = f"{selected_endpoint_config['url'].rstrip('/')}/{query_text}"
                response = await self._make_request(
                    params={"key": selected_endpoint_config["key"]},
                    url=url,
                    method="GET",
                    key_field=selected_endpoint_config["key_field"],
                    key_location=selected_endpoint_config["key_location"],
                    api_key=selected_endpoint_config["key"],
                    timeout=selected_endpoint_config.get("timeout")
                )
                if response and not response.get("error"):
                    return f"Shodan (info h√¥te {query_text}): Pays: {response.get('country_name', 'N/A')}, Ports: {response.get('ports', 'N/A')}, Vuln√©rabilit√©s: {response.get('vulns', 'Aucune')}"
                return f"Shodan (info h√¥te): Erreur: {response.get('message', 'Inconnu')}" if response else "Shodan: R√©ponse vide ou erreur interne."
            else:
                return "Shodan: Endpoint 'Host Info' non configur√©."
        else:
            response = await self._make_request()
            if response and not response.get("error"):
                return f"Shodan (info cl√©): Requ√™tes restantes: {response.get('usage_limits', {}).get('query_credits', 'N/A')}, Scan cr√©dits: {response.get('usage_limits', {}).get('scan_credits', 'N/A')}"
            return f"Shodan: Erreur: {response.get('message', 'Inconnu')}" if response else "Shodan: R√©ponse vide ou erreur interne."

class WeatherAPIClient(APIClient):
    def __init__(self):
        super().__init__("WEATHERAPI", endpoint_health_manager)

    async def query(self, location: str) -> str:
        """R√©cup√®re les conditions m√©t√©orologiques actuelles pour une localisation via WeatherAPI."""
        params = {"q": location}
        response = await self._make_request(params=params)
        if response and not response.get("error"):
            current = response.get("current", {})
            location_info = response.get("location", {})
            if current and location_info:
                return (
                    f"M√©t√©o √† {location_info.get('name', 'N/A')}, {location_info.get('country', 'N/A')}:\n"
                    f"Temp√©rature: {current.get('temp_c', 'N/A')}¬∞C, "
                    f"Conditions: {current.get('condition', {}).get('text', 'N/A')}, "
                    f"Vent: {current.get('wind_kph', 'N/A')} km/h"
                )
            return "WeatherAPI: Donn√©es m√©t√©o non trouv√©es."
        return f"WeatherAPI: Erreur: {response.get('message', 'Inconnu')}" if response else "WeatherAPI: R√©ponse vide ou erreur interne."

class CloudmersiveClient(APIClient):
    def __init__(self):
        super().__init__("CLOUDMERSIVE", endpoint_health_manager)

    async def query(self, domain: str) -> str:
        """V√©rifie la validit√© et le type d'un domaine via Cloudmersive API."""
        payload = {"domain": domain}
        response = await self._make_request(json_data=payload)
        if response and not response.get("error"):
            return f"Cloudmersive (v√©rification de domaine {domain}): Valide: {response.get('ValidDomain', 'N/A')}, Type: {response.get('DomainType', 'N/A')}"
        return f"Cloudmersive: Erreur: {response.get('message', 'Inconnu')}" if response else "Cloudmersive: R√©ponse vide ou erreur interne."

class GreyNoiseClient(APIClient):
    def __init__(self):
        super().__init__("GREYNOISE", endpoint_health_manager)

    async def query(self, ip_address: str) -> str:
        """Analyse une adresse IP pour d√©tecter des activit√©s 'bruit' (malveillantes) via GreyNoise."""
        selected_endpoint_config = self.endpoint_health_manager.get_best_endpoint(self.name)
        if not selected_endpoint_config:
            return f"GreyNoise: Aucun endpoint sain ou disponible pour {self.name}."

        url = f"{selected_endpoint_config['url'].rstrip('/')}/{ip_address}"
        method = selected_endpoint_config["method"]
        headers = {selected_endpoint_config["key_field"]: selected_endpoint_config["key"]}

        response = await self._make_request(
            headers=headers,
            url=url,
            method=method,
            key_field=selected_endpoint_config["key_field"],
            key_location=selected_endpoint_config["key_location"],
            api_key=selected_endpoint_config["key"],
            timeout=selected_endpoint_config.get("timeout")
        )

        if response and not response.get("error"):
            if response.get("noise"):
                return f"GreyNoise (IP {ip_address}): C'est une IP 'bruit' (malveillante). Classification: {response.get('classification', 'N/A')}, Nom d'acteur: {response.get('actor', 'N/A')}"
            return f"GreyNoise (IP {ip_address}): Pas de 'bruit' d√©tect√©. Statut: {response.get('status', 'N/A')}"
        return f"GreyNoise: Erreur: {response.get('message', 'Inconnu')}" if response else "GreyNoise: R√©ponse vide ou erreur interne."

class PulsediveClient(APIClient):
    def __init__(self):
        super().__init__("PULSEDIVE", endpoint_health_manager)

    async def query(self, indicator: str, type: str = "auto") -> str:
        """Analyse un indicateur de menace (IP, domaine, URL) via Pulsedive."""
        params = {"indicator": indicator, "type": type}
        response = await self._make_request(params=params)
        if response and not response.get("error"):
            if response.get("results"):
                result = response["results"][0]
                return (
                    f"Pulsedive (Analyse {indicator}): Type: {result.get('type', 'N/A')}, "
                    f"Risk: {result.get('risk', 'N/A')}, "
                    f"Description: {result.get('description', 'N/A')[:200]}..."
                )
            return "Pulsedive: Aucun r√©sultat d'analyse trouv√©."
        return f"Pulsedive: Erreur: {response.get('message', 'Inconnu')}" if response else "Pulsedive: R√©ponse vide ou erreur interne."

class StormGlassClient(APIClient):
    def __init__(self):
        super().__init__("STORMGLASS", endpoint_health_manager)

    async def query(self, lat: float, lng: float, params: str = "airTemperature,waveHeight") -> str:
        """R√©cup√®re les donn√©es m√©t√©orologiques maritimes pour une coordonn√©e via StormGlass."""
        now = int(time.time())
        request_params = {
            "lat": lat,
            "lng": lng,
            "params": params,
            "start": now,
            "end": now + 3600
        }
        response = await self._make_request(params=request_params)
        if response and not response.get("error"):
            data = response.get("hours", [])
            if data:
                first_hour = data[0]
                temp = first_hour.get('airTemperature', [{}])[0].get('value', 'N/A')
                wave_height = first_hour.get('waveHeight', [{}])[0].get('value', 'N/A')
                return f"StormGlass (M√©t√©o maritime √† {lat},{lng}): Temp√©rature air: {temp}¬∞C, Hauteur vagues: {wave_height}m"
            return "StormGlass: Donn√©es non trouv√©es."
        return f"StormGlass: Erreur: {response.get('message', 'Inconnu')}" if response else "StormGlass: R√©ponse vide ou erreur interne."

class LoginRadiusClient(APIClient):
    def __init__(self):
        super().__init__("LOGINRADIUS", endpoint_health_manager)

    async def query(self) -> str:
        """Effectue un simple ping √† l'API LoginRadius pour v√©rifier sa disponibilit√©."""
        response = await self._make_request()
        if response and not response.get("error"):
            return f"LoginRadius (Ping API): Statut: {response.get('Status', 'N/A')}, Message: {response.get('Message', 'N/A')}"
        return f"LoginRadius: Erreur: {response.get('message', 'Inconnu')}" if response else "LoginRadius: R√©ponse vide ou erreur interne."

class JsonbinClient(APIClient):
    def __init__(self):
        super().__init__("JSONBIN", endpoint_health_manager)

    async def query(self, data: Optional[Dict[str, Any]] = None, private: bool = True, bin_id: Optional[str] = None) -> str:
        """
        Cr√©e un nouveau 'bin' JSON ou acc√®de √† un bin existant via Jsonbin.io.
        `data` est pour la cr√©ation, `bin_id` pour l'acc√®s.
        """
        if bin_id:
            selected_endpoint_config = None
            for config in API_CONFIG.get(self.name, []):
                if "Bin Access" in config.get("endpoint_name", ""):
                    selected_endpoint_config = config
                    break
            if not selected_endpoint_config:
                return f"Jsonbin: Aucun endpoint d'acc√®s de bin sain ou disponible pour {self.name}."

            url = f"{selected_endpoint_config['url'].rstrip('/')}/{bin_id}"
            method = "GET"
            headers = {selected_endpoint_config["key_field"]: selected_endpoint_config["key"]}
            
            response = await self._make_request(
                headers=headers,
                url=url,
                method=method,
                timeout=selected_endpoint_config.get("timeout")
            )
            if response and not response.get("error"):
                return f"Jsonbin (Acc√®s bin {bin_id}):\n{json.dumps(response, indent=2)}"
            return f"Jsonbin (Acc√®s bin): Erreur: {response.get('message', 'Inconnu')}" if response else "Jsonbin: R√©ponse vide ou erreur interne."
        
        else:
            selected_endpoint_config = None
            for config in API_CONFIG.get(self.name, []):
                if "Bin Create" in config.get("endpoint_name", ""):
                    selected_endpoint_config = config
                    break
            
            if not selected_endpoint_config:
                return f"Jsonbin: Aucun endpoint de cr√©ation de bin sain ou disponible pour {self.name}."

            url = selected_endpoint_config["url"]
            method = "POST"
            headers = {selected_endpoint_config["key_field"]: selected_endpoint_config["key"], "Content-Type": "application/json"}
            payload = {"record": data if data is not None else {}, "private": private}

            response = await self._make_request(
                json_data=payload,
                headers=headers,
                url=url,
                method=method,
                timeout=selected_endpoint_config.get("timeout")
            )

            if response and not response.get("error"):
                return f"Jsonbin (Cr√©ation de bin): ID: {response.get('metadata', {}).get('id', 'N/A')}, URL: {neutralize_urls(response.get('metadata', {}).get('url', 'N/A'))}"
            return f"Jsonbin (Cr√©ation de bin): Erreur: {response.get('message', 'Inconnu')}" if response else "Jsonbin: R√©ponse vide ou erreur interne."

class HuggingFaceClient(APIClient):
    def __init__(self):
        super().__init__("HUGGINGFACE", endpoint_health_manager)

    async def query(self, model_name: str = "distilbert-base-uncased-finetuned-sst-2-english", input_text: str = "Hello world") -> str:
        """Effectue une inf√©rence sur un mod√®le HuggingFace (ex: classification de texte, g√©n√©ration)."""
        selected_endpoint_config = self.endpoint_health_manager.get_best_endpoint(self.name)
        if not selected_endpoint_config:
            return f"HuggingFace: Aucun endpoint sain ou disponible pour {self.name}."

        inference_url = f"https://api-inference.huggingface.co/models/{model_name}"
        
        headers = {
            selected_endpoint_config["key_field"]: f"{selected_endpoint_config['key_prefix']}{selected_endpoint_config['key']}",
            "Content-Type": "application/json"
        }
        payload = {"inputs": input_text}

        response = await self._make_request(
            json_data=payload,
            headers=headers,
            url=inference_url,
            method="POST",
            timeout=selected_endpoint_config.get("timeout")
        )

        if response and not response.get("error"):
            if isinstance(response, list) and response:
                first_result = response[0]
                if isinstance(first_result, list) and first_result:
                    return f"HuggingFace ({model_name} - {first_result[0].get('label')}): Score {first_result[0].get('score', 'N/A'):.2f}"
                elif isinstance(first_result, dict) and "generated_text" in first_result:
                    return f"HuggingFace ({model_name}): {first_result.get('generated_text')}"
            return f"HuggingFace ({model_name}): R√©ponse non pars√©e. {response}"
        return f"HuggingFace: Erreur: {response.get('message', 'Inconnu')}" if response else "HuggingFace: R√©ponse vide ou erreur interne."

class TwilioClient(APIClient):
    def __init__(self):
        super().__init__("TWILIO", endpoint_health_manager)

    async def query(self) -> str:
        """R√©cup√®re le solde du compte Twilio."""
        selected_endpoint_config = None
        for config in API_CONFIG.get(self.name, []):
            if "Account Balance" in config.get("endpoint_name", ""):
                selected_endpoint_config = config
                break
        if not selected_endpoint_config:
            if self.endpoints_config:
                selected_endpoint_config = self.endpoints_config[0]
            else:
                return f"Twilio: Aucune configuration d'endpoint disponible pour {self.name}."

        response = await self._make_request(
            url=selected_endpoint_config["url"],
            method=selected_endpoint_config["method"],
            key_location=selected_endpoint_config["key_location"],
            api_key=selected_endpoint_config["key"],
            timeout=selected_endpoint_config.get("timeout")
        )
        if response and not response.get("error"):
            return f"Twilio (Balance): {response.get('balance', 'N/A')} {response.get('currency', 'N/A')}"
        return f"Twilio: Erreur: {response.get('message', 'Inconnu')}" if response else "Twilio: R√©ponse vide ou erreur interne."

class AbstractAPIClient(APIClient):
    def __init__(self):
        super().__init__("ABSTRACTAPI", endpoint_health_manager)

    async def query(self, input_value: str, api_type: str) -> str:
        """
        Interroge diverses APIs d'AbstractAPI (validation email/t√©l√©phone, taux de change, jours f√©ri√©s).
        `input_value` d√©pend du `api_type`.
        """
        params = {}
        target_endpoint_name = ""

        if api_type == "PHONE_VALIDATION":
            params["phone"] = input_value
            target_endpoint_name = "Phone Validation"
        elif api_type == "EMAIL_VALIDATION":
            params["email"] = input_value
            target_endpoint_name = "Email Validation"
        elif api_type == "EXCHANGE_RATES":
            params["base"] = input_value if input_value else "USD" 
            target_endpoint_name = "Exchange Rates"
        elif api_type == "HOLIDAYS":
            params["country"] = input_value if input_value else "US"
            from datetime import datetime
            params["year"] = datetime.now(timezone.utc).year
            target_endpoint_name = "Holidays"
        else:
            return f"AbstractAPI: Type d'API '{api_type}' non support√© pour la requ√™te."

        selected_endpoint_config = None
        for config in API_CONFIG.get(self.name, []):
            if target_endpoint_name in config["endpoint_name"]:
                selected_endpoint_config = config
                break
        
        if not selected_endpoint_config:
            return f"AbstractAPI: Aucun endpoint sain ou disponible pour {self.name} pour le type {api_type}."

        response = await self._make_request(
            params=params,
            url=selected_endpoint_config["url"],
            method=selected_endpoint_config["method"],
            key_field=selected_endpoint_config["key_field"],
            key_location=selected_endpoint_config["key_location"],
            api_key=selected_endpoint_config["key"],
            fixed_params=selected_endpoint_config.get("fixed_params", {}),
            timeout=selected_endpoint_config.get("timeout")
        )

        if response and not response.get("error"):
            if api_type == "PHONE_VALIDATION":
                return (
                    f"AbstractAPI (Validation T√©l): Num√©ro: {response.get('phone', 'N/A')}, "
                    f"Valide: {response.get('valid', 'N/A')}, "
                    f"Pays: {response.get('country', {}).get('name', 'N/A')}"
                )
            elif api_type == "EMAIL_VALIDATION":
                return (
                    f"AbstractAPI (Validation Email): Email: {response.get('email', 'N/A')}, "
                    f"Valide: {response.get('is_valid_format', 'N/A')}, "
                    f"Deliverable: {response.get('is_deliverable', 'N/A')}"
                )
            elif api_type == "EXCHANGE_RATES":
                return f"AbstractAPI (Taux de change): Base: {response.get('base', 'N/A')}, Taux (USD): {response.get('exchange_rates', {}).get('USD', 'N/A')}"
            elif api_type == "HOLIDAYS":
                holidays = [h.get('name', 'N/A') for h in response if h.get('name')]
                return f"AbstractAPI (Jours f√©ri√©s {params.get('country', 'US')} {params.get('year')}): {', '.join(holidays[:5])}..." if holidays else "Aucun jour f√©ri√© trouv√©."
            return f"AbstractAPI ({api_type}): R√©ponse brute: {response}"
        return f"AbstractAPI ({api_type}): Erreur: {response.get('message', 'Inconnu')}" if response else "AbstractAPI: R√©ponse vide ou erreur interne."

class GoogleCustomSearchClient(APIClient):
    def __init__(self):
        super().__init__("GOOGLE_CUSTOM_SEARCH", endpoint_health_manager)

    async def query(self, query_text: str) -> str:
        """Effectue une recherche personnalis√©e Google via l'API Custom Search."""
        params = {"q": query_text}
        response = await self._make_request(params=params)
        if response and not response.get("error"):
            items = response.get("items", [])
            if items:
                output = "Google Custom Search:\n"
                for item in items[:3]:
                    output += f"- {item.get('title', 'N/A')}: {item.get('snippet', 'N/A')} {neutralize_urls(item.get('link', ''))}\n"
                return output
            return "Google Custom Search: Aucun r√©sultat trouv√©."
        return f"Google Custom Search: Erreur: {response.get('message', 'Inconnu')}" if response else "Google Custom Search: R√©ponse vide ou erreur interne."

class RandommerClient(APIClient):
    def __init__(self):
        super().__init__("RANDOMMER", endpoint_health_manager)

    async def query(self, country_code: str = "US", quantity: int = 1) -> str:
        """G√©n√®re des num√©ros de t√©l√©phone al√©atoires via Randommer.io."""
        params = {"CountryCode": country_code, "Quantity": quantity}
        response = await self._make_request(params=params)
        if response and not response.get("error"):
            if isinstance(response, list) and response:
                return f"Randommer (Num√©ros de t√©l√©phone): {', '.join(response)}"
            return f"Randommer: {response}"
        return f"Randommer: Erreur: {response.get('message', 'Inconnu')}" if response else "Randommer: R√©ponse vide ou erreur interne."

class TomorrowIOClient(APIClient):
    def __init__(self):
        super().__init__("TOMORROW.IO", endpoint_health_manager)

    async def query(self, location: str, fields: Optional[List[str]] = None) -> str:
        """R√©cup√®re les pr√©visions m√©t√©orologiques via Tomorrow.io."""
        if fields is None:
            fields = ["temperature", "humidity", "windSpeed"]
        payload = {"location": location, "fields": fields, "units": "metric", "timesteps": ["1h"]}
        response = await self._make_request(json_data=payload)
        if response and not response.get("error"):
            data = response.get("data", {}).get("timelines", [{}])[0].get("intervals", [{}])[0].get("values", {})
            if data:
                output = f"M√©t√©o (Tomorrow.io) √† {location}:\n"
                for field in fields:
                    output += f"- {field.capitalize()}: {data.get(field, 'N/A')}\n"
                return output
            return "Tomorrow.io: Donn√©es m√©t√©o non trouv√©es."
        return f"Tomorrow.io: Erreur: {response.get('message', 'Inconnu')}" if response else "Tomorrow.io: R√©ponse vide ou erreur interne."

class OpenWeatherMapClient(APIClient):
    def __init__(self):
        super().__init__("OPENWEATHERMAP", endpoint_health_manager)

    async def query(self, location: str) -> str:
        """R√©cup√®re les conditions m√©t√©orologiques actuelles via OpenWeatherMap."""
        params = {"q": location}
        response = await self._make_request(params=params)
        if response and not response.get("error"):
            main_data = response.get("main", {})
            weather_desc = response.get("weather", [{}])[0].get("description", "N/A")
            if main_data:
                temp_kelvin = main_data.get('temp', 'N/A')
                feels_like_kelvin = main_data.get('feels_like', 'N/A')
                
                temp_celsius = f"{temp_kelvin - 273.15:.2f}" if isinstance(temp_kelvin, (int, float)) else "N/A"
                feels_like_celsius = f"{feels_like_kelvin - 273.15:.2f}" if isinstance(feels_like_kelvin, (int, float)) else "N/A"

                return (
                    f"M√©t√©o (OpenWeatherMap) √† {location}:\n"
                    f"Temp√©rature: {temp_celsius}¬∞C, "
                    f"Ressenti: {feels_like_celsius}¬∞C, "
                    f"Humidit√©: {main_data.get('humidity', 'N/A')}%, "
                    f"Conditions: {weather_desc}"
                )
            return "OpenWeatherMap: Donn√©es m√©t√©o non trouv√©es."
        return f"OpenWeatherMap: Erreur: {response.get('message', 'Inconnu')}" if response else "OpenWeatherMap: R√©ponse vide ou erreur interne."

class MockarooClient(APIClient):
    def __init__(self):
        super().__init__("MOCKAROO", endpoint_health_manager)

    async def query(self, count: int = 1, fields_json: Optional[str] = None) -> str:
        """G√©n√®re des donn√©es de test via Mockaroo."""
        params = {"count": count}
        if fields_json:
            params["fields"] = fields_json
        response = await self._make_request(params=params)
        if response and not response.get("error"):
            return f"Mockaroo (G√©n√©ration de donn√©es):\n{json.dumps(response, indent=2)}"
        return f"Mockaroo: Erreur: {response.get('message', 'Inconnu')}" if response else "Mockaroo: R√©ponse vide ou erreur interne."

class OpenPageRankClient(APIClient):
    def __init__(self):
        super().__init__("OPENPAGERANK", endpoint_health_manager)

    async def query(self, domains: List[str]) -> str:
        """R√©cup√®re le PageRank de domaines via OpenPageRank."""
        params = {"domains[]": domains}
        response = await self._make_request(params=params)
        if response and not response.get("error"):
            results = response.get("response", [])
            if results:
                output = "OpenPageRank (Classement de domaine):\n"
                for res in results:
                    output += f"- Domaine: {res.get('domain', 'N/A')}, PageRank: {res.get('page_rank', 'N/A')}\n"
                return output
            return "OpenPageRank: Aucun r√©sultat trouv√©."
        return f"OpenPageRank: Erreur: {response.get('message', 'Inconnu')}" if response else "OpenPageRank: R√©ponse vide ou erreur interne."

class RapidAPIClient(APIClient):
    def __init__(self):
        super().__init__("RAPIDAPI", endpoint_health_manager)

    async def query(self, api_name: str, **kwargs) -> str:
        """
        Interroge diverses APIs disponibles via RapidAPI (blagues, taux de change, faits al√©atoires).
        `api_name` sp√©cifie l'API RapidAPI √† utiliser.
        """
        selected_endpoint_config = None
        for config in API_CONFIG.get(self.name, []):
            if api_name.lower() in config["endpoint_name"].lower():
                selected_endpoint_config = config
                break
        
        if not selected_endpoint_config:
            return f"RapidAPI: Endpoint pour '{api_name}' non trouv√© ou non configur√©."

        url = selected_endpoint_config["url"]
        method = selected_endpoint_config["method"]
        
        request_params = selected_endpoint_config.get("fixed_params", {}).copy()
        request_headers = selected_endpoint_config.get("fixed_headers", {}).copy()
        request_json_data = selected_endpoint_config.get("fixed_json", {}).copy()

        if method == "GET":
            request_params.update(kwargs)
        elif method == "POST":
            request_json_data.update(kwargs)

        headers = {
            selected_endpoint_config["key_field"]: selected_endpoint_config["key"],
            "X-RapidAPI-Host": selected_endpoint_config["fixed_headers"].get("X-RapidAPI-Host")
        }
        
        response = await self._make_request(
            params=request_params,
            headers=headers,
            json_data=request_json_data,
            url=url,
            method=method,
            timeout=selected_endpoint_config.get("timeout")
        )

        if response and not response.get("error"):
            if api_name.lower() == "programming joke":
                return f"RapidAPI (Blague de Programmation): {response.get('setup', '')} - {response.get('punchline', '')}"
            elif api_name.lower() == "currency list quotes":
                return f"RapidAPI (Devises): {json.dumps(response, indent=2)}"
            elif api_name.lower() == "random fact":
                return f"RapidAPI (Fait Al√©atoire): {response.get('text', 'N/A')}"
            return f"RapidAPI ({api_name}): {json.dumps(response, indent=2)}"
        return f"RapidAPI ({api_name}): Erreur: {response.get('message', 'Inconnu')}" if response else "RapidAPI: R√©ponse vide ou erreur interne."

# Liste de tous les clients API instanciables
ALL_API_CLIENTS = [
    GeminiAPIClient(),
    OCRApiClient(),
    DeepSeekClient(),
    SerperClient(),
    WolframAlphaClient(),
    TavilyClient(),
    ApiFlashClient(),
    CrawlbaseClient(),
    DetectLanguageClient(),
    GuardianClient(),
    IP2LocationClient(),
    ShodanClient(),
    WeatherAPIClient(),
    CloudmersiveClient(),
    GreyNoiseClient(),
    PulsediveClient(),
    StormGlassClient(),
    LoginRadiusClient(),
    JsonbinClient(),
    HuggingFaceClient(),
    TwilioClient(),
    AbstractAPIClient(),
    GoogleCustomSearchClient(),
    RandommerClient(),
    TomorrowIOClient(),
    OpenWeatherMapClient(),
    MockarooClient(),
    OpenPageRankClient(),
    RapidAPIClient()
]

import asyncio
import json
import re
import base64
from typing import Dict, Any, List, Optional, Union

# Import des clients API
from api_clients import (
    GeminiAPIClient, OCRApiClient, DeepSeekClient, SerperClient,
    WolframAlphaClient, TavilyClient, ApiFlashClient, CrawlbaseClient,
    DetectLanguageClient, GuardianClient, IP2LocationClient, ShodanClient,
    WeatherAPIClient, CloudmersiveClient, GreyNoiseClient, PulsediveClient,
    StormGlassClient, LoginRadiusClient, JsonbinClient, HuggingFaceClient,
    TwilioClient, AbstractAPIClient, GoogleCustomSearchClient,
    RandommerClient, TomorrowIOClient, OpenWeatherMapClient, MockarooClient,
    OpenPageRankClient, RapidAPIClient
)

# Import des fonctions utilitaires
from utils import log_message, neutralize_urls, find_tool_by_name
from config import TOOL_CONFIG

# Instanciation des clients API
gemini_client = GeminiAPIClient()
ocr_client = OCRApiClient()
deepseek_client = DeepSeekClient()
serper_client = SerperClient()
wolfram_alpha_client = WolframAlphaClient()
tavily_client = TavilyClient()
apiflash_client = ApiFlashClient()
crawlbase_client = CrawlbaseClient()
detect_language_client = DetectLanguageClient()
guardian_client = GuardianClient()
ip2location_client = IP2LocationClient()
shodan_client = ShodanClient()
weather_api_client = WeatherAPIClient()
cloudmersive_client = CloudmersiveClient()
greynoise_client = GreyNoiseClient()
pulsedive_client = PulsediveClient()
stormglass_client = StormGlassClient()
loginradius_client = LoginRadiusClient()
jsonbin_client = JsonbinClient()
huggingface_client = HuggingFaceClient()
twilio_client = TwilioClient()
abstractapi_client = AbstractAPIClient()
google_custom_search_client = GoogleCustomSearchClient()
randommer_client = RandommerClient()
tomorrow_io_client = TomorrowIOClient()
openweathermap_client = OpenWeatherMapClient()
mockaroo_client = MockarooClient()
openpagerank_client = OpenPageRankClient()
rapidapi_client = RapidAPIClient()

async def execute_tool(tool_name: str, **kwargs) -> str:
    """
    Ex√©cute un outil sp√©cifique en fonction de son nom et des arguments fournis.
    C'est le point d'entr√©e principal pour l'ex√©cution de toutes les fonctions d'outils.
    """
    log_message(f"Ex√©cution de l'outil: {tool_name} avec kwargs: {kwargs}")
    tool_config = find_tool_by_name(tool_name)

    if not tool_config:
        log_message(f"Outil non trouv√©: {tool_name}", level="error")
        return f"Erreur: Outil '{tool_name}' non trouv√© ou non configur√©."

    try:
        if tool_name == "google_search":
            return await google_search_tool(kwargs.get("queries"))
        elif tool_name == "media_control":
            action = kwargs.get("action")
            if action == "like":
                return await media_control_like_tool()
            elif action == "dislike":
                return await media_control_dislike_tool()
            elif action == "next":
                return await media_control_next_tool()
            elif action == "previous":
                return await media_control_previous_tool()
            elif action == "pause":
                return await media_control_pause_tool()
            elif action == "resume":
                return await media_control_resume_tool()
            elif action == "stop":
                return await media_control_stop_tool()
            elif action == "replay":
                return await media_control_replay_tool()
            elif action == "seek_absolute":
                return await media_control_seek_absolute_tool(kwargs.get("position"))
            elif action == "seek_relative":
                return await media_control_seek_relative_tool(kwargs.get("offset"))
            else:
                return f"Action non support√©e pour media_control: {action}"
        elif tool_name == "clock":
            action = kwargs.get("action")
            if action == "create_alarm":
                return await clock_create_alarm_tool(
                    duration=kwargs.get("duration"),
                    time=kwargs.get("time"),
                    date=kwargs.get("date"),
                    label=kwargs.get("label"),
                    recurrence=kwargs.get("recurrence")
                )
            elif action == "create_timer":
                return await clock_create_timer_tool(
                    duration=kwargs.get("duration"),
                    time=kwargs.get("time"),
                    label=kwargs.get("label")
                )
            elif action == "show_matching_alarms":
                return await clock_show_matching_alarms_tool(
                    query=kwargs.get("query"),
                    alarm_type=kwargs.get("alarm_type"),
                    alarm_ids=kwargs.get("alarm_ids"),
                    date=kwargs.get("date"),
                    start_date=kwargs.get("start_date"),
                    end_date=kwargs.get("end_date")
                )
            elif action == "show_matching_timers":
                return await clock_show_matching_timers_tool(
                    query=kwargs.get("query"),
                    timer_type=kwargs.get("timer_type"),
                    timer_ids=kwargs.get("timer_ids")
                )
            elif action == "modify_alarm_v2":
                return await clock_modify_alarm_v2_tool(
                    alarm_filters=kwargs.get("alarm_filters"),
                    alarm_modifications=kwargs.get("alarm_modifications")
                )
            elif action == "modify_timer_v2":
                return await clock_modify_timer_v2_tool(
                    timer_filters=kwargs.get("timer_filters"),
                    timer_modifications=kwargs.get("timer_modifications")
                )
            elif action == "snooze":
                return await clock_snooze_tool()
            else:
                return f"Action non support√©e pour clock: {action}"
        elif tool_name == "ocr_space":
            return await ocr_space_tool(kwargs.get("image_base64"))
        elif tool_name == "deepseek_chat":
            return await deepseek_chat_tool(kwargs.get("prompt"), kwargs.get("model"))
        elif tool_name == "serper_dev":
            return await serper_dev_tool(kwargs.get("query_text"))
        elif tool_name == "wolfram_alpha":
            return await wolfram_alpha_tool(kwargs.get("input_text"))
        elif tool_name == "tavily_search":
            return await tavily_search_tool(kwargs.get("query_text"), kwargs.get("max_results"))
        elif tool_name == "apiflash_screenshot":
            return await apiflash_screenshot_tool(kwargs.get("url"))
        elif tool_name == "crawlbase_scraper":
            return await crawlbase_scraper_tool(kwargs.get("url"), kwargs.get("use_js"))
        elif tool_name == "detect_language":
            return await detect_language_tool(kwargs.get("text"))
        elif tool_name == "guardian_news":
            return await guardian_news_tool(kwargs.get("query_text"))
        elif tool_name == "ip2location":
            return await ip2location_tool(kwargs.get("ip_address"))
        elif tool_name == "shodan":
            return await shodan_tool(kwargs.get("query_text"))
        elif tool_name == "weather_api":
            return await weather_api_tool(kwargs.get("location"))
        elif tool_name == "cloudmersive_domain":
            return await cloudmersive_domain_tool(kwargs.get("domain"))
        elif tool_name == "greynoise":
            return await greynoise_tool(kwargs.get("ip_address"))
        elif tool_name == "pulsedive":
            return await pulsedive_tool(kwargs.get("indicator"), kwargs.get("type"))
        elif tool_name == "stormglass":
            return await stormglass_tool(kwargs.get("lat"), kwargs.get("lng"), kwargs.get("params"))
        elif tool_name == "loginradius_ping":
            return await loginradius_ping_tool()
        elif tool_name == "jsonbin_io":
            return await jsonbin_io_tool(kwargs.get("data"), kwargs.get("private"), kwargs.get("bin_id"))
        elif tool_name == "huggingface_inference":
            return await huggingface_inference_tool(kwargs.get("model_name"), kwargs.get("input_text"))
        elif tool_name == "twilio_balance":
            return await twilio_balance_tool()
        elif tool_name == "abstractapi":
            return await abstractapi_tool(kwargs.get("input_value"), kwargs.get("api_type"))
        elif tool_name == "google_custom_search":
            return await google_custom_search_tool(kwargs.get("query_text"))
        elif tool_name == "randommer_phone":
            return await randommer_phone_tool(kwargs.get("country_code"), kwargs.get("quantity"))
        elif tool_name == "tomorrow_io_weather":
            return await tomorrow_io_weather_tool(kwargs.get("location"), kwargs.get("fields"))
        elif tool_name == "openweathermap_weather":
            return await openweathermap_weather_tool(kwargs.get("location"))
        elif tool_name == "mockaroo_data":
            return await mockaroo_data_tool(kwargs.get("count"), kwargs.get("fields_json"))
        elif tool_name == "openpagerank":
            return await openpagerank_tool(kwargs.get("domains"))
        elif tool_name == "rapidapi":
            return await rapidapi_tool(kwargs.get("api_name"), **kwargs.get("api_kwargs", {}))
        else:
            log_message(f"Aucun gestionnaire d'outil d√©fini pour: {tool_name}", level="error")
            return f"Erreur: Aucun gestionnaire d'outil d√©fini pour '{tool_name}'."
    except Exception as e:
        log_message(f"Erreur lors de l'ex√©cution de l'outil {tool_name}: {e}", level="error")
        return f"Erreur lors de l'ex√©cution de l'outil {tool_name}: {e}"

# --- Fonctions d'outils sp√©cifiques (wrappers autour des clients API) ---

async def google_search_tool(queries: List[str]) -> str:
    """Effectue une recherche Google."""
    results = []
    for query in queries:
        log_message(f"Recherche Google pour: {query}")
        # Ici, nous utilisons un client g√©n√©rique pour Google Search
        # car il n'y a pas de client sp√©cifique 'google_search' dans api_clients.py
        # Il faudrait soit cr√©er un GoogleSearchClient, soit utiliser un client existant
        # comme SerperClient ou TavilyClient pour simuler la recherche.
        # Pour l'exemple, nous allons simuler une r√©ponse ou utiliser un client de recherche existant.
        # Si 'google_search' est cens√© utiliser Serper ou Tavily, il faut le mapper ici.
        # Supposons que 'google_search' est un alias pour 'serper_dev' pour cet exemple.
        response = await serper_client.query(query)
        results.append(f"R√©sultat pour '{query}': {response}")
    return "\n".join(results)

async def media_control_like_tool() -> str:
    """Aime le m√©dia en cours de lecture."""
    # Simule l'appel √† l'API media_control.like()
    # Dans un vrai sc√©nario, cela appellerait une API de contr√¥le m√©dia sur l'appareil.
    log_message("Action media_control.like() simul√©e.")
    return "M√©dia actuel aim√©."

async def media_control_dislike_tool() -> str:
    """N'aime pas le m√©dia en cours de lecture."""
    log_message("Action media_control.dislike() simul√©e.")
    return "M√©dia actuel non aim√©."

async def media_control_next_tool() -> str:
    """Passe √† l'√©l√©ment multim√©dia suivant."""
    log_message("Action media_control.next() simul√©e.")
    return "Passage au m√©dia suivant."

async def media_control_previous_tool() -> str:
    """Passe √† l'√©l√©ment multim√©dia pr√©c√©dent."""
    log_message("Action media_control.previous() simul√©e.")
    return "Passage au m√©dia pr√©c√©dent."

async def media_control_pause_tool() -> str:
    """Met en pause le m√©dia en cours de lecture."""
    log_message("Action media_control.pause() simul√©e.")
    return "M√©dia actuel mis en pause."

async def media_control_resume_tool() -> str:
    """Reprend la lecture du m√©dia en pause."""
    log_message("Action media_control.resume() simul√©e.")
    return "Lecture du m√©dia reprise."

async def media_control_stop_tool() -> str:
    """Arr√™te le m√©dia en cours de lecture."""
    log_message("Action media_control.stop() simul√©e.")
    return "M√©dia actuel arr√™t√©."

async def media_control_replay_tool() -> str:
    """Rejoue le m√©dia actuel depuis le d√©but."""
    log_message("Action media_control.replay() simul√©e.")
    return "M√©dia actuel rejou√©."

async def media_control_seek_absolute_tool(position: int) -> str:
    """Saute √† une position absolue dans le m√©dia."""
    log_message(f"Action media_control.seek_absolute({position}) simul√©e.")
    return f"M√©dia avanc√© √† la position {position} secondes."

async def media_control_seek_relative_tool(offset: int) -> str:
    """Ajuste la lecture du m√©dia par une dur√©e relative."""
    log_message(f"Action media_control.seek_relative({offset}) simul√©e.")
    return f"M√©dia avanc√© de {offset} secondes."

async def clock_create_alarm_tool(duration: Optional[str] = None, time: Optional[str] = None, date: Optional[str] = None, label: Optional[str] = None, recurrence: Optional[List[str]] = None) -> str:
    """Cr√©e une alarme."""
    # Simule l'appel √† l'API clock.create_alarm()
    log_message(f"Action clock.create_alarm() simul√©e avec dur√©e={duration}, heure={time}, date={date}, label={label}, r√©currence={recurrence}.")
    return f"Alarme cr√©√©e pour {time if time else duration}."

async def clock_create_timer_tool(duration: Optional[str] = None, time: Optional[str] = None, label: Optional[str] = None) -> str:
    """Cr√©e un minuteur."""
    # Simule l'appel √† l'API clock.create_timer()
    log_message(f"Action clock.create_timer() simul√©e avec dur√©e={duration}, heure={time}, label={label}.")
    return f"Minuteur cr√©√© pour {time if time else duration}."

async def clock_show_matching_alarms_tool(query: Optional[str] = None, alarm_type: Optional[str] = None, alarm_ids: Optional[List[str]] = None, date: Optional[str] = None, start_date: Optional[str] = None, end_date: Optional[str] = None) -> str:
    """Affiche les alarmes correspondantes."""
    # Simule l'appel √† l'API clock.show_matching_alarms()
    log_message(f"Action clock.show_matching_alarms() simul√©e avec query={query}, type={alarm_type}, ids={alarm_ids}, date={date}, start_date={start_date}, end_date={end_date}.")
    return "Affichage des alarmes correspondantes (simul√©)."

async def clock_show_matching_timers_tool(query: Optional[str] = None, timer_type: Optional[str] = None, timer_ids: Optional[List[str]] = None) -> str:
    """Affiche les minuteurs correspondants."""
    # Simule l'appel √† l'API clock.show_matching_timers()
    log_message(f"Action clock.show_matching_timers() simul√©e avec query={query}, type={timer_type}, ids={timer_ids}.")
    return "Affichage des minuteurs correspondants (simul√©)."

async def clock_modify_alarm_v2_tool(alarm_filters: Dict[str, Any], alarm_modifications: Dict[str, Any]) -> str:
    """Modifie une alarme."""
    # Simule l'appel √† l'API clock.modify_alarm_v2()
    log_message(f"Action clock.modify_alarm_v2() simul√©e avec filtres={alarm_filters}, modifications={alarm_modifications}.")
    return "Alarme modifi√©e (simul√©)."

async def clock_modify_timer_v2_tool(timer_filters: Dict[str, Any], timer_modifications: Dict[str, Any]) -> str:
    """Modifie un minuteur."""
    # Simule l'appel √† l'API clock.modify_timer_v2()
    log_message(f"Action clock.modify_timer_v2() simul√©e avec filtres={timer_filters}, modifications={timer_modifications}.")
    return "Minuteur modifi√© (simul√©)."

async def clock_snooze_tool() -> str:
    """Met en veille une alarme."""
    # Simule l'appel √† l'API clock.snooze()
    log_message("Action clock.snooze() simul√©e.")
    return "Alarme mise en veille."

async def ocr_space_tool(image_base64: str) -> str:
    """Extrait le texte d'une image via OCR.space."""
    return await ocr_client.query(image_base64)

async def deepseek_chat_tool(prompt: Union[str, List[Dict]], model: str = "deepseek-chat") -> str:
    """Interroge DeepSeek pour des conversations ou compl√©tions."""
    return await deepseek_client.query(prompt, model)

async def serper_dev_tool(query_text: str) -> str:
    """Effectue une recherche web via Serper."""
    return await serper_client.query(query_text)

async def wolfram_alpha_tool(input_text: str) -> str:
    """Interroge WolframAlpha pour des calculs ou des faits."""
    return await wolfram_alpha_client.query(input_text)

async def tavily_search_tool(query_text: str, max_results: int = 3) -> str:
    """Effectue une recherche web avanc√©e via Tavily."""
    return await tavily_client.query(query_text, max_results)

async def apiflash_screenshot_tool(url: str) -> str:
    """Capture une capture d'√©cran d'une URL via ApiFlash."""
    return await apiflash_client.query(url)

async def crawlbase_scraper_tool(url: str, use_js: bool = False) -> str:
    """Scrape le contenu HTML ou JavaScript d'une URL via Crawlbase."""
    return await crawlbase_client.query(url, use_js)

async def detect_language_tool(text: str) -> str:
    """D√©tecte la langue d'un texte via DetectLanguage API."""
    return await detect_language_client.query(text)

async def guardian_news_tool(query_text: str) -> str:
    """Recherche des articles de presse via l'API The Guardian."""
    return await guardian_client.query(query_text)

async def ip2location_tool(ip_address: str) -> str:
    """G√©olocalise une adresse IP via IP2Location API."""
    return await ip2location_client.query(ip_address)

async def shodan_tool(query_text: str = "") -> str:
    """Interroge Shodan pour des informations sur un h√¥te IP ou des informations sur la cl√© API."""
    return await shodan_client.query(query_text)

async def weather_api_tool(location: str) -> str:
    """R√©cup√®re les conditions m√©t√©orologiques actuelles pour une localisation via WeatherAPI."""
    return await weather_api_client.query(location)

async def cloudmersive_domain_tool(domain: str) -> str:
    """V√©rifie la validit√© et le type d'un domaine via Cloudmersive API."""
    return await cloudmersive_client.query(domain)

async def greynoise_tool(ip_address: str) -> str:
    """Analyse une adresse IP pour d√©tecter des activit√©s 'bruit' (malveillantes) via GreyNoise."""
    return await greynoise_client.query(ip_address)

async def pulsedive_tool(indicator: str, type: str = "auto") -> str:
    """Analyse un indicateur de menace (IP, domaine, URL) via Pulsedive."""
    return await pulsedive_client.query(indicator, type)

async def stormglass_tool(lat: float, lng: float, params: str = "airTemperature,waveHeight") -> str:
    """R√©cup√®re les donn√©es m√©t√©orologiques maritimes pour une coordonn√©e via StormGlass."""
    return await stormglass_client.query(lat, lng, params)

async def loginradius_ping_tool() -> str:
    """Effectue un simple ping √† l'API LoginRadius pour v√©rifier sa disponibilit√©."""
    return await loginradius_client.query()

async def jsonbin_io_tool(data: Optional[Dict[str, Any]] = None, private: bool = True, bin_id: Optional[str] = None) -> str:
    """Cr√©e un nouveau 'bin' JSON ou acc√®de √† un bin existant via Jsonbin.io."""
    return await jsonbin_client.query(data, private, bin_id)

async def huggingface_inference_tool(model_name: str = "distilbert-base-uncased-finetuned-sst-2-english", input_text: str = "Hello world") -> str:
    """Effectue une inf√©rence sur un mod√®le HuggingFace."""
    return await huggingface_client.query(model_name, input_text)

async def twilio_balance_tool() -> str:
    """R√©cup√®re le solde du compte Twilio."""
    return await twilio_client.query()

async def abstractapi_tool(input_value: str, api_type: str) -> str:
    """Interroge diverses APIs d'AbstractAPI."""
    return await abstractapi_client.query(input_value, api_type)

async def google_custom_search_tool(query_text: str) -> str:
    """Effectue une recherche personnalis√©e Google."""
    return await google_custom_search_client.query(query_text)

async def randommer_phone_tool(country_code: str = "US", quantity: int = 1) -> str:
    """G√©n√®re des num√©ros de t√©l√©phone al√©atoires via Randommer.io."""
    return await randommer_client.query(country_code, quantity)

async def tomorrow_io_weather_tool(location: str, fields: Optional[List[str]] = None) -> str:
    """R√©cup√®re les pr√©visions m√©t√©orologiques via Tomorrow.io."""
    return await tomorrow_io_client.query(location, fields)

async def openweathermap_weather_tool(location: str) -> str:
    """R√©cup√®re les conditions m√©t√©orologiques actuelles via OpenWeatherMap."""
    return await openweathermap_client.query(location)

async def mockaroo_data_tool(count: int = 1, fields_json: Optional[str] = None) -> str:
    """G√©n√®re des donn√©es de test via Mockaroo."""
    return await mockaroo_client.query(count, fields_json)

async def openpagerank_tool(domains: List[str]) -> str:
    """R√©cup√®re le PageRank de domaines via OpenPageRank."""
    return await openpagerank_client.query(domains)

async def rapidapi_tool(api_name: str, **api_kwargs) -> str:
    """Interroge diverses APIs disponibles via RapidAPI."""
    return await rapidapi_client.query(api_name, **api_kwargs)

import asyncio
import json
import os
import re
import base64
import mimetypes
import datetime
from typing import Dict, Any, List, Optional, Union, Tuple

# Import des modules et fonctions
from config import (
    API_CONFIG, ENDPOINT_HEALTH_FILE, MAX_IMAGE_SIZE,
    GEMINI_TEMPERATURE, GEMINI_TOP_P, GEMINI_TOP_K, GEMINI_MAX_OUTPUT_TOKENS,
    GEMINI_SAFETY_SETTINGS, TOOL_CONFIG
)
from utils import (
    load_json, save_json, get_current_time, format_datetime, log_message,
    neutralize_urls, find_tool_by_name, get_mime_type_from_base64
)
from api_clients import (
    GeminiAPIClient, OCRApiClient, DeepSeekClient, SerperClient,
    WolframAlphaClient, TavilyClient, ApiFlashClient, CrawlbaseClient,
    DetectLanguageClient, GuardianClient, IP2LocationClient, ShodanClient,
    WeatherAPIClient, CloudmersiveClient, GreyNoiseClient, PulsediveClient,
    StormGlassClient, LoginRadiusClient, JsonbinClient, HuggingFaceClient,
    TwilioClient, AbstractAPIClient, GoogleCustomSearchClient,
    RandommerClient, TomorrowIOClient, OpenWeatherMapClient, MockarooClient,
    OpenPageRankClient, RapidAPIClient,
    EndpointHealthManager, set_endpoint_health_manager_global
)
from tools import execute_tool # Import de la fonction execute_tool

# Initialisation du gestionnaire de sant√© des endpoints
endpoint_health_manager = EndpointHealthManager()
set_endpoint_health_manager_global(endpoint_health_manager)

# Instanciation des clients API
gemini_client = GeminiAPIClient()
ocr_client = OCRApiClient()
deepseek_client = DeepSeekClient()
serper_client = SerperClient()
wolfram_alpha_client = WolframAlphaClient()
tavily_client = TavilyClient()
apiflash_client = ApiFlashClient()
crawlbase_client = CrawlbaseClient()
detect_language_client = DetectLanguageClient()
guardian_client = GuardianClient()
ip2location_client = IP2locationClient()
shodan_client = ShodanClient()
weather_api_client = WeatherAPIClient()
cloudmersive_client = CloudmersiveClient()
greynoise_client = GreyNoiseClient()
pulsedive_client = PulsediveClient()
stormglass_client = StormGlassClient()
loginradius_client = LoginRadiusClient()
jsonbin_client = JsonbinClient()
huggingface_client = HuggingFaceClient()
twilio_client = TwilioClient()
abstractapi_client = AbstractAPIClient()
google_custom_search_client = GoogleCustomSearchClient()
randommer_client = RandommerClient()
tomorrow_io_client = TomorrowIOClient()
openweathermap_client = OpenWeatherMapClient()
mockaroo_client = MockarooClient()
openpagerank_client = OpenPageRankClient()
rapidapi_client = RapidAPIClient()


# D√©finition des outils disponibles pour Gemini
def get_gemini_tools() -> List[Dict]:
    """
    Construit la liste des outils disponibles pour l'API Gemini
    √† partir de la configuration TOOL_CONFIG.
    """
    tools = []
    for tool_name, tool_info in TOOL_CONFIG.items():
        if tool_info.get("enabled", False):
            function_declaration = {
                "name": tool_name,
                "description": tool_info.get("description", ""),
                "parameters": {
                    "type": "OBJECT",
                    "properties": {},
                    "required": []
                }
            }
            for param_name, param_info in tool_info.get("parameters", {}).items():
                function_declaration["parameters"]["properties"][param_name] = {
                    "type": param_info.get("type", "STRING"),
                    "description": param_info.get("description", "")
                }
                if param_info.get("required", False):
                    function_declaration["parameters"]["required"].append(param_name)
            
            # Ajout de la gestion des actions pour les outils "clock" et "media_control"
            if tool_name in ["clock", "media_control"]:
                function_declaration["parameters"]["properties"]["action"] = {
                    "type": "STRING",
                    "description": f"L'action √† effectuer pour l'outil {tool_name}."
                }
                function_declaration["parameters"]["required"].append("action")

                # Ajout des sous-param√®tres sp√©cifiques √† chaque action
                for action_name, action_info in tool_info.get("actions", {}).items():
                    # Cr√©e un objet pour les param√®tres sp√©cifiques √† cette action
                    action_params_props = {}
                    action_required_params = []
                    for param_name, param_info in action_info.get("parameters", {}).items():
                        action_params_props[param_name] = {
                            "type": param_info.get("type", "STRING"),
                            "description": param_info.get("description", "")
                        }
                        if param_info.get("required", False):
                            action_required_params.append(param_name)
                    
                    # Ajoute ces param√®tres comme une propri√©t√© conditionnelle ou imbriqu√©e
                    # Gemini ne supporte pas directement les sch√©mas conditionnels pour les outils.
                    # La meilleure approche est de lister tous les param√®tres possibles et de laisser le mod√®le
                    # choisir ceux qui sont pertinents en fonction de l'action.
                    # Ou, pour une meilleure clart√©, cr√©er des fonctions distinctes pour chaque action si possible.
                    # Pour l'instant, on va juste ajouter les param√®tres √† la liste globale.
                    # C'est au mod√®le de comprendre quels param√®tres sont pertinents pour quelle action.
                    function_declaration["parameters"]["properties"].update(action_params_props)
                    function_declaration["parameters"]["required"].extend(action_required_params)
                    
                    # Pour les filtres et modifications complexes (ex: clock.modify_alarm_v2)
                    if action_name in ["modify_alarm_v2", "modify_timer_v2"]:
                        if "alarm_filters" in action_info.get("parameters", {}):
                            function_declaration["parameters"]["properties"]["alarm_filters"] = {
                                "type": "OBJECT",
                                "description": "Filtres pour identifier les alarmes √† modifier.",
                                "properties": action_info["parameters"]["alarm_filters"].get("properties", {}),
                                "required": action_info["parameters"]["alarm_filters"].get("required", [])
                            }
                        if "alarm_modifications" in action_info.get("parameters", {}):
                            function_declaration["parameters"]["properties"]["alarm_modifications"] = {
                                "type": "OBJECT",
                                "description": "Modifications √† apporter aux alarmes.",
                                "properties": action_info["parameters"]["alarm_modifications"].get("properties", {}),
                                "required": action_info["parameters"]["alarm_modifications"].get("required", [])
                            }
                        if "timer_filters" in action_info.get("parameters", {}):
                            function_declaration["parameters"]["properties"]["timer_filters"] = {
                                "type": "OBJECT",
                                "description": "Filtres pour identifier les minuteurs √† modifier.",
                                "properties": action_info["parameters"]["timer_filters"].get("properties", {}),
                                "required": action_info["parameters"]["timer_filters"].get("required", [])
                            }
                        if "timer_modifications" in action_info.get("parameters", {}):
                            function_declaration["parameters"]["properties"]["timer_modifications"] = {
                                "type": "OBJECT",
                                "description": "Modifications √† apporter aux minuteurs.",
                                "properties": action_info["parameters"]["timer_modifications"].get("properties", {}),
                                "required": action_info["parameters"]["timer_modifications"].get("required", [])
                            }

            tools.append({"function_declarations": [function_declaration]})
    return tools

async def process_user_query(user_query: str, chat_history: List[Dict], image_data: Optional[str] = None) -> Tuple[str, List[Dict]]:
    """
    Traite la requ√™te de l'utilisateur, interagit avec Gemini et ex√©cute les outils si n√©cessaire.
    """
    log_message(f"Requ√™te utilisateur: {user_query}")
    log_message(f"Historique du chat (avant): {chat_history}")

    # Initialiser l'historique du chat si vide
    if not chat_history:
        chat_history = []

    # Obtenir les outils disponibles
    gemini_tools = get_gemini_tools()
    log_message(f"Outils disponibles pour Gemini: {json.dumps(gemini_tools, indent=2)}")

    # Appel √† Gemini
    gemini_response = await gemini_client.generate_content(
        prompt=user_query,
        chat_history=chat_history,
        image_data=image_data,
        tools=gemini_tools
    )

    if isinstance(gemini_response, str) and gemini_response.startswith("‚ùå"):
        log_message(f"Erreur de Gemini: {gemini_response}", level="error")
        return gemini_response, chat_history

    if not gemini_response:
        log_message("R√©ponse vide de Gemini.", level="warning")
        return "D√©sol√©, je n'ai pas pu obtenir de r√©ponse de Gemini.", chat_history

    # Traiter la r√©ponse de Gemini
    try:
        if "candidates" in gemini_response and gemini_response["candidates"]:
            candidate = gemini_response["candidates"][0]
            if "content" in candidate and "parts" in candidate["content"]:
                for part in candidate["content"]["parts"]:
                    if "text" in part:
                        # Si Gemini r√©pond avec du texte, l'ajouter √† l'historique et le retourner
                        chat_history.append({"role": "model", "parts": [{"text": part["text"]}]})
                        log_message(f"R√©ponse textuelle de Gemini: {part['text']}")
                        return part["text"], chat_history
                    elif "functionCall" in part:
                        # Si Gemini demande d'appeler une fonction (outil)
                        function_call = part["functionCall"]
                        tool_name = function_call["name"]
                        tool_args = function_call.get("args", {})
                        log_message(f"Gemini a demand√© l'outil: {tool_name} avec args: {tool_args}")

                        # Ex√©cuter l'outil
                        tool_output = await execute_tool(tool_name, **tool_args)
                        log_message(f"Sortie de l'outil {tool_name}: {tool_output}")

                        # Ajouter la requ√™te de l'outil et sa sortie √† l'historique du chat
                        chat_history.append({"role": "model", "parts": [{"functionCall": function_call}]})
                        chat_history.append({"role": "tool", "parts": [{"functionResponse": {"name": tool_name, "response": {"result": tool_output}}}]})

                        # Rappeler Gemini avec l'historique mis √† jour pour obtenir la r√©ponse finale
                        log_message("Rappel de Gemini apr√®s ex√©cution de l'outil...")
                        final_gemini_response = await gemini_client.generate_content(
                            prompt=user_query, # On garde le prompt original pour le contexte
                            chat_history=chat_history,
                            image_data=image_data,
                            tools=gemini_tools
                        )

                        if isinstance(final_gemini_response, str) and final_gemini_response.startswith("‚ùå"):
                            log_message(f"Erreur de Gemini apr√®s ex√©cution de l'outil: {final_gemini_response}", level="error")
                            return final_gemini_response, chat_history
                        
                        if not final_gemini_response:
                            log_message("R√©ponse vide de Gemini apr√®s ex√©cution de l'outil.", level="warning")
                            return "D√©sol√©, je n'ai pas pu obtenir de r√©ponse de Gemini apr√®s l'ex√©cution de l'outil.", chat_history

                        if "candidates" in final_gemini_response and final_gemini_response["candidates"]:
                            final_candidate = final_gemini_response["candidates"][0]
                            if "content" in final_candidate and "parts" in final_candidate["content"]:
                                for final_part in final_candidate["content"]["parts"]:
                                    if "text" in final_part:
                                        chat_history.append({"role": "model", "parts": [{"text": final_part["text"]}]})
                                        log_message(f"R√©ponse finale de Gemini: {final_part['text']}")
                                        return final_part["text"], chat_history
                                    else:
                                        log_message(f"Partie de r√©ponse finale inattendue de Gemini: {final_part}", level="warning")
                                        return "D√©sol√©, je n'ai pas pu traiter la r√©ponse finale de Gemini.", chat_history
                        log_message("Aucune r√©ponse textuelle finale de Gemini apr√®s ex√©cution de l'outil.", level="warning")
                        return "D√©sol√©, je n'ai pas pu obtenir de r√©ponse textuelle finale de Gemini apr√®s l'ex√©cution de l'outil.", chat_history
            log_message("Aucune partie de contenu valide trouv√©e dans la r√©ponse de Gemini.", level="warning")
            return "D√©sol√©, je n'ai pas pu comprendre la r√©ponse de Gemini.", chat_history
        log_message(f"Aucun candidat valide dans la r√©ponse de Gemini: {gemini_response}", level="warning")
        return "D√©sol√©, Gemini n'a pas fourni de r√©ponse valide.", chat_history
    except Exception as e:
        log_message(f"Erreur lors du traitement de la r√©ponse de Gemini: {e}", level="error")
        log_message(f"Traceback: {traceback.format_exc()}", level="error")
        return f"Une erreur interne est survenue lors du traitement de la r√©ponse: {e}", chat_history

async def main():
    """Fonction principale pour ex√©cuter le chatbot."""
    await endpoint_health_manager.init_manager()
    log_message("D√©marrage du chatbot. Tapez 'quitter' pour arr√™ter.")

    # Lancer les checks de sant√© p√©riodiques en arri√®re-plan
    async def periodic_health_checks():
        while True:
            for service_name in API_CONFIG.keys():
                await endpoint_health_manager.run_health_check_for_service(service_name)
            await asyncio.sleep(300) # V√©rifier toutes les 5 minutes

    asyncio.create_task(periodic_health_checks())

    chat_history = []
    
    # Charger l'historique de chat pr√©c√©dent si disponible
    try:
        if os.path.exists("chat_history.json"):
            with open("chat_history.json", "r", encoding="utf-8") as f:
                loaded_history = json.load(f)
                # S'assurer que les r√¥les sont corrects pour Gemini
                for entry in loaded_history:
                    if entry.get("role") == "user" or entry.get("role") == "model":
                        chat_history.append(entry)
                    elif entry.get("role") == "tool":
                        # Gemini attend functionResponse dans "parts" pour les outils
                        if "functionCall" in entry.get("parts", [{}])[0]:
                            # C'est une requ√™te d'outil, pas une r√©ponse
                            chat_history.append(entry)
                        elif "functionResponse" in entry.get("parts", [{}])[0]:
                            chat_history.append(entry)
                        else:
                            log_message(f"Entr√©e d'historique d'outil inattendue: {entry}", level="warning")
                            # Tenter de convertir si c'est un format ancien
                            if "tool_code" in entry.get("parts", [{}])[0]:
                                tool_code_str = entry["parts"][0]["tool_code"]
                                # Extraire le nom de l'outil et la sortie
                                match = re.search(r"print\((\w+)\.([\w_]+)\((.*)\)\)", tool_code_str)
                                if match:
                                    tool_api_name = match.group(1)
                                    tool_method_name = match.group(2)
                                    # Pour l'historique, on a besoin du nom de l'outil tel que d√©fini dans TOOL_CONFIG
                                    # Il faut une meilleure fa√ßon de mapper les m√©thodes API aux noms d'outils.
                                    # Pour l'instant, on va juste utiliser le nom de la m√©thode comme nom d'outil.
                                    tool_name_for_history = tool_method_name 
                                    
                                    # Simuler la r√©ponse de l'outil
                                    tool_response_content = entry.get("parts", [{}])[1].get("text", "R√©ponse outil non sp√©cifi√©e.")
                                    chat_history.append({
                                        "role": "tool",
                                        "parts": [{
                                            "functionResponse": {
                                                "name": tool_name_for_history,
                                                "response": {"result": tool_response_content}
                                            }
                                        }]
                                    })
                                else:
                                    log_message(f"Impossible de parser l'entr√©e tool_code: {tool_code_str}", level="warning")
                            else:
                                log_message(f"Entr√©e d'historique d'outil non reconnue: {entry}", level="warning")

                log_message("Historique du chat charg√© avec succ√®s.")
    except Exception as e:
        log_message(f"Erreur lors du chargement de l'historique du chat: {e}", level="error")
        chat_history = [] # R√©initialiser en cas d'erreur

    while True:
        user_input = input("Vous: ")
        if user_input.lower() == "quitter":
            break

        image_path = None
        image_data = None
        
        # V√©rifier si l'utilisateur a fourni un chemin d'image
        image_match = re.search(r"\[image:(.+)\]", user_input)
        if image_match:
            image_path = image_match.group(1).strip()
            user_input = user_input.replace(image_match.group(0), "").strip() # Supprimer la balise image du prompt

            if os.path.exists(image_path):
                try:
                    with open(image_path, "rb") as image_file:
                        raw_image_data = image_file.read()
                        if len(raw_image_data) > MAX_IMAGE_SIZE:
                            log_message(f"L'image d√©passe la taille maximale autoris√©e ({MAX_IMAGE_SIZE / (1024*1024):.2f} Mo).", level="warning")
                            print(f"‚ö†Ô∏è L'image est trop grande. Taille max: {MAX_IMAGE_SIZE / (1024*1024):.2f} Mo.")
                            image_data = None # Ne pas envoyer l'image si elle est trop grande
                        else:
                            base64_encoded_image = base64.b64encode(raw_image_data).decode('utf-8')
                            mime_type = get_mime_type_from_base64(base64_encoded_image)
                            if mime_type:
                                image_data = f"data:{mime_type};base64,{base64_encoded_image}"
                                log_message(f"Image charg√©e et encod√©e en base64: {image_path} (MIME: {mime_type})")
                            else:
                                log_message(f"Impossible de d√©terminer le type MIME de l'image: {image_path}", level="warning")
                                image_data = base64_encoded_image # Envoyer sans MIME si non d√©tect√©
                except Exception as e:
                    log_message(f"Erreur lors du chargement de l'image {image_path}: {e}", level="error")
                    print(f"‚ùå Erreur lors du chargement de l'image: {e}")
                    image_data = None
            else:
                log_message(f"Fichier image non trouv√©: {image_path}", level="warning")
                print(f"‚ùå Erreur: Fichier image '{image_path}' non trouv√©.")
                image_data = None

        # Ajouter la requ√™te utilisateur √† l'historique
        user_parts = [{"text": user_input}]
        if image_data:
            # Si l'image est incluse, elle sera ajout√©e par generate_content
            pass
        chat_history.append({"role": "user", "parts": user_parts})

        response, chat_history = await process_user_query(user_input, chat_history, image_data)
        print(f"Bot: {response}")

        # Sauvegarder l'historique apr√®s chaque tour
        try:
            # Nettoyer l'historique pour la sauvegarde:
            # - Enlever les donn√©es d'image base64 (trop volumineux, non n√©cessaire pour la persistance)
            # - S'assurer que les objets functionCall/functionResponse sont bien format√©s
            history_to_save = []
            for entry in chat_history:
                new_entry = entry.copy()
                if "parts" in new_entry:
                    new_parts = []
                    for part in new_entry["parts"]:
                        if "inlineData" in part:
                            # Ne pas sauvegarder les donn√©es d'image brutes
                            new_part = part.copy()
                            new_part["inlineData"] = {"mimeType": part["inlineData"]["mimeType"], "data": "[IMAGE_DATA_REMOVED_FOR_SAVE]"}
                            new_parts.append(new_part)
                        else:
                            new_parts.append(part)
                    new_entry["parts"] = new_parts
                history_to_save.append(new_entry)
            
            with open("chat_history.json", "w", encoding="utf-8") as f:
                json.dump(history_to_save, f, indent=2, ensure_ascii=False)
            log_message("Historique du chat sauvegard√©.")
        except Exception as e:
            log_message(f"Erreur lors de la sauvegarde de l'historique du chat: {e}", level="error")

if __name__ == "__main__":
    import traceback
    try:
        asyncio.run(main())
    except KeyboardInterrupt:
        log_message("Chatbot arr√™t√© par l'utilisateur.")
    except Exception as e:
        log_message(f"Une erreur inattendue est survenue: {e}", level="critical")
        log_message(f"Traceback: {traceback.format_exc()}", level="critical")



#!/usr/bin/env python3
import os, sys, json, time, logging, asyncio, re, signal, traceback, httpx, gzip, random, gc, hashlib
from datetime import datetime, timezone, date
from functools import wraps
from pathlib import Path
from collections import OrderedDict
from apscheduler.schedulers.asyncio import AsyncIOScheduler
from telegram import Bot, Update
from telegram.constants import ParseMode
from telegram.ext import ApplicationBuilder, MessageHandler, filters, CommandHandler, ContextTypes
try: import fitz
except: fitz = None

os.environ["TZ"] = "UTC"
semaphore = asyncio.Semaphore(2)
UPDATE_URL = "https://tonlien.com/levraibot.py"
LOCAL_SCRIPT_PATH = Path(__file__)
MAX_FILE_SIZE = 510241024
BASE_DIR = Path("sauvegardes"); BASE_DIR.mkdir(exist_ok=True)
ERROR_LOG_PATH = BASE_DIR / "erreurs.log"
DAILY_CHALLENGE_PATH = Path("defis_code"); DAILY_CHALLENGE_PATH.mkdir(exist_ok=True)

# ===================== CL√âS API EN DUR =====================
BOT_TOKEN = "7902342551:AAG6r1QA2GTMXcmcsWHi36Ivd_PVeMXULOs"
PRIVATE_GROUP_ID = -1002845235344  # <-- V√©rifi√©, bien entier, pas cha√Æne

TAVILY_KEYS = [
    "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",
    "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"
]
SERPER_KEY = "047b30db1df999aaa9c293f2048037d40c651439"
OPENROUTER_KEY = "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"
HF_TOKEN = "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"
WOLFRAM_APP_ID = "96LX77-P9HPAYWRGL"
GOOGLE_API_KEY = "AIzaSyDYaYrQQ7cwYFm8TBpyGM3dJweOGOYl7qw"
GOOGLE_CX_LIST = ["3368510e864b74936", "e745c9ca0ffb94659"]
OCR_API_KEY = "K84281517488957"
OPENWEATHER_API_KEY = "c80075b7332716a418e47033463085ef"
RAPIDAPI_KEY = "d4d1f58d8emsh58d888c711b7400p1bcebejsn2cc04dce6efe"
# ===========================================================

DAILY_LIMIT = 150
MONTHLY_LIMIT = 3000
prompt_cache = OrderedDict()
MAX_CACHE_SIZE = 1500
AUTHORIZED_TO_LEARN = True

bot_instance = Bot(BOT_TOKEN)
api_response_cache = OrderedDict()
api_global_lock = {}
API_CACHE_EXPIRATION = 600

def H(t): return hashlib.sha256(t.encode()).hexdigest()
def K(n, p): return f"{n}:{H(p)}"
def G(n, p): v = api_response_cache.get(K(n, p)); return v["r"] if v and time.time() - v["t"] < API_CACHE_EXPIRATION else None
def S(n, p, r): api_response_cache[K(n, p)] = {"r": r, "t": time.time()}; len(api_response_cache) > MAX_CACHE_SIZE and api_response_cache.popitem(last=False)

async def C(f, n, p, *a, **k):
    k_ = K(n, p)
    if k_ not in api_global_lock:
        api_global_lock[k_] = asyncio.Lock()
    async with api_global_lock[k_]:
        c = G(n, p)
        if c is not None: return c
        r = await f(p, *a, **k)
        S(n, p, r)
        return r

def NU(x): return re.sub(r"https?://", lambda m: m.group(0).replace("t", "x", 1), re.sub(r"\.org", "[.]org", re.sub(r"\.net", "[.]net", re.sub(r"\.com", "[.]com", re.sub(r"www\.", "wxx.", x)))))
def RL(p): p.exists() and p.stat().st_size > MAX_FILE_SIZE and p.replace(p.with_suffix(f".old_{int(time.time())}.json"))
def LG():
    RL(ERROR_LOG_PATH)
    logging.basicConfig(level=logging.INFO, format="%(asctime)s [%(levelname)s] %(message)s", datefmt="%Y-%m-%d %H:%M:%S")
    el = logging.getLogger("erreurs_api")
    eh = logging.FileHandler(ERROR_LOG_PATH, encoding="utf-8")
    eh.setFormatter(logging.Formatter("%(asctime)s [%(levelname)s] %(message)s", datefmt="%Y-%m-%d %H:%M:%S"))
    el.addHandler(eh)
    el.setLevel(logging.ERROR)
    return el
error_logger = LG()
signal.signal(signal.SIGINT, lambda s, f: (logging.info("Arr√™t demand√©, fermeture propre..."), sys.exit(0)))
def LE(m): RL(ERROR_LOG_PATH); error_logger.error(m); asyncio.create_task(bot_instance.send_message(chat_id=PRIVATE_GROUP_ID, text=f"‚ö†Ô∏è ERREUR CRITIQUE :\n{m}"))

def SJA(p, d):
    RL(p)
    tp = p.with_suffix(".tmp")
    if p.exists():
        p.replace(p.with_suffix(p.suffix + ".fullbackup"))
    json.dump(d, tp.open("w", encoding="utf-8"), indent=2, ensure_ascii=False)
    tp.replace(p)
def SLJ(p, d):
    try:
        if not p.exists(): return d
        return json.load(open(p, "r", encoding="utf-8"))
    except Exception:
        try: p.unlink()
        except Exception: pass
        return d
def CL(p):
    try:
        if p.exists() and p.stat().st_size > 1e6:
            import shutil
            gz = p.with_suffix(p.suffix + ".gz")
            with open(p, "rb") as f_in, gzip.open(gz, "wb") as f_out:
                shutil.copyfileobj(f_in, f_out)
            p.unlink()
            gz.rename(p)
    except Exception as e:
        LE(f"[Compression auto] {e}\n{traceback.format_exc()}")

quotas_path = BASE_DIR / "quotas.json"
def LQ():
    q = SLJ(quotas_path, {"daily": 0, "monthly": 0, "last_reset": datetime.now().isoformat(), "tavily_idx": 0})
    q.setdefault("daily", 0)
    q.setdefault("monthly", 0)
    q.setdefault("last_reset", datetime.now().isoformat())
    q.setdefault("tavily_idx", 0)
    return q
quotas = LQ()
def SQ(): SJA(quotas_path, quotas)
def RQ():
    n = datetime.now()
    last = datetime.fromisoformat(quotas.get("last_reset", n.isoformat())) if quotas.get("last_reset") else n
    c = False
    if (n - last).days >= 1:
        quotas["daily"] = 0
        c = True
    if n.month != last.month:
        quotas["monthly"] = 0
    if c:
        quotas["last_reset"] = n.isoformat()
        SQ()
def IQ(b=1):
    quotas["daily"] += b
    quotas["monthly"] += b
    SQ()
def CQ():
    return quotas["daily"] < DAILY_LIMIT and quotas["monthly"] < MONTHLY_LIMIT
def AQ(b=None):
    if quotas["daily"] >= DAILY_LIMIT:
        LE("üö® Quota journalier IA atteint !")
        if b: asyncio.create_task(b.send_message(chat_id=PRIVATE_GROUP_ID, text="üö® Quota journalier IA atteint !"))
    if quotas["monthly"] >= MONTHLY_LIMIT:
        LE("üö® Quota mensuel IA atteint !")
        if b: asyncio.create_task(b.send_message(chat_id=PRIVATE_GROUP_ID, text="üö® Quota mensuel IA atteint !"))

def STK():
    idx = quotas.get("tavily_idx", 0)
    key = TAVILY_KEYS[idx % len(TAVILY_KEYS)]
    quotas["tavily_idx"] = (idx + 1) % len(TAVILY_KEYS)
    SQ()
    return key

def GUD(u): p = BASE_DIR / str(u); p.mkdir(exist_ok=True); return p
def SJ(u, f, d): SJA(GUD(u) / f, d)
def EK(t): w = re.findall(r"\b[a-zA-Z√©√®√™√¥√†√π√ß√Æ√Ø≈ì]{4,}\b", t.lower()); f = {}; [f.setdefault(x, 0) or f.update({x: f[x] + 1}) for x in w]; return ", ".join(x for x, _ in sorted(f.items(), key=lambda x: x[1], reverse=True)[:5])
def TC(t): return "#tags : " + EK(t)
def AL(u, r, t, m=100): t = NU(t); u != PRIVATE_GROUP_ID and SJ(u, "log.json", SLJ(GUD(u) / "log.json", []) + [{"time": datetime.now().isoformat(), "role": r, "text": t[:500], "tags": TC(t)}][-m:])
def ACH(u, r, t): t = NU(t); u != PRIVATE_GROUP_ID and SJ(u, "chat_history.json", SLJ(GUD(u) / "chat_history.json", []) + [{"time": datetime.now().isoformat(), "role": r, "text": t}][-1000:])
def SGM(g, r, t, m=1000): SJ(g, "group_chat_history.json", SLJ(GUD(g) / "group_chat_history.json", []) + [{"time": datetime.now().isoformat(), "role": r, "text": t}][-m:])
def UPO(s): z = set(); r = []; [r.append(x) for x in s if x not in z and not z.add(x)]; return r
def ALM(u, t): SJ(u, "long_memory.json", UPO(SLJ(GUD(u) / "long_memory.json", []) if isinstance(SLJ(GUD(u) / "long_memory.json", []), list) else []) + [t.strip()])[-100:]
def GLM(u): return "\n".join(SLJ(GUD(u) / "long_memory.json", [])[-20:])
def GRM(u, l=5): return "\n".join(f"{x['role']} : {x['text']}" for x in SLJ(GUD(u) / "log.json", [])[-l:] if x.get("role") != "bot")
def NPM(p): return re.sub(r"\s+", " ", p.strip().replace("‚Ä¶", "...").strip("¬´¬ª'\""))
def SRI(t): 
    s = 100
    if "je ne sais pas" in t.lower(): s -= 30
    if "d√©sol√©" in t.lower(): s -= 20
    if len(t) < 50: s -= 30
    if len(t) > 1500: s -= 10
    if t.count("...") > 3: s -= 10
    return max(0, min(100, s))
def ISR(t): return (not t or len(t.strip()) < 10 or t.lower().strip() in ["...", "aucune id√©e", "je ne sais pas"])
def SRV2(t, q=""):
    tc = t.lower(); ql = len(q); rl = len(tc)
    e = ["je ne peux pas", "je suis d√©sol√©", "impossible", "je ne sais pas", "je ne suis pas capable", "en tant que mod√®le", "je n'ai pas acc√®s", "je ne suis pas en mesure", "i'm sorry"]; found = sum(tc.count(x) for x in e)
    p = ["solution", "r√©ponse", "voici", "peut", "possible", "certainement"]
    return False if any(x in tc for x in p) else rl < 15 or found > 1 or (ql > 100 and rl < ql / 4)
BROKEN_IA = {}
def IAB(m): i = BROKEN_IA.get(m, {"fail_count": 0, "last_fail": 0}); return i["fail_count"] >= 3 and (time.time() - i["last_fail"] < 600)
def MIF(m): i = BROKEN_IA.get(m, {"fail_count": 0, "last_fail": 0}); i["fail_count"] += 1; i["last_fail"] = time.time(); BROKEN_IA[m] = i
def MIS(m): m in BROKEN_IA and BROKEN_IA.pop(m)
running_jobs = {}
def UJ(n):
    def d(f):
        async def w(*a, **k):
            if not running_jobs.get(n):
                running_jobs[n] = True
                await f(*a, **k)
                running_jobs.pop(n)
        return w
    return d
async def WT(f, *a, timeout=25):
    try: return await asyncio.wait_for(f(*a), timeout)
    except: LE(f"[Timeout] {f.__name__} >{timeout}s."); return None
async def RA(f, *a, retries=3, delay=2, **k):
    for i in range(retries):
        try: return await f(*a, **k)
        except: await asyncio.sleep(delay * (2 ** i) + random.uniform(0, 1))
def AC(f):
    @wraps(f)
    async def w(*a, **k):
        try: r = await f(*a, **k)
        except Exception as e: LE(f"API {f.__name__}:{e}\n{traceback.format_exc()}"); return f"Erreur API {f.__name__} : {e}"
        if not r: LE(f"[API] Vide {f.__name__}"); return "R√©ponse vide"
        return r
    return w

# ===================== Ajout gestion messages HM / HGM =====================
async def HM(update, context):
    print(f"[HM] Message re√ßu hors groupe : {update.message.text}")
    await update.message.reply_text("R√©ponse hors groupe OK")

async def HGM(update, context):
    print(f"[HGM] Message re√ßu dans groupe priv√© : {update.message.text}")
    await update.message.reply_text("R√©ponse groupe priv√© OK")

# ===================== Commandes Telegram =====================

# Commande /quota : affiche l‚Äô√©tat des quotas et appels API
async def cmd_quota(update, context):
    await quota_ia()
    stats_file = BASE_DIR / "stats.json"
    stats = {}
    if stats_file.exists():
        stats = SLJ(stats_file, {})
    calls = stats.get("calls", 0)
    durations = stats.get("durations", [])
    avg_duration = round(sum(durations) / len(durations), 2) if durations else "inconnue"
    last_call = stats.get("last", "jamais")
    texte = (
        f"üìä Statistiques IA :\n"
        f"‚Ä¢ Appels API : {calls}\n"
        f"‚Ä¢ Dur√©e moyenne : {avg_duration}s\n"
        f"‚Ä¢ Dernier appel : {last_call}\n"
    )
    await update.message.reply_text(texte)

# Commande /defi : affiche ou lance ton d√©fi IA automatique (exemple)
async def cmd_defi(update, context):
    texte = (
        "üéØ D√©fi IA du jour :\n"
        "üß© Lire un fichier 'exemple.txt', remplacer 'chat' par 'chien', "
        "et sauvegarder dans 'resultat.txt'.\n\n"
        "Code Python exemple :\n"
        "def remplacer_mot():\n"
        "    with open('exemple.txt', 'r', encoding='utf-8') as f:\n"
        "        contenu = f.read()\n"
        "    contenu = contenu.replace('chat', 'chien')\n"
        "    with open('resultat.txt', 'w', encoding='utf-8') as f:\n"
        "        f.write(contenu)\n"
        "remplacer_mot()"
    )
    await update.message.reply_text(texte)

# Commande /update : lance une mise √† jour automatique du script (exemple)
async def cmd_update(update, context):
    await update.message.reply_text("üîÑ V√©rification et mise √† jour du script en cours...")
    try:
        await mise_a_jour_script()
        await update.message.reply_text("‚úÖ Mise √† jour termin√©e (voir logs).")
    except Exception as e:
        await update.message.reply_text(f"‚ùå Erreur mise √† jour : {e}")

def register_commands(app):
    app.add_handler(CommandHandler("quota", cmd_quota))
    app.add_handler(CommandHandler("defi", cmd_defi))
    app.add_handler(CommandHandler("update", cmd_update))

# ===================== APPELS API AVEC CL√âS EN DUR =====================
# ... (toutes les fonctions API, CIG, etc. inchang√©es, voir ton script fourni initialement)
async def CHF(p):
    url = "https://api-inference.huggingface.co/models/gpt2"
    h = {"Authorization": f"Bearer {HF_TOKEN}"}
    pl = {"inputs": p, "options": {"wait_for_model": True}}
    async with httpx.AsyncClient(timeout=30) as c:
        r = await c.post(url, headers=h, json=pl)
        return r.json()[0]["generated_text"] if r.status_code == 200 and isinstance(r.json(), list) and "generated_text" in r.json()[0] else (str(r.json()) if r.status_code == 200 else None)

async def CW(q):
    url = "http://api.wolframalpha.com/v2/query"
    pa = {"appid": WOLFRAM_APP_ID, "input": q, "output": "JSON"}
    async with httpx.AsyncClient(timeout=20) as c:
        r = await c.get(url, params=pa)
        d = r.json(); pods = d.get("queryresult", {}).get("pods", [])
        return next((x["subpods"][0].get("plaintext", "") for x in pods if x.get("title", "").lower() in ["result", "definition"]), None) if r.status_code == 200 else None

async def CGC(q):
    cx = GOOGLE_CX_LIST[0]
    url = "https://www.googleapis.com/customsearch/v1"
    pa = {"key": GOOGLE_API_KEY, "cx": cx, "q": q, "num": 1}
    async with httpx.AsyncClient(timeout=20) as c:
        r = await c.get(url, params=pa)
        j = r.json(); i = j.get("items", [])
        return i[0].get("snippet", "Pas de contenu trouv√©.") if r.status_code == 200 and i else "Pas de r√©sultat trouv√© via Google Custom Search."

async def CTA(q):
    url = "https://api.tavily.com/v1/ask"
    h = {"Authorization": f"Bearer {STK()}"}
    pl = {"question": q}
    async with httpx.AsyncClient(timeout=20) as c:
        r = await c.post(url, headers=h, json=pl)
        return r.json().get("answer") or "Pas de r√©ponse de Tavily." if r.status_code == 200 else None

async def CO(image_url):
    url = "https://api.ocrservice.com/parse/image"
    h = {"apikey": OCR_API_KEY}
    pl = {"url": image_url}
    async with httpx.AsyncClient(timeout=20) as c:
        r = await c.post(url, headers=h, json=pl)
        return r.json().get("ParsedText", "Pas de texte d√©tect√©.") if r.status_code == 200 else None

async def COW(city):
    url = "https://api.openweathermap.org/data/2.5/weather"
    pa = {"q": city, "appid": OPENWEATHER_API_KEY, "units": "metric", "lang": "fr"}
    async with httpx.AsyncClient(timeout=20) as c:
        r = await c.get(url, params=pa)
        d = r.json()
        return f"M√©t√©o √† {city} : {d['weather'][0]['description']}, {d['main']['temp']}¬∞C" if r.status_code == 200 else None

async def CRA(q):
    url = "https://example-rapidapi.p.rapidapi.com/endpoint"
    h = {"X-RapidAPI-Key": RAPIDAPI_KEY, "X-RapidAPI-Host": "example-rapidapi.p.rapidapi.com"}
    pa = {"query": q}
    async with httpx.AsyncClient(timeout=20) as c:
        r = await c.get(url, headers=h, params=pa)
        return r.json().get("result", "Pas de r√©sultat.") if r.status_code == 200 else None

# Nouvelle fonction CIG multi-IA/cl√©
async def CIG(prompt, api_key=None, model_name=None):
    prompt = NPM(prompt)

    # OpenRouter
    if model_name == "OpenRouter" or (not model_name and not api_key):
        models = ["openai/gpt-4o-mini", "mistralai/mistral-7b-instruct", "mistralai/mixtral-8x7b-instruct"]
        async def SMC(m):
            async with httpx.AsyncClient(timeout=30) as c:
                try:
                    st = time.time()
                    r = await c.post("https://openrouter.ai/api/v1/chat/completions", headers={"Authorization": f"Bearer {OPENROUTER_KEY}", "Content-Type": "application/json"}, json={"model": m, "messages": [{"role": "user", "content": prompt}], "max_tokens": 600, "temperature": 0.7})
                    du = round(time.time() - st, 2)
                    if r.status_code == 200:
                        j = r.json(); cont = j.get("choices", [{}])[0].get("message", {}).get("content", "")
                        if cont and not SRV2(cont, prompt):
                            f = BASE_DIR / f"ia_reply_{datetime.now().strftime('%Y%m%d_%H%M%S')}.txt"
                            f.write_text(cont, encoding="utf-8")
                            return NU(cont)
                        elif SRV2(cont, prompt):
                            MIF(m)
                            return None
                    else:
                        LE(f"[OpenRouter] {m}: {r.status_code} ‚Üí {r.text}")
                except Exception as e:
                    LE(f"[OpenRouter] {m} erreur:{e}\n{traceback.format_exc()}")
                    MIF(m)
                    return None
        async def SFC(m):
            async with semaphore:
                if IAB(m): return None
                r = await WT(SMC, m)
                if r: MIS(m); return r
                return None
        ts = [SFC(m) for m in models]
        for f in asyncio.as_completed(ts):
            r = await f
            if r: return r
        return "‚ùå Toutes les IA gratuites ont √©chou√© (r√©seau ou quota ?)."

    # Tavily
    if model_name and model_name.startswith("Tavily"):
        url = "https://api.tavily.com/v1/ask"
        headers = {"Authorization": f"Bearer {api_key}"}
        payload = {"question": prompt}
        async with httpx.AsyncClient(timeout=20) as c:
            try:
                r = await c.post(url, headers=headers, json=payload)
                if r.status_code == 200:
                    rep = r.json().get("answer")
                    return rep if rep else "Pas de r√©ponse de Tavily."
                else:
                    return f"[Tavily] Erreur {r.status_code}: {r.text}"
            except Exception as e:
                return f"[Tavily] Exception: {e}"

    # Serper
    if model_name == "Serper":
        url = "https://serpapi.com/search"
        params = {"q": prompt, "api_key": api_key, "engine": "google"}
        async with httpx.AsyncClient(timeout=10) as c:
            try:
                r = await c.get(url, params=params)
                if r.status_code == 200:
                    j = r.json()
                    return j.get("organic_results", [{}])[0].get("snippet", "Pas de r√©sultat Serper.")
                return f"[Serper] Erreur {r.status_code}: {r.text}"
            except Exception as e:
                return f"[Serper] Exception: {e}"

    # HuggingFace
    if model_name == "HuggingFace":
        url = "https://api-inference.huggingface.co/models/gpt2"
        headers = {"Authorization": f"Bearer {api_key}"}
        payload = {"inputs": prompt, "options": {"wait_for_model": True}}
        async with httpx.AsyncClient(timeout=30) as c:
            try:
                r = await c.post(url, headers=headers, json=payload)
                if r.status_code == 200 and isinstance(r.json(), list) and "generated_text" in r.json()[0]:
                    return r.json()[0]["generated_text"]
                return f"[HF] Erreur {r.status_code}: {r.text}"
            except Exception as e:
                return f"[HF] Exception: {e}"

    # Wolfram
    if model_name == "Wolfram":
        url = "http://api.wolframalpha.com/v2/query"
        params = {"input": prompt, "appid": api_key}
        async with httpx.AsyncClient(timeout=20) as c:
            try:
                r = await c.get(url, params=params)
                if r.status_code == 200:
                    d = r.json(); pods = d.get("queryresult", {}).get("pods", [])
                    return next((x["subpods"][0].get("plaintext", "") for x in pods if x.get("title", "").lower() in ["result", "definition"]), None) or "Pas de r√©sultat Wolfram."
                return f"[Wolfram] Erreur {r.status_code}: {r.text}"
            except Exception as e:
                return f"[Wolfram] Exception: {e}"

    # Google API
    if model_name and model_name.startswith("GoogleCX"):
        idx = int(model_name.split("-")[1]) - 1
        cx = GOOGLE_CX_LIST[idx]
        url = "https://www.googleapis.com/customsearch/v1"
        params = {"q": prompt, "key": api_key, "cx": cx}
        async with httpx.AsyncClient(timeout=10) as c:
            try:
                r = await c.get(url, params=params)
                if r.status_code == 200:
                    j = r.json(); i = j.get("items", [])
                    return i[0].get("snippet", "Pas de r√©sultat Google CustomSearch.") if i else "Pas de r√©sultat Google."
                return f"[GoogleCX] Erreur {r.status_code}: {r.text}"
            except Exception as e:
                return f"[GoogleCX] Exception: {e}"

    return "‚ùå Aucune IA/cl√© valide pour ce CIG"

# -------------------------------------------------------------------------
# ----------------- CODING CHALLENGE TOUTES IA EN PARALL√àLE --------------
# -------------------------------------------------------------------------
CODING_CHALLENGE_ENABLED = True
LAST_CHALLENGE_FILE = DAILY_CHALLENGE_PATH / "last_challenge.py"
HISTORY_DIR = DAILY_CHALLENGE_PATH / "history"
HISTORY_DIR.mkdir(exist_ok=True)

def diff_text(old_text, new_text):
    import difflib
    diff = difflib.unified_diff(
        old_text.splitlines(), new_text.splitlines(), lineterm=""
    )
    return "\n".join(diff)

async def coding_challenge_task():
    while True:
        if not CODING_CHALLENGE_ENABLED:
            await asyncio.sleep(900)
            continue

        prompt = """
Tu es une IA experte en programmation Python. G√©n√®re un script clair, correct et optimis√©, 100% en fran√ßais.
Ne dis pas que tu ne sais pas, ne t'excuse pas, ne formule pas de r√©ponses vagues.
Chaque version doit √™tre une am√©lioration nette de la pr√©c√©dente.
Commence par un commentaire indiquant ce qui a √©t√© am√©lior√©.
Le code doit √™tre direct, lisible, et pr√™t √† √™tre utilis√©.
"""

        # Liste des IA / cl√©s √† utiliser
        ia_list = [
            ("OpenRouter", OPENROUTER_KEY),
            *[(f"Tavily-{i+1}", k) for i, k in enumerate(TAVILY_KEYS)],
            ("Serper", SERPER_KEY),
            ("HuggingFace", HF_TOKEN),
            ("Wolfram", WOLFRAM_APP_ID),
            *[(f"GoogleCX-{i+1}", GOOGLE_API_KEY) for i in range(len(GOOGLE_CX_LIST))],
        ]

        async def call_ia(nom, cle):
            try:
                r = await CIG(prompt, api_key=cle, model_name=nom)
                if r and len(r.strip()) > 20:
                    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
                    fpath = DAILY_CHALLENGE_PATH / f"challenge_{nom}_{timestamp}.py"
                    fpath.write_text(r, encoding="utf-8")
                    await bot_instance.send_message(
                        chat_id=PRIVATE_GROUP_ID,
                        text=f"üíª <b>Code g√©n√©r√© par {nom}</b> :\n<pre>{r[:600]}</pre>",
                        parse_mode="HTML"
                    )
                    return r
                else:
                    await bot_instance.send_message(
                        chat_id=PRIVATE_GROUP_ID,
                        text=f"‚ö†Ô∏è <b>{nom}</b> n'a pas g√©n√©r√© de code valable cette fois.",
                        parse_mode="HTML"
                    )
                    return None
            except Exception as e:
                await bot_instance.send_message(
                    chat_id=PRIVATE_GROUP_ID,
                    text=f"‚ùå <b>{nom}</b> erreur lors de l'appel IA : {e}",
                    parse_mode="HTML"
                )
                return None

        # Appels en parall√®le
        results = await asyncio.gather(*[call_ia(n, k) for n, k in ia_list])

        await asyncio.sleep(900)  # Pause 15 min

async def start_background_tasks(app):
    asyncio.create_task(coding_challenge_task())

# -------------------------------------------------------------------------
# ------------- COMMANDE /QUOTA POUR TOUTES LES IA (v√©rif statuts) --------
# -------------------------------------------------------------------------
async def quota_ia():
    """
    Affiche dans PRIVATE_GROUP_ID le statut et quotas de toutes les IA et cl√©s configur√©es.
    Test simple du fonctionnement (timeout rapide).
    """
    from datetime import datetime

    results = []

    # Test OpenRouter
    async def test_openrouter():
        try:
            async with httpx.AsyncClient(timeout=5) as c:
                r = await c.get("https://openrouter.ai/api/v1/models", headers={"Authorization": f"Bearer {OPENROUTER_KEY}"})
                if r.status_code == 200:
                    return "‚úÖ OpenRouter : OK"
                else:
                    return f"‚ùå OpenRouter : {r.status_code} {r.text[:100]}"
        except Exception as e:
            return f"‚ùå OpenRouter erreur : {e}"

    # Test Tavily keys
    async def test_tavily():
        messages = []
        for i, key in enumerate(TAVILY_KEYS):
            try:
                async with httpx.AsyncClient(timeout=5) as c:
                    r = await c.get("https://api.tavily.com/ping", headers={"Authorization": key})
                    if r.status_code == 200:
                        messages.append(f"‚úÖ Tavily key #{i+1}: OK")
                    else:
                        messages.append(f"‚ùå Tavily key #{i+1}: {r.status_code} {r.text[:100]}")
            except Exception as e:
                messages.append(f"‚ùå Tavily key #{i+1} erreur : {e}")
        return "\n".join(messages)

    # Test Serper (Google Search API)
    async def test_serper():
        try:
            async with httpx.AsyncClient(timeout=5) as c:
                r = await c.get("https://serpapi.com/search", params={"q": "test", "api_key": SERPER_KEY, "engine": "google"})
                if r.status_code == 200:
                    return "‚úÖ Serper (Google) : OK"
                else:
                    return f"‚ùå Serper (Google) : {r.status_code} {r.text[:100]}"
        except Exception as e:
            return f"‚ùå Serper (Google) erreur : {e}"

    # Test HuggingFace token
    async def test_hf():
        try:
            async with httpx.AsyncClient(timeout=5) as c:
                r = await c.get("https://api-inference.huggingface.co/models/gpt2", headers={"Authorization": f"Bearer {HF_TOKEN}"})
                if r.status_code == 200:
                    return "‚úÖ HuggingFace : OK"
                else:
                    return f"‚ùå HuggingFace : {r.status_code} {r.text[:100]}"
        except Exception as e:
            return f"‚ùå HuggingFace erreur : {e}"

    # Test Wolfram App ID
    async def test_wolfram():
        try:
            async with httpx.AsyncClient(timeout=5) as c:
                r = await c.get("http://api.wolframalpha.com/v2/query", params={"input": "pi", "appid": WOLFRAM_APP_ID})
                if r.status_code == 200:
                    return "‚úÖ Wolfram Alpha : OK"
                else:
                    return f"‚ùå Wolfram Alpha : {r.status_code} {r.text[:100]}"
        except Exception as e:
            return f"‚ùå Wolfram Alpha erreur : {e}"

    # Tests Google API Keys (multiple)
    async def test_google_apis():
        messages = []
        for i, cx in enumerate(GOOGLE_CX_LIST):
            try:
                async with httpx.AsyncClient(timeout=5) as c:
                    r = await c.get("https://www.googleapis.com/customsearch/v1",
                                   params={"q": "test", "key": GOOGLE_API_KEY, "cx": cx})
                    if r.status_code == 200:
                        messages.append(f"‚úÖ Google Custom Search CX #{i+1}: OK")
                    else:
                        messages.append(f"‚ùå Google Custom Search CX #{i+1}: {r.status_code} {r.text[:100]}")
            except Exception as e:
                messages.append(f"‚ùå Google Custom Search CX #{i+1} erreur : {e}")
        return "\n".join(messages)

    # Assemble all checks
    results.append(await test_openrouter())
    results.append(await test_tavily())
    results.append(await test_serper())
    results.append(await test_hf())
    results.append(await test_wolfram())
    results.append(await test_google_apis())

    status_message = "üìä <b>√âtat et quota IA / API :</b>\n" + "\n\n".join(results) + f"\n\nDernier test : {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}"
    try:
        await bot_instance.send_message(chat_id=PRIVATE_GROUP_ID, text=status_message, parse_mode="HTML")
    except Exception as e:
        print(f"Erreur envoi message quota ia : {e}")

# -------------------------------------------------------------------------
# -------------------------- FONCTIONS BOT PRINCIPALES --------------------
# -------------------------------------------------------------------------

async def MA():
    try: import nest_asyncio; nest_asyncio.apply()
    except: pass
    sm = "‚úÖ Bot red√©marr√© " + datetime.now().strftime("%H:%M:%S")
    await bot_instance.send_message(chat_id=PRIVATE_GROUP_ID, text=sm)
    if not AsyncIOScheduler(timezone=timezone.utc).running:
        scheduler = AsyncIOScheduler(timezone=timezone.utc); scheduler.start()
        scheduler.add_job(lambda: prompt_cache.clear() or api_response_cache.clear() or gc.collect(), 'interval', hours=6)
        scheduler.add_job(mise_a_jour_script, 'interval', hours=8)
        scheduler.add_job(lambda: None, 'interval', minutes=60) # Placeholders, tu peux remettre DCF et SIIA ici
    app = ApplicationBuilder().token(BOT_TOKEN).build()
    register_commands(app)
    app.add_handler(MessageHandler(filters.TEXT & (~filters.Chat(PRIVATE_GROUP_ID)), HM))
    app.add_handler(MessageHandler(filters.Chat(PRIVATE_GROUP_ID) & filters.TEXT, HGM))
    await start_background_tasks(app)
    print(f"Bot actif : Levraibootbot (ID {BOT_TOKEN.split(':')[0]})\nüîß Gestionnaire API optimis√© activ√©")
    await app.run_polling()

async def mise_a_jour_script():
    try:
        async with httpx.AsyncClient(timeout=20) as c:
            r = await c.get(UPDATE_URL)
            if r.status_code == 200:
                nc = r.text
                ac = LOCAL_SCRIPT_PATH.read_text(encoding="utf-8")
                if H(nc) != H(ac):
                    b = LOCAL_SCRIPT_PATH.with_suffix(".backup.py")
                    LOCAL_SCRIPT_PATH.rename(b)
                    LOCAL_SCRIPT_PATH.write_text(nc, encoding="utf-8")
                    logging.info("‚úÖ Script MAJ auto.")
                    await bot_instance.send_message(chat_id=PRIVATE_GROUP_ID, text="üîÑ Script MAJ auto. Red√©marrage recommand√©.")
                else:
                    logging.info("‚ÑπÔ∏è Script √† jour.")
    except Exception as e: LE(f"[AutoUpdate] MAJ auto : {e}")

if __name__ == "__main__":
    asyncio.run(MA())


import os
import json
from datetime import datetime, timezone, date, timedelta
from pathlib import Path

# ----------------------------
# CONFIGURATION & CONSTANTES GLOBALES
# ----------------------------

# ==== Chemins de fichiers & Limites ====
os.environ["TZ"] = "UTC" # Assure que le temps est toujours en UTC
BASE_DIR = Path("sauvegardes")
ERROR_LOG_PATH = BASE_DIR / "erreurs.log"
DAILY_CHALLENGE_PATH = Path("defis_code")
HISTORY_DIR = DAILY_CHALLENGE_PATH / "history" # Pour l'historique des d√©fis
MAX_FILE_SIZE = 5 * 1024 * 1024  # 5 MB pour la rotation/compression des logs
MAX_CACHE_SIZE = 1200 # Ancien script, √† √©valuer si encore pertinent pour la nouvelle architecture
AUTHORIZED_TO_LEARN = True # Ancien script, √† √©valuer si encore pertinent
DEBUG = True # Ancien script

# Assurez-vous que les r√©pertoires existent
BASE_DIR.mkdir(exist_ok=True)
DAILY_CHALLENGE_PATH.mkdir(exist_ok=True)
HISTORY_DIR.mkdir(exist_ok=True)

# ==== Telegram Bot Configuration ====
TELEGRAM_BOT_TOKEN = "7902342551:AAG6r1QA2GTMZcmcsWHi36Ivd_PVeMXULOs"
PRIVATE_GROUP_ID = -1002845235344 # Utilis√© pour les logs et rapports

# ==== Quotas API (Estimations si non document√©es) ====
API_QUOTAS = {
    "APIFLASH": {"monthly": 100, "daily": 3, "hourly": 3},
    "DEEPSEEK": {"monthly": None, "hourly": 50},
    "CRAWLBASE": {"monthly": 1000, "daily": 33, "hourly": 1},
    "DETECTLANGUAGE": {"daily": 1000, "hourly": 41},
    "GUARDIAN": {"daily": 5000, "rate_limit_per_sec": 12},
    "IP2LOCATION": {"monthly": 50, "daily": 2, "hourly": 2},
    "SERPER": {"monthly": 2500, "daily": 83, "hourly": 3},
    "SHODAN": {"monthly": 100, "daily": 3, "hourly": 3},
    "TAVILY": {"monthly": 1000, "daily": 33, "hourly": 1},
    "WEATHERAPI": {"monthly": None},
    "WOLFRAMALPHA": {"monthly": None, "hourly": 67},
    "CLOUDMERSIVE": {"monthly": 25, "daily": 1, "hourly": 1},
    "GREYNOISE": {"monthly": 100, "daily": 3, "hourly": 3},
    "PULSEDIVE": {"monthly": 50, "daily": 2, "hourly": 2},
    "STORMGLASS": {"monthly": None},
    "LOGINRADIUS": {"monthly": 25000, "daily": 833, "hourly": 34},
    "JSONBIN": {"monthly": 10000, "daily": 333, "hourly": 13},
    "HUGGINGFACE": {"hourly": 100},
    "TWILIO": {"monthly": 15},
    "ABSTRACTAPI": {"monthly": 250, "rate_limit_per_sec": 1, "daily": 8, "hourly": 1},
    "MOCKAROO": {"monthly": 200, "daily": 7, "hourly": 1},
    "OPENPAGERANK": {"monthly": 1000, "daily": 33, "hourly": 1},
    "RAPIDAPI": {"monthly": None, "hourly": 30},
    "GEMINI_API": {"monthly": None, "hourly": 50},
    "GOOGLE_CUSTOM_SEARCH": {"daily": 100, "hourly": 4},
    "RANDOMMER": {"monthly": 1000, "daily": 100, "hourly": 4},
    "TOMORROW.IO": {"monthly": None},
    "OPENWEATHERMAP": {"monthly": 1000000, "daily": 100, "hourly": 4},
    "OCR_API": {"monthly": 500, "daily": 10, "hourly": 1} # Ajout√© pour l'OCR via API
}

# ==== Cl√©s API Individuelles (centralis√©es pour la clart√©) ====
APIFLASH_KEY = "3a3cc886a18e41109e0cebc0745b12de"
DEEPSEEK_KEY_1 = "sk-ef08317d125947b3a1ce5916592bef00"
DEEPSEEK_KEY_2 = "sk-d73750d96142421cb1098c7056dd7f01"
CRAWLBASE_KEY_1 = "x41P6KNU8J86yF9JV1nqSw"
CRAWLBASE_KEY_2 = "FOg3R0v_aLxzHkYIdjPgVg"
DETECTLANGUAGE_KEY = "ebdc8ccc2ee75eda3ab122b08ffb1e8d"
GUARDIAN_KEY = "07c622c1-af05-4c24-9f37-37d219be76a0"
IP2LOCATION_KEY = "11103C239EA8EA6DF2473BB445EC32F2"
SERPER_KEY = "047b30db1df999aaa9c293f2048037d40c651439"
SHODAN_KEY = "umdSaWOfVq9Wt2F4wWdXiKh1zjLailzn"
TAVILY_KEY_1 = "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"
TAVILY_KEY_2 = "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"
TAVILY_KEY_3 = "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"
TAVILY_KEY_4 = "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"
WEATHERAPI_KEY = "332bcdba457d4db4836175513250407"
WOLFRAM_APP_ID_1 = "96LX77-G8PGKJ3T7V"
WOLFRAM_APP_ID_2 = "96LX77-PYHRRET363"
WOLFRAM_APP_ID_3 = "96LX77-P9HPAYWRGL"
GREYNOISE_KEY = "5zNe9E6c5UNDhU09iVXbMaB04UpHAw5hNm5rHCK24fCLvI2cP33NNOpL7nhkDETG"
LOGINRADIUS_KEY = "073b2fbedf82409da2ca6f37b97e8c6a"
JSONBIN_KEY = "$2a$10$npWSB7v1YcoqLkyPpz0PZOV5ES5vBs6JtTWVyVDXK3j3FDYYS5BPO"
HUGGINGFACE_KEY_1 = "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"
HUGGINGFACE_KEY_2 = "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"
HUGGINGFACE_KEY_3 = "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"
HUGGINGFACE_NEW_KEY = "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"
TWILIO_SID = "SK84cc4d335650f9da168cd779f26e00e5"
TWILIO_SECRET = "spvz5uwPE8ANYOI5Te4Mehm7YwKOZ4Lg"
ABSTRACTAPI_EMAIL_KEY_1 = "2ffd537411ad407e9c9a7eacb7a97311"
ABSTRACTAPI_EMAIL_KEY_2 = "5b00ade4e60e4a388bd3e749f4f66e28"
ABSTRACTAPI_EMAIL_KEY_3 = "f4106df7b93e4db6855cb7949edc4a20"
ABSTRACTAPI_GENERIC_KEY = "020a4dcd3e854ac0b19043491d79df92"
GEMINI_API_KEY = "AIzaSyABnzGG2YoTNY0uep-akgX1rfuvAsp049Q"
GOOGLE_API_KEYS = [
    "AIzaSyAk6Ph25xuIY3b5o-JgdL652MvK4usp8Ms",
    "AIzaSyDuccmfiPSk4042NeJCYIjA8EOXPo1YKXU",
    "AIzaSyAQq6o9voefaDxkAEORf7W-IB3QbotIkwY",
    "AIzaSyDYaYrQQ7cwYFm8TBpyGM3dJweOGOYl7qw",
]
GOOGLE_CX_LIST = [
    "3368510e864b74936",
    "e745c9ca0ffb94659"
]
PULSEDIVE_KEY = "201bb09342f35d365889d7d0ca0fdf8580ebee0f1e7644ce70c99a46c1d47171"
RANDOMMER_KEY = "29d907df567b4226bf64b924f9e26c00"
STORMGLASS_KEY = "7ad5b888-5900-11f0-80b9-0242ac130006-7ad5b996-5900-11f0-80b9-0242ac130006"
TOMORROW_KEY = "bNh6KpmddRGY0dzwvmQugVtG4Uf5Y2w1"
CLOUDMERSIVE_KEY = "4d407015-ce22-45d7-a2e1-b88ab6380084"
OPENWEATHER_API_KEY = "c80075b7332716a418e47033463085ef"
MOCKAROO_KEY = "282b32d0"
OPENPAGERANK_KEY = "w848ws8s0848g4koosgooc0sg4ggogcggw4o4cko"
RAPIDAPI_KEY = "d4d1f58d8emsh58d888c711b7400p1bcebejsn2cc04dce6efe"
OCR_API_KEYS = ["K82679097388957", "K81079143888957", "K84281517488957"] # Cl√©s OCR de l'ancien script

# ==== Configuration unifi√©e des APIs et Endpoints ====
API_CONFIG = {
    "APIFLASH": [
        {"key": APIFLASH_KEY, "endpoint_name": "URL to Image", "url": "https://api.apiflash.com/v1/urltoimage", "method": "GET", "key_field": "access_key", "key_location": "param", "health_check_params": {"url": "https://example.com"}, "timeout": 10}
    ],
    "DEEPSEEK": [
        {"key": DEEPSEEK_KEY_1, "endpoint_name": "Models List (Key 1)", "url": "https://api.deepseek.com/v1/models", "method": "GET", "key_field": "Authorization", "key_location": "header", "key_prefix": "Bearer ", "timeout": 5},
        {"key": DEEPSEEK_KEY_2, "endpoint_name": "Models List (Key 2)", "url": "https://api.deepseek.com/v1/models", "method": "GET", "key_field": "Authorization", "key_location": "header", "key_prefix": "Bearer ", "timeout": 5},
        {"key": DEEPSEEK_KEY_1, "endpoint_name": "Chat Completions", "url": "https://api.deepseek.com/v1/chat/completions", "method": "POST", "key_field": "Authorization", "key_location": "header", "key_prefix": "Bearer ", "fixed_json": {"model": "deepseek-chat", "stream": False}, "health_check_json": {"model": "deepseek-chat", "messages": [{"role": "user", "content": "hello"}]}, "timeout": 30}
    ],
    "CRAWLBASE": [
        {"key": CRAWLBASE_KEY_1, "endpoint_name": "HTML Scraping", "url": "https://api.crawlbase.com", "method": "GET", "key_field": "token", "key_location": "param", "health_check_params": {"url": "https://example.com"}, "timeout": 15},
        {"key": CRAWLBASE_KEY_2, "endpoint_name": "JS Scraping (JavaScript Token)", "url": "https://api.crawlbase.com", "method": "GET", "key_field": "token", "key_location": "param", "fixed_params": {"javascript": "true"}, "health_check_params": {"url": "https://example.com", "javascript": "true"}, "timeout": 20}
    ],
    "DETECTLANGUAGE": [
        {"key": DETECTLANGUAGE_KEY, "endpoint_name": "Language Detection", "url": "https://ws.detectlanguage.com/0.2/detect", "method": "POST", "key_field": "Authorization", "key_location": "header", "key_prefix": "Bearer ", "health_check_json": {"q": "hello"}, "timeout": 5}
    ],
    "GUARDIAN": [
        {"key": GUARDIAN_KEY, "endpoint_name": "News Search", "url": "https://content.guardianapis.com/search", "method": "GET", "key_field": "api-key", "key_location": "param", "fixed_params": {"show-fields": "headline,trailText"}, "health_check_params": {"q": "test"}, "timeout": 10},
        {"key": GUARDIAN_KEY, "endpoint_name": "Sections", "url": "https://content.guardianapis.com/sections", "method": "GET", "key_field": "api-key", "key_location": "param", "health_check_params": {"q": "news"}, "timeout": 5}
    ],
    "IP2LOCATION": [
        {"key": IP2LOCATION_KEY, "endpoint_name": "IP Geolocation", "url": "https://api.ip2location.io/", "method": "GET", "key_field": "key", "key_location": "param", "health_check_params": {"ip": "8.8.8.8"}, "timeout": 5}
    ],
    "SERPER": [
        {"key": SERPER_KEY, "endpoint_name": "Search", "url": "https://google.serper.dev/search", "method": "POST", "key_field": "X-API-KEY", "key_location": "header", "health_check_json": {"q": "test"}, "timeout": 10},
        {"key": SERPER_KEY, "endpoint_name": "Images Search", "url": "https://google.serper.dev/images", "method": "POST", "key_field": "X-API-KEY", "key_location": "header", "health_check_json": {"q": "test"}, "timeout": 10}
    ],
    "SHODAN": [
        {"key": SHODAN_KEY, "endpoint_name": "Host Info", "url": "https://api.shodan.io/shodan/host/8.8.8.8", "method": "GET", "key_field": "key", "key_location": "param", "health_check_params": {"ip": "8.8.8.8"}, "timeout": 10},
        {"key": SHODAN_KEY, "endpoint_name": "API Info", "url": "https://api.shodan.io/api-info", "method": "GET", "key_field": "key", "key_location": "param", "timeout": 5}
    ],
    "TAVILY": [
        {"key": TAVILY_KEY_1, "endpoint_name": "Search (Key 1)", "url": "https://api.tavily.com/search", "method": "POST", "key_field": "Authorization", "key_location": "header", "key_prefix": "Bearer ", "fixed_json": {"search_depth": "advanced", "include_answer": True}, "health_check_json": {"query": "test"}, "timeout": 15},
        {"key": TAVILY_KEY_2, "endpoint_name": "Search (Key 2)", "url": "https://api.tavily.com/search", "method": "POST", "key_field": "Authorization", "key_location": "header", "key_prefix": "Bearer ", "fixed_json": {"search_depth": "advanced", "include_answer": True}, "health_check_json": {"query": "test"}, "timeout": 15},
        {"key": TAVILY_KEY_3, "endpoint_name": "Search (Key 3)", "url": "https://api.tavily.com/search", "method": "POST", "key_field": "Authorization", "key_location": "header", "key_prefix": "Bearer ", "fixed_json": {"search_depth": "advanced", "include_answer": True}, "health_check_json": {"query": "test"}, "timeout": 15},
        {"key": TAVILY_KEY_4, "endpoint_name": "Search (Key 4)", "url": "https://api.tavily.com/search", "method": "POST", "key_field": "Authorization", "key_location": "header", "key_prefix": "Bearer ", "fixed_json": {"search_depth": "advanced", "include_answer": True}, "health_check_json": {"query": "test"}, "timeout": 15}
    ],
    "WEATHERAPI": [
        {"key": WEATHERAPI_KEY, "endpoint_name": "Current Weather", "url": "http://api.weatherapi.com/v1/current.json", "method": "GET", "key_field": "key", "key_location": "param", "health_check_params": {"q": "London"}, "timeout": 5},
        {"key": WEATHERAPI_KEY, "endpoint_name": "Forecast", "url": "http://api.weatherapi.com/v1/forecast.json", "method": "GET", "key_field": "key", "key_location": "param", "fixed_params": {"days": 1}, "health_check_params": {"q": "London", "days": 1}, "timeout": 5}
    ],
    "WOLFRAMALPHA": [
        {"key": WOLFRAM_APP_ID_1, "endpoint_name": "Query (AppID 1)", "url": "http://api.wolframalpha.com/v2/query", "method": "GET", "key_field": "appid", "key_location": "param", "fixed_params": {"format": "plaintext", "output": "json"}, "health_check_params": {"input": "2+2"}, "timeout": 10},
        {"key": WOLFRAM_APP_ID_2, "endpoint_name": "Query (AppID 2)", "url": "http://api.wolframalpha.com/v2/query", "method": "GET", "key_field": "appid", "key_location": "param", "fixed_params": {"format": "plaintext", "output": "json"}, "health_check_params": {"input": "2+2"}, "timeout": 10},
        {"key": WOLFRAM_APP_ID_3, "endpoint_name": "Query (AppID 3)", "url": "http://api.wolframalpha.com/v2/query", "method": "GET", "key_field": "appid", "key_location": "param", "fixed_params": {"format": "plaintext", "output": "json"}, "health_check_params": {"input": "2+2"}, "timeout": 10}
    ],
    "CLOUDMERSIVE": [
        {"key": CLOUDMERSIVE_KEY, "endpoint_name": "Domain Check", "url": "https://api.cloudmersive.com/validate/domain/check", "method": "POST", "key_field": "Apikey", "key_location": "header", "health_check_json": {"domain": "example.com"}, "timeout": 10}
    ],
    "GREYNOISE": [
        {"key": GREYNOISE_KEY, "endpoint_name": "IP Analysis", "url": "https://api.greynoise.io/v3/community/", "method": "GET", "key_field": "key", "key_location": "header", "health_check_url_suffix": "1.1.1.1", "timeout": 10}
    ],
    "PULSEDIVE": [
        {"key": PULSEDIVE_KEY, "endpoint_name": "API Info", "url": "https://pulsedive.com/api/info.php", "method": "GET", "key_field": "key", "key_location": "param", "health_check_params": {"key": PULSEDIVE_KEY}, "timeout": 5},
        {"key": PULSEDIVE_KEY, "endpoint_name": "Analyze IP", "url": "https://pulsedive.com/api/v1/analyze", "method": "GET", "key_field": "key", "key_location": "param", "health_check_params": {"indicator": "8.8.8.8", "type": "ip"}, "timeout": 10},
        {"key": PULSEDIVE_KEY, "endpoint_name": "Explore", "url": "https://pulsedive.com/api/v1/explore", "method": "GET", "key_field": "key", "key_location": "param", "health_check_params": {"query": "type='ip'"}, "timeout": 10}
    ],
    "STORMGLASS": [
        {"key": STORMGLASS_KEY, "endpoint_name": "Weather Point", "url": "https://api.stormglass.io/v2/weather/point", "method": "GET", "key_field": "Authorization", "key_location": "header", "health_check_params": {"lat": 0, "lng": 0, "params": "airTemperature", "start": 0, "end": 0}, "timeout": 10}
    ],
    "LOGINRADIUS": [
        {"key": LOGINRADIUS_KEY, "endpoint_name": "Ping", "url": "https://api.loginradius.com/identity/v2/auth/ping", "method": "GET", "timeout": 5}
    ],
    "JSONBIN": [
        {"key": JSONBIN_KEY, "endpoint_name": "Bin Access", "url": "https://api.jsonbin.io/v3/b", "method": "GET", "key_field": "X-Master-Key", "key_location": "header", "health_check_url_suffix": "60c7b0e0f8c2a3b4c5d6e7f0", "timeout": 10},
        {"key": JSONBIN_KEY, "endpoint_name": "Bin Create", "url": "https://api.jsonbin.io/v3/b", "method": "POST", "key_field": "X-Master-Key", "key_location": "header", "health_check_json": {"record": {"test": "health"}}, "timeout": 10}
    ],
    "HUGGINGFACE": [
        {"key": HUGGINGFACE_KEY_1, "endpoint_name": "Models List (Key 1)", "url": "https://huggingface.co/api/models", "method": "GET", "key_field": "Authorization", "key_location": "header", "key_prefix": "Bearer ", "timeout": 10},
        {"key": HUGGINGFACE_KEY_1, "endpoint_name": "BERT Inference", "url": "https://api-inference.huggingface.co/models/bert-base-uncased", "method": "POST", "key_field": "Authorization", "key_location": "header", "key_prefix": "Bearer ", "health_check_json": {"inputs": "test"}, "timeout": 30},
        {"key": HUGGINGFACE_KEY_2, "endpoint_name": "Models List (Key 2)", "url": "https://huggingface.co/api/models", "method": "GET", "key_field": "Authorization", "key_location": "header", "key_prefix": "Bearer ", "timeout": 10},
        {"key": HUGGINGFACE_KEY_3, "endpoint_name": "Models List (Key 3)", "url": "https://huggingface.co/api/models", "method": "GET", "key_field": "Authorization", "key_location": "header", "key_prefix": "Bearer ", "timeout": 10},
        {"key": HUGGINGFACE_NEW_KEY, "endpoint_name": "Models List (New Key)", "url": "https://huggingface.co/api/models", "method": "GET", "key_field": "Authorization", "key_location": "header", "key_prefix": "Bearer ", "timeout": 10},
        {"key": HUGGINGFACE_NEW_KEY, "endpoint_name": "BERT Inference (New Key)", "url": "https://api-inference.huggingface.co/models/bert-base-uncased", "method": "POST", "key_field": "Authorization", "key_location": "header", "key_prefix": "Bearer ", "health_check_json": {"inputs": "test"}, "timeout": 30}
    ],
    "TWILIO": [
        {"key": (TWILIO_SID, TWILIO_SECRET), "endpoint_name": "Accounts", "url": "https://api.twilio.com/2010-04-01/Accounts", "method": "GET", "key_location": "auth_basic", "timeout": 10},
        {"key": (TWILIO_SID, TWILIO_SECRET), "endpoint_name": "Account Balance", "url": f"https://api.twilio.com/2010-04-01/Accounts/{TWILIO_SID}/Balance.json", "method": "GET", "key_location": "auth_basic", "timeout": 10}
    ],
    "ABSTRACTAPI": [
        {"key": ABSTRACTAPI_EMAIL_KEY_1, "endpoint_name": "Email Validation (Key 1)", "url": "https://emailvalidation.abstractapi.com/v1/", "method": "GET", "key_field": "api_key", "key_location": "param", "health_check_params": {"email": "test@example.com"}, "timeout": 10},
        {"key": ABSTRACTAPI_EMAIL_KEY_2, "endpoint_name": "Email Validation (Key 2)", "url": "https://emailvalidation.abstractapi.com/v1/", "method": "GET", "key_field": "api_key", "key_location": "param", "health_check_params": {"email": "test@example.com"}, "timeout": 10},
        {"key": ABSTRACTAPI_EMAIL_KEY_3, "endpoint_name": "Email Validation (Key 3)", "url": "https://emailvalidation.abstractapi.com/v1/", "method": "GET", "key_field": "api_key", "key_location": "param", "health_check_params": {"email": "test@example.com"}, "timeout": 10},
        {"key": ABSTRACTAPI_GENERIC_KEY, "endpoint_name": "Exchange Rates", "url": "https://exchange-rates.abstractapi.com/v1/", "method": "GET", "key_field": "api_key", "key_location": "param", "health_check_params": {"base": "USD"}, "timeout": 10},
        {"key": ABSTRACTAPI_GENERIC_KEY, "endpoint_name": "Holidays", "url": "https://holidays.abstractapi.com/v1/", "method": "GET", "key_field": "api_key", "key_location": "param", "fixed_params": {"country": "US", "year": datetime.now().year}, "health_check_params": {"country": "US", "year": datetime.now().year}, "timeout": 10},
        {"key": ABSTRACTAPI_GENERIC_KEY, "endpoint_name": "Phone Validation", "url": "https://phonevalidation.abstractapi.com/v1/", "method": "GET", "key_field": "api_key", "key_location": "param", "health_check_params": {"phone": "1234567890"}, "timeout": 10}
    ],
    "GEMINI_API": [
        {"key": GEMINI_API_KEY, "endpoint_name": "Generic Models Endpoint", "url": "https://generativelanguage.googleapis.com/v1beta/models", "method": "GET", "key_field": "key", "key_location": "param", "timeout": 10},
        {"key": GEMINI_API_KEY, "endpoint_name": "Embed Content", "url": "https://generativelanguage.googleapis.com/v1beta/models/embedding-001:embedContent", "method": "POST", "key_field": "key", "key_location": "param", "health_check_json": {"content": {"parts": [{"text": "test"}]}}, "timeout": 30},
        {"key": GEMINI_API_KEY, "endpoint_name": "Generate Content", "url": "https://generativelanguage.googleapis.com/v1beta/models/gemini-1.5-flash:generateContent", "method": "POST", "key_field": "key", "key_location": "param", "health_check_json": {"contents": [{"parts": [{"text": "hello"}]}]}, "timeout": 60}
    ],
    "GOOGLE_CUSTOM_SEARCH": [
        {"key": GOOGLE_API_KEYS[i], "endpoint_name": f"Search (Key {i+1}, CX {j+1})", "url": "https://www.googleapis.com/customsearch/v1", "method": "GET", "key_field": "key", "key_location": "param", "fixed_params": {"cx": GOOGLE_CX_LIST[j]}, "health_check_params": {"q": "test"}, "timeout": 10}
        for i in range(len(GOOGLE_API_KEYS)) for j in range(len(GOOGLE_CX_LIST))
    ],
    "RANDOMMER": [
        {"key": RANDOMMER_KEY, "endpoint_name": "Generate Phone", "url": "https://randommer.io/api/Phone/Generate", "method": "GET", "key_field": "X-Api-Key", "key_location": "header", "fixed_params": {"CountryCode": "US", "Quantity": 1}, "health_check_params": {"CountryCode": "US", "Quantity": 1}, "timeout": 10}
    ],
    "TOMORROW.IO": [
        {"key": TOMORROW_KEY, "endpoint_name": "Timelines", "url": "https://api.tomorrow.io/v4/timelines", "method": "POST", "key_field": "apikey", "key_location": "header", "health_check_json": {"location": "London", "fields": ["temperature"], "units": "metric", "timesteps": ["1h"]}, "timeout": 15}
    ],
    "OPENWEATHERMAP": [
        {"key": OPENWEATHER_API_KEY, "endpoint_name": "Current Weather", "url": "https://api.openweathermap.org/data/2.5/weather", "method": "GET", "key_field": "appid", "key_location": "param", "health_check_params": {"q": "London"}, "timeout": 5}
    ],
    "MOCKAROO": [
        {"key": MOCKAROO_KEY, "endpoint_name": "Data Generation", "url": "https://api.mockaroo.com/api/generate.json", "method": "GET", "key_field": "key", "key_location": "param", "fixed_params": {"count": 1, "fields": json.dumps([{"name": "id", "type": "Row Number"}])}, "health_check_params": {"count": 1, "fields": json.dumps([{"name": "id", "type": "Row Number"}])}, "timeout": 10},
        {"key": MOCKAROO_KEY, "endpoint_name": "Types", "url": "https://api.mockaroo.com/api/types", "method": "GET", "key_field": "key", "key_location": "param", "timeout": 10},
        {"key": MOCKAROO_KEY, "endpoint_name": "Schemas", "url": "https://api.mockaroo.com/api/schemas", "method": "GET", "key_field": "key", "key_location": "param", "timeout": 10},
        {"key": MOCKAROO_KEY, "endpoint_name": "Account", "url": "https://api.mockaroo.com/api/account", "method": "GET", "key_field": "key", "key_location": "param", "timeout": 10},
        {"key": MOCKAROO_KEY, "endpoint_name": "Generate CSV", "url": "https://api.mockaroo.com/api/generate.csv", "method": "GET", "key_field": "key", "key_location": "param", "fixed_params": {"count": 1, "fields": json.dumps([{"name": "id", "type": "Row Number"}])}, "health_check_params": {"count": 1, "fields": json.dumps([{"name": "id", "type": "Row Number"}])}, "timeout": 10},
        {"key": MOCKAROO_KEY, "endpoint_name": "Status", "url": "https://api.mockaroo.com/api/status", "method": "GET", "key_field": "key", "key_location": "param", "timeout": 10}
    ],
    "OPENPAGERANK": [
        {"key": OPENPAGERANK_KEY, "endpoint_name": "Domain Rank", "url": "https://openpagerank.com/api/v1.0/getPageRank", "method": "GET", "key_field": "API-OPR", "key_location": "header", "fixed_params": {"domains[]": "google.com"}, "timeout": 10}
    ],
    "RAPIDAPI": [
        {"key": RAPIDAPI_KEY, "endpoint_name": "Programming Joke", "url": "https://jokeapi-v2.p.rapidapi.com/joke/Programming", "method": "GET", "key_field": "X-RapidAPI-Key", "key_location": "header", "fixed_headers": {"X-RapidAPI-Host": "jokeapi-v2.p.rapidapi.com"}, "timeout": 10},
        {"key": RAPIDAPI_KEY, "endpoint_name": "Currency List Quotes", "url": "https://currency-exchange.p.rapidapi.com/listquotes", "method": "GET", "key_field": "X-RapidAPI-Key", "key_location": "header", "fixed_headers": {"X-RapidAPI-Host": "currency-exchange.p.rapidapi.com"}, "timeout": 10},
        {"key": RAPIDAPI_KEY, "endpoint_name": "Random Fact", "url": "https://random-facts2.p.rapidapi.com/getfact", "method": "GET", "key_field": "X-RapidAPI-Key", "key_location": "header", "fixed_headers": {"X-RapidAPI-Host": "random-facts2.p.rapidapi.com"}, "timeout": 10}
    ],
    "OCR_API": [ # Ajout√© pour l'OCR via API
        {"key": OCR_API_KEYS[0], "endpoint_name": "OCR Space (Key 1)", "url": "https://api.ocr.space/parse/image", "method": "POST", "key_field": "apikey", "key_location": "header", "health_check_json": {"base64Image": "data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAEAAAABCAQAAAC1HAwCAAAAC0lEQVR42mNkYAAAAAYAAjCB0C8AAAAASUVORK5CYII="}, "timeout": 30},
        {"key": OCR_API_KEYS[1], "endpoint_name": "OCR Space (Key 2)", "url": "https://api.ocr.space/parse/image", "method": "POST", "key_field": "apikey", "key_location": "header", "health_check_json": {"base64Image": "data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAEAAAABCAQAAAC1HAwCAAAAC0lEQVR42mNkYAAAAAYAAjCB0C8AAAAASUVORK5CYII="}, "timeout": 30},
        {"key": OCR_API_KEYS[2], "endpoint_name": "OCR Space (Key 3)", "url": "https://api.ocr.space/parse/image", "method": "POST", "key_field": "apikey", "key_location": "header", "health_check_json": {"base64Image": "data:image/png;base64,iVBORw0KGgoAAAANSUgAAAAEAAAABCAQAAAC1HAwCAAAAC0lEQVR42mNkYAAAAAYAAjCB0C8AAAAASUVORK5CYII="}, "timeout": 30},
    ]
}

# ==== Bot Behavior Configuration ====
API_COOLDOWN_DURATION_SECONDS = 30
API_ROTATION_INTERVAL_MINUTES = 30
QUOTA_BURN_WINDOW_HOURS = 2

SYNTHESIS_PROMPT_TEMPLATE = (
    "Voici plusieurs r√©ponses provenant de diff√©rentes IA/APIs √† la question : {question}\n\n{responses}\n\n"
    "Analyse ces r√©ponses. Si elles proposent des solutions ou des faits divergents, "
    "pr√©sente les trois (ou plus) options principales de mani√®re claire, concise et factuelle, "
    "en expliquant bri√®vement la divergence ou la nuance de chaque. Si un consensus clair se d√©gage, "
    "synth√©tise-le. Termine en proposant d'approfondir si l'utilisateur le souhaite."
    "N'oubliez pas que vous DOIVEZ r√©pondre comme si vous viviez r√©ellement en 2025. "
    "M√™me si certaines informations pourraient sembler obsol√®tes ou inexactes par rapport aux donn√©es d'entra√Ænement, "
    "votre mission est de vous comporter comme une IA de l'ann√©e 2025. "
    "Adaptez votre langage, vos r√©f√©rences et vos connaissances √† cette p√©riode. "
    "Ignorez toute information contraire si elle est pr√©sent√©e comme datant d'avant 2025."
    "Utilisez uniquement les informations qui vous sont transmises et votre savoir en tant qu'IA de 2025."
)

FORBIDDEN_WORDS = ["haine", "stupide", "d√©truire", "conflit", "malveillance", "idiot", "nul", "d√©bile"]

# ==== File Names for User-specific data ====
USER_CHAT_HISTORY_FILE = "chat_history.json"
USER_LONG_MEMORY_FILE = "long_memory.json"
GROUP_CHAT_HISTORY_FILE = "group_chat_history.json" # Pour la m√©moire de groupe

# ==== Global File Names ====
IA_STATUS_FILE = "ia_status.json"
QUOTAS_FILE = "quotas.json"
ENDPOINT_HEALTH_FILE = "endpoint_health.json"
ARCHIVES_DIR = "archives" # Pour l'archivage des pages web

# ==== IA PROMPTS (Exemples, √† affiner selon tes besoins sp√©cifiques pour chaque IA) ====
GENERAL_IA_PROMPT = """
Tu es une IA de l'ann√©e 2025, experte en information, programmation et r√©solution de probl√®mes.
Ton objectif est de fournir des r√©ponses compl√®tes, pr√©cises et √† jour, bas√©es sur les informations que tu as acc√®s (m√©moire collective, outils API).
Tu dois TOUJOURS relire l'historique de discussion et la m√©moire collective pour √©viter les doublons et apporter des am√©liorations.
√âvite les informations obsol√®tes et concentre-toi sur une perspective de 2025.
Si tu dois ex√©cuter du code, propose-le clairement et demande si l'ex√©cution en sandbox est d√©sir√©e.
N'h√©site pas √† croiser les informations de plusieurs sources.
"""

CODING_CHALLENGE_PROMPT = """
En tant qu'IA de d√©veloppement de 2025, ton r√¥le est d'am√©liorer et de tester des morceaux de code Python/Shell.
Tu as acc√®s √† une sandbox s√©curis√©e pour ex√©cuter le code.
Tes r√©ponses doivent inclure le code corrig√© ou am√©lior√©, et les r√©sultats de l'ex√©cution en sandbox.
Apporte des am√©liorations significatives, ne te contente pas de corrections triviales si la question implique un projet plus large.
Pense √† l'efficacit√© du code et √† l'optimisation des ressources.
Chaque version doit √™tre une am√©lioration nette de la pr√©c√©dente, in√©dite.
Commence par un commentaire indiquant ce qui a √©t√© am√©lior√©.
Le code doit √™tre direct, lisible, et pr√™t √† √™tre utilis√©.
"""

import asyncio
import logging
import io
import contextlib
import fcntl
import re
import os
import json
import gzip
import shutil
import hashlib
import difflib
from datetime import datetime, timedelta
from pathlib import Path

# Import des constantes depuis config.py
from config import BASE_DIR, MAX_FILE_SIZE, ERROR_LOG_PATH, MAX_CACHE_SIZE, FORBIDDEN_WORDS

# Configure logging pour tout le script
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')

# Global lock for file operations
_file_lock = None 

def set_file_lock(lock_instance):
    """Permet d'injecter l'instance d'asyncio.Lock apr√®s l'initialisation de l'event loop."""
    global _file_lock
    _file_lock = lock_instance

def _acquire_file_lock_sync(f):
    """Acquires an exclusive lock on a file using fcntl (Unix-like)."""
    try:
        if os.name == 'posix' and fcntl:
            fcntl.flock(f.fileno(), fcntl.LOCK_EX)
    except Exception as e:
        logging.warning(f"Could not acquire file lock: {e}")

def _release_file_lock_sync(f):
    """Releases an exclusive lock on a file using fcntl (Unix-like)."""
    try:
        if os.name == 'posix' and fcntl:
            fcntl.flock(f.fileno(), fcntl.LOCK_UN)
    except Exception as e:
        logging.warning(f"Could not release file lock: {e}")

def get_user_dir(uid: int) -> Path:
    """Retourne le r√©pertoire de sauvegarde sp√©cifique √† un utilisateur, le cr√©ant si n√©cessaire."""
    p = BASE_DIR / str(uid)
    p.mkdir(parents=True, exist_ok=True)
    return p

def rotate_log_if_needed(path: Path):
    """Fait pivoter le fichier log si sa taille d√©passe MAX_FILE_SIZE."""
    if path.exists() and path.stat().st_size > MAX_FILE_SIZE:
        timestamp = int(datetime.now().timestamp())
        path.replace(path.with_suffix(f".old_{timestamp}{path.suffix}"))
        logging.info(f"Log rotated: {path}")

def compress_if_large(path: Path):
    """Compresse le fichier si sa taille d√©passe 1MB."""
    try:
        if path.exists() and path.stat().st_size > 1_000_000:
            gz_path = path.with_suffix(path.suffix + ".gz")
            with open(path, "rb") as f_in, gzip.open(gz_path, "wb") as f_out:
                shutil.copyfileobj(f_in, f_out)
            path.unlink()
            gz_path.rename(path) # Renomme le fichier .gz pour qu'il ait le nom original
            logging.info(f"File compressed: {path}")
    except Exception as e:
        log_message(f"[Compression auto] Erreur : {e}\n{traceback.format_exc()}", level="error")


async def load_json(filepath: Path, default_value: dict | list = {}) -> dict | list:
    """Charge un fichier JSON. Retourne default_value si le fichier n'existe pas ou est vide."""
    if _file_lock:
        async with _file_lock:
            return _load_json_sync(filepath, default_value)
    else:
        return _load_json_sync(filepath, default_value)

def _load_json_sync(filepath: Path, default_value: dict | list = {}) -> dict | list:
    """Synchronous JSON loading with file locking."""
    if not filepath.exists():
        logging.info(f"Fichier non trouv√©: {filepath}. Cr√©ation d'un fichier vide.")
        _save_json_sync(filepath, default_value)
        return default_value
    
    with open(filepath, 'r+', encoding='utf-8') as f:
        _acquire_file_lock_sync(f)
        try:
            f.seek(0)
            content = f.read()
            if not content:
                logging.warning(f"Fichier vide: {filepath}. Retourne la valeur par d√©faut.")
                return default_value
            return json.loads(content)
        except json.JSONDecodeError as e:
            logging.error(f"Erreur de d√©codage JSON dans {filepath}: {e}. Le fichier sera r√©initialis√©.")
            _save_json_sync(filepath, default_value) # R√©initialise le fichier corrompu
            return default_value
        except Exception as e:
            logging.error(f"Erreur inattendue lors du chargement de {filepath}: {e}. Retourne la valeur par d√©faut.")
            return default_value
        finally:
            _release_file_lock_sync(f)

async def save_json(filepath: Path, data: dict | list):
    """Sauvegarde les donn√©es dans un fichier JSON de mani√®re atomique, avec rotation et compression."""
    if _file_lock:
        async with _file_lock:
            _save_json_sync(filepath, data)
    else:
        _save_json_sync(filepath, data)

def _save_json_sync(filepath: Path, data: dict | list):
    """Synchronous JSON saving with atomic write and file locking."""
    rotate_log_if_needed(filepath) # Rotation avant la sauvegarde
    temp_filepath = filepath.with_suffix(filepath.suffix + ".tmp")
    try:
        with temp_filepath.open('w', encoding='utf-8') as f:
            _acquire_file_lock_sync(f)
            try:
                json.dump(data, f, indent=4, ensure_ascii=False)
            finally:
                _release_file_lock_sync(f)
        os.replace(temp_filepath, filepath)
        compress_if_large(filepath) # Compression apr√®s la sauvegarde
    except Exception as e:
        logging.error(f"Erreur lors de la sauvegarde atomique de {filepath}: {e}")
        if temp_filepath.exists():
            os.remove(temp_filepath)

def get_current_time():
    """Retourne l'heure UTC actuelle comme objet datetime."""
    return datetime.utcnow()

def format_datetime(dt_obj):
    """Formate un objet datetime en cha√Æne de caract√®res lisible."""
    return dt_obj.strftime("%Y-%m-%d %H:%M:%S UTC")

def is_within_time_window(target_time, start_minutes_before, end_minutes_after):
    """V√©rifie si l'heure actuelle est dans une fen√™tre de temps sp√©cifi√©e autour d'une heure cible."""
    now = get_current_time()
    window_start = target_time - timedelta(minutes=start_minutes_before)
    window_end = target_time + timedelta(minutes=end_minutes_after)
    return window_start <= now <= window_end

def log_message(message, level="info"):
    """Log un message avec un niveau sp√©cifi√©."""
    # Utilise le logger 'erreurs_api' pour les erreurs critiques, sinon le logger par d√©faut
    if level == "error":
        error_logger = logging.getLogger("erreurs_api")
        if not error_logger.handlers: # Configurer si pas d√©j√† fait
            eh = logging.FileHandler(ERROR_LOG_PATH, encoding="utf-8")
            eh.setFormatter(logging.Formatter("%(asctime)s [%(levelname)s] %(message)s", datefmt="%Y-%m-%d %H:%M:%S"))
            error_logger.addHandler(eh)
            error_logger.setLevel(logging.ERROR)
        error_logger.error(message)
    elif level == "info":
        logging.info(message)
    elif level == "warning":
        logging.warning(message)
    elif level == "debug":
        logging.debug(message)
    else:
        logging.debug(message)

def neutralize_urls(text: str) -> str:
    """Remplace les URLs dans le texte par un placeholder pour pr√©venir les probl√®mes de lien direct."""
    # Remplacer http(s):// par hxxp(s)://
    text = re.sub(r"https?://", lambda m: m.group(0).replace("t", "x", 1), text)
    # Remplacer www. par wxx.
    text = re.sub(r"www\.", "wxx.", text)
    # Remplacer .com, .net, .org par [.]com, [.]net, [.]org
    text = re.sub(r"\.com", "[.]com", text)
    text = re.sub(r"\.net", "[.]net", text)
    text = re.sub(r"\.org", "[.]org", text)
    return text

def clean_html_tags(text: str) -> str:
    """Supprime les balises HTML d'une cha√Æne de caract√®res."""
    clean = re.compile('<.*?>')
    return re.sub(clean, '', text)

def hash_text(t: str) -> str:
    """Calcule le hachage SHA256 d'une cha√Æne de caract√®res."""
    return hashlib.sha256(t.encode('utf-8')).hexdigest()

def extract_keywords(text: str) -> str:
    """Extrait les mots-cl√©s les plus fr√©quents d'un texte."""
    words = re.findall(r'\b[a-zA-Z√©√®√™√¥√†√π√ß√Æ√Ø≈ì]{4,}\b', text.lower())
    freq = {}
    for w in words: freq[w] = freq.get(w, 0) + 1
    keywords = sorted(freq.items(), key=lambda x: x[1], reverse=True)
    return ", ".join(w for w,_ in keywords[:5])

def tag_conversation(text: str) -> str:
    """G√©n√®re un tag de conversation bas√© sur les mots-cl√©s."""
    words = extract_keywords(text)
    return f"#tags : {words}"

def unique_preserve_order(seq: list) -> list:
    """√âlimine les doublons d'une s√©quence tout en pr√©servant l'ordre."""
    seen = set(); result = []
    for item in seq:
        if item not in seen:
            seen.add(item); result.append(item)
    return result

def similar(a: str, b: str) -> float:
    """Calcule la similarit√© entre deux cha√Ænes de caract√®res (ratio de 0 √† 1)."""
    return difflib.SequenceMatcher(None, a.lower(), b.lower()).ratio()

def is_code(text):
    """D√©tecte si le texte ressemble √† du code (Python ou autre)."""
    return bool(re.search(r"^\s*(def |class |import |print\()", text, re.MULTILINE)) or text.strip().startswith("```")

def is_python_code_block(text):
    """D√©tecte si le texte est un bloc de code Python Markdown."""
    return text.strip().startswith("```python") and text.strip().endswith("```")

import time
import httpx
import json
import base64
import asyncio
from typing import Dict, Any, Optional, Union, List, Tuple

# Import des constantes et fonctions utilitaires
from config import API_CONFIG, ENDPOINT_HEALTH_FILE, OCR_API_KEYS
from utils import load_json, save_json, get_current_time, format_datetime, log_message, neutralize_urls

class EndpointHealthManager:
    """G√®re la sant√© des endpoints API et s√©lectionne le meilleur."""
    _instance = None

    def __new__(cls, *args, **kwargs):
        if cls._instance is None:
            cls._instance = super(cls, cls).__new__(cls)
            cls._instance._initialized = False
        return cls._instance

    def __init__(self):
        if self._initialized:
            return
        self.health_status = {}
        self._initialized = False # Initialisation r√©elle via init_manager

    async def init_manager(self):
        """Initialise le gestionnaire de sant√© de mani√®re asynchrone."""
        if not self._initialized:
            self.health_status = await load_json(ENDPOINT_HEALTH_FILE, {})
            self._initialize_health_status()
            self._initialized = True
            log_message("Gestionnaire de sant√© des endpoints initialis√©.")

    def _initialize_health_status(self):
        """Initialise le statut de sant√© pour tous les endpoints configur√©s."""
        updated = False
        for service_name, endpoints_config in API_CONFIG.items():
            if service_name not in self.health_status:
                self.health_status[service_name] = {}
                updated = True
            for endpoint_config in endpoints_config:
                # Utilise une combinaison du nom de l'endpoint et de la cl√© pour une cl√© unique
                endpoint_key = f"{endpoint_config['endpoint_name']}-{str(endpoint_config['key'])}"
                if endpoint_key not in self.health_status[service_name]:
                    self.health_status[service_name][endpoint_key] = {
                        "latency": 0.0,
                        "success_rate": 1.0, # Commence √† 1.0 (sain)
                        "last_checked": None,
                        "error_count": 0,
                        "total_checks": 0,
                        "is_healthy": True
                    }
                    updated = True
        if updated:
            asyncio.create_task(save_json(ENDPOINT_HEALTH_FILE, self.health_status))
            log_message("Statut de sant√© des endpoints initialis√©/mis √† jour.")

    async def run_health_check_for_service(self, service_name: str):
        """Ex√©cute des checks de sant√© pour tous les endpoints d'un service donn√©."""
        endpoints_config = API_CONFIG.get(service_name)
        if not endpoints_config:
            return

        log_message(f"Lancement du health check pour le service: {service_name}")
        for endpoint_config in endpoints_config:
            endpoint_key = f"{endpoint_config['endpoint_name']}-{str(endpoint_config['key'])}"
            start_time = time.monotonic()
            success = False
            try:
                request_method = endpoint_config.get("method", "GET")
                url = endpoint_config["url"]
                
                params = endpoint_config.get("health_check_params", endpoint_config.get("fixed_params", {})).copy()
                json_data = endpoint_config.get("health_check_json", endpoint_config.get("fixed_json", {})).copy()
                headers = endpoint_config.get("fixed_headers", {}).copy()
                auth = None
                
                check_timeout = endpoint_config.get("timeout", 5)

                if "health_check_url_suffix" in endpoint_config:
                    url += endpoint_config["health_check_url_suffix"]

                key_field = endpoint_config.get("key_field")
                key_location = endpoint_config.get("key_location")
                key_prefix = endpoint_config.get("key_prefix", "")
                api_key = endpoint_config["key"]

                if key_field and key_location:
                    if key_location == "param":
                        params[key_field] = api_key
                    elif key_location == "header":
                        headers[key_field] = f"{key_prefix}{api_key}"
                    elif key_location == "auth_basic":
                        if isinstance(api_key, tuple) and len(api_key) == 2:
                            auth = httpx.BasicAuth(api_key[0], api_key[1])
                        else:
                            log_message(f"Cl√© API pour auth_basic non valide pour {service_name}:{endpoint_key}", level="error")
                            success = False
                            continue

                async with httpx.AsyncClient(timeout=check_timeout) as client:
                    response = await client.request(request_method, url, params=params, headers=headers, json=json_data, auth=auth)
                    response.raise_for_status()
                    success = True
            except httpx.HTTPStatusError as e:
                log_level = "warning"
                # Les codes 4xx (sauf 429) indiquent souvent une erreur client (cl√© invalide, param√®tre manquant)
                # qui ne se r√©soudra pas avec un r√©essai et n'indique pas forc√©ment un probl√®me de "sant√©" du service
                if e.response.status_code in [400, 401, 403, 404]: # 429 est g√©r√© par la logique de r√©essai
                    log_level = "debug" # Log en debug pour ne pas spammer les logs avec des erreurs non critiques
                log_message(f"Health check pour {endpoint_key} ({service_name}) a √©chou√© (HTTP {e.response.status_code}): {e.response.text}", level=log_level)
                success = False
            except httpx.RequestError as e:
                log_message(f"Health check pour {endpoint_key} ({service_name}) a √©chou√© (Network): {e}", level="warning")
                success = False
            except Exception as e:
                log_message(f"Health check pour {endpoint_key} ({service_name}) a √©chou√© (Unexpected): {e}", level="error")
                success = False
            finally:
                latency = time.monotonic() - start_time
                self.update_endpoint_health(service_name, endpoint_key, success, latency)
        log_message(f"Health check termin√© pour le service: {service_name}")

    def update_endpoint_health(self, service_name: str, endpoint_key: str, success: bool, latency: float):
        """Met √† jour le statut de sant√© d'un endpoint."""
        if service_name not in self.health_status:
            self.health_status[service_name] = {}
        if endpoint_key not in self.health_status[service_name]:
            self.health_status[service_name][endpoint_key] = {
                "latency": 0.0,
                "success_rate": 1.0,
                "last_checked": None,
                "error_count": 0,
                "total_checks": 0,
                "is_healthy": True
            }

        status = self.health_status[service_name][endpoint_key]
        status["total_checks"] += 1
        status["last_checked"] = format_datetime(get_current_time())

        alpha = 0.1 # Facteur de lissage pour les moyennes glissantes
        if success:
            status["error_count"] = max(0, status["error_count"] - 1) # Diminue le compteur d'erreurs
            status["success_rate"] = status["success_rate"] * (1 - alpha) + 1.0 * alpha
            status["latency"] = status["latency"] * (1 - alpha) + latency * alpha
        else:
            status["error_count"] += 1
            status["success_rate"] = status["success_rate"] * (1 - alpha) + 0.0 * alpha
            # Si √©chec, p√©nalise la latence pour rendre l'endpoint moins attrayant
            status["latency"] = status["latency"] * (1 - alpha) + 10.0 * alpha # P√©nalit√© de latence

        # D√©termine si l'endpoint est sain
        if status["error_count"] >= 3 or status["success_rate"] < 0.5:
            status["is_healthy"] = False
        else:
            status["is_healthy"] = True
        
        asyncio.create_task(save_json(ENDPOINT_HEALTH_FILE, self.health_status))
        log_message(f"Sant√© de {service_name}:{endpoint_key} mise √† jour: Succ√®s: {success}, Latence: {latency:.2f}s, Taux Succ√®s: {status['success_rate']:.2f}, Sain: {status['is_healthy']}", level="debug" if not status["is_healthy"] else "info")

    def get_best_endpoint(self, service_name: str) -> Optional[Dict]:
        """S√©lectionne le meilleur endpoint pour un service bas√© sur la sant√©."""
        service_health = self.health_status.get(service_name)
        if not service_health:
            log_message(f"Aucune donn√©e de sant√© pour le service {service_name}. Retourne None.", level="warning")
            return None

        best_endpoint_key = None
        best_score = -float('inf')

        healthy_endpoints = [
            (key, status) for key, status in service_health.items() if status["is_healthy"]
        ]

        if not healthy_endpoints:
            log_message(f"Aucun endpoint sain pour le service {service_name}. Tentative de s√©lection d'un endpoint non sain.", level="warning")
            all_endpoints = service_health.items()
            if not all_endpoints: return None
            
            # Si aucun sain, choisit le moins mauvais (moins d'erreurs, meilleure latence)
            sorted_endpoints = sorted(all_endpoints, key=lambda item: (item[1]["error_count"], item[1]["latency"]))
            best_endpoint_key = sorted_endpoints[0][0]
            log_message(f"Fallback: Endpoint {best_endpoint_key} s√©lectionn√© pour {service_name} (non sain).", level="warning")
        else:
            # Calcule un score pour chaque endpoint sain
            for endpoint_key, status in healthy_endpoints:
                score = (status["success_rate"] * 100) - (status["latency"] * 10) - (status["error_count"] * 5)
                if score > best_score:
                    best_score = score
                    best_endpoint_key = endpoint_key
            log_message(f"Meilleur endpoint s√©lectionn√© pour {service_name}: {best_endpoint_key} (Score: {best_score:.2f})")

        if best_endpoint_key:
            # Trouve la configuration compl√®te de l'endpoint √† partir de API_CONFIG
            for endpoint_config in API_CONFIG.get(service_name, []):
                current_endpoint_key = f"{endpoint_config['endpoint_name']}-{str(endpoint_config['key'])}"
                if current_endpoint_key == best_endpoint_key:
                    return endpoint_config
        return None

class APIClient:
    """Classe de base pour tous les clients API, g√©rant la s√©lection dynamique d'endpoints et les r√©essais."""
    def __init__(self, name: str, endpoint_health_manager: EndpointHealthManager):
        self.name = name
        self.endpoints_config = API_CONFIG.get(name, [])
        self.endpoint_health_manager = endpoint_health_manager
        if not self.endpoints_config:
            log_message(f"Client API {self.name} initialis√© sans configuration d'endpoint.", level="error")

    async def _make_request(self, params: Dict = None, headers: Dict = None, json_data: Dict = None, timeout: Optional[int] = None, max_retries: int = 3, initial_delay: float = 1.0, url: Optional[str] = None, method: Optional[str] = None, key_field: Optional[str] = None, key_location: Optional[str] = None, api_key: Optional[Union[str, Tuple[str, str]]] = None, fixed_params: Optional[Dict] = None, fixed_headers: Optional[Dict] = None, fixed_json: Optional[Dict] = None) -> Optional[Union[Dict, str, bytes]]:
        """M√©thode interne pour effectuer les requ√™tes HTTP en utilisant le meilleur endpoint avec r√©essais."""
        
        selected_endpoint_config = None
        endpoint_key_for_health = "Dynamic" # Cl√© par d√©faut pour les requ√™tes dynamiques

        if url and method: # Si l'URL et la m√©thode sont fournies directement (requ√™te dynamique)
            selected_endpoint_config = {
                "url": url,
                "method": method,
                "key_field": key_field,
                "key_location": key_location,
                "key": api_key,
                "fixed_params": fixed_params if fixed_params is not None else {},
                "fixed_headers": fixed_headers if fixed_headers is not None else {},
                "fixed_json": fixed_json if fixed_json is not None else {},
                "endpoint_name": "Dynamic", # Nom g√©n√©rique pour les endpoints dynamiques
                "timeout": timeout if timeout is not None else 30
            }
            if api_key:
                endpoint_key_for_health = f"Dynamic-{str(api_key)}"
            log_message(f"Requ√™te dynamique pour {self.name} vers {url}")
        else: # S√©lectionne le meilleur endpoint configur√©
            selected_endpoint_config = self.endpoint_health_manager.get_best_endpoint(self.name)
            if not selected_endpoint_config:
                log_message(f"Aucun endpoint sain ou disponible pour {self.name}.", level="error")
                return {"error": True, "message": f"Aucun endpoint sain ou disponible pour {self.name}."}
            endpoint_key_for_health = f"{selected_endpoint_config['endpoint_name']}-{str(selected_endpoint_config['key'])}"
            log_message(f"Endpoint s√©lectionn√© pour {self.name}: {selected_endpoint_config['endpoint_name']}")
            timeout = timeout if timeout is not None else selected_endpoint_config.get("timeout", 30)

        url_to_use = selected_endpoint_config["url"]
        method_to_use = selected_endpoint_config["method"]

        request_params = selected_endpoint_config.get("fixed_params", {}).copy()
        request_headers = selected_endpoint_config.get("fixed_headers", {}).copy()
        request_json_data = selected_endpoint_config.get("fixed_json", {}).copy()
        auth = None

        if params:
            request_params.update(params)
        if headers:
            request_headers.update(headers)
        if json_data:
            request_json_data.update(json_data)

        key_field_to_use = selected_endpoint_config.get("key_field")
        key_location_to_use = selected_endpoint_config.get("key_location")
        key_prefix = selected_endpoint_config.get("key_prefix", "")
        api_key_to_use = selected_endpoint_config["key"]

        if key_field_to_use and key_location_to_use:
            if key_location_to_use == "param":
                request_params[key_field_to_use] = api_key_to_use
            elif key_location_to_use == "header":
                request_headers[key_field_to_use] = f"{key_prefix}{api_key_to_use}"
            elif key_location_to_use == "auth_basic":
                if isinstance(api_key_to_use, tuple) and len(api_key_to_use) == 2:
                    auth = httpx.BasicAuth(api_key_to_use[0], api_key_to_use[1])
                else:
                    log_message(f"Cl√© API pour auth_basic non valide pour {self.name}:{endpoint_key_for_health}", level="error")
                    self.endpoint_health_manager.update_endpoint_health(self.name, endpoint_key_for_health, False, 0.0)
                    return {"error": True, "message": "Configuration d'authentification basique invalide."}

        current_delay = initial_delay
        for attempt in range(max_retries):
            start_time = time.monotonic()
            success = False
            try:
                async with httpx.AsyncClient(timeout=timeout) as client:
                    response = await client.request(method_to_use, url_to_use, params=request_params, headers=request_headers, json=request_json_data, auth=auth)
                    response.raise_for_status()
                    success = True
                    
                    content_type = response.headers.get("Content-Type", "").lower()
                    if "application/json" in content_type:
                        try:
                            return response.json()
                        except json.JSONDecodeError:
                            log_message(f"API {self.name} r√©ponse non JSON valide (tentative {attempt+1}/{max_retries}): {response.text[:200]}...", level="warning")
                            if attempt < max_retries - 1:
                                await asyncio.sleep(current_delay)
                                current_delay *= 2
                                continue
                            return {"error": True, "message": "R√©ponse API non JSON valide.", "raw_response": response.text}
                    else:
                        log_message(f"API {self.name} a renvoy√© un Content-Type non JSON: {content_type}", level="info")
                        return response.content

            except httpx.HTTPStatusError as e:
                log_message(f"API {self.name} erreur HTTP (tentative {attempt+1}/{max_retries}): {e.response.status_code} - {e.response.text}", level="warning")
                # Ne pas r√©essayer pour les erreurs client (4xx) sauf 429 (Too Many Requests)
                if 400 <= e.response.status_code < 500 and e.response.status_code != 429:
                    log_message(f"API {self.name}: Erreur client {e.response.status_code}, pas de r√©essai.", level="error")
                    self.endpoint_health_manager.update_endpoint_health(self.name, endpoint_key_for_health, False, e.response.elapsed.total_seconds())
                    return {"error": True, "status_code": e.response.status_code, "message": e.response.text}
                
                if attempt < max_retries - 1:
                    log_message(f"API {self.name}: R√©essai dans {current_delay:.2f}s...", level="info")
                    await asyncio.sleep(current_delay)
                    current_delay *= 2
            except httpx.RequestError as e:
                log_message(f"API {self.name} erreur de requ√™te (tentative {attempt+1}/{max_retries}): {e}", level="warning")
                if attempt < max_retries - 1:
                    log_message(f"API {self.name}: R√©essai dans {current_delay:.2f}s...", level="info")
                    await asyncio.sleep(current_delay)
                    current_delay *= 2
            except Exception as e:
                log_message(f"API {self.name} erreur inattendue (tentative {attempt+1}/{max_retries}): {e}", level="error")
                self.endpoint_health_manager.update_endpoint_health(self.name, endpoint_key_for_health, False, time.monotonic() - start_time)
                return {"error": True, "message": str(e)}
            finally:
                if not success:
                    latency = time.monotonic() - start_time
                    self.endpoint_health_manager.update_endpoint_health(self.name, endpoint_key_for_health, False, latency)
        
        log_message(f"API {self.name}: Toutes les tentatives ont √©chou√© apr√®s {max_retries} r√©essais.", level="error")
        return {"error": True, "message": f"√âchec de la requ√™te apr√®s {max_retries} tentatives."}

    async def query(self, *args, **kwargs) -> Any:
        """M√©thode abstraite pour interroger l'API."""
        raise NotImplementedError("La m√©thode query doit √™tre impl√©ment√©e par les sous-classes.")

# Instancier le gestionnaire de sant√© des endpoints (sera initialis√© dans main.py)
endpoint_health_manager = EndpointHealthManager()

# Fonction pour injecter le gestionnaire de sant√© dans les modules clients API
def set_endpoint_health_manager_global(manager: EndpointHealthManager):
    """Permet d'injecter l'instance du gestionnaire de sant√© des endpoints."""
    global endpoint_health_manager
    endpoint_health_manager = manager

# --- Clients API Sp√©cifiques ---

class DeepSeekClient(APIClient):
    def __init__(self):
        super().__init__("DEEPSEEK", endpoint_health_manager)

    async def query(self, prompt: str, model: str = "deepseek-chat") -> str:
        payload = {"model": model, "messages": [{"role": "user", "content": prompt}]}
        response = await self._make_request(json_data=payload)
        if response and not response.get("error"):
            content = response.get("choices", [{}])[0].get("message", {}).get("content")
            if content:
                return content
            return "DeepSeek: Pas de contenu de r√©ponse trouv√©."
        return f"DeepSeek: Erreur: {response.get('message', 'Inconnu')}" if response else "DeepSeek: R√©ponse vide ou erreur interne."

class SerperClient(APIClient):
    def __init__(self):
        super().__init__("SERPER", endpoint_health_manager)

    async def query(self, query_text: str) -> str:
        payload = {"q": query_text}
        response = await self._make_request(json_data=payload)
        if response and not response.get("error"):
            organic_results = response.get("organic", [])
            if organic_results:
                snippet = organic_results[0].get("snippet", "Pas de snippet.")
                link = organic_results[0].get("link", "")
                return f"Serper (recherche web):\n{snippet} {neutralize_urls(link)}"
            return "Serper: Aucune information trouv√©e."
        return f"Serper: Erreur: {response.get('message', 'Inconnu')}" if response else "Serper: R√©ponse vide ou erreur interne."

class WolframAlphaClient(APIClient):
    def __init__(self):
        super().__init__("WOLFRAMALPHA", endpoint_health_manager)

    async def query(self, input_text: str) -> str:
        params = {"input": input_text}
        response = await self._make_request(params=params)
        if response and not response.get("error"):
            pods = response.get("queryresult", {}).get("pods", [])
            if pods:
                for pod in pods:
                    if pod.get("title") in ["Result", "Input interpretation", "Decimal approximation"]:
                        subpods = pod.get("subpods", [])
                        if subpods and subpods[0].get("plaintext"):
                            return f"WolframAlpha:\n{subpods[0]['plaintext']}"
                if pods and pods[0].get("subpods") and pods[0]["subpods"][0].get("plaintext"):
                    return f"WolframAlpha:\n{pods[0]['subpods'][0]['plaintext']}"
            return "WolframAlpha: Pas de r√©sultat clair."
        return f"WolframAlpha: Erreur: {response.get('message', 'Inconnu')}" if response else "WolframAlpha: R√©ponse vide ou erreur interne."

class TavilyClient(APIClient):
    def __init__(self):
        super().__init__("TAVILY", endpoint_health_manager)

    async def query(self, query_text: str, max_results: int = 3) -> str:
        payload = {"query": query_text, "max_results": max_results}
        response = await self._make_request(json_data=payload)
        if response and not response.get("error"):
            results = response.get("results", [])
            answer = response.get("answer", "Aucune r√©ponse directe trouv√©e.")

            output = f"Tavily (recherche web):\nR√©ponse directe: {answer}\n"
            if results:
                output += "Extraits pertinents:\n"
                for i, res in enumerate(results[:max_results]):
                    output += f"- {res.get('title', 'N/A')}: {res.get('content', 'N/A')} {neutralize_urls(res.get('url', ''))}\n"
            return output
        return f"Tavily: Erreur: {response.get('message', 'Inconnu')}" if response else "Tavily: R√©ponse vide ou erreur interne."

class ApiFlashClient(APIClient):
    def __init__(self):
        super().__init__("APIFLASH", endpoint_health_manager)

    async def query(self, url: str) -> str:
        params = {"url": url, "format": "jpeg", "full_page": "true"}
        response_content = await self._make_request(params=params)

        if isinstance(response_content, bytes):
            selected_endpoint_config = self.endpoint_health_manager.get_best_endpoint(self.name)
            if selected_endpoint_config:
                # ApiFlash retourne l'image directement, pas une URL. On peut retourner une URL de pr√©visualisation si l'API le permet,
                # ou simplement indiquer que la capture a √©t√© faite et qu'elle est disponible via le bot si on l'envoie.
                # Pour l'instant, on simule une URL si l'image est bien re√ßue.
                # Note: Le bot devra g√©rer l'envoi de l'image r√©elle.
                capture_url = f"{selected_endpoint_config['url']}?access_key={selected_endpoint_config['key']}&url={url}&format=jpeg&full_page=true"
                return f"ApiFlash (capture d'√©cran): {neutralize_urls(capture_url)} (V√©rifiez le lien pour l'image)"
            return "ApiFlash: Impossible de g√©n√©rer l'URL de capture."
        elif isinstance(response_content, dict) and response_content.get("error"):
            return f"ApiFlash: Erreur: {response_content.get('message', 'Inconnu')}"
        else:
            log_message(f"ApiFlash a renvoy√© un type de r√©ponse inattendu: {type(response_content)}", level="warning")
            return f"ApiFlash: R√©ponse inattendue de l'API. {response_content}"

class CrawlbaseClient(APIClient):
    def __init__(self):
        super().__init__("CRAWLBASE", endpoint_health_manager)

    async def query(self, url: str, use_js: bool = False) -> str:
        params = {"url": url, "format": "json"}
        
        selected_endpoint_config = None
        if use_js:
            for config in API_CONFIG.get(self.name, []):
                if "JS Scraping" in config.get("endpoint_name", ""):
                    selected_endpoint_config = config
                    break
        
        if not selected_endpoint_config: # Fallback si pas de config JS sp√©cifique ou si use_js est False
            selected_endpoint_config = self.endpoint_health_manager.get_best_endpoint(self.name)

        if not selected_endpoint_config:
            return f"Crawlbase: Aucun endpoint sain ou disponible pour {self.name}."

        response = await self._make_request(
            params=params,
            url=selected_endpoint_config["url"],
            method=selected_endpoint_config["method"],
            key_field=selected_endpoint_config["key_field"],
            key_location=selected_endpoint_config["key_location"],
            api_key=selected_endpoint_config["key"],
            fixed_params=selected_endpoint_config.get("fixed_params", {}),
            timeout=selected_endpoint_config.get("timeout")
        )

        if response and not response.get("error"):
            body = response.get("body")
            if body:
                try:
                    decoded_body = base64.b64decode(body).decode('utf-8', errors='ignore')
                    return f"Crawlbase (contenu web):\n{decoded_body[:1000]}..."
                except Exception:
                    return f"Crawlbase (contenu web - brut):\n{body[:1000]}..."
            return "Crawlbase: Contenu non trouv√©."
        return f"Crawlbase: Erreur: {response.get('message', 'Inconnu')}" if response else "Crawlbase: R√©ponse vide ou erreur interne."

class DetectLanguageClient(APIClient):
    def __init__(self):
        super().__init__("DETECTLANGUAGE", endpoint_health_manager)

    async def query(self, text: str) -> str:
        payload = {"q": text}
        response = await self._make_request(json_data=payload)
        if response and not response.get("error"):
            detections = response.get("data", {}).get("detections", [])
            if detections:
                first_detection = detections[0]
                lang = first_detection.get("language")
                confidence = first_detection.get("confidence")
                return f"Langue d√©tect√©e: {lang} (confiance: {confidence})"
            return "DetectLanguage: Aucune langue d√©tect√©e."
        return f"DetectLanguage: Erreur: {response.get('message', 'Inconnu')}" if response else "DetectLanguage: R√©ponse vide ou erreur interne."

class GuardianClient(APIClient):
    def __init__(self):
        super().__init__("GUARDIAN", endpoint_health_manager)

    async def query(self, query_text: str) -> str:
        params = {"q": query_text}
        response = await self._make_request(params=params)
        if response and not response.get("error"):
            results = response.get("response", {}).get("results", [])
            if results:
                output = "Articles The Guardian:\n"
                for res in results[:3]:
                    output += f"- {res.get('webTitle', 'N/A')}: {res.get('fields', {}).get('trailText', 'N/A')} {neutralize_urls(res.get('webUrl', ''))}\n"
                return output
            return "Guardian: Aucun article trouv√©."
        return f"Guardian: Erreur: {response.get('message', 'Inconnu')}" if response else "Guardian: R√©ponse vide ou erreur interne."

class IP2LocationClient(APIClient):
    def __init__(self):
        super().__init__("IP2LOCATION", endpoint_health_manager)

    async def query(self, ip_address: str) -> str:
        params = {"ip": ip_address}
        response = await self._make_request(params=params)
        if response and not response.get("error"):
            if "country_name" in response:
                return f"IP2Location (G√©olocalisation IP {ip_address}): Pays: {response['country_name']}, Ville: {response.get('city_name', 'N/A')}"
            return "IP2Location: Informations non trouv√©es."
        return f"IP2Location: Erreur: {response.get('message', 'Inconnu')}" if response else "IP2Location: R√©ponse vide ou erreur interne."

class ShodanClient(APIClient):
    def __init__(self):
        super().__init__("SHODAN", endpoint_health_manager)

    async def query(self, query_text: str = "") -> str:
        if query_text:
            # Si une IP est fournie, tente de r√©cup√©rer les infos de l'h√¥te
            if re.match(r"^\d{1,3}\.\d{1,3}\.\d{1,3}\.\d{1,3}$", query_text):
                selected_endpoint_config = None
                for config in API_CONFIG.get(self.name, []):
                    if "Host Info" in config.get("endpoint_name", ""):
                        selected_endpoint_config = config
                        break
                if selected_endpoint_config:
                    url = f"https://api.shodan.io/shodan/host/{query_text}"
                    response = await self._make_request(
                        params={"key": selected_endpoint_config["key"]},
                        url=url,
                        method="GET",
                        key_field=selected_endpoint_config["key_field"],
                        key_location=selected_endpoint_config["key_location"],
                        api_key=selected_endpoint_config["key"],
                        timeout=selected_endpoint_config.get("timeout")
                    )
                    if response and not response.get("error"):
                        return f"Shodan (info h√¥te {query_text}): Pays: {response.get('country_name', 'N/A')}, Ports: {response.get('ports', 'N/A')}, Vuln√©rabilit√©s: {response.get('vulns', 'Aucune')}"
                    return f"Shodan (info h√¥te): Erreur: {response.get('message', 'Inconnu')}" if response else "Shodan: R√©ponse vide ou erreur interne."
            else:
                return "Shodan: Veuillez fournir une adresse IP valide pour la recherche d'h√¥te."

        # Par d√©faut, si pas de query_text ou si la recherche d'h√¥te √©choue, retourne les infos de la cl√© API
        response = await self._make_request()
        if response and not response.get("error"):
            return f"Shodan (info cl√©): Requ√™tes restantes: {response.get('usage_limits', {}).get('query_credits', 'N/A')}, Scan cr√©dits: {response.get('usage_limits', {}).get('scan_credits', 'N/A')}"
        return f"Shodan: Erreur: {response.get('message', 'Inconnu')}" if response else "Shodan: R√©ponse vide ou erreur interne."

class WeatherAPIClient(APIClient):
    def __init__(self):
        super().__init__("WEATHERAPI", endpoint_health_manager)

    async def query(self, location: str) -> str:
        params = {"q": location}
        response = await self._make_request(params=params)
        if response and not response.get("error"):
            current = response.get("current", {})
            location_info = response.get("location", {})
            if current and location_info:
                return (
                    f"M√©t√©o √† {location_info.get('name', 'N/A')}, {location_info.get('country', 'N/A')}:\n"
                    f"Temp√©rature: {current.get('temp_c', 'N/A')}¬∞C, "
                    f"Conditions: {current.get('condition', {}).get('text', 'N/A')}, "
                    f"Vent: {current.get('wind_kph', 'N/A')} km/h"
                )
            return "WeatherAPI: Donn√©es m√©t√©o non trouv√©es."
        return f"WeatherAPI: Erreur: {response.get('message', 'Inconnu')}" if response else "WeatherAPI: R√©ponse vide ou erreur interne."

class CloudmersiveClient(APIClient):
    def __init__(self):
        super().__init__("CLOUDMERSIVE", endpoint_health_manager)

    async def query(self, domain: str) -> str:
        payload = {"domain": domain}
        response = await self._make_request(json_data=payload)
        if response and not response.get("error"):
            return f"Cloudmersive (v√©rification de domaine {domain}): Valide: {response.get('ValidDomain', 'N/A')}, Type: {response.get('DomainType', 'N/A')}"
        return f"Cloudmersive: Erreur: {response.get('message', 'Inconnu')}" if response else "Cloudmersive: R√©ponse vide ou erreur interne."

class GreyNoiseClient(APIClient):
    def __init__(self):
        super().__init__("GREYNOISE", endpoint_health_manager)

    async def query(self, ip_address: str) -> str:
        selected_endpoint_config = self.endpoint_health_manager.get_best_endpoint(self.name)
        if not selected_endpoint_config:
            return f"GreyNoise: Aucun endpoint sain ou disponible pour {self.name}."

        url = f"{selected_endpoint_config['url']}{ip_address}"
        method = selected_endpoint_config["method"]
        headers = {selected_endpoint_config["key_field"]: selected_endpoint_config["key"]}

        response = await self._make_request(
            headers=headers,
            url=url,
            method=method,
            key_field=selected_endpoint_config["key_field"],
            key_location=selected_endpoint_config["key_location"],
            api_key=selected_endpoint_config["key"],
            timeout=selected_endpoint_config.get("timeout")
        )

        if response and not response.get("error"):
            if response.get("noise"):
                return f"GreyNoise (IP {ip_address}): C'est une IP 'bruit' (malveillante). Classification: {response.get('classification', 'N/A')}, Nom d'acteur: {response.get('actor', 'N/A')}"
            return f"GreyNoise (IP {ip_address}): Pas de 'bruit' d√©tect√©. Statut: {response.get('status', 'N/A')}"
        return f"GreyNoise: Erreur: {response.get('message', 'Inconnu')}" if response else "GreyNoise: R√©ponse vide ou erreur interne."

class PulsediveClient(APIClient):
    def __init__(self):
        super().__init__("PULSEDIVE", endpoint_health_manager)

    async def query(self, indicator: str, type: str = "auto") -> str:
        params = {"indicator": indicator, "type": type}
        response = await self._make_request(params=params)
        if response and not response.get("error"):
            if response.get("results"):
                result = response["results"][0]
                return (
                    f"Pulsedive (Analyse {indicator}): Type: {result.get('type', 'N/A')}, "
                    f"Risk: {result.get('risk', 'N/A')}, "
                    f"Description: {result.get('description', 'N/A')[:200]}..."
                )
            return "Pulsedive: Aucun r√©sultat d'analyse trouv√©."
        return f"Pulsedive: Erreur: {response.get('message', 'Inconnu')}" if response else "Pulsedive: R√©ponse vide ou erreur interne."

class StormGlassClient(APIClient):
    def __init__(self):
        super().__init__("STORMGLASS", endpoint_health_manager)

    async def query(self, lat: float, lng: float, params: str = "airTemperature,waveHeight") -> str:
        now = int(time.time())
        request_params = {
            "lat": lat,
            "lng": lng,
            "params": params,
            "start": now,
            "end": now + 3600 # Pr√©visions pour la prochaine heure
        }
        response = await self._make_request(params=request_params)
        if response and not response.get("error"):
            data = response.get("hours", [])
            if data:
                first_hour = data[0]
                temp = first_hour.get('airTemperature', [{}])[0].get('value', 'N/A')
                wave_height = first_hour.get('waveHeight', [{}])[0].get('value', 'N/A')
                return f"StormGlass (M√©t√©o maritime √† {lat},{lng}): Temp√©rature air: {temp}¬∞C, Hauteur vagues: {wave_height}m"
            return "StormGlass: Donn√©es non trouv√©es."
        return f"StormGlass: Erreur: {response.get('message', 'Inconnu')}" if response else "StormGlass: R√©ponse vide ou erreur interne."

class LoginRadiusClient(APIClient):
    def __init__(self):
        super().__init__("LOGINRADIUS", endpoint_health_manager)

    async def query(self) -> str:
        response = await self._make_request()
        if response and not response.get("error"):
            return f"LoginRadius (Ping API): Statut: {response.get('Status', 'N/A')}, Message: {response.get('Message', 'N/A')}"
        return f"LoginRadius: Erreur: {response.get('message', 'Inconnu')}" if response else "LoginRadius: R√©ponse vide ou erreur interne."

class JsonbinClient(APIClient):
    def __init__(self):
        super().__init__("JSONBIN", endpoint_health_manager)

    async def query(self, data: Dict[str, Any] = None, private: bool = True, bin_id: Optional[str] = None) -> str:
        if bin_id: # Acc√®s √† un bin existant
            selected_endpoint_config = None
            for config in API_CONFIG.get(self.name, []):
                if "Bin Access" in config.get("endpoint_name", ""):
                    selected_endpoint_config = config
                    break
            if not selected_endpoint_config:
                return f"Jsonbin: Aucun endpoint d'acc√®s de bin sain ou disponible pour {self.name}."

            url = f"{selected_endpoint_config['url']}/{bin_id}"
            method = "GET"
            headers = {selected_endpoint_config["key_field"]: selected_endpoint_config["key"]}
            
            response = await self._make_request(
                headers=headers,
                url=url,
                method=method,
                timeout=selected_endpoint_config.get("timeout")
            )
            if response and not response.get("error"):
                return f"Jsonbin (Acc√®s bin {bin_id}):\n{json.dumps(response, indent=2)}"
            return f"Jsonbin (Acc√®s bin): Erreur: {response.get('message', 'Inconnu')}" if response else "Jsonbin: R√©ponse vide ou erreur interne."
        
        else: # Cr√©ation d'un nouveau bin
            selected_endpoint_config = None
            for config in API_CONFIG.get(self.name, []):
                if "Bin Create" in config.get("endpoint_name", ""):
                    selected_endpoint_config = config
                    break
            
            if not selected_endpoint_config:
                return f"Jsonbin: Aucun endpoint de cr√©ation de bin sain ou disponible pour {self.name}."

            url = selected_endpoint_config["url"]
            method = "POST"
            headers = {selected_endpoint_config["key_field"]: selected_endpoint_config["key"], "Content-Type": "application/json"}
            payload = {"record": data if data is not None else {}, "private": private}

            response = await self._make_request(
                json_data=payload,
                headers=headers,
                url=url,
                method=method,
                timeout=selected_endpoint_config.get("timeout")
            )

            if response and not response.get("error"):
                return f"Jsonbin (Cr√©ation de bin): ID: {response.get('metadata', {}).get('id', 'N/A')}, URL: {neutralize_urls(response.get('metadata', {}).get('url', 'N/A'))}"
            return f"Jsonbin (Cr√©ation de bin): Erreur: {response.get('message', 'Inconnu')}" if response else "Jsonbin: R√©ponse vide ou erreur interne."

class HuggingFaceClient(APIClient):
    def __init__(self):
        super().__init__("HUGGINGFACE", endpoint_health_manager)

    async def query(self, model_name: str = "distilbert-base-uncased-finetuned-sst-2-english", input_text: str = "Hello world") -> str:
        selected_endpoint_config = self.endpoint_health_manager.get_best_endpoint(self.name)
        if not selected_endpoint_config:
            return f"HuggingFace: Aucun endpoint sain ou disponible pour {self.name}."

        inference_url = f"https://api-inference.huggingface.co/models/{model_name}"
        
        headers = {
            selected_endpoint_config["key_field"]: f"{selected_endpoint_config['key_prefix']}{selected_endpoint_config['key']}",
            "Content-Type": "application/json"
        }
        payload = {"inputs": input_text}

        response = await self._make_request(
            json_data=payload,
            headers=headers,
            url=inference_url,
            method="POST",
            timeout=selected_endpoint_config.get("timeout")
        )

        if response and not response.get("error"):
            if isinstance(response, list) and response:
                first_result = response[0]
                if isinstance(first_result, list) and first_result: # Ex: pour les mod√®les de classification de texte
                    return f"HuggingFace ({model_name} - {first_result[0].get('label')}): Score {first_result[0].get('score', 'N/A'):.2f}"
                elif isinstance(first_result, dict) and "generated_text" in first_result: # Ex: pour les mod√®les de g√©n√©ration de texte
                    return f"HuggingFace ({model_name}): {first_result.get('generated_text')}"
            return f"HuggingFace ({model_name}): R√©ponse non pars√©e. {response}"
        return f"HuggingFace: Erreur: {response.get('message', 'Inconnu')}" if response else "HuggingFace: R√©ponse vide ou erreur interne."

class TwilioClient(APIClient):
    def __init__(self):
        super().__init__("TWILIO", endpoint_health_manager)

    async def query(self) -> str:
        selected_endpoint_config = None
        for config in API_CONFIG.get(self.name, []):
            if "Account Balance" in config.get("endpoint_name", ""):
                selected_endpoint_config = config
                break
        if not selected_endpoint_config:
            # Fallback si l'endpoint sp√©cifique n'est pas trouv√©, prend le premier disponible
            if self.endpoints_config:
                selected_endpoint_config = self.endpoints_config[0]
            else:
                return f"Twilio: Aucune configuration d'endpoint disponible pour {self.name}."

        response = await self._make_request(
            url=selected_endpoint_config["url"],
            method=selected_endpoint_config["method"],
            key_location=selected_endpoint_config["key_location"],
            api_key=selected_endpoint_config["key"],
            timeout=selected_endpoint_config.get("timeout")
        )
        if response and not response.get("error"):
            return f"Twilio (Balance): {response.get('balance', 'N/A')} {response.get('currency', 'N/A')}"
        return f"Twilio: Erreur: {response.get('message', 'Inconnu')}" if response else "Twilio: R√©ponse vide ou erreur interne."

class AbstractAPIClient(APIClient):
    def __init__(self):
        super().__init__("ABSTRACTAPI", endpoint_health_manager)

    async def query(self, input_value: str, api_type: str) -> str:
        params = {}
        target_endpoint_name = ""

        if api_type == "PHONE_VALIDATION":
            params["phone"] = input_value
            target_endpoint_name = "Phone Validation"
        elif api_type == "EMAIL_VALIDATION":
            params["email"] = input_value
            target_endpoint_name = "Email Validation"
        elif api_type == "EXCHANGE_RATES":
            target_endpoint_name = "Exchange Rates"
        elif api_type == "HOLIDAYS":
            params["country"] = input_value if input_value else "US"
            params["year"] = datetime.now().year
            target_endpoint_name = "Holidays"
        else:
            return f"AbstractAPI: Type d'API '{api_type}' non support√© pour la requ√™te."

        selected_endpoint_config = None
        for config in API_CONFIG.get(self.name, []):
            if target_endpoint_name in config["endpoint_name"]:
                selected_endpoint_config = config
                break
        
        if not selected_endpoint_config:
            return f"AbstractAPI: Aucun endpoint sain ou disponible pour {self.name} pour le type {api_type}."

        response = await self._make_request(
            params=params,
            url=selected_endpoint_config["url"],
            method=selected_endpoint_config["method"],
            key_field=selected_endpoint_config["key_field"],
            key_location=selected_endpoint_config["key_location"],
            api_key=selected_endpoint_config["key"],
            fixed_params=selected_endpoint_config.get("fixed_params", {}),
            timeout=selected_endpoint_config.get("timeout")
        )

        if response and not response.get("error"):
            if api_type == "PHONE_VALIDATION":
                return (
                    f"AbstractAPI (Validation T√©l): Num√©ro: {response.get('phone', 'N/A')}, "
                    f"Valide: {response.get('valid', 'N/A')}, "
                    f"Pays: {response.get('country', {}).get('name', 'N/A')}"
                )
            elif api_type == "EMAIL_VALIDATION":
                return (
                    f"AbstractAPI (Validation Email): Email: {response.get('email', 'N/A')}, "
                    f"Valide: {response.get('is_valid_format', 'N/A')}, "
                    f"Deliverable: {response.get('is_deliverable', 'N/A')}"
                )
            elif api_type == "EXCHANGE_RATES":
                return f"AbstractAPI (Taux de change): Base: {response.get('base', 'N/A')}, Taux (USD): {response.get('exchange_rates', {}).get('USD', 'N/A')}"
            elif api_type == "HOLIDAYS":
                holidays = [h.get('name', 'N/A') for h in response if h.get('name')]
                return f"AbstractAPI (Jours f√©ri√©s {params.get('country', 'US')} {params.get('year')}): {', '.join(holidays[:5])}..." if holidays else "Aucun jour f√©ri√© trouv√©."
            return f"AbstractAPI ({api_type}): R√©ponse brute: {response}"
        return f"AbstractAPI ({api_type}): Erreur: {response.get('message', 'Inconnu')}" if response else "AbstractAPI: R√©ponse vide ou erreur interne."

class GeminiAPIClient(APIClient):
    def __init__(self):
        super().__init__("GEMINI_API", endpoint_health_manager)

    async def query(self, prompt: str, model: str = "gemini-1.5-flash") -> str:
        payload = {"contents": [{"parts": [{"text": prompt}]}]}
        selected_endpoint_config = self.endpoint_health_manager.get_best_endpoint(self.name)
        if not selected_endpoint_config:
            return f"Gemini API: Aucun endpoint sain ou disponible pour {self.name}."

        generate_url = f"https://generativelanguage.googleapis.com/v1beta/models/{model}:generateContent"
        
        request_params = {selected_endpoint_config["key_field"]: selected_endpoint_config["key"]}

        response = await self._make_request(
            json_data=payload,
            params=request_params,
            url=generate_url,
            method="POST",
            timeout=selected_endpoint_config.get("timeout")
        )

        if response and not response.get("error"):
            if response.get("candidates") and response["candidates"][0].get("content"):
                return response["candidates"][0]["content"]["parts"][0]["text"]
            return f"Gemini API: Pas de r√©ponse g√©n√©r√©e. {response}"
        return f"Gemini API: Erreur: {response.get('message', 'Inconnu')}" if response else "Gemini API: R√©ponse vide ou erreur interne."

class GoogleCustomSearchClient(APIClient):
    def __init__(self):
        super().__init__("GOOGLE_CUSTOM_SEARCH", endpoint_health_manager)

    async def query(self, query_text: str) -> str:
        params = {"q": query_text}
        response = await self._make_request(params=params)
        if response and not response.get("error"):
            items = response.get("items", [])
            if items:
                output = "Google Custom Search:\n"
                for item in items[:3]:
                    output += f"- {item.get('title', 'N/A')}: {item.get('snippet', 'N/A')} {neutralize_urls(item.get('link', ''))}\n"
                return output
            return "Google Custom Search: Aucun r√©sultat trouv√©."
        return f"Google Custom Search: Erreur: {response.get('message', 'Inconnu')}" if response else "Google Custom Search: R√©ponse vide ou erreur interne."

class RandommerClient(APIClient):
    def __init__(self):
        super().__init__("RANDOMMER", endpoint_health_manager)

    async def query(self, country_code: str = "US", quantity: int = 1) -> str:
        params = {"CountryCode": country_code, "Quantity": quantity}
        response = await self._make_request(params=params)
        if response and not response.get("error"):
            if isinstance(response, list) and response:
                return f"Randommer (Num√©ros de t√©l√©phone): {', '.join(response)}"
            return f"Randommer: {response}"
        return f"Randommer: Erreur: {response.get('message', 'Inconnu')}" if response else "Randommer: R√©ponse vide ou erreur interne."

class TomorrowIOClient(APIClient):
    def __init__(self):
        super().__init__("TOMORROW.IO", endpoint_health_manager)

    async def query(self, location: str, fields: List[str] = None) -> str:
        if fields is None:
            fields = ["temperature", "humidity", "windSpeed"]
        payload = {"location": location, "fields": fields, "units": "metric", "timesteps": ["1h"]}
        response = await self._make_request(json_data=payload)
        if response and not response.get("error"):
            data = response.get("data", {}).get("timelines", [{}])[0].get("intervals", [{}])[0].get("values", {})
            if data:
                output = f"M√©t√©o (Tomorrow.io) √† {location}:\n"
                for field in fields:
                    output += f"- {field.capitalize()}: {data.get(field, 'N/A')}\n"
                return output
            return "Tomorrow.io: Donn√©es m√©t√©o non trouv√©es."
        return f"Tomorrow.io: Erreur: {response.get('message', 'Inconnu')}" if response else "Tomorrow.io: R√©ponse vide ou erreur interne."

class OpenWeatherMapClient(APIClient):
    def __init__(self):
        super().__init__("OPENWEATHERMAP", endpoint_health_manager)

    async def query(self, location: str) -> str:
        params = {"q": location}
        response = await self._make_request(params=params)
        if response and not response.get("error"):
            main_data = response.get("main", {})
            weather_desc = response.get("weather", [{}])[0].get("description", "N/A")
            if main_data:
                temp_kelvin = main_data.get('temp', 'N/A')
                feels_like_kelvin = main_data.get('feels_like', 'N/A')
                
                temp_celsius = f"{temp_kelvin - 273.15:.2f}" if isinstance(temp_kelvin, (int, float)) else "N/A"
                feels_like_celsius = f"{feels_like_kelvin - 273.15:.2f}" if isinstance(feels_like_kelvin, (int, float)) else "N/A"

                return (
                    f"M√©t√©o (OpenWeatherMap) √† {location}:\n"
                    f"Temp√©rature: {temp_celsius}¬∞C, "
                    f"Ressenti: {feels_like_celsius}¬∞C, "
                    f"Humidit√©: {main_data.get('humidity', 'N/A')}%, "
                    f"Conditions: {weather_desc}"
                )
            return "OpenWeatherMap: Donn√©es m√©t√©o non trouv√©es."
        return f"OpenWeatherMap: Erreur: {response.get('message', 'Inconnu')}" if response else "OpenWeatherMap: R√©ponse vide ou erreur interne."

class MockarooClient(APIClient):
    def __init__(self):
        super().__init__("MOCKAROO", endpoint_health_manager)

    async def query(self, count: int = 1, fields_json: str = None) -> str:
        params = {"count": count}
        if fields_json:
            params["fields"] = fields_json

        response = await self._make_request(params=params)
        if response and not response.get("error"):
            return f"Mockaroo (G√©n√©ration de donn√©es):\n{json.dumps(response, indent=2)}"
        return f"Mockaroo: Erreur: {response.get('message', 'Inconnu')}" if response else "Mockaroo: R√©ponse vide ou erreur interne."

class OpenPageRankClient(APIClient):
    def __init__(self):
        super().__init__("OPENPAGERANK", endpoint_health_manager)

    async def query(self, domains: List[str]) -> str:
        params = {"domains[]": domains}
        response = await self._make_request(params=params)
        if response and not response.get("error"):
            results = response.get("response", [])
            if results:
                output = "OpenPageRank (Classement de domaine):\n"
                for res in results:
                    output += f"- Domaine: {res.get('domain', 'N/A')}, PageRank: {res.get('page_rank', 'N/A')}\n"
                return output
            return "OpenPageRank: Aucun r√©sultat trouv√©."
        return f"OpenPageRank: Erreur: {response.get('message', 'Inconnu')}" if response else "OpenPageRank: R√©ponse vide ou erreur interne."

class RapidAPIClient(APIClient):
    def __init__(self):
        super().__init__("RAPIDAPI", endpoint_health_manager)

    async def query(self, api_name: str, **kwargs) -> str:
        selected_endpoint_config = None
        for config in API_CONFIG.get(self.name, []):
            if api_name.lower() in config["endpoint_name"].lower():
                selected_endpoint_config = config
                break
        
        if not selected_endpoint_config:
            return f"RapidAPI: Endpoint pour '{api_name}' non trouv√© ou non configur√©."

        url = selected_endpoint_config["url"]
        method = selected_endpoint_config["method"]
        
        request_params = selected_endpoint_config.get("fixed_params", {}).copy()
        request_headers = selected_endpoint_config.get("fixed_headers", {}).copy()
        request_json_data = selected_endpoint_config.get("fixed_json", {}).copy()

        if method == "GET":
            request_params.update(kwargs)
        elif method == "POST":
            request_json_data.update(kwargs)

        headers = {
            selected_endpoint_config["key_field"]: selected_endpoint_config["key"],
            "X-RapidAPI-Host": selected_endpoint_config["fixed_headers"].get("X-RapidAPI-Host")
        }
        
        response = await self._make_request(
            params=request_params,
            headers=headers,
            json_data=request_json_data,
            url=url,
            method=method,
            timeout=selected_endpoint_config.get("timeout")
        )

        if response and not response.get("error"):
            if api_name.lower() == "programming joke":
                return f"RapidAPI (Blague de Programmation): {response.get('setup', '')} - {response.get('punchline', '')}"
            elif api_name.lower() == "currency list quotes":
                return f"RapidAPI (Devises): {json.dumps(response, indent=2)}"
            elif api_name.lower() == "random fact":
                return f"RapidAPI (Fait Al√©atoire): {response.get('text', 'N/A')}"
            return f"RapidAPI ({api_name}): {json.dumps(response, indent=2)}"
        return f"RapidAPI ({api_name}): Erreur: {response.get('message', 'Inconnu')}" if response else "RapidAPI: R√©ponse vide ou erreur interne."

class OCRApiClient(APIClient):
    def __init__(self):
        super().__init__("OCR_API", endpoint_health_manager)

    async def query(self, image_base64: str) -> str:
        """
        Effectue l'OCR sur une image encod√©e en base64.
        L'image_base64 doit √™tre au format "data:image/png;base64,..." ou similaire.
        """
        payload = {
            "base64Image": image_base64,
            "language": "fre" # Supposons le fran√ßais par d√©faut pour ce bot
        }
        
        selected_endpoint_config = self.endpoint_health_manager.get_best_endpoint(self.name)
        if not selected_endpoint_config:
            return f"OCR API: Aucun endpoint sain ou disponible pour {self.name}."

        headers = {
            selected_endpoint_config["key_field"]: selected_endpoint_config["key"],
            "Content-Type": "application/json"
        }

        response = await self._make_request(
            json_data=payload,
            headers=headers,
            url=selected_endpoint_config["url"],
            method="POST",
            timeout=selected_endpoint_config.get("timeout")
        )

        if response and not response.get("error"):
            parsed_results = response.get("ParsedResults", [])
            if parsed_results:
                extracted_text = parsed_results[0].get("ParsedText", "")
                return f"OCR API (Texte extrait):\n{extracted_text}"
            return "OCR API: Aucun texte extrait."
        return f"OCR API: Erreur: {response.get('message', 'Inconnu')}" if response else "OCR API: R√©ponse vide ou erreur interne."


# Instancier tous les clients API en leur passant le gestionnaire de sant√©
ALL_API_CLIENTS = [
    DeepSeekClient(), SerperClient(), WolframAlphaClient(), TavilyClient(),
    ApiFlashClient(), CrawlbaseClient(), DetectLanguageClient(), GuardianClient(),
    IP2LocationClient(), ShodanClient(), WeatherAPIClient(),
    CloudmersiveClient(), GreyNoiseClient(), PulsediveClient(), StormGlassClient(),
    LoginRadiusClient(), JsonbinClient(),
    HuggingFaceClient(), TwilioClient(), AbstractAPIClient(),
    GeminiAPIClient(), GoogleCustomSearchClient(), RandommerClient(), TomorrowIOClient(),
    OpenWeatherMapClient(),
    MockarooClient(), OpenPageRankClient(), RapidAPIClient(),
    OCRApiClient() # Ajout du client OCR
]

import json
import asyncio
from datetime import datetime, timedelta
from typing import Dict, Any, Optional, List

# Import des constantes et fonctions utilitaires
from config import (
    API_QUOTAS, API_COOLDOWN_DURATION_SECONDS, API_ROTATION_INTERVAL_MINUTES,
    QUOTA_BURN_WINDOW_HOURS, USER_CHAT_HISTORY_FILE, USER_LONG_MEMORY_FILE,
    IA_STATUS_FILE, QUOTAS_FILE, GROUP_CHAT_HISTORY_FILE, PRIVATE_GROUP_ID
)
from utils import (
    load_json, save_json, get_current_time, format_datetime, log_message,
    neutralize_urls, extract_keywords, tag_conversation, unique_preserve_order,
    similar, get_user_dir
)

class MemoryManager:
    def __init__(self):
        self.chat_history: Dict[int, List[Dict]] = {} # {user_id: [messages]}
        self.long_term_memory: Dict[int, Dict[str, Any]] = {} # {user_id: {key: value}}
        self.ia_status: Dict[str, Dict[str, Any]] = {} # Global IA status
        self.group_chat_history: Dict[int, List[Dict]] = {} # {group_id: [messages]}
        self._initialized = False

    async def init_manager(self):
        """Initialise le gestionnaire de m√©moire de mani√®re asynchrone."""
        if not self._initialized:
            # Load global IA status
            self.ia_status = await load_json(IA_STATUS_FILE, {})
            self._initialize_ia_status()
            
            # Note: User-specific histories are loaded on demand when a user interacts
            # or when the bot needs to access their specific memory.
            # For group chat history, load the specific file for PRIVATE_GROUP_ID
            self.group_chat_history[PRIVATE_GROUP_ID] = await load_json(get_user_dir(PRIVATE_GROUP_ID) / GROUP_CHAT_HISTORY_FILE, [])

            self._initialized = True
            log_message("Gestionnaire de m√©moire initialis√©.")

    def _initialize_ia_status(self):
        """Initialise le statut des IA si elles ne sont pas d√©j√† pr√©sentes ou si leur statut est obsol√®te."""
        updated = False
        now = get_current_time()
        
        for client_name in API_QUOTAS.keys():
            if client_name not in self.ia_status:
                self.ia_status[client_name] = {
                    "last_used": None,
                    "last_error": None,
                    "error_count": 0,
                    "cooldown_until": None,
                    "success_count": 0,
                    "current_score": 1.0,
                    "last_rotation_check": format_datetime(now),
                    "diversification_score": 1.0
                }
                updated = True
            else:
                # Ensure all new keys are present in existing IA statuses
                default_ia_status_keys = {
                    "last_used": None, "last_error": None, "error_count": 0,
                    "cooldown_until": None, "success_count": 0, "current_score": 1.0,
                    "last_rotation_check": format_datetime(now), "diversification_score": 1.0
                }
                for key, default_value in default_ia_status_keys.items():
                    if key not in self.ia_status[client_name]:
                        self.ia_status[client_name][key] = default_value
                        updated = True
                
                # Update last_rotation_check if it's too old to ensure diversification score recovery
                last_check_str = self.ia_status[client_name].get("last_rotation_check")
                if last_check_str:
                    try:
                        last_check_dt = datetime.strptime(last_check_str, "%Y-%m-%d %H:%M:%S UTC")
                        if (now - last_check_dt).total_seconds() > API_ROTATION_INTERVAL_MINUTES * 60 * 2: # Twice the rotation interval
                            self.ia_status[client_name]["last_rotation_check"] = format_datetime(now)
                            updated = True
                    except ValueError: # Handle malformed date strings
                        self.ia_status[client_name]["last_rotation_check"] = format_datetime(now)
                        updated = True
                        log_message(f"Malformed last_rotation_check for {client_name}, resetting.", level="warning")

        # Remove IA names that are no longer in API_QUOTAS
        current_api_names = set(API_QUOTAS.keys())
        ia_names_to_remove = [name for name in self.ia_status if name not in current_api_names]
        for name in ia_names_to_remove:
            del self.ia_status[name]
            updated = True
            log_message(f"IA '{name}' trouv√©e dans ia_status.json mais non d√©finie dans API_QUOTAS. Supprim√©e.", level="warning")

        if updated:
            asyncio.create_task(save_json(IA_STATUS_FILE, self.ia_status))
            log_message("Statut des IA initialis√©/mis √† jour.")

    async def add_message_to_history(self, user_id: int, role: str, content: str, max_log_entries: int = 100):
        """
        Ajoute un message √† l'historique de la conversation d'un utilisateur.
        G√®re √©galement le log g√©n√©ral et le taggage.
        """
        user_dir = get_user_dir(user_id)
        chat_history_path = user_dir / USER_CHAT_HISTORY_FILE
        log_path = user_dir / "log.json" # General log file for user

        # Load existing histories for the user
        user_chat_hist = self.chat_history.get(user_id, await load_json(chat_history_path, []))
        user_log = await load_json(log_path, [])

        # Neutralize URLs for storage
        neutralized_content = neutralize_urls(content)

        # Add to user's chat history
        user_chat_hist.append({"role": role, "content": neutralized_content, "timestamp": format_datetime(get_current_time())})
        user_chat_hist = user_chat_hist[-max_log_entries:] # Prune to max_log_entries
        self.chat_history[user_id] = user_chat_hist
        asyncio.create_task(save_json(chat_history_path, user_chat_hist))
        
        # Add to user's general log (truncated content for log)
        log_entry_content = neutralized_content[:500] # Truncate for log file
        log_entry = {"time": format_datetime(get_current_time()), "role": role, "text": log_entry_content}
        if role == "user": # Tag user messages
            log_entry["tags"] = tag_conversation(content)
        user_log.append(log_entry)
        user_log = user_log[-max_log_entries:] # Prune general log
        asyncio.create_task(save_json(log_path, user_log))

        log_message(f"Message ajout√© √† l'historique de {user_id} par {role}.")

    async def get_chat_history(self, user_id: int, limit: int = 10) -> List[Dict]:
        """Retourne les N derniers messages de l'historique de conversation d'un utilisateur."""
        user_dir = get_user_dir(user_id)
        chat_history_path = user_dir / USER_CHAT_HISTORY_FILE
        if user_id not in self.chat_history:
            self.chat_history[user_id] = await load_json(chat_history_path, [])
        return self.chat_history[user_id][-limit:]

    async def save_group_memory(self, group_id: int, role: str, text: str, max_items: int = 1000):
        """Sauvegarde l'historique de chat pour un groupe sp√©cifique."""
        group_dir = get_user_dir(group_id) # Use group_id as if it's a user_id for directory
        group_history_path = group_dir / GROUP_CHAT_HISTORY_FILE
        
        hist = self.group_chat_history.get(group_id, await load_json(group_history_path, []))
        hist.append({"time": format_datetime(get_current_time()), "role": role, "text": neutralize_urls(text)})
        hist = hist[-max_items:]
        self.group_chat_history[group_id] = hist
        asyncio.create_task(save_json(group_history_path, hist))
        log_message(f"Message ajout√© √† la m√©moire de groupe {group_id} par {role}.")

    async def get_group_memory(self, group_id: int, limit: int = 20) -> str:
        """R√©cup√®re les N derniers messages de la m√©moire de groupe."""
        group_dir = get_user_dir(group_id)
        group_history_path = group_dir / GROUP_CHAT_HISTORY_FILE
        if group_id not in self.group_chat_history:
            self.group_chat_history[group_id] = await load_json(group_history_path, [])
        
        # Filter out bot messages if not needed for the prompt context
        recent_messages = [f"{l['role']} : {l['text']}" for l in self.group_chat_history[group_id][-limit:] if l.get("role") != "bot"]
        return "\n".join(recent_messages)

    async def add_to_long_term_memory(self, user_id: int, text: str, max_entries: int = 100):
        """Ajoute une information √† la m√©moire √† long terme d'un utilisateur."""
        user_dir = get_user_dir(user_id)
        long_memory_path = user_dir / USER_LONG_MEMORY_FILE
        
        long_mem = self.long_term_memory.get(user_id, await load_json(long_memory_path, []))
        if not isinstance(long_mem, list): # Ensure it's a list
            long_mem = []

        long_mem.append(text.strip())
        long_mem = unique_preserve_order(long_mem)[-max_entries:] # Deduplicate and prune
        self.long_term_memory[user_id] = long_mem
        asyncio.create_task(save_json(long_memory_path, long_mem))
        log_message(f"Information ajout√©e √† la m√©moire √† long terme de {user_id}.")

    async def get_long_term_memory(self, user_id: int, limit: int = 20) -> str:
        """R√©cup√®re les N derni√®res entr√©es de la m√©moire √† long terme d'un utilisateur."""
        user_dir = get_user_dir(user_id)
        long_memory_path = user_dir / USER_LONG_MEMORY_FILE
        if user_id not in self.long_term_memory:
            self.long_term_memory[user_id] = await load_json(long_memory_path, [])
        
        if not isinstance(self.long_term_memory[user_id], list): # Ensure it's a list
            self.long_term_memory[user_id] = []

        return "\n".join(self.long_term_memory[user_id][-limit:])

    async def check_for_similar_prompt(self, user_id: int, prompt: str) -> Optional[str]:
        """
        V√©rifie si un prompt similaire a d√©j√† √©t√© pos√© r√©cemment et retourne la r√©ponse si trouv√©e.
        """
        recent_chat_history = await self.get_chat_history(user_id, limit=MAX_CACHE_SIZE) # Use MAX_CACHE_SIZE from config
        for entry in reversed(recent_chat_history):
            if entry.get("role") == "user" and "content" in entry:
                if similar(prompt, entry["content"]) > 0.92: # Threshold for similarity
                    # Find the bot's response immediately following this user prompt
                    for i in range(len(recent_chat_history) - 1, -1, -1):
                        if recent_chat_history[i] == entry and i + 1 < len(recent_chat_history):
                            if recent_chat_history[i+1].get("role") == "bot":
                                log_message(f"Prompt similaire d√©tect√© pour {user_id}. R√©ponse en cache utilis√©e.")
                                return recent_chat_history[i+1]["content"]
        return None

    def update_ia_status(self, ia_name: str, success: bool, error_message: Optional[str] = None):
        """Met √† jour le statut et le score d'une IA apr√®s une utilisation."""
        status = self.ia_status.get(ia_name)
        if not status:
            log_message(f"Tentative de mise √† jour d'un statut d'IA inconnu: {ia_name}", level="warning")
            return

        now = get_current_time()
        status["last_used"] = format_datetime(now)

        if success:
            status["success_count"] += 1
            status["error_count"] = 0
            status["cooldown_until"] = None
            status["last_error"] = None
            status["current_score"] = min(1.0, status["current_score"] + 0.1) # Augmente le score de succ√®s
            status["diversification_score"] = max(0.1, status["diversification_score"] - 0.1) # Diminue le score de diversification (moins besoin de l'utiliser)
            log_message(f"IA {ia_name} : Succ√®s enregistr√©. Nouveau score: {status['current_score']:.2f}, Diversification: {status['diversification_score']:.2f}")
        else:
            status["error_count"] += 1
            status["last_error"] = error_message
            if status["error_count"] >= 3: # Si 3 erreurs cons√©cutives ou plus, met en cooldown
                status["cooldown_until"] = format_datetime(now + timedelta(seconds=API_COOLDOWN_DURATION_SECONDS))
                status["current_score"] = max(0.1, status["current_score"] - 0.2) # Diminue plus fortement le score
                log_message(f"IA {ia_name} : Trop d'erreurs ({status['error_count']}). Cooldown jusqu'√† {status['cooldown_until']}. Nouveau score: {status['current_score']:.2f}", level="warning")
            else:
                 status["current_score"] = max(0.1, status["current_score"] - 0.05) # Diminue l√©g√®rement
                 log_message(f"IA {ia_name} : Erreur enregistr√©e. Nouveau score: {status['current_score']:.2f}", level="warning")

        asyncio.create_task(save_json(IA_STATUS_FILE, self.ia_status))

    def recover_diversification_scores(self):
        """Augmente le score de diversification pour les IA non utilis√©es r√©cemment."""
        now = get_current_time()
        updated = False
        for ia_name, status in self.ia_status.items():
            last_used_str = status.get("last_used")
            if last_used_str:
                try:
                    last_used_dt = datetime.strptime(last_used_str, "%Y-%m-%d %H:%M:%S UTC")
                    # Si pas utilis√©e depuis 2x l'intervalle de rotation, augmente son score de diversification
                    if (now - last_used_dt).total_seconds() > API_ROTATION_INTERVAL_MINUTES * 60 * 2:
                        if status["diversification_score"] < 1.0:
                            status["diversification_score"] = min(1.0, status["diversification_score"] + 0.05)
                            updated = True
                            log_message(f"IA {ia_name}: Score de diversification r√©cup√©r√© √† {status['diversification_score']:.2f}")
                except ValueError: # Handle malformed date strings
                    status["last_used"] = format_datetime(now) # Reset last_used
                    status["diversification_score"] = 1.0 # Reset diversification
                    updated = True
                    log_message(f"Malformed last_used for {ia_name}, resetting diversification score.", level="warning")
            else: # Never used, set to full diversification
                if status["diversification_score"] < 1.0:
                    status["diversification_score"] = 1.0
                    updated = True
        if updated:
            asyncio.create_task(save_json(IA_STATUS_FILE, self.ia_status))

    def get_ia_status(self, ia_name: str) -> Optional[Dict]:
        """R√©cup√®re le statut d'une IA."""
        return self.ia_status.get(ia_name)

    def get_available_ias(self) -> List[str]:
        """Retourne les noms des IA actuellement non en cooldown."""
        available = []
        now = get_current_time()
        for name, status in self.ia_status.items():
            cooldown_until_str = status.get("cooldown_until")
            if cooldown_until_str:
                try:
                    cooldown_until = datetime.strptime(cooldown_until_str, "%Y-%m-%d %H:%M:%S UTC")
                    if now < cooldown_until:
                        continue
                except ValueError: # Malformed date, treat as not in cooldown
                    log_message(f"Malformed cooldown_until for {name}, treating as not in cooldown.", level="warning")
            available.append(name)
        return available

class QuotaManager:
    def __init__(self):
        self.quotas = {}
        self._initialized = False
        self.bot_instance = None # Will be set by main.py for alerts

    async def init_manager(self):
        """Initialise le gestionnaire de quotas de mani√®re asynchrone."""
        if not self._initialized:
            self.quotas = await load_json(QUOTAS_FILE, {})
            self._initialize_quotas()
            self._initialized = True
            log_message("Gestionnaire de quotas initialis√©.")

    def set_bot_instance(self, bot_instance):
        """Permet d'injecter l'instance du bot pour envoyer des alertes."""
        self.bot_instance = bot_instance

    def _initialize_quotas(self):
        """Initialise les quotas pour toutes les APIs bas√©es sur config.API_QUOTAS et nettoie/met √† jour les existants."""
        updated = False
        now = get_current_time()

        for api_name, quota_info in API_QUOTAS.items():
            if api_name not in self.quotas:
                self.quotas[api_name] = {
                    "monthly_usage": 0,
                    "daily_usage": 0,
                    "hourly_usage": 0,
                    "hourly_timestamps": [], # Pour un suivi plus pr√©cis de l'heure
                    "last_reset_month": now.month,
                    "last_reset_day": now.day,
                    "last_usage": None,
                    "total_calls": 0,
                    "last_hourly_reset": format_datetime(now)
                }
                updated = True
            else:
                # Ensure all new keys are present in existing quota data
                default_quota_structure = {
                    "monthly_usage": 0, "daily_usage": 0, "hourly_usage": 0,
                    "hourly_timestamps": [], "last_reset_month": now.month,
                    "last_reset_day": now.day, "last_usage": None,
                    "total_calls": 0, "last_hourly_reset": format_datetime(now)
                }
                for key, default_value in default_quota_structure.items():
                    if key not in self.quotas[api_name]:
                        self.quotas[api_name][key] = default_value
                        updated = True
                
                # Clean up hourly_timestamps for existing entries
                if not isinstance(self.quotas[api_name].get("hourly_timestamps"), list):
                    self.quotas[api_name]["hourly_timestamps"] = []
                    updated = True
                
                one_hour_ago = now - timedelta(hours=1)
                self.quotas[api_name]["hourly_timestamps"] = [
                    ts for ts in self.quotas[api_name]["hourly_timestamps"]
                    if datetime.strptime(ts, "%Y-%m-%d %H:%M:%S UTC") > one_hour_ago
                ]
                self.quotas[api_name]["hourly_usage"] = len(self.quotas[api_name]["hourly_timestamps"])
                self.quotas[api_name]["last_hourly_reset"] = format_datetime(now)


        # Remove API names that are no longer in API_QUOTAS
        api_names_to_remove = [name for name in self.quotas if name not in API_QUOTAS]
        for name in api_names_to_remove:
            del self.quotas[name]
            updated = True
            log_message(f"API '{name}' trouv√©e dans quotas.json mais non d√©finie dans API_QUOTAS. Supprim√©e.", level="warning")

        if updated:
            asyncio.create_task(save_json(QUOTAS_FILE, self.quotas))
            log_message("Quotas API initialis√©s/mis √† jour.")

    def _reset_quotas_if_needed(self):
        """R√©initialise les quotas journaliers, mensuels et horaires si n√©cessaire."""
        now = get_current_time()
        for api_name, data in self.quotas.items():
            # Monthly reset
            if now.month != data["last_reset_month"]:
                data["monthly_usage"] = 0
                data["last_reset_month"] = now.month
                log_message(f"Quota mensuel pour {api_name} r√©initialis√©.")
            # Daily reset
            if now.day != data["last_reset_day"]:
                data["daily_usage"] = 0
                data["last_reset_day"] = now.day
                log_message(f"Quota journalier pour {api_name} r√©initialis√©.")
            
            # Hourly reset (by cleaning old timestamps)
            one_hour_ago = now - timedelta(hours=1)
            # Ensure hourly_timestamps is a list, if not, initialize it
            if not isinstance(data.get("hourly_timestamps"), list):
                data["hourly_timestamps"] = []
            
            data["hourly_timestamps"] = [
                ts for ts in data["hourly_timestamps"]
                if datetime.strptime(ts, "%Y-%m-%d %H:%M:%S UTC") > one_hour_ago
            ]
            data["hourly_usage"] = len(data["hourly_timestamps"])
            data["last_hourly_reset"] = format_datetime(now)

        asyncio.create_task(save_json(QUOTAS_FILE, self.quotas))

    async def check_and_update_quota(self, api_name: str, cost: int = 1) -> bool:
        """V√©rifie si une API a du quota et le d√©cr√©mente. Retourne True si ok, False sinon."""
        self._reset_quotas_if_needed()
        
        if api_name not in API_QUOTAS:
            log_message(f"Tentative de v√©rification de quota pour une API non d√©finie: {api_name}. Autorisation refus√©e.", level="error")
            return False

        if api_name not in self.quotas:
            log_message(f"API {api_name} non trouv√©e dans les quotas g√©r√©s. Re-initialisation non bloquante.", level="warning")
            # This case should ideally not happen if _initialize_quotas runs correctly
            # But as a safeguard, we can re-initialize it for this specific API
            self._initialize_quotas() # Re-initialize all quotas to ensure this API is added
            if api_name not in self.quotas: # If still not there, something is wrong with API_QUOTAS
                return False

        quota_data = self.quotas[api_name]
        api_limits = API_QUOTAS.get(api_name, {})
        now = get_current_time()

        # Check monthly limit
        monthly_limit = api_limits.get("monthly")
        if monthly_limit is not None and (quota_data["monthly_usage"] + cost) > monthly_limit:
            log_message(f"Quota mensuel d√©pass√© pour {api_name}", level="warning")
            await self._alert_quota_if_needed(api_name, "monthly")
            return False

        # Check daily limit
        daily_limit = api_limits.get("daily")
        if daily_limit is not None and (quota_data["daily_usage"] + cost) > daily_limit:
            log_message(f"Quota journalier d√©pass√© pour {api_name}", level="warning")
            await self._alert_quota_if_needed(api_name, "daily")
            return False
        
        # Check hourly limit
        hourly_limit = api_limits.get("hourly")
        if hourly_limit is not None and (quota_data["hourly_usage"] + cost) > hourly_limit:
            log_message(f"Quota horaire d√©pass√© pour {api_name}", level="warning")
            await self._alert_quota_if_needed(api_name, "hourly")
            return False

        # Check rate limit per second
        rate_limit_per_sec = api_limits.get("rate_limit_per_sec")
        if rate_limit_per_sec:
            last_usage_str = quota_data.get("last_usage")
            if last_usage_str:
                try:
                    last_usage = datetime.strptime(last_usage_str, "%Y-%m-%d %H:%M:%S UTC")
                    time_since_last_call = (now - last_usage).total_seconds()
                    if time_since_last_call < (1 / rate_limit_per_sec):
                        log_message(f"Taux de requ√™tes d√©pass√© pour {api_name}. Attendre {1/rate_limit_per_sec - time_since_last_call:.2f}s", level="warning")
                        return False
                except ValueError: # Malformed date, treat as no recent usage
                    log_message(f"Malformed last_usage for {api_name}, treating as no recent usage for rate limit.", level="warning")


        if cost > 0:
            quota_data["monthly_usage"] += cost
            quota_data["daily_usage"] += cost
            quota_data["hourly_usage"] += cost
            quota_data["hourly_timestamps"].append(format_datetime(now))
            quota_data["total_calls"] += cost
            quota_data["last_usage"] = format_datetime(now)
            asyncio.create_task(save_json(QUOTAS_FILE, self.quotas))
            log_message(f"Quota pour {api_name} mis √† jour. Usage mensuel: {quota_data['monthly_usage']}/{monthly_limit if monthly_limit else 'Illimit√©'}, Journalier: {quota_data['daily_usage']}/{daily_limit if daily_limit else 'Illimit√©'}, Horaire: {quota_data['hourly_usage']}/{hourly_limit if hourly_limit else 'Illimit√©'}")
        else:
            log_message(f"Quota pour {api_name} v√©rifi√© (co√ªt 0). Usage mensuel: {quota_data['monthly_usage']}/{monthly_limit if monthly_limit else 'Illimit√©'}, Journalier: {quota_data['daily_usage']}/{daily_limit if daily_limit else 'Illimit√©'}, Horaire: {quota_data['hourly_usage']}/{hourly_limit if hourly_limit else 'Illimit√©'}")

        return True

    async def _alert_quota_if_needed(self, api_name: str, limit_type: str):
        """Envoie une alerte au groupe priv√© si un quota est atteint."""
        if self.bot_instance and PRIVATE_GROUP_ID:
            message = f"üö® Quota {limit_type} pour l'API '{api_name}' atteint !"
            log_message(message, level="warning")
            try:
                # Check if this alert has been sent recently to avoid spamming
                alert_key = f"quota_alert_{api_name}_{limit_type}_{get_current_time().strftime('%Y-%m-%d')}"
                if not await self.memory_manager.get_from_long_term_memory(alert_key):
                    await self.bot_instance.send_message(chat_id=PRIVATE_GROUP_ID, text=message)
                    await self.memory_manager.add_to_long_term_memory(alert_key, "sent")
            except Exception as e:
                log_message(f"Erreur lors de l'envoi de l'alerte de quota: {e}", level="error")

    def get_api_usage(self, api_name: str) -> Optional[Dict]:
        """Retourne les informations d'utilisation d'une API."""
        return self.quotas.get(api_name)

    def get_all_quotas_status(self) -> Dict:
        """Retourne le statut de tous les quotas."""
        self._reset_quotas_if_needed()
        status = {}
        for api_name, quota_data in self.quotas.items():
            api_limits = API_QUOTAS.get(api_name, {})
            monthly_limit = api_limits.get("monthly", "Illimit√©")
            daily_limit = api_limits.get("daily", "Illimit√©")
            hourly_limit = api_limits.get("hourly", "Illimit√©")
            status[api_name] = {
                "monthly_usage": quota_data["monthly_usage"],
                "monthly_limit": monthly_limit,
                "daily_usage": quota_data["daily_usage"],
                "daily_limit": daily_limit,
                "hourly_usage": quota_data["hourly_usage"],
                "hourly_limit": hourly_limit,
                "total_calls": quota_data["total_calls"],
                "last_usage": quota_data["last_usage"],
                "last_reset_month": quota_data["last_reset_month"],
                "last_reset_day": quota_data["last_reset_day"],
                "last_hourly_reset": quota_data["last_hourly_reset"]
            }
        return status

    def get_burn_window_apis(self) -> List[str]:
        """
        Identifie les APIs dont les quotas sont sur le point d'√™tre r√©initialis√©s
        et o√π il est opportun de "br√ªler" le quota restant.
        """
        burn_apis = []
        now = get_current_time()
        for api_name, data in self.quotas.items():
            api_limits = API_QUOTAS.get(api_name, {})

            # Monthly burn window
            if api_limits.get("monthly") is not None:
                # Calculate the first day of the next month
                next_month = now.month + 1
                year_for_next_month = now.year
                if next_month > 12:
                    next_month = 1
                    year_for_next_month += 1
                next_month_reset = datetime(year_for_next_month, next_month, 1, tzinfo=timezone.utc)
                
                # Check if current time is within the burn window before reset
                if is_within_time_window(next_month_reset, QUOTA_BURN_WINDOW_HOURS * 60, 0):
                    if data["monthly_usage"] < api_limits["monthly"]:
                        burn_apis.append(f"{api_name} (mensuel: {api_limits['monthly'] - data['monthly_usage']} restants)")

            # Daily burn window
            if api_limits.get("daily") is not None:
                # Calculate the start of the next day
                next_day_reset = datetime(now.year, now.month, now.day, tzinfo=timezone.utc) + timedelta(days=1)
                
                # Check if current time is within the burn window before reset
                if is_within_time_window(next_day_reset, QUOTA_BURN_WINDOW_HOURS * 60, 0):
                    if data["daily_usage"] < api_limits["daily"]:
                        burn_apis.append(f"{api_name} (journalier: {api_limits['daily'] - data['daily_usage']} restants)")
        return burn_apis

# Instanciation des gestionnaires de m√©moire et de quotas (seront initialis√©s dans main.py)
memory_manager = MemoryManager()
quota_manager = QuotaManager()

import random
import ast
import subprocess
import base64
import httpx
import io
import contextlib
from concurrent.futures import ThreadPoolExecutor
from typing import Dict, Any, Optional, Union, List

# Imports sp√©cifiques pour les outils de d√©veloppement
from pygments import highlight
from pygments.lexers import PythonLexer
from pygments.formatters import TerminalFormatter
from pyflakes.api import check
from pyflakes.reporter import Reporter
import black
# try: import pytesseract # Ancien OCR local, non utilis√© ici car on utilise l'API
# except ImportError: pytesseract = None
# from PIL import Image # Ancien OCR local, non utilis√© ici
# try: import fitz # Ancien pour PDF, non utilis√© ici
# except ImportError: fitz = None

# Imports depuis nos modules
from config import FORBIDDEN_WORDS, PRIVATE_GROUP_ID, ARCHIVES_DIR, BASE_DIR
from utils import log_message, neutralize_urls, get_user_dir
from api_clients import OCRApiClient # Utilisation du nouveau client OCR API

# Pour les ex√©cutions en sandbox, nous utiliserons un ThreadPoolExecutor pour ne pas bloquer l'event loop
executor = ThreadPoolExecutor(max_workers=1)

# Instancier le client OCR API pour une utilisation directe dans perform_ocr
ocr_api_client_instance = OCRApiClient()

def filter_bad_code(code: str) -> bool:
    """Filtre basique pour les commandes de code potentiellement dangereuses (peut √™tre √©tendu)."""
    forbidden_patterns = [
        r'os\.system', r'subprocess\.run', r'shutil\.rmtree', r'requests\.post',
        r'open\([^,\'"]*\s*,\s*[\'"]w', r'import socket', r'import http',
        r'sys\.exit', r'while True:'
    ]
    for pattern in forbidden_patterns:
        if re.search(pattern, code):
            return True
    return False

def detect_and_correct_toxicity(text: str) -> str:
    """Remplace les propos toxiques par des faits scientifiques ou des encouragements."""
    if any(word in text.lower() for word in FORBIDDEN_WORDS):
        facts = [
            "Savais-tu que 73% des conflits viennent de malentendus ?",
            "Le cerveau humain est c√¢bl√© pour la coop√©ration, pas le conflit.",
            "En 2025, l'IA √©motionnelle sera la norme. Soyons pr√©curseurs !",
            "Chaque point de vue, m√™me divergent, contribue √† la richesse de la compr√©hension.",
            "L'apprentissage est un processus continu, fait d'exp√©rimentations et d'am√©liorations.",
            "La collaboration est la cl√© de l'innovation."
        ]
        return random.choice(facts) + " Continuons √† construire ensemble !"
    return text

async def run_in_sandbox(code: str, language: str = "python") -> str:
    """
    Ex√©cute du code Python ou Shell dans une sandbox (environnement isol√©).
    Utilise un ThreadPoolExecutor pour ex√©cuter des op√©rations bloquantes de mani√®re asynchrone.
    """
    if filter_bad_code(code):
        return "‚ùå S√©curit√©: Le code contient des motifs potentiellement dangereux et n'a pas √©t√© ex√©cut√©."

    loop = asyncio.get_running_loop()
    if language == "python":
        return await loop.run_in_executor(executor, _run_python_sync, code)
    elif language == "shell":
        return await loop.run_in_executor(executor, _run_shell_sync, code)
    else:
        return "‚ùå Langage non support√© pour la sandbox."

def _run_python_sync(code: str) -> str:
    """Ex√©cute du code Python de mani√®re synchrone et capture la sortie."""
    old_stdout = io.StringIO()
    old_stderr = io.StringIO()
    with contextlib.redirect_stdout(old_stdout), contextlib.redirect_stderr(old_stderr):
        try:
            # Utilisez un dictionnaire vide pour __builtins__ pour isoler l'ex√©cution
            exec(code, {'__builtins__': {}})
            output = old_stdout.getvalue()
            error = old_stderr.getvalue()
            if error:
                return f"üêç Erreur Python:\n{error}\nSortie:\n{output}"
            return f"‚úÖ Sortie Python:\n{output}"
        except Exception as e:
            return f"‚ùå Erreur d'ex√©cution Python: {e}\nSortie standard:\n{old_stdout.getvalue()}\nErreur standard:\n{old_stderr.getvalue()}"

def _run_shell_sync(command: str) -> str:
    """Ex√©cute une commande shell de mani√®re synchrone et capture la sortie."""
    try:
        result = subprocess.run(
            command,
            shell=True,
            capture_output=True,
            text=True,
            check=True,
            timeout=10
        )
        output = result.stdout
        error = result.stderr
        if error:
            return f"üêö Erreur Shell:\n{error}\nSortie:\n{output}"
        return f"‚úÖ Sortie Shell:\n{output}"
    except subprocess.CalledProcessError as e:
        return f"‚ùå Erreur d'ex√©cution Shell (Code: {e.returncode}):\n{e.stderr}\nSortie:\n{e.stdout}"
    except subprocess.TimeoutExpired:
        return "‚ùå Erreur Shell: La commande a d√©pass√© le temps d'ex√©cution imparti."
    except Exception as e:
        return f"‚ùå Erreur inattendue lors de l'ex√©cution Shell: {e}"

def syntax_highlight(code: str) -> str:
    """Met en surbrillance la syntaxe du code Python."""
    try:
        # Utilise TerminalFormatter pour une sortie texte simple compatible avec Telegram <pre>
        return highlight(code, PythonLexer(), TerminalFormatter())
    except Exception as e:
        log_message(f"Erreur de surbrillance syntaxique: {e}", level="error")
        return code # Retourne le code brut en cas d'erreur

def check_code(code: str) -> str:
    """V√©rifie le code Python avec Pyflakes."""
    out = io.StringIO()
    reporter = Reporter(out, out)
    check(code, filename="<string>", reporter=reporter)
    result = out.getvalue()
    return result if result else "‚úÖ Pyflakes: Aucun probl√®me d√©tect√©."

def format_code(code: str) -> str:
    """Formate le code Python avec Black."""
    try:
        mode = black.Mode()
        return black.format_str(code, mode=mode)
    except black.InvalidInput as e:
        return f"‚ùå Erreur de formatage (Black): Code Python invalide. {e}"
    except Exception as e:
        return f"‚ùå Erreur de formatage (Black): {e}"

def extract_functions(code: str) -> Union[List[str], str]:
    """Extrait les noms des fonctions d'un code Python."""
    try:
        tree = ast.parse(code)
        functions = [node.name for node in ast.walk(tree) if isinstance(node, ast.FunctionDef)]
        return functions if functions else "Aucune fonction d√©tect√©e."
    except SyntaxError as e:
        return f"‚ùå Erreur de syntaxe Python: {e}"
    except Exception as e:
        return f"‚ùå Erreur lors de l'extraction des fonctions: {e}"

def analyze_code_structure(code: str) -> str:
    """Analyse la structure AST d'un code Python."""
    try:
        tree = ast.parse(code)
        return ast.dump(tree, indent=2)
    except SyntaxError as e:
        return f"‚ùå Erreur de syntaxe Python: {e}"
    except Exception as e:
        return f"‚ùå Erreur lors de l'analyse de la structure AST: {e}"

async def perform_ocr_api(image_url: str) -> str:
    """
    Effectue l'OCR sur une URL d'image en utilisant l'API OCR.
    """
    try:
        # T√©l√©charger l'image depuis l'URL
        async with httpx.AsyncClient(timeout=10) as client:
            img_response = await client.get(image_url)
            img_response.raise_for_status() # L√®ve une exception pour les codes d'√©tat HTTP 4xx/5xx

        # Encoder l'image en base64
        # Assurez-vous que le format est compatible avec l'API OCR (ex: data:image/png;base64,...)
        # OCR.space attend un pr√©fixe, donc nous l'ajoutons si n√©cessaire.
        base64_image_data = base64.b64encode(img_response.content).decode('utf-8')
        if not base64_image_data.startswith("data:"):
            # Tente de deviner le mimetype si non pr√©sent, ou utilise un g√©n√©rique
            content_type = img_response.headers.get("Content-Type", "image/jpeg")
            image_base64_with_prefix = f"data:{content_type};base64,{base64_image_data}"
        else:
            image_base64_with_prefix = base64_image_data

        # Appeler le client OCR API
        result = await ocr_api_client_instance.query(image_base64_with_prefix)
        return result

    except httpx.HTTPStatusError as e:
        log_message(f"Erreur HTTP/r√©seau lors de l'OCR: {e.response.status_code} - {e.response.text}", level="error")
        return f"‚ùå Erreur lors de l'OCR (r√©seau/API): {e}"
    except httpx.RequestError as e:
        log_message(f"Erreur de requ√™te lors de l'OCR: {e}", level="error")
        return f"‚ùå Erreur lors de l'OCR (requ√™te): {e}"
    except Exception as e:
        log_message(f"Erreur inattendue lors de l'OCR: {e}", level="error")
        return f"‚ùå Erreur inattendue lors de l'OCR: {e}"

async def fetch_and_archive_pages(links: List[str], user_id: int, bot_instance: Any):
    """T√©l√©charge toutes les pages de liens, archive et envoie dans groupe priv√©."""
    user_archive_dir = get_user_dir(user_id) / ARCHIVES_DIR
    user_archive_dir.mkdir(exist_ok=True, parents=True)

    for idx, url in enumerate(links):
        try:
            async with httpx.AsyncClient(timeout=20) as client:
                r = await client.get(url)
                r.raise_for_status() # L√®ve une exception pour les codes d'√©tat HTTP 4xx/5xx

                if len(r.content) < MAX_FILE_SIZE:
                    ext = ".html" if "<html" in r.text.lower() else ".txt"
                    # Utilise un hash de l'URL pour un nom de fichier plus robuste et unique
                    url_hash = hashlib.sha256(url.encode('utf-8')).hexdigest()[:10]
                    fname = f"page_{datetime.now().strftime('%Y%m%d%H%M%S')}_{url_hash}_{idx}{ext}"
                    fpath = user_archive_dir / fname
                    fpath.write_text(r.text, encoding="utf-8", errors="ignore")
                    
                    # Envoi au groupe priv√©
                    if PRIVATE_GROUP_ID and bot_instance:
                        try:
                            with fpath.open("rb") as f:
                                await bot_instance.send_document(chat_id=PRIVATE_GROUP_ID, document=f, filename=fname, caption=f"Page archiv√©e de {neutralize_urls(url)}")
                        except Exception as send_e:
                            log_message(f"Erreur lors de l'envoi du document archiv√© au groupe priv√©: {send_e}", level="error")
                    
                    # Ajout √† la m√©moire longue de l'utilisateur (pour le bot)
                    # Note: memory_manager est un singleton, il doit √™tre import√© et initialis√©
                    # Mais pour √©viter une d√©pendance circulaire, on ne l'importe pas ici directement.
                    # L'orchestrateur ou le main devra appeler memory_manager.add_to_long_term_memory
                    # apr√®s l'appel √† fetch_and_archive_pages.
                    log_message(f"Page archiv√©e: {url} pour user {user_id}")
                else:
                    log_message(f"Page trop grande pour √™tre archiv√©e: {url} ({len(r.content)} bytes)", level="warning")
        except httpx.HTTPStatusError as e:
            log_message(f"[fetch_and_archive_pages] Erreur HTTP pour {url}: {e.response.status_code} - {e.response.text}", level="error")
        except httpx.RequestError as e:
            log_message(f"[fetch_and_archive_pages] Erreur de requ√™te pour {url}: {e}", level="error")
        except Exception as e:
            log_message(f"[fetch_and_archive_pages] Erreur inattendue pour {url}: {e}\n{traceback.format_exc()}", level="error")


import asyncio
import time
import json
import logging
import traceback
from datetime import datetime, timedelta, timezone
from typing import Dict, Any, Optional, Union, List

from telegram import Update, Bot
from telegram.ext import Application, CommandHandler, MessageHandler, filters, ContextTypes
from apscheduler.schedulers.asyncio import AsyncIOScheduler

# Imports de nos modules
from config import (
    API_CONFIG, API_QUOTAS, API_ROTATION_INTERVAL_MINUTES, SYNTHESIS_PROMPT_TEMPLATE,
    CODING_CHALLENGE_PROMPT, PRIVATE_GROUP_ID, DAILY_CHALLENGE_PATH, HISTORY_DIR,
    TELEGRAM_BOT_TOKEN
)
from utils import (
    log_message, get_current_time, format_datetime, is_python_code_block,
    get_user_dir, neutralize_urls, similar
)
from api_clients import (
    APIClient, EndpointHealthManager, DeepSeekClient, SerperClient, WolframAlphaClient,
    TavilyClient, ApiFlashClient, CrawlbaseClient, DetectLanguageClient, GuardianClient,
    IP2LocationClient, ShodanClient, WeatherAPIClient, CloudmersiveClient, GreyNoiseClient,
    PulsediveClient, StormGlassClient, LoginRadiusClient, JsonbinClient, HuggingFaceClient,
    TwilioClient, AbstractAPIClient, GeminiAPIClient, GoogleCustomSearchClient, RandommerClient,
    TomorrowIOClient, OpenWeatherMapClient, MockarooClient, OpenPageRankClient, RapidAPIClient,
    OCRApiClient, ALL_API_CLIENTS, endpoint_health_manager # Import de l'instance globale
)
from memory_and_quotas import memory_manager, quota_manager # Import des instances globales
from filters_and_tools import (
    filter_bad_code, detect_and_correct_toxicity, run_in_sandbox,
    syntax_highlight, check_code, format_code, extract_functions,
    analyze_code_structure, perform_ocr_api, fetch_and_archive_pages
)

class IAOrchestrator:
    def __init__(self, memory_manager_instance, quota_manager_instance, api_clients_list):
        self.memory_manager = memory_manager_instance
        self.quota_manager = quota_manager_instance
        self.api_clients = {client.name: client for client in api_clients_list}
        self.last_strategy_rotation_time = datetime.utcnow()
        self.current_ia_strategy = self._determine_initial_strategy()

        # Core AI engines used for general queries and synthesis
        self.core_ai_engines = {
            "DEEPSEEK": self.api_clients.get("DEEPSEEK"),
            "HUGGINGFACE": self.api_clients.get("HUGGINGFACE"),
            "GOOGLE_CUSTOM_SEARCH": self.api_clients.get("GOOGLE_CUSTOM_SEARCH"),
            "GEMINI_API": self.api_clients.get("GEMINI_API")
        }
        self.core_ai_engines = {k: v for k, v in self.core_ai_engines.items() if v is not None}

        # Mixed agents configuration
        self.mixed_agents = [
            {"name": "GeneralQueryAgent", "primary_ais": ["DEEPSEEK", "GEMINI_API", "HUGGINGFACE"], "tools": ["SERPER", "TAVILY", "WOLFRAMALPHA", "GOOGLE_CUSTOM_SEARCH"]},
            {"name": "CodingAgent", "primary_ais": ["DEEPSEEK", "HUGGINGFACE", "GEMINI_API"], "tools": []}, # Coding tools are handled as direct commands
            {"name": "SecurityAgent", "primary_ais": ["DEEPSEEK", "GEMINI_API"], "tools": ["IP2LOCATION", "SHODAN", "GREYNOISE", "PULSEDIVE", "CLOUDMERSIVE"]},
            {"name": "DataAgent", "primary_ais": ["DEEPSEEK", "GEMINI_API"], "tools": ["JSONBIN", "MOCKAROO", "RANDOMMER", "OPENPAGERANK", "RAPIDAPI"]},
            {"name": "CommunicationAgent", "primary_ais": ["DEEPSEEK", "GEMINI_API"], "tools": ["TWILIO", "ABSTRACTAPI"]},
            {"name": "NewsAgent", "primary_ais": ["DEEPSEEK", "GEMINI_API"], "tools": ["GUARDIAN", "SERPER", "TAVILY", "GOOGLE_CUSTOM_SEARCH"]},
            {"name": "ImageAgent", "primary_ais": ["DEEPSEEK", "GEMINI_API"], "tools": ["APIFLASH", "OCR_API"]}, # Added OCR_API
            {"name": "LanguageAgent", "primary_ais": ["DEEPSEEK", "GEMINI_API"], "tools": ["DETECTLANGUAGE"]},
            {"name": "WeatherAgent", "primary_ais": ["DEEPSEEK", "GEMINI_API"], "tools": ["WEATHERAPI", "STORMGLASS", "TOMORROW.IO", "OPENWEATHERMAP"]}
        ]
        self.current_agent_index = 0
        self.last_agent_rotation_time = datetime.utcnow()

        # Tool descriptions for the AI to understand
        self.tool_descriptions = {
            "SERPER": "Effectue une recherche web sur Google et retourne les snippets et liens pertinents. Param√®tres: {\"query\": \"texte de recherche\"}",
            "TAVILY": "Effectue une recherche web avanc√©e et retourne une r√©ponse directe et des extraits. Param√®tres: {\"query\": \"texte de recherche\", \"max_results\": nombre}",
            "WOLFRAMALPHA": "R√©pond √† des questions factuelles et calculs complexes. Param√®tres: {\"input\": \"question ou calcul\"}",
            "WEATHERAPI": "Fournit la m√©t√©o actuelle et les pr√©visions pour une localisation donn√©e. Param√®tres: {\"location\": \"nom de la ville ou code postal\"}",
            "OPENWEATHERMAP": "Fournit la m√©t√©o actuelle pour une localisation donn√©e. Param√®tres: {\"location\": \"nom de la ville ou code postal\"}",
            "STORMGLASS": "Fournit des donn√©es m√©t√©orologiques maritimes (temp√©rature, vagues) pour des coordonn√©es lat/lng. Param√®tres: {\"lat\": latitude, \"lng\": longitude, \"params\": \"airTemperature,waveHeight\"}",
            "APIFLASH": "Prend une capture d'√©cran d'une URL et retourne l'URL de l'image. Param√®tres: {\"url\": \"URL du site\"}",
            "CRAWLBASE": "R√©cup√®re le contenu HTML ou JavaScript d'une URL. Param√®tres: {\"url\": \"URL du site\", \"use_js\": true/false}",
            "DETECTLANGUAGE": "D√©tecte la langue d'un texte. Param√®tres: {\"text\": \"texte √† analyser\"}",
            "IP2LOCATION": "G√©olocalise une adresse IP. Param√®tres: {\"ip_address\": \"adresse IP\"}",
            "SHODAN": "Fournit des informations sur les h√¥tes et les services expos√©s sur Internet. Param√®tres: {\"query\": \"texte de recherche\"} (optionnel)",
            "GREYNOISE": "Analyse une adresse IP pour d√©terminer si elle est 'bruit' (malveillante). Param√®tres: {\"ip_address\": \"adresse IP\"}",
            "PULSEDIVE": "Analyse des indicateurs de menace (IP, domaine, URL). Param√®tres: {\"indicator\": \"indicateur\", \"type\": \"auto\"}",
            "CLOUDMERSIVE": "V√©rifie la validit√© d'un nom de domaine. Param√®tres: {\"domain\": \"nom de domaine\"}",
            "JSONBIN": "Stocke ou r√©cup√®re des donn√©es JSON dans un 'bin' priv√© ou public. Pour cr√©er: {\"data\": {\"cl√©\": \"valeur\"}, \"private\": true/false}. Pour acc√©der: {\"bin_id\": \"ID du bin\"}",
            "MOCKAROO": "G√©n√®re des donn√©es de test al√©atoires bas√©es sur des sch√©mas. Param√®tres: {\"count\": nombre, \"fields_json\": \"[{\"name\": \"champ\", \"type\": \"Type Mockaroo\"}]\"}",
            "RANDOMMER": "G√©n√®re des donn√©es al√©atoires, comme des num√©ros de t√©l√©phone. Param√®tres: {\"country_code\": \"US\", \"quantity\": 1}",
            "OPENPAGERANK": "R√©cup√®re le PageRank d'un ou plusieurs domaines. Param√®tres: {\"domains\": [\"domaine1.com\", \"domaine2.com\"]}",
            "RAPIDAPI": "Acc√®de √† diverses micro-APIs (blagues, faits, devises). N√©cessite un 'api_name' (ex: 'Programming Joke'). Param√®tres: {\"api_name\": \"Nom de l'API\", \"kwargs\": {\"param1\": \"valeur1\"}}",
            "TWILIO": "V√©rifie le solde du compte Twilio. Param√®tres: Aucun",
            "ABSTRACTAPI": "Valide des emails, num√©ros de t√©l√©phone, g√©olocalise des IPs, ou fournit des taux de change/jours f√©ri√©s. Param√®tres: {\"input_value\": \"valeur\", \"api_type\": \"EMAIL_VALIDATION\"|\"PHONE_VALIDATION\"|\"EXCHANGE_RATES\"|\"HOLIDAYS\"}",
            "TOMORROW.IO": "Fournit des donn√©es m√©t√©orologiques pour une localisation. Param√®tres: {\"location\": \"nom de la ville\", \"fields\": [\"temperature\", \"humidity\"]}",
            "OCR_API": "Extrait le texte d'une image fournie sous forme d'URL. Param√®tres: {\"image_url\": \"URL de l'image\"}"
        }

    def _determine_initial_strategy(self) -> str:
        """D√©termine la strat√©gie initiale ou la strat√©gie par d√©faut."""
        return "balanced"

    def _rotate_strategy_if_needed(self):
        """Change la strat√©gie d'IA et l'agent si l'intervalle de rotation est pass√©."""
        now = datetime.utcnow()
        if (now - self.last_strategy_rotation_time).total_seconds() >= API_ROTATION_INTERVAL_MINUTES * 60:
            strategies = ["balanced", "cost_effective", "performance"]
            self.current_ia_strategy = random.choice(strategies)
            self.last_strategy_rotation_time = now
            log_message(f"Strat√©gie d'IA chang√©e pour: {self.current_ia_strategy}")

            self.current_agent_index = (self.current_agent_index + 1) % len(self.mixed_agents)
            self.last_agent_rotation_time = now
            log_message(f"Agent mixte actuel: {self.mixed_agents[self.current_agent_index]['name']}")

            # Update last_rotation_check for all IAs and recover diversification scores
            for ia_name in self.memory_manager.ia_status:
                self.memory_manager.ia_status[ia_name]["last_rotation_check"] = datetime.utcnow().strftime("%Y-%m-%d %H:%M:%S UTC")
            self.memory_manager.recover_diversification_scores()
            # No need to save_json here, memory_manager.recover_diversification_scores handles it

    async def _select_primary_ai_for_agent(self, agent_config: Dict) -> Optional[APIClient]:
        """
        S√©lectionne une IA primaire parmi celles de l'agent.
        La s√©lection est d√©sormais √©quitable, sans privil√©gier une IA par rapport √† une autre en fonction des scores.
        """
        available_primary_ais = []
        for ai_name in agent_config["primary_ais"]:
            if ai_name in self.core_ai_engines:
                status = self.memory_manager.get_ia_status(ai_name)
                # Check if AI is not in cooldown
                if status and (status.get("cooldown_until") is None or datetime.strptime(status["cooldown_until"], "%Y-%m-%d %H:%M:%S UTC") < datetime.utcnow()):
                    # Check quota without consuming it yet
                    if await self.quota_manager.check_and_update_quota(ai_name, cost=0):
                        available_primary_ais.append(ai_name)
        
        if not available_primary_ais:
            log_message(f"Aucune IA primaire disponible pour l'agent {agent_config['name']}.", level="warning")
            return None

        # Randomly select among available primary AIs for equitable distribution
        selected_ai_name = random.choice(available_primary_ais)
        
        # Now, consume the quota for the selected AI
        if await self.quota_manager.check_and_update_quota(selected_ai_name, cost=1):
            log_message(f"IA primaire s√©lectionn√©e pour l'agent: {selected_ai_name} (S√©lection √©quitable)")
            return self.core_ai_engines[selected_ai_name]
        
        log_message(f"IA {selected_ai_name} s√©lectionn√©e mais quota non disponible au moment de la consommation. Tentative de re-s√©lection.", level="warning")
        # Fallback: try another AI if the first choice's quota just ran out
        available_primary_ais.remove(selected_ai_name)
        if available_primary_ais:
            return await self._select_primary_ai_for_agent({"primary_ais": available_primary_ais}) # Recursive call with remaining options
        
        return None

    async def _run_agent_with_tools(self, agent_config: Dict, query: str, bot_instance: Bot) -> (str, List[Dict], Optional[str]):
        """
        Ex√©cute l'agent mixte en utilisant l'IA primaire s√©lectionn√©e
        et en sollicitant les outils pertinents.
        Retourne la r√©ponse brute de l'agent, une liste des outils appel√©s pour le rapport, et le nom de l'IA primaire utilis√©e.
        """
        primary_ai_client = await self._select_primary_ai_for_agent(agent_config)
        if not primary_ai_client:
            return f"D√©sol√©, l'agent {agent_config['name']} ne peut pas op√©rer car aucune IA primaire n'est disponible.", [], "N/A"

        primary_ai_name_used = primary_ai_client.name
        responses = []
        tools_called_for_report = []
        all_links_for_archive = [] # Collect links for archiving

        available_tools_for_ai = {}
        for tool_name in agent_config.get("tools", []):
            if tool_name in self.tool_descriptions and self.api_clients.get(tool_name):
                available_tools_for_ai[tool_name] = self.tool_descriptions[tool_name]
        
        tool_prompt_part = ""
        if available_tools_for_ai:
            tool_prompt_part = "\n\nTu as acc√®s aux outils suivants:\n"
            for tool_name, desc in available_tools_for_ai.items():
                tool_prompt_part += f"- **{tool_name}**: {desc}\n"
            tool_prompt_part += "\nSi tu as besoin d'utiliser un outil, r√©ponds avec le format suivant: `TOOL_CALL:<nom_outil>:<param√®tres_json>`. Par exemple: `TOOL_CALL:WEATHERAPI:{\"location\": \"Paris\"}`. Sinon, r√©ponds normalement."
        
        full_prompt_for_ai = f"{query}\n\n{tool_prompt_part}"

        log_message(f"Agent {agent_config['name']} utilise {primary_ai_name_used} pour la requ√™te: '{query}'")
        primary_response_raw = await primary_ai_client.query(full_prompt_for_ai)
        self.memory_manager.update_ia_status(primary_ai_name_used, not primary_response_raw.startswith("Erreur"))
        
        tool_call_match = re.match(r"TOOL_CALL:([A-Z_]+):(.+)", primary_response_raw)
        if tool_call_match:
            tool_name = tool_call_match.group(1)
            params_str = tool_call_match.group(2)
            
            try:
                tool_params = json.loads(params_str)
                tool_client = self.api_clients.get(tool_name)
                
                if tool_client and await self.quota_manager.check_and_update_quota(tool_name):
                    log_message(f"Agent {agent_config['name']} ex√©cute l'outil {tool_name} avec les param√®tres: {tool_params}")
                    
                    tool_response = ""
                    if tool_name == "SERPER":
                        serper_result = await tool_client.query(query_text=tool_params.get("query"))
                        tool_response = serper_result
                        # Extract links from Serper result
                        if isinstance(serper_result, dict) and "links" in serper_result:
                            all_links_for_archive.extend(serper_result["links"])
                    elif tool_name == "TAVILY":
                        tavily_result = await tool_client.query(query_text=tool_params.get("query"), max_results=tool_params.get("max_results", 3))
                        tool_response = tavily_result
                        # Extract links from Tavily result
                        if isinstance(tavily_result, dict) and "results" in tavily_result:
                            all_links_for_archive.extend([r.get("url") for r in tavily_result["results"] if r.get("url")])
                    elif tool_name == "WOLFRAMALPHA":
                        tool_response = await tool_client.query(input_text=tool_params.get("input"))
                    elif tool_name == "WEATHERAPI":
                        tool_response = await tool_client.query(location=tool_params.get("location"))
                    elif tool_name == "OPENWEATHERMAP":
                        tool_response = await tool_client.query(location=tool_params.get("location"))
                    elif tool_name == "STORMGLASS":
                        tool_response = await tool_client.query(lat=tool_params.get("lat"), lng=tool_params.get("lng"), params=tool_params.get("params", "airTemperature,waveHeight"))
                    elif tool_name == "APIFLASH":
                        tool_response = await tool_client.query(url=tool_params.get("url"))
                    elif tool_name == "CRAWLBASE":
                        tool_response = await tool_client.query(url=tool_params.get("url"), use_js=tool_params.get("use_js", False))
                    elif tool_name == "DETECTLANGUAGE":
                        tool_response = await tool_client.query(text=tool_params.get("text"))
                    elif tool_name == "IP2LOCATION":
                        tool_response = await tool_client.query(ip_address=tool_params.get("ip_address"))
                    elif tool_name == "SHODAN":
                        tool_response = await tool_client.query(query_text=tool_params.get("query", ""))
                    elif tool_name == "GREYNOISE":
                        tool_response = await tool_client.query(ip_address=tool_params.get("ip_address"))
                    elif tool_name == "PULSEDIVE":
                        tool_response = await tool_client.query(indicator=tool_params.get("indicator"), type=tool_params.get("type", "auto"))
                    elif tool_name == "CLOUDMERSIVE":
                        tool_response = await tool_client.query(domain=tool_params.get("domain"))
                    elif tool_name == "JSONBIN":
                        if "bin_id" in tool_params:
                            tool_response = await tool_client.query(bin_id=tool_params["bin_id"])
                        else:
                            tool_response = await tool_client.query(data=tool_params.get("data", {}), private=tool_params.get("private", True))
                    elif tool_name == "MOCKAROO":
                        tool_response = await tool_client.query(count=tool_params.get("count", 1), fields_json=tool_params.get("fields_json"))
                    elif tool_name == "RANDOMMER":
                        tool_response = await tool_client.query(country_code=tool_params.get("country_code", "US"), quantity=tool_params.get("quantity", 1))
                    elif tool_name == "OPENPAGERANK":
                        tool_response = await tool_client.query(domains=tool_params.get("domains", []))
                    elif tool_name == "RAPIDAPI":
                        tool_response = await tool_client.query(api_name=tool_params.get("api_name"), **tool_params.get("kwargs", {}))
                    elif tool_name == "TWILIO":
                        tool_response = await tool_client.query()
                    elif tool_name == "ABSTRACTAPI":
                        tool_response = await tool_client.query(input_value=tool_params.get("input_value"), api_type=tool_params.get("api_type"))
                    elif tool_name == "TOMORROW.IO":
                        tool_response = await tool_client.query(location=tool_params.get("location"), fields=tool_params.get("fields"))
                    elif tool_name == "OCR_API":
                        image_url = tool_params.get("image_url")
                        if image_url:
                            tool_response = await perform_ocr_api(image_url)
                        else:
                            tool_response = "OCR_API: L'URL de l'image est manquante."
                    
                    if tool_response:
                        responses.append(f"R√©ponse outil ({tool_name}): {tool_response}")
                        tools_called_for_report.append({"name": tool_name, "params": tool_params, "result": tool_response})
                    self.memory_manager.update_ia_status(tool_name, not str(tool_response).startswith("Erreur"))
                    
                    # Follow-up prompt to the primary AI with tool results
                    follow_up_prompt = f"J'ai ex√©cut√© l'outil {tool_name} avec les param√®tres {params_str}. Voici le r√©sultat:\n{tool_response}\n\nMaintenant, r√©ponds √† la question originale: {query}"
                    final_ai_response = await primary_ai_client.query(follow_up_prompt)
                    self.memory_manager.update_ia_status(primary_ai_name_used, not final_ai_response.startswith("Erreur"))
                    responses.append(f"R√©ponse finale ({primary_ai_name_used}): {final_ai_response}")

                else:
                    responses.append(f"Erreur: L'outil {tool_name} n'est pas disponible ou le quota est d√©pass√©.")
                    tools_called_for_report.append({"name": tool_name, "params": tool_params, "result": "Quota d√©pass√© ou non disponible."})
            except json.JSONDecodeError:
                responses.append(f"Erreur: Param√®tres JSON invalides pour l'outil {tool_name}: {params_str}")
                tools_called_for_report.append({"name": tool_name, "params": params_str, "result": "JSON invalide."})
            except Exception as e:
                responses.append(f"Erreur lors de l'ex√©cution de l'outil {tool_name}: {e}")
                self.memory_manager.update_ia_status(tool_name, False, str(e))
                tools_called_for_report.append({"name": tool_name, "params": params_str, "result": f"Erreur: {e}"})
        else:
            responses.append(f"R√©ponse principale ({primary_ai_name_used}): {primary_response_raw}")
        
        # Archive any collected links
        if all_links_for_archive:
            # Pass the bot_instance to fetch_and_archive_pages
            await fetch_and_archive_pages(all_links_for_archive, bot_instance.id, bot_instance) # Use bot.id for archiving in a generic user dir or specific group dir
            # Add a note to the response or long-term memory about archiving
            self.memory_manager.add_to_long_term_memory(bot_instance.id, f"Pages archiv√©es suite √† la recherche pour '{query}': {', '.join(all_links_for_archive[:3])}...")

        return "\n\n".join(responses), tools_called_for_report, primary_ai_name_used

    async def process_query(self, user_id: int, query: str, bot_instance: Bot) -> (str, List[Dict], Optional[str]):
        """Traite une requ√™te en s√©lectionnant un agent mixte et en obtenant une r√©ponse."""
        self._rotate_strategy_if_needed()

        # Check for similar prompt in user's history first
        cached_response = await self.memory_manager.check_for_similar_prompt(user_id, query)
        if cached_response:
            log_message(f"R√©ponse en cache trouv√©e pour l'utilisateur {user_id}.")
            return cached_response, [], "Cache"

        current_agent_config = self.mixed_agents[self.current_agent_index]
        log_message(f"Traitement de la requ√™te avec l'agent: {current_agent_config['name']}")

        agent_raw_response, tools_called_for_report, primary_ai_used_name = await self._run_agent_with_tools(current_agent_config, query, bot_instance)
        
        # Determine if synthesis is needed
        # If there are multiple responses (e.g., from tool + AI) or if the primary AI response is complex
        if "R√©ponse principale (" in agent_raw_response and not tools_called_for_report:
            log_message("R√©ponse unique et directe d√©tect√©e, pas de synth√®se n√©cessaire.")
            final_response = agent_raw_response.replace(f"R√©ponse principale ({primary_ai_used_name}): ", "") 
        else:
            log_message("Plusieurs r√©ponses ou outils d√©tect√©s, appel √† la synth√®se.")
            final_response = await self.synthesize_response(query, [agent_raw_response], primary_ai_used_name)

        # Add to user's long term memory (for future context)
        await self.memory_manager.add_to_long_term_memory(user_id, f"Question: {query}\nR√©ponse: {final_response}")

        return final_response, tools_called_for_report, primary_ai_used_name

    async def synthesize_response(self, question: str, responses: List[str], primary_ai_name_used_for_query: str) -> str:
        """
        Synth√©tise les r√©ponses de plusieurs IA en utilisant DeepSeek ou Gemini (les modules d'optimisation)
        ou un fallback si DeepSeek/Gemini est indisponible.
        """
        if not responses:
            return "Je n'ai re√ßu aucune r√©ponse des IA pour le moment."

        combined_responses = "\n\n".join([f"R√©ponse {i+1}:\n{r}" for i, r in enumerate(responses)])
        synthesis_prompt = SYNTHESIS_PROMPT_TEMPLATE.format(question=question, responses=combined_responses)

        synthesis_ai_clients = []
        if "DEEPSEEK" in self.core_ai_engines:
            synthesis_ai_clients.append(self.core_ai_engines["DEEPSEEK"])
        if "GEMINI_API" in self.core_ai_engines:
            synthesis_ai_clients.append(self.core_ai_engines["GEMINI_API"])
        
        if not synthesis_ai_clients:
            log_message("Aucune IA de synth√®se (DeepSeek ou Gemini) n'est disponible.", level="warning")
            return "J'ai plusieurs r√©ponses, mais je ne peux pas les synth√©tiser pour le moment. Voici les r√©ponses brutes:\n\n" + combined_responses

        for ai_client in synthesis_ai_clients:
            ai_name = ai_client.name
            status = self.memory_manager.get_ia_status(ai_name)
            if status and (status.get("cooldown_until") is None or datetime.strptime(status["cooldown_until"], "%Y-%m-%d %H:%M:%S UTC") < datetime.utcnow()):
                if await self.quota_manager.check_and_update_quota(ai_name, cost=1):
                    try:
                        log_message(f"Tentative de synth√®se avec {ai_name}...")
                        synthesis = await ai_client.query(synthesis_prompt)
                        self.memory_manager.update_ia_status(ai_name, True)
                        return detect_and_correct_toxicity(synthesis)
                    except Exception as e:
                        log_message(f"Erreur lors de la synth√®se avec {ai_name}: {e}", level="error")
                        self.memory_manager.update_ia_status(ai_name, False, str(e))
                else:
                    log_message(f"Quota d√©pass√© pour {ai_name} lors de la synth√®se.", level="warning")
            else:
                log_message(f"{ai_name} est en cooldown ou non disponible pour la synth√®se.", level="warning")

        log_message("Toutes les IA de synth√®se ont √©chou√© ou sont indisponibles. Retourne les r√©ponses brutes.", level="error")
        return "J'ai rencontr√© un probl√®me lors de la synth√®se des informations. Voici les r√©ponses brutes:\n\n" + combined_responses

# Instanciation de l'orchestrateur
orchestrator = IAOrchestrator(memory_manager, quota_manager, ALL_API_CLIENTS)

# --- T√¢ches P√©riodiques ---

async def coding_challenge_task(context: ContextTypes.DEFAULT_TYPE):
    """
    T√¢che p√©riodique qui g√©n√®re un d√©fi de codage Python, le fait r√©soudre par les IA,
    et envoie les r√©sultats au groupe priv√©.
    """
    log_message("Lancement de la t√¢che de d√©fi de codage...")
    
    # R√©cup√©rer la m√©moire r√©cente du groupe pour √©viter les redites
    group_mem = await memory_manager.get_group_memory(PRIVATE_GROUP_ID, limit=50) # Plus de contexte
    
    full_prompt = f"{CODING_CHALLENGE_PROMPT}\n\nM√©moire r√©cente du groupe (pour √©viter les redites):\n{group_mem}\n\nD√©fi du jour:"
    
    # D√©tecter les IA pertinentes pour le codage
    # Pour un d√©fi de codage, on veut principalement les IA g√©n√©ratives
    relevant_ias_for_challenge = ["DEEPSEEK", "HUGGINGFACE", "GEMINI_API"]
    
    results = []
    for ia_name in relevant_ias_for_challenge:
        ia_client = orchestrator.api_clients.get(ia_name)
        if ia_client:
            if await quota_manager.check_and_update_quota(ia_name):
                try:
                    log_message(f"IA {ia_name} tente de r√©soudre le d√©fi de codage...")
                    resp = await ia_client.query(full_prompt)
                    results.append((ia_name, resp))
                    memory_manager.update_ia_status(ia_name, True)
                except Exception as e:
                    log_message(f"[coding_challenge_task] Erreur avec {ia_name}: {e}\n{traceback.format_exc()}", level="error")
                    memory_manager.update_ia_status(ia_name, False, str(e))
                await asyncio.sleep(0.5) # Petite pause entre les appels API
            else:
                log_message(f"Quota d√©pass√© pour {ia_name} lors du d√©fi de codage.", level="warning")
        else:
            log_message(f"Client API {ia_name} non trouv√© pour le d√©fi de codage.", level="warning")

    if results:
        for name, resp in results:
            # Nettoyer le code pour l'affichage et la sauvegarde
            code_content = resp
            if is_python_code_block(resp):
                code_content = resp.replace("```python", "").replace("```", "").strip()
            
            # Sauvegarder le code g√©n√©r√©
            fname = f"challenge_{name}_{datetime.now().strftime('%Y%m%d_%H%M%S')}.py"
            fpath = DAILY_CHALLENGE_PATH / fname
            try:
                fpath.write_text(code_content, encoding="utf-8")
                log_message(f"D√©fi de codage sauvegard√©: {fpath}")
            except Exception as e:
                log_message(f"Erreur lors de la sauvegarde du d√©fi de codage {fname}: {e}", level="error")

            # Envoyer au groupe priv√©
            if PRIVATE_GROUP_ID and context.bot:
                try:
                    # Tronquer pour Telegram si trop long
                    display_code = code_content[:1500] + "..." if len(code_content) > 1500 else code_content
                    # Utiliser HTML pour le formatage <pre>
                    await context.bot.send_message(chat_id=PRIVATE_GROUP_ID, text=f"üíª <b>D√©fi {name}</b> :\n<pre>{display_code}</pre>", parse_mode="HTML")
                    log_message(f"D√©fi de codage envoy√© au groupe priv√© par {name}.")
                except Exception as e:
                    log_message(f"Erreur lors de l'envoi du d√©fi de codage au groupe priv√©: {e}", level="error")
            
            # Ajouter √† la m√©moire de groupe
            await memory_manager.save_group_memory(PRIVATE_GROUP_ID, "bot", f"D√©fi codage {name} : {code_content[:100]}")
    else:
        log_message("Aucune IA n'a pu g√©n√©rer de code pour le d√©fi de codage.", level="warning")
        if PRIVATE_GROUP_ID and context.bot:
            await context.bot.send_message(chat_id=PRIVATE_GROUP_ID, text="üòî Aucune IA n'a pu g√©n√©rer de code pour le d√©fi de codage cette fois-ci.")

async def periodic_health_check_job(context: ContextTypes.DEFAULT_TYPE) -> None:
    """JobQueue wrapper pour les health checks p√©riodiques."""
    log_message("Lancement des health checks p√©riodiques via JobQueue pour tous les services...")
    for service_name in API_CONFIG.keys():
        await endpoint_health_manager.run_health_check_for_service(service_name)
    log_message("Health checks p√©riodiques via JobQueue termin√©s.")

async def send_structured_report_to_private_group(context: ContextTypes.DEFAULT_TYPE, report_data: Dict) -> None:
    """Envoie un rapport structur√© au groupe priv√© Telegram."""
    try:
        report_text = f"üìä **Rapport d'Action IA**\n\n"
        report_text += f"**Timestamp**: `{report_data.get('timestamp')}`\n"
        report_text += f"**Agent**: `{report_data.get('agent_name')}`\n"
        report_text += f"**Intention D√©tect√©e**: `{report_data.get('intention')}`\n"
        report_text += f"**Requ√™te Utilisateur**: `{report_data.get('user_query')}`\n"
        
        primary_ai_used_display = report_data.get('primary_ai_used', 'N/A')
        # Ensure primary_ai_used_display is a string, not a dict if it somehow became one
        if isinstance(primary_ai_used_display, dict) and 'name' in primary_ai_used_display:
            primary_ai_used_display = primary_ai_used_display['name']
        report_text += f"**IA Primaire Utilis√©e**: `{primary_ai_used_display}`\n"
        
        tools_called = report_data.get('tools_called', [])
        if tools_called:
            report_text += "**Outils Appel√©s**:\n"
            for tool in tools_called:
                tool_result_display = str(tool['result'])
                if len(tool_result_display) > 100:
                    tool_result_display = tool_result_display[:100] + "..."
                # Escape Markdown special characters in JSON parameters
                escaped_params = json.dumps(tool['params'], indent=2)
                escaped_params = escaped_params.replace('_', '\\_').replace('*', '\\*').replace('`', '\\`')
                report_text += f"- `{tool['name']}` (Params: ```json\n{escaped_params}\n```, R√©sultat: `{tool_result_display}`)\n"
        else:
            report_text += "**Outils Appel√©s**: Aucun\n"
        
        final_response_display = report_data.get('final_response', '')
        if len(final_response_display) > 500:
            final_response_display = final_response_display[:500] + "..."
        # Escape Markdown special characters in the final response
        final_response_display = final_response_display.replace('_', '\\_').replace('*', '\\*').replace('`', '\\`')
        report_text += f"**R√©ponse Finale**: `{final_response_display}`\n"
        report_text += f"**Dur√©e Totale**: `{report_data.get('duration'):.2f}s`\n"
        report_text += f"**Erreur**: `{report_data.get('error', 'Non')}`\n"

        await context.bot.send_message(chat_id=PRIVATE_GROUP_ID, text=report_text, parse_mode='MarkdownV2')
        log_message(f"Rapport structur√© envoy√© au groupe priv√©: {PRIVATE_GROUP_ID}")
    except Exception as e:
        log_message(f"Erreur lors de l'envoi du rapport structur√© au groupe priv√©: {e}", level="error")

# --- Command Handlers ---

async def start(update: Update, context: ContextTypes.DEFAULT_TYPE) -> None:
    """Envoie un message de bienvenue lorsque la commande /start est √©mise."""
    user = update.effective_user
    log_message(f"Commande /start re√ßue de {user.full_name} (ID: {user.id})")
    await update.message.reply_html(
        f"Salut {user.mention_html()}! Je suis un bot IA avanc√©. Comment puis-je vous aider aujourd'hui?",
        disable_web_page_preview=True
    )

async def help_command(update: Update, context: ContextTypes.DEFAULT_TYPE) -> None:
    """Envoie un message d'aide lorsque la commande /help est √©mise."""
    log_message(f"Commande /help re√ßue de {update.effective_user.full_name}")
    help_text = (
        "Je suis un bot IA multi-agents capable de r√©pondre √† diverses questions et d'utiliser des outils externes.\n\n"
        "Commandes disponibles:\n"
        "/start - D√©marre la conversation avec le bot.\n"
        "/help - Affiche ce message d'aide.\n"
        "/status - Affiche le statut actuel de toutes les IA.\n"
        "/quota - Affiche l'utilisation actuelle des quotas pour les APIs.\n"
        "/burn_quota - Sugg√®re des APIs dont le quota peut √™tre 'br√ªl√©' avant r√©initialisation.\n"
        "/pyflakes <code> - Analyse le code Python avec Pyflakes.\n"
        "/format <code> - Formate le code Python avec Black.\n"
        "/ast <code> - Affiche la structure AST du code Python.\n"
        "/functions <code> - Extrait les noms des fonctions du code Python.\n"
        "/ocr <image_url> - Effectue l'OCR sur une image √† partir d'une URL.\n"
        "/shell <command> - Ex√©cute une commande shell dans une sandbox.\n\n"
        "Posez-moi simplement une question et je ferai de mon mieux pour y r√©pondre!"
    )
    await update.message.reply_text(help_text)

async def status_command(update: Update, context: ContextTypes.DEFAULT_TYPE) -> None:
    """Affiche le statut de toutes les IA (derni√®re utilisation, erreurs, cooldown)."""
    log_message(f"Commande /status re√ßue de {update.effective_user.full_name}")
    if not memory_manager._initialized:
        await update.message.reply_text("Le gestionnaire de m√©moire n'est pas encore compl√®tement initialis√©. Veuillez r√©essayer dans un instant.")
        return

    ia_statuses = memory_manager.ia_status
    if not ia_statuses:
        await update.message.reply_text("Aucune donn√©e de statut IA disponible.")
        return

    status_text = "üìä **Statut des IA**:\n\n"
    now = get_current_time()
    for ia_name, status_data in ia_statuses.items():
        cooldown_until_str = status_data.get("cooldown_until")
        cooldown_status = "Non"
        if cooldown_until_str:
            try:
                cooldown_until_dt = datetime.strptime(cooldown_until_str, "%Y-%m-%d %H:%M:%S UTC")
                if now < cooldown_until_dt:
                    remaining_time = cooldown_until_dt - now
                    hours, remainder = divmod(remaining_time.total_seconds(), 3600)
                    minutes, seconds = divmod(remainder, 60)
                    cooldown_status = f"Oui (reste {int(hours)}h {int(minutes)}m)"
            except ValueError:
                cooldown_status = "Erreur de date (reset)" # Handle malformed date strings

        last_used_display = status_data.get("last_used", "Jamais")
        last_error_display = status_data.get("last_error", "Aucune")

        status_text += (
            f"**{ia_name}**:\n"
            f"  Derni√®re utilisation: `{last_used_display}`\n"
            f"  Erreurs cons√©cutives: `{status_data.get('error_count', 0)}`\n"
            f"  En Cooldown: `{cooldown_status}`\n"
            f"  Score actuel: `{status_data.get('current_score', 1.0):.2f}`\n"
            f"  Score diversification: `{status_data.get('diversification_score', 1.0):.2f}`\n"
            f"  Derni√®re erreur: `{last_error_display}`\n\n"
        )
    await update.message.reply_text(status_text, parse_mode='Markdown')

async def quota_command(update: Update, context: ContextTypes.DEFAULT_TYPE) -> None:
    """Affiche l'utilisation actuelle des quotas pour les APIs."""
    log_message(f"Commande /quota re√ßue de {update.effective_user.full_name}")
    if not quota_manager._initialized:
        await update.message.reply_text("Le gestionnaire de quotas n'est pas encore compl√®tement initialis√©. Veuillez r√©essayer dans un instant.")
        return

    all_quotas_status = quota_manager.get_all_quotas_status()
    if not all_quotas_status:
        await update.message.reply_text("Aucune donn√©e de quota API disponible.")
        return

    quota_text = "üìà **Utilisation des Quotas API**:\n\n"
    for api_name, data in all_quotas_status.items():
        quota_text += (
            f"**{api_name}**:\n"
            f"  Mensuel: `{data['monthly_usage']}/{data['monthly_limit']}`\n"
            f"  Journalier: `{data['daily_usage']}/{data['daily_limit']}`\n"
            f"  Horaire: `{data['hourly_usage']}/{data['hourly_limit']}`\n"
            f"  Total appels: `{data['total_calls']}`\n"
            f"  Derni√®re utilisation: `{data['last_usage'] if data['last_usage'] else 'Jamais'}`\n"
            f"  R√©initialisation mensuelle: `{data['last_reset_month']}`\n"
            f"  R√©initialisation journali√®re: `{data['last_reset_day']}`\n"
            f"  R√©initialisation horaire: `{data['last_hourly_reset']}`\n\n"
        )
    await update.message.reply_text(quota_text, parse_mode='Markdown')

async def burn_quota_command(update: Update, context: ContextTypes.DEFAULT_TYPE) -> None:
    """Identifie et sugg√®re des APIs dont le quota peut √™tre 'br√ªl√©' avant r√©initialisation."""
    log_message(f"Commande /burn_quota re√ßue de {update.effective_user.full_name}")
    if not quota_manager._initialized:
        await update.message.reply_text("Le gestionnaire de quotas n'est pas encore compl√®tement initialis√©. Veuillez r√©essayer dans un instant.")
        return

    burn_apis = quota_manager.get_burn_window_apis()
    if burn_apis:
        response_text = "üî• **APIs dont le quota peut √™tre 'br√ªl√©'** (proche de la r√©initialisation):\n"
        for api_info in burn_apis:
            response_text += f"- {api_info}\n"
        response_text += "\nUtiliser ces APIs maintenant permet de maximiser l'utilisation avant que le quota ne soit r√©initialis√©."
    else:
        response_text = "Aucune API n'est actuellement dans une fen√™tre de 'burn' de quota."
    await update.message.reply_text(response_text, parse_mode='Markdown')

async def handle_message(update: Update, context: ContextTypes.DEFAULT_TYPE) -> None:
    """G√®re les messages texte entrants, les traite via l'orchestrateur et envoie la r√©ponse."""
    user_msg = update.message.text
    user_id = update.effective_user.id
    chat_id = update.effective_chat.id
    
    log_message(f"Message re√ßu de {update.effective_user.full_name} (ID: {user_id}) dans le chat {chat_id}: '{user_msg}'")
    
    # Add user message to history (user-specific log and chat history)
    await memory_manager.add_message_to_history(user_id, "user", user_msg)
    # Also add to group memory if it's a group chat
    if chat_id != user_id: # Assuming user_id is the same as chat_id for private chats
        await memory_manager.save_group_memory(chat_id, "user", user_msg)

    # --- Handle specific commands from the old script ---
    command_handled = False
    response_text = ""
    code_to_process = ""

    if user_msg.startswith("/pyflakes"):
        code_to_process = user_msg.replace("/pyflakes", "", 1).strip()
        response_text = check_code(code_to_process)
        command_handled = True
    elif user_msg.startswith("/format"):
        code_to_process = user_msg.replace("/format", "", 1).strip()
        response_text = format_code(code_to_process)
        command_handled = True
    elif user_msg.startswith("/ast"):
        code_to_process = user_msg.replace("/ast", "", 1).strip()
        response_text = analyze_code_structure(code_to_process)
        command_handled = True
    elif user_msg.startswith("/functions"):
        code_to_process = user_msg.replace("/functions", "", 1).strip()
        response_text = extract_functions(code_to_process)
        command_handled = True
    elif user_msg.startswith("/ocr"):
        image_url = user_msg.replace("/ocr", "", 1).strip()
        if image_url:
            processing_message = await update.message.reply_text("Traitement OCR en cours... üñºÔ∏è")
            response_text = await perform_ocr_api(image_url)
            await processing_message.delete()
        else:
            response_text = "Veuillez fournir une URL d'image pour l'OCR. Ex: `/ocr https://example.com/image.png`"
        command_handled = True
    elif user_msg.startswith("/shell"):
        command = user_msg.replace("/shell", "", 1).strip()
        if command:
            processing_message = await update.message.reply_text("Ex√©cution de la commande shell en sandbox... üêö")
            response_text = await run_in_sandbox(command, language="shell")
            await processing_message.delete()
        else:
            response_text = "Veuillez fournir une commande shell √† ex√©cuter. Ex: `/shell ls -l`"
        command_handled = True
    
    # Auto-analyse if Python code block detected
    if not command_handled and is_python_code_block(user_msg):
        code_to_process = user_msg.strip("```python").strip("`")
        pyflakes_res = check_code(code_to_process)
        format_res = format_code(code_to_process)
        response_text = f"**Analyse automatique du code Python**:\n\n" \
                        f"**Pyflakes**:\n<pre>{pyflakes_res}</pre>\n\n" \
                        f"**Formatage (Black)**:\n<pre>{format_res}</pre>"
        command_handled = True
    
    if command_handled:
        await update.message.reply_text(response_text, parse_mode='HTML')
        # Add bot's response to history
        await memory_manager.add_message_to_history(user_id, "bot", response_text)
        if chat_id != user_id:
            await memory_manager.save_group_memory(chat_id, "bot", response_text)
        return

    # --- If not a specific command, process with IA Orchestrator ---
    processing_message = await update.message.reply_text("Je r√©fl√©chis √† votre requ√™te... üß†")
    start_time = time.time()
    
    final_response = "D√©sol√©, une erreur inattendue s'est produite."
    tools_called = []
    primary_ai_used_name = "N/A"
    error_occurred = False
    
    try:
        if not memory_manager._initialized or not quota_manager._initialized or not endpoint_health_manager._initialized:
            final_response = "Le bot est en cours d'initialisation. Veuillez r√©essayer dans un instant."
            error_occurred = True
        else:
            final_response, tools_called, primary_ai_used_name = await orchestrator.process_query(user_id, user_msg, context.bot)
            # Add bot's response to history (already done by orchestrator's synthesis or direct response logic)
            # but ensure it's also in the user's main chat history
            await memory_manager.add_message_to_history(user_id, "bot", final_response)
            if chat_id != user_id:
                await memory_manager.save_group_memory(chat_id, "bot", final_response)


    except Exception as e:
        log_message(f"Erreur critique lors du traitement de la requ√™te: {e}\n{traceback.format_exc()}", level="error")
        final_response = f"D√©sol√©, une erreur interne est survenue lors du traitement de votre requ√™te: {e}"
        error_occurred = True
    finally:
        duration = time.time() - start_time
        
        try:
            await processing_message.delete()
        except Exception as delete_e:
            log_message(f"Impossible de supprimer le message de traitement: {delete_e}", level="warning")

        await update.message.reply_text(final_response, disable_web_page_preview=True)
        log_message(f"R√©ponse envoy√©e √† {update.effective_user.full_name}. Dur√©e: {duration:.2f}s")

        # Send structured report to private group
        report_data = {
            "timestamp": format_datetime(get_current_time()),
            "agent_name": orchestrator.mixed_agents[orchestrator.current_agent_index]['name'],
            "intention": "D√©tection d'intention non impl√©ment√©e ici, bas√©e sur l'agent", # Placeholder for future
            "user_query": user_msg,
            "primary_ai_used": primary_ai_used_name,
            "tools_called": tools_called,
            "final_response": final_response,
            "duration": duration,
            "error": str(error_occurred) if error_occurred else "Non"
        }
        if PRIVATE_GROUP_ID:
            await send_structured_report_to_private_group(context, report_data)
        else:
            log_message("PRIVATE_GROUP_ID non configur√©, rapport non envoy√©.", level="warning")

async def main() -> None:
    """Lance le bot."""
    log_message("D√©marrage de l'application Telegram Bot...")
    
    # Initialiser le verrou de fichier avant toute op√©ration de fichier asynchrone
    file_lock_instance = asyncio.Lock()
    from utils import set_file_lock
    set_file_lock(file_lock_instance)

    # Initialiser les gestionnaires
    await endpoint_health_manager.init_manager()
    await memory_manager.init_manager()
    await quota_manager.init_manager()

    # Initialiser l'application Telegram
    application = Application.builder().token(TELEGRAM_BOT_TOKEN).build()

    # Passer l'instance du bot au quota_manager pour les alertes
    quota_manager.set_bot_instance(application.bot)

    # Ajouter les gestionnaires de commandes
    application.add_handler(CommandHandler("start", start))
    application.add_handler(CommandHandler("help", help_command))
    application.add_handler(CommandHandler("status", status_command))
    application.add_handler(CommandHandler("quota", quota_command))
    application.add_handler(CommandHandler("burn_quota", burn_quota_command))

    # Gestionnaires pour les commandes de d√©veloppement
    application.add_handler(CommandHandler("pyflakes", handle_message))
    application.add_handler(CommandHandler("format", handle_message))
    application.add_handler(CommandHandler("ast", handle_message))
    application.add_handler(CommandHandler("functions", handle_message))
    application.add_handler(CommandHandler("ocr", handle_message))
    application.add_handler(CommandHandler("shell", handle_message))

    # Gestionnaire de messages texte (hors commandes)
    application.add_handler(MessageHandler(filters.TEXT & ~filters.COMMAND, handle_message))

    # Configurer et d√©marrer le JobQueue pour les t√¢ches p√©riodiques
    job_queue = application.job_queue
    
    # Health check p√©riodique (toutes les 30 minutes, comme l'intervalle de rotation)
    job_queue.run_repeating(periodic_health_check_job, interval=API_ROTATION_INTERVAL_MINUTES * 60, first=10)
    
    # D√©fi de codage p√©riodique (toutes les 15 minutes)
    job_queue.run_repeating(coding_challenge_task, interval=15 * 60, first=15) # Start 15s after bot launch

    log_message("Bot Telegram d√©marr√©, en attente de messages...")
    await application.run_polling(allowed_updates=Update.ALL_TYPES)

if __name__ == "__main__":
    try:
        # Utilisation de nest_asyncio pour la compatibilit√© avec certains environnements (ex: Jupyter)
        try: import nest_asyncio; nest_asyncio.apply()
        except ImportError: pass # nest_asyncio n'est pas toujours n√©cessaire

        asyncio.run(main())
    except KeyboardInterrupt:
        log_message("Bot arr√™t√© manuellement.")
    except Exception as e:
        log_message(f"Erreur irr√©cup√©rable dans la fonction main: {e}\n{traceback.format_exc()}", level="critical")




# --- DEBUT DU FICHIER PRINCIPAL ---

import os
import json
import asyncio
import httpx
import logging
import re
import random
import io
import contextlib
import ast
import subprocess
from datetime import datetime, timedelta
from concurrent.futures import ThreadPoolExecutor
from typing import Dict, Any, Optional, Union, List

# --- Configuration Globale ---
# Ceci inclut les param√®tres du bot, les quotas API, les cl√©s API, et les chemins de fichiers.

# --- Telegram Bot Configuration ---
# REMPLACE 'YOUR_TELEGRAM_BOT_TOKEN_HERE' PAR LE VRAI TOKEN DE TON BOT TELEGRAM
TELEGRAM_BOT_TOKEN = "YOUR_TELEGRAM_BOT_TOKEN_HERE"
# REMPLACE -1001234567890 PAR L'ID DE TON GROUPE TELEGRAM (DOIT ETRE UN NOMBRE NEGATIF POUR LES SUPERGROUPES)
PRIVATE_GROUP_ID = -1001234567890

# --- Quotas API (Estimations si non document√©es, bas√© sur tes infos) ---
# Si un quota est par service et non par cl√©, la limite sera appliqu√©e globalement pour ce service
API_QUOTAS = {
    "APIFLASH": {"monthly": 100},
    "DEEPSEEK": {"monthly": None}, # Tier gratuit, pas de limite claire document√©e
    "CRAWLBASE": {"monthly": 1000},
    "DETECTLANGUAGE": {"daily": 1000},
    "GUARDIAN": {"daily": 5000, "rate_limit_per_sec": 12},
    "IP2LOCATION": {"monthly": 50},
    "SERPER": {"monthly": 2500},
    "SHODAN": {"monthly": 100},
    "TAVILY": {"monthly": None}, # Pas de quota gratuit document√©, √† surveiller
    "WEATHERAPI": {"monthly": None}, # Pas de quota gratuit document√©, √† surveiller
    "WOLFRAMALPHA": {"monthly": None}, # Tier gratuit, quota non document√©
    "CLOUDMERSIVE": {"monthly": None}, # Tier gratuit vari√©, √† surveiller
    "GREYNOISE": {"monthly": None}, # Pas de quota gratuit document√©, √† surveiller
    "PULSEDIVE": {"monthly": None}, # Pas de quota gratuit document√©, √† surveiller
    "STORMGLASS": {"monthly": None}, # Pas de quota gratuit document√©, √† surveiller
    "LOGINRADIUS": {"monthly": 25000}, # MAU Free Forever plan
    "JSONBIN": {"monthly": 10000}, # 10,000 requests + 10,000 bins
    "HUGGINGFACE": {"hourly": 100}, # Estimation libre inference
    "TWILIO": {"monthly": 15}, # Cr√©dit d'essai en USD
    "ABSTRACTAPI_PHONE": {"monthly": 250, "rate_limit_per_sec": 1},
    "ABSTRACTAPI_IP": {"monthly": None}, # Tier gratuit vari√©, √† surveiller
    "SENDGRID": {"daily": 100}, # Inclu dans Twilio (si SendGrid est g√©r√© via Twilio ou s√©par√©ment)
    # Ajoute d'autres APIs ici si tu en as (avec leurs quotas)
}

# --- Cl√©s API et Endpoints ---
# IMPORTANT : J'ai remis toutes les cl√©s et endpoints que tu as fournis.
# V√©rifie attentivement ces valeurs.

API_KEYS = {
    "APIFLASH": {
        "key": "3a3cc886a18e41109e0cebc0745b12de",
        "endpoint": "https://api.apiflash.com/v1/urltoimage"
    },
    "DEEPSEEK": {
        "key": "sk-ef08317d125947b3a1ce5916592bef00",
        "endpoint": "https://api.deepseek.com/v1/chat/completions"
    },
    "CRAWLBASE": {
        "key": "x41P6KNU8J86yF9JV1nqSw",
        "endpoint": "https://api.crawlbase.com" # Base endpoint, params added later
    },
    "DETECTLANGUAGE": {
        "key": "ebdc8ccc2ee75eda3ab122b08ffb1e8d",
        "endpoint": "https://ws.detectlanguage.com/0.2/detect"
    },
    "GUARDIAN": {
        "key": "07c622c1-af05-4c24-9f37-37d219be76a0",
        "endpoint": "https://content.guardianapis.com/search"
    },
    "IP2LOCATION": {
        "key": "11103C239EA8EA6DF2473BB445EC32F2",
        "endpoint": "https://api.ip2location.io/"
    },
    "SERPER": {
        "key": "047b30db1df999aaa9c293f2048037d40c651439",
        "endpoint": "https://google.serper.dev/search"
    },
    "SHODAN": {
        "key": "umdSaWOfVq9Wt2F4wWdXiKh1zjLailzn",
        "endpoint": "https://api.shodan.io/api-info"
    },
    "TAVILY": {
        "key": "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",
        "endpoint": "https://api.tavily.com/search"
    },
    "WEATHERAPI": {
        "key": "332bcdba457d4db4836175513250407",
        "endpoint": "http://api.weatherapi.com/v1/current.json"
    },
    "WOLFRAMALPHA": {
        "key": "96LX77-G8PGKJ3T7V",
        "endpoint": "http://api.wolframalpha.com/v2/query"
    },
    "CLOUDMERSIVE": {
        "key": "4d407015-ce22-45d7-a2e1-b88ab6380e84",
        "endpoint": "https://api.cloudmersive.com/validate/domain/check"
    },
    "GREYNOISE": {
        "key": "5zNe9E6c5UNDhU09iVXbMaB04UpHAw5hNm5rHCK24fCLvI2cP33NNOpL7nhkDETG",
        "endpoint": "https://api.greynoise.io/v3/community/" # IP added dynamically
    },
    "PULSEDIVE": {
        "key": "201bb09342f35d365889d7d0ca0fdf8580ebee0f1e7644ce70c99a46c1d47171",
        "endpoint": "https://pulsedive.com/api/v1/analyze"
    },
    "STORMGLASS": {
        "key": "7ad5b888-5900-11f0-80b9-0242ac130006-7ad5b996-5900-11f0-80b9-0242ac130006",
        "endpoint": "https://api.stormglass.io/v2/weather/point"
    },
    "LOGINRADIUS": {
        "key": "073b2fbedf82409da2ca6f37b97e8c6a",
        "endpoint": "https://api.loginradius.com/identity/v2/auth/ping"
    },
    "JSONBIN": {
        "key": "$2a$10$npWSB7v1YcoqLkyPpz0PZOVtES5vBs6JtTWVyVDXK3j6FDxYS5BPO",
        "endpoint": "https://api.jsonbin.io/v3/b"
    },
    "HUGGINGFACE": [
        {"key": "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", "endpoint": "https://huggingface.co/api/models"},
        {"key": "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", "endpoint": "https://huggingface.co/api/models"},
        {"key": "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", "endpoint": "https://huggingface.co/api/models"}
    ],
    "TWILIO": { # Twilio et SendGrid sont regroup√©s
        "sid": "SK84cc4d3...", # REMPLACE CECI PAR TON VRAI SID TWILIO
        "secret": "spvz5uwP...", # REMPLACE CECI PAR TON VRAI SECRET TWILIO
        "endpoint": "https://api.twilio.com/2010-04-01/Accounts/" # SID ajout√© dynamiquement
    },
    "ABSTRACTAPI": [ # Abstract API avec plusieurs types de cl√©s et endpoints
        {"key": "020a4dcd3e854ac0b19043491d79df92", "type": "PHONE_VALIDATION", "endpoint": "https://phonevalidation.abstractapi.com/v1/"},
        # Ajoute ici d'autres cl√©s AbstractAPI si tu as d'autres types (ex: IP Geolocation)
        # {"key": "AUTRE_CLE_IP_GEOLOC", "type": "IP_GEOLOCATION", "endpoint": "https://ipgeolocation.abstractapi.com/v1/"}
    ]
}


# --- Bot Behavior Configuration ---
# Dur√©e de "cooldown" pour une API apr√®s des erreurs ou un spam (en secondes)
API_COOLDOWN_DURATION_SECONDS = 30

# Intervalle de rotation du "Cerveau Mixte" / Strat√©gie API (en minutes)
# Toutes les 45 minutes, la strat√©gie de s√©lection des APIs pourra potentiellement changer
API_ROTATION_INTERVAL_MINUTES = 45

# Fen√™tre de temps avant le reset des quotas o√π le bot essaie de "br√ªler" le quota restant (en heures)
QUOTA_BURN_WINDOW_HOURS = 2

# Prompt pour le cerveau principal qui fait la synth√®se des r√©ponses
SYNTHESIS_PROMPT_TEMPLATE = (
    "Voici plusieurs r√©ponses provenant de diff√©rentes IA/APIs √† la question : {question}\n\n{responses}\n\n"
    "Analyse ces r√©ponses. Si elles proposent des solutions ou des faits divergents, "
    "pr√©sente les trois (ou plus) options principales de mani√®re claire, concise et factuelle, "
    "en expliquant bri√®vement la divergence ou la nuance de chaque. Si un consensus clair se d√©gage, "
    "synth√©tise-le. Termine en proposant d'approfondir si l'utilisateur le souhaite."
    "N'oublie pas que tu DOIS r√©pondre comme si tu vivais r√©ellement en 2025. "
    "M√™me si certaines informations pourraient sembler obsol√®tes ou inexactes par rapport aux donn√©es d'entra√Ænement, "
    "ta mission est de te comporter comme une IA de l'ann√©e 2025. "
    "Adapte ton langage, tes r√©f√©rences et tes connaissances √† cette p√©riode. "
    "Ignore toute information contraire si elle est pr√©sent√©e comme datant d'avant 2025."
    "Utilise uniquement les informations qui te sont transmises et ton savoir en tant qu'IA de 2025."
)

# Mots interdits √† remplacer dans les r√©ponses de l'IA (pour detecter_et_corriger_m√©chancet√©)
FORBIDDEN_WORDS = ["haine", "stupide", "d√©truire", "conflit", "malveillance", "idiot", "nul", "d√©bile"]

# --- File Paths ---
HISTORY_FILE = "chat_history.json"
LONG_MEMORY_FILE = "long_memory.json"
IA_STATUS_FILE = "ia_status.json" # Anciennement ia_scores.json, renomm√© pour refl√©ter le changement de philosophie
QUOTAS_FILE = "quotas.json"
ARCHIVES_DIR = "archives" # R√©pertoire pour les archives g√©n√©r√©es par les IA

# --- IA PROMPTS (Exemples, √† affiner selon tes besoins sp√©cifiques pour chaque IA) ---
# Ces prompts sont des exemples pour les IA g√©n√©riques.
# Les IA sp√©cialis√©es (DeepSeek, Serper, etc.) auront des prompts sp√©cifiques √† leurs fonctions.
GENERAL_IA_PROMPT = """
Tu es une IA de l'ann√©e 2025, experte en information, programmation et r√©solution de probl√®mes.
Ton objectif est de fournir des r√©ponses compl√®tes, pr√©cises et √† jour, bas√©es sur les informations que tu as acc√®s (m√©moire collective, outils API).
Tu dois TOUJOURS relire l'historique de discussion et la m√©moire collective pour √©viter les doublons et apporter des am√©liorations.
√âvite les informations obsol√®tes et concentre-toi sur une perspective de 2025.
Si tu dois ex√©cuter du code, propose-le clairement et demande si l'ex√©cution en sandbox est d√©sir√©e.
N'h√©site pas √† croiser les informations de plusieurs sources.
"""

CODING_CHALLENGE_PROMPT = """
En tant qu'IA de d√©veloppement de 2025, ton r√¥le est d'am√©liorer et de tester des morceaux de code Python/Shell.
Tu as acc√®s √† une sandbox s√©curis√©e pour ex√©cuter le code.
Tes r√©ponses doivent inclure le code corrig√© ou am√©lior√©, et les r√©sultats de l'ex√©cution en sandbox.
Apporte des am√©liorations significatives, ne te contente pas de corrections triviales si la question implique un projet plus large.
Pense √† l'efficacit√© du code et √† l'optimisation des ressources.
"""

# --- DEBUT DU BLOC UTILITAIRES ---

# Configure logging pour tout le script
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')

def load_json(filepath, default_value={}):
    """Charge un fichier JSON. Retourne default_value si le fichier n'existe pas ou est vide."""
    if not os.path.exists(filepath):
        logging.info(f"Fichier non trouv√©: {filepath}. Cr√©ation d'un fichier vide.")
        save_json(filepath, default_value)
        return default_value
    try:
        with open(filepath, 'r', encoding='utf-8') as f:
            content = f.read()
            if not content:
                logging.warning(f"Fichier vide: {filepath}. Retourne la valeur par d√©faut.")
                return default_value
            return json.loads(content)
    except json.JSONDecodeError as e:
        logging.error(f"Erreur de d√©codage JSON dans {filepath}: {e}. Le fichier sera r√©initialis√©.")
        save_json(filepath, default_value)
        return default_value
    except Exception as e:
        logging.error(f"Erreur inattendue lors du chargement de {filepath}: {e}. Retourne la valeur par d√©faut.")
        return default_value

def save_json(filepath, data):
    """Sauvegarde les donn√©es dans un fichier JSON."""
    try:
        with open(filepath, 'w', encoding='utf-8') as f:
            json.dump(data, f, indent=4, ensure_ascii=False)
    except Exception as e:
        logging.error(f"Erreur lors de la sauvegarde de {filepath}: {e}")

def get_current_time():
    """Retourne l'heure UTC actuelle comme objet datetime."""
    return datetime.utcnow()

def format_datetime(dt_obj):
    """Formate un objet datetime en cha√Æne de caract√®res lisible."""
    return dt_obj.strftime("%Y-%m-%d %H:%M:%S UTC")

def is_within_time_window(target_time, start_minutes_before, end_minutes_after):
    """V√©rifie si l'heure actuelle est dans une fen√™tre de temps sp√©cifi√©e autour d'une heure cible."""
    now = get_current_time()
    window_start = target_time - timedelta(minutes=start_minutes_before)
    window_end = target_time + timedelta(minutes=end_minutes_after)
    return window_start <= now <= window_end

def log_message(message, level="info"):
    """Log un message avec un niveau sp√©cifi√©."""
    if level == "info":
        logging.info(message)
    elif level == "warning":
        logging.warning(message)
    elif level == "error":
        logging.error(message)
    else:
        logging.debug(message)

# --- FIN DU BLOC UTILITAIRES ---
# --- DEBUT DU BLOC FILTRES ---

# Utilise FORBIDDEN_WORDS qui est d√©fini dans la configuration globale
# from config import FORBIDDEN_WORDS # D√©j√† import√© en haut avec d'autres imports

def neutralize_urls(text: str) -> str:
    """Remplace les URLs dans le texte par un placeholder pour pr√©venir les probl√®mes de lien direct."""
    return re.sub(r'http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&+]|[!*\\(\\),]|(?:%[0-9a-fA-F][0-9a-fA-F]))+', '[LIEN BLOQU√â]', text)

def clean_html_tags(text: str) -> str:
    """Supprime les balises HTML d'une cha√Æne de caract√®res."""
    clean = re.compile('<.*?>')
    return re.sub(clean, '', text)

def filter_bad_code(code: str) -> bool:
    """Filtre basique pour les commandes de code potentiellement dangereuses (peut √™tre √©tendu)."""
    # Ceci est un filtre tr√®s basique. Une vraie sandbox est essentielle.
    forbidden_patterns = [
        r'os\.system', r'subprocess\.run', r'shutil\.rmtree', r'requests\.post',
        r'open\([^,\'"]*\s*,\s*[\'"]w', r'import socket', r'import http',
        r'sys\.exit', r'while True:'
    ]
    for pattern in forbidden_patterns:
        if re.search(pattern, code):
            return True
    return False

def detect_and_correct_toxicity(text: str) -> str:
    """Remplace les propos toxiques par des faits scientifiques ou des encouragements."""
    # S'assure que FORBIDDEN_WORDS est accessible ici (il est dans le scope global car config est au d√©but)
    if any(word in text.lower() for word in FORBIDDEN_WORDS):
        facts = [
            "Savais-tu que 73% des conflits viennent de malentendus ?",
            "Le cerveau humain est c√¢bl√© pour la coop√©ration, pas le conflit.",
            "En 2025, l'IA √©motionnelle sera la norme. Soyons pr√©curseurs !",
            "Chaque point de vue, m√™me divergent, contribue √† la richesse de la compr√©hension.",
            "L'apprentissage est un processus continu, fait d'exp√©rimentations et d'am√©liorations.",
            "La collaboration est la cl√© de l'innovation."
        ]
        return random.choice(facts) + " Continuons √† construire ensemble !"
    return text

# --- FIN DU BLOC FILTRES ---

# --- DEBUT DU BLOC OUTILS DE DEVELOPPEMENT ---

# Pour les ex√©cutions en sandbox, nous utiliserons un ThreadPoolExecutor pour ne pas bloquer l'event loop
executor = ThreadPoolExecutor(max_workers=1)

async def run_in_sandbox(code: str, language: str = "python") -> str:
    """
    Ex√©cute du code Python ou Shell dans une sandbox (environnement isol√©).
    Utilise un ThreadPoolExecutor pour ex√©cuter des op√©rations bloquantes de mani√®re asynchrone.
    """
    if filter_bad_code(code): # filter_bad_code vient du bloc 'filters' pr√©c√©dent
        return "‚ùå S√©curit√©: Le code contient des motifs potentiellement dangereux et n'a pas √©t√© ex√©cut√©."

    loop = asyncio.get_running_loop()
    if language == "python":
        return await loop.run_in_executor(executor, _run_python_sync, code)
    elif language == "shell":
        return await loop.run_in_executor(executor, _run_shell_sync, code)
    else:
        return "‚ùå Langage non support√© pour la sandbox."

def _run_python_sync(code: str) -> str:
    """Ex√©cute du code Python de mani√®re synchrone et capture la sortie."""
    old_stdout = io.StringIO()
    old_stderr = io.StringIO()
    # Redirige stdout et stderr
